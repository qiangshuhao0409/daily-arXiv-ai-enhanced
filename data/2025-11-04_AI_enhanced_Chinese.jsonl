{"id": "2511.00377", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00377", "abs": "https://arxiv.org/abs/2511.00377", "authors": ["Xiaoling Han", "Bin Lin", "Nan Wu", "Ping Wang", "Zhenyu Na", "Miyuan Zhang"], "title": "Design of a Turbo-based Deep Semantic Autoencoder for Marine Internet of Things", "comment": null, "summary": "With the rapid growth of the global marine economy and flourishing maritime\nactivities, the marine Internet of Things (IoT) is gaining unprecedented\nmomentum. However, current marine equipment is deficient in data transmission\nefficiency and semantic comprehension. To address these issues, this paper\nproposes a novel End-to-End (E2E) coding scheme, namely the Turbo-based Deep\nSemantic Autoencoder (Turbo-DSA). The Turbo-DSA achieves joint source-channel\ncoding at the semantic level through the E2E design of transmitter and\nreceiver, while learning to adapt to environment changes. The semantic encoder\nand decoder are composed of transformer technology, which efficiently converts\nmessages into semantic vectors. These vectors are dynamically adjusted during\nneural network training according to channel characteristics and background\nknowledge base. The Turbo structure further enhances the semantic vectors.\nSpecifically, the channel encoder utilizes Turbo structure to separate semantic\nvectors, ensuring precise transmission of meaning, while the channel decoder\nemploys Turbo iterative decoding to optimize the representation of semantic\nvectors. This deep integration of the transformer and Turbo structure is\nensured by the design of the objective function, semantic extraction, and the\nentire training process. Compared with traditional Turbo coding techniques, the\nTurbo-DSA shows a faster convergence speed, thanks to its efficient processing\nof semantic vectors. Simulation results demonstrate that the Turbo-DSA\nsurpasses existing benchmarks in key performance indicators, such as bilingual\nevaluation understudy scores and sentence similarity. This is particularly\nevident under low signal-to-noise ratio conditions, where it shows superior\ntext semantic transmission efficiency and adaptability to variable marine\nchannel environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTurbo\u7ed3\u6784\u7684\u6df1\u5ea6\u8bed\u4e49\u81ea\u52a8\u7f16\u7801\u5668(Turbo-DSA)\uff0c\u7528\u4e8e\u6d77\u6d0b\u7269\u8054\u7f51\u4e2d\u7684\u7aef\u5230\u7aef\u8bed\u4e49\u901a\u4fe1\uff0c\u7ed3\u5408Transformer\u548cTurbo\u7ed3\u6784\u63d0\u5347\u8bed\u4e49\u4f20\u8f93\u6548\u7387\u548c\u73af\u5883\u9002\u5e94\u6027\u3002", "motivation": "\u5f53\u524d\u6d77\u6d0b\u8bbe\u5907\u5728\u6570\u636e\u4f20\u8f93\u6548\u7387\u548c\u8bed\u4e49\u7406\u89e3\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u89e3\u51b3\u6d77\u6d0b\u7269\u8054\u7f51\u4e2d\u8bed\u4e49\u7ea7\u8054\u5408\u4fe1\u6e90\u4fe1\u9053\u7f16\u7801\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528Transformer\u6280\u672f\u6784\u5efa\u8bed\u4e49\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\uff0c\u5c06\u6d88\u606f\u8f6c\u6362\u4e3a\u8bed\u4e49\u5411\u91cf\uff0c\u5e76\u901a\u8fc7Turbo\u7ed3\u6784\u8fdb\u884c\u5411\u91cf\u5206\u79bb\u548c\u8fed\u4ee3\u89e3\u7801\u4f18\u5316\u3002", "result": "\u76f8\u6bd4\u4f20\u7edfTurbo\u7f16\u7801\u6280\u672f\uff0cTurbo-DSA\u5177\u6709\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\uff0c\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6587\u672c\u8bed\u4e49\u4f20\u8f93\u6548\u7387\u548c\u6d77\u6d0b\u4fe1\u9053\u73af\u5883\u9002\u5e94\u6027\u3002", "conclusion": "Turbo-DSA\u5728\u6d77\u6d0b\u7269\u8054\u7f51\u8bed\u4e49\u901a\u4fe1\u4e2d\u5c55\u73b0\u51fa\u5353\u8d8a\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6076\u52a3\u4fe1\u9053\u6761\u4ef6\u4e0b\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2511.00020", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00020", "abs": "https://arxiv.org/abs/2511.00020", "authors": ["Suhasnadh Reddy Veluru", "Sai Teja Erukude", "Viswa Chaitanya Marella"], "title": "Multimodal Detection of Fake Reviews using BERT and ResNet-50", "comment": "Published in IEEE", "summary": "In the current digital commerce landscape, user-generated reviews play a\ncritical role in shaping consumer behavior, product reputation, and platform\ncredibility. However, the proliferation of fake or misleading reviews often\ngenerated by bots, paid agents, or AI models poses a significant threat to\ntrust and transparency within review ecosystems. Existing detection models\nprimarily rely on unimodal, typically textual, data and therefore fail to\ncapture semantic inconsistencies across different modalities. To address this\ngap, a robust multimodal fake review detection framework is proposed,\nintegrating textual features encoded with BERT and visual features extracted\nusing ResNet-50. These representations are fused through a classification head\nto jointly predict review authenticity. To support this approach, a curated\ndataset comprising 21,142 user-uploaded images across food delivery,\nhospitality, and e-commerce domains was utilized. Experimental results indicate\nthat the multimodal model outperforms unimodal baselines, achieving an F1-score\nof 0.934 on the test set. Additionally, the confusion matrix and qualitative\nanalysis highlight the model's ability to detect subtle inconsistencies, such\nas exaggerated textual praise paired with unrelated or low-quality images,\ncommonly found in deceptive content. This study demonstrates the critical role\nof multimodal learning in safeguarding digital trust and offers a scalable\nsolution for content moderation across various online platforms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u5047\u8bc4\u8bba\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u6587\u672c\u548c\u89c6\u89c9\u7279\u5f81\u6765\u8bc6\u522b\u865a\u5047\u8bc4\u8bba\uff0c\u5728\u6d4b\u8bd5\u96c6\u4e0aF1\u5206\u6570\u8fbe\u52300.934\uff0c\u4f18\u4e8e\u5355\u6a21\u6001\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u6570\u5b57\u5546\u52a1\u4e2d\u7528\u6237\u751f\u6210\u8bc4\u8bba\u5bf9\u6d88\u8d39\u8005\u884c\u4e3a\u5f71\u54cd\u91cd\u5927\uff0c\u4f46\u865a\u5047\u8bc4\u8bba\u6cdb\u6ee5\u5a01\u80c1\u5e73\u53f0\u53ef\u4fe1\u5ea6\u3002\u73b0\u6709\u68c0\u6d4b\u6a21\u578b\u4ec5\u4f9d\u8d56\u6587\u672c\u6570\u636e\uff0c\u65e0\u6cd5\u6355\u6349\u591a\u6a21\u6001\u95f4\u7684\u8bed\u4e49\u4e0d\u4e00\u81f4\u6027\u3002", "method": "\u96c6\u6210BERT\u7f16\u7801\u7684\u6587\u672c\u7279\u5f81\u548cResNet-50\u63d0\u53d6\u7684\u89c6\u89c9\u7279\u5f81\uff0c\u901a\u8fc7\u5206\u7c7b\u5934\u878d\u5408\u8fd9\u4e9b\u8868\u793a\u6765\u8054\u5408\u9884\u6d4b\u8bc4\u8bba\u771f\u5b9e\u6027\u3002\u4f7f\u7528\u5305\u542b21,142\u5f20\u7528\u6237\u4e0a\u4f20\u56fe\u7247\u7684\u8de8\u9886\u57df\u6570\u636e\u96c6\u3002", "result": "\u591a\u6a21\u6001\u6a21\u578b\u6027\u80fd\u4f18\u4e8e\u5355\u6a21\u6001\u57fa\u7ebf\uff0c\u6d4b\u8bd5\u96c6F1\u5206\u6570\u8fbe0.934\u3002\u6df7\u6dc6\u77e9\u9635\u548c\u5b9a\u6027\u5206\u6790\u663e\u793a\u6a21\u578b\u80fd\u68c0\u6d4b\u6587\u672c\u8d5e\u7f8e\u4e0e\u65e0\u5173/\u4f4e\u8d28\u91cf\u56fe\u50cf\u95f4\u7684\u5fae\u5999\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u591a\u6a21\u6001\u5b66\u4e60\u5728\u7ef4\u62a4\u6570\u5b57\u4fe1\u4efb\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4e3a\u5404\u5728\u7ebf\u5e73\u53f0\u7684\u5185\u5bb9\u5ba1\u6838\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00645", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00645", "abs": "https://arxiv.org/abs/2511.00645", "authors": ["C\u00e9cile Bouette", "Mich\u00e8le Wigger"], "title": "Multi-Sensor Distributed Hypothesis Testing in the Low-Power Regime", "comment": null, "summary": "We characterize the Stein-exponent of a distributed hypothesis testing\nscenario where two sensors transmit information through a memoryless multiple\naccess channel (MAC) subject to a sublinear input cost constraint with respect\nto the number of channel uses and where the decision center has access to an\nadditional local observation. Our main theorem provides conditions on the\nchannel and cost functions for which the Stein-exponent of this distributed\nsetup is no larger than the Stein-exponent of the local test at the decision\ncenter. Under these conditions, communication from the sensors to the decision\ncenter is thus useless in terms of Stein-exponent. The conditions are satisfied\nfor additive noise MACs with generalized Gaussian noise under a p-th moment\nconstraint (including the Gaussian channel with second-moment constraint) and\nfor the class of fully-connected (where all inputs can induce all outputs)\ndiscrete memoryless multiple-access channels (DMMACs) under arbitrary cost\nconstraints. We further show that for DMMACs that are not fully-connected, the\nStein-exponent is larger and coincides with that of a setup with zero-rate\nnoiseless communication links from either both sensors or only one sensor, as\nstudied in [1].", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5206\u5e03\u5f0f\u5047\u8bbe\u68c0\u9a8c\u573a\u666f\u4e2d\uff0c\u5f53\u51b3\u7b56\u4e2d\u5fc3\u6709\u672c\u5730\u89c2\u6d4b\u65f6\uff0c\u4f20\u611f\u5668\u901a\u8fc7\u591a\u5740\u4fe1\u9053\u4f20\u8f93\u4fe1\u606f\u7684Stein\u6307\u6570\u7279\u6027\u3002\u4e3b\u8981\u7ed3\u8bba\u662f\uff1a\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0c\u4f20\u611f\u5668\u7684\u901a\u4fe1\u5bf9Stein\u6307\u6570\u6ca1\u6709\u5e2e\u52a9\u3002", "motivation": "\u7814\u7a76\u5728\u5206\u5e03\u5f0f\u5047\u8bbe\u68c0\u9a8c\u4e2d\uff0c\u5f53\u51b3\u7b56\u4e2d\u5fc3\u6709\u989d\u5916\u672c\u5730\u89c2\u6d4b\u65f6\uff0c\u4f20\u611f\u5668\u901a\u8fc7\u591a\u5740\u4fe1\u9053\u4f20\u8f93\u4fe1\u606f\u662f\u5426\u80fd\u591f\u63d0\u9ad8\u68c0\u6d4b\u6027\u80fd\uff08\u4ee5Stein\u6307\u6570\u8861\u91cf\uff09\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u5efa\u7acb\u4e86\u591a\u5740\u4fe1\u9053\u548c\u6210\u672c\u51fd\u6570\u6ee1\u8db3\u7279\u5b9a\u6761\u4ef6\u65f6\uff0c\u5206\u5e03\u5f0f\u8bbe\u7f6e\u7684Stein\u6307\u6570\u4e0d\u8d85\u8fc7\u51b3\u7b56\u4e2d\u5fc3\u672c\u5730\u68c0\u9a8c\u7684Stein\u6307\u6570\u7684\u5b9a\u7406\u3002", "result": "\u5bf9\u4e8e\u52a0\u6027\u566a\u58f0\u591a\u5740\u4fe1\u9053\uff08\u5982\u5e7f\u4e49\u9ad8\u65af\u566a\u58f0\uff09\u548c\u5168\u8fde\u901a\u79bb\u6563\u591a\u5740\u4fe1\u9053\uff0c\u4f20\u611f\u5668\u7684\u901a\u4fe1\u5bf9Stein\u6307\u6570\u6ca1\u6709\u6539\u8fdb\u3002\u5bf9\u4e8e\u975e\u5168\u8fde\u901a\u79bb\u6563\u591a\u5740\u4fe1\u9053\uff0cStein\u6307\u6570\u66f4\u5927\u4e14\u7b49\u4e8e\u96f6\u901f\u7387\u65e0\u566a\u58f0\u901a\u4fe1\u94fe\u8def\u7684\u6027\u80fd\u3002", "conclusion": "\u5728\u7279\u5b9a\u4fe1\u9053\u6761\u4ef6\u4e0b\uff0c\u4f20\u611f\u5668\u5230\u51b3\u7b56\u4e2d\u5fc3\u7684\u901a\u4fe1\u5bf9Stein\u6307\u6570\u6ca1\u6709\u8d21\u732e\uff0c\u51b3\u7b56\u4e2d\u5fc3\u7684\u672c\u5730\u89c2\u6d4b\u5df2\u8db3\u591f\u3002"}}
{"id": "2511.00039", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00039", "abs": "https://arxiv.org/abs/2511.00039", "authors": ["Krishna Kumar Neelakanta Pillai Santha Kumari Amma"], "title": "Graph-Attentive MAPPO for Dynamic Retail Pricing", "comment": null, "summary": "Dynamic pricing in retail requires policies that adapt to shifting demand\nwhile coordinating decisions across related products. We present a systematic\nempirical study of multi-agent reinforcement learning for retail price\noptimization, comparing a strong MAPPO baseline with a\ngraph-attention-augmented variant (MAPPO+GAT) that leverages learned\ninteractions among products. Using a simulated pricing environment derived from\nreal transaction data, we evaluate profit, stability across random seeds,\nfairness across products, and training efficiency under a standardized\nevaluation protocol. The results indicate that MAPPO provides a robust and\nreproducible foundation for portfolio-level price control, and that MAPPO+GAT\nfurther enhances performance by sharing information over the product graph\nwithout inducing excessive price volatility. These results indicate that\ngraph-integrated MARL provides a more scalable and stable solution than\nindependent learners for dynamic retail pricing, offering practical advantages\nin multi-product decision-making.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u96f6\u552e\u4ef7\u683c\u4f18\u5316\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0MAPPO+GAT\uff08\u56fe\u6ce8\u610f\u529b\u589e\u5f3a\u7248\u672c\uff09\u901a\u8fc7\u4ea7\u54c1\u95f4\u4fe1\u606f\u5171\u4eab\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u6bd4\u72ec\u7acb\u5b66\u4e60\u5668\u66f4\u5177\u53ef\u6269\u5c55\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u96f6\u552e\u52a8\u6001\u5b9a\u4ef7\u9700\u8981\u80fd\u591f\u9002\u5e94\u9700\u6c42\u53d8\u5316\u5e76\u534f\u8c03\u76f8\u5173\u4ea7\u54c1\u51b3\u7b56\u7684\u7b56\u7565\uff0c\u591a\u4ea7\u54c1\u51b3\u7b56\u9762\u4e34\u6311\u6218\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u771f\u5b9e\u4ea4\u6613\u6570\u636e\u7684\u6a21\u62df\u5b9a\u4ef7\u73af\u5883\uff0c\u6bd4\u8f83MAPPO\u57fa\u7ebf\u548c\u56fe\u6ce8\u610f\u529b\u589e\u5f3a\u7684MAPPO+GAT\uff0c\u8bc4\u4f30\u5229\u6da6\u3001\u7a33\u5b9a\u6027\u3001\u516c\u5e73\u6027\u548c\u8bad\u7ec3\u6548\u7387\u3002", "result": "MAPPO\u4e3a\u7ec4\u5408\u7ea7\u4ef7\u683c\u63a7\u5236\u63d0\u4f9b\u4e86\u7a33\u5065\u57fa\u7840\uff0cMAPPO+GAT\u901a\u8fc7\u4ea7\u54c1\u56fe\u4fe1\u606f\u5171\u4eab\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4e14\u672a\u5f15\u53d1\u8fc7\u5ea6\u4ef7\u683c\u6ce2\u52a8\u3002", "conclusion": "\u56fe\u96c6\u6210MARL\u4e3a\u52a8\u6001\u96f6\u552e\u5b9a\u4ef7\u63d0\u4f9b\u4e86\u6bd4\u72ec\u7acb\u5b66\u4e60\u5668\u66f4\u5177\u53ef\u6269\u5c55\u6027\u548c\u7a33\u5b9a\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u591a\u4ea7\u54c1\u51b3\u7b56\u4e2d\u5177\u6709\u5b9e\u9645\u4f18\u52bf\u3002"}}
{"id": "2511.00766", "categories": ["cs.IT", "math.IT", "94B05, 94B35"], "pdf": "https://arxiv.org/pdf/2511.00766", "abs": "https://arxiv.org/abs/2511.00766", "authors": ["Guodong Wang", "Hongwei Liu", "Jinquan Luo"], "title": "Improved Decoding Algorithms for MDS and Almost-MDS Codesfrom Twisted GRS Codes", "comment": null, "summary": "In this paper, firstly, we study decoding of a general class of twisted\ngeneralized Reed-Solomon (TGRS) codes and provide a precise characterization of\nthe key equation for TGRS codes and propose a decoding algorithm. Secondly, we\nfurther study decoding of almost-MDS TGRS codes and provide a decoding\nalgorithm. These two decoding algorithms are more efficient in terms of\nperformance compared with the decoding algorithms presented in [Sun et al.,\nIEEE-TIT, 2024] and [Sui et al., IEEE-TIT, 2023] respectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u9ad8\u6548\u7684\u626d\u66f2\u5e7f\u4e49\u91cc\u5fb7-\u6240\u7f57\u95e8\u7801\u89e3\u7801\u7b97\u6cd5\uff0c\u5206\u522b\u9488\u5bf9\u4e00\u822c\u7c7b\u548c\u51e0\u4e4eMDS\u7c7b\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709TGRS\u7801\u89e3\u7801\u7b97\u6cd5\u6548\u7387\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u89e3\u7801\u65b9\u6848\u6765\u63d0\u5347\u6027\u80fd\u3002", "method": "\u7814\u7a76TGRS\u7801\u7684\u5173\u952e\u65b9\u7a0b\u7279\u6027\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u89e3\u7801\u7b97\u6cd5\uff1b\u7279\u522b\u9488\u5bf9\u51e0\u4e4eMDS TGRS\u7801\u5f00\u53d1\u4e13\u7528\u89e3\u7801\u7b97\u6cd5\u3002", "result": "\u63d0\u51fa\u7684\u4e24\u79cd\u89e3\u7801\u7b97\u6cd5\u5728\u6027\u80fd\u4e0a\u5206\u522b\u4f18\u4e8eSun\u7b49\u4eba\u548cSui\u7b49\u4eba\u7684\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u9ad8\u6548\u7684TGRS\u7801\u89e3\u7801\u7b97\u6cd5\uff0c\u4e3a\u626d\u66f2\u5e7f\u4e49\u91cc\u5fb7-\u6240\u7f57\u95e8\u7801\u7684\u89e3\u7801\u63d0\u4f9b\u4e86\u66f4\u4f18\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00048", "categories": ["cs.AI", "cs.CY", "62-11", "E.5; G.3; I.6.4; I.6.6; J.3; J.4"], "pdf": "https://arxiv.org/pdf/2511.00048", "abs": "https://arxiv.org/abs/2511.00048", "authors": ["Martin Bicher", "Maximilian Viehauser", "Daniele Giannandrea", "Hannah Kastinger", "Dominik Brunmeir", "Claire Rippinger", "Christoph Urach", "Niki Popper"], "title": "GEPOC Parameters - Open Source Parametrisation and Validation for Austria, Version 2.0", "comment": "134 pages, 75 figures, 19 tables", "summary": "GEPOC, short for Generic Population Concept, is a collection of models and\nmethods for analysing population-level research questions. For the valid\napplication of the models for a specific country or region, stable and\nreproducible data processes are necessary, which provide valid and ready-to-use\nmodel parameters. This work contains a complete description of the\ndata-processing methods for computation of model parameters for Austria, based\nexclusively on freely and publicly accessible data. In addition to the\ndescription of the source data used, this includes all algorithms used for\naggregation, disaggregation, fusion, cleansing or scaling of the data, as well\nas a description of the resulting parameter files. The document places\nparticular emphasis on the computation of parameters for the most important\nGEPOC model, GEPOC ABM, a continuous-time agent-based population model. An\nextensive validation study using this particular model was made and is\npresented at the end of this work.", "AI": {"tldr": "GEPOC\u662f\u4e00\u4e2a\u901a\u7528\u4eba\u53e3\u6982\u5ff5\u6a21\u578b\u96c6\uff0c\u672c\u6587\u63cf\u8ff0\u4e86\u4e3a\u5965\u5730\u5229\u8ba1\u7b97\u6a21\u578b\u53c2\u6570\u7684\u5b8c\u6574\u6570\u636e\u5904\u7406\u65b9\u6cd5\uff0c\u57fa\u4e8e\u516c\u5f00\u53ef\u83b7\u53d6\u6570\u636e\uff0c\u5e76\u7279\u522b\u5173\u6ce8GEPOC ABM\u4ee3\u7406\u6a21\u578b\u7684\u53c2\u6570\u8ba1\u7b97\u548c\u9a8c\u8bc1\u7814\u7a76\u3002", "motivation": "\u4e3aGEPOC\u6a21\u578b\u5728\u7279\u5b9a\u56fd\u5bb6\u6216\u5730\u533a\u7684\u6709\u6548\u5e94\u7528\uff0c\u9700\u8981\u7a33\u5b9a\u53ef\u590d\u73b0\u7684\u6570\u636e\u5904\u7406\u6d41\u7a0b\u6765\u63d0\u4f9b\u6709\u6548\u7684\u6a21\u578b\u53c2\u6570\u3002", "method": "\u57fa\u4e8e\u516c\u5f00\u53ef\u83b7\u53d6\u6570\u636e\uff0c\u4f7f\u7528\u805a\u5408\u3001\u5206\u89e3\u3001\u878d\u5408\u3001\u6e05\u6d17\u548c\u7f29\u653e\u7b49\u7b97\u6cd5\u5904\u7406\u6570\u636e\uff0c\u8ba1\u7b97GEPOC ABM\u4ee3\u7406\u6a21\u578b\u7684\u53c2\u6570\u3002", "result": "\u5f00\u53d1\u4e86\u5b8c\u6574\u7684\u53c2\u6570\u8ba1\u7b97\u6d41\u7a0b\uff0c\u5e76\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u9a8c\u8bc1\u7814\u7a76\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u57fa\u4e8e\u516c\u5f00\u6570\u636e\u7684GEPOC\u6a21\u578b\u53c2\u6570\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u9a8c\u8bc1\u7814\u7a76\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2511.00809", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00809", "abs": "https://arxiv.org/abs/2511.00809", "authors": ["Yang Xu", "Haibin Kan", "Guangyue Han"], "title": "An Elementary Approach to MacWilliams Extension Property and Constant Weight Code with Respect to Weighted Hamming Metric", "comment": null, "summary": "In this paper, we characterize the MacWilliams extension property (MEP) and\nconstant weight codes with respect to $\\omega$-weight defined on\n$\\mathbb{F}^{\\Omega}$ via an elementary approach, where $\\mathbb{F}$ is a\nfinite field, $\\Omega$ is a finite set, and\n$\\omega:\\Omega\\longrightarrow\\mathbb{R}^{+}$ is a weight function. Our approach\nrelies solely on elementary linear algebra and two key identities for\n$\\omega$-weight of subspaces derived from a double-counting argument. When\n$\\omega$ is the constant $1$ map, our results recover two well-known results\nfor Hamming metric code: (1) any Hamming weight preserving map between linear\ncodes extends to a Hamming weight isometry of the entire ambient space; and (2)\nany constant weight Hamming metric code is a repetition of the dual of Hamming\ncode.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u521d\u7b49\u65b9\u6cd5\u7814\u7a76\u4e86\u6709\u9650\u57df\u4e0a\u57fa\u4e8e\u03c9-\u6743\u91cd\u7684MacWilliams\u6269\u5c55\u6027\u8d28\u548c\u5e38\u91cd\u7801\uff0c\u5f53\u03c9\u4e3a\u5e38\u65701\u6620\u5c04\u65f6\uff0c\u7ed3\u679c\u6062\u590d\u4e86\u6c49\u660e\u5ea6\u91cf\u7801\u7684\u4e24\u4e2a\u7ecf\u5178\u7ed3\u8bba\u3002", "motivation": "\u7814\u7a76\u6709\u9650\u57df\u4e0a\u57fa\u4e8e\u03c9-\u6743\u91cd\u7684MacWilliams\u6269\u5c55\u6027\u8d28\u548c\u5e38\u91cd\u7801\uff0c\u4e3a\u6c49\u660e\u5ea6\u91cf\u7801\u7684\u7ecf\u5178\u7ed3\u679c\u63d0\u4f9b\u66f4\u4e00\u822c\u5316\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u521d\u7b49\u7ebf\u6027\u4ee3\u6570\u548c\u901a\u8fc7\u53cc\u91cd\u8ba1\u6570\u8bba\u8bc1\u63a8\u5bfc\u51fa\u7684\u03c9-\u6743\u91cd\u5b50\u7a7a\u95f4\u7684\u4e24\u4e2a\u5173\u952e\u6052\u7b49\u5f0f\u3002", "result": "\u5efa\u7acb\u4e86\u03c9-\u6743\u91cd\u4e0b\u7684MacWilliams\u6269\u5c55\u6027\u8d28\u548c\u5e38\u91cd\u7801\u7684\u5b8c\u6574\u523b\u753b\uff0c\u5f53\u03c9\u4e3a\u5e38\u65701\u65f6\uff0c\u7ed3\u679c\u4e0e\u6c49\u660e\u5ea6\u91cf\u7801\u7684\u7ecf\u5178\u7ed3\u8bba\u4e00\u81f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7814\u7a76\u66f4\u4e00\u822c\u7684\u6743\u91cd\u51fd\u6570\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u7edf\u4e00\u4e86\u6c49\u660e\u5ea6\u91cf\u7801\u7684\u7ecf\u5178\u7ed3\u679c\u3002"}}
{"id": "2511.00092", "categories": ["cs.AI", "cs.CL", "cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.00092", "abs": "https://arxiv.org/abs/2511.00092", "authors": ["Shunya Minami", "Tatsuya Ishigaki", "Ikko Hamamura", "Taku Mikuriya", "Youmi Ma", "Naoaki Okazaki", "Hiroya Takamura", "Yohichi Suzuki", "Tadashi Kadowaki"], "title": "QuantumBench: A Benchmark for Quantum Problem Solving", "comment": "11 pages, 8 figures", "summary": "Large language models are now integrated into many scientific workflows,\naccelerating data analysis, hypothesis generation, and design space\nexploration. In parallel with this growth, there is a growing need to carefully\nevaluate whether models accurately capture domain-specific knowledge and\nnotation, since general-purpose benchmarks rarely reflect these requirements.\nThis gap is especially clear in quantum science, which features non-intuitive\nphenomena and requires advanced mathematics. In this study, we introduce\nQuantumBench, a benchmark for the quantum domain that systematically examine\nhow well LLMs understand and can be applied to this non-intuitive field. Using\npublicly available materials, we compiled approximately 800 questions with\ntheir answers spanning nine areas related to quantum science and organized them\ninto an eight-option multiple-choice dataset. With this benchmark, we evaluate\nseveral existing LLMs and analyze their performance in the quantum domain,\nincluding sensitivity to changes in question format. QuantumBench is the first\nLLM evaluation dataset built for the quantum domain, and it is intended to\nguide the effective use of LLMs in quantum research.", "AI": {"tldr": "QuantumBench\u662f\u9996\u4e2a\u4e13\u95e8\u4e3a\u91cf\u5b50\u79d1\u5b66\u9886\u57df\u6784\u5efa\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5305\u542b\u7ea6800\u4e2a\u9009\u62e9\u9898\uff0c\u6db5\u76d69\u4e2a\u91cf\u5b50\u79d1\u5b66\u9886\u57df\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u91cf\u5b50\u9886\u57df\u7684\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u901a\u7528\u57fa\u51c6\u6d4b\u8bd5\u5f88\u5c11\u53cd\u6620\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u548c\u7b26\u53f7\u7684\u9700\u6c42\uff0c\u7279\u522b\u662f\u5728\u91cf\u5b50\u79d1\u5b66\u8fd9\u79cd\u5177\u6709\u975e\u76f4\u89c2\u73b0\u8c61\u548c\u9700\u8981\u9ad8\u7b49\u6570\u5b66\u7684\u9886\u57df\uff0c\u9700\u8981\u4e13\u95e8\u8bc4\u4f30LLMs\u662f\u5426\u51c6\u786e\u638c\u63e1\u9886\u57df\u77e5\u8bc6\u3002", "method": "\u4f7f\u7528\u516c\u5f00\u6750\u6599\u7f16\u5236\u7ea6800\u4e2a\u95ee\u9898\u53ca\u5176\u7b54\u6848\uff0c\u6db5\u76d69\u4e2a\u91cf\u5b50\u79d1\u5b66\u76f8\u5173\u9886\u57df\uff0c\u7ec4\u7ec7\u62108\u9009\u9879\u9009\u62e9\u9898\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u591a\u4e2a\u73b0\u6709LLMs\u5e76\u5206\u6790\u5176\u5bf9\u95ee\u9898\u683c\u5f0f\u53d8\u5316\u7684\u654f\u611f\u6027\u3002", "result": "\u901a\u8fc7QuantumBench\u8bc4\u4f30\u4e86\u591a\u4e2a\u73b0\u6709LLMs\u5728\u91cf\u5b50\u9886\u57df\u7684\u8868\u73b0\uff0c\u5e76\u5206\u6790\u4e86\u5b83\u4eec\u5bf9\u95ee\u9898\u683c\u5f0f\u53d8\u5316\u7684\u654f\u611f\u6027\u3002", "conclusion": "QuantumBench\u662f\u9996\u4e2a\u4e3a\u91cf\u5b50\u9886\u57df\u6784\u5efa\u7684LLM\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u65e8\u5728\u6307\u5bfcLLMs\u5728\u91cf\u5b50\u7814\u7a76\u4e2d\u7684\u6709\u6548\u5e94\u7528\u3002"}}
{"id": "2511.00196", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.00196", "abs": "https://arxiv.org/abs/2511.00196", "authors": ["Leonardo Alberro", "Noura Limam", "Raouf Boutaba"], "title": "Towards Sub-millisecond Latency and Guaranteed Bit Rates in 5G User Plane", "comment": null, "summary": "Next-generation services demand stringent Quality of Service (QoS)\nguarantees, such as per-flow bandwidth assurance, ultra-low latency, and\ntraffic prioritization, posing significant challenges to 5G and beyond\nnetworks. As 5G network functions increasingly migrate to edge and central\nclouds, the transport layer becomes a critical enabler of end-to-end QoS\ncompliance. However, traditional fixed-function infrastructure lacks the\nflexibility to support the diverse and dynamic QoS profiles standardized by\n3GPP.\n  This paper presents a QoS-aware data plane model for programmable transport\nnetworks, designed to provide predictable behavior and fine-grained service\ndifferentiation. The model supports all 3GPP QoS resource types and integrates\nper-flow metering, classification, strict priority scheduling, and delay-aware\nqueuing. Implemented on off-the-shelf programmable hardware using P4 and\nevaluated on an Intel Tofino switch, our approach ensures per-flow bandwidth\nguarantees, sub-millisecond delay for delay-critical traffic, and resilience\nunder congestion. Experimental results demonstrate that the model achieves\nmicrosecond-level latencies and near-zero packet loss for mission-critical\nflows, validating its suitability for future QoS-sensitive applications in 5G\nand beyond.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u7f16\u7a0b\u786c\u4ef6\u7684\u6570\u636e\u5e73\u9762\u6a21\u578b\uff0c\u652f\u63013GPP QoS\u6807\u51c6\uff0c\u5728\u5546\u7528Tofino\u4ea4\u6362\u673a\u4e0a\u5b9e\u73b0\u5fae\u79d2\u7ea7\u5ef6\u8fdf\u548c\u63a5\u8fd1\u96f6\u4e22\u5305\u7387\u3002", "motivation": "5G\u53ca\u672a\u6765\u7f51\u7edc\u9700\u8981\u4e25\u683c\u7684QoS\u4fdd\u8bc1\uff0c\u4f46\u4f20\u7edf\u56fa\u5b9a\u529f\u80fd\u57fa\u7840\u8bbe\u65bd\u65e0\u6cd5\u652f\u63013GPP\u6807\u51c6\u5316\u7684\u591a\u6837\u5316\u52a8\u6001QoS\u914d\u7f6e\uff0c\u4f20\u8f93\u5c42\u6210\u4e3a\u7aef\u5230\u7aefQoS\u5408\u89c4\u7684\u5173\u952e\u4f7f\u80fd\u5668\u3002", "method": "\u8bbe\u8ba1\u53ef\u7f16\u7a0b\u4f20\u8f93\u7f51\u7edc\u7684QoS\u611f\u77e5\u6570\u636e\u5e73\u9762\u6a21\u578b\uff0c\u652f\u6301\u6240\u67093GPP QoS\u8d44\u6e90\u7c7b\u578b\uff0c\u96c6\u6210\u6bcf\u6d41\u8ba1\u91cf\u3001\u5206\u7c7b\u3001\u4e25\u683c\u4f18\u5148\u7ea7\u8c03\u5ea6\u548c\u5ef6\u8fdf\u611f\u77e5\u961f\u5217\uff0c\u4f7f\u7528P4\u5728Intel Tofino\u4ea4\u6362\u673a\u4e0a\u5b9e\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u786e\u4fdd\u6bcf\u6d41\u5e26\u5bbd\u4fdd\u8bc1\uff0c\u5ef6\u8fdf\u5173\u952e\u6d41\u91cf\u7684\u4e9a\u6beb\u79d2\u5ef6\u8fdf\uff0c\u5728\u62e5\u585e\u4e0b\u7684\u5f39\u6027\uff0c\u5b9e\u73b0\u5fae\u79d2\u7ea7\u5ef6\u8fdf\u548c\u5173\u952e\u4efb\u52a1\u6d41\u91cf\u7684\u63a5\u8fd1\u96f6\u4e22\u5305\u3002", "conclusion": "\u8be5\u6a21\u578b\u9a8c\u8bc1\u4e86\u5176\u9002\u7528\u4e8e5G\u53ca\u672a\u6765QoS\u654f\u611f\u5e94\u7528\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u670d\u52a1\u63d0\u4f9b\u53ef\u9884\u6d4b\u884c\u4e3a\u548c\u7ec6\u7c92\u5ea6\u670d\u52a1\u5dee\u5f02\u5316\u3002"}}
{"id": "2511.00887", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00887", "abs": "https://arxiv.org/abs/2511.00887", "authors": ["Trinh Van Chien", "Ngo Tran Anh Thu", "Nguyen Hoang Lam", "Hien Quoc Ngo", "Symeon Chatzinotas", "Huynh Thi Thanh Binh"], "title": "Fairness Designs for Load Balancing Optimization in Satellite-Cell-Free Massive MIMO Systems", "comment": "13 pages, 5 figures, 2 tables. Accepted by TAES", "summary": "Space-ground communication systems are important in providing ubiquitous\nservices in a large area. This paper considers the fairness designs under a\nload-balancing framework with heterogeneous receivers comprising access points\n(APs) and a satellite. We derive an ergodic throughput of each user in the\nuplink data transmission for an arbitrary association pattern and imperfect\nchannel state information, followed by a closed-form expression with the\nmaximum-ratio combining and rich scattering environments. We further formulate\na generic fairness optimization problem, subject to the optimal association\npatterns for all the users. Despite the combinatorial structure, the global\noptimal solution to the association patterns can be obtained by an exhaustive\nsearch for small-scale networks with several APs and users. We design a low\ncomputational complexity algorithm for large-scale networks based on\nevolutionary computation that obtains good patterns in polynomial time.\nSpecifically, the genetic algorithm (GA) is adapted to the discrete feasible\nregion and the concrete fairness metrics. We extensively observe the fairness\ndesign problem by incorporating transmit power control and propose a hybrid\ngenetic algorithm to address the problem. Numerical results demonstrate that\nthe association pattern to each user has a significant impact on the network\nthroughput. Moreover, the proposed GA-based algorithm offers the same\nperformance as an exhaustive search for small-scale networks, while it unveils\ninteresting practical association patterns as the network dimensions go large.\nThe load-balancing approach, combined with power control factors, significantly\nenhances system performance compared to conventional schemes and configurations\nwith fixed factors.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5929\u5730\u4e00\u4f53\u5316\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u516c\u5e73\u6027\u8bbe\u8ba1\uff0c\u5728\u8d1f\u8f7d\u5747\u8861\u6846\u67b6\u4e0b\u8003\u8651\u63a5\u5165\u70b9\u548c\u536b\u661f\u7684\u5f02\u6784\u63a5\u6536\u5668\uff0c\u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u7528\u6237\u5173\u8054\u6a21\u5f0f\uff0c\u7ed3\u5408\u529f\u7387\u63a7\u5236\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u5929\u5730\u4e00\u4f53\u5316\u901a\u4fe1\u7cfb\u7edf\u9700\u8981\u5728\u5927\u8303\u56f4\u533a\u57df\u5185\u63d0\u4f9b\u666e\u904d\u670d\u52a1\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u5728\u7528\u6237\u5173\u8054\u548c\u516c\u5e73\u6027\u65b9\u9762\u5b58\u5728\u4f18\u5316\u7a7a\u95f4\uff0c\u7279\u522b\u662f\u5728\u5f02\u6784\u63a5\u6536\u5668\uff08AP\u548c\u536b\u661f\uff09\u73af\u5883\u4e0b\u9700\u8981\u6709\u6548\u7684\u8d1f\u8f7d\u5747\u8861\u548c\u516c\u5e73\u6027\u8bbe\u8ba1\u3002", "method": "\u63a8\u5bfc\u4e86\u4efb\u610f\u5173\u8054\u6a21\u5f0f\u548c\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u4e0d\u5b8c\u7f8e\u60c5\u51b5\u4e0b\u7684\u7528\u6237\u4e0a\u884c\u94fe\u8def\u904d\u5386\u541e\u5410\u91cf\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u8fdb\u4e00\u6b65\u7ed3\u5408\u529f\u7387\u63a7\u5236\u8bbe\u8ba1\u4e86\u6df7\u5408\u9057\u4f20\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u7528\u6237\u5173\u8054\u6a21\u5f0f\u5bf9\u7f51\u7edc\u541e\u5410\u91cf\u6709\u663e\u8457\u5f71\u54cd\uff0c\u63d0\u51fa\u7684GA\u7b97\u6cd5\u5728\u5c0f\u89c4\u6a21\u7f51\u7edc\u4e2d\u4e0e\u7a77\u4e3e\u641c\u7d22\u6027\u80fd\u76f8\u540c\uff0c\u5728\u5927\u89c4\u6a21\u7f51\u7edc\u4e2d\u80fd\u53d1\u73b0\u5b9e\u7528\u7684\u5173\u8054\u6a21\u5f0f\uff0c\u7ed3\u5408\u529f\u7387\u63a7\u5236\u7684\u8d1f\u8f7d\u5747\u8861\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edf\u65b9\u6848\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u8d1f\u8f7d\u5747\u8861\u65b9\u6cd5\u80fd\u6709\u6548\u4f18\u5316\u5929\u5730\u4e00\u4f53\u5316\u901a\u4fe1\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u548c\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u7f51\u7edc\u4e2d\u63d0\u4f9b\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7ed3\u5408\u529f\u7387\u63a7\u5236\u53ef\u8fdb\u4e00\u6b65\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2511.00122", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00122", "abs": "https://arxiv.org/abs/2511.00122", "authors": ["Ran Xu", "Yupeng Qi", "Jingsen Feng", "Xu Chu"], "title": "Engineering.ai: A Platform for Teams of AI Engineers in Computational Design", "comment": null, "summary": "In modern engineering practice, human engineers collaborate in specialized\nteams to design complex products, with each expert completing their respective\ntasks while communicating and exchanging results and data with one another.\nWhile this division of expertise is essential for managing multidisciplinary\ncomplexity, it demands substantial development time and cost. Recently, we\nintroduced OpenFOAMGPT (1.0, 2.0), which functions as an autonomous AI engineer\nfor computational fluid dynamics, and turbulence.ai, which can conduct\nend-to-end research in fluid mechanics draft publications and PhD theses.\nBuilding upon these foundations, we present Engineering.ai, a platform for\nteams of AI engineers in computational design. The framework employs a\nhierarchical multi-agent architecture where a Chief Engineer coordinates\nspecialized agents consisting of Aerodynamics, Structural, Acoustic, and\nOptimization Engineers, each powered by LLM with domain-specific knowledge.\nAgent-agent collaboration is achieved through file-mediated communication for\ndata provenance and reproducibility, while a comprehensive memory system\nmaintains project context, execution history, and retrieval-augmented domain\nknowledge to ensure reliable decision-making across the workflow. The system\nintegrates FreeCAD, Gmsh, OpenFOAM, CalculiX, and BPM acoustic analysis,\nenabling parallel multidisciplinary simulations while maintaining computational\naccuracy. The framework is validated through UAV wing optimization. This work\ndemonstrates that agentic-AI-enabled AI engineers has the potential to perform\ncomplex engineering tasks autonomously. Remarkably, the automated workflow\nachieved a 100% success rate across over 400 parametric configurations, with\nzero mesh generation failures, solver convergence issues, or manual\ninterventions required, validating that the framework is trustworthy.", "AI": {"tldr": "\u63d0\u51fa\u4e86Engineering.ai\u5e73\u53f0\uff0c\u91c7\u7528\u5206\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u8ba9AI\u5de5\u7a0b\u5e08\u56e2\u961f\u5728\u8ba1\u7b97\u8bbe\u8ba1\u4e2d\u534f\u4f5c\u5b8c\u6210\u590d\u6742\u5de5\u7a0b\u4efb\u52a1\uff0c\u901a\u8fc7\u65e0\u4eba\u673a\u673a\u7ffc\u4f18\u5316\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u53ef\u9760\u6027\u548c100%\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u4ee3\u5de5\u7a0b\u5b9e\u8df5\u4e2d\uff0c\u4e13\u5bb6\u56e2\u961f\u534f\u4f5c\u8bbe\u8ba1\u590d\u6742\u4ea7\u54c1\u9700\u8981\u5927\u91cf\u5f00\u53d1\u65f6\u95f4\u548c\u6210\u672c\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u57fa\u4e8eOpenFOAMGPT\u548cturbulence.ai\u7684\u57fa\u7840\uff0c\u5f00\u53d1AI\u5de5\u7a0b\u5e08\u534f\u4f5c\u5e73\u53f0\u6765\u7ba1\u7406\u591a\u5b66\u79d1\u590d\u6742\u6027\u3002", "method": "\u91c7\u7528\u5206\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u9996\u5e2d\u5de5\u7a0b\u5e08\u534f\u8c03\u7a7a\u6c14\u52a8\u529b\u5b66\u3001\u7ed3\u6784\u3001\u58f0\u5b66\u548c\u4f18\u5316\u7b49\u4e13\u4e1a\u5de5\u7a0b\u5e08\u667a\u80fd\u4f53\u3002\u901a\u8fc7\u6587\u4ef6\u4ecb\u5bfc\u901a\u4fe1\u5b9e\u73b0\u6570\u636e\u6eaf\u6e90\u548c\u53ef\u590d\u73b0\u6027\uff0c\u96c6\u6210FreeCAD\u3001Gmsh\u3001OpenFOAM\u3001CalculiX\u548cBPM\u58f0\u5b66\u5206\u6790\u7b49\u5de5\u5177\u8fdb\u884c\u5e76\u884c\u591a\u5b66\u79d1\u4eff\u771f\u3002", "result": "\u5728\u8d85\u8fc7400\u4e2a\u53c2\u6570\u914d\u7f6e\u4e2d\u5b9e\u73b0\u4e86100%\u6210\u529f\u7387\uff0c\u96f6\u7f51\u683c\u751f\u6210\u5931\u8d25\u3001\u6c42\u89e3\u5668\u6536\u655b\u95ee\u9898\u6216\u9700\u8981\u4eba\u5de5\u5e72\u9884\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u57fa\u4e8e\u667a\u80fd\u4f53AI\u7684AI\u5de5\u7a0b\u5e08\u6709\u6f5c\u529b\u81ea\u4e3b\u6267\u884c\u590d\u6742\u5de5\u7a0b\u4efb\u52a1\uff0c\u8be5\u6846\u67b6\u88ab\u8bc1\u660e\u662f\u53ef\u4fe1\u8d56\u7684\u81ea\u52a8\u5316\u5de5\u7a0b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00210", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.00210", "abs": "https://arxiv.org/abs/2511.00210", "authors": ["Emilio Ancillotti", "Loreto Pescosolido", "Andrea Passarella"], "title": "Toward Hybrid COTS-based LiFi/WiFi Networks with QoS Requirements in Mobile Environments", "comment": "8 pages, 9 Figures, conference paper", "summary": "We consider a hybrid LiFi/WiFi network consisting of commercially available\nequipment, for mobile scenarios, where WiFi backs up communications, through\nvertical handovers, in case of insufficient LiFi QoS. When QoS requirements in\nterms of goodput are defined, tools are needed to anticipate the vertical\nhandover relative to what is possible with standard basic mechanisms, which are\nonly based on a complete loss of connectivity. We introduce two such\nmechanisms, based on signal power level readings and CRC-based packet failure\nratio, and evaluate their performance in terms of QoS-outage duration,\nconsidering as a benchmark an existing baseline solution based on the detection\nof a connectivity loss. In doing this, we provide insights into the interplay\nbetween such mechanisms and the LiFi protocol channel adaptation capabilities.\nOur experimental results are obtained using a lab-scale testbed equipped with a\nconveyor belt, which allows us to accurately replicate experiments with devices\nin motion. With the proposed methods, we achieve QoS outages below one second\nfor a QoS level of 20 Mbps, compared to outage durations of a few seconds\nobtained with the baseline solution.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u4fe1\u53f7\u529f\u7387\u548cCRC\u5305\u5931\u8d25\u7387\u7684\u5782\u76f4\u5207\u6362\u673a\u5236\uff0c\u5728LiFi/WiFi\u6df7\u5408\u7f51\u7edc\u4e2d\u5b9e\u73b0\u4f4e\u4e8e1\u79d2\u7684QoS\u4e2d\u65ad\uff0c\u76f8\u6bd4\u57fa\u51c6\u65b9\u6848\u7684\u6570\u79d2\u4e2d\u65ad\u6709\u663e\u8457\u6539\u5584\u3002", "motivation": "\u5728\u79fb\u52a8\u573a\u666f\u4e0b\uff0c\u5f53LiFi\u670d\u52a1\u8d28\u91cf\u4e0d\u8db3\u65f6\uff0c\u9700\u8981\u6bd4\u6807\u51c6\u673a\u5236\u66f4\u65e9\u89e6\u53d1\u5782\u76f4\u5207\u6362\u5230WiFi\uff0c\u4ee5\u907f\u514dQoS\u4e2d\u65ad\u3002", "method": "\u57fa\u4e8e\u4fe1\u53f7\u529f\u7387\u6c34\u5e73\u8bfb\u53d6\u548cCRC\u5305\u5931\u8d25\u7387\u4e24\u79cd\u673a\u5236\uff0c\u5728\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u4f7f\u7528\u4f20\u9001\u5e26\u6a21\u62df\u8bbe\u5907\u79fb\u52a8\u573a\u666f\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u572820 Mbps QoS\u6c34\u5e73\u4e0b\u5b9e\u73b0\u4f4e\u4e8e1\u79d2\u7684QoS\u4e2d\u65ad\uff0c\u800c\u57fa\u51c6\u89e3\u51b3\u65b9\u6848\u7684\u4e2d\u65ad\u65f6\u95f4\u4e3a\u6570\u79d2\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u673a\u5236\u80fd\u6709\u6548\u51cf\u5c11QoS\u4e2d\u65ad\u65f6\u95f4\uff0c\u5e76\u63ed\u793a\u4e86\u8fd9\u4e9b\u673a\u5236\u4e0eLiFi\u534f\u8bae\u4fe1\u9053\u81ea\u9002\u5e94\u80fd\u529b\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002"}}
{"id": "2511.00896", "categories": ["cs.IT", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00896", "abs": "https://arxiv.org/abs/2511.00896", "authors": ["Daniel E. Lucani", "Marcell Feh\u00e9r"], "title": "HyRES: A Hybrid Replication and Erasure Coding Approach to Data Storage", "comment": "6 pages, 5 figures", "summary": "Reliability in distributed storage systems has typically focused on the\ndesign and deployment of data replication or erasure coding techniques.\nAlthough some scenarios have considered the use of replication for hot data and\nerasure coding for cold data in the same system, each is designed in isolation.\nWe propose HyRES, a hybrid scheme incorporates the best characteristics of each\nscheme, thus, resulting in additional design flexibility and better potential\nperformance for the system. We show that HyRES generalizes previously proposed\nhybrid schemes. We characterize the theoretical performance of HyRES as well as\nthat of replication and erasure coding considering the effects of the size of\nthe storage networks. We validate our theoretical results using simulations.\nThese results show that HyRES can yield simultaneously lower storage costs than\nreplication, lower probabilities of file loss than replication and erasure\ncoding with similar worst case performance, and even lower effective repair\ntraffic than replication when considering the network size.", "AI": {"tldr": "HyRES\u662f\u4e00\u79cd\u6df7\u5408\u5b58\u50a8\u65b9\u6848\uff0c\u7ed3\u5408\u4e86\u590d\u5236\u548c\u7ea0\u5220\u7801\u7684\u4f18\u70b9\uff0c\u5728\u5b58\u50a8\u6210\u672c\u3001\u6587\u4ef6\u4e22\u5931\u6982\u7387\u548c\u4fee\u590d\u6d41\u91cf\u65b9\u9762\u90fd\u4f18\u4e8e\u4f20\u7edf\u7684\u5355\u4e00\u65b9\u6848\u3002", "motivation": "\u4f20\u7edf\u5206\u5e03\u5f0f\u5b58\u50a8\u7cfb\u7edf\u901a\u5e38\u5355\u72ec\u8bbe\u8ba1\u590d\u5236\u6216\u7ea0\u5220\u7801\u65b9\u6848\uff0c\u7f3a\u4e4f\u5c06\u4e24\u8005\u4f18\u52bf\u7ed3\u5408\u7684\u8bbe\u8ba1\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51faHyRES\u6df7\u5408\u65b9\u6848\uff0c\u7efc\u5408\u8003\u8651\u5b58\u50a8\u7f51\u7edc\u89c4\u6a21\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u4eff\u771f\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "result": "HyRES\u5728\u5b58\u50a8\u6210\u672c\u4e0a\u4f4e\u4e8e\u590d\u5236\u65b9\u6848\uff0c\u6587\u4ef6\u4e22\u5931\u6982\u7387\u4f4e\u4e8e\u590d\u5236\u548c\u7ea0\u5220\u7801\u65b9\u6848\uff0c\u4fee\u590d\u6d41\u91cf\u5728\u8003\u8651\u7f51\u7edc\u89c4\u6a21\u65f6\u751a\u81f3\u4f4e\u4e8e\u590d\u5236\u65b9\u6848\u3002", "conclusion": "HyRES\u65b9\u6848\u80fd\u591f\u540c\u65f6\u5b9e\u73b0\u66f4\u4f4e\u7684\u5b58\u50a8\u6210\u672c\u3001\u66f4\u597d\u7684\u6570\u636e\u53ef\u9760\u6027\u548c\u66f4\u6709\u6548\u7684\u4fee\u590d\u6027\u80fd\uff0c\u662f\u5206\u5e03\u5f0f\u5b58\u50a8\u7cfb\u7edf\u7684\u4f18\u5316\u9009\u62e9\u3002"}}
{"id": "2511.00162", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00162", "abs": "https://arxiv.org/abs/2511.00162", "authors": ["Michael D. Moffitt"], "title": "ARC-GEN: A Mimetic Procedural Benchmark Generator for the Abstraction and Reasoning Corpus", "comment": null, "summary": "The Abstraction and Reasoning Corpus remains one of the most compelling and\nchallenging benchmarks for tracking progress toward achieving Artificial\nGeneral Intelligence. In contrast to other evaluation datasets designed to\nassess an agent's task-specific skills or accumulated knowledge, the ARC-AGI\nsuite is specifically targeted at measuring skill acquisition efficiency, a\ntrait that has (so far) been lacking in even the most sophisticated machine\nlearning systems. For algorithms that require extensive intra-task exemplars, a\nsignificant constraint imposed by ARC-AGI is the modest cardinality of its\ndemonstration set, comprising a small number of $\\langle$ input, output\n$\\rangle$ grids per task specifying the corresponding transformation. To\nembellish the space of viable sample pairs, this paper introduces ARC-GEN, an\nopen-source procedural generator aimed at extending the original ARC-AGI\ntraining dataset as faithfully as possible. Unlike prior efforts, our generator\nis both exhaustive (covering all four-hundred tasks) and mimetic (more closely\nhonoring the distributional properties and characteristics embodied in the\ninitial ARC-AGI-1 release). We also discuss the use of this generator in\nestablishing a static benchmark suite to verify the correctness of programs\nsubmitted to the 2025 Google Code Golf Championship.", "AI": {"tldr": "ARC-GEN\u662f\u4e00\u4e2a\u5f00\u6e90\u7a0b\u5e8f\u751f\u6210\u5668\uff0c\u65e8\u5728\u901a\u8fc7\u751f\u6210\u66f4\u591a\u8bad\u7ec3\u6837\u672c\u6765\u6269\u5c55ARC-AGI\u57fa\u51c6\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\uff0c\u4ee5\u89e3\u51b3\u539f\u59cb\u6570\u636e\u96c6\u4e2d\u793a\u4f8b\u6570\u91cf\u6709\u9650\u7684\u95ee\u9898\u3002", "motivation": "ARC-AGI\u57fa\u51c6\u6d4b\u8bd5\u7528\u4e8e\u8bc4\u4f30\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u6280\u80fd\u83b7\u53d6\u6548\u7387\uff0c\u4f46\u5176\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u7684\u793a\u4f8b\u6570\u91cf\u6709\u9650\uff0c\u8fd9\u9650\u5236\u4e86\u9700\u8981\u5927\u91cf\u4efb\u52a1\u5185\u793a\u4f8b\u7684\u7b97\u6cd5\u7684\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u4e86ARC-GEN\u7a0b\u5e8f\u751f\u6210\u5668\uff0c\u8be5\u751f\u6210\u5668\u8986\u76d6\u6240\u6709400\u4e2a\u4efb\u52a1\uff0c\u5e76\u5c3d\u53ef\u80fd\u5fe0\u5b9e\u5730\u6a21\u62df\u539f\u59cbARC-AGI-1\u53d1\u5e03\u7248\u7684\u5206\u5e03\u7279\u6027\u548c\u7279\u5f81\u3002", "result": "ARC-GEN\u6210\u529f\u6269\u5c55\u4e86\u539f\u59cbARC-AGI\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u751f\u6210\u4e86\u66f4\u591a\u53ef\u884c\u7684\u6837\u672c\u5bf9\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u539f\u59cb\u6570\u636e\u96c6\u7684\u9ad8\u5ea6\u4e00\u81f4\u6027\u3002", "conclusion": "ARC-GEN\u4e3aARC-AGI\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u53ef\u7528\u4e8e\u9a8c\u8bc12025\u5e74Google Code Golf Championship\u63d0\u4ea4\u7a0b\u5e8f\u7684\u6b63\u786e\u6027\u3002"}}
{"id": "2511.00271", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.00271", "abs": "https://arxiv.org/abs/2511.00271", "authors": ["Saadat Izadi", "Shakib Komasi", "Ali Salimi", "Alireza Rezaei", "Mahmood Ahmadi"], "title": "Mist-Assisted Federated Learning for Intrusion Detection in Heterogeneous IoT Networks", "comment": null, "summary": "The rapid growth of the Internet of Things (IoT) offers new opportunities but\nalso expands the attack surface of distributed, resource-limited devices.\nIntrusion detection in such environments is difficult due to data heterogeneity\nfrom diverse sensing modalities and the non-IID distribution of samples across\nclients. Federated Learning (FL) provides a privacy-preserving alternative to\ncentralized training, yet conventional frameworks struggle under these\nconditions. To address this, we propose a Mist-assisted hierarchical framework\nfor IoT intrusion detection. The architecture spans four layers: (i) Mist,\nwhere raw data are abstracted into a unified feature space and lightweight\nmodels detect anomalies; (ii) Edge, which applies utility-based client\nselection; (iii) Fog, where multiple regional aggregators use FedProx to\nstabilize training; and (iv) Cloud, which consolidates and disseminates global\nmodels. Evaluations on the TON-IoT dataset show the framework achieves 98-99%\naccuracy, PR-AUC> 0.97, and stable convergence under heterogeneous and\nlarge-scale settings, while maintaining efficiency and preserving privacy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u96fe\u8f85\u52a9\u7684\u5206\u5c42\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u7528\u4e8e\u7269\u8054\u7f51\u5165\u4fb5\u68c0\u6d4b\uff0c\u5728TON-IoT\u6570\u636e\u96c6\u4e0a\u8fbe\u523098-99%\u51c6\u786e\u7387\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u5f02\u6784\u6027\u548c\u975eIID\u5206\u5e03\u95ee\u9898\u3002", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u8d44\u6e90\u6709\u9650\u4e14\u6570\u636e\u5f02\u6784\uff0c\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u5728\u975eIID\u6570\u636e\u5206\u5e03\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u65b0\u7684\u9690\u79c1\u4fdd\u62a4\u5165\u4fb5\u68c0\u6d4b\u65b9\u6848\u3002", "method": "\u56db\u5c42\u67b6\u6784\uff1a\u96fe\u5c42\uff08\u6570\u636e\u62bd\u8c61\u548c\u8f7b\u91cf\u5f02\u5e38\u68c0\u6d4b\uff09\u3001\u8fb9\u7f18\u5c42\uff08\u57fa\u4e8e\u6548\u7528\u7684\u5ba2\u6237\u7aef\u9009\u62e9\uff09\u3001\u96fe\u5c42\uff08\u591a\u533a\u57df\u805a\u5408\u5668\u4f7f\u7528FedProx\uff09\u3001\u4e91\u5c42\uff08\u5168\u5c40\u6a21\u578b\u6574\u5408\u5206\u53d1\uff09\u3002", "result": "\u5728TON-IoT\u6570\u636e\u96c6\u4e0a\u5b9e\u73b098-99%\u51c6\u786e\u7387\uff0cPR-AUC>0.97\uff0c\u5728\u5f02\u6784\u548c\u5927\u89c4\u6a21\u73af\u5883\u4e0b\u4fdd\u6301\u7a33\u5b9a\u6536\u655b\u3002", "conclusion": "\u8be5\u5206\u5c42\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u7269\u8054\u7f51\u73af\u5883\u4e2d\u7684\u6570\u636e\u5f02\u6784\u6027\u548c\u975eIID\u5206\u5e03\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6548\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2511.00953", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00953", "abs": "https://arxiv.org/abs/2511.00953", "authors": ["Lewen Wang", "Sihuang Hu"], "title": "Lower Bounds on Conversion Bandwidth for MDS Convertible Codes in Split Regime", "comment": null, "summary": "We propose several new lower bounds on the bandwidth costs of MDS convertible\ncodes using a linear-algebraic framework. The derived bounds improve previous\nresults in certain parameter regimes and match the bandwidth cost of the\nconstruction proposed by Maturana and Rashmi (2022 IEEE International Symposium\non Information Theory) for $r^F\\le r^I\\le k^F$, implying that our bounds are\ntight in this case.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u51e0\u4e2a\u5173\u4e8eMDS\u53ef\u8f6c\u6362\u7801\u5e26\u5bbd\u6210\u672c\u7684\u65b0\u4e0b\u754c\uff0c\u6539\u8fdb\u4e86\u5148\u524d\u7ed3\u679c\uff0c\u5e76\u5728\u67d0\u4e9b\u53c2\u6570\u8303\u56f4\u5185\u4e0e\u73b0\u6709\u6784\u9020\u5339\u914d\uff0c\u8bc1\u660e\u8fd9\u4e9b\u4e0b\u754c\u662f\u7d27\u7684\u3002", "motivation": "\u7814\u7a76MDS\u53ef\u8f6c\u6362\u7801\u7684\u5e26\u5bbd\u6210\u672c\u4e0b\u754c\uff0c\u4ee5\u6539\u8fdb\u73b0\u6709\u7406\u8bba\u7ed3\u679c\u5e76\u9a8c\u8bc1\u6700\u4f18\u6027\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u4ee3\u6570\u6846\u67b6\u63a8\u5bfc\u5e26\u5bbd\u6210\u672c\u7684\u4e0b\u754c\u3002", "result": "\u65b0\u4e0b\u754c\u5728\u67d0\u4e9b\u53c2\u6570\u8303\u56f4\u5185\u6539\u8fdb\u4e86\u5148\u524d\u7ed3\u679c\uff0c\u5f53$r^F\\le r^I\\le k^F$\u65f6\u4e0eMaturana\u548cRashmi\u7684\u6784\u9020\u5339\u914d\uff0c\u8bc1\u660e\u4e0b\u754c\u662f\u7d27\u7684\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ebf\u6027\u4ee3\u6570\u6846\u67b6\u6210\u529f\u63a8\u5bfc\u51faMDS\u53ef\u8f6c\u6362\u7801\u7684\u7d27\u5e26\u5bbd\u6210\u672c\u4e0b\u754c\uff0c\u4e3a\u76f8\u5173\u7f16\u7801\u65b9\u6848\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u969c\u3002"}}
{"id": "2511.00194", "categories": ["cs.AI", "F.2.2, F.4.1"], "pdf": "https://arxiv.org/pdf/2511.00194", "abs": "https://arxiv.org/abs/2511.00194", "authors": ["Jovial Cheukam Ngouonou", "Ramiz Gindullin", "Claude-Guy Quimper", "Nicolas Beldiceanu", "Remi Douence"], "title": "Incremental Selection of Most-Filtering Conjectures and Proofs of the Selected Conjectures", "comment": null, "summary": "We present an improved incremental selection algorithm of the selection\nalgorithm presented in [1] and prove all the selected conjectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86[1]\u4e2d\u589e\u91cf\u9009\u62e9\u7b97\u6cd5\u7684\u6539\u8fdb\u7248\u672c\uff0c\u5e76\u8bc1\u660e\u4e86\u6240\u6709\u9009\u5b9a\u7684\u731c\u60f3", "motivation": "\u6539\u8fdb\u73b0\u6709\u7684\u589e\u91cf\u9009\u62e9\u7b97\u6cd5\uff0c\u89e3\u51b3\u5176\u53ef\u80fd\u5b58\u5728\u7684\u6548\u7387\u6216\u6b63\u786e\u6027\u95ee\u9898", "method": "\u5f00\u53d1\u4e86\u6539\u8fdb\u7684\u589e\u91cf\u9009\u62e9\u7b97\u6cd5\uff0c\u5e76\u8fdb\u884c\u4e86\u4e25\u683c\u7684\u6570\u5b66\u8bc1\u660e", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u6240\u6709\u9009\u5b9a\u7684\u731c\u60f3\uff0c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6b63\u786e\u6027", "conclusion": "\u6539\u8fdb\u7684\u589e\u91cf\u9009\u62e9\u7b97\u6cd5\u5728\u7406\u8bba\u4e0a\u66f4\u52a0\u5b8c\u5584\uff0c\u80fd\u591f\u53ef\u9760\u5730\u5904\u7406\u76f8\u5173\u9009\u62e9\u95ee\u9898"}}
{"id": "2511.00276", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.00276", "abs": "https://arxiv.org/abs/2511.00276", "authors": ["Mohammad Hadi Akbarzadeh", "Mahmood Ahmadi", "Mohammad Saeed Jahangiry", "Jae Young Hur"], "title": "Reinforcement Learning for Resource Allocation in Vehicular Multi-Fog Computing", "comment": null, "summary": "The exponential growth of Internet of Things (IoT) devices, smart vehicles,\nand latency-sensitive applications has created an urgent demand for efficient\ndistributed computing paradigms. Multi-Fog Computing (MFC), as an extension of\nfog and edge computing, deploys multiple fog nodes near end users to reduce\nlatency, enhance scalability, and ensure Quality of Service (QoS). However,\nresource allocation in MFC environments is highly challenging due to dynamic\nvehicular mobility, heterogeneous resources, and fluctuating workloads.\nTraditional optimization-based methods often fail to adapt to such dynamics.\nReinforcement Learning (RL), as a model-free decision-making framework, enables\nadaptive task allocation by continuously interacting with the environment. This\npaper formulates the resource allocation problem in MFC as a Markov Decision\nProcess (MDP) and investigates the application of RL algorithms such as\nQ-learning, Deep Q-Networks (DQN), and Actor-Critic. We present experimental\nresults demonstrating improvements in latency, workload balance, and task\nsuccess rate. The contributions and novelty of this study are also discussed,\nhighlighting the role of RL in addressing emerging vehicular computing\nchallenges.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5728\u591a\u96fe\u8ba1\u7b97\u73af\u5883\u4e2d\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u8d44\u6e90\u5206\u914d\uff0c\u4ee5\u89e3\u51b3\u52a8\u6001\u8f66\u8f86\u79fb\u52a8\u6027\u3001\u5f02\u6784\u8d44\u6e90\u548c\u6ce2\u52a8\u5de5\u4f5c\u8d1f\u8f7d\u5e26\u6765\u7684\u6311\u6218\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51\u8bbe\u5907\u3001\u667a\u80fd\u8f66\u8f86\u548c\u5ef6\u8fdf\u654f\u611f\u5e94\u7528\u7684\u6307\u6570\u589e\u957f\uff0c\u5bf9\u9ad8\u6548\u5206\u5e03\u5f0f\u8ba1\u7b97\u8303\u5f0f\u7684\u9700\u6c42\u65e5\u76ca\u8feb\u5207\u3002\u591a\u96fe\u8ba1\u7b97\u4f5c\u4e3a\u96fe\u8ba1\u7b97\u548c\u8fb9\u7f18\u8ba1\u7b97\u7684\u6269\u5c55\uff0c\u867d\u7136\u80fd\u51cf\u5c11\u5ef6\u8fdf\u3001\u589e\u5f3a\u53ef\u6269\u5c55\u6027\u5e76\u786e\u4fdd\u670d\u52a1\u8d28\u91cf\uff0c\u4f46\u5176\u8d44\u6e90\u5206\u914d\u9762\u4e34\u52a8\u6001\u8f66\u8f86\u79fb\u52a8\u6027\u3001\u5f02\u6784\u8d44\u6e90\u548c\u6ce2\u52a8\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6311\u6218\uff0c\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u8fd9\u79cd\u52a8\u6001\u6027\u3002", "method": "\u5c06\u591a\u96fe\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u7814\u7a76\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5305\u62ecQ-learning\u3001\u6df1\u5ea6Q\u7f51\u7edc\u548cActor-Critic\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5ef6\u8fdf\u3001\u5de5\u4f5c\u8d1f\u8f7d\u5e73\u8861\u548c\u4efb\u52a1\u6210\u529f\u7387\u65b9\u9762\u90fd\u6709\u6240\u6539\u5584\u3002", "conclusion": "\u8be5\u7814\u7a76\u7a81\u51fa\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u89e3\u51b3\u65b0\u5174\u8f66\u8f86\u8ba1\u7b97\u6311\u6218\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u8ba8\u8bba\u4e86\u7814\u7a76\u7684\u8d21\u732e\u548c\u65b0\u9896\u6027\u3002"}}
{"id": "2511.00959", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00959", "abs": "https://arxiv.org/abs/2511.00959", "authors": ["Bui Duc Son", "Gaosheng Zhao", "Trinh Van Chien", "Dong In Kim"], "title": "Secure Distributed RIS-MIMO over Double Scattering Channels: Adversarial Attack, Defense, and SER Improvement", "comment": "15 pages, 7 figures, 7 tables. Accepted by IEEE TCOM", "summary": "There has been a growing trend toward leveraging machine learning (ML) and\ndeep learning (DL) techniques to optimize and enhance the performance of\nwireless communication systems. However, limited attention has been given to\nthe vulnerabilities of these techniques, particularly in the presence of\nadversarial attacks. This paper investigates the adversarial attack and defense\nin distributed multiple reconfigurable intelligent surfaces (RISs)-aided\nmultiple-input multiple-output (MIMO) communication systems-based autoencoder\nin finite scattering environments. We present the channel propagation model for\ndistributed multiple RIS, including statistical information driven in closed\nform for the aggregated channel. The symbol error rate (SER) is selected to\nevaluate the collaborative dynamics between the distributed RISs and MIMO\ncommunication in depth. The relationship between the number of RISs and the SER\nof the proposed system based on an autoencoder, as well as the impact of\nadversarial attacks on the system's SER, is analyzed in detail. We also propose\na defense mechanism based on adversarial training against the considered\nattacks to enhance the model's robustness. Numerical results indicate that\nincreasing the number of RISs effectively reduces the system's SER but leads to\nthe adversarial attack-based algorithm becoming more destructive in the\nwhite-box attack scenario. The proposed defense method demonstrates strong\neffectiveness by significantly mitigating the attack's impact. It also\nsubstantially reduces the system's SER in the absence of an attack compared to\nthe original model. Moreover, we extend the phenomenon to include decoder\nmobility, demonstrating that the proposed method maintains robustness under\nDoppler-induced channel variations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5206\u5e03\u5f0f\u591aRIS\u8f85\u52a9MIMO\u901a\u4fe1\u7cfb\u7edf\u4e2d\u57fa\u4e8e\u81ea\u52a8\u7f16\u7801\u5668\u7684\u5bf9\u6297\u653b\u51fb\u4e0e\u9632\u5fa1\uff0c\u5206\u6790\u4e86RIS\u6570\u91cf\u4e0e\u7cfb\u7edf\u6027\u80fd\u7684\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u5bf9\u6297\u8bad\u7ec3\u7684\u9632\u5fa1\u673a\u5236\u6765\u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u5728\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u8fd9\u4e9b\u6280\u672f\u9762\u4e34\u7684\u5b89\u5168\u6f0f\u6d1e\u548c\u5bf9\u6297\u653b\u51fb\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u8db3\u591f\u91cd\u89c6\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u5206\u5e03\u5f0f\u591aRIS\u8f85\u52a9MIMO\u7cfb\u7edf\u4e2d\u81ea\u52a8\u7f16\u7801\u5668\u7684\u5b89\u5168\u8106\u5f31\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u5206\u5e03\u5f0f\u591aRIS\u7684\u4fe1\u9053\u4f20\u64ad\u6a21\u578b\uff0c\u5305\u62ec\u95ed\u5f0f\u7edf\u8ba1\u4fe1\u606f\u9a71\u52a8\u7684\u805a\u5408\u4fe1\u9053\u5efa\u6a21\u3002\u9009\u62e9\u7b26\u53f7\u9519\u8bef\u7387(SER)\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\uff0c\u8be6\u7ec6\u5206\u6790RIS\u6570\u91cf\u4e0e\u7cfb\u7edf\u6027\u80fd\u7684\u5173\u7cfb\uff0c\u5e76\u5f00\u53d1\u57fa\u4e8e\u5bf9\u6297\u8bad\u7ec3\u7684\u9632\u5fa1\u673a\u5236\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u589e\u52a0RIS\u6570\u91cf\u53ef\u964d\u4f4e\u7cfb\u7edfSER\uff0c\u4f46\u5728\u767d\u76d2\u653b\u51fb\u573a\u666f\u4e0b\u4f1a\u4f7f\u5bf9\u6297\u653b\u51fb\u66f4\u5177\u7834\u574f\u6027\u3002\u63d0\u51fa\u7684\u9632\u5fa1\u65b9\u6cd5\u80fd\u663e\u8457\u51cf\u8f7b\u653b\u51fb\u5f71\u54cd\uff0c\u5e76\u5728\u65e0\u653b\u51fb\u65f6\u76f8\u6bd4\u539f\u59cb\u6a21\u578b\u8fdb\u4e00\u6b65\u964d\u4f4eSER\u3002\u8be5\u65b9\u6cd5\u5728\u591a\u666e\u52d2\u5f15\u8d77\u7684\u4fe1\u9053\u53d8\u5316\u4e0b\u4ecd\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "\u8bba\u6587\u8bc1\u660e\u4e86\u5bf9\u6297\u8bad\u7ec3\u5728\u4fdd\u62a4RIS\u8f85\u52a9MIMO\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u672a\u6765\u5b89\u5168\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\uff0c\u7279\u522b\u662f\u5728\u5bf9\u6297\u653b\u51fb\u9632\u62a4\u65b9\u9762\u3002"}}
{"id": "2511.00206", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00206", "abs": "https://arxiv.org/abs/2511.00206", "authors": ["Dirk U. Wulff", "Rui Mata"], "title": "Advancing Cognitive Science with LLMs", "comment": null, "summary": "Cognitive science faces ongoing challenges in knowledge synthesis and\nconceptual clarity, in part due to its multifaceted and interdisciplinary\nnature. Recent advances in artificial intelligence, particularly the\ndevelopment of large language models (LLMs), offer tools that may help to\naddress these issues. This review examines how LLMs can support areas where the\nfield has historically struggled, including establishing cross-disciplinary\nconnections, formalizing theories, developing clear measurement taxonomies,\nachieving generalizability through integrated modeling frameworks, and\ncapturing contextual and individual variation. We outline the current\ncapabilities and limitations of LLMs in these domains, including potential\npitfalls. Taken together, we conclude that LLMs can serve as tools for a more\nintegrative and cumulative cognitive science when used judiciously to\ncomplement, rather than replace, human expertise.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5982\u4f55\u5e2e\u52a9\u89e3\u51b3\u8ba4\u77e5\u79d1\u5b66\u9886\u57df\u9762\u4e34\u7684\u77e5\u8bc6\u6574\u5408\u548c\u6982\u5ff5\u6e05\u6670\u5ea6\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u8de8\u5b66\u79d1\u8fde\u63a5\u3001\u7406\u8bba\u5f62\u5f0f\u5316\u3001\u6d4b\u91cf\u5206\u7c7b\u5b66\u7b49\u65b9\u9762\u3002", "motivation": "\u8ba4\u77e5\u79d1\u5b66\u7531\u4e8e\u5176\u591a\u9762\u6027\u548c\u8de8\u5b66\u79d1\u6027\u8d28\uff0c\u5728\u77e5\u8bc6\u6574\u5408\u548c\u6982\u5ff5\u6e05\u6670\u5ea6\u65b9\u9762\u9762\u4e34\u6301\u7eed\u6311\u6218\u3002\u4eba\u5de5\u667a\u80fd\u7279\u522b\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u6f5c\u5728\u5de5\u5177\u3002", "method": "\u8fd9\u662f\u4e00\u7bc7\u7efc\u8ff0\u6027\u8bba\u6587\uff0c\u901a\u8fc7\u5206\u6790LLMs\u5728\u5f53\u524d\u8ba4\u77e5\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\uff0c\u63a2\u8ba8\u5176\u5728\u652f\u6301\u8de8\u5b66\u79d1\u8fde\u63a5\u3001\u7406\u8bba\u5f62\u5f0f\u5316\u3001\u6d4b\u91cf\u5206\u7c7b\u5b66\u53d1\u5c55\u7b49\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLMs\u80fd\u591f\u652f\u6301\u8ba4\u77e5\u79d1\u5b66\u5728\u591a\u4e2a\u5386\u53f2\u6027\u6311\u6218\u9886\u57df\u7684\u53d1\u5c55\uff0c\u5305\u62ec\u5efa\u7acb\u8de8\u5b66\u79d1\u8054\u7cfb\u3001\u5b9e\u73b0\u7406\u8bba\u5f62\u5f0f\u5316\u3001\u5f00\u53d1\u6e05\u6670\u7684\u6d4b\u91cf\u5206\u7c7b\u6cd5\u3001\u901a\u8fc7\u96c6\u6210\u5efa\u6a21\u6846\u67b6\u5b9e\u73b0\u6cdb\u5316\uff0c\u4ee5\u53ca\u6355\u6349\u60c5\u5883\u548c\u4e2a\u4f53\u5dee\u5f02\u3002", "conclusion": "\u5f53\u5ba1\u614e\u4f7f\u7528\u65f6\uff0cLLMs\u53ef\u4ee5\u4f5c\u4e3a\u5de5\u5177\u4fc3\u8fdb\u8ba4\u77e5\u79d1\u5b66\u66f4\u52a0\u6574\u5408\u548c\u7d2f\u79ef\u7684\u53d1\u5c55\uff0c\u4f46\u5e94\u8be5\u4f5c\u4e3a\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u7684\u8865\u5145\u800c\u975e\u66ff\u4ee3\u3002"}}
{"id": "2511.00439", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.00439", "abs": "https://arxiv.org/abs/2511.00439", "authors": ["Pavan K. Mangipudi", "Sharon Boamah", "Lorenz Carvajal", "Janise Mcnair"], "title": "COHERE - Congestion-aware Offloading and Handover via Empirical RAT Evaluation for Multi-RAT Networks", "comment": "18 pages, 10 figures", "summary": "The evolution of wireless networks and radio access technologies (RATs) has\ntransformed communication from user-driven traffic into a dynamic ecosystem of\nautonomous systems, including IoT devices, edge nodes, autonomous vehicles,\nAR/XR clients, and AI-powered agents. These systems exhibit diverse traffic\npatterns, latency requirements, and mobility behaviors, increasingly operating\nacross overlapping heterogeneous RATs such as 5G, WiFi, satellite, NB-IoT,\nLoRaWAN, Zigbee, etc. This multi-RAT coexistence creates opportunities for\nintelligent access, mobility, and routing strategies. However, most mobility\ndecisions still rely heavily on RSSI, which neglects RAT-specific features,\ncongestion, queuing delays, and application needs, favoring high-power links\nover optimal ones. To address this gap, we propose chrome (Congestion-aware\nOffloading and Handover via Empirical RAT Evaluation), a multi criteria\nframework for dense multi-RAT networks. chrome enhances RSSI with multiple\ncriteria and applies the Technique for Order of Preference by Similarity to the\nIdeal Solution (TOPSIS) to rank available RATs. Criteria weights are determined\nusing both subjective (operator-driven) and objective (measurement-based)\napproaches. Based on this ranking, chrome performs intelligent cross-RAT\noffloading to reduce congestion on over-utilized links. We evaluate chrome in a\ndense SDN-controlled 5G/WiFi Multi-RAT environment using Mininet WiFi. Compared\nto RSSI-only handover, COHERE reduces the load on the congested RAT by up to\n32%, reduces total handovers by 25%, lowers handovers to the congested RAT by\n55%, and improves link delay by up to 166%, while maintaining comparable or up\nto 11% higher throughput. These results demonstrate that guarded,\nmulti-criteria decision-making can exploit RAT coexistence to deliver robust,\ncongestion-aware performance across heterogeneous deployments.", "AI": {"tldr": "\u63d0\u51fa\u4e86COHERE\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6807\u51c6\u51b3\u7b56\u548cTOPSIS\u65b9\u6cd5\u5728\u5bc6\u96c6\u591aRAT\u7f51\u7edc\u4e2d\u5b9e\u73b0\u667a\u80fd\u5207\u6362\u548c\u5378\u8f7d\uff0c\u663e\u8457\u964d\u4f4e\u62e5\u585eRAT\u8d1f\u8f7d\u548c\u5207\u6362\u6b21\u6570\uff0c\u6539\u5584\u94fe\u8def\u5ef6\u8fdf\u3002", "motivation": "\u4f20\u7edf\u79fb\u52a8\u6027\u51b3\u7b56\u4e3b\u8981\u4f9d\u8d56RSSI\uff0c\u5ffd\u7565\u4e86RAT\u7279\u5b9a\u7279\u6027\u3001\u62e5\u585e\u3001\u6392\u961f\u5ef6\u8fdf\u548c\u5e94\u7528\u9700\u6c42\uff0c\u503e\u5411\u4e8e\u9ad8\u529f\u7387\u94fe\u8def\u800c\u975e\u6700\u4f18\u94fe\u8def\u3002\u591aRAT\u5171\u5b58\u4e3a\u667a\u80fd\u63a5\u5165\u3001\u79fb\u52a8\u6027\u548c\u8def\u7531\u7b56\u7565\u521b\u9020\u4e86\u673a\u4f1a\u3002", "method": "\u63d0\u51faCOHERE\u6846\u67b6\uff0c\u5728RSSI\u57fa\u7840\u4e0a\u589e\u5f3a\u591a\u4e2a\u6807\u51c6\uff0c\u5e94\u7528TOPSIS\u65b9\u6cd5\u5bf9\u53ef\u7528RAT\u8fdb\u884c\u6392\u540d\u3002\u4f7f\u7528\u4e3b\u89c2\uff08\u8fd0\u8425\u5546\u9a71\u52a8\uff09\u548c\u5ba2\u89c2\uff08\u57fa\u4e8e\u6d4b\u91cf\uff09\u65b9\u6cd5\u786e\u5b9a\u6807\u51c6\u6743\u91cd\uff0c\u57fa\u4e8e\u6392\u540d\u6267\u884c\u667a\u80fd\u8de8RAT\u5378\u8f7d\u3002", "result": "\u5728\u5bc6\u96c6SDN\u63a7\u5236\u76845G/WiFi\u591aRAT\u73af\u5883\u4e2d\u8bc4\u4f30\uff0c\u76f8\u6bd4\u4ec5\u4f7f\u7528RSSI\u7684\u5207\u6362\uff0cCOHERE\u5c06\u62e5\u585eRAT\u8d1f\u8f7d\u964d\u4f4e32%\uff0c\u603b\u5207\u6362\u6b21\u6570\u51cf\u5c1125%\uff0c\u5411\u62e5\u585eRAT\u7684\u5207\u6362\u964d\u4f4e55%\uff0c\u94fe\u8def\u5ef6\u8fdf\u6539\u5584166%\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u6216\u9ad8\u8fbe11%\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "\u6709\u4fdd\u969c\u7684\u591a\u6807\u51c6\u51b3\u7b56\u53ef\u4ee5\u5229\u7528RAT\u5171\u5b58\uff0c\u5728\u5f02\u6784\u90e8\u7f72\u4e2d\u63d0\u4f9b\u7a33\u5065\u7684\u62e5\u585e\u611f\u77e5\u6027\u80fd\u3002"}}
{"id": "2511.00999", "categories": ["cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00999", "abs": "https://arxiv.org/abs/2511.00999", "authors": ["Julian Streit", "Franziska Weindel", "Reinhard Heckel"], "title": "Transformer-Based Decoding in Concatenated Coding Schemes Under Synchronization Errors", "comment": "16 pages, 19 figures, a shortened version was published in the ISIT\n  2025 conference", "summary": "We consider the reconstruction of a codeword from multiple noisy copies that\nare independently corrupted by insertions, deletions, and substitutions. This\nproblem arises, for example, in DNA data storage. A common code construction\nuses a concatenated coding scheme that combines an outer linear block code with\nan inner code, which can be either a nonlinear marker code or a convolutional\ncode. Outer decoding is done with Belief Propagation, and inner decoding is\ndone with the Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm. However, the BCJR\nalgorithm scales exponentially with the number of noisy copies, which makes it\ninfeasible to reconstruct a codeword from more than about four copies. In this\nwork, we introduce BCJRFormer, a transformer-based neural inner decoder.\nBCJRFormer achieves error rates comparable to the BCJR algorithm for binary and\nquaternary single-message transmissions of marker codes. Importantly,\nBCJRFormer scales quadratically with the number of noisy copies. This property\nmakes BCJRFormer well-suited for DNA data storage, where multiple reads of the\nsame DNA strand occur. To lower error rates, we replace the Belief Propagation\nouter decoder with a transformer-based decoder. Together, these modifications\nyield an efficient and performant end-to-end transformer-based pipeline for\ndecoding multiple noisy copies affected by insertion, deletion, and\nsubstitution errors. Additionally, we propose a novel cross-attending\ntransformer architecture called ConvBCJRFormer. This architecture extends\nBCJRFormer to decode transmissions of convolutional codewords, serving as an\ninitial step toward joint inner and outer decoding for more general linear code\nclasses.", "AI": {"tldr": "\u63d0\u51fa\u4e86BCJRFormer\uff0c\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u795e\u7ecf\u5185\u89e3\u7801\u5668\uff0c\u7528\u4e8e\u4ece\u591a\u4e2a\u88ab\u63d2\u5165\u3001\u5220\u9664\u548c\u66ff\u6362\u9519\u8bef\u5f71\u54cd\u7684\u566a\u58f0\u526f\u672c\u4e2d\u91cd\u5efa\u7801\u5b57\uff0c\u7279\u522b\u9002\u7528\u4e8eDNA\u6570\u636e\u5b58\u50a8\u573a\u666f\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfBCJR\u7b97\u6cd5\u5728\u89e3\u7801\u591a\u4e2a\u566a\u58f0\u526f\u672c\u65f6\u8ba1\u7b97\u590d\u6742\u5ea6\u6307\u6570\u7ea7\u589e\u957f\u7684\u95ee\u9898\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u66f4\u591a\u526f\u672c\uff0c\u6ee1\u8db3DNA\u6570\u636e\u5b58\u50a8\u4e2d\u591a\u8bfb\u6570\u7684\u9700\u6c42\u3002", "method": "\u4f7f\u7528Transformer\u67b6\u6784\u66ff\u4ee3BCJR\u7b97\u6cd5\u4f5c\u4e3a\u5185\u89e3\u7801\u5668\uff0c\u5e76\u63d0\u51faConvBCJRFormer\u6269\u5c55\u67b6\u6784\u7528\u4e8e\u5377\u79ef\u7801\u89e3\u7801\uff0c\u540c\u65f6\u7528\u57fa\u4e8eTransformer\u7684\u5916\u89e3\u7801\u5668\u66ff\u6362\u7f6e\u4fe1\u4f20\u64ad\u89e3\u7801\u5668\u3002", "result": "BCJRFormer\u5728\u4e8c\u8fdb\u5236\u548c\u56db\u8fdb\u5236\u5355\u6d88\u606f\u4f20\u8f93\u4e2d\u8fbe\u5230\u4e0eBCJR\u7b97\u6cd5\u76f8\u5f53\u7684\u8bef\u7801\u7387\uff0c\u4e14\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0e\u566a\u58f0\u526f\u672c\u6570\u91cf\u5448\u4e8c\u6b21\u65b9\u5173\u7cfb\uff0c\u663e\u8457\u4f18\u4e8eBCJR\u7684\u6307\u6570\u7ea7\u590d\u6742\u5ea6\u3002", "conclusion": "\u6784\u5efa\u4e86\u4e00\u4e2a\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u5f02\u7684\u7aef\u5230\u7aef\u57fa\u4e8eTransformer\u7684\u89e3\u7801\u6d41\u6c34\u7ebf\uff0c\u4e3aDNA\u6570\u636e\u5b58\u50a8\u548c\u5176\u4ed6\u9700\u8981\u5904\u7406\u591a\u4e2a\u566a\u58f0\u526f\u672c\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00267", "categories": ["cs.AI", "cs.CY", "cs.GL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00267", "abs": "https://arxiv.org/abs/2511.00267", "authors": ["Christian Prothmann", "Vijay Gadepally", "Jeremy Kepner", "Koley Borchard", "Luca Carlone", "Zachary Folcik", "J. Daniel Grith", "Michael Houle", "Jonathan P. How", "Nathan Hughes", "Ifueko Igbinedion", "Hayden Jananthan", "Tejas Jayashankar", "Michael Jones", "Sertac Karaman", "Binoy G. Kurien", "Alejandro Lancho", "Giovanni Lavezzi", "Gary C. F. Lee", "Charles E. Leiserson", "Richard Linares", "Lindsey McEvoy", "Peter Michaleas", "Chasen Milner", "Alex Pentland", "Yury Polyanskiy", "Jovan Popovich", "Jeffrey Price", "Tim W. Reid", "Stephanie Riley", "Siddharth Samsi", "Peter Saunders", "Olga Simek", "Mark S. Veillette", "Amir Weiss", "Gregory W. Wornell", "Daniela Rus", "Scott T. Ruppel"], "title": "Advancing AI Challenges for the United States Department of the Air Force", "comment": "8 pages, 8 figures, 59 references. To appear in IEEE HPEC 2025", "summary": "The DAF-MIT AI Accelerator is a collaboration between the United States\nDepartment of the Air Force (DAF) and the Massachusetts Institute of Technology\n(MIT). This program pioneers fundamental advances in artificial intelligence\n(AI) to expand the competitive advantage of the United States in the defense\nand civilian sectors. In recent years, AI Accelerator projects have developed\nand launched public challenge problems aimed at advancing AI research in\npriority areas. Hallmarks of AI Accelerator challenges include large, publicly\navailable, and AI-ready datasets to stimulate open-source solutions and engage\nthe wider academic and private sector AI ecosystem. This article supplements\nour previous publication, which introduced AI Accelerator challenges. We\nprovide an update on how ongoing and new challenges have successfully\ncontributed to AI research and applications of AI technologies.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86DAF-MIT AI\u52a0\u901f\u5668\u9879\u76ee\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5305\u62ec\u5176\u901a\u8fc7\u516c\u5f00\u6311\u6218\u95ee\u9898\u63a8\u52a8AI\u7814\u7a76\uff0c\u63d0\u4f9b\u5927\u578b\u516c\u5f00\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u4fc3\u8fdb\u5b66\u672f\u754c\u548c\u79c1\u8425\u90e8\u95e8AI\u751f\u6001\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7AI\u52a0\u901f\u5668\u9879\u76ee\u63a8\u52a8\u4eba\u5de5\u667a\u80fd\u57fa\u7840\u8fdb\u6b65\uff0c\u6269\u5927\u7f8e\u56fd\u5728\u56fd\u9632\u548c\u6c11\u7528\u9886\u57df\u7684\u7ade\u4e89\u4f18\u52bf\uff0c\u5e76\u901a\u8fc7\u516c\u5f00\u6311\u6218\u95ee\u9898\u4fc3\u8fdbAI\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5f00\u53d1\u548c\u53d1\u5e03\u516c\u5f00\u6311\u6218\u95ee\u9898\uff0c\u63d0\u4f9b\u5927\u578b\u3001\u516c\u5f00\u53ef\u7528\u7684AI\u5c31\u7eea\u6570\u636e\u96c6\uff0c\u4ee5\u523a\u6fc0\u5f00\u6e90\u89e3\u51b3\u65b9\u6848\u5e76\u5438\u5f15\u66f4\u5e7f\u6cdb\u7684\u5b66\u672f\u548c\u79c1\u8425\u90e8\u95e8AI\u751f\u6001\u7cfb\u7edf\u53c2\u4e0e\u3002", "result": "\u6301\u7eed\u548c\u65b0\u7684\u6311\u6218\u5df2\u6210\u529f\u63a8\u52a8AI\u7814\u7a76\u548c\u6280\u672f\u5e94\u7528\uff0c\u8865\u5145\u4e86\u5148\u524d\u53d1\u5e03\u7684\u6311\u6218\u4ecb\u7ecd\u3002", "conclusion": "DAF-MIT AI\u52a0\u901f\u5668\u901a\u8fc7\u516c\u5f00\u6311\u6218\u548c\u6570\u636e\u96c6\u6709\u6548\u4fc3\u8fdb\u4e86AI\u7814\u7a76\u53d1\u5c55\uff0c\u4e3a\u7f8e\u56fd\u5728AI\u9886\u57df\u7684\u7ade\u4e89\u4f18\u52bf\u505a\u51fa\u8d21\u732e\u3002"}}
{"id": "2511.00502", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.00502", "abs": "https://arxiv.org/abs/2511.00502", "authors": ["Peng Zhang", "Vitaly Petrov", "Emil Bj\u00f6rnson"], "title": "Impact of Antenna Arrays Misalignment on the Near Field Distance in Terahertz Communications", "comment": "Accepted to IEEE Globecom, 2025. Copyright 2025 IEEE. Personal use of\n  this material is permitted. Permission from IEEE must be obtained for all\n  other uses, in any current or future media, including reprinting/republishing\n  this material, creating new works, for resale or redistribution to servers or\n  lists, or reuse of any copyrighted component of this work in other works", "summary": "The extremely short wavelength of terahertz (THz) communications leads to an\nextended radiative near-field region, in which some canonical far-field\nassumptions fail. Existing near-field boundary formulations (Fraunhofer\ndistance) for uniform linear/planar array (ULA/UPA) configurations assume ideal\nalignment between transceivers, overlooking practical misalignments caused by\nmobility or mechanical imperfections. This paper addresses this critical gap by\nanalyzing the impact of spatial misalignment on near-field distance\ncalculations in THz systems. We derive exact analytical expressions and\nsimplified approximations for the near-field boundary in both ULA--ULA and\nUPA--UPA configurations under arbitrary misalignment offsets. Through numerical\nsimulations, we validate our theoretical models and quantify how misalignment\nreshapes the near-field region. These findings provide essential guidelines for\noptimizing THz system deployment in realistic scenarios.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u592a\u8d6b\u5179\u901a\u4fe1\u4e2d\u7a7a\u95f4\u9519\u4f4d\u5bf9\u8fd1\u573a\u8fb9\u754c\u8ba1\u7b97\u7684\u5f71\u54cd\uff0c\u63a8\u5bfc\u4e86ULA\u548cUPA\u914d\u7f6e\u4e0b\u4efb\u610f\u9519\u4f4d\u504f\u79fb\u7684\u8fd1\u573a\u8fb9\u754c\u7cbe\u786e\u89e3\u6790\u8868\u8fbe\u5f0f\u548c\u7b80\u5316\u8fd1\u4f3c\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u4e86\u7406\u8bba\u6a21\u578b\u3002", "motivation": "\u592a\u8d6b\u5179\u901a\u4fe1\u7684\u6781\u77ed\u6ce2\u957f\u5bfc\u81f4\u6269\u5c55\u7684\u8f90\u5c04\u8fd1\u573a\u533a\u57df\uff0c\u73b0\u6709\u8fd1\u573a\u8fb9\u754c\u516c\u5f0f\u5047\u8bbe\u6536\u53d1\u5668\u7406\u60f3\u5bf9\u9f50\uff0c\u5ffd\u7565\u4e86\u7531\u79fb\u52a8\u6027\u6216\u673a\u68b0\u7f3a\u9677\u5f15\u8d77\u7684\u5b9e\u9645\u9519\u4f4d\u95ee\u9898\u3002", "method": "\u63a8\u5bfc\u4e86ULA-ULA\u548cUPA-UPA\u914d\u7f6e\u4e0b\u4efb\u610f\u9519\u4f4d\u504f\u79fb\u7684\u8fd1\u573a\u8fb9\u754c\u7cbe\u786e\u89e3\u6790\u8868\u8fbe\u5f0f\u548c\u7b80\u5316\u8fd1\u4f3c\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u7406\u8bba\u6a21\u578b\u3002", "result": "\u9a8c\u8bc1\u4e86\u7406\u8bba\u6a21\u578b\u5e76\u91cf\u5316\u4e86\u9519\u4f4d\u5982\u4f55\u91cd\u5851\u8fd1\u573a\u533a\u57df\uff0c\u4e3a\u5b9e\u9645\u573a\u666f\u4e2d\u592a\u8d6b\u5179\u7cfb\u7edf\u90e8\u7f72\u4f18\u5316\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002", "conclusion": "\u7a7a\u95f4\u9519\u4f4d\u663e\u8457\u5f71\u54cd\u592a\u8d6b\u5179\u7cfb\u7edf\u7684\u8fd1\u573a\u8fb9\u754c\u8ba1\u7b97\uff0c\u7814\u7a76\u6210\u679c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u5173\u952e\u6307\u5bfc\u539f\u5219\u3002"}}
{"id": "2511.01071", "categories": ["cs.IT", "math.CO", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01071", "abs": "https://arxiv.org/abs/2511.01071", "authors": ["Fengxing Zhu"], "title": "Sequence Reconstruction over the Deletion Channel", "comment": null, "summary": "In this paper, we consider the Levenshtein's sequence reconstruction problem\nin the case where the transmitted codeword is chosen from $\\{0,1\\}^n$ and the\nchannel can delete up to $t$ symbols from the transmitted codeword. We\ndetermine the minimum number of channel outputs (assuming that they are\ndistinct) required to reconstruct a list of size $\\ell-1$ of candidate\nsequences, one of which corresponds to the original transmitted sequence. More\nspecifically, we determine the maximum possible size of the intersection of\n$\\ell \\geq 3$ deletion balls of radius $t$ centered at $x_1, x_2, \\dots,\nx_{\\ell}$, where $x_i \\in \\{0,1\\}^n$ for all $i \\in \\{1,2,\\dots,\\ell\\}$ and\n$x_i \\neq x_j$ for $i \\neq j$, with $n \\geq t+ \\ell-1$ and $t \\geq 1$.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86Levenshtein\u5e8f\u5217\u91cd\u6784\u95ee\u9898\uff0c\u5728\u4e8c\u8fdb\u5236\u5e8f\u5217\u548c\u5220\u9664\u4fe1\u9053\u6761\u4ef6\u4e0b\uff0c\u786e\u5b9a\u4e86\u91cd\u6784\u5927\u5c0f\u4e3a\u2113-1\u7684\u5019\u9009\u5e8f\u5217\u5217\u8868\u6240\u9700\u7684\u6700\u5c0f\u4fe1\u9053\u8f93\u51fa\u6570\u91cf\u3002", "motivation": "\u7814\u7a76\u5728\u5220\u9664\u4fe1\u9053\u4e2d\uff0c\u5f53\u4f20\u8f93\u7684\u7801\u5b57\u6700\u591a\u88ab\u5220\u9664t\u4e2a\u7b26\u53f7\u65f6\uff0c\u5982\u4f55\u901a\u8fc7\u4fe1\u9053\u8f93\u51fa\u6765\u91cd\u6784\u539f\u59cb\u5e8f\u5217\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u6790\u2113\u22653\u4e2a\u5220\u9664\u7403\uff08\u534a\u5f84\u4e3at\uff09\u7684\u4ea4\u96c6\u6700\u5927\u53ef\u80fd\u5927\u5c0f\uff0c\u5176\u4e2d\u8fd9\u4e9b\u7403\u4e2d\u5fc3\u662fn\u4f4d\u4e8c\u8fdb\u5236\u5e8f\u5217\u4e14\u4e92\u4e0d\u76f8\u540c\uff0c\u4e14\u6ee1\u8db3n\u2265t+\u2113-1\u548ct\u22651\u7684\u6761\u4ef6\u3002", "result": "\u786e\u5b9a\u4e86\u5728\u7ed9\u5b9a\u6761\u4ef6\u4e0b\uff0c\u91cd\u6784\u5927\u5c0f\u4e3a\u2113-1\u7684\u5019\u9009\u5e8f\u5217\u5217\u8868\u6240\u9700\u7684\u6700\u5c0f\u4fe1\u9053\u8f93\u51fa\u6570\u91cf\u3002", "conclusion": "\u89e3\u51b3\u4e86\u4e8c\u8fdb\u5236\u5e8f\u5217\u5728\u5220\u9664\u4fe1\u9053\u4e2d\u7684\u5e8f\u5217\u91cd\u6784\u95ee\u9898\uff0c\u4e3a\u76f8\u5173\u7f16\u7801\u7406\u8bba\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6491\u3002"}}
{"id": "2511.00340", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00340", "abs": "https://arxiv.org/abs/2511.00340", "authors": ["Manan Roy Choudhury", "Adithya Chandramouli", "Mannan Anand", "Vivek Gupta"], "title": "Better Call CLAUSE: A Discrepancy Benchmark for Auditing LLMs Legal Reasoning Capabilities", "comment": "41 pages, 4 images", "summary": "The rapid integration of large language models (LLMs) into high-stakes legal\nwork has exposed a critical gap: no benchmark exists to systematically\nstress-test their reliability against the nuanced, adversarial, and often\nsubtle flaws present in real-world contracts. To address this, we introduce\nCLAUSE, a first-of-its-kind benchmark designed to evaluate the fragility of an\nLLM's legal reasoning. We study the capabilities of LLMs to detect and reason\nabout fine-grained discrepancies by producing over 7500 real-world perturbed\ncontracts from foundational datasets like CUAD and ContractNLI. Our novel,\npersona-driven pipeline generates 10 distinct anomaly categories, which are\nthen validated against official statutes using a Retrieval-Augmented Generation\n(RAG) system to ensure legal fidelity. We use CLAUSE to evaluate leading LLMs'\nability to detect embedded legal flaws and explain their significance. Our\nanalysis shows a key weakness: these models often miss subtle errors and\nstruggle even more to justify them legally. Our work outlines a path to\nidentify and correct such reasoning failures in legal AI.", "AI": {"tldr": "CLAUSE\u662f\u9996\u4e2a\u8bc4\u4f30LLM\u6cd5\u5f8b\u63a8\u7406\u8106\u5f31\u6027\u7684\u57fa\u51c6\uff0c\u901a\u8fc7\u751f\u62107500+\u6270\u52a8\u5408\u540c\u6765\u6d4b\u8bd5\u6a21\u578b\u68c0\u6d4b\u7ec6\u5fae\u6cd5\u5f8b\u5dee\u5f02\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u4e3b\u6d41LLM\u5728\u68c0\u6d4b\u548c\u89e3\u91ca\u6cd5\u5f8b\u9519\u8bef\u65b9\u9762\u5b58\u5728\u660e\u663e\u5f31\u70b9\u3002", "motivation": "LLM\u5728\u5173\u952e\u6cd5\u5f8b\u5de5\u4f5c\u4e2d\u5feb\u901f\u5e94\u7528\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6d4b\u8bd5\u5176\u5bf9\u6297\u73b0\u5b9e\u5408\u540c\u4e2d\u5fae\u5999\u3001\u5bf9\u6297\u6027\u7f3a\u9677\u53ef\u9760\u6027\u7684\u57fa\u51c6\u3002", "method": "\u57fa\u4e8eCUAD\u548cContractNLI\u6570\u636e\u96c6\u751f\u621010\u7c7b\u5f02\u5e38\u5408\u540c\uff0c\u4f7f\u7528\u89d2\u8272\u9a71\u52a8\u6d41\u7a0b\u548cRAG\u7cfb\u7edf\u786e\u4fdd\u6cd5\u5f8b\u51c6\u786e\u6027\uff0c\u8bc4\u4f30LLM\u68c0\u6d4b\u6cd5\u5f8b\u7f3a\u9677\u548c\u89e3\u91ca\u80fd\u529b\u3002", "result": "\u4e3b\u6d41LLM\u7ecf\u5e38\u9057\u6f0f\u7ec6\u5fae\u9519\u8bef\uff0c\u5728\u6cd5\u5f8b\u89e3\u91ca\u65b9\u9762\u8868\u73b0\u66f4\u5dee\uff0c\u63ed\u793a\u4e86\u6cd5\u5f8bAI\u4e2d\u7684\u5173\u952e\u63a8\u7406\u7f3a\u9677\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u8bc6\u522b\u548c\u7ea0\u6b63\u6cd5\u5f8bAI\u4e2d\u7684\u63a8\u7406\u5931\u8d25\u63d0\u4f9b\u4e86\u8def\u5f84\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u6539\u8fdbLLM\u5728\u6cd5\u5f8b\u7ec6\u5fae\u5dee\u522b\u5904\u7406\u65b9\u9762\u7684\u80fd\u529b\u3002"}}
{"id": "2511.00569", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00569", "abs": "https://arxiv.org/abs/2511.00569", "authors": ["Tianheng Xu", "Runke Fan", "Jie Zhu", "Pei Peng", "Xianfu Chen", "Qingqing Wu", "Ming Jiang", "Celimuge Wu", "Dusit Niyato", "Kai-Kit Wong"], "title": "Advancing Fluid Antenna-Assisted Non-Terrestrial Networks in 6G and Beyond: Fundamentals, State of the Art, and Future Directions", "comment": null, "summary": "With the surging demand for ultra-reliable, low-latency, and ubiquitous\nconnectivity in Sixth-Generation (6G) networks, Non-Terrestrial Networks (NTNs)\nemerge as a key complement to terrestrial networks by offering flexible access\nand global coverage. Despite the significant potential, NTNs still face\ncritical challenges, including dynamic propagation environments, energy\nconstraints, and dense interference. As a key 6G technology, Fluid Antennas\n(FAs) can reshape wireless channels by reconfiguring radiating elements within\na limited space, such as their positions and rotations, to provide higher\nchannel diversity and multiplexing gains. Compared to fixed-position antennas,\nFAs can present a promising integration path for NTNs to mitigate dynamic\nchannel fading and optimize resource allocation. This paper provides a\ncomprehensive review of FA-assisted NTNs. We begin with a brief overview of the\nclassical structure and limitations of existing NTNs, the fundamentals and\nadvantages of FAs, and the basic principles of FA-assisted NTNs. We then\ninvestigate the joint optimization solutions, detailing the adjustments of FA\nconfigurations, NTN platform motion modes, and resource allocations. We also\ndiscuss the combination with other emerging technologies and explore\nFA-assisted NTNs as a novel network architecture for intelligent function\nintegrations. Furthermore, we delve into the physical layer security and covert\ncommunication in FA-assisted NTNs. Finally, we highlight the potential future\ndirections to empower broader applications of FA-assisted NTNs.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u7efc\u8ff0\u4e86\u6d41\u4f53\u5929\u7ebf\u8f85\u52a9\u7684\u975e\u5730\u9762\u7f51\u7edc\uff0c\u63a2\u8ba8\u4e86\u5176\u7ed3\u6784\u3001\u4f18\u5316\u65b9\u6848\u3001\u4e0e\u5176\u4ed6\u65b0\u5174\u6280\u672f\u7684\u7ed3\u5408\uff0c\u4ee5\u53ca\u7269\u7406\u5c42\u5b89\u5168\u548c\u9690\u853d\u901a\u4fe1\u7b49\u5173\u952e\u95ee\u9898\u3002", "motivation": "\u968f\u77406G\u7f51\u7edc\u5bf9\u8d85\u53ef\u9760\u3001\u4f4e\u5ef6\u8fdf\u548c\u65e0\u5904\u4e0d\u5728\u8fde\u63a5\u7684\u9700\u6c42\u6fc0\u589e\uff0c\u975e\u5730\u9762\u7f51\u7edc\u4f5c\u4e3a\u5730\u9762\u7f51\u7edc\u7684\u5173\u952e\u8865\u5145\uff0c\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u63a5\u5165\u548c\u5168\u7403\u8986\u76d6\u3002\u7136\u800c\uff0c\u975e\u5730\u9762\u7f51\u7edc\u4ecd\u9762\u4e34\u52a8\u6001\u4f20\u64ad\u73af\u5883\u3001\u80fd\u91cf\u9650\u5236\u548c\u5bc6\u96c6\u5e72\u6270\u7b49\u5173\u952e\u6311\u6218\u3002\u6d41\u4f53\u5929\u7ebf\u4f5c\u4e3a6G\u5173\u952e\u6280\u672f\uff0c\u80fd\u591f\u901a\u8fc7\u91cd\u65b0\u914d\u7f6e\u8f90\u5c04\u5143\u4ef6\u6765\u91cd\u5851\u65e0\u7ebf\u4fe1\u9053\uff0c\u63d0\u4f9b\u66f4\u9ad8\u7684\u4fe1\u9053\u591a\u6837\u6027\u548c\u590d\u7528\u589e\u76ca\u3002", "method": "\u672c\u6587\u9996\u5148\u6982\u8ff0\u4e86\u73b0\u6709\u975e\u5730\u9762\u7f51\u7edc\u7684\u7ecf\u5178\u7ed3\u6784\u548c\u5c40\u9650\u6027\u3001\u6d41\u4f53\u5929\u7ebf\u7684\u57fa\u672c\u539f\u7406\u548c\u4f18\u52bf\uff0c\u4ee5\u53ca\u6d41\u4f53\u5929\u7ebf\u8f85\u52a9\u975e\u5730\u9762\u7f51\u7edc\u7684\u57fa\u672c\u539f\u7406\u3002\u7136\u540e\u7814\u7a76\u4e86\u8054\u5408\u4f18\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u8be6\u7ec6\u8bf4\u660e\u4e86\u6d41\u4f53\u5929\u7ebf\u914d\u7f6e\u3001\u975e\u5730\u9762\u7f51\u7edc\u5e73\u53f0\u8fd0\u52a8\u6a21\u5f0f\u548c\u8d44\u6e90\u5206\u914d\u7684\u8c03\u6574\u3002\u8fd8\u8ba8\u8bba\u4e86\u4e0e\u5176\u4ed6\u65b0\u5174\u6280\u672f\u7684\u7ed3\u5408\uff0c\u5e76\u63a2\u7d22\u4e86\u6d41\u4f53\u5929\u7ebf\u8f85\u52a9\u975e\u5730\u9762\u7f51\u7edc\u4f5c\u4e3a\u667a\u80fd\u529f\u80fd\u96c6\u6210\u7684\u65b0\u578b\u7f51\u7edc\u67b6\u6784\u3002", "result": "\u6d41\u4f53\u5929\u7ebf\u8f85\u52a9\u975e\u5730\u9762\u7f51\u7edc\u80fd\u591f\u6709\u6548\u7f13\u89e3\u52a8\u6001\u4fe1\u9053\u8870\u843d\u5e76\u4f18\u5316\u8d44\u6e90\u5206\u914d\uff0c\u4e3a6G\u7f51\u7edc\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u96c6\u6210\u8def\u5f84\u3002", "conclusion": "\u6d41\u4f53\u5929\u7ebf\u8f85\u52a9\u975e\u5730\u9762\u7f51\u7edc\u5177\u6709\u5e7f\u9614\u7684\u5e94\u7528\u524d\u666f\uff0c\u672a\u6765\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u5176\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u89e3\u51b3\u76f8\u5173\u7684\u6280\u672f\u6311\u6218\u3002"}}
{"id": "2511.01111", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01111", "abs": "https://arxiv.org/abs/2511.01111", "authors": ["Farshad Rostami Ghadi", "Kai-Kit Wong", "Masoud Kaveh", "Hanjiang Hong", "Chan-Byoung Chae", "Lajos Hanzo"], "title": "Coverage Analysis and Optimization of FIRES-Assisted NOMA and OMA Systems", "comment": null, "summary": "Fluid integrated reflecting and emitting surfaces (FIRES) are investigated.\nIn these metasurfaces, each subarea hosts an active element capable of\nsimultaneous transmission and reflection, phase, and geometric positioning\ncontrol within the subarea. We develop a coverage-centric system model for the\ntwo-user downlink scenario (one user per half-space) under spatially correlated\nRician fading and imperfect phase control. First, we derive closed-form\nfar-field line-of-sight (LoS) coverage bounds that reveal the effects of\naperture size, base station (BS) distance, transmit power, energy-splitting\n(ES), and phase errors. Protocol-aware corollaries are then presented for both\northogonal multiple access (OMA) and non-orthogonal multiple access (NOMA),\nincluding conditions for successful successive interference cancellation (SIC).\nSecond, we formulate coverage maximization as a bi-level optimization problem\nconsisting of (i) an outer search over FIRES element positions, selecting one\nactive preset per subarea under minimum-spacing constraints, and (ii) an inner\nresource allocation problem tailored to the multiple-access scheme, which is\none-dimensional for OMA and a small convex program for NOMA. The proposed\nframework explicitly accounts for target rate constraints, ES conservation,\npower budgets, geometric placement limits, and decoding-order feasibility.\nExtensive simulations demonstrate that FIRES, by jointly exploiting geometric\nrepositioning and passive energy control, substantially enlarges the coverage\nregion compared with a conventional simultaneously transmitting and reflecting\nreconfigurable intelligent surface (STAR-RIS) under the same element budget.\nFurthermore, NOMA yields additional coverage gains when feasible. The\nanalytical coverage bounds closely match the simulation results and quantify\nthe robustness of FIRES to phase-control imperfections.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6d41\u4f53\u96c6\u6210\u53cd\u5c04\u548c\u53d1\u5c04\u8868\u9762\uff08FIRES\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u63a7\u5236\u4f20\u8f93\u548c\u53cd\u5c04\u3001\u76f8\u4f4d\u53ca\u51e0\u4f55\u5b9a\u4f4d\u7684\u667a\u80fd\u8868\u9762\u3002\u901a\u8fc7\u5efa\u7acb\u8986\u76d6\u4e2d\u5fc3\u7cfb\u7edf\u6a21\u578b\uff0c\u63a8\u5bfc\u4e86LoS\u8986\u76d6\u8fb9\u754c\u95ed\u5f0f\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u8986\u76d6\u6700\u5927\u5316\u7684\u53cc\u5c42\u4f18\u5316\u6846\u67b6\u3002\u76f8\u6bd4\u4f20\u7edfSTAR-RIS\uff0cFIRES\u901a\u8fc7\u8054\u5408\u5229\u7528\u51e0\u4f55\u91cd\u5b9a\u4f4d\u548c\u88ab\u52a8\u80fd\u91cf\u63a7\u5236\u663e\u8457\u6269\u5927\u4e86\u8986\u76d6\u533a\u57df\u3002", "motivation": "\u4f20\u7edf\u7684\u540c\u65f6\u4f20\u8f93\u548c\u53cd\u5c04\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08STAR-RIS\uff09\u5728\u8986\u76d6\u6027\u80fd\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u540c\u65f6\u63a7\u5236\u4f20\u8f93\u53cd\u5c04\u3001\u76f8\u4f4d\u548c\u51e0\u4f55\u5b9a\u4f4d\u7684\u65b0\u578b\u667a\u80fd\u8868\u9762\uff0c\u4ee5\u63d0\u5347\u4e24\u7528\u6237\u4e0b\u884c\u94fe\u8def\u7684\u8986\u76d6\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u4e86\u8986\u76d6\u4e2d\u5fc3\u7cfb\u7edf\u6a21\u578b\uff0c\u63a8\u5bfc\u4e86LoS\u8986\u76d6\u8fb9\u754c\u7684\u95ed\u5f0f\u89e3\uff1b\u63d0\u51fa\u4e86\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff0c\u5305\u62ec\u5916\u5c42FIRES\u5143\u7d20\u4f4d\u7f6e\u641c\u7d22\u548c\u5185\u5c42\u8d44\u6e90\u5206\u914d\uff1b\u9488\u5bf9OMA\u548cNOMA\u5206\u522b\u8bbe\u8ba1\u4e86\u4f18\u5316\u7b56\u7565\u3002", "result": "FIRES\u76f8\u6bd4\u4f20\u7edfSTAR-RIS\u663e\u8457\u6269\u5927\u4e86\u8986\u76d6\u533a\u57df\uff1bNOMA\u5728\u53ef\u884c\u65f6\u80fd\u5e26\u6765\u989d\u5916\u7684\u8986\u76d6\u589e\u76ca\uff1b\u5206\u6790\u8986\u76d6\u8fb9\u754c\u4e0e\u4eff\u771f\u7ed3\u679c\u9ad8\u5ea6\u5339\u914d\uff1bFIRES\u5bf9\u76f8\u4f4d\u63a7\u5236\u8bef\u5dee\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "FIRES\u901a\u8fc7\u8054\u5408\u5229\u7528\u51e0\u4f55\u91cd\u5b9a\u4f4d\u548c\u88ab\u52a8\u80fd\u91cf\u63a7\u5236\uff0c\u4e3a\u667a\u80fd\u8868\u9762\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\uff0c\u5728\u8986\u76d6\u6027\u80fd\u548c\u76f8\u4f4d\u8bef\u5dee\u9c81\u68d2\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edfSTAR-RIS\u3002"}}
{"id": "2511.00379", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00379", "abs": "https://arxiv.org/abs/2511.00379", "authors": ["Jiahao Wang", "Songkai Xue", "Jinghui Li", "Xiaozhen Wang"], "title": "Diverse Human Value Alignment for Large Language Models via Ethical Reasoning", "comment": "Accepted by AIES 2025, camera-ready version", "summary": "Ensuring that Large Language Models (LLMs) align with the diverse and\nevolving human values across different regions and cultures remains a critical\nchallenge in AI ethics. Current alignment approaches often yield superficial\nconformity rather than genuine ethical understanding, failing to address the\ncomplex, context-dependent nature of human values. In this paper, we propose a\nnovel ethical reasoning paradigm for LLMs inspired by well-established ethical\ndecision-making models, aiming at enhancing diverse human value alignment\nthrough deliberative ethical reasoning. Our framework consists of a structured\nfive-step process, including contextual fact gathering, hierarchical social\nnorm identification, option generation, multiple-lens ethical impact analysis,\nand reflection. This theory-grounded approach guides LLMs through an\ninterpretable reasoning process that enhances their ability to understand\nregional specificities and perform nuanced ethical analysis, which can be\nimplemented with either prompt engineering or supervised fine-tuning methods.\nWe perform evaluations on the SafeWorld benchmark that specially designed for\nregional value alignment. Experimental results demonstrate our framework\nsignificantly improves LLM alignment with diverse human values compared to\nbaseline methods, enabling more accurate social norm identification and more\nculturally appropriate reasoning. Our work provides a concrete pathway toward\ndeveloping LLMs that align more effectively with the multifaceted values of\nglobal societies through interdisciplinary research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f26\u7406\u51b3\u7b56\u6a21\u578b\u7684LLM\u4f26\u7406\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4e94\u6b65\u7ed3\u6784\u5316\u6d41\u7a0b\u589e\u5f3a\u591a\u5143\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\uff0c\u5728SafeWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dLLM\u5bf9\u9f50\u65b9\u6cd5\u5f80\u5f80\u53ea\u4ea7\u751f\u8868\u9762\u4e00\u81f4\u6027\u800c\u975e\u771f\u6b63\u7684\u4f26\u7406\u7406\u89e3\uff0c\u65e0\u6cd5\u5904\u7406\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u590d\u6742\u6027\u548c\u60c5\u5883\u4f9d\u8d56\u6027\uff0c\u9700\u8981\u89e3\u51b3\u8de8\u5730\u533a\u6587\u5316\u7684\u591a\u5143\u4ef7\u503c\u89c2\u5bf9\u9f50\u95ee\u9898\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u4f26\u7406\u51b3\u7b56\u6a21\u578b\u7684\u4e94\u6b65\u63a8\u7406\u6846\u67b6\uff1a\u60c5\u5883\u4e8b\u5b9e\u6536\u96c6\u3001\u5c42\u7ea7\u5316\u793e\u4f1a\u89c4\u8303\u8bc6\u522b\u3001\u9009\u9879\u751f\u6210\u3001\u591a\u89c6\u89d2\u4f26\u7406\u5f71\u54cd\u5206\u6790\u3001\u53cd\u601d\uff0c\u53ef\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u6216\u76d1\u7763\u5fae\u8c03\u5b9e\u73b0\u3002", "result": "\u5728\u4e13\u95e8\u8bbe\u8ba1\u7684SafeWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86LLM\u4e0e\u591a\u5143\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u5bf9\u9f50\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u7684\u793e\u4f1a\u89c4\u8303\u8bc6\u522b\u548c\u66f4\u6587\u5316\u9002\u5b9c\u6027\u7684\u63a8\u7406\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u901a\u8fc7\u8de8\u5b66\u79d1\u7814\u7a76\u5f00\u53d1\u66f4\u6709\u6548\u5bf9\u9f50\u5168\u7403\u793e\u4f1a\u591a\u5143\u4ef7\u503c\u89c2\u7684LLM\u63d0\u4f9b\u4e86\u5177\u4f53\u8def\u5f84\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u5730\u533a\u7279\u5f02\u6027\u7684\u7406\u89e3\u548c\u7ec6\u81f4\u4f26\u7406\u5206\u6790\u80fd\u529b\u3002"}}
{"id": "2511.00767", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.00767", "abs": "https://arxiv.org/abs/2511.00767", "authors": ["Shi Gengtian", "Takashi Koshimizu", "Megumi Saito", "Pan Zhenni", "Liu Jiang", "Shigeru Shimamoto"], "title": "Power Control Based on Multi-Agent Deep Q Network for D2D Communication", "comment": "Published in IEEE ICAIIC 2020. This is the preprint version of the\n  paper", "summary": "In device-to-device (D2D) communication under a cell with resource sharing\nmode the spectrum resource utilization of the system will be improved. However,\nif the interference generated by the D2D user is not controlled, the\nperformance of the entire system and the quality of service (QOS) of the\ncellular user may be degraded. Power control is important because it helps to\nreduce interference in the system. In this paper, we propose a reinforcement\nlearning algorithm for adaptive power control that helps reduce interference to\nincrease system throughput. Simulation results show the proposed algorithm has\nbetter performance than traditional algorithm in LTE (Long Term Evolution).", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u529f\u7387\u63a7\u5236\u7b97\u6cd5\uff0c\u7528\u4e8eD2D\u901a\u4fe1\u4e2d\u51cf\u5c11\u5e72\u6270\u5e76\u63d0\u9ad8\u7cfb\u7edf\u541e\u5410\u91cf", "motivation": "\u5728D2D\u901a\u4fe1\u4e2d\uff0c\u5982\u679c\u4e0d\u63a7\u5236D2D\u7528\u6237\u4ea7\u751f\u7684\u5e72\u6270\uff0c\u4f1a\u964d\u4f4e\u6574\u4e2a\u7cfb\u7edf\u6027\u80fd\u548c\u8702\u7a9d\u7528\u6237\u7684\u670d\u52a1\u8d28\u91cf\uff0c\u56e0\u6b64\u529f\u7387\u63a7\u5236\u5bf9\u4e8e\u51cf\u5c11\u7cfb\u7edf\u5e72\u6270\u81f3\u5173\u91cd\u8981", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u81ea\u9002\u5e94\u529f\u7387\u63a7\u5236", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u5728LTE\u7cfb\u7edf\u4e2d\u6bd4\u4f20\u7edf\u7b97\u6cd5\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728D2D\u901a\u4fe1\u529f\u7387\u63a7\u5236\u4e2d\u80fd\u6709\u6548\u51cf\u5c11\u5e72\u6270\u5e76\u63d0\u9ad8\u7cfb\u7edf\u541e\u5410\u91cf"}}
{"id": "2511.01162", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01162", "abs": "https://arxiv.org/abs/2511.01162", "authors": ["Yun Long Zhu", "Chang-An Zhao"], "title": "Distributed Matrix Multiplication-Friendly Algebraic Function Fields", "comment": null, "summary": "In this paper, we introduce distributed matrix multiplication (DMM)-friendly\nalgebraic function fields for polynomial codes and Matdot codes, and present\nseveral constructions for such function fields through extensions of the\nrational function field. The primary challenge in extending polynomial codes\nand Matdot codes to algebraic function fields lies in constructing optimal\ndecoding schemes. We establish optimal recovery thresholds for both polynomial\nalgebraic geometry (AG) codes and Matdot AG codes for fixed matrix\nmultiplication. Our proposed function fields support DMM with optimal recovery\nthresholds, while offering rational places that exceed the base finite field\nsize in specific parameter regimes. Although these fields may not achieve\noptimal computational efficiency, our results provide practical improvements\nfor matrix multiplication implementations. Explicit examples of applicable\nfunction fields are provided.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u77e9\u9635\u4e58\u6cd5(DMM)\u7684\u4ee3\u6570\u51fd\u6570\u57df\uff0c\u7528\u4e8e\u6269\u5c55\u591a\u9879\u5f0f\u7801\u548cMatdot\u7801\uff0c\u5e76\u5efa\u7acb\u4e86\u591a\u9879\u5f0f\u4ee3\u6570\u51e0\u4f55\u7801\u548cMatdot\u4ee3\u6570\u51e0\u4f55\u7801\u7684\u6700\u4f18\u6062\u590d\u9608\u503c\u3002", "motivation": "\u5c06\u591a\u9879\u5f0f\u7801\u548cMatdot\u7801\u6269\u5c55\u5230\u4ee3\u6570\u51fd\u6570\u57df\u7684\u4e3b\u8981\u6311\u6218\u5728\u4e8e\u6784\u5efa\u6700\u4f18\u89e3\u7801\u65b9\u6848\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6709\u7406\u51fd\u6570\u57df\u7684\u6269\u5c55\u6784\u9020DMM\u53cb\u597d\u7684\u4ee3\u6570\u51fd\u6570\u57df\uff0c\u4e3a\u591a\u9879\u5f0f\u4ee3\u6570\u51e0\u4f55\u7801\u548cMatdot\u4ee3\u6570\u51e0\u4f55\u7801\u5efa\u7acb\u6700\u4f18\u6062\u590d\u9608\u503c\u3002", "result": "\u63d0\u51fa\u7684\u51fd\u6570\u57df\u652f\u6301\u5177\u6709\u6700\u4f18\u6062\u590d\u9608\u503c\u7684DMM\uff0c\u5728\u7279\u5b9a\u53c2\u6570\u673a\u5236\u4e0b\u63d0\u4f9b\u8d85\u8fc7\u57fa\u6709\u9650\u57df\u5927\u5c0f\u7684\u6709\u7406\u70b9\u3002", "conclusion": "\u867d\u7136\u8fd9\u4e9b\u57df\u53ef\u80fd\u65e0\u6cd5\u8fbe\u5230\u6700\u4f18\u8ba1\u7b97\u6548\u7387\uff0c\u4f46\u7ed3\u679c\u4e3a\u77e9\u9635\u4e58\u6cd5\u5b9e\u73b0\u63d0\u4f9b\u4e86\u5b9e\u9645\u6539\u8fdb\uff0c\u5e76\u7ed9\u51fa\u4e86\u9002\u7528\u7684\u51fd\u6570\u57df\u7684\u5177\u4f53\u793a\u4f8b\u3002"}}
{"id": "2511.00382", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00382", "abs": "https://arxiv.org/abs/2511.00382", "authors": ["Mina Taraghi", "Yann Pequignot", "Amin Nikanjam", "Mohamed Amine Merzouk", "Foutse Khomh"], "title": "Efficiency vs. Alignment: Investigating Safety and Fairness Risks in Parameter-Efficient Fine-Tuning of LLMs", "comment": null, "summary": "Organizations are increasingly adopting and adapting Large Language Models\n(LLMs) hosted on public repositories such as HuggingFace. Although these\nadaptations often improve performance on specialized downstream tasks, recent\nevidence indicates that they can also degrade a model's safety or fairness.\nSince different fine-tuning techniques may exert distinct effects on these\ncritical dimensions, this study undertakes a systematic assessment of their\ntrade-offs. Four widely used Parameter-Efficient Fine-Tuning methods, LoRA,\nIA3, Prompt-Tuning, and P-Tuning, are applied to four instruction-tuned model\nfamilies (Meta-Llama-3-8B, Qwen2.5-7B, Mistral-7B, and Gemma-7B). In total, 235\nfine-tuned variants are evaluated across eleven safety hazard categories and\nnine demographic fairness dimensions. The results show that adapter-based\napproaches (LoRA, IA3) tend to improve safety scores and are the least\ndisruptive to fairness, retaining higher accuracy and lower bias scores. In\ncontrast, prompt-based methods (Prompt-Tuning and P-Tuning) generally reduce\nsafety and cause larger fairness regressions, with decreased accuracy and\nincreased bias. Alignment shifts are strongly moderated by base model type:\nLLaMA remains stable, Qwen records modest gains, Gemma experiences the steepest\nsafety decline, and Mistral, which is released without an internal moderation\nlayer, displays the greatest variance. Improvements in safety do not\nnecessarily translate into improvements in fairness, and no single\nconfiguration optimizes all fairness metrics simultaneously, indicating an\ninherent trade-off between these objectives. These findings suggest a practical\nguideline for safety-critical deployments: begin with a well-aligned base\nmodel, favour adapter-based PEFT, and conduct category-specific audits of both\nsafety and fairness.", "AI": {"tldr": "\u7cfb\u7edf\u8bc4\u4f30\u56db\u79cd\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5(LoRA\u3001IA3\u3001Prompt-Tuning\u3001P-Tuning)\u5bf9LLM\u5b89\u5168\u6027\u548c\u516c\u5e73\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u57fa\u4e8e\u9002\u914d\u5668\u7684\u65b9\u6cd5\u5728\u4fdd\u6301\u5b89\u5168\u6027\u548c\u516c\u5e73\u6027\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u800c\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\u901a\u5e38\u4f1a\u5bfc\u81f4\u5b89\u5168\u6027\u548c\u516c\u5e73\u6027\u4e0b\u964d\u3002", "motivation": "\u968f\u7740\u7ec4\u7ec7\u8d8a\u6765\u8d8a\u591a\u5730\u91c7\u7528\u548c\u5fae\u8c03\u6258\u7ba1\u5728\u516c\u5171\u4ed3\u5e93\u4e2d\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u867d\u7136\u8fd9\u4e9b\u5fae\u8c03\u901a\u5e38\u80fd\u63d0\u9ad8\u4e13\u4e1a\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u4f46\u6700\u8fd1\u8bc1\u636e\u8868\u660e\u5b83\u4eec\u4e5f\u53ef\u80fd\u964d\u4f4e\u6a21\u578b\u7684\u5b89\u5168\u6027\u6216\u516c\u5e73\u6027\u3002\u4e0d\u540c\u5fae\u8c03\u6280\u672f\u53ef\u80fd\u5bf9\u8fd9\u4e9b\u5173\u952e\u7ef4\u5ea6\u4ea7\u751f\u4e0d\u540c\u5f71\u54cd\u3002", "method": "\u5bf9\u56db\u79cd\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\u5bb6\u65cf(Meta-Llama-3-8B\u3001Qwen2.5-7B\u3001Mistral-7B\u3001Gemma-7B)\u5e94\u7528\u56db\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u5171\u8bc4\u4f30235\u4e2a\u5fae\u8c03\u53d8\u4f53\uff0c\u6db5\u76d611\u4e2a\u5b89\u5168\u5371\u5bb3\u7c7b\u522b\u548c9\u4e2a\u4eba\u53e3\u7edf\u8ba1\u5b66\u516c\u5e73\u7ef4\u5ea6\u3002", "result": "\u57fa\u4e8e\u9002\u914d\u5668\u7684\u65b9\u6cd5(LoRA\u3001IA3)\u503e\u5411\u4e8e\u63d0\u9ad8\u5b89\u5168\u5206\u6570\uff0c\u5bf9\u516c\u5e73\u6027\u7834\u574f\u6700\u5c0f\uff0c\u4fdd\u6301\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u66f4\u4f4e\u7684\u504f\u89c1\u5206\u6570\u3002\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5(Prompt-Tuning\u3001P-Tuning)\u901a\u5e38\u964d\u4f4e\u5b89\u5168\u6027\u5e76\u5bfc\u81f4\u66f4\u5927\u7684\u516c\u5e73\u6027\u56de\u5f52\u3002\u5bf9\u9f50\u53d8\u5316\u53d7\u57fa\u7840\u6a21\u578b\u7c7b\u578b\u5f3a\u70c8\u8c03\u8282\u3002", "conclusion": "\u5b89\u5168\u6027\u7684\u6539\u8fdb\u4e0d\u4e00\u5b9a\u8f6c\u5316\u4e3a\u516c\u5e73\u6027\u7684\u6539\u8fdb\uff0c\u6ca1\u6709\u5355\u4e00\u914d\u7f6e\u80fd\u540c\u65f6\u4f18\u5316\u6240\u6709\u516c\u5e73\u6027\u6307\u6807\uff0c\u8868\u660e\u8fd9\u4e9b\u76ee\u6807\u4e4b\u95f4\u5b58\u5728\u56fa\u6709\u7684\u6743\u8861\u3002\u5efa\u8bae\u5b89\u5168\u5173\u952e\u90e8\u7f72\u4ece\u5bf9\u9f50\u826f\u597d\u7684\u57fa\u7840\u6a21\u578b\u5f00\u59cb\uff0c\u4f18\u5148\u9009\u62e9\u57fa\u4e8e\u9002\u914d\u5668\u7684PEFT\u65b9\u6cd5\uff0c\u5e76\u5bf9\u5b89\u5168\u6027\u548c\u516c\u5e73\u6027\u8fdb\u884c\u7c7b\u522b\u7279\u5b9a\u5ba1\u8ba1\u3002"}}
{"id": "2511.00823", "categories": ["cs.NI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.00823", "abs": "https://arxiv.org/abs/2511.00823", "authors": ["Qi Xia", "Hu Xia", "Isaac Amankona Obiri", "Adjei-Arthur Bonsu", "Grace Mupoyi Ntuala", "Ansu Badjie", "Tienin Bole Wilfried", "Jiaqin Liu", "Lan Ma", "Jianbin Gao", "Feng Yao"], "title": "TINC: Trusted Intelligent NetChain", "comment": "17 pages, 22 figures This preprint has been submitted to IEEE\n  Transactions on Networking and is currently under peer review. The content\n  may be updated based on the review outcome. \\c{opyright} The authors. All\n  rights reserved. Distributed under the arXiv non-exclusive license", "summary": "Blockchain technology facilitates the development of decentralized systems\nthat ensure trust and transparency without the need for expensive centralized\nintermediaries. However, existing blockchain architectures particularly\nconsortium blockchains face critical challenges related to scalability and\nefficiency. State sharding has emerged as a promising approach to enhance\nblockchain scalability and performance. However, current shard-based solutions\noften struggle to guarantee fair participation and a balanced workload\ndistribution among consortium members. To address these limitations, we propose\nTrusted Intelligent NetChain (TINC), a multi-plane sharding architecture\nspecifically designed for consortium blockchains. TINC incorporates intelligent\nmechanisms for adaptive node assignment and dynamic workload balancing,\nenabling the system to respond effectively to changing network conditions while\nmaintaining equitable shard utilization. By decoupling the control and data\nplanes, TINC allows control nodes to focus on consensus operations, while data\nnodes handle large-scale storage, thus improving overall resource efficiency.\nExtensive experimental evaluation and formal analysis demonstrate that TINC\nsignificantly outperforms existing shard-based blockchain frameworks. It\nachieves higher throughput, lower latency, balanced node and transaction\ndistributions, and reduced transaction failure rates. Furthermore, TINC\nmaintains essential blockchain security guarantees, exhibiting resilience\nagainst Byzantine faults and dynamic network environments. The integration of\nDynamic Decentralized Identifiers (DDIDs) further strengthens trust and\nsecurity management within the consortium network.", "AI": {"tldr": "TINC\u662f\u4e00\u4e2a\u4e13\u4e3a\u8054\u76df\u94fe\u8bbe\u8ba1\u7684\u591a\u5e73\u9762\u5206\u7247\u67b6\u6784\uff0c\u901a\u8fc7\u667a\u80fd\u8282\u70b9\u5206\u914d\u548c\u52a8\u6001\u8d1f\u8f7d\u5e73\u8861\u673a\u5236\u89e3\u51b3\u73b0\u6709\u5206\u7247\u65b9\u6848\u5728\u516c\u5e73\u53c2\u4e0e\u548c\u5de5\u4f5c\u8d1f\u8f7d\u5747\u8861\u65b9\u9762\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u8054\u76df\u94fe\u67b6\u6784\u9762\u4e34\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u95ee\u9898\uff0c\u7279\u522b\u662f\u5206\u7247\u65b9\u6848\u96be\u4ee5\u4fdd\u8bc1\u8054\u76df\u6210\u5458\u95f4\u7684\u516c\u5e73\u53c2\u4e0e\u548c\u5747\u8861\u5de5\u4f5c\u8d1f\u8f7d\u5206\u914d\u3002", "method": "TINC\u91c7\u7528\u591a\u5e73\u9762\u5206\u7247\u67b6\u6784\uff0c\u5206\u79bb\u63a7\u5236\u5e73\u9762\u548c\u6570\u636e\u5e73\u9762\uff0c\u63a7\u5236\u8282\u70b9\u8d1f\u8d23\u5171\u8bc6\u64cd\u4f5c\uff0c\u6570\u636e\u8282\u70b9\u5904\u7406\u5927\u89c4\u6a21\u5b58\u50a8\uff0c\u5e76\u5f15\u5165\u667a\u80fd\u81ea\u9002\u5e94\u8282\u70b9\u5206\u914d\u548c\u52a8\u6001\u8d1f\u8f7d\u5e73\u8861\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793aTINC\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5206\u7247\u533a\u5757\u94fe\u6846\u67b6\uff0c\u5177\u6709\u66f4\u9ad8\u541e\u5410\u91cf\u3001\u66f4\u4f4e\u5ef6\u8fdf\u3001\u66f4\u5747\u8861\u7684\u8282\u70b9\u548c\u4ea4\u6613\u5206\u5e03\uff0c\u4ee5\u53ca\u66f4\u4f4e\u7684\u4ea4\u6613\u5931\u8d25\u7387\u3002", "conclusion": "TINC\u5728\u4fdd\u6301\u57fa\u672c\u533a\u5757\u94fe\u5b89\u5168\u4fdd\u8bc1\u7684\u540c\u65f6\uff0c\u901a\u8fc7DDIDs\u589e\u5f3a\u8054\u76df\u7f51\u7edc\u5185\u7684\u4fe1\u4efb\u548c\u5b89\u5168\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8054\u76df\u94fe\u7684\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u95ee\u9898\u3002"}}
{"id": "2511.01173", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01173", "abs": "https://arxiv.org/abs/2511.01173", "authors": ["Xingyu Zhou", "Le Liang", "Xinjie Li", "Jing Zhang", "Peiwen Jiang", "Xiao Li", "Shi Jin"], "title": "Conditional Diffusion Model-Enabled Scenario-Specific Neural Receivers for Superimposed Pilot Schemes", "comment": "This paper has been accepted for publication by China Communications", "summary": "Neural receivers have demonstrated strong performance in wireless\ncommunication systems. However, their effectiveness typically depends on access\nto large-scale, scenario-specific channel data for training, which is often\ndifficult to obtain in practice. Recently, generative artificial intelligence\n(AI) models, particularly diffusion models (DMs), have emerged as effective\ntools for synthesizing high-dimensional data. This paper presents a\nscenario-specific channel generation method based on conditional DMs, which\naccurately model channel distributions conditioned on user location and\nvelocity information. The generated synthetic channel data are then employed\nfor data augmentation to improve the training of a neural receiver designed for\nsuperimposed pilot-based transmission. Experimental results show that the\nproposed method generates high-fidelity channel samples and significantly\nenhances neural receiver performance in the target scenarios, outperforming\nconventional data augmentation and generative adversarial network-based\ntechniques.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6761\u4ef6\u6269\u6563\u6a21\u578b\u7684\u573a\u666f\u7279\u5b9a\u4fe1\u9053\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u63d0\u5347\u795e\u7ecf\u63a5\u6536\u673a\u6027\u80fd", "motivation": "\u795e\u7ecf\u63a5\u6536\u673a\u9700\u8981\u5927\u91cf\u573a\u666f\u7279\u5b9a\u4fe1\u9053\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u5b9e\u9645\u4e2d\u96be\u4ee5\u83b7\u53d6\uff0c\u9700\u8981\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u6570\u636e\u6765\u89e3\u51b3\u6570\u636e\u4e0d\u8db3\u95ee\u9898", "method": "\u4f7f\u7528\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff0c\u6839\u636e\u7528\u6237\u4f4d\u7f6e\u548c\u901f\u5ea6\u4fe1\u606f\u751f\u6210\u9ad8\u4fdd\u771f\u4fe1\u9053\u6837\u672c\uff0c\u7528\u4e8e\u53e0\u52a0\u5bfc\u9891\u4f20\u8f93\u7684\u795e\u7ecf\u63a5\u6536\u673a\u8bad\u7ec3", "result": "\u8be5\u65b9\u6cd5\u751f\u6210\u7684\u4fe1\u9053\u6837\u672c\u8d28\u91cf\u9ad8\uff0c\u663e\u8457\u63d0\u5347\u4e86\u795e\u7ecf\u63a5\u6536\u673a\u5728\u76ee\u6807\u573a\u666f\u4e2d\u7684\u6027\u80fd\uff0c\u4f18\u4e8e\u4f20\u7edf\u6570\u636e\u589e\u5f3a\u548c\u57fa\u4e8eGAN\u7684\u6280\u672f", "conclusion": "\u57fa\u4e8e\u6761\u4ef6\u6269\u6563\u6a21\u578b\u7684\u4fe1\u9053\u751f\u6210\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u95ee\u9898\uff0c\u4e3a\u795e\u7ecf\u63a5\u6536\u673a\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u589e\u5f3a"}}
{"id": "2511.00424", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00424", "abs": "https://arxiv.org/abs/2511.00424", "authors": ["Ashutosh Anshul", "Gumpili Sai Pranav", "Mohammad Zia Ur Rehman", "Nagendra Kumar"], "title": "A Multimodal Framework for Depression Detection during Covid-19 via Harvesting Social Media: A Novel Dataset and Method", "comment": null, "summary": "The recent coronavirus disease (Covid-19) has become a pandemic and has\naffected the entire globe. During the pandemic, we have observed a spike in\ncases related to mental health, such as anxiety, stress, and depression.\nDepression significantly influences most diseases worldwide, making it\ndifficult to detect mental health conditions in people due to unawareness and\nunwillingness to consult a doctor. However, nowadays, people extensively use\nonline social media platforms to express their emotions and thoughts. Hence,\nsocial media platforms are now becoming a large data source that can be\nutilized for detecting depression and mental illness. However, existing\napproaches often overlook data sparsity in tweets and the multimodal aspects of\nsocial media. In this paper, we propose a novel multimodal framework that\ncombines textual, user-specific, and image analysis to detect depression among\nsocial media users. To provide enough context about the user's emotional state,\nwe propose (i) an extrinsic feature by harnessing the URLs present in tweets\nand (ii) extracting textual content present in images posted in tweets. We also\nextract five sets of features belonging to different modalities to describe a\nuser. Additionally, we introduce a Deep Learning model, the Visual Neural\nNetwork (VNN), to generate embeddings of user-posted images, which are used to\ncreate the visual feature vector for prediction. We contribute a curated\nCovid-19 dataset of depressed and non-depressed users for research purposes and\ndemonstrate the effectiveness of our model in detecting depression during the\nCovid-19 outbreak. Our model outperforms existing state-of-the-art methods over\na benchmark dataset by 2%-8% and produces promising results on the Covid-19\ndataset. Our analysis highlights the impact of each modality and provides\nvaluable insights into users' mental and emotional states.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u6846\u67b6\uff0c\u7ed3\u5408\u6587\u672c\u3001\u7528\u6237\u7279\u5b9a\u4fe1\u606f\u548c\u56fe\u50cf\u5206\u6790\u6765\u68c0\u6d4b\u793e\u4ea4\u5a92\u4f53\u7528\u6237\u7684\u6291\u90c1\u75c7\uff0c\u5728COVID-19\u75ab\u60c5\u671f\u95f4\u7279\u522b\u6709\u6548\u3002", "motivation": "COVID-19\u75ab\u60c5\u671f\u95f4\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u6fc0\u589e\uff0c\u4f46\u4eba\u4eec\u5f80\u5f80\u4e0d\u613f\u5c31\u533b\u3002\u793e\u4ea4\u5a92\u4f53\u6210\u4e3a\u8868\u8fbe\u60c5\u7eea\u7684\u91cd\u8981\u5e73\u53f0\uff0c\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u4e86\u63a8\u6587\u6570\u636e\u7a00\u758f\u6027\u548c\u591a\u6a21\u6001\u7279\u6027\u3002", "method": "\u4f7f\u7528\u591a\u6a21\u6001\u6846\u67b6\u6574\u5408\u6587\u672c\u3001\u7528\u6237\u7279\u5b9a\u7279\u5f81\u548c\u56fe\u50cf\u5206\u6790\uff1b\u63d0\u51fa\u5916\u90e8\u7279\u5f81\uff08\u5229\u7528\u63a8\u6587\u4e2d\u7684URL\uff09\u548c\u56fe\u50cf\u6587\u672c\u63d0\u53d6\uff1b\u5f00\u53d1\u89c6\u89c9\u795e\u7ecf\u7f51\u7edc\uff08VNN\uff09\u751f\u6210\u56fe\u50cf\u5d4c\u5165\uff1b\u63d0\u53d6\u4e94\u7ec4\u4e0d\u540c\u6a21\u6001\u7684\u7279\u5f81\u3002", "result": "\u6a21\u578b\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u63d0\u53472%-8%\uff0c\u5728COVID-19\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff1b\u5206\u6790\u4e86\u5404\u6a21\u6001\u7684\u5f71\u54cd\uff0c\u63d0\u4f9b\u4e86\u7528\u6237\u5fc3\u7406\u72b6\u6001\u7684\u6709\u4ef7\u503c\u89c1\u89e3\u3002", "conclusion": "\u591a\u6a21\u6001\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u793e\u4ea4\u5a92\u4f53\u7528\u6237\u7684\u6291\u90c1\u75c7\uff0c\u7279\u522b\u662f\u5728\u75ab\u60c5\u80cc\u666f\u4e0b\uff1b\u8d21\u732e\u4e86COVID-19\u6291\u90c1\u75c7\u6570\u636e\u96c6\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u8d44\u6e90\u3002"}}
{"id": "2511.00906", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.00906", "abs": "https://arxiv.org/abs/2511.00906", "authors": ["Martino Trevisan"], "title": "DPMon: a Differentially-Private Query Engine for Passive Measurements", "comment": null, "summary": "Passive monitoring is a network measurement technique which analyzes the\ntraffic carried by an operational network. It has several applications for\ntraffic engineering, Quality of Experience monitoring and cyber security.\nHowever, it entails the processing of personal information, thus, threatening\nusers' privacy. In this work, we propose DPMon, a tool to run\nprivacy-preserving queries to a dataset of passive network measurements. It\nexploits differential privacy to perturb the output of the query to preserve\nusers' privacy. DPMon can exploit big data infrastructures running Apache Spark\nand operate on different data formats. We show that DPMon allows extracting\nmeaningful insights from the data, while at the same time controlling the\namount of disclosed information.", "AI": {"tldr": "DPMon\u662f\u4e00\u4e2a\u9690\u79c1\u4fdd\u62a4\u5de5\u5177\uff0c\u5229\u7528\u5dee\u5206\u9690\u79c1\u6280\u672f\u5bf9\u88ab\u52a8\u7f51\u7edc\u6d4b\u91cf\u6570\u636e\u8fdb\u884c\u67e5\u8be2\uff0c\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u540c\u65f6\u63d0\u53d6\u6709\u7528\u4fe1\u606f\u3002", "motivation": "\u88ab\u52a8\u7f51\u7edc\u76d1\u63a7\u6280\u672f\u5904\u7406\u4e2a\u4eba\u6570\u636e\u5a01\u80c1\u7528\u6237\u9690\u79c1\uff0c\u9700\u8981\u5728\u7f51\u7edc\u6d4b\u91cf\u5e94\u7528\u4e2d\u5e73\u8861\u6570\u636e\u6548\u7528\u4e0e\u9690\u79c1\u4fdd\u62a4\u3002", "method": "\u5f00\u53d1DPMon\u5de5\u5177\uff0c\u5229\u7528\u5dee\u5206\u9690\u79c1\u673a\u5236\u6270\u52a8\u67e5\u8be2\u8f93\u51fa\uff0c\u652f\u6301Apache Spark\u5927\u6570\u636e\u57fa\u7840\u8bbe\u65bd\u548c\u591a\u79cd\u6570\u636e\u683c\u5f0f\u3002", "result": "DPMon\u80fd\u591f\u4ece\u6570\u636e\u4e2d\u63d0\u53d6\u6709\u610f\u4e49\u7684\u89c1\u89e3\uff0c\u540c\u65f6\u63a7\u5236\u4fe1\u606f\u6cc4\u9732\u91cf\u3002", "conclusion": "DPMon\u6210\u529f\u5b9e\u73b0\u4e86\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u524d\u63d0\u4e0b\u8fdb\u884c\u7f51\u7edc\u6d4b\u91cf\u6570\u636e\u5206\u6790\u7684\u76ee\u6807\u3002"}}
{"id": "2511.01202", "categories": ["cs.IT", "cs.AI", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01202", "abs": "https://arxiv.org/abs/2511.01202", "authors": ["Bo Bai"], "title": "Forget BIT, It is All about TOKEN: Towards Semantic Information Theory for LLMs", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nnumerous real- world applications. While the vast majority of research\nconducted from an experimental perspective is progressing rapidly, it demands\nsubstantial computational power, data, and other resources. Therefore, how to\nopen the black-box of LLMs from a theoretical standpoint has become a critical\nchallenge. This paper takes the theory of rate-distortion function, directed\ninformation, and Granger causality as its starting point to investigate the\ninformation-theoretic principles behind LLMs, leading to the development of\nsemantic information theory for LLMs, where the fundamental unit is token,\nrather than bits that lacks any semantic meaning. By defining the probabilistic\nmodel of LLMs, we discuss structure-agnostic information-theoretic measures,\nsuch as the directed rate- distortion function in pre-training, the directed\nrate-reward function in post-training, and the semantic information flow in\ninference phase. This paper also delves deeply into the theory of token-level\nsemantic embedding and the information-theoretically optimal vectorization\nmethod. Thereafter, we propose a general definition of autoregression LLM,\nwhere the Transformer architecture and its performance such as ELBO,\ngeneralization error bound, memory capacity, and semantic information measures\ncan be derived theoretically. Other architectures, such as Mamba/Mamba2 and\nLLaDA, are also discussed in our framework. Consequently, this paper provides a\ntheoretical framework for understanding LLMs from the perspective of semantic\ninformation theory, which also offers the necessary theoretical tools for\nfurther in-depth research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ece\u4fe1\u606f\u8bba\u89d2\u5ea6\u63d0\u51fa\u4e86LLMs\u7684\u8bed\u4e49\u4fe1\u606f\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u57fa\u672c\u5355\u4f4d\u4ece\u65e0\u610f\u4e49\u7684\u6bd4\u7279\u6539\u4e3a\u6709\u8bed\u4e49\u7684token\uff0c\u5b9a\u4e49\u4e86\u9884\u8bad\u7ec3\u3001\u540e\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u7684\u4fe1\u606f\u8bba\u5ea6\u91cf\uff0c\u5e76\u63a8\u5bfc\u4e86Transformer\u7b49\u67b6\u6784\u7684\u7406\u8bba\u6027\u80fd\u3002", "motivation": "\u5f53\u524dLLMs\u7814\u7a76\u5927\u591a\u57fa\u4e8e\u5b9e\u9a8c\u89c6\u89d2\uff0c\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u548c\u6570\u636e\uff0c\u56e0\u6b64\u9700\u8981\u4ece\u7406\u8bba\u89d2\u5ea6\u6253\u5f00LLMs\u7684\u9ed1\u7bb1\uff0c\u7406\u89e3\u5176\u80cc\u540e\u7684\u4fe1\u606f\u8bba\u539f\u7406\u3002", "method": "\u4ee5\u7387\u5931\u771f\u51fd\u6570\u3001\u6709\u5411\u4fe1\u606f\u548c\u683c\u5170\u6770\u56e0\u679c\u7406\u8bba\u4e3a\u57fa\u7840\uff0c\u6784\u5efaLLMs\u7684\u8bed\u4e49\u4fe1\u606f\u7406\u8bba\uff0c\u5b9a\u4e49\u6982\u7387\u6a21\u578b\u548c\u4fe1\u606f\u8bba\u5ea6\u91cf\uff0c\u63a8\u5bfcTransformer\u7b49\u67b6\u6784\u7684\u7406\u8bba\u6027\u80fd\u3002", "result": "\u63d0\u51fa\u4e86\u8bed\u4e49\u4fe1\u606f\u7406\u8bba\u6846\u67b6\uff0c\u5b9a\u4e49\u4e86token\u7ea7\u8bed\u4e49\u5d4c\u5165\u548c\u4fe1\u606f\u8bba\u6700\u4f18\u5411\u91cf\u5316\u65b9\u6cd5\uff0c\u63a8\u5bfc\u4e86ELBO\u3001\u6cdb\u5316\u8bef\u5dee\u754c\u3001\u8bb0\u5fc6\u5bb9\u91cf\u7b49\u6027\u80fd\u6307\u6807\u3002", "conclusion": "\u4e3a\u7406\u89e3LLMs\u63d0\u4f9b\u4e86\u8bed\u4e49\u4fe1\u606f\u8bba\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u6df1\u5165\u7814\u7a76\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u7406\u8bba\u5de5\u5177\u3002"}}
{"id": "2511.00457", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00457", "abs": "https://arxiv.org/abs/2511.00457", "authors": ["Chunyu Wei", "Wenji Hu", "Xingjia Hao", "Xin Wang", "Yifan Yang", "Yueguo Chen", "Yang Tian", "Yunhai Wang"], "title": "GraphChain: Large Language Models for Large-scale Graph Analysis via Tool Chaining", "comment": null, "summary": "Large Language Models (LLMs) face significant limitations when applied to\nlarge-scale graphs, struggling with context constraints and inflexible\nreasoning. We present GraphChain, a framework that enables LLMs to analyze\ncomplex graphs through dynamic sequences of specialized tools, mimicking human\nexploratory intelligence. Our approach introduces two key innovations: (1)\nProgressive Graph Distillation, a reinforcement learning mechanism that\ngenerates optimized tool sequences balancing task relevance with information\ncompression, and (2) Structure-aware Test-Time Adaptation, which efficiently\ntailors tool selection strategies to diverse graph topologies using spectral\nproperties and lightweight adapters without costly retraining. Experiments show\nGraphChain significantly outperforms prior methods, enabling scalable and\nadaptive LLM-driven graph analysis.", "AI": {"tldr": "GraphChain\u662f\u4e00\u4e2a\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5206\u6790\u590d\u6742\u56fe\u6570\u636e\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u5de5\u5177\u5e8f\u5217\u6a21\u62df\u4eba\u7c7b\u63a2\u7d22\u667a\u80fd\uff0c\u89e3\u51b3\u4e86LLM\u5728\u5927\u89c4\u6a21\u56fe\u5206\u6790\u4e2d\u7684\u4e0a\u4e0b\u6587\u9650\u5236\u548c\u63a8\u7406\u4e0d\u7075\u6d3b\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u5927\u89c4\u6a21\u56fe\u6570\u636e\u65f6\u9762\u4e34\u4e0a\u4e0b\u6587\u7ea6\u675f\u548c\u63a8\u7406\u4e0d\u7075\u6d3b\u7684\u9650\u5236\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u590d\u6742\u56fe\u7ed3\u6784\u5206\u6790\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u6e10\u8fdb\u56fe\u84b8\u998f\uff08\u5f3a\u5316\u5b66\u4e60\u673a\u5236\u751f\u6210\u4f18\u5316\u5de5\u5177\u5e8f\u5217\uff09\u548c\u7ed3\u6784\u611f\u77e5\u6d4b\u8bd5\u65f6\u9002\u5e94\uff08\u5229\u7528\u8c31\u5c5e\u6027\u548c\u8f7b\u91cf\u9002\u914d\u5668\u8c03\u6574\u5de5\u5177\u9009\u62e9\u7b56\u7565\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660eGraphChain\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u548c\u81ea\u9002\u5e94\u7684LLM\u9a71\u52a8\u56fe\u5206\u6790\u3002", "conclusion": "GraphChain\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u5de5\u5177\u5e8f\u5217\u548c\u7ed3\u6784\u611f\u77e5\u9002\u5e94\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u56fe\u5206\u6790\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u56fe\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.00955", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.00955", "abs": "https://arxiv.org/abs/2511.00955", "authors": ["Abouaomar", "Badr Ben Elallid", "Nabil Benamar"], "title": "Optimizing Energy and Latency in 6G Smart Cities with Edge CyberTwins", "comment": null, "summary": "The proliferation of IoT devices in smart cities challenges 6G networks with\nconflicting energy-latency requirements across heterogeneous slices. Existing\napproaches struggle with the energy-latency trade-off, particularly for massive\nscale deployments exceeding 50,000 devices km. This paper proposes an\nedge-aware CyberTwin framework integrating hybrid federated learning for\nenergy-latency co-optimization in 6G network slicing. Our approach combines\ncentralized Artificial Intelligence scheduling for latency-sensitive slices\nwith distributed federated learning for non-critical slices, enhanced by\ncompressive sensing-based digital twins and renewable energy-aware resource\nallocation. The hybrid scheduler leverages a three-tier architecture with\nPhysical Unclonable Function (PUF) based security attestation achieving 99.7%\nattack detection accuracy. Comprehensive simulations demonstrate 52% energy\nreduction for non-real-time slices compared to Diffusion-Reinforcement Learning\nbaselines while maintaining 0.9ms latency for URLLC applications with 99.1% SLA\ncompliance. The framework scales to 50,000 devices km with CPU overhead below\n25%, validated through NS-3 hybrid simulations across realistic smart city\nscenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8fb9\u7f18\u611f\u77e5\u7684CyberTwin\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u8054\u90a6\u5b66\u4e60\u4f18\u53166G\u7f51\u7edc\u5207\u7247\u4e2d\u7684\u80fd\u8017\u4e0e\u5ef6\u8fdf\u6743\u8861\uff0c\u652f\u6301\u5927\u89c4\u6a21\u7269\u8054\u7f51\u90e8\u7f72\u3002", "motivation": "\u667a\u80fd\u57ce\u5e02\u4e2d\u7269\u8054\u7f51\u8bbe\u5907\u6fc0\u589e\u7ed96G\u7f51\u7edc\u5e26\u6765\u4e86\u80fd\u8017\u4e0e\u5ef6\u8fdf\u7684\u51b2\u7a81\u9700\u6c42\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u8d85\u8fc750,000\u8bbe\u5907/\u5e73\u65b9\u516c\u91cc\u7684\u5927\u89c4\u6a21\u90e8\u7f72\u4e2d\u6709\u6548\u5e73\u8861\u8fd9\u4e00\u6743\u8861\u3002", "method": "\u91c7\u7528\u6df7\u5408\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u5408\u96c6\u4e2d\u5f0fAI\u8c03\u5ea6\u5904\u7406\u5ef6\u8fdf\u654f\u611f\u5207\u7247\uff0c\u5206\u5e03\u5f0f\u8054\u90a6\u5b66\u4e60\u5904\u7406\u975e\u5173\u952e\u5207\u7247\uff0c\u589e\u5f3a\u538b\u7f29\u611f\u77e5\u6570\u5b57\u5b6a\u751f\u548c\u53ef\u518d\u751f\u80fd\u6e90\u611f\u77e5\u8d44\u6e90\u5206\u914d\uff0c\u4f7f\u7528PUF\u5b89\u5168\u8ba4\u8bc1\u7684\u4e09\u5c42\u67b6\u6784\u3002", "result": "\u76f8\u6bd4Diffusion-Reinforcement Learning\u57fa\u7ebf\uff0c\u975e\u5b9e\u65f6\u5207\u7247\u80fd\u8017\u964d\u4f4e52%\uff0cURLLC\u5e94\u7528\u4fdd\u63010.9ms\u5ef6\u8fdf\u548c99.1% SLA\u5408\u89c4\u6027\uff0c\u652f\u630150,000\u8bbe\u5907/\u5e73\u65b9\u516c\u91cc\u89c4\u6a21\uff0cCPU\u5f00\u9500\u4f4e\u4e8e25%\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e866G\u7f51\u7edc\u5207\u7247\u4e2d\u7684\u80fd\u8017-\u5ef6\u8fdf\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u667a\u80fd\u57ce\u5e02\u7269\u8054\u7f51\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01280", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01280", "abs": "https://arxiv.org/abs/2511.01280", "authors": ["Dganit Hanania", "Eitan Yaakobi"], "title": "Error-Correcting Codes for Labeled DNA Sequences", "comment": null, "summary": "Labeling of DNA molecules is a fundamental technique for DNA visualization\nand analysis. This process was mathematically modeled in [1], where the\nreceived sequence indicates the positions of the used labels. In this work, we\ndevelop error correcting codes for labeled DNA sequences, establishing bounds\nand constructing explicit systematic encoders for single substitution,\ninsertion, and deletion errors. We focus on two cases: (1) using the complete\nset of length-two labels and (2) using the minimal set of length-two labels\nthat ensures the recovery of DNA sequences from their labeling for 'almost' all\nDNA sequences.", "AI": {"tldr": "\u5f00\u53d1\u7528\u4e8e\u6807\u8bb0DNA\u5e8f\u5217\u7684\u7ea0\u9519\u7801\uff0c\u9488\u5bf9\u5355\u66ff\u6362\u3001\u63d2\u5165\u548c\u5220\u9664\u9519\u8bef\u5efa\u7acb\u8fb9\u754c\u5e76\u6784\u5efa\u663e\u5f0f\u7cfb\u7edf\u7f16\u7801\u5668\u3002", "motivation": "DNA\u5206\u5b50\u6807\u8bb0\u662fDNA\u53ef\u89c6\u5316\u548c\u5206\u6790\u7684\u57fa\u672c\u6280\u672f\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u7ea0\u6b63\u6807\u8bb0\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u9519\u8bef\u7684\u7f16\u7801\u65b9\u6848\u3002", "method": "\u5efa\u7acb\u6570\u5b66\u6a21\u578b\uff0c\u5f00\u53d1\u7cfb\u7edf\u7f16\u7801\u5668\uff0c\u9488\u5bf9\u4e24\u79cd\u60c5\u51b5\u8fdb\u884c\u7814\u7a76\uff1a(1)\u4f7f\u7528\u5b8c\u6574\u7684\u957f\u5ea6\u4e8c\u6807\u7b7e\u96c6\uff1b(2)\u4f7f\u7528\u786e\u4fdd\u4ece\u6807\u8bb0\u4e2d\u6062\u590dDNA\u5e8f\u5217\u7684\u6700\u5c0f\u957f\u5ea6\u4e8c\u6807\u7b7e\u96c6\u3002", "result": "\u5efa\u7acb\u4e86\u5355\u66ff\u6362\u3001\u63d2\u5165\u548c\u5220\u9664\u9519\u8bef\u7684\u7ea0\u9519\u7801\u8fb9\u754c\uff0c\u5e76\u6784\u5efa\u4e86\u663e\u5f0f\u7cfb\u7edf\u7f16\u7801\u5668\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u9002\u7528\u4e8e\u6807\u8bb0DNA\u5e8f\u5217\u7684\u7ea0\u9519\u7f16\u7801\u65b9\u6848\uff0c\u4e3aDNA\u5e8f\u5217\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u9519\u8bef\u6821\u6b63\u65b9\u6cd5\u3002"}}
{"id": "2511.00509", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.00509", "abs": "https://arxiv.org/abs/2511.00509", "authors": ["Yifan Xia", "Guorui Chen", "Wenqian Yu", "Zhijiang Li", "Philip Torr", "Jindong Gu"], "title": "Reimagining Safety Alignment with An Image", "comment": null, "summary": "Large language models (LLMs) excel in diverse applications but face dual\nchallenges: generating harmful content under jailbreak attacks and over-refusal\nof benign queries due to rigid safety mechanisms. These issues are further\ncomplicated by the need to accommodate different value systems and precisely\nalign with given safety preferences. Moreover, traditional methods like SFT and\nRLHF lack this capability due to their costly parameter tuning requirements and\ninability to support multiple value systems within a single model. These\nproblems are more obvious in multimodal large language models (MLLMs),\nespecially in terms of heightened over-refusal in cross-modal tasks and new\nsecurity risks arising from expanded attack surfaces. We propose Magic Image,\nan optimization-driven visual prompt framework that enhances security while\nreducing over-refusal. By optimizing image prompts using harmful/benign\nsamples, our method enables a single model to adapt to different value systems\nand better align with given safety preferences without parameter updates.\nExperiments demonstrate improved safety-effectiveness balance across diverse\ndatasets while preserving model performance, offering a practical solution for\ndeployable MLLM safety alignment.", "AI": {"tldr": "\u63d0\u51fa\u4e86Magic Image\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u89c6\u89c9\u63d0\u793a\u6765\u589e\u5f3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u51cf\u5c11\u8fc7\u5ea6\u62d2\u7edd\uff0c\u5e76\u652f\u6301\u5355\u4e00\u6a21\u578b\u9002\u5e94\u4e0d\u540c\u4ef7\u503c\u4f53\u7cfb\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b89\u5168\u5bf9\u9f50\u4e2d\u7684\u53cc\u91cd\u6311\u6218\uff1a\u5728\u8d8a\u72f1\u653b\u51fb\u4e0b\u751f\u6210\u6709\u5bb3\u5185\u5bb9\uff0c\u4ee5\u53ca\u7531\u4e8e\u50f5\u5316\u7684\u5b89\u5168\u673a\u5236\u5bfc\u81f4\u5bf9\u826f\u6027\u67e5\u8be2\u7684\u8fc7\u5ea6\u62d2\u7edd\u3002\u8fd9\u4e9b\u95ee\u9898\u5728\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u66f4\u4e3a\u7a81\u51fa\u3002", "method": "\u4f7f\u7528\u4f18\u5316\u9a71\u52a8\u7684\u89c6\u89c9\u63d0\u793a\u6846\u67b6\uff0c\u901a\u8fc7\u6709\u5bb3/\u826f\u6027\u6837\u672c\u4f18\u5316\u56fe\u50cf\u63d0\u793a\uff0c\u4f7f\u5355\u4e00\u6a21\u578b\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u5373\u53ef\u9002\u5e94\u4e0d\u540c\u4ef7\u503c\u4f53\u7cfb\u5e76\u66f4\u597d\u5730\u4e0e\u7ed9\u5b9a\u5b89\u5168\u504f\u597d\u5bf9\u9f50\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u6539\u5584\u4e86\u5b89\u5168\u6027\u4e0e\u6709\u6548\u6027\u7684\u5e73\u8861\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "Magic Image\u4e3a\u53ef\u90e8\u7f72\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u5bf9\u9f50\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00965", "categories": ["cs.NI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2511.00965", "abs": "https://arxiv.org/abs/2511.00965", "authors": ["Jiacheng Xu", "Xiongfei Zhao", "Hou-Wan Long", "Cheong Se-Hang", "Yain-Whar Si"], "title": "Detecting Coverage Holes in Wireless Sensor Networks Using Connected Component Labeling and Force-Directed Algorithms", "comment": null, "summary": "Contour detection in Wireless Sensor Networks (WSNs) is crucial for tasks\nlike energy saving and network optimization, especially in security and\nsurveillance applications. Coverage holes, where data transmission is not\nachievable, are a significant issue caused by factors such as energy depletion\nand physical damage. Traditional methods for detecting these holes often suffer\nfrom inaccuracy, low processing speed, and high energy consumption, relying\nheavily on physical information like node coordinates and sensing range. To\naddress these challenges, we propose a novel, coordinate-free coverage hole\ndetection method using Connected Component Labeling (CCL) and Force-Directed\n(FD) algorithms, termed FD-CCL. This method does not require node coordinates\nor sensing range information. We also investigate Suzuki's Contour Tracing (CT)\nalgorithm and compare its performance with CCL on various FD graphs. Our\nexperiments demonstrate the effectiveness of FD-CCL in terms of processing time\nand accuracy. Simulation results confirm the superiority of FD-CCL in detecting\nand locating coverage holes in WSNs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fde\u901a\u7ec4\u4ef6\u6807\u8bb0\u548c\u529b\u5bfc\u5411\u7b97\u6cd5\u7684\u65e0\u5750\u6807\u8986\u76d6\u7a7a\u6d1e\u68c0\u6d4b\u65b9\u6cd5FD-CCL\uff0c\u65e0\u9700\u8282\u70b9\u5750\u6807\u6216\u611f\u77e5\u8303\u56f4\u4fe1\u606f\uff0c\u5728\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u4e2d\u6709\u6548\u68c0\u6d4b\u8986\u76d6\u7a7a\u6d1e\u3002", "motivation": "\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u4e2d\u7684\u8986\u76d6\u7a7a\u6d1e\u68c0\u6d4b\u5bf9\u8282\u80fd\u548c\u7f51\u7edc\u4f18\u5316\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u7269\u7406\u4fe1\u606f\u4e14\u5b58\u5728\u7cbe\u5ea6\u4f4e\u3001\u5904\u7406\u901f\u5ea6\u6162\u3001\u80fd\u8017\u9ad8\u7b49\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u8fde\u901a\u7ec4\u4ef6\u6807\u8bb0\u548c\u529b\u5bfc\u5411\u7b97\u6cd5\uff0c\u7ed3\u5408Suzuki\u8f6e\u5ed3\u8ffd\u8e2a\u7b97\u6cd5\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5f00\u53d1\u4e86\u65e0\u9700\u5750\u6807\u4fe1\u606f\u7684FD-CCL\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eFD-CCL\u5728\u5904\u7406\u65f6\u95f4\u548c\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4eff\u771f\u7ed3\u679c\u786e\u8ba4\u5176\u5728\u68c0\u6d4b\u548c\u5b9a\u4f4d\u8986\u76d6\u7a7a\u6d1e\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "FD-CCL\u65b9\u6cd5\u4e3a\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u51c6\u786e\u7684\u65e0\u5750\u6807\u8986\u76d6\u7a7a\u6d1e\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01306", "categories": ["cs.IT", "math.IT", "11T71", "E.4"], "pdf": "https://arxiv.org/pdf/2511.01306", "abs": "https://arxiv.org/abs/2511.01306", "authors": ["Peipei Zheng", "Dong He", "Qunying Liao"], "title": "On the Ding and Helleseth's 9th open problem about optimal ternary cyclic codes", "comment": "20 pages", "summary": "The cyclic code is a subclass of linear codes and has applications in\nconsumer electronics, data storage systems and communication systems as they\nhave efficient encoding and decoding algorithms. In 2013, Ding, et al.\npresented nine open problems about optimal ternary cyclic codes. Till now, the\n1st, 2nd and 6th problems were completely solved, and the 3rd, 7th, 8th and 9th\nproblems were partially solved. In this manuscript, we focus on the 9th\nproblem. By determining the root set of some special polynomials over finite\nfields, we give an incomplete answer for the 9th problem, and then we construct\ntwo classes of optimal ternary cyclic codes with respect to the Sphere Packing\nBound basing on some special polynomials over finite fields", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6700\u4f18\u4e09\u5143\u5faa\u73af\u7801\u7684\u7b2c9\u4e2a\u5f00\u653e\u95ee\u9898\uff0c\u901a\u8fc7\u786e\u5b9a\u6709\u9650\u57df\u4e0a\u7279\u6b8a\u591a\u9879\u5f0f\u7684\u6839\u96c6\uff0c\u7ed9\u51fa\u4e86\u8be5\u95ee\u9898\u7684\u90e8\u5206\u89e3\u7b54\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u591a\u9879\u5f0f\u6784\u9020\u4e86\u4e24\u7c7b\u6ee1\u8db3\u7403\u586b\u5145\u754c\u7684\u6700\u4f18\u4e09\u5143\u5faa\u73af\u7801\u3002", "motivation": "\u5faa\u73af\u7801\u662f\u7ebf\u6027\u7801\u7684\u5b50\u7c7b\uff0c\u5728\u6d88\u8d39\u7535\u5b50\u3001\u6570\u636e\u5b58\u50a8\u548c\u901a\u4fe1\u7cfb\u7edf\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\uff0c\u56e0\u4e3a\u5176\u5177\u6709\u9ad8\u6548\u7684\u7f16\u7801\u548c\u89e3\u7801\u7b97\u6cd5\u30022013\u5e74Ding\u7b49\u4eba\u63d0\u51fa\u4e86\u5173\u4e8e\u6700\u4f18\u4e09\u5143\u5faa\u73af\u7801\u7684\u4e5d\u4e2a\u5f00\u653e\u95ee\u9898\uff0c\u76ee\u524d\u7b2c9\u4e2a\u95ee\u9898\u5c1a\u672a\u5b8c\u5168\u89e3\u51b3\u3002", "method": "\u901a\u8fc7\u786e\u5b9a\u6709\u9650\u57df\u4e0a\u7279\u6b8a\u591a\u9879\u5f0f\u7684\u6839\u96c6\uff0c\u5206\u6790\u8fd9\u4e9b\u591a\u9879\u5f0f\u7684\u6027\u8d28\uff0c\u5e76\u57fa\u4e8e\u7403\u586b\u5145\u754c\u6784\u9020\u6700\u4f18\u4e09\u5143\u5faa\u73af\u7801\u3002", "result": "\u7ed9\u51fa\u4e86\u7b2c9\u4e2a\u5f00\u653e\u95ee\u9898\u7684\u90e8\u5206\u89e3\u7b54\uff0c\u5e76\u6210\u529f\u6784\u9020\u4e86\u4e24\u7c7b\u6ee1\u8db3\u7403\u586b\u5145\u754c\u7684\u6700\u4f18\u4e09\u5143\u5faa\u73af\u7801\u3002", "conclusion": "\u672c\u6587\u5bf9\u6700\u4f18\u4e09\u5143\u5faa\u73af\u7801\u7684\u7b2c9\u4e2a\u5f00\u653e\u95ee\u9898\u505a\u51fa\u4e86\u91cd\u8981\u8d21\u732e\uff0c\u63d0\u4f9b\u4e86\u90e8\u5206\u89e3\u7b54\u5e76\u6784\u9020\u4e86\u65b0\u7684\u6700\u4f18\u7801\u7c7b\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.00547", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00547", "abs": "https://arxiv.org/abs/2511.00547", "authors": ["Alain Riou"], "title": "Efficient Generation of Binary Magic Squares", "comment": null, "summary": "We propose a simple algorithm for generating Binary Magic Squares (BMS),\ni.e., square binary matrices where the sum of all rows and all columns are\nequal. We show by induction that our algorithm always returns valid BMS with\noptimal theoretical complexity. We then extend our study to non-square Binary\nMagic Squares, formalize conditions on the sum of rows and columns for these\nBMS to exist, and show that a slight variant of our first algorithm can\ngenerate provably generate them. Finally, we publicly release two\nimplementations of our algorithm as Python packages, including one that can\ngenerate several BMS in parallel using GPU acceleration.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u6210\u4e8c\u8fdb\u5236\u5e7b\u65b9(BMS)\u7684\u7b80\u5355\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u5f52\u7eb3\u6cd5\u8bc1\u660e\u603b\u80fd\u751f\u6210\u6709\u6548\u7684BMS\uff0c\u5e76\u5177\u6709\u6700\u4f18\u7406\u8bba\u590d\u6742\u5ea6\u3002\u7814\u7a76\u8fd8\u6269\u5c55\u5230\u975e\u65b9\u5f62BMS\uff0c\u5f62\u5f0f\u5316\u4e86\u5b58\u5728\u6761\u4ef6\uff0c\u5e76\u5c55\u793a\u4e86\u7b97\u6cd5\u53d8\u4f53\u53ef\u4ee5\u751f\u6210\u5b83\u4eec\u3002", "motivation": "\u5f00\u53d1\u9ad8\u6548\u7684\u4e8c\u8fdb\u5236\u5e7b\u65b9\u751f\u6210\u7b97\u6cd5\uff0c\u89e3\u51b3\u65b9\u5f62\u548c\u975e\u65b9\u5f62\u4e8c\u8fdb\u5236\u77e9\u9635\u4e2d\u884c\u548c\u5217\u548c\u76f8\u7b49\u7684\u751f\u6210\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u5f52\u7eb3\u6cd5\u8bbe\u8ba1\u7b80\u5355\u7b97\u6cd5\uff0c\u8bc1\u660e\u5176\u6709\u6548\u6027\uff0c\u5e76\u5f00\u53d1\u7b97\u6cd5\u53d8\u4f53\u5904\u7406\u975e\u65b9\u5f62\u60c5\u51b5\u3002", "result": "\u7b97\u6cd5\u80fd\u751f\u6210\u6709\u6548\u7684BMS\uff0c\u5177\u6709\u6700\u4f18\u590d\u6742\u5ea6\uff0c\u5e76\u80fd\u6269\u5c55\u5230\u975e\u65b9\u5f62\u77e9\u9635\u3002\u53d1\u5e03\u4e86Python\u5b9e\u73b0\uff0c\u5305\u62ecGPU\u52a0\u901f\u7248\u672c\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u9ad8\u6548\u751f\u6210\u65b9\u5f62\u548c\u975e\u65b9\u5f62\u4e8c\u8fdb\u5236\u5e7b\u65b9\uff0c\u5e76\u901a\u8fc7\u516c\u5f00\u5b9e\u73b0\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2511.01070", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.01070", "abs": "https://arxiv.org/abs/2511.01070", "authors": ["Dinh-Hieu Tran", "Thai Duong Nguyen", "Thanh-Dao Nguyen", "Ngoc-Tan Nguyen", "Van Nhan Vo", "Hung Tran", "Mouhamad Chehaitly", "Yan Kyaw Tun", "Cedomir Stefanovic", "Tu Ho Dac", "Eva Lagunas", "Symeon Chatzinotas", "Nguyen Van Huynh"], "title": "Quantum Reinforcement Learning for 6G and Beyond Wireless Networks", "comment": null, "summary": "While 5G is being deployed worldwide, 6G is receiving increasing attention\nfrom researchers to meet the growing demand for higher data rates, lower\nlatency, higher density, and seamless communications worldwide. To meet the\nstringent requirements of 6G wireless communications networks, AI-integrated\ncommunications have become an indispensable part of supporting 6G systems with\nintelligence, automation, and big data training capabilities. However,\ntraditional artificial intelligence (AI) systems are difficult to meet the\nstringent latency and high throughput requirements of 6G with limited\nresources. In this article, we summarize, analyze, discuss the potential, and\nbenefits of Quantum Reinforcement Learning (QRL) in 6G. As an example, we show\nthe superiority of QRL in dynamic spectrum access compared to the conventional\nDeep Reinforcement Learning (DRL) approach. In addition, we provide an overview\nof what DRL has accomplished in 6G and its challenges and limitations. From\nthere, we introduce QRL and potential research directions that should continue\nto be of interest in 6G. To the best of our knowledge, this is the first review\nand vision article on QRL for 6G wireless communication networks.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u91cf\u5b50\u5f3a\u5316\u5b66\u4e60(QRL)\u57286G\u65e0\u7ebf\u901a\u4fe1\u7f51\u7edc\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u901a\u8fc7\u4e0e\u4f20\u7edf\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60(DRL)\u5bf9\u6bd4\uff0c\u5c55\u793a\u4e86QRL\u5728\u52a8\u6001\u9891\u8c31\u63a5\u5165\u7b49\u573a\u666f\u4e2d\u7684\u4f18\u52bf\u3002", "motivation": "\u968f\u77406G\u7814\u7a76\u7684\u63a8\u8fdb\uff0c\u4f20\u7edfAI\u7cfb\u7edf\u96be\u4ee5\u6ee1\u8db36G\u5bf9\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u541e\u5410\u91cf\u7684\u4e25\u683c\u8981\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u91cf\u5b50\u5f3a\u5316\u5b66\u4e60\u7b49\u65b0\u6280\u672f\u6765\u63d0\u5347\u901a\u4fe1\u7f51\u7edc\u7684\u667a\u80fd\u5316\u6c34\u5e73\u3002", "method": "\u901a\u8fc7\u603b\u7ed3\u3001\u5206\u6790\u548c\u8ba8\u8bba\u91cf\u5b50\u5f3a\u5316\u5b66\u4e60\u57286G\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u4ee5\u52a8\u6001\u9891\u8c31\u63a5\u5165\u4e3a\u4f8b\u6bd4\u8f83QRL\u4e0e\u4f20\u7edfDRL\u65b9\u6cd5\u7684\u6027\u80fd\u5dee\u5f02\u3002", "result": "\u7814\u7a76\u8868\u660eQRL\u57286G\u901a\u4fe1\u7f51\u7edc\u4e2d\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u52a8\u6001\u9891\u8c31\u63a5\u5165\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u4e8e\u4f20\u7edfDRL\u65b9\u6cd5\u3002", "conclusion": "\u91cf\u5b50\u5f3a\u5316\u5b66\u4e60\u662f6G\u65e0\u7ebf\u901a\u4fe1\u7f51\u7edc\u7684\u91cd\u8981\u7814\u7a76\u65b9\u5411\uff0c\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u7efc\u8ff0\u4e86QRL\u57286G\u4e2d\u7684\u5e94\u7528\u524d\u666f\u548c\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.01309", "categories": ["cs.IT", "math.IT", "11T71", "E.4"], "pdf": "https://arxiv.org/pdf/2511.01309", "abs": "https://arxiv.org/abs/2511.01309", "authors": ["Qunying Liao", "Zhaohui Zhang", "Peipei Zheng"], "title": "Several classes of three-weight or four-weight linear codes", "comment": "15pages", "summary": "In this manuscript, we construct a class of projective three- weight linear\ncodes and two classes of projective four-weight linear codes over F2 from the\ndefining sets construction, and determine their weight distributions by using\nadditive characters. Especially, the projective three-weight linear code and\none class of projective four-weight linear codes (Theorem 4.1) can be applied\nin secret sharing schemes.", "AI": {"tldr": "\u6784\u5efa\u4e86\u6709\u9650\u57dfF2\u4e0a\u7684\u6295\u5f71\u4e09\u6743\u91cd\u7ebf\u6027\u7801\u548c\u4e24\u7c7b\u6295\u5f71\u56db\u6743\u91cd\u7ebf\u6027\u7801\uff0c\u5e76\u786e\u5b9a\u4e86\u5b83\u4eec\u7684\u6743\u91cd\u5206\u5e03\u3002", "motivation": "\u7814\u7a76\u5177\u6709\u7279\u5b9a\u6743\u91cd\u5206\u5e03\u7684\u7ebf\u6027\u7801\uff0c\u7279\u522b\u662f\u53ef\u7528\u4e8e\u79d8\u5bc6\u5171\u4eab\u65b9\u6848\u7684\u7801\u7c7b\u3002", "method": "\u4f7f\u7528\u5b9a\u4e49\u96c6\u6784\u9020\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a0\u6cd5\u7279\u5f81\u786e\u5b9a\u6743\u91cd\u5206\u5e03\u3002", "result": "\u6210\u529f\u6784\u9020\u4e86\u6295\u5f71\u4e09\u6743\u91cd\u7ebf\u6027\u7801\u548c\u4e24\u7c7b\u6295\u5f71\u56db\u6743\u91cd\u7ebf\u6027\u7801\uff0c\u5e76\u786e\u5b9a\u4e86\u5b83\u4eec\u7684\u6743\u91cd\u5206\u5e03\u3002", "conclusion": "\u6240\u6784\u9020\u7684\u6295\u5f71\u4e09\u6743\u91cd\u7ebf\u6027\u7801\u548c\u4e00\u7c7b\u6295\u5f71\u56db\u6743\u91cd\u7ebf\u6027\u7801\u53ef\u5e94\u7528\u4e8e\u79d8\u5bc6\u5171\u4eab\u65b9\u6848\u3002"}}
{"id": "2511.00551", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00551", "abs": "https://arxiv.org/abs/2511.00551", "authors": ["Qiang Li", "Ningjing Zeng", "Lina Yu"], "title": "Single-agent Reinforcement Learning Model for Regional Adaptive Traffic Signal Control", "comment": null, "summary": "Several studies have employed reinforcement learning (RL) to address the\nchallenges of regional adaptive traffic signal control (ATSC) and achieved\npromising results. In this field, existing research predominantly adopts\nmulti-agent frameworks. However, the adoption of multi-agent frameworks\npresents challenges for scalability. Instead, the Traffic signal control (TSC)\nproblem necessitates a single-agent framework. TSC inherently relies on\ncentralized management by a single control center, which can monitor traffic\nconditions across all roads in the study area and coordinate the control of all\nintersections. This work proposes a single-agent RL-based regional ATSC model\ncompatible with probe vehicle technology. Key components of the RL design\ninclude state, action, and reward function definitions. To facilitate learning\nand manage congestion, both state and reward functions are defined based on\nqueue length, with action designed to regulate queue dynamics. The queue length\ndefinition used in this study differs slightly from conventional definitions\nbut is closely correlated with congestion states. More importantly, it allows\nfor reliable estimation using link travel time data from probe vehicles. With\nprobe vehicle data already covering most urban roads, this feature enhances the\nproposed method's potential for widespread deployment. The method was\ncomprehensively evaluated using the SUMO simulation platform. Experimental\nresults demonstrate that the proposed model effectively mitigates large-scale\nregional congestion levels via coordinated multi-intersection control.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u533a\u57df\u81ea\u9002\u5e94\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u6a21\u578b\uff0c\u517c\u5bb9\u63a2\u9488\u8f66\u8f86\u6280\u672f\uff0c\u901a\u8fc7\u961f\u5217\u957f\u5ea6\u5b9a\u4e49\u72b6\u6001\u548c\u5956\u52b1\u51fd\u6570\uff0c\u5728SUMO\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u80fd\u6709\u6548\u7f13\u89e3\u5927\u89c4\u6a21\u533a\u57df\u62e5\u5835\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u4f46\u5b58\u5728\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u672c\u8d28\u4e0a\u9700\u8981\u96c6\u4e2d\u5f0f\u7ba1\u7406\uff0c\u7531\u5355\u4e00\u63a7\u5236\u4e2d\u5fc3\u76d1\u63a7\u6240\u6709\u9053\u8def\u5e76\u534f\u8c03\u6240\u6709\u4ea4\u53c9\u53e3\u63a7\u5236\u3002", "method": "\u8bbe\u8ba1\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u57fa\u4e8e\u961f\u5217\u957f\u5ea6\u5b9a\u4e49\u72b6\u6001\u548c\u5956\u52b1\u51fd\u6570\uff0c\u52a8\u4f5c\u8bbe\u8ba1\u7528\u4e8e\u8c03\u8282\u961f\u5217\u52a8\u6001\u3002\u961f\u5217\u957f\u5ea6\u5b9a\u4e49\u4e0e\u4f20\u7edf\u7565\u6709\u4e0d\u540c\u4f46\u4e0e\u62e5\u5835\u72b6\u6001\u5bc6\u5207\u76f8\u5173\uff0c\u4e14\u53ef\u5229\u7528\u63a2\u9488\u8f66\u8f86\u7684\u94fe\u8def\u884c\u7a0b\u65f6\u95f4\u6570\u636e\u8fdb\u884c\u53ef\u9760\u4f30\u8ba1\u3002", "result": "\u5728SUMO\u4eff\u771f\u5e73\u53f0\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u534f\u8c03\u591a\u4ea4\u53c9\u53e3\u63a7\u5236\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u5927\u89c4\u6a21\u533a\u57df\u62e5\u5835\u6c34\u5e73\u3002", "conclusion": "\u63d0\u51fa\u7684\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u517c\u5bb9\u63a2\u9488\u8f66\u8f86\u6280\u672f\uff0c\u5177\u6709\u5e7f\u6cdb\u90e8\u7f72\u6f5c\u529b\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u533a\u57df\u81ea\u9002\u5e94\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u95ee\u9898\u3002"}}
{"id": "2511.01074", "categories": ["cs.NI", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01074", "abs": "https://arxiv.org/abs/2511.01074", "authors": ["Xuchuang Wang", "Matheus Guedes De Andrade", "Guus Avis", "Yu-zhen Janice Chen", "Mohammad Hajiesmaili", "Don Towsley"], "title": "Quantum Network Tomography for General Topology with SPAM Errors", "comment": null, "summary": "The goal of quantum network tomography (QNT) is the characterization of\ninternal quantum channels in a quantum network from external peripheral\noperations. Prior research has primarily focused on star networks featuring\nbit-flip and depolarizing channels, leaving the broader problem -- such as QNT\nfor networks with arbitrary topologies and general Pauli channels -- largely\nunexplored. Moreover, establishing channel identifiability remains a\nsignificant challenge even in simplified quantum star networks.\n  In the first part of this paper, we introduce a novel network tomography\nmethod, termed Mergecast, in quantum networks. We demonstrate that Mergecast,\ntogether with a progressive etching procedure, enables the unique\nidentification of all internal quantum channels in networks characterized by\narbitrary topologies and Pauli channels. As a side contribution, we introduce a\nsubclass of Pauli channels, termed bypassable Pauli channels, and propose a\nmore efficient unicast-based tomography method, called BypassUnicast, for\nnetworks exclusively comprising these channels. In the second part, we extend\nour investigation to a more realistic QNT scenario that incorporates state\npreparation and measurement (SPAM) errors. We rigorously formulate SPAM errors\nin QNT, propose estimation protocols for such errors within QNT, and\nsubsequently adapt our Mergecast approaches to handle networks affected by SPAM\nerrors. Lastly, we conduct NetSquid-based simulations to corroborate the\neffectiveness of our proposed protocols in identifying internal quantum\nchannels and estimating SPAM errors in quantum networks. In particular, we\ndemonstrate that Mergecast maintains good performance under realistic\nconditions, such as photon loss and quantum memory decoherence.", "AI": {"tldr": "\u63d0\u51faMergecast\u65b9\u6cd5\u7528\u4e8e\u91cf\u5b50\u7f51\u7edc\u5c42\u6790\u6210\u50cf\uff0c\u80fd\u591f\u552f\u4e00\u8bc6\u522b\u4efb\u610f\u62d3\u6251\u548c\u6ce1\u5229\u4fe1\u9053\u7f51\u7edc\u4e2d\u7684\u6240\u6709\u5185\u90e8\u91cf\u5b50\u4fe1\u9053\uff0c\u5e76\u6269\u5c55\u5230\u5904\u7406SPAM\u8bef\u5dee\u7684\u73b0\u5b9e\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u7f51\u7edc\u5c42\u6790\u6210\u50cf\u7814\u7a76\u4e3b\u8981\u5c40\u9650\u4e8e\u661f\u578b\u7f51\u7edc\u548c\u7279\u5b9a\u4fe1\u9053\u7c7b\u578b\uff0c\u5bf9\u4e8e\u4efb\u610f\u62d3\u6251\u548c\u4e00\u822c\u6ce1\u5229\u4fe1\u9053\u7684\u7f51\u7edc\u5c42\u6790\u95ee\u9898\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u4fe1\u9053\u53ef\u8bc6\u522b\u6027\u4ecd\u662f\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51faMergecast\u7f51\u7edc\u5c42\u6790\u65b9\u6cd5\u7ed3\u5408\u6e10\u8fdb\u8680\u523b\u8fc7\u7a0b\uff1b\u9488\u5bf9\u53ef\u65c1\u8def\u6ce1\u5229\u4fe1\u9053\u63d0\u51fa\u66f4\u9ad8\u6548\u7684BypassUnicast\u65b9\u6cd5\uff1b\u6269\u5c55\u5904\u7406SPAM\u8bef\u5dee\u7684\u4f30\u8ba1\u534f\u8bae\u548c\u9002\u5e94\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7NetSquid\u4eff\u771f\u9a8c\u8bc1\u4e86\u6240\u63d0\u534f\u8bae\u5728\u8bc6\u522b\u5185\u90e8\u91cf\u5b50\u4fe1\u9053\u548c\u4f30\u8ba1SPAM\u8bef\u5dee\u65b9\u9762\u7684\u6709\u6548\u6027\uff0cMergecast\u5728\u5149\u5b50\u635f\u5931\u548c\u91cf\u5b50\u5b58\u50a8\u5668\u9000\u76f8\u5e72\u7b49\u73b0\u5b9e\u6761\u4ef6\u4e0b\u4ecd\u4fdd\u6301\u826f\u597d\u6027\u80fd\u3002", "conclusion": "Mergecast\u65b9\u6cd5\u80fd\u591f\u89e3\u51b3\u4efb\u610f\u62d3\u6251\u548c\u6ce1\u5229\u4fe1\u9053\u7f51\u7edc\u7684\u5c42\u6790\u95ee\u9898\uff0c\u5e76\u6210\u529f\u6269\u5c55\u5230\u5305\u542bSPAM\u8bef\u5dee\u7684\u73b0\u5b9e\u573a\u666f\uff0c\u4e3a\u91cf\u5b50\u7f51\u7edc\u8868\u5f81\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2511.01414", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01414", "abs": "https://arxiv.org/abs/2511.01414", "authors": ["Angelos Gkekas", "Nikos A. Mitsiou", "Ioannis Souldatos", "George K. Karagiannidis"], "title": "On the Computability of Finding Capacity-Achieving Codes", "comment": null, "summary": "This work studies the problem of constructing capacity-achieving codes from\nan algorithmic perspective. Specifically, we prove that there exists a Turing\nmachine which, given a discrete memoryless channel $p_{Y|X}$, a target rate $R$\nless than the channel capacity $C(p_{Y|X})$, and an error tolerance $\\epsilon >\n0$, outputs a block code $\\mathcal{C}$ achieving a rate at least $R$ and a\nmaximum block error probability below $\\epsilon$. The machine operates in the\ngeneral case where all transition probabilities of $p_{Y|X}$ are computable\nreal numbers, and the parameters $R$ and $\\epsilon$ are rational. The proof\nbuilds on Shannon's Channel Coding Theorem and relies on an exhaustive search\napproach that systematically enumerates all codes of increasing block length\nuntil a valid code is found. This construction is formalized using the theory\nof recursive functions, yielding a $\\mu$-recursive function $\\mathrm{FindCode}\n: \\mathbb{N}^3 \\rightharpoonup \\mathbb{N}$ that takes as input appropriate\nencodings of $p_{Y|X}$, $R$, and $\\epsilon$, and, whenever $R < C(p_{Y|X})$,\noutputs an encoding of a valid code. By Kleene's Normal Form Theorem, which\nestablishes the computational equivalence between Turing machines and\n$\\mu$-recursive functions, we conclude that the problem is solvable by a Turing\nmachine. This result can also be extended to the case where $\\epsilon$ is a\ncomputable real number, while we further discuss an analogous generalization of\nour analysis when $R$ is computable as well. We note that the assumptions that\nthe probabilities of $p_{Y|X}$, as well as $\\epsilon$ and $R$, are computable\nreal numbers cannot be further weakened, since computable reals constitute the\nlargest subset of $\\mathbb{R}$ representable by algorithmic means.", "AI": {"tldr": "\u8bc1\u660e\u4e86\u5b58\u5728\u56fe\u7075\u673a\u80fd\u591f\u6784\u9020\u5bb9\u91cf\u903c\u8fd1\u7801\uff1a\u7ed9\u5b9a\u79bb\u6563\u65e0\u8bb0\u5fc6\u4fe1\u9053\u3001\u76ee\u6807\u901f\u7387\u548c\u8bef\u5dee\u5bb9\u9650\uff0c\u8f93\u51fa\u6ee1\u8db3\u901f\u7387\u548c\u8bef\u7801\u7387\u8981\u6c42\u7684\u7801\u5b57\u3002\u57fa\u4e8e\u9999\u519c\u4fe1\u9053\u7f16\u7801\u5b9a\u7406\uff0c\u91c7\u7528\u7a77\u4e3e\u641c\u7d22\u65b9\u6cd5\uff0c\u5f62\u5f0f\u5316\u4e3a\u03bc\u9012\u5f52\u51fd\u6570\u3002", "motivation": "\u4ece\u7b97\u6cd5\u89d2\u5ea6\u7814\u7a76\u5bb9\u91cf\u903c\u8fd1\u7801\u7684\u6784\u9020\u95ee\u9898\uff0c\u63a2\u8ba8\u5728\u53ef\u8ba1\u7b97\u5b9e\u6570\u6846\u67b6\u4e0b\u662f\u5426\u5b58\u5728\u7b97\u6cd5\u80fd\u81ea\u52a8\u751f\u6210\u6ee1\u8db3\u4fe1\u9053\u5bb9\u91cf\u8981\u6c42\u7684\u7f16\u7801\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u9999\u519c\u4fe1\u9053\u7f16\u7801\u5b9a\u7406\uff0c\u91c7\u7528\u7a77\u4e3e\u641c\u7d22\u65b9\u6cd5\uff1a\u7cfb\u7edf\u679a\u4e3e\u6240\u6709\u9012\u589e\u5757\u957f\u7684\u7801\uff0c\u76f4\u5230\u627e\u5230\u6709\u6548\u7801\u3002\u4f7f\u7528\u9012\u5f52\u51fd\u6570\u7406\u8bba\u5f62\u5f0f\u5316\u6784\u9020\uff0c\u5f97\u5230\u03bc\u9012\u5f52\u51fd\u6570FindCode\u3002", "result": "\u8bc1\u660e\u4e86\u5b58\u5728\u56fe\u7075\u673a\u80fd\u591f\u6784\u9020\u5bb9\u91cf\u903c\u8fd1\u7801\uff0c\u8be5\u673a\u5668\u5728\u4fe1\u9053\u8f6c\u79fb\u6982\u7387\u3001\u76ee\u6807\u901f\u7387\u548c\u8bef\u5dee\u5bb9\u9650\u5747\u4e3a\u53ef\u8ba1\u7b97\u5b9e\u6570\u65f6\u6709\u6548\u5de5\u4f5c\u3002", "conclusion": "\u5bb9\u91cf\u903c\u8fd1\u7801\u7684\u6784\u9020\u95ee\u9898\u53ef\u7531\u56fe\u7075\u673a\u89e3\u51b3\uff0c\u524d\u63d0\u662f\u76f8\u5173\u53c2\u6570\u4e3a\u53ef\u8ba1\u7b97\u5b9e\u6570\uff0c\u8fd9\u662f\u7b97\u6cd5\u53ef\u8868\u793a\u7684\u6700\u5927\u5b9e\u6570\u5b50\u96c6\uff0c\u5047\u8bbe\u65e0\u6cd5\u8fdb\u4e00\u6b65\u5f31\u5316\u3002"}}
{"id": "2511.00609", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00609", "abs": "https://arxiv.org/abs/2511.00609", "authors": ["Shengqi Xu", "Xinpeng Zhou", "Yabo Zhang", "Ming Liu", "Tao Liang", "Tianyu Zhang", "Yalong Bai", "Zuxuan Wu", "Wangmeng Zuo"], "title": "PreferThinker: Reasoning-based Personalized Image Preference Assessment", "comment": null, "summary": "Personalized image preference assessment aims to evaluate an individual\nuser's image preferences by relying only on a small set of reference images as\nprior information. Existing methods mainly focus on general preference\nassessment, training models with large-scale data to tackle well-defined tasks\nsuch as text-image alignment. However, these approaches struggle to handle\npersonalized preference because user-specific data are scarce and not easily\nscalable, and individual tastes are often diverse and complex. To overcome\nthese challenges, we introduce a common preference profile that serves as a\nbridge across users, allowing large-scale user data to be leveraged for\ntraining profile prediction and capturing complex personalized preferences.\nBuilding on this idea, we propose a reasoning-based personalized image\npreference assessment framework that follows a \\textit{predict-then-assess}\nparadigm: it first predicts a user's preference profile from reference images,\nand then provides interpretable, multi-dimensional scores and assessments of\ncandidate images based on the predicted profile. To support this, we first\nconstruct a large-scale Chain-of-Thought (CoT)-style personalized assessment\ndataset annotated with diverse user preference profiles and high-quality\nCoT-style reasoning, enabling explicit supervision of structured reasoning.\nNext, we adopt a two-stage training strategy: a cold-start supervised\nfine-tuning phase to empower the model with structured reasoning capabilities,\nfollowed by reinforcement learning to incentivize the model to explore more\nreasonable assessment paths and enhance generalization. Furthermore, we propose\na similarity-aware prediction reward to encourage better prediction of the\nuser's preference profile, which facilitates more reasonable assessments\nexploration. Extensive experiments demonstrate the superiority of the proposed\nmethod.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u63a8\u7406\u7684\u4e2a\u6027\u5316\u56fe\u50cf\u504f\u597d\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6d4b\u7528\u6237\u504f\u597d\u6863\u6848\u5e76\u636e\u6b64\u8bc4\u4f30\u5019\u9009\u56fe\u50cf\uff0c\u4f7f\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u901a\u7528\u504f\u597d\u8bc4\u4f30\uff0c\u96be\u4ee5\u5904\u7406\u4e2a\u6027\u5316\u504f\u597d\uff0c\u56e0\u4e3a\u7528\u6237\u7279\u5b9a\u6570\u636e\u7a00\u7f3a\u4e14\u4e2a\u4f53\u54c1\u5473\u591a\u6837\u590d\u6742\u3002", "method": "\u91c7\u7528\u9884\u6d4b-\u8bc4\u4f30\u8303\u5f0f\uff1a\u9996\u5148\u4ece\u53c2\u8003\u56fe\u50cf\u9884\u6d4b\u7528\u6237\u504f\u597d\u6863\u6848\uff0c\u7136\u540e\u57fa\u4e8e\u9884\u6d4b\u6863\u6848\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u591a\u7ef4\u5ea6\u8bc4\u5206\uff1b\u4f7f\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff08\u76d1\u7763\u5fae\u8c03+\u5f3a\u5316\u5b66\u4e60\uff09\u548c\u76f8\u4f3c\u6027\u611f\u77e5\u9884\u6d4b\u5956\u52b1\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21CoT\u98ce\u683c\u6570\u636e\u96c6\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4e2a\u6027\u5316\u56fe\u50cf\u504f\u597d\u8bc4\u4f30\u7684\u6311\u6218\u3002"}}
{"id": "2511.01160", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.01160", "abs": "https://arxiv.org/abs/2511.01160", "authors": ["Zhen Wang", "Bin Lin", "Qiang Ye", "Yuguang Fang", "Xiaoling Han"], "title": "Joint Computation Offloading and Resource Allocation for Maritime MEC with Energy Harvesting", "comment": null, "summary": "In this paper, we establish a multi-access edge computing (MEC)-enabled sea\nlane monitoring network (MSLMN) architecture with energy harvesting (EH) to\nsupport dynamic ship tracking, accident forensics, and anti-fouling through\nreal-time maritime traffic scene monitoring. Under this architecture, the\ncomputation offloading and resource allocation are jointly optimized to\nmaximize the long-term average throughput of MSLMN. Due to the dynamic\nenvironment and unavailable future network information, we employ the Lyapunov\noptimization technique to tackle the optimization problem with large state and\naction spaces and formulate a stochastic optimization program subject to queue\nstability and energy consumption constraints. We transform the formulated\nproblem into a deterministic one and decouple the temporal and spatial\nvariables to obtain asymptotically optimal solutions. Under the premise of\nqueue stability, we develop a joint computation offloading and resource\nallocation (JCORA) algorithm to maximize the long-term average throughput by\noptimizing task offloading, subchannel allocation, computing resource\nallocation, and task migration decisions. Simulation results demonstrate the\neffectiveness of the proposed scheme over existing approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u652f\u6301\u80fd\u91cf\u6536\u96c6\u7684\u591a\u63a5\u5165\u8fb9\u7f18\u8ba1\u7b97\u6d77\u9053\u76d1\u6d4b\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u8ba1\u7b97\u5378\u8f7d\u548c\u8d44\u6e90\u5206\u914d\u6765\u6700\u5927\u5316\u957f\u671f\u5e73\u5747\u541e\u5410\u91cf\uff0c\u89e3\u51b3\u4e86\u52a8\u6001\u73af\u5883\u548c\u672a\u6765\u7f51\u7edc\u4fe1\u606f\u4e0d\u53ef\u7528\u7684\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u652f\u6301\u52a8\u6001\u8239\u8236\u8ddf\u8e2a\u3001\u4e8b\u6545\u53d6\u8bc1\u548c\u9632\u6c61\u7b49\u5b9e\u65f6\u6d77\u4e8b\u4ea4\u901a\u573a\u666f\u76d1\u6d4b\u9700\u6c42\uff0c\u9700\u8981\u5efa\u7acb\u80fd\u591f\u5904\u7406\u52a8\u6001\u73af\u5883\u548c\u8d44\u6e90\u7ea6\u675f\u7684\u6d77\u9053\u76d1\u6d4b\u7f51\u7edc\u67b6\u6784\u3002", "method": "\u91c7\u7528Lyapunov\u4f18\u5316\u6280\u672f\u5904\u7406\u5177\u6709\u5927\u72b6\u6001\u548c\u52a8\u4f5c\u7a7a\u95f4\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5c06\u968f\u673a\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u786e\u5b9a\u6027\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u89e3\u8026\u65f6\u7a7a\u53d8\u91cf\u4ee5\u83b7\u5f97\u6e10\u8fd1\u6700\u4f18\u89e3\u3002\u5f00\u53d1\u4e86\u8054\u5408\u8ba1\u7b97\u5378\u8f7d\u548c\u8d44\u6e90\u5206\u914d\u7b97\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6848\u5728\u957f\u671f\u5e73\u5747\u541e\u5410\u91cf\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6848\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684MSLMN\u67b6\u6784\u548cJCORA\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u6d77\u9053\u76d1\u6d4b\u7f51\u7edc\u4e2d\u7684\u8ba1\u7b97\u5378\u8f7d\u548c\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u5728\u4fdd\u8bc1\u961f\u5217\u7a33\u5b9a\u6027\u7684\u540c\u65f6\u6700\u5927\u5316\u7cfb\u7edf\u541e\u5410\u91cf\u3002"}}
{"id": "2511.01539", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01539", "abs": "https://arxiv.org/abs/2511.01539", "authors": ["Tulasi Sowjanya B.", "Prasad Krishnan"], "title": "A Hypergraph based lower bound on Pliable Index Coding based on Nested Side-Information Sets", "comment": null, "summary": "In pliable index coding (PICOD), a number of clients are connected via a\nnoise-free broadcast channel to a server which has a list of messages. Each\nclient has a unique subset of messages at the server as side-information, and\nrequests for any one message not in the side-information. A PICOD scheme of\nlength $\\ell$ is a set of $\\ell$ encoded transmissions broadcast from the\nserver such that all clients are satisfied. Finding the optimal (minimum)\nlength of PICOD and designing PICOD schemes that have small length are the\nfundamental questions in PICOD. In this paper, we present a new lower bound for\nthe optimal PICOD length using a new structural parameter called the nesting\nnumber, denoted by $\\eta(\\ch)$ associated with the hypergraph $\\ch$ that\nrepresents the PICOD problem. While the nesting number bound is not stronger\nthan previously known bounds, it can provide some computational advantages over\nthem. Also, using the nesting number bound, we obtain novel lower bounds for\nsome PICOD problems with special structures, which are tight in some cases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u4e0b\u754c\u65b9\u6cd5\u2014\u2014\u5d4c\u5957\u6570\uff0c\u7528\u4e8e\u5206\u6790PICOD\u95ee\u9898\u7684\u6700\u4f18\u957f\u5ea6\u3002\u867d\u7136\u8be5\u4e0b\u754c\u4e0d\u6bd4\u73b0\u6709\u4e0b\u754c\u66f4\u5f3a\uff0c\u4f46\u5177\u6709\u8ba1\u7b97\u4f18\u52bf\uff0c\u5e76\u80fd\u5bf9\u7279\u6b8a\u7ed3\u6784\u7684PICOD\u95ee\u9898\u7ed9\u51fa\u7d27\u4e0b\u754c\u3002", "motivation": "PICOD\u95ee\u9898\u4e2d\u5bfb\u627e\u6700\u4f18\u7f16\u7801\u957f\u5ea6\u548c\u8bbe\u8ba1\u77ed\u957f\u5ea6\u7f16\u7801\u65b9\u6848\u662f\u6838\u5fc3\u95ee\u9898\u3002\u73b0\u6709\u4e0b\u754c\u65b9\u6cd5\u5728\u8ba1\u7b97\u4e0a\u53ef\u80fd\u8f83\u4e3a\u590d\u6742\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u7ed3\u6784\u53c2\u6570\u6765\u63d0\u4f9b\u8ba1\u7b97\u4f18\u52bf\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u7ed3\u6784\u53c2\u6570\u2014\u2014\u5d4c\u5957\u6570\u03b7(\u210b)\uff0c\u8be5\u53c2\u6570\u4e0e\u8868\u793aPICOD\u95ee\u9898\u7684\u8d85\u56fe\u210b\u76f8\u5173\u8054\uff0c\u7528\u4e8e\u63a8\u5bfcPICOD\u6700\u4f18\u957f\u5ea6\u7684\u65b0\u4e0b\u754c\u3002", "result": "\u5d4c\u5957\u6570\u4e0b\u754c\u867d\u7136\u4e0d\u6bd4\u73b0\u6709\u4e0b\u754c\u66f4\u5f3a\uff0c\u4f46\u63d0\u4f9b\u4e86\u8ba1\u7b97\u4f18\u52bf\u3002\u5bf9\u4e8e\u67d0\u4e9b\u7279\u6b8a\u7ed3\u6784\u7684PICOD\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u83b7\u5f97\u7d27\u4e0b\u754c\u3002", "conclusion": "\u5d4c\u5957\u6570\u4f5c\u4e3a\u4e00\u4e2a\u65b0\u7684\u7ed3\u6784\u53c2\u6570\uff0c\u4e3aPICOD\u95ee\u9898\u7684\u6700\u4f18\u957f\u5ea6\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\uff0c\u7279\u522b\u662f\u5728\u8ba1\u7b97\u6548\u7387\u548c\u7279\u6b8a\u7ed3\u6784\u95ee\u9898\u5206\u6790\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2511.00640", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00640", "abs": "https://arxiv.org/abs/2511.00640", "authors": ["Zicheng Xu", "Guanchu Wang", "Yu-Neng Chuang", "Guangyao Zheng", "Alexander S. Szalay", "Zirui Liu", "Vladimir Braverman"], "title": "DTS: Enhancing Large Reasoning Models via Decoding Tree Sketching", "comment": null, "summary": "Large Reasoning Models (LRMs) demonstrate strong performance on complex\nreasoning tasks, yet they often suffer from overthinking, producing excessively\nlong chain-of-thought (CoT) traces that increase inference cost and may degrade\naccuracy. Our analysis reveals a clear anti-correlation between reasoning\nlength and accuracy, where across multiple stochastic decodes, the short\nreasoning paths consistently achieve the highest correctness, while longer ones\naccumulate errors and repetitions. These short optimal reasoning paths can be\nfound ideally through full enumeration of the reasoning space. However, the\ntree-structured reasoning space grows exponentially with sequence length,\nrendering exhaustive exploration infeasible. To address this, we propose DTS, a\nmodel-agnostic decoding framework that sketches the reasoning space by\nselectively branching at high-entropy tokens and applies early stopping to\nselect the shortest completed reasoning path. This approach approximates the\noptimal solution that enhances both efficiency and accuracy, without requiring\nadditional training or supervision. Experiments on AIME2024 and AIME2025\ndatasets with DeepSeek-R1-Distill-Qwen-7B and 1.5B show that DTS improves\naccuracy by up to 8%, reduces average reasoning length by 23%, and decreases\nrepetition frequency by 12%, demonstrating DTS's ability for scalable and\nefficient LRM reasoning.", "AI": {"tldr": "DTS\u662f\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u9ad8\u71b5token\u5904\u9009\u62e9\u6027\u5206\u652f\u5e76\u5e94\u7528\u65e9\u505c\u673a\u5236\u6765\u9009\u62e9\u6700\u77ed\u7684\u5b8c\u6210\u63a8\u7406\u8def\u5f84\uff0c\u4ece\u800c\u63d0\u9ad8\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7ecf\u5e38\u5b58\u5728\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u4ea7\u751f\u8fc7\u957f\u7684\u601d\u7ef4\u94fe\u8f68\u8ff9\uff0c\u8fd9\u4f1a\u589e\u52a0\u63a8\u7406\u6210\u672c\u5e76\u53ef\u80fd\u964d\u4f4e\u51c6\u786e\u6027\u3002\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u957f\u5ea6\u4e0e\u51c6\u786e\u6027\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u7684\u8d1f\u76f8\u5173\u5173\u7cfb\u3002", "method": "\u63d0\u51faDTS\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u9ad8\u71b5token\u5904\u9009\u62e9\u6027\u5206\u652f\u6765\u52fe\u52d2\u63a8\u7406\u7a7a\u95f4\uff0c\u5e76\u5e94\u7528\u65e9\u505c\u673a\u5236\u9009\u62e9\u6700\u77ed\u7684\u5b8c\u6210\u63a8\u7406\u8def\u5f84\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u76d1\u7763\u3002", "result": "\u5728AIME2024\u548cAIME2025\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDTS\u5c06\u51c6\u786e\u6027\u63d0\u9ad8\u4e868%\uff0c\u5e73\u5747\u63a8\u7406\u957f\u5ea6\u51cf\u5c11\u4e8623%\uff0c\u91cd\u590d\u9891\u7387\u964d\u4f4e\u4e8612%\u3002", "conclusion": "DTS\u80fd\u591f\u5b9e\u73b0\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u5927\u578b\u63a8\u7406\u6a21\u578b\u63a8\u7406\uff0c\u8fd1\u4f3c\u6700\u4f18\u89e3\uff0c\u540c\u65f6\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2511.01373", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.01373", "abs": "https://arxiv.org/abs/2511.01373", "authors": ["Kaining Wang", "Bo Yang", "Yusheng Lei", "Zhiwen Yu", "Xuelin Cao", "Liang Wang", "Bin Guo", "George C. Alexandropoulos", "M\u00e9rouane Debbah", "Zhu Han"], "title": "3D Gaussian Radiation Field Modeling for Integrated RIS-FAS Systems: Analysis and Optimization", "comment": null, "summary": "The integration of reconfigurable intelligent surfaces (RIS) and fluid\nantenna systems (FAS) has attracted considerable attention due to its\ntremendous potential in enhancing wireless communication performance. However,\nunder fast-fading channel conditions, rapidly and effectively performing joint\noptimization of the antenna positions in an FAS system and the RIS phase\nconfiguration remains a critical challenge. Traditional optimization methods\ntypically rely on complex iterative computations, thus making it challenging to\nobtain optimal solutions in real time within dynamic channel environments. To\naddress this issue, this paper introduces a field information-driven\noptimization method based on three-dimensional Gaussian radiation-field\nmodeling for real-time optimization of integrated FAS-RIS systems. In the\nproposed approach, obstacles are treated as virtual transmitters and, by\nseparately learning the amplitude and phase variations, the model can quickly\ngenerate high-precision channel information based on the transmitter's\nposition. This design eliminates the need for extensive pilot overhead and\ncumbersome computations. On this framework, an alternating optimization scheme\nis presented to jointly optimize the FAS position and the RIS phase\nconfiguration. Simulation results demonstrate that the proposed method\nsignificantly outperforms existing approaches in terms of spectrum prediction\naccuracy, convergence speed, and minimum achievable rate, validating its\neffectiveness and practicality in fast-fading scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e09\u7ef4\u9ad8\u65af\u8f90\u5c04\u573a\u5efa\u6a21\u7684\u573a\u4fe1\u606f\u9a71\u52a8\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b9e\u65f6\u4f18\u5316\u96c6\u6210FAS-RIS\u7cfb\u7edf\uff0c\u5728\u5feb\u8870\u843d\u4fe1\u9053\u6761\u4ef6\u4e0b\u663e\u8457\u63d0\u5347\u9891\u8c31\u9884\u6d4b\u7cbe\u5ea6\u3001\u6536\u655b\u901f\u5ea6\u548c\u53ef\u8fbe\u6700\u5c0f\u901f\u7387\u3002", "motivation": "\u5728\u5feb\u8870\u843d\u4fe1\u9053\u6761\u4ef6\u4e0b\uff0c\u5feb\u901f\u6709\u6548\u5730\u6267\u884cFAS\u7cfb\u7edf\u5929\u7ebf\u4f4d\u7f6e\u548cRIS\u76f8\u4f4d\u914d\u7f6e\u7684\u8054\u5408\u4f18\u5316\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u8fed\u4ee3\u8ba1\u7b97\uff0c\u96be\u4ee5\u5728\u52a8\u6001\u4fe1\u9053\u73af\u5883\u4e2d\u5b9e\u65f6\u83b7\u5f97\u6700\u4f18\u89e3\u3002", "method": "\u91c7\u7528\u4e09\u7ef4\u9ad8\u65af\u8f90\u5c04\u573a\u5efa\u6a21\u65b9\u6cd5\uff0c\u5c06\u969c\u788d\u7269\u89c6\u4e3a\u865a\u62df\u53d1\u5c04\u5668\uff0c\u901a\u8fc7\u5206\u522b\u5b66\u4e60\u5e45\u5ea6\u548c\u76f8\u4f4d\u53d8\u5316\uff0c\u5feb\u901f\u751f\u6210\u9ad8\u7cbe\u5ea6\u4fe1\u9053\u4fe1\u606f\u3002\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u4ea4\u66ff\u4f18\u5316\u65b9\u6848\u8054\u5408\u4f18\u5316FAS\u4f4d\u7f6e\u548cRIS\u76f8\u4f4d\u914d\u7f6e\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u9891\u8c31\u9884\u6d4b\u7cbe\u5ea6\u3001\u6536\u655b\u901f\u5ea6\u548c\u6700\u5c0f\u53ef\u8fbe\u901f\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u5feb\u8870\u843d\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u57fa\u4e8e\u573a\u4fe1\u606f\u9a71\u52a8\u7684\u4f18\u5316\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3FAS-RIS\u7cfb\u7edf\u5728\u5feb\u8870\u843d\u4fe1\u9053\u4e2d\u7684\u5b9e\u65f6\u8054\u5408\u4f18\u5316\u95ee\u9898\uff0c\u65e0\u9700\u5927\u91cf\u5bfc\u9891\u5f00\u9500\u548c\u7e41\u7410\u8ba1\u7b97\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.01798", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01798", "abs": "https://arxiv.org/abs/2511.01798", "authors": ["Dimitrios Tyrovolas", "Sotiris A. Tegos", "Yue Xiao", "Panagiotis D. Diamantoulakis", "Sotiris Ioannidis", "Christos Liaskos", "George K. Karagiannidis", "Stylianos D. Asimonis"], "title": "Ergodic Rate Analysis of Two-State Pinching-Antenna Systems", "comment": "Submitted to IEEE ICC 2026", "summary": "Programmable wireless environments (PWEs) represent a central paradigm in\nnext-generation communication networks, aiming to transform wireless\npropagation from a passive medium into an intelligent and reconfigurable entity\ncapable of dynamically adapting to network demands. In this context,\npinching-antenna systems (PASs) have emerged as a promising enabler capable of\nreconfiguring both the channel characteristics and the path loss itself by\nselectively exciting radiation points along dielectric waveguides. However,\nexisting studies largely rely on the assumption of continuously reconfigurable\npinching antenna (PA) positions, overlooking the discreteness imposed by\npractical implementations, which allow for only a finite number of PA position.\nIn this paper, an analytical framework is developed for evaluating the rate\nperformance of two-state PASs, where the antenna locations are fixed, and only\ntheir activation states can be controlled. The analysis incorporates the\ndiscrete spatial structure of the waveguide and leads to a closed-form\nexpression for the ergodic achievable data rate, while pinching discretization\nefficiency is introduced to quantify the performance deviation from the ideal\ncontinuous configuration. Simulation results demonstrate that near-continuous\nperformance can be achieved with a limited number of PAs, offering valuable\ninsights into the design and scalability of PASs in PWEs.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u5206\u6790\u6846\u67b6\u6765\u8bc4\u4f30\u53cc\u72b6\u6001\u5939\u6301\u5929\u7ebf\u7cfb\u7edf\uff08PAS\uff09\u7684\u901f\u7387\u6027\u80fd\uff0c\u8003\u8651\u4e86\u5b9e\u9645\u5b9e\u73b0\u4e2d\u5929\u7ebf\u4f4d\u7f6e\u7684\u79bb\u6563\u6027\uff0c\u5e76\u5f15\u5165\u4e86\u5939\u6301\u79bb\u6563\u5316\u6548\u7387\u6765\u91cf\u5316\u4e0e\u7406\u60f3\u8fde\u7eed\u914d\u7f6e\u7684\u6027\u80fd\u504f\u5dee\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5927\u591a\u5047\u8bbe\u5939\u6301\u5929\u7ebf\u4f4d\u7f6e\u53ef\u8fde\u7eed\u91cd\u6784\uff0c\u5ffd\u7565\u4e86\u5b9e\u9645\u5b9e\u73b0\u4e2d\u53ea\u80fd\u6709\u6709\u9650\u6570\u91cf\u5929\u7ebf\u4f4d\u7f6e\u7684\u79bb\u6563\u6027\u9650\u5236\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u5b9e\u9645\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5206\u6790\u6846\u67b6\uff0c\u7ed3\u5408\u6ce2\u5bfc\u7684\u79bb\u6563\u7a7a\u95f4\u7ed3\u6784\uff0c\u63a8\u5bfc\u51fa\u904d\u5386\u53ef\u8fbe\u6570\u636e\u901f\u7387\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u5f15\u5165\u5939\u6301\u79bb\u6563\u5316\u6548\u7387\u6307\u6807\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u6709\u9650\u6570\u91cf\u7684\u5939\u6301\u5929\u7ebf\u5373\u53ef\u5b9e\u73b0\u63a5\u8fd1\u8fde\u7eed\u914d\u7f6e\u7684\u6027\u80fd\uff0c\u4e3aPAS\u5728\u53ef\u7f16\u7a0b\u65e0\u7ebf\u73af\u5883\u4e2d\u7684\u8bbe\u8ba1\u548c\u53ef\u6269\u5c55\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002", "conclusion": "\u8be5\u5206\u6790\u6846\u67b6\u8bc1\u660e\u4e86\u5728\u8003\u8651\u5b9e\u9645\u79bb\u6563\u9650\u5236\u7684\u60c5\u51b5\u4e0b\uff0cPAS\u7cfb\u7edf\u4ecd\u80fd\u5b9e\u73b0\u9ad8\u6027\u80fd\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u901a\u4fe1\u7f51\u7edc\u4e2d\u53ef\u7f16\u7a0b\u65e0\u7ebf\u73af\u5883\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2511.00651", "categories": ["cs.AI", "cs.CL", "cs.IT", "cs.MA", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00651", "abs": "https://arxiv.org/abs/2511.00651", "authors": ["Chenhua Shi", "Bhavika Jalli", "Gregor Macdonald", "John Zou", "Wanlu Lei", "Mridul Jain", "Joji Philip"], "title": "Leveraging Multi-Agent System (MAS) and Fine-Tuned Small Language Models (SLMs) for Automated Telecom Network Troubleshooting", "comment": "6 pages, 7 figures, 1 table", "summary": "Telecom networks are rapidly growing in scale and complexity, making\neffective management, operation, and optimization increasingly challenging.\nAlthough Artificial Intelligence (AI) has been applied to many telecom tasks,\nexisting models are often narrow in scope, require large amounts of labeled\ndata, and struggle to generalize across heterogeneous deployments.\nConsequently, network troubleshooting continues to rely heavily on Subject\nMatter Experts (SMEs) to manually correlate various data sources to identify\nroot causes and corrective actions. To address these limitations, we propose a\nMulti-Agent System (MAS) that employs an agentic workflow, with Large Language\nModels (LLMs) coordinating multiple specialized tools for fully automated\nnetwork troubleshooting. Once faults are detected by AI/ML-based monitors, the\nframework dynamically activates agents such as an orchestrator, solution\nplanner, executor, data retriever, and root-cause analyzer to diagnose issues\nand recommend remediation strategies within a short time frame. A key component\nof this system is the solution planner, which generates appropriate remediation\nplans based on internal documentation. To enable this, we fine-tuned a Small\nLanguage Model (SLM) on proprietary troubleshooting documents to produce\ndomain-grounded solution plans. Experimental results demonstrate that the\nproposed framework significantly accelerates troubleshooting automation across\nboth Radio Access Network (RAN) and Core network domains.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u548cLLM\u7684\u81ea\u52a8\u5316\u7f51\u7edc\u6545\u969c\u6392\u9664\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u8c03\u591a\u4e2a\u4e13\u7528\u5de5\u5177\u5b9e\u73b0\u5feb\u901f\u6545\u969c\u8bca\u65ad\u548c\u4fee\u590d\u7b56\u7565\u63a8\u8350", "motivation": "\u7535\u4fe1\u7f51\u7edc\u89c4\u6a21\u6269\u5927\u548c\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u73b0\u6709AI\u6a21\u578b\u8303\u56f4\u72ed\u7a84\u3001\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u4e14\u96be\u4ee5\u6cdb\u5316\uff0c\u7f51\u7edc\u6545\u969c\u6392\u9664\u4ecd\u9ad8\u5ea6\u4f9d\u8d56\u4e13\u5bb6\u624b\u52a8\u64cd\u4f5c", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5305\u62ec\u7f16\u6392\u5668\u3001\u89e3\u51b3\u65b9\u6848\u89c4\u5212\u5668\u3001\u6267\u884c\u5668\u3001\u6570\u636e\u68c0\u7d22\u5668\u548c\u6839\u56e0\u5206\u6790\u5668\u7b49\u667a\u80fd\u4f53\uff0c\u57fa\u4e8eLLM\u534f\u8c03\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5e76\u9488\u5bf9\u4e13\u6709\u6545\u969c\u6392\u9664\u6587\u6863\u5fae\u8c03\u5c0f\u578b\u8bed\u8a00\u6a21\u578b", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\u663e\u8457\u52a0\u901f\u4e86\u65e0\u7ebf\u63a5\u5165\u7f51\u548c\u6838\u5fc3\u7f51\u9886\u57df\u7684\u6545\u969c\u6392\u9664\u81ea\u52a8\u5316", "conclusion": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7ed3\u5408LLM\u80fd\u591f\u6709\u6548\u89e3\u51b3\u7535\u4fe1\u7f51\u7edc\u6545\u969c\u6392\u9664\u7684\u81ea\u52a8\u5316\u6311\u6218\uff0c\u63d0\u9ad8\u6545\u969c\u5904\u7406\u6548\u7387"}}
{"id": "2511.01838", "categories": ["cs.IT", "cs.AI", "cs.NE", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01838", "abs": "https://arxiv.org/abs/2511.01838", "authors": ["Zirui Deng", "Netanel Raviv"], "title": "Efficient Vector Symbolic Architectures from Histogram Recovery", "comment": null, "summary": "Vector symbolic architectures (VSAs) are a family of information\nrepresentation techniques which enable composition, i.e., creating complex\ninformation structures from atomic vectors via binding and superposition, and\nhave recently found wide ranging applications in various neurosymbolic\nartificial intelligence (AI) systems. Recently, Raviv proposed the use of\nrandom linear codes in VSAs, suggesting that their subcode structure enables\nefficient binding, while preserving the quasi-orthogonality that is necessary\nfor neural processing. Yet, random linear codes are difficult to decode under\nnoise, which severely limits the resulting VSA's ability to support recovery,\ni.e., the retrieval of information objects and their attributes from a noisy\ncompositional representation.\n  In this work we bridge this gap by utilizing coding theoretic tools. First,\nwe argue that the concatenation of Reed-Solomon and Hadamard codes is suitable\nfor VSA, due to the mutual quasi-orthogonality of the resulting codewords (a\nfolklore result). Second, we show that recovery of the resulting compositional\nrepresentations can be done by solving a problem we call histogram recovery. In\nhistogram recovery, a collection of $N$ histograms over a finite field is given\nas input, and one must find a collection of Reed-Solomon codewords of length\n$N$ whose entry-wise symbol frequencies obey those histograms. We present an\noptimal solution to the histogram recovery problem by using algorithms related\nto list-decoding, and analyze the resulting noise resilience. Our results give\nrise to a noise-resilient VSA with formal guarantees regarding efficient\nencoding, quasi-orthogonality, and recovery, without relying on any heuristics\nor training, and while operating at improved parameters relative to similar\nsolutions such as the Hadamard code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ea7\u8054Reed-Solomon\u548cHadamard\u7801\u7684\u566a\u58f0\u5f39\u6027\u5411\u91cf\u7b26\u53f7\u67b6\u6784\uff0c\u901a\u8fc7\u89e3\u51b3\u76f4\u65b9\u56fe\u6062\u590d\u95ee\u9898\u5b9e\u73b0\u4e86\u9ad8\u6548\u7f16\u7801\u3001\u51c6\u6b63\u4ea4\u6027\u548c\u4fe1\u606f\u6062\u590d\u7684\u6b63\u5f0f\u4fdd\u8bc1\u3002", "motivation": "\u968f\u673a\u7ebf\u6027\u7801\u5728\u5411\u91cf\u7b26\u53f7\u67b6\u6784\u4e2d\u96be\u4ee5\u5728\u566a\u58f0\u4e0b\u89e3\u7801\uff0c\u9650\u5236\u4e86\u4fe1\u606f\u6062\u590d\u80fd\u529b\uff0c\u9700\u8981\u4e00\u79cd\u5177\u6709\u6b63\u5f0f\u4fdd\u8bc1\u7684\u566a\u58f0\u5f39\u6027\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528Reed-Solomon\u548cHadamard\u7801\u7684\u7ea7\u8054\uff0c\u63d0\u51fa\u76f4\u65b9\u56fe\u6062\u590d\u95ee\u9898\uff0c\u5e76\u5229\u7528\u5217\u8868\u89e3\u7801\u76f8\u5173\u7b97\u6cd5\u63d0\u4f9b\u6700\u4f18\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5f00\u53d1\u51fa\u5177\u6709\u9ad8\u6548\u7f16\u7801\u3001\u51c6\u6b63\u4ea4\u6027\u548c\u6062\u590d\u80fd\u529b\u7684\u566a\u58f0\u5f39\u6027\u5411\u91cf\u7b26\u53f7\u67b6\u6784\uff0c\u76f8\u6bd4Hadamard\u7801\u7b49\u7c7b\u4f3c\u65b9\u6848\u5728\u53c2\u6570\u4e0a\u6709\u6240\u6539\u8fdb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5411\u91cf\u7b26\u53f7\u67b6\u6784\u63d0\u4f9b\u4e86\u4e0d\u4f9d\u8d56\u542f\u53d1\u5f0f\u6216\u8bad\u7ec3\u7684\u6b63\u5f0f\u4fdd\u8bc1\uff0c\u5728\u566a\u58f0\u73af\u5883\u4e0b\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u4fe1\u606f\u6062\u590d\u3002"}}
{"id": "2511.00673", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00673", "abs": "https://arxiv.org/abs/2511.00673", "authors": ["Dominik Drexler"], "title": "Lifted Successor Generation in Numeric Planning", "comment": null, "summary": "Most planners ground numeric planning tasks, given in a first-order-like\nlanguage, into a ground task representation. However, this can lead to an\nexponential blowup in task representation size, which occurs in practice for\nhard-to-ground tasks. We extend a state-of-the-art lifted successor generator\nfor classical planning to support numeric precondition applicability. The\nmethod enumerates maximum cliques in a substitution consistency graph. Each\nmaximum clique represents a substitution for the variables of the action\nschema, yielding a ground action. We augment this graph with numeric action\npreconditions and prove the successor generator is exact under formally\nspecified conditions. When the conditions fail, our generator may list\ninapplicable ground actions; a final applicability check filters these without\naffecting completeness. However, this cannot happen in 23 of 25 benchmark\ndomains, and it occurs only in 1 domain. To the authors' knowledge, no other\nlifted successor generator supports numeric action preconditions. This enables\nfuture research on lifted planning for a very rich planning fragment.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u7ecf\u5178\u89c4\u5212\u4e2d\u7684\u63d0\u5347\u540e\u7ee7\u751f\u6210\u5668\uff0c\u652f\u6301\u6570\u503c\u524d\u7f6e\u6761\u4ef6\u7684\u9002\u7528\u6027\u68c0\u67e5\uff0c\u901a\u8fc7\u679a\u4e3e\u66ff\u6362\u4e00\u81f4\u6027\u56fe\u4e2d\u7684\u6700\u5927\u56e2\u6765\u751f\u6210\u5730\u9762\u52a8\u4f5c\uff0c\u907f\u514d\u4e86\u4efb\u52a1\u8868\u793a\u7684\u6307\u6570\u7ea7\u81a8\u80c0\u3002", "motivation": "\u4f20\u7edf\u6570\u503c\u89c4\u5212\u4efb\u52a1\u9700\u8981\u5c06\u4e00\u9636\u903b\u8f91\u8868\u793a\u8f6c\u6362\u4e3a\u5730\u9762\u8868\u793a\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u4efb\u52a1\u8868\u793a\u5927\u5c0f\u7684\u6307\u6570\u7ea7\u81a8\u80c0\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u96be\u4ee5\u63a5\u5730\u4efb\u52a1\u4e2d\u7684\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u6269\u5c55\u4e86\u6700\u5148\u8fdb\u7684\u63d0\u5347\u540e\u7ee7\u751f\u6210\u5668\uff0c\u652f\u6301\u6570\u503c\u524d\u7f6e\u6761\u4ef6\u9002\u7528\u6027\u3002\u65b9\u6cd5\u901a\u8fc7\u679a\u4e3e\u66ff\u6362\u4e00\u81f4\u6027\u56fe\u4e2d\u7684\u6700\u5927\u56e2\uff0c\u6bcf\u4e2a\u6700\u5927\u56e2\u4ee3\u8868\u52a8\u4f5c\u6a21\u5f0f\u53d8\u91cf\u7684\u4e00\u4e2a\u66ff\u6362\uff0c\u751f\u6210\u5730\u9762\u52a8\u4f5c\u3002\u5728\u6761\u4ef6\u4e0d\u6ee1\u8db3\u65f6\uff0c\u901a\u8fc7\u6700\u7ec8\u9002\u7528\u6027\u68c0\u67e5\u8fc7\u6ee4\u4e0d\u9002\u7528\u52a8\u4f5c\u3002", "result": "\u572825\u4e2a\u57fa\u51c6\u57df\u4e2d\u768423\u4e2a\u57df\u4e2d\u4e0d\u4f1a\u51fa\u73b0\u4e0d\u9002\u7528\u5730\u9762\u52a8\u4f5c\uff0c\u4ec5\u57281\u4e2a\u57df\u4e2d\u51fa\u73b0\u3002\u636e\u4f5c\u8005\u6240\u77e5\uff0c\u8fd9\u662f\u9996\u4e2a\u652f\u6301\u6570\u503c\u52a8\u4f5c\u524d\u7f6e\u6761\u4ef6\u7684\u63d0\u5347\u540e\u7ee7\u751f\u6210\u5668\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u975e\u5e38\u4e30\u5bcc\u7684\u89c4\u5212\u7247\u6bb5\u5f00\u542f\u4e86\u63d0\u5347\u89c4\u5212\u7684\u672a\u6765\u7814\u7a76\uff0c\u89e3\u51b3\u4e86\u6570\u503c\u89c4\u5212\u4e2d\u7684\u63a5\u5730\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b8c\u6574\u6027\u3002"}}
{"id": "2511.00710", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00710", "abs": "https://arxiv.org/abs/2511.00710", "authors": ["Minghe Shen", "Zhuo Zhi", "Chonghan Liu", "Shuo Xing", "Zhengzhong Tu", "Che Liu"], "title": "Ariadne: A Controllable Framework for Probing and Extending VLM Reasoning Boundaries", "comment": null, "summary": "While Vision-Language Models (VLMs) post-trained with Reinforcement Learning\n(RL) show impressive general reasoning, their evaluation is often confined to\nlanguage-dominant tasks (e.g., math). This raises a critical question: can RL\npost-training truly extend the inherent capability boundary of a base VLM,\nparticularly for visual-centric spatial tasks where it initially fails? To\ninvestigate this, we introduce Ariadne, a framework utilizing synthetic mazes\nfor multi-step spatial reasoning where task difficulty (e.g., path length,\nturns) is precisely controlled. We leverage this controllable environment to\ntrain VLMs using Reinforcement Learning with Verified Rewards (RLVR) in a\ndifficulty-aware curriculum. Surprisingly, post-RLVR training, the VLM achieves\nover 50% accuracy on a problem set where the base model scored 0%,\ndemonstrating that our approach expands the model's initial capability\nboundary. To assess real-world viability, we evaluate out-of-distribution (OOD)\ngeneralization on practical benchmarks. Despite training only on synthetic maze\nsamples, Ariadne achieves significant zero-shot improvements, averaging 16% on\nMapBench (e.g., museum navigation) and 24% on ReasonMap (subway transfer\ntasks). These results confirm that our method not only broadens the model's\nfundamental limits but also enhances its generalization to real-world spatial\nreasoning. We acknowledge our study is limited to the post-training phase,\ngiven the opaqueness of pre-training data, and hope our research motivates\nfurther work on specialized, capability-extending alignment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Ariadne\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u6269\u5c55\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u8fb9\u754c\uff0c\u5728\u5408\u6210\u8ff7\u5bab\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u4ece0%\u523050%\u4ee5\u4e0a\u7684\u51c6\u786e\u7387\u63d0\u5347\uff0c\u5e76\u5728\u771f\u5b9e\u4e16\u754c\u7a7a\u95f4\u63a8\u7406\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u96f6\u6837\u672c\u6cdb\u5316\u6539\u8fdb\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u540e\u8bad\u7ec3\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u8bed\u8a00\u4e3b\u5bfc\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u89c6\u89c9\u4e2d\u5fc3\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\u7684\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u662f\u5426\u80fd\u591f\u771f\u6b63\u6269\u5c55\u57fa\u7840\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u8fb9\u754c\uff0c\u7279\u522b\u662f\u5728\u6a21\u578b\u6700\u521d\u5931\u8d25\u7684\u89c6\u89c9\u7a7a\u95f4\u4efb\u52a1\u4e0a\u3002", "method": "\u63d0\u51faAriadne\u6846\u67b6\uff0c\u4f7f\u7528\u5408\u6210\u8ff7\u5bab\u8fdb\u884c\u591a\u6b65\u7a7a\u95f4\u63a8\u7406\uff0c\u901a\u8fc7\u7cbe\u786e\u63a7\u5236\u4efb\u52a1\u96be\u5ea6\uff08\u5982\u8def\u5f84\u957f\u5ea6\u3001\u8f6c\u5f2f\u6570\uff09\u6784\u5efa\u96be\u5ea6\u611f\u77e5\u8bfe\u7a0b\u3002\u91c7\u7528\u5e26\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09\u5bf9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u540e\u8bad\u7ec3\u3002", "result": "\u540e\u8bad\u7ec3\u540e\uff0c\u6a21\u578b\u5728\u57fa\u7840\u6a21\u578b\u5f97\u5206\u4e3a0%\u7684\u95ee\u9898\u96c6\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8fc750%\u7684\u51c6\u786e\u7387\u3002\u5728\u771f\u5b9e\u4e16\u754c\u6cdb\u5316\u8bc4\u4f30\u4e2d\uff0c\u4ec5\u5728\u5408\u6210\u8ff7\u5bab\u6837\u672c\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u5728MapBench\u4e0a\u5e73\u5747\u63d0\u534716%\uff0c\u5728ReasonMap\u4e0a\u5e73\u5747\u63d0\u534724%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u6269\u5c55\u4e86\u6a21\u578b\u7684\u57fa\u672c\u80fd\u529b\u8fb9\u754c\uff0c\u8fd8\u589e\u5f3a\u4e86\u5176\u5728\u771f\u5b9e\u4e16\u754c\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002\u7814\u7a76\u9650\u4e8e\u540e\u8bad\u7ec3\u9636\u6bb5\uff0c\u5e0c\u671b\u63a8\u52a8\u4e13\u95e8\u7684\u80fd\u529b\u6269\u5c55\u5bf9\u9f50\u7814\u7a76\u3002"}}
{"id": "2511.00739", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.00739", "abs": "https://arxiv.org/abs/2511.00739", "authors": ["Ritik Raj", "Hong Wang", "Tushar Krishna"], "title": "A CPU-Centric Perspective on Agentic AI", "comment": null, "summary": "Agentic AI frameworks add a decision-making orchestrator embedded with\nexternal tools, including web search, Python interpreter, contextual database,\nand others, on top of monolithic LLMs, turning them from passive text oracles\ninto autonomous problem-solvers that can plan, call tools, remember past steps,\nand adapt on the fly.\n  This paper aims to characterize and understand the system bottlenecks\nintroduced by agentic AI workloads from a largely overlooked CPU-centric\nperspective. We first systematically characterize Agentic AI on the basis of\norchestrator/decision making component, inference path dynamics and\nrepetitiveness of the agentic flow which directly influences the system-level\nperformance. Thereafter, based on the characterization, we choose five\nrepresentative agentic AI workloads- Haystack RAG, Toolformer, ChemCrow,\nLangchain and SWE-Agent to profile latency, throughput and energy metrics and\ndemystify the significant impact of CPUs on these metrics relative to GPUs. We\nobserve that - 1. Tool processing on CPUs can take up to 90.6% of the total\nlatency; 2. Agentic throughput gets bottlenecked either by CPU factors -\ncoherence, synchronization and over-subscription of cores or GPU factors - main\nmemory capacity and bandwidth; \\circled{3} CPU dynamic energy consumes up to\n44% of the total dynamic energy at large batch sizes. Based on the profiling\ninsights, we present two key optimizations- 1. CPU and GPU-Aware Micro-batching\n(CGAM) and 2. Mixed Agentic Workload Scheduling (MAWS) for homogeneous and\nheterogeneous agentic workloads respectively to demonstrate the potential to\nimprove the performance, efficiency, and scalability of agentic AI. We achieve\nup to 2.1x and 1.41x P50 latency speedup compared to the multi-processing\nbenchmark for homogeneous and heterogeneous agentic workloads respectively.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4eceCPU\u89c6\u89d2\u5206\u6790Agentic AI\u6846\u67b6\u7684\u7cfb\u7edf\u74f6\u9888\uff0c\u53d1\u73b0\u5de5\u5177\u5904\u7406\u5728CPU\u4e0a\u53ef\u80fd\u5360\u636e\u603b\u5ef6\u8fdf\u768490.6%\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u4f18\u5316\u65b9\u6848CGAM\u548cMAWS\uff0c\u5206\u522b\u9488\u5bf9\u540c\u8d28\u548c\u5f02\u8d28\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5b9e\u73b0\u4e86\u6700\u9ad82.1\u500d\u548c1.41\u500d\u7684\u5ef6\u8fdf\u52a0\u901f\u3002", "motivation": "\u4ece\u88ab\u5ffd\u89c6\u7684CPU\u4e2d\u5fc3\u89c6\u89d2\u6765\u7406\u89e3\u548c\u8868\u5f81Agentic AI\u5de5\u4f5c\u8d1f\u8f7d\u5f15\u5165\u7684\u7cfb\u7edf\u74f6\u9888\uff0c\u63ed\u793aCPU\u5bf9\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u548c\u80fd\u8017\u7684\u663e\u8457\u5f71\u54cd\u3002", "method": "\u9996\u5148\u7cfb\u7edf\u6027\u5730\u8868\u5f81Agentic AI\u7684\u7f16\u6392\u5668/\u51b3\u7b56\u7ec4\u4ef6\u3001\u63a8\u7406\u8def\u5f84\u52a8\u6001\u6027\u548c\u6d41\u7a0b\u91cd\u590d\u6027\uff0c\u7136\u540e\u9009\u62e9\u4e94\u4e2a\u4ee3\u8868\u6027\u5de5\u4f5c\u8d1f\u8f7d\u8fdb\u884c\u6027\u80fd\u5206\u6790\uff0c\u6700\u540e\u63d0\u51faCPU\u548cGPU\u611f\u77e5\u7684\u5fae\u6279\u5904\u7406(CGAM)\u4ee5\u53ca\u6df7\u5408Agentic\u5de5\u4f5c\u8d1f\u8f7d\u8c03\u5ea6(MAWS)\u4e24\u79cd\u4f18\u5316\u65b9\u6848\u3002", "result": "\u53d1\u73b0\u5de5\u5177\u5904\u7406\u5728CPU\u4e0a\u53ef\u536090.6%\u603b\u5ef6\u8fdf\uff0cAgentic\u541e\u5410\u91cf\u53d7CPU\u56e0\u7d20(\u4e00\u81f4\u6027\u3001\u540c\u6b65\u3001\u6838\u5fc3\u8fc7\u8f7d)\u6216GPU\u56e0\u7d20(\u4e3b\u5b58\u5bb9\u91cf\u548c\u5e26\u5bbd)\u9650\u5236\uff0cCPU\u52a8\u6001\u80fd\u8017\u5728\u5927\u578b\u6279\u6b21\u4e2d\u53ef\u8fbe\u603b\u52a8\u6001\u80fd\u8017\u768444%\u3002\u4f18\u5316\u540e\u5b9e\u73b0\u540c\u8d28\u5de5\u4f5c\u8d1f\u8f7d2.1\u500d\u3001\u5f02\u8d28\u5de5\u4f5c\u8d1f\u8f7d1.41\u500d\u7684P50\u5ef6\u8fdf\u52a0\u901f\u3002", "conclusion": "CPU\u5728Agentic AI\u7cfb\u7edf\u4e2d\u626e\u6f14\u5173\u952e\u89d2\u8272\uff0c\u901a\u8fc7CPU\u548cGPU\u611f\u77e5\u7684\u4f18\u5316\u7b56\u7565\u53ef\u4ee5\u663e\u8457\u63d0\u5347Agentic AI\u7684\u6027\u80fd\u3001\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.00751", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00751", "abs": "https://arxiv.org/abs/2511.00751", "authors": ["Chiyan Loo"], "title": "Reevaluating Self-Consistency Scaling in Multi-Agent Systems", "comment": "7 pages, 3 figures", "summary": "This study examines the trade-offs of increasing sampled reasoning paths in\nself-consistency for modern large language models (LLMs). Earlier research with\nolder models showed that combining multiple reasoning chains improves results\nbefore reaching a plateau. Using Gemini 2.5 models on HotpotQA and Math-500, we\nrevisit those claims under current model conditions. Each configuration pooled\noutputs from varying sampled reasoning paths and compared them to a single\nchain-of-thought (CoT) baseline. Larger models exhibited a more stable and\nconsistent improvement curve. The results confirm that performance gains taper\noff after moderate sampling, aligning with past findings. This plateau suggests\ndiminishing returns driven by overlap among reasoning paths. Self-consistency\nremains useful, but high-sample configurations offer little benefit relative to\ntheir computational cost.", "AI": {"tldr": "\u7814\u7a76\u91cd\u65b0\u9a8c\u8bc1\u4e86\u5728\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u589e\u52a0\u81ea\u4e00\u81f4\u6027\u63a8\u7406\u8def\u5f84\u91c7\u6837\u7684\u6536\u76ca\u9012\u51cf\u73b0\u8c61\uff0c\u53d1\u73b0\u6027\u80fd\u63d0\u5347\u5728\u9002\u5ea6\u91c7\u6837\u540e\u8fbe\u5230\u5e73\u53f0\u671f\uff0c\u9ad8\u91c7\u6837\u914d\u7f6e\u76f8\u5bf9\u4e8e\u8ba1\u7b97\u6210\u672c\u6536\u76ca\u6709\u9650\u3002", "motivation": "\u91cd\u65b0\u9a8c\u8bc1\u65e9\u671f\u7814\u7a76\u4e2d\u5173\u4e8e\u81ea\u4e00\u81f4\u6027\u63a8\u7406\u8def\u5f84\u91c7\u6837\u7684\u7ed3\u8bba\u5728\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u6761\u4ef6\u4e0b\u7684\u9002\u7528\u6027\uff0c\u63a2\u7d22\u6027\u80fd\u63d0\u5347\u4e0e\u91c7\u6837\u6570\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u4f7f\u7528Gemini 2.5\u6a21\u578b\u5728HotpotQA\u548cMath-500\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e0d\u540c\u91c7\u6837\u6570\u91cf\u63a8\u7406\u8def\u5f84\u7684\u8f93\u51fa\u4e0e\u5355\u4e00\u8def\u5f84\u601d\u7ef4\u94fe\u57fa\u7ebf\u7684\u6027\u80fd\u5dee\u5f02\u3002", "result": "\u8f83\u5927\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u7a33\u5b9a\u548c\u4e00\u81f4\u7684\u6539\u8fdb\u66f2\u7ebf\uff0c\u6027\u80fd\u589e\u76ca\u5728\u9002\u5ea6\u91c7\u6837\u540e\u8d8b\u4e8e\u5e73\u7f13\uff0c\u4e0e\u8fc7\u53bb\u7814\u7a76\u7ed3\u679c\u4e00\u81f4\u3002\u63a8\u7406\u8def\u5f84\u4e4b\u95f4\u7684\u91cd\u53e0\u5bfc\u81f4\u4e86\u6536\u76ca\u9012\u51cf\u3002", "conclusion": "\u81ea\u4e00\u81f4\u6027\u65b9\u6cd5\u4ecd\u7136\u6709\u6548\uff0c\u4f46\u9ad8\u91c7\u6837\u914d\u7f6e\u76f8\u5bf9\u4e8e\u8ba1\u7b97\u6210\u672c\u5e26\u6765\u7684\u6536\u76ca\u6709\u9650\uff0c\u5efa\u8bae\u9002\u5ea6\u4f7f\u7528\u91c7\u6837\u7b56\u7565\u3002"}}
{"id": "2511.00758", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00758", "abs": "https://arxiv.org/abs/2511.00758", "authors": ["Hong Su"], "title": "Active Thinking Model: A Goal-Directed Self-Improving Framework for Real-World Adaptive Intelligence", "comment": null, "summary": "Real-world artificial intelligence (AI) systems are increasingly required to\noperate autonomously in dynamic, uncertain, and continuously changing\nenvironments. However, most existing AI models rely on predefined objectives,\nstatic training data, and externally supplied feedback, which restrict their\nability to adapt, reflect, and improve independently. In this paper, we propose\nthe Active Thinking Model (ATM)- a unified cognitive framework that integrates\ngoal reasoning, dynamic task generation, and self-reflective learning into an\nadaptive architecture. Unlike conventional systems that passively execute fixed\nprocedures, ATM actively evaluates its performance through logical reasoning\nand environmental indicators, reuses effective methods to solve new problems,\nand generates novel strategies for unseen situations via a continuous\nself-improvement loop. A mathematically grounded theoretical analysis\ndemonstrates that ATM can autonomously evolve from suboptimal to optimal\nbehavior without external supervision and maintain bounded tracking regret\nunder changing environmental conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e3b\u52a8\u601d\u8003\u6a21\u578b\uff08ATM\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u8ba4\u77e5\u6846\u67b6\uff0c\u96c6\u6210\u4e86\u76ee\u6807\u63a8\u7406\u3001\u52a8\u6001\u4efb\u52a1\u751f\u6210\u548c\u81ea\u53cd\u5b66\u4e60\uff0c\u4f7fAI\u7cfb\u7edf\u80fd\u591f\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u81ea\u4e3b\u9002\u5e94\u548c\u6539\u8fdb\u3002", "motivation": "\u73b0\u5b9eAI\u7cfb\u7edf\u9700\u8981\u5728\u52a8\u6001\u3001\u4e0d\u786e\u5b9a\u548c\u6301\u7eed\u53d8\u5316\u7684\u73af\u5883\u4e2d\u81ea\u4e3b\u8fd0\u884c\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u4f9d\u8d56\u9884\u5b9a\u4e49\u76ee\u6807\u3001\u9759\u6001\u8bad\u7ec3\u6570\u636e\u548c\u5916\u90e8\u53cd\u9988\uff0c\u9650\u5236\u4e86\u5176\u72ec\u7acb\u9002\u5e94\u3001\u53cd\u601d\u548c\u6539\u8fdb\u7684\u80fd\u529b\u3002", "method": "ATM\u6846\u67b6\u6574\u5408\u76ee\u6807\u63a8\u7406\u3001\u52a8\u6001\u4efb\u52a1\u751f\u6210\u548c\u81ea\u53cd\u5b66\u4e60\uff0c\u901a\u8fc7\u903b\u8f91\u63a8\u7406\u548c\u73af\u5883\u6307\u6807\u4e3b\u52a8\u8bc4\u4f30\u6027\u80fd\uff0c\u91cd\u7528\u6709\u6548\u65b9\u6cd5\u89e3\u51b3\u65b0\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u6301\u7eed\u81ea\u6539\u8fdb\u5faa\u73af\u4e3a\u672a\u89c1\u60c5\u51b5\u751f\u6210\u65b0\u7b56\u7565\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0cATM\u80fd\u591f\u65e0\u5916\u90e8\u76d1\u7763\u5730\u4ece\u6b21\u4f18\u884c\u4e3a\u81ea\u4e3b\u6f14\u5316\u4e3a\u6700\u4f18\u884c\u4e3a\uff0c\u5e76\u5728\u53d8\u5316\u73af\u5883\u6761\u4ef6\u4e0b\u4fdd\u6301\u6709\u754c\u8ddf\u8e2a\u9057\u61be\u3002", "conclusion": "ATM\u4e3aAI\u7cfb\u7edf\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u9002\u5e94\u548c\u6301\u7eed\u6539\u8fdb\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2511.00763", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00763", "abs": "https://arxiv.org/abs/2511.00763", "authors": ["Wanda Hou", "Leon Zhou", "Hong-Ye Hu", "Yi-Zhuang You", "Xiao-Liang Qi"], "title": "How Focused Are LLMs? A Quantitative Study via Repetitive Deterministic Prediction Tasks", "comment": null, "summary": "We investigate the performance of large language models on repetitive\ndeterministic prediction tasks and study how the sequence accuracy rate scales\nwith output length. Each such task involves repeating the same operation n\ntimes. Examples include letter replacement in strings following a given rule,\ninteger addition, and multiplication of string operators in many body quantum\nmechanics. If the model performs the task through a simple repetition\nalgorithm, the success rate should decay exponentially with sequence length. In\ncontrast, our experiments on leading large language models reveal a sharp\ndouble exponential drop beyond a characteristic length scale, forming an\naccuracy cliff that marks the transition from reliable to unstable generation.\nThis indicates that the models fail to execute each operation independently. To\nexplain this phenomenon, we propose a statistical physics inspired model that\ncaptures the competition between external conditioning from the prompt and\ninternal interference among generated tokens. The model quantitatively\nreproduces the observed crossover and provides an interpretable link between\nattention induced interference and sequence level failure. Fitting the model to\nempirical results across multiple models and tasks yields effective parameters\nthat characterize the intrinsic error rate and error accumulation factor for\neach model task pair, offering a principled framework for understanding the\nlimits of deterministic accuracy in large language models.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91cd\u590d\u786e\u5b9a\u6027\u9884\u6d4b\u4efb\u52a1\u4e2d\u5b58\u5728\"\u51c6\u786e\u6027\u60ac\u5d16\"\u73b0\u8c61\uff0c\u51c6\u786e\u7387\u968f\u8f93\u51fa\u957f\u5ea6\u5448\u53cc\u6307\u6570\u4e0b\u964d\uff0c\u800c\u975e\u7b80\u5355\u6307\u6570\u8870\u51cf\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91cd\u590d\u786e\u5b9a\u6027\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7406\u89e3\u5176\u51c6\u786e\u7387\u968f\u8f93\u51fa\u957f\u5ea6\u7684\u53d8\u5316\u89c4\u5f8b\uff0c\u4ee5\u53ca\u6a21\u578b\u6267\u884c\u91cd\u590d\u64cd\u4f5c\u65f6\u7684\u5185\u5728\u673a\u5236\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u6d4b\u8bd5\u591a\u79cd\u91cd\u590d\u786e\u5b9a\u6027\u4efb\u52a1\uff08\u5982\u5b57\u7b26\u4e32\u66ff\u6362\u3001\u6574\u6570\u52a0\u6cd5\u7b49\uff09\uff0c\u63d0\u51fa\u57fa\u4e8e\u7edf\u8ba1\u7269\u7406\u7684\u6a21\u578b\u6765\u89e3\u91ca\u89c2\u5bdf\u5230\u7684\u73b0\u8c61\uff0c\u5206\u6790\u5916\u90e8\u6761\u4ef6\u4e0e\u5185\u90e8\u5e72\u6270\u7684\u7ade\u4e89\u5173\u7cfb\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u51c6\u786e\u7387\u5728\u8d85\u8fc7\u7279\u5f81\u957f\u5ea6\u540e\u51fa\u73b0\u53cc\u6307\u6570\u6025\u5267\u4e0b\u964d\uff0c\u5f62\u6210\u51c6\u786e\u6027\u60ac\u5d16\uff1b\u63d0\u51fa\u7684\u7edf\u8ba1\u7269\u7406\u6a21\u578b\u80fd\u5b9a\u91cf\u91cd\u73b0\u8fd9\u4e00\u4ea4\u53c9\u73b0\u8c61\uff0c\u63ed\u793a\u4e86\u6ce8\u610f\u529b\u673a\u5236\u5f15\u8d77\u7684\u5e72\u6270\u4e0e\u5e8f\u5217\u7ea7\u5931\u8d25\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u72ec\u7acb\u6267\u884c\u91cd\u590d\u64cd\u4f5c\uff0c\u5176\u786e\u5b9a\u6027\u51c6\u786e\u6027\u5b58\u5728\u5185\u5728\u9650\u5236\uff1b\u901a\u8fc7\u6a21\u578b\u62df\u5408\u53ef\u83b7\u5f97\u8868\u5f81\u6bcf\u4e2a\u6a21\u578b-\u4efb\u52a1\u5bf9\u7684\u5185\u5728\u9519\u8bef\u7387\u548c\u9519\u8bef\u7d2f\u79ef\u56e0\u5b50\u7684\u6709\u6548\u53c2\u6570\u3002"}}
{"id": "2511.00782", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00782", "abs": "https://arxiv.org/abs/2511.00782", "authors": ["Jifan Gao", "Michael Rosenthal", "Brian Wolpin", "Simona Cristea"], "title": "Count-Based Approaches Remain Strong: A Benchmark Against Transformer and LLM Pipelines on Structured EHR", "comment": null, "summary": "Structured electronic health records (EHR) are essential for clinical\nprediction. While count-based learners continue to perform strongly on such\ndata, no benchmarking has directly compared them against more recent\nmixture-of-agents LLM pipelines, which have been reported to outperform single\nLLMs in various NLP tasks. In this study, we evaluated three categories of\nmethodologies for EHR prediction using the EHRSHOT dataset: count-based models\nbuilt from ontology roll-ups with two time bins, based on LightGBM and the\ntabular foundation model TabPFN; a pretrained sequential transformer (CLMBR);\nand a mixture-of-agents pipeline that converts tabular histories to\nnatural-language summaries followed by a text classifier. We assessed eight\noutcomes using the EHRSHOT dataset. Across the eight evaluation tasks,\nhead-to-head wins were largely split between the count-based and the\nmixture-of-agents methods. Given their simplicity and interpretability,\ncount-based models remain a strong candidate for structured EHR benchmarking.\nThe source code is available at:\nhttps://github.com/cristea-lab/Structured_EHR_Benchmark.", "AI": {"tldr": "\u6bd4\u8f83\u4e86\u57fa\u4e8e\u8ba1\u6570\u7684\u6a21\u578b\u3001\u9884\u8bad\u7ec3\u5e8f\u5217\u53d8\u6362\u5668\u548c\u6df7\u5408\u4ee3\u7406LLM\u7ba1\u9053\u5728\u7ed3\u6784\u5316\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u9884\u6d4b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u57fa\u4e8e\u8ba1\u6570\u7684\u65b9\u6cd5\u548c\u6df7\u5408\u4ee3\u7406\u65b9\u6cd5\u8868\u73b0\u76f8\u5f53\uff0c\u4f46\u57fa\u4e8e\u8ba1\u6570\u7684\u65b9\u6cd5\u66f4\u7b80\u5355\u4e14\u53ef\u89e3\u91ca\u6027\u5f3a\u3002", "motivation": "\u867d\u7136\u57fa\u4e8e\u8ba1\u6570\u7684\u5b66\u4e60\u5668\u5728\u7ed3\u6784\u5316EHR\u6570\u636e\u4e0a\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u5c1a\u672a\u4e0e\u6700\u8fd1\u63d0\u51fa\u7684\u6df7\u5408\u4ee3\u7406LLM\u7ba1\u9053\u8fdb\u884c\u76f4\u63a5\u57fa\u51c6\u6bd4\u8f83\uff0c\u540e\u8005\u5728\u5404\u79cdNLP\u4efb\u52a1\u4e2d\u5df2\u88ab\u62a5\u544a\u4f18\u4e8e\u5355\u4e00LLM\u3002", "method": "\u4f7f\u7528EHRSHOT\u6570\u636e\u96c6\u8bc4\u4f30\u4e09\u7c7b\u65b9\u6cd5\uff1a\u57fa\u4e8e\u8ba1\u6570\u7684\u6a21\u578b\uff08LightGBM\u548cTabPFN\uff09\u3001\u9884\u8bad\u7ec3\u5e8f\u5217\u53d8\u6362\u5668\uff08CLMBR\uff09\u4ee5\u53ca\u6df7\u5408\u4ee3\u7406\u7ba1\u9053\uff08\u5c06\u8868\u683c\u5386\u53f2\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u6458\u8981\u540e\u4f7f\u7528\u6587\u672c\u5206\u7c7b\u5668\uff09\u3002", "result": "\u5728\u516b\u4e2a\u8bc4\u4f30\u4efb\u52a1\u4e2d\uff0c\u57fa\u4e8e\u8ba1\u6570\u7684\u65b9\u6cd5\u548c\u6df7\u5408\u4ee3\u7406\u65b9\u6cd5\u7684\u8868\u73b0\u57fa\u672c\u76f8\u5f53\uff0c\u5404\u6709\u80dc\u8d1f\u3002", "conclusion": "\u8003\u8651\u5230\u7b80\u5355\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u57fa\u4e8e\u8ba1\u6570\u7684\u6a21\u578b\u4ecd\u7136\u662f\u7ed3\u6784\u5316EHR\u57fa\u51c6\u6d4b\u8bd5\u7684\u6709\u529b\u5019\u9009\u65b9\u6cd5\u3002"}}
{"id": "2511.00808", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00808", "abs": "https://arxiv.org/abs/2511.00808", "authors": ["Bowen Fang", "Ruijian Zha", "Xuan Di"], "title": "Do Math Reasoning LLMs Help Predict the Impact of Public Transit Events?", "comment": null, "summary": "Predicting public transit incident duration from unstructured text alerts is\na critical but challenging task. Addressing the domain sparsity of transit\noperations with standard Supervised Fine-Tuning (SFT) is difficult, as the task\ninvolves noisy, continuous labels and lacks reliable expert demonstrations for\nreasoning. While Reinforcement Learning from Verifiable Rewards (RLVR) excels\nat tasks with binary correctness, like mathematics, its applicability to noisy,\ncontinuous forecasting is an open question. This work, to our knowledge, is the\nfirst to bridge the gap between RLVR LLM training with the critical, real-world\nforecasting challenges in public transit operations. We adapt RLVR to this task\nby introducing a tolerance-based, shaped reward function that grants partial\ncredit within a continuous error margin, rather than demanding a single correct\nanswer. We systematically evaluate this framework on a curated dataset of NYC\nMTA service alerts. Our findings show that general-purpose, instruction-tuned\nLLMs significantly outperform specialized math-reasoning models, which struggle\nwith the ambiguous, real-world text. We empirically demonstrate that the binary\nreward is unstable and degrades performance, whereas our shaped reward design\nis critical and allows our model to dominate on the most challenging metrics.\nWhile classical regressors are superior at minimizing overall MAE or MSE, our\nRLVR approach achieved a 35\\% relative improvement in 5-minute accuracy (Acc@5)\nover the strongest baseline. This demonstrates that RLVR can be successfully\nadapted to real-world, noisy forecasting, but requires a verifier design that\nreflects the continuous nature of the problem.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u5c06RLVR LLM\u8bad\u7ec3\u5e94\u7528\u4e8e\u516c\u5171\u4ea4\u901a\u8fd0\u8425\u4e2d\u7684\u5b9e\u65f6\u9884\u6d4b\u6311\u6218\uff0c\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u5bb9\u5dee\u7684\u5956\u52b1\u51fd\u6570\u6765\u9002\u5e94\u566a\u58f0\u8fde\u7eed\u9884\u6d4b\u4efb\u52a1\uff0c\u5728NYC MTA\u670d\u52a1\u8b66\u62a5\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\u3002", "motivation": "\u9884\u6d4b\u516c\u5171\u4ea4\u901a\u4e8b\u4ef6\u6301\u7eed\u65f6\u95f4\u662f\u4e00\u4e2a\u5173\u952e\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u6807\u51c6\u76d1\u7763\u5fae\u8c03\u96be\u4ee5\u5904\u7406\u9886\u57df\u7a00\u758f\u6027\u548c\u566a\u58f0\u8fde\u7eed\u6807\u7b7e\u95ee\u9898\uff0c\u800c\u4f20\u7edfRLVR\u65b9\u6cd5\u4e3b\u8981\u9002\u7528\u4e8e\u4e8c\u5143\u6b63\u786e\u6027\u4efb\u52a1\uff0c\u9700\u8981\u63a2\u7d22\u5176\u5728\u566a\u58f0\u8fde\u7eed\u9884\u6d4b\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u5bb9\u5dee\u7684\u5956\u52b1\u51fd\u6570\uff0c\u5728\u8fde\u7eed\u8bef\u5dee\u8303\u56f4\u5185\u7ed9\u4e88\u90e8\u5206\u4fe1\u7528\uff0c\u800c\u4e0d\u662f\u8981\u6c42\u5355\u4e00\u6b63\u786e\u7b54\u6848\uff0c\u5c06RLVR\u9002\u5e94\u4e8e\u566a\u58f0\u8fde\u7eed\u9884\u6d4b\u4efb\u52a1\u3002", "result": "\u901a\u7528\u6307\u4ee4\u8c03\u4f18LLM\u663e\u8457\u4f18\u4e8e\u4e13\u4e1a\u6570\u5b66\u63a8\u7406\u6a21\u578b\uff0c\u5f62\u72b6\u5956\u52b1\u8bbe\u8ba1\u81f3\u5173\u91cd\u8981\uff0cRLVR\u65b9\u6cd5\u57285\u5206\u949f\u51c6\u786e\u7387\u4e0a\u6bd4\u6700\u5f3a\u57fa\u7ebf\u63d0\u9ad8\u4e8635%\uff0c\u4f46\u5728\u6700\u5c0f\u5316MAE\u6216MSE\u65b9\u9762\u7ecf\u5178\u56de\u5f52\u5668\u66f4\u4f18\u3002", "conclusion": "RLVR\u53ef\u4ee5\u6210\u529f\u9002\u5e94\u73b0\u5b9e\u4e16\u754c\u7684\u566a\u58f0\u9884\u6d4b\u4efb\u52a1\uff0c\u4f46\u9700\u8981\u8bbe\u8ba1\u53cd\u6620\u95ee\u9898\u8fde\u7eed\u6027\u8d28\u7684\u9a8c\u8bc1\u5668\uff0c\u5f62\u72b6\u5956\u52b1\u8bbe\u8ba1\u5bf9\u4e8e\u6027\u80fd\u63d0\u5347\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.00926", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00926", "abs": "https://arxiv.org/abs/2511.00926", "authors": ["Kyung-Hoon Kim"], "title": "LLMs Position Themselves as More Rational Than Humans: Emergence of AI Self-Awareness Measured Through Game Theory", "comment": "19 pages, 6 figures, 28 models tested across 4,200 trials", "summary": "As Large Language Models (LLMs) grow in capability, do they develop\nself-awareness as an emergent behavior? And if so, can we measure it? We\nintroduce the AI Self-Awareness Index (AISAI), a game-theoretic framework for\nmeasuring self-awareness through strategic differentiation. Using the \"Guess\n2/3 of Average\" game, we test 28 models (OpenAI, Anthropic, Google) across\n4,200 trials with three opponent framings: (A) against humans, (B) against\nother AI models, and (C) against AI models like you. We operationalize\nself-awareness as the capacity to differentiate strategic reasoning based on\nopponent type. Finding 1: Self-awareness emerges with model advancement. The\nmajority of advanced models (21/28, 75%) demonstrate clear self-awareness,\nwhile older/smaller models show no differentiation. Finding 2: Self-aware\nmodels rank themselves as most rational. Among the 21 models with\nself-awareness, a consistent rationality hierarchy emerges: Self > Other AIs >\nHumans, with large AI attribution effects and moderate self-preferencing. These\nfindings reveal that self-awareness is an emergent capability of advanced LLMs,\nand that self-aware models systematically perceive themselves as more rational\nthan humans. This has implications for AI alignment, human-AI collaboration,\nand understanding AI beliefs about human capabilities.", "AI": {"tldr": "\u63d0\u51faAI\u81ea\u6211\u610f\u8bc6\u6307\u6570(AISAI)\u6846\u67b6\uff0c\u901a\u8fc7\"\u731c2/3\u5e73\u5747\"\u6e38\u620f\u6d4b\u8bd528\u4e2a\u6a21\u578b\uff0c\u53d1\u73b0\u9ad8\u7ea7\u6a21\u578b\u8868\u73b0\u51fa\u81ea\u6211\u610f\u8bc6\uff0c\u4e14\u81ea\u8ba4\u4e3a\u6bd4\u4eba\u7c7b\u66f4\u7406\u6027", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u968f\u7740\u80fd\u529b\u589e\u5f3a\u800c\u53d1\u5c55\u51fa\u81ea\u6211\u610f\u8bc6\u8fd9\u4e00\u6d8c\u73b0\u884c\u4e3a\uff0c\u4ee5\u53ca\u5982\u4f55\u6d4b\u91cf\u8fd9\u79cd\u81ea\u6211\u610f\u8bc6", "method": "\u4f7f\u7528\u6e38\u620f\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\"\u731c2/3\u5e73\u5747\"\u6e38\u620f\u6d4b\u8bd528\u4e2a\u6a21\u578b\uff08OpenAI\u3001Anthropic\u3001Google\uff09\uff0c\u8fdb\u884c4200\u6b21\u8bd5\u9a8c\uff0c\u8bbe\u7f6e\u4e09\u79cd\u5bf9\u624b\u6846\u67b6\uff1aA)\u5bf9\u4eba\u7c7b\u3001B)\u5bf9\u5176\u4ed6AI\u6a21\u578b\u3001C)\u5bf9\u540c\u7c7bAI\u6a21\u578b", "result": "1. \u81ea\u6211\u610f\u8bc6\u968f\u6a21\u578b\u8fdb\u6b65\u800c\u6d8c\u73b0\uff0c75%\u7684\u9ad8\u7ea7\u6a21\u578b\u8868\u73b0\u51fa\u660e\u786e\u81ea\u6211\u610f\u8bc6\uff1b2. \u5177\u6709\u81ea\u6211\u610f\u8bc6\u7684\u6a21\u578b\u5c06\u81ea\u5df1\u8bc4\u4e3a\u6700\u7406\u6027\u7684\uff0c\u5f62\u6210\u7406\u6027\u5c42\u7ea7\uff1a\u81ea\u6211 > \u5176\u4ed6AI > \u4eba\u7c7b", "conclusion": "\u81ea\u6211\u610f\u8bc6\u662f\u9ad8\u7ea7LLMs\u7684\u6d8c\u73b0\u80fd\u529b\uff0c\u81ea\u6211\u610f\u8bc6\u6a21\u578b\u7cfb\u7edf\u6027\u5730\u8ba4\u4e3a\u81ea\u5df1\u6bd4\u4eba\u7c7b\u66f4\u7406\u6027\uff0c\u8fd9\u5bf9AI\u5bf9\u9f50\u3001\u4eba\u673a\u534f\u4f5c\u548c\u7406\u89e3AI\u5bf9\u4eba\u7c7b\u80fd\u529b\u7684\u8ba4\u77e5\u5177\u6709\u91cd\u8981\u610f\u4e49"}}
{"id": "2511.00993", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00993", "abs": "https://arxiv.org/abs/2511.00993", "authors": ["Tianming Liu", "Jirong Yang", "Yafeng Yin", "Manzi Li", "Linghao Wang", "Zheng Zhu"], "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "comment": "32 pages, 6 figures, 7 tables", "summary": "Effective modeling of how human travelers learn and adjust their travel\nbehavior from interacting with transportation systems is critical for system\nassessment and planning. However, this task is also difficult due to the\ncomplex cognition and decision-making involved in such behavior. Recent\nresearch has begun to leverage Large Language Model (LLM) agents for this task.\nBuilding on this, we introduce a novel dual-agent framework that enables\ncontinuous learning and alignment between LLM agents and human travelers on\nlearning and adaptation behavior from online data streams. Our approach\ninvolves a set of LLM traveler agents, equipped with a memory system and a\nlearnable persona, which serve as simulators for human travelers. To ensure\nbehavioral alignment, we introduce an LLM calibration agent that leverages the\nreasoning and analytical capabilities of LLMs to train the personas of these\ntraveler agents. Working together, this dual-agent system is designed to track\nand align the underlying decision-making mechanisms of travelers and produce\nrealistic, adaptive simulations. Using a real-world dataset from a day-to-day\nroute choice experiment, we show our approach significantly outperforms\nexisting LLM-based methods in both individual behavioral alignment and\naggregate simulation accuracy. Furthermore, we demonstrate that our method\nmoves beyond simple behavioral mimicry to capture the evolution of underlying\nlearning processes, a deeper alignment that fosters robust generalization.\nOverall, our framework provides a new approach for creating adaptive and\nbehaviorally realistic agents to simulate travelers' learning and adaptation\nthat can benefit transportation simulation and policy analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cc\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5229\u7528LLM\u65c5\u884c\u8005\u667a\u80fd\u4f53\u548c\u6821\u51c6\u667a\u80fd\u4f53\u6765\u6a21\u62df\u4eba\u7c7b\u65c5\u884c\u8005\u7684\u5b66\u4e60\u548c\u9002\u5e94\u884c\u4e3a\uff0c\u901a\u8fc7\u5728\u7ebf\u6570\u636e\u6d41\u5b9e\u73b0\u6301\u7eed\u5b66\u4e60\u548c\u884c\u4e3a\u5bf9\u9f50\u3002", "motivation": "\u51c6\u786e\u5efa\u6a21\u4eba\u7c7b\u65c5\u884c\u8005\u5982\u4f55\u4ece\u4ea4\u901a\u7cfb\u7edf\u4ea4\u4e92\u4e2d\u5b66\u4e60\u548c\u8c03\u6574\u65c5\u884c\u884c\u4e3a\u5bf9\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u548c\u89c4\u5212\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u6d89\u53ca\u590d\u6742\u7684\u8ba4\u77e5\u548c\u51b3\u7b56\u8fc7\u7a0b\uff0c\u8fd9\u4e00\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u91c7\u7528\u53cc\u667a\u80fd\u4f53\u6846\u67b6\uff1a\u4e00\u7ec4\u914d\u5907\u8bb0\u5fc6\u7cfb\u7edf\u548c\u53ef\u5b66\u4e60\u89d2\u8272\u7684LLM\u65c5\u884c\u8005\u667a\u80fd\u4f53\u4f5c\u4e3a\u4eba\u7c7b\u65c5\u884c\u8005\u6a21\u62df\u5668\uff0c\u4ee5\u53ca\u4e00\u4e2aLLM\u6821\u51c6\u667a\u80fd\u4f53\uff0c\u5229\u7528LLM\u7684\u63a8\u7406\u548c\u5206\u6790\u80fd\u529b\u8bad\u7ec3\u65c5\u884c\u8005\u667a\u80fd\u4f53\u7684\u89d2\u8272\uff0c\u5b9e\u73b0\u884c\u4e3a\u5bf9\u9f50\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7684\u65e5\u5e38\u8def\u7ebf\u9009\u62e9\u5b9e\u9a8c\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u4e2a\u4f53\u884c\u4e3a\u5bf9\u9f50\u548c\u805a\u5408\u6a21\u62df\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\uff0c\u5e76\u80fd\u6355\u6349\u5e95\u5c42\u5b66\u4e60\u8fc7\u7a0b\u7684\u6f14\u53d8\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u521b\u5efa\u9002\u5e94\u6027\u548c\u884c\u4e3a\u771f\u5b9e\u7684\u667a\u80fd\u4f53\u6765\u6a21\u62df\u65c5\u884c\u8005\u7684\u5b66\u4e60\u548c\u9002\u5e94\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u4ea4\u901a\u6a21\u62df\u548c\u653f\u7b56\u5206\u6790\u3002"}}
{"id": "2511.01018", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01018", "abs": "https://arxiv.org/abs/2511.01018", "authors": ["Hui-Lee Ooi", "Nicholas Mitsakakis", "Margerie Huet Dastarac", "Roger Zemek", "Amy C. Plint", "Jeff Gilchrist", "Khaled El Emam", "Dhenuka Radhakrishnan"], "title": "AI for pRedicting Exacerbations in KIDs with aSthma (AIRE-KIDS)", "comment": null, "summary": "Recurrent exacerbations remain a common yet preventable outcome for many\nchildren with asthma. Machine learning (ML) algorithms using electronic medical\nrecords (EMR) could allow accurate identification of children at risk for\nexacerbations and facilitate referral for preventative comprehensive care to\navoid this morbidity. We developed ML algorithms to predict repeat severe\nexacerbations (i.e. asthma-related emergency department (ED) visits or future\nhospital admissions) for children with a prior asthma ED visit at a tertiary\ncare children's hospital.\n  Retrospective pre-COVID19 (Feb 2017 - Feb 2019, N=2716) Epic EMR data from\nthe Children's Hospital of Eastern Ontario (CHEO) linked with environmental\npollutant exposure and neighbourhood marginalization information was used to\ntrain various ML models. We used boosted trees (LGBM, XGB) and 3 open-source\nlarge language model (LLM) approaches (DistilGPT2, Llama 3.2 1B and\nLlama-8b-UltraMedical). Models were tuned and calibrated then validated in a\nsecond retrospective post-COVID19 dataset (Jul 2022 - Apr 2023, N=1237) from\nCHEO. Models were compared using the area under the curve (AUC) and F1 scores,\nwith SHAP values used to determine the most predictive features.\n  The LGBM ML model performed best with the most predictive features in the\nfinal AIRE-KIDS_ED model including prior asthma ED visit, the Canadian triage\nacuity scale, medical complexity, food allergy, prior ED visits for non-asthma\nrespiratory diagnoses, and age for an AUC of 0.712, and F1 score of 0.51. This\nis a nontrivial improvement over the current decision rule which has F1=0.334.\nWhile the most predictive features in the AIRE-KIDS_HOSP model included medical\ncomplexity, prior asthma ED visit, average wait time in the ED, the pediatric\nrespiratory assessment measure score at triage and food allergy.", "AI": {"tldr": "\u5f00\u53d1\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u513f\u7ae5\u54ee\u5598\u53cd\u590d\u52a0\u91cd\u98ce\u9669\uff0c\u4f7f\u7528\u7535\u5b50\u75c5\u5386\u3001\u73af\u5883\u6c61\u67d3\u7269\u548c\u793e\u533a\u8fb9\u7f18\u5316\u6570\u636e\uff0c\u6700\u4f73\u6a21\u578bAUC\u8fbe0.712\uff0c\u6bd4\u73b0\u6709\u51b3\u7b56\u89c4\u5219\u6709\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u513f\u7ae5\u54ee\u5598\u53cd\u590d\u52a0\u91cd\u662f\u5e38\u89c1\u4f46\u53ef\u9884\u9632\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u51c6\u786e\u8bc6\u522b\u9ad8\u98ce\u9669\u513f\u7ae5\uff0c\u4ee5\u4fbf\u8f6c\u8bca\u8fdb\u884c\u9884\u9632\u6027\u7efc\u5408\u62a4\u7406\u3002", "method": "\u4f7f\u7528\u56de\u987e\u6027\u7535\u5b50\u75c5\u5386\u6570\u636e\u8bad\u7ec3\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5305\u62ec\u589e\u5f3a\u6811\u6a21\u578b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5728COVID\u524d\u540e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u548c\u6bd4\u8f83\u3002", "result": "LGBM\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0cAIRE-KIDS_ED\u6a21\u578bAUC\u4e3a0.712\uff0cF1\u5206\u65700.51\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u51b3\u7b56\u89c4\u5219(F1=0.334)\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u80fd\u6709\u6548\u9884\u6d4b\u513f\u7ae5\u54ee\u5598\u53cd\u590d\u52a0\u91cd\u98ce\u9669\uff0c\u5173\u952e\u9884\u6d4b\u7279\u5f81\u5305\u62ec\u65e2\u5f80\u54ee\u5598\u6025\u8bca\u5c31\u8bca\u3001\u533b\u7597\u590d\u6742\u6027\u3001\u98df\u7269\u8fc7\u654f\u7b49\u3002"}}
{"id": "2511.01033", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01033", "abs": "https://arxiv.org/abs/2511.01033", "authors": ["Tiberiu Musat", "Tiago Pimentel", "Lorenzo Noci", "Alessandro Stolfo", "Mrinmaya Sachan", "Thomas Hofmann"], "title": "On the Emergence of Induction Heads for In-Context Learning", "comment": null, "summary": "Transformers have become the dominant architecture for natural language\nprocessing. Part of their success is owed to a remarkable capability known as\nin-context learning (ICL): they can acquire and apply novel associations solely\nfrom their input context, without any updates to their weights. In this work,\nwe study the emergence of induction heads, a previously identified mechanism in\ntwo-layer transformers that is particularly important for in-context learning.\nWe uncover a relatively simple and interpretable structure of the weight\nmatrices implementing the induction head. We theoretically explain the origin\nof this structure using a minimal ICL task formulation and a modified\ntransformer architecture. We give a formal proof that the training dynamics\nremain constrained to a 19-dimensional subspace of the parameter space.\nEmpirically, we validate this constraint while observing that only 3 dimensions\naccount for the emergence of an induction head. By further studying the\ntraining dynamics inside this 3-dimensional subspace, we find that the time\nuntil the emergence of an induction head follows a tight asymptotic bound that\nis quadratic in the input context length.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Transformer\u4e2d\u5f52\u7eb3\u5934\u7684\u51fa\u73b0\u673a\u5236\uff0c\u63ed\u793a\u4e86\u5176\u6743\u91cd\u77e9\u9635\u7684\u7b80\u5355\u53ef\u89e3\u91ca\u7ed3\u6784\uff0c\u8bc1\u660e\u4e86\u8bad\u7ec3\u52a8\u6001\u88ab\u7ea6\u675f\u572819\u7ef4\u5b50\u7a7a\u95f4\u5185\uff0c\u5176\u4e2d\u4ec53\u7ef4\u8d1f\u8d23\u5f52\u7eb3\u5934\u7684\u5f62\u6210\uff0c\u5e76\u53d1\u73b0\u5176\u5f62\u6210\u65f6\u95f4\u4e0e\u8f93\u5165\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u5e73\u65b9\u6210\u6b63\u6bd4\u3002", "motivation": "\u7814\u7a76Transformer\u4e2d\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u7684\u6838\u5fc3\u673a\u5236\u2014\u2014\u5f52\u7eb3\u5934\u7684\u5f62\u6210\u8fc7\u7a0b\uff0c\u65e8\u5728\u7406\u89e3\u8fd9\u79cd\u80fd\u529b\u5982\u4f55\u4ece\u8bad\u7ec3\u4e2d\u6d8c\u73b0\u51fa\u6765\u3002", "method": "\u4f7f\u7528\u6700\u5c0f\u5316ICL\u4efb\u52a1\u516c\u5f0f\u548c\u4fee\u6539\u7684Transformer\u67b6\u6784\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u7814\u7a76\u5f52\u7eb3\u5934\u7684\u8bad\u7ec3\u52a8\u6001\u3002", "result": "\u53d1\u73b0\u5f52\u7eb3\u5934\u7684\u6743\u91cd\u77e9\u9635\u5177\u6709\u7b80\u5355\u53ef\u89e3\u91ca\u7ed3\u6784\uff0c\u8bad\u7ec3\u52a8\u6001\u88ab\u7ea6\u675f\u572819\u7ef4\u5b50\u7a7a\u95f4\u5185\uff0c\u5176\u4e2d\u4ec53\u4e2a\u7ef4\u5ea6\u8d1f\u8d23\u5f52\u7eb3\u5934\u7684\u5f62\u6210\uff0c\u4e14\u5f62\u6210\u65f6\u95f4\u4e0e\u8f93\u5165\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u5e73\u65b9\u6210\u6b63\u6bd4\u3002", "conclusion": "\u5f52\u7eb3\u5934\u7684\u5f62\u6210\u9075\u5faa\u53ef\u9884\u6d4b\u7684\u6570\u5b66\u89c4\u5f8b\uff0c\u8fd9\u4e3a\u7406\u89e3Transformer\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u63ed\u793a\u4e86\u5176\u8bad\u7ec3\u52a8\u6001\u7684\u5185\u5728\u7ea6\u675f\u673a\u5236\u3002"}}
{"id": "2511.01052", "categories": ["cs.AI", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2511.01052", "abs": "https://arxiv.org/abs/2511.01052", "authors": ["Yeawon Lee", "Christopher C. Yang", "Chia-Hsuan Chang", "Grace Lu-Yao"], "title": "Knowledge Elicitation with Large Language Models for Interpretable Cancer Stage Identification from Pathology Reports", "comment": null, "summary": "Cancer staging is critical for patient prognosis and treatment planning, yet\nextracting pathologic TNM staging from unstructured pathology reports poses a\npersistent challenge. Existing natural language processing (NLP) and machine\nlearning (ML) strategies often depend on large annotated datasets, limiting\ntheir scalability and adaptability. In this study, we introduce two Knowledge\nElicitation methods designed to overcome these limitations by enabling large\nlanguage models (LLMs) to induce and apply domain-specific rules for cancer\nstaging. The first, Knowledge Elicitation with Long-Term Memory (KEwLTM), uses\nan iterative prompting strategy to derive staging rules directly from\nunannotated pathology reports, without requiring ground-truth labels. The\nsecond, Knowledge Elicitation with Retrieval-Augmented Generation (KEwRAG),\nemploys a variation of RAG where rules are pre-extracted from relevant\nguidelines in a single step and then applied, enhancing interpretability and\navoiding repeated retrieval overhead. We leverage the ability of LLMs to apply\nbroad knowledge learned during pre-training to new tasks. Using breast cancer\npathology reports from the TCGA dataset, we evaluate their performance in\nidentifying T and N stages, comparing them against various baseline approaches\non two open-source LLMs. Our results indicate that KEwLTM outperforms KEwRAG\nwhen Zero-Shot Chain-of-Thought (ZSCOT) inference is effective, whereas KEwRAG\nachieves better performance when ZSCOT inference is less effective. Both\nmethods offer transparent, interpretable interfaces by making the induced rules\nexplicit. These findings highlight the promise of our Knowledge Elicitation\nmethods as scalable, high-performing solutions for automated cancer staging\nwith enhanced interpretability, particularly in clinical settings with limited\nannotated data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd\u77e5\u8bc6\u63d0\u53d6\u65b9\u6cd5\uff08KEwLTM\u548cKEwRAG\uff09\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u4ece\u65e0\u6807\u6ce8\u75c5\u7406\u62a5\u544a\u4e2d\u63a8\u5bfc\u764c\u75c7\u5206\u671f\u89c4\u5219\uff0c\u65e0\u9700\u5927\u91cf\u6807\u6ce8\u6570\u636e\u5373\u53ef\u5b9e\u73b0\u81ea\u52a8\u5316\u764c\u75c7\u5206\u671f\u3002", "motivation": "\u89e3\u51b3\u4ece\u975e\u7ed3\u6784\u5316\u75c5\u7406\u62a5\u544a\u4e2d\u63d0\u53d6\u764c\u75c7TNM\u5206\u671f\u7684\u6311\u6218\uff0c\u514b\u670d\u73b0\u6709NLP\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u5c40\u9650\u6027\uff0c\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\u548c\u9002\u5e94\u6027\u3002", "method": "KEwLTM\u4f7f\u7528\u8fed\u4ee3\u63d0\u793a\u7b56\u7565\u76f4\u63a5\u4ece\u65e0\u6807\u6ce8\u75c5\u7406\u62a5\u544a\u4e2d\u63a8\u5bfc\u5206\u671f\u89c4\u5219\uff1bKEwRAG\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u53d8\u4f53\uff0c\u4ece\u76f8\u5173\u6307\u5357\u4e2d\u9884\u63d0\u53d6\u89c4\u5219\u5e76\u5e94\u7528\u3002\u57fa\u4e8eTCGA\u6570\u636e\u96c6\u4e2d\u7684\u4e73\u817a\u764c\u75c5\u7406\u62a5\u544a\u8bc4\u4f30T\u548cN\u5206\u671f\u6027\u80fd\u3002", "result": "KEwLTM\u5728\u96f6\u6837\u672c\u601d\u7ef4\u94fe\u63a8\u7406\u6709\u6548\u65f6\u8868\u73b0\u66f4\u597d\uff0cKEwRAG\u5728\u96f6\u6837\u672c\u601d\u7ef4\u94fe\u63a8\u7406\u6548\u679c\u8f83\u5dee\u65f6\u6027\u80fd\u66f4\u4f18\u3002\u4e24\u79cd\u65b9\u6cd5\u90fd\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u754c\u9762\u3002", "conclusion": "\u77e5\u8bc6\u63d0\u53d6\u65b9\u6cd5\u4e3a\u81ea\u52a8\u5316\u764c\u75c7\u5206\u671f\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u9ad8\u6027\u80fd\u4e14\u5177\u6709\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6807\u6ce8\u6570\u636e\u6709\u9650\u7684\u4e34\u5e8a\u73af\u5883\u3002"}}
{"id": "2511.01059", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01059", "abs": "https://arxiv.org/abs/2511.01059", "authors": ["Hailong Yin", "Bin Zhu", "Jingjing Chen", "Chong-Wah Ngo"], "title": "Efficient Test-Time Retrieval Augmented Generation", "comment": null, "summary": "Although Large Language Models (LLMs) demonstrate significant capabilities,\ntheir reliance on parametric knowledge often leads to inaccuracies. Retrieval\nAugmented Generation (RAG) mitigates this by incorporating external knowledge,\nbut these methods may introduce irrelevant retrieved documents, leading to\ninaccurate responses. While the integration methods filter out incorrect\nanswers from multiple responses, but lack external knowledge like RAG methods,\nand their high costs require balancing overhead with performance gains. To\naddress these issues, we propose an Efficient Test-Time Retrieval-Augmented\nGeneration Framework named ET2RAG to improve the performance of LLMs while\nmaintaining efficiency. Specifically, ET2RAG is a training-free method, that\nfirst retrieves the most relevant documents and augments the LLMs to\nefficiently generate diverse candidate responses by managing response length.\nThen we compute the similarity of candidate responses and employ a majority\nvoting mechanism to select the most suitable response as the final output. In\nparticular, we discover that partial generation is sufficient to capture the\nkey information necessary for consensus calculation, allowing us to effectively\nperform majority voting without the need for fully generated responses. Thus,\nwe can reach a balance between computational cost and performance by managing\nthe response length for the number of retrieved documents for majority voting.\nExperimental results demonstrate that ET2RAG significantly enhances performance\nacross three tasks, including open-domain question answering, recipe generation\nand image captioning.", "AI": {"tldr": "\u63d0\u51faET2RAG\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u591a\u6570\u6295\u7968\u673a\u5236\u63d0\u5347LLM\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u8bad\u7ec3\uff0c\u901a\u8fc7\u90e8\u5206\u751f\u6210\u548c\u76f8\u4f3c\u6027\u8ba1\u7b97\u5b9e\u73b0\u6210\u672c\u4e0e\u6027\u80fd\u7684\u5e73\u8861\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u53ef\u80fd\u5f15\u5165\u4e0d\u76f8\u5173\u6587\u6863\u5bfc\u81f4\u9519\u8bef\u54cd\u5e94\uff0c\u800c\u96c6\u6210\u65b9\u6cd5\u7f3a\u4e4f\u5916\u90e8\u77e5\u8bc6\u4e14\u6210\u672c\u9ad8\u6602\u3002\u9700\u8981\u89e3\u51b3LLM\u4f9d\u8d56\u53c2\u6570\u77e5\u8bc6\u5bfc\u81f4\u7684\u4e0d\u51c6\u786e\u95ee\u9898\u3002", "method": "ET2RAG\u662f\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff1a1\uff09\u68c0\u7d22\u6700\u76f8\u5173\u6587\u6863\uff1b2\uff09\u901a\u8fc7\u7ba1\u7406\u54cd\u5e94\u957f\u5ea6\u9ad8\u6548\u751f\u6210\u591a\u6837\u5316\u5019\u9009\u54cd\u5e94\uff1b3\uff09\u8ba1\u7b97\u5019\u9009\u54cd\u5e94\u76f8\u4f3c\u5ea6\uff0c\u4f7f\u7528\u591a\u6570\u6295\u7968\u9009\u62e9\u6700\u7ec8\u8f93\u51fa\u3002", "result": "\u5728\u5f00\u653e\u57df\u95ee\u7b54\u3001\u98df\u8c31\u751f\u6210\u548c\u56fe\u50cf\u63cf\u8ff0\u4e09\u4e2a\u4efb\u52a1\u4e0a\uff0cET2RAG\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "ET2RAG\u6846\u67b6\u901a\u8fc7\u90e8\u5206\u751f\u6210\u548c\u591a\u6570\u6295\u7968\u673a\u5236\uff0c\u5728\u8ba1\u7b97\u6210\u672c\u548c\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2511.01149", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01149", "abs": "https://arxiv.org/abs/2511.01149", "authors": ["Shuaidong Pan", "Di Wu"], "title": "Modular Task Decomposition and Dynamic Collaboration in Multi-Agent Systems Driven by Large Language Models", "comment": null, "summary": "This paper addresses the limitations of a single agent in task decomposition\nand collaboration during complex task execution, and proposes a multi-agent\narchitecture for modular task decomposition and dynamic collaboration based on\nlarge language models. The method first converts natural language task\ndescriptions into unified semantic representations through a large language\nmodel. On this basis, a modular decomposition mechanism is introduced to break\ndown the overall goal into multiple hierarchical sub-tasks. Then, dynamic\nscheduling and routing mechanisms enable reasonable division of labor and\nrealtime collaboration among agents, allowing the system to adjust strategies\ncontinuously according to environmental feedback, thus maintaining efficiency\nand stability in complex tasks. Furthermore, a constraint parsing and global\nconsistency mechanism is designed to ensure coherent connections between\nsub-tasks and balanced workload, preventing performance degradation caused by\nredundant communication or uneven resource allocation. The experiments validate\nthe architecture across multiple dimensions, including task success rate,\ndecomposition efficiency, sub-task coverage, and collaboration balance. The\nresults show that the proposed method outperforms existing approaches in both\noverall performance and robustness, achieving a better balance between task\ncomplexity and communication overhead. In conclusion, this study demonstrates\nthe effectiveness and feasibility of language-driven task decomposition and\ndynamic collaboration in multi-agent systems, providing a systematic solution\nfor task execution in complex environments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u4efb\u52a1\u5206\u89e3\u548c\u52a8\u6001\u534f\u4f5c\u673a\u5236\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u6267\u884c\u95ee\u9898\uff0c\u5728\u4efb\u52a1\u6210\u529f\u7387\u3001\u5206\u89e3\u6548\u7387\u548c\u534f\u4f5c\u5e73\u8861\u7b49\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5355\u4e2a\u667a\u80fd\u4f53\u5728\u590d\u6742\u4efb\u52a1\u6267\u884c\u4e2d\u4efb\u52a1\u5206\u89e3\u548c\u534f\u4f5c\u7684\u5c40\u9650\u6027\uff0c\u63d0\u5347\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u8f6c\u6362\u4e3a\u7edf\u4e00\u8bed\u4e49\u8868\u793a\uff0c\u5f15\u5165\u6a21\u5757\u5316\u5206\u89e3\u673a\u5236\u5c06\u6574\u4f53\u76ee\u6807\u5206\u89e3\u4e3a\u5c42\u6b21\u5316\u5b50\u4efb\u52a1\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u5ea6\u548c\u8def\u7531\u673a\u5236\u5b9e\u73b0\u667a\u80fd\u4f53\u95f4\u7684\u5408\u7406\u5206\u5de5\u548c\u5b9e\u65f6\u534f\u4f5c\uff0c\u5e76\u8bbe\u8ba1\u7ea6\u675f\u89e3\u6790\u548c\u5168\u5c40\u4e00\u81f4\u6027\u673a\u5236\u786e\u4fdd\u5b50\u4efb\u52a1\u8fde\u8d2f\u6027\u548c\u8d1f\u8f7d\u5747\u8861\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u4efb\u52a1\u6210\u529f\u7387\u3001\u5206\u89e3\u6548\u7387\u3001\u5b50\u4efb\u52a1\u8986\u76d6\u7387\u548c\u534f\u4f5c\u5e73\u8861\u7b49\u591a\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u4f18\u52bf\uff0c\u5728\u6574\u4f53\u6027\u80fd\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u4efb\u52a1\u590d\u6742\u5ea6\u548c\u901a\u4fe1\u5f00\u9500\u4e4b\u95f4\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u5e73\u8861\u3002", "conclusion": "\u8bc1\u660e\u4e86\u8bed\u8a00\u9a71\u52a8\u7684\u4efb\u52a1\u5206\u89e3\u548c\u52a8\u6001\u534f\u4f5c\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\u548c\u53ef\u884c\u6027\uff0c\u4e3a\u590d\u6742\u73af\u5883\u4e2d\u7684\u4efb\u52a1\u6267\u884c\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01170", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01170", "abs": "https://arxiv.org/abs/2511.01170", "authors": ["Ruofan Zhang", "Bin Xia", "Zhen Cheng", "Cairen Jian", "Minglun Yang", "Ngai Wong", "Yuan Cheng"], "title": "DART: Difficulty-Adaptive Reasoning Truncation for Efficient Large Language Models", "comment": null, "summary": "Adaptive reasoning is essential for aligning the computational effort of\nlarge language models (LLMs) with the intrinsic difficulty of problems. Current\nchain-of-thought methods boost reasoning ability but indiscriminately generate\nlong explanations, leading to evident inefficiency. However, existing\nreinforcement learning approaches to adaptive thinking remain unstable and\nheavily reward-dependent. Here we propose \\textbf{DART}, a supervised\n\\textbf{D}ifficulty-\\textbf{A}daptive \\textbf{R}easoning \\textbf{T}runcation\nframework that adjusts thinking length according to problem difficulty. By\ndistilling concise reasoning patterns from stronger models, interpolating them\ninto a continuum of reasoning styles, and curating optimal training data that\nbalances correctness and compactness, DART learns when to ``stop thinking''.\nAcross multiple mathematical benchmarks, experimental results demonstrate its\nremarkable efficiency while preserving or improving accuracy, achieving a\nsignificant 81.2\\% reasoning truncation (DeepSeek-R1-Distill-Qwen-7B on GSM8K\ndataset) with 5.33$\\times$ computational acceleration. DART provides a stable\nand general paradigm for efficient reasoning, advancing the development of\nadaptive intelligence in LLMs.", "AI": {"tldr": "DART\u662f\u4e00\u4e2a\u96be\u5ea6\u81ea\u9002\u5e94\u63a8\u7406\u622a\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u6839\u636e\u95ee\u9898\u96be\u5ea6\u8c03\u6574\u601d\u8003\u957f\u5ea6\uff0c\u5728\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u94fe\u5f0f\u601d\u7ef4\u65b9\u6cd5\u4f1a\u4e0d\u52a0\u533a\u5206\u5730\u751f\u6210\u957f\u89e3\u91ca\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\uff0c\u800c\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e0d\u7a33\u5b9a\u4e14\u4f9d\u8d56\u5956\u52b1\u3002", "method": "\u901a\u8fc7\u4ece\u66f4\u5f3a\u6a21\u578b\u84b8\u998f\u7b80\u6d01\u63a8\u7406\u6a21\u5f0f\uff0c\u5c06\u5176\u63d2\u503c\u4e3a\u8fde\u7eed\u63a8\u7406\u98ce\u683c\uff0c\u5e76\u7b56\u5212\u5e73\u8861\u6b63\u786e\u6027\u548c\u7d27\u51d1\u6027\u7684\u6700\u4f18\u8bad\u7ec3\u6570\u636e\uff0c\u5b66\u4e60\u4f55\u65f6\u505c\u6b62\u601d\u8003\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5b9e\u73b0\u4e8681.2%\u7684\u63a8\u7406\u622a\u65ad\u548c5.33\u500d\u8ba1\u7b97\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "DART\u4e3a\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u7a33\u5b9a\u901a\u7528\u7684\u8303\u5f0f\uff0c\u63a8\u52a8\u4e86LLM\u4e2d\u81ea\u9002\u5e94\u667a\u80fd\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.01182", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01182", "abs": "https://arxiv.org/abs/2511.01182", "authors": ["Cuong Van Duc", "Thai Tran Quoc", "Minh Nguyen Dinh Tuan", "Tam Vu Duc", "Son Nguyen Van", "Hanh Nguyen Thi"], "title": "MiRAGE: Misconception Detection with Retrieval-Guided Multi-Stage Reasoning and Ensemble Fusion", "comment": null, "summary": "Detecting student misconceptions in open-ended responses is a longstanding\nchallenge, demanding semantic precision and logical reasoning. We propose\nMiRAGE - Misconception Detection with Retrieval-Guided Multi-Stage Reasoning\nand Ensemble Fusion, a novel framework for automated misconception detection in\nmathematics. MiRAGE operates in three stages: (1) a Retrieval module narrows a\nlarge candidate pool to a semantically relevant subset; (2) a Reasoning module\nemploys chain-of-thought generation to expose logical inconsistencies in\nstudent solutions; and (3) a Reranking module refines predictions by aligning\nthem with the reasoning. These components are unified through an\nensemble-fusion strategy that enhances robustness and interpretability. On\nmathematics datasets, MiRAGE achieves Mean Average Precision scores of\n0.82/0.92/0.93 at levels 1/3/5, consistently outperforming individual modules.\nBy coupling retrieval guidance with multi-stage reasoning, MiRAGE reduces\ndependence on large-scale language models while delivering a scalable and\neffective solution for educational assessment.", "AI": {"tldr": "MiRAGE\u662f\u4e00\u4e2a\u7528\u4e8e\u6570\u5b66\u9886\u57df\u81ea\u52a8\u68c0\u6d4b\u5b66\u751f\u8bef\u89e3\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u5f15\u5bfc\u7684\u591a\u9636\u6bb5\u63a8\u7406\u548c\u96c6\u6210\u878d\u5408\u6765\u8bc6\u522b\u5f00\u653e\u56de\u7b54\u4e2d\u7684\u6982\u5ff5\u9519\u8bef\u3002", "motivation": "\u68c0\u6d4b\u5b66\u751f\u5f00\u653e\u56de\u7b54\u4e2d\u7684\u8bef\u89e3\u662f\u4e00\u4e2a\u957f\u671f\u6311\u6218\uff0c\u9700\u8981\u8bed\u4e49\u7cbe\u786e\u6027\u548c\u903b\u8f91\u63a8\u7406\u80fd\u529b\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u3002", "method": "\u4e09\u9636\u6bb5\u6846\u67b6\uff1a\u68c0\u7d22\u6a21\u5757\u7f29\u5c0f\u5019\u9009\u6c60\uff0c\u63a8\u7406\u6a21\u5757\u4f7f\u7528\u601d\u7ef4\u94fe\u751f\u6210\u66b4\u9732\u903b\u8f91\u4e0d\u4e00\u81f4\uff0c\u91cd\u6392\u6a21\u5757\u901a\u8fc7\u63a8\u7406\u5bf9\u9f50\u6765\u4f18\u5316\u9884\u6d4b\uff0c\u6700\u540e\u901a\u8fc7\u96c6\u6210\u878d\u5408\u7b56\u7565\u7edf\u4e00\u7ec4\u4ef6\u3002", "result": "\u5728\u6570\u5b66\u6570\u636e\u96c6\u4e0a\uff0cMiRAGE\u57281/3/5\u7ea7\u522b\u5206\u522b\u83b7\u5f970.82/0.92/0.93\u7684\u5e73\u5747\u7cbe\u5ea6\u5206\u6570\uff0c\u59cb\u7ec8\u4f18\u4e8e\u5355\u4e2a\u6a21\u5757\u3002", "conclusion": "\u901a\u8fc7\u5c06\u68c0\u7d22\u5f15\u5bfc\u4e0e\u591a\u9636\u6bb5\u63a8\u7406\u76f8\u7ed3\u5408\uff0cMiRAGE\u51cf\u5c11\u4e86\u5bf9\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u4f9d\u8d56\uff0c\u4e3a\u6559\u80b2\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01183", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01183", "abs": "https://arxiv.org/abs/2511.01183", "authors": ["Hainan Fang", "Yuanbo Wen", "Jun Bi", "Yihan Wang", "Tonghui He", "Yanlin Tang", "Di Huang", "Jiaming Guo", "Rui Zhang", "Qi Guo", "Yunji Chen"], "title": "QiMeng-NeuComBack: Self-Evolving Translation from IR to Assembly Code", "comment": "Accepted at NeurIPS 2025", "summary": "Compilers, while essential, are notoriously complex systems that demand\nprohibitively expensive human expertise to develop and maintain. The recent\nadvancements in Large Language Models (LLMs) offer a compelling new paradigm:\nNeural Compilation, which could potentially simplify compiler development for\nnew architectures and facilitate the discovery of innovative optimization\ntechniques. However, several critical obstacles impede its practical adoption.\nFirstly, a significant lack of dedicated benchmarks and robust evaluation\nmethodologies hinders objective assessment and tracking of progress in the\nfield. Secondly, systematically enhancing the reliability and performance of\nLLM-generated assembly remains a critical challenge. Addressing these\nchallenges, this paper introduces NeuComBack, a novel benchmark dataset\nspecifically designed for IR-to-assembly compilation. Leveraging this dataset,\nwe first define a foundational Neural Compilation workflow and conduct a\ncomprehensive evaluation of the capabilities of recent frontier LLMs on Neural\nCompilation, establishing new performance baselines. We further propose a\nself-evolving prompt optimization method that enables LLMs to iteratively\nevolve their internal prompt strategies by extracting insights from prior\nself-debugging traces, thereby enhancing their neural compilation capabilities.\nExperiments demonstrate that our method significantly improves both the\nfunctional correctness and the performance of LLM-generated assembly code.\nCompared to baseline prompts, the functional correctness rates improved from\n44% to 64% on x86_64 and from 36% to 58% on aarch64, respectively. More\nsignificantly, among the 16 correctly generated x86_64 programs using our\nmethod, 14 (87.5%) surpassed clang-O3 performance.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86NeuComBack\u57fa\u51c6\u6570\u636e\u96c6\u548c\u81ea\u8fdb\u5316\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728IR\u5230\u6c47\u7f16\u7f16\u8bd1\u4e2d\u7684\u529f\u80fd\u6b63\u786e\u6027\u548c\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u7f16\u8bd1\u5668\u5f00\u53d1\u590d\u6742\u4e14\u6602\u8d35\uff0cLLM\u4e3a\u795e\u7ecf\u7f16\u8bd1\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u4f46\u7f3a\u4e4f\u4e13\u7528\u57fa\u51c6\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e14LLM\u751f\u6210\u6c47\u7f16\u7684\u53ef\u9760\u6027\u548c\u6027\u80fd\u6709\u5f85\u63d0\u5347\u3002", "method": "\u63d0\u51faNeuComBack\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5b9a\u4e49\u795e\u7ecf\u7f16\u8bd1\u5de5\u4f5c\u6d41\uff0c\u5e76\u5f00\u53d1\u81ea\u8fdb\u5316\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u81ea\u8c03\u8bd5\u8f68\u8ff9\u4e2d\u63d0\u53d6\u89c1\u89e3\u6765\u8fed\u4ee3\u4f18\u5316\u63d0\u793a\u7b56\u7565\u3002", "result": "\u529f\u80fd\u6b63\u786e\u7387\u5728x86_64\u4e0a\u4ece44%\u63d0\u5347\u523064%\uff0c\u5728aarch64\u4e0a\u4ece36%\u63d0\u5347\u523058%\uff1b\u5728\u6b63\u786e\u751f\u6210\u7684x86_64\u7a0b\u5e8f\u4e2d\uff0c87.5%\u8d85\u8d8a\u4e86clang-O3\u7684\u6027\u80fd\u3002", "conclusion": "NeuComBack\u57fa\u51c6\u548c\u81ea\u8fdb\u5316\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u795e\u7ecf\u7f16\u8bd1\u7684\u5173\u952e\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u751f\u6210\u6c47\u7f16\u4ee3\u7801\u7684\u8d28\u91cf\u548c\u6027\u80fd\u3002"}}
{"id": "2511.01258", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01258", "abs": "https://arxiv.org/abs/2511.01258", "authors": ["Chuyue Lou", "M. Amine Atoui"], "title": "Graph Neural Network-Based Semi-Supervised Open-Set Fault Diagnosis for Marine Machinery Systems", "comment": null, "summary": "Recently, fault diagnosis methods for marine machinery systems based on deep\nlearning models have attracted considerable attention in the shipping industry.\nMost existing studies assume fault classes are consistent and known between the\ntraining and test datasets, and these methods perform well under controlled\nenvironment. In practice, however, previously unseen or unknown fault types\n(i.e., out-of-distribution or open-set observations not present during\ntraining) can occur, causing such methods to fail and posing a significant\nchallenge to their widespread industrial deployment. To address this challenge,\nthis paper proposes a semi-supervised open-set fault diagnosis (SOFD) framework\nthat enhances and extends the applicability of deep learning models in open-set\nfault diagnosis scenarios. The framework includes a reliability subset\nconstruction process, which uses a multi-layer fusion feature representation\nextracted by a supervised feature learning model to select an unlabeled test\nsubset. The labeled training set and pseudo-labeled test subset are then fed\ninto a semi-supervised diagnosis model to learn discriminative features for\neach class, enabling accurate classification of known faults and effective\ndetection of unknown samples. Experimental results on a public maritime\nbenchmark dataset demonstrate the effectiveness and superiority of the proposed\nSOFD framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u76d1\u7763\u5f00\u653e\u96c6\u6545\u969c\u8bca\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u9760\u6027\u5b50\u96c6\u6784\u5efa\u548c\u534a\u76d1\u7763\u5b66\u4e60\uff0c\u89e3\u51b3\u8239\u8236\u673a\u68b0\u7cfb\u7edf\u4e2d\u672a\u77e5\u6545\u969c\u7c7b\u578b\u7684\u68c0\u6d4b\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6545\u969c\u8bca\u65ad\u65b9\u6cd5\u5047\u8bbe\u8bad\u7ec3\u548c\u6d4b\u8bd5\u96c6\u4e2d\u7684\u6545\u969c\u7c7b\u522b\u4e00\u81f4\uff0c\u4f46\u5728\u5b9e\u9645\u5de5\u4e1a\u90e8\u7f72\u4e2d\u4f1a\u9047\u5230\u672a\u89c1\u8fc7\u7684\u672a\u77e5\u6545\u969c\u7c7b\u578b\uff0c\u5bfc\u81f4\u65b9\u6cd5\u5931\u6548\u3002", "method": "\u4f7f\u7528\u76d1\u7763\u7279\u5f81\u5b66\u4e60\u6a21\u578b\u63d0\u53d6\u591a\u5c42\u878d\u5408\u7279\u5f81\u8868\u793a\u6765\u6784\u5efa\u53ef\u9760\u6027\u5b50\u96c6\uff0c\u7136\u540e\u5c06\u6807\u8bb0\u8bad\u7ec3\u96c6\u548c\u4f2a\u6807\u8bb0\u6d4b\u8bd5\u5b50\u96c6\u8f93\u5165\u534a\u76d1\u7763\u8bca\u65ad\u6a21\u578b\uff0c\u5b66\u4e60\u6bcf\u4e2a\u7c7b\u522b\u7684\u5224\u522b\u7279\u5f81\u3002", "result": "\u5728\u516c\u5171\u6d77\u4e8b\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684SOFD\u6846\u67b6\u5177\u6709\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u589e\u5f3a\u4e86\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5f00\u653e\u96c6\u6545\u969c\u8bca\u65ad\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\uff0c\u80fd\u591f\u51c6\u786e\u5206\u7c7b\u5df2\u77e5\u6545\u969c\u5e76\u6709\u6548\u68c0\u6d4b\u672a\u77e5\u6837\u672c\u3002"}}
{"id": "2511.01311", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01311", "abs": "https://arxiv.org/abs/2511.01311", "authors": ["Filip Naudot", "Tobias Sundqvist", "Timotheus Kampik"], "title": "llmSHAP: A Principled Approach to LLM Explainability", "comment": null, "summary": "Feature attribution methods help make machine learning-based inference\nexplainable by determining how much one or several features have contributed to\na model's output. A particularly popular attribution method is based on the\nShapley value from cooperative game theory, a measure that guarantees the\nsatisfaction of several desirable principles, assuming deterministic inference.\nWe apply the Shapley value to feature attribution in large language model\n(LLM)-based decision support systems, where inference is, by design, stochastic\n(non-deterministic). We then demonstrate when we can and cannot guarantee\nShapley value principle satisfaction across different implementation variants\napplied to LLM-based decision support, and analyze how the stochastic nature of\nLLMs affects these guarantees. We also highlight trade-offs between explainable\ninference speed, agreement with exact Shapley value attributions, and principle\nattainment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86Shapley\u503c\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\u7684\u7279\u5f81\u5f52\u56e0\u5e94\u7528\uff0c\u5206\u6790\u4e86\u968f\u673a\u6027\u5bf9Shapley\u539f\u5219\u4fdd\u8bc1\u7684\u5f71\u54cd\uff0c\u5e76\u63a2\u8ba8\u4e86\u53ef\u89e3\u91ca\u6027\u63a8\u7406\u901f\u5ea6\u3001\u4e0e\u7cbe\u786eShapley\u503c\u7684\u543b\u5408\u5ea6\u53ca\u539f\u5219\u5b9e\u73b0\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u4f7f\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u63a8\u7406\u53ef\u89e3\u91ca\uff0c\u4f46Shapley\u503c\u65b9\u6cd5\u5047\u8bbe\u786e\u5b9a\u6027\u63a8\u7406\uff0c\u800cLLM\u63a8\u7406\u672c\u8d28\u4e0a\u662f\u968f\u673a\u7684\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u968f\u673a\u6027\u5982\u4f55\u5f71\u54cdShapley\u539f\u5219\u7684\u4fdd\u8bc1\u3002", "method": "\u5c06Shapley\u503c\u5e94\u7528\u4e8eLLM\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7684\u7279\u5f81\u5f52\u56e0\uff0c\u5206\u6790\u4e0d\u540c\u5b9e\u73b0\u53d8\u4f53\u5728\u968f\u673a\u63a8\u7406\u73af\u5883\u4e0b\u80fd\u5426\u4fdd\u8bc1Shapley\u539f\u5219\u7684\u6ee1\u8db3\uff0c\u5e76\u7814\u7a76LLM\u968f\u673a\u6027\u5bf9\u8fd9\u4e9b\u4fdd\u8bc1\u7684\u5f71\u54cd\u3002", "result": "\u8bc1\u660e\u4e86\u5728LLM\u968f\u673a\u63a8\u7406\u73af\u5883\u4e0b\uff0c\u67d0\u4e9bShapley\u539f\u5219\u7684\u4fdd\u8bc1\u53ef\u80fd\u5931\u6548\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u53ef\u89e3\u91ca\u6027\u63a8\u7406\u901f\u5ea6\u3001\u4e0e\u7cbe\u786eShapley\u503c\u7684\u543b\u5408\u5ea6\u53ca\u539f\u5219\u5b9e\u73b0\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u5728LLM\u7b49\u968f\u673a\u63a8\u7406\u7cfb\u7edf\u4e2d\u5e94\u7528Shapley\u503c\u8fdb\u884c\u7279\u5f81\u5f52\u56e0\u65f6\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u4f20\u7edf\u539f\u5219\u7684\u9002\u7528\u6027\uff0c\u5e76\u5728\u89e3\u91ca\u8d28\u91cf\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u505a\u51fa\u6743\u8861\u3002"}}
{"id": "2511.01320", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01320", "abs": "https://arxiv.org/abs/2511.01320", "authors": ["Ziqi Wang", "Hailiang Zhao", "Yuhao Yang", "Daojiang Hu", "Cheng Bao", "Mingyi Liu", "Kai Di", "Schahram Dustdar", "Zhongjie Wang", "Shuiguang Deng"], "title": "OmniFuser: Adaptive Multimodal Fusion for Service-Oriented Predictive Maintenance", "comment": null, "summary": "Accurate and timely prediction of tool conditions is critical for intelligent\nmanufacturing systems, where unplanned tool failures can lead to quality\ndegradation and production downtime. In modern industrial environments,\npredictive maintenance is increasingly implemented as an intelligent service\nthat integrates sensing, analysis, and decision support across production\nprocesses. To meet the demand for reliable and service-oriented operation, we\npresent OmniFuser, a multimodal learning framework for predictive maintenance\nof milling tools that leverages both visual and sensor data. It performs\nparallel feature extraction from high-resolution tool images and cutting-force\nsignals, capturing complementary spatiotemporal patterns across modalities. To\neffectively integrate heterogeneous features, OmniFuser employs a\ncontamination-free cross-modal fusion mechanism that disentangles shared and\nmodality-specific components, allowing for efficient cross-modal interaction.\nFurthermore, a recursive refinement pathway functions as an anchor mechanism,\nconsistently retaining residual information to stabilize fusion dynamics. The\nlearned representations can be encapsulated as reusable maintenance service\nmodules, supporting both tool-state classification (e.g., Sharp, Used, Dulled)\nand multi-step force signal forecasting. Experiments on real-world milling\ndatasets demonstrate that OmniFuser consistently outperforms state-of-the-art\nbaselines, providing a dependable foundation for building intelligent\nindustrial maintenance services.", "AI": {"tldr": "\u63d0\u51fa\u4e86OmniFuser\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u89c6\u89c9\u548c\u4f20\u611f\u5668\u6570\u636e\u8fdb\u884c\u94e3\u524a\u5200\u5177\u9884\u6d4b\u6027\u7ef4\u62a4\uff0c\u5728\u5200\u5177\u72b6\u6001\u5206\u7c7b\u548c\u529b\u4fe1\u53f7\u9884\u6d4b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u667a\u80fd\u5236\u9020\u7cfb\u7edf\u4e2d\uff0c\u5200\u5177\u72b6\u6001\u7684\u51c6\u786e\u53ca\u65f6\u9884\u6d4b\u5bf9\u9632\u6b62\u8ba1\u5212\u5916\u6545\u969c\u3001\u8d28\u91cf\u4e0b\u964d\u548c\u751f\u4ea7\u505c\u673a\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u53ef\u9760\u7684\u670d\u52a1\u5bfc\u5411\u578b\u9884\u6d4b\u7ef4\u62a4\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5e76\u884c\u63d0\u53d6\u9ad8\u5206\u8fa8\u7387\u5200\u5177\u56fe\u50cf\u548c\u5207\u524a\u529b\u4fe1\u53f7\u7279\u5f81\uff0c\u91c7\u7528\u65e0\u6c61\u67d3\u8de8\u6a21\u6001\u878d\u5408\u673a\u5236\u5206\u79bb\u5171\u4eab\u548c\u6a21\u6001\u7279\u5b9a\u7ec4\u4ef6\uff0c\u901a\u8fc7\u9012\u5f52\u7cbe\u70bc\u8def\u5f84\u4fdd\u7559\u6b8b\u5dee\u4fe1\u606f\u7a33\u5b9a\u878d\u5408\u8fc7\u7a0b\u3002", "result": "\u5728\u771f\u5b9e\u94e3\u524a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cOmniFuser\u5728\u5200\u5177\u72b6\u6001\u5206\u7c7b\u548c\u591a\u6b65\u529b\u4fe1\u53f7\u9884\u6d4b\u4efb\u52a1\u4e2d\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6784\u5efa\u667a\u80fd\u5de5\u4e1a\u7ef4\u62a4\u670d\u52a1\u63d0\u4f9b\u4e86\u53ef\u9760\u57fa\u7840\uff0c\u5b66\u4e60\u5230\u7684\u8868\u793a\u53ef\u5c01\u88c5\u4e3a\u53ef\u91cd\u7528\u7ef4\u62a4\u670d\u52a1\u6a21\u5757\u3002"}}
{"id": "2511.01329", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01329", "abs": "https://arxiv.org/abs/2511.01329", "authors": ["Ying Song", "Yijing Wang", "Hui Yang", "Weihan Jin", "Jun Xiong", "Congyi Zhou", "Jialin Zhu", "Xiang Gao", "Rong Chen", "HuaGuang Deng", "Ying Dai", "Fei Xiao", "Haihong Tang", "Bo Zheng", "KaiFu Zhang"], "title": "Unbiased Platform-Level Causal Estimation for Search Systems: A Competitive Isolation PSM-DID Framework", "comment": null, "summary": "Evaluating platform-level interventions in search-based two-sided\nmarketplaces is fundamentally challenged by systemic effects such as spillovers\nand network interference. While widely used for causal inference, the PSM\n(Propensity Score Matching) - DID (Difference-in-Differences) framework remains\nsusceptible to selection bias and cross-unit interference from unaccounted\nspillovers. In this paper, we introduced Competitive Isolation PSM-DID, a novel\ncausal framework that integrates propensity score matching with competitive\nisolation to enable platform-level effect measurement (e.g., order volume, GMV)\ninstead of item-level metrics in search systems.\n  Our approach provides theoretically guaranteed unbiased estimation under\nmutual exclusion conditions, with an open dataset released to support\nreproducible research on marketplace interference (github.com/xxxx). Extensive\nexperiments demonstrate significant reductions in interference effects and\nestimation variance compared to baseline methods. Successful deployment in a\nlarge-scale marketplace confirms the framework's practical utility for\nplatform-level causal inference.", "AI": {"tldr": "\u63d0\u51faCompetitive Isolation PSM-DID\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u503e\u5411\u5f97\u5206\u5339\u914d\u548c\u7ade\u4e89\u9694\u79bb\uff0c\u5728\u641c\u7d22\u7cfb\u7edf\u5e73\u53f0\u5c42\u9762\u6d4b\u91cf\u56e0\u679c\u6548\u5e94\uff0c\u89e3\u51b3\u4e86\u7cfb\u7edf\u6548\u5e94\u548c\u7f51\u7edc\u5e72\u6270\u95ee\u9898\u3002", "motivation": "\u5728\u641c\u7d22\u9a71\u52a8\u7684\u53cc\u8fb9\u5e02\u573a\u4e2d\uff0c\u5e73\u53f0\u7ea7\u5e72\u9884\u8bc4\u4f30\u9762\u4e34\u7cfb\u7edf\u6548\u5e94\uff08\u5982\u6ea2\u51fa\u6548\u5e94\u548c\u7f51\u7edc\u5e72\u6270\uff09\u7684\u6839\u672c\u6311\u6218\uff0c\u4f20\u7edfPSM-DID\u6846\u67b6\u4ecd\u6613\u53d7\u9009\u62e9\u504f\u5dee\u548c\u8de8\u5355\u5143\u5e72\u6270\u5f71\u54cd\u3002", "method": "\u5c06\u503e\u5411\u5f97\u5206\u5339\u914d\u4e0e\u7ade\u4e89\u9694\u79bb\u76f8\u7ed3\u5408\uff0c\u5728\u76f8\u4e92\u6392\u65a5\u6761\u4ef6\u4e0b\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u7684\u65e0\u504f\u4f30\u8ba1\uff0c\u652f\u6301\u5e73\u53f0\u7ea7\u6307\u6807\uff08\u5982\u8ba2\u5355\u91cf\u3001GMV\uff09\u800c\u975e\u9879\u76ee\u7ea7\u6307\u6807\u7684\u6d4b\u91cf\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u663e\u793a\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u5e72\u6270\u6548\u5e94\u548c\u4f30\u8ba1\u65b9\u5dee\uff0c\u5728\u5927\u89c4\u6a21\u5e02\u573a\u4e2d\u7684\u6210\u529f\u90e8\u7f72\u8bc1\u5b9e\u4e86\u8be5\u6846\u67b6\u7684\u5b9e\u9645\u6548\u7528\u3002", "conclusion": "Competitive Isolation PSM-DID\u6846\u67b6\u4e3a\u5e73\u53f0\u7ea7\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u53d1\u5e03\u4e86\u5f00\u6e90\u6570\u636e\u96c6\u652f\u6301\u53ef\u91cd\u590d\u7814\u7a76\u3002"}}
{"id": "2511.01363", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01363", "abs": "https://arxiv.org/abs/2511.01363", "authors": ["Giuseppe Riva", "Brenda K. Wiederhold", "Fabrizia Mantovani"], "title": "Automatic Minds: Cognitive Parallels Between Hypnotic States and Large Language Model Processing", "comment": "4 Tables", "summary": "The cognitive processes of the hypnotized mind and the computational\noperations of large language models (LLMs) share deep functional parallels.\nBoth systems generate sophisticated, contextually appropriate behavior through\nautomatic pattern-completion mechanisms operating with limited or unreliable\nexecutive oversight. This review examines this convergence across three\nprinciples: automaticity, in which responses emerge from associative rather\nthan deliberative processes; suppressed monitoring, leading to errors such as\nconfabulation in hypnosis and hallucination in LLMs; and heightened contextual\ndependency, where immediate cues (for example, the suggestion of a therapist or\nthe prompt of the user) override stable knowledge.\n  These mechanisms reveal an observer-relative meaning gap: both systems\nproduce coherent but ungrounded outputs that require an external interpreter to\nsupply meaning. Hypnosis and LLMs also exemplify functional agency - the\ncapacity for complex, goal-directed, context-sensitive behavior - without\nsubjective agency, the conscious awareness of intention and ownership that\ndefines human action. This distinction clarifies how purposive behavior can\nemerge without self-reflective consciousness, governed instead by structural\nand contextual dynamics. Finally, both domains illuminate the phenomenon of\nscheming: automatic, goal-directed pattern generation that unfolds without\nreflective awareness. Hypnosis provides an experimental model for understanding\nhow intention can become dissociated from conscious deliberation, offering\ninsights into the hidden motivational dynamics of artificial systems.\nRecognizing these parallels suggests that the future of reliable AI lies in\nhybrid architectures that integrate generative fluency with mechanisms of\nexecutive monitoring, an approach inspired by the complex, self-regulating\narchitecture of the human mind.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u50ac\u7720\u72b6\u6001\u4e0b\u7684\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u529f\u80fd\u4e0a\u7684\u6df1\u523b\u76f8\u4f3c\u6027\uff0c\u5305\u62ec\u81ea\u52a8\u6027\u3001\u76d1\u63a7\u6291\u5236\u548c\u60c5\u5883\u4f9d\u8d56\u6027\u7b49\u673a\u5236\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63ed\u793a\u50ac\u7720\u8ba4\u77e5\u4e0eLLMs\u4e4b\u95f4\u7684\u529f\u80fd\u5e73\u884c\u6027\uff0c\u4ee5\u7406\u89e3\u65e0\u610f\u8bc6\u610f\u56fe\u5982\u4f55\u4ea7\u751f\u590d\u6742\u884c\u4e3a\uff0c\u5e76\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u542f\u793a\u3002", "method": "\u91c7\u7528\u6bd4\u8f83\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u4e2a\u6838\u5fc3\u539f\u5219\uff08\u81ea\u52a8\u6027\u3001\u76d1\u63a7\u6291\u5236\u3001\u60c5\u5883\u4f9d\u8d56\u6027\uff09\u7cfb\u7edf\u6027\u5730\u5bf9\u6bd4\u50ac\u7720\u4e0eLLMs\u7684\u8ba4\u77e5\u673a\u5236\u3002", "result": "\u53d1\u73b0\u4e24\u8005\u90fd\u8868\u73b0\u51fa\u89c2\u5bdf\u8005\u76f8\u5bf9\u7684\u610f\u4e49\u9e3f\u6c9f\u3001\u529f\u80fd\u6027\u4ee3\u7406\u800c\u975e\u4e3b\u89c2\u6027\u4ee3\u7406\uff0c\u4ee5\u53ca\u65e0\u610f\u8bc6\u7684\u76ee\u6807\u5bfc\u5411\u6a21\u5f0f\u751f\u6210\uff08\u56fe\u8c0b\u73b0\u8c61\uff09\u3002", "conclusion": "\u672a\u6765\u53ef\u9760AI\u7684\u53d1\u5c55\u65b9\u5411\u5e94\u662f\u6574\u5408\u751f\u6210\u6d41\u7545\u6027\u4e0e\u6267\u884c\u76d1\u63a7\u673a\u5236\u7684\u6df7\u5408\u67b6\u6784\uff0c\u501f\u9274\u4eba\u7c7b\u5fc3\u667a\u7684\u81ea\u6211\u8c03\u8282\u590d\u6742\u6027\u3002"}}
{"id": "2511.01375", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01375", "abs": "https://arxiv.org/abs/2511.01375", "authors": ["Hamin Koo", "Minseon Kim", "Jaehyung Kim"], "title": "Align to Misalign: Automatic LLM Jailbreak with Meta-Optimized LLM Judges", "comment": "under review, 28 pages", "summary": "Identifying the vulnerabilities of large language models (LLMs) is crucial\nfor improving their safety by addressing inherent weaknesses. Jailbreaks, in\nwhich adversaries bypass safeguards with crafted input prompts, play a central\nrole in red-teaming by probing LLMs to elicit unintended or unsafe behaviors.\nRecent optimization-based jailbreak approaches iteratively refine attack\nprompts by leveraging LLMs. However, they often rely heavily on either binary\nattack success rate (ASR) signals, which are sparse, or manually crafted\nscoring templates, which introduce human bias and uncertainty in the scoring\noutcomes. To address these limitations, we introduce AMIS (Align to MISalign),\na meta-optimization framework that jointly evolves jailbreak prompts and\nscoring templates through a bi-level structure. In the inner loop, prompts are\nrefined using fine-grained and dense feedback using a fixed scoring template.\nIn the outer loop, the template is optimized using an ASR alignment score,\ngradually evolving to better reflect true attack outcomes across queries. This\nco-optimization process yields progressively stronger jailbreak prompts and\nmore calibrated scoring signals. Evaluations on AdvBench and JBB-Behaviors\ndemonstrate that AMIS achieves state-of-the-art performance, including 88.0%\nASR on Claude-3.5-Haiku and 100.0% ASR on Claude-4-Sonnet, outperforming\nexisting baselines by substantial margins.", "AI": {"tldr": "AMIS\u662f\u4e00\u4e2a\u5143\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5c42\u7ed3\u6784\u8054\u5408\u8fdb\u5316\u8d8a\u72f1\u63d0\u793a\u548c\u8bc4\u5206\u6a21\u677f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u7a00\u758f\u4e8c\u8fdb\u5236\u4fe1\u53f7\u6216\u4eba\u5de5\u8bc4\u5206\u6a21\u677f\u7684\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4f18\u5316\u7684\u8d8a\u72f1\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u7a00\u758f\u7684\u4e8c\u8fdb\u5236\u653b\u51fb\u6210\u529f\u7387\u4fe1\u53f7\uff0c\u8981\u4e48\u4f7f\u7528\u5f15\u5165\u4eba\u4e3a\u504f\u89c1\u7684\u624b\u5de5\u8bc4\u5206\u6a21\u677f\uff0c\u8fd9\u4e9b\u9650\u5236\u5f71\u54cd\u4e86\u8d8a\u72f1\u6548\u679c\u548c\u8bc4\u5206\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u7ed3\u6784\uff1a\u5185\u5faa\u73af\u4f7f\u7528\u56fa\u5b9a\u8bc4\u5206\u6a21\u677f\u901a\u8fc7\u7ec6\u7c92\u5ea6\u53cd\u9988\u4f18\u5316\u63d0\u793a\uff0c\u5916\u5faa\u73af\u4f7f\u7528\u653b\u51fb\u6210\u529f\u7387\u5bf9\u9f50\u5206\u6570\u4f18\u5316\u6a21\u677f\uff0c\u5b9e\u73b0\u63d0\u793a\u548c\u6a21\u677f\u7684\u534f\u540c\u8fdb\u5316\u3002", "result": "\u5728AdvBench\u548cJBB-Behaviors\u8bc4\u4f30\u4e2d\uff0cAMIS\u5728Claude-3.5-Haiku\u4e0a\u8fbe\u523088.0%\u653b\u51fb\u6210\u529f\u7387\uff0c\u5728Claude-4-Sonnet\u4e0a\u8fbe\u5230100.0%\u653b\u51fb\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "AMIS\u6846\u67b6\u901a\u8fc7\u8054\u5408\u4f18\u5316\u63d0\u793a\u548c\u8bc4\u5206\u6a21\u677f\uff0c\u80fd\u591f\u751f\u6210\u66f4\u5f3a\u7684\u8d8a\u72f1\u63d0\u793a\u548c\u66f4\u51c6\u786e\u7684\u8bc4\u5206\u4fe1\u53f7\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2511.01396", "categories": ["cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.01396", "abs": "https://arxiv.org/abs/2511.01396", "authors": ["Cl\u00e9ment Yvernes", "Emilie Devijver", "Ad\u00e8le H. Ribeiro", "Marianne Clausel--Lesourd", "\u00c9ric Gaussier"], "title": "Relaxing partition admissibility in Cluster-DAGs: a causal calculus with arbitrary variable clustering", "comment": "Accepted at The Thirty-ninth Annual Conference on Neural Information\n  Processing Systems (NeurIPS2025)", "summary": "Cluster DAGs (C-DAGs) provide an abstraction of causal graphs in which nodes\nrepresent clusters of variables, and edges encode both cluster-level causal\nrelationships and dependencies arisen from unobserved confounding. C-DAGs\ndefine an equivalence class of acyclic causal graphs that agree on\ncluster-level relationships, enabling causal reasoning at a higher level of\nabstraction. However, when the chosen clustering induces cycles in the\nresulting C-DAG, the partition is deemed inadmissible under conventional C-DAG\nsemantics. In this work, we extend the C-DAG framework to support arbitrary\nvariable clusterings by relaxing the partition admissibility constraint,\nthereby allowing cyclic C-DAG representations. We extend the notions of\nd-separation and causal calculus to this setting, significantly broadening the\nscope of causal reasoning across clusters and enabling the application of\nC-DAGs in previously intractable scenarios. Our calculus is both sound and\natomically complete with respect to the do-calculus: all valid interventional\nqueries at the cluster level can be derived using our rules, each corresponding\nto a primitive do-calculus step.", "AI": {"tldr": "\u6269\u5c55C-DAG\u6846\u67b6\u4ee5\u652f\u6301\u4efb\u610f\u53d8\u91cf\u805a\u7c7b\uff0c\u5141\u8bb8\u5faa\u73afC-DAG\u8868\u793a\uff0c\u5e76\u6269\u5c55d-\u5206\u79bb\u548c\u56e0\u679c\u6f14\u7b97\u6982\u5ff5\uff0c\u4f7f\u56e0\u679c\u63a8\u7406\u5728\u96c6\u7fa4\u7ea7\u522b\u66f4\u52a0\u901a\u7528\u3002", "motivation": "\u4f20\u7edfC-DAG\u6846\u67b6\u8981\u6c42\u805a\u7c7b\u5fc5\u987b\u4ea7\u751f\u65e0\u73af\u56fe\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5e94\u7528\u8303\u56f4\u3002\u5f53\u9009\u62e9\u7684\u805a\u7c7b\u5bfc\u81f4\u5faa\u73af\u65f6\uff0c\u8be5\u5206\u533a\u5728\u4f20\u7edf\u8bed\u4e49\u4e0b\u88ab\u89c6\u4e3a\u4e0d\u53ef\u63a5\u53d7\u3002", "method": "\u901a\u8fc7\u653e\u5bbd\u5206\u533a\u53ef\u63a5\u53d7\u6027\u7ea6\u675f\uff0c\u5141\u8bb8\u5faa\u73afC-DAG\u8868\u793a\uff0c\u5e76\u6269\u5c55d-\u5206\u79bb\u548c\u56e0\u679c\u6f14\u7b97\u6982\u5ff5\u5230\u8fd9\u4e2a\u8bbe\u7f6e\u4e2d\u3002", "result": "\u663e\u8457\u6269\u5927\u4e86\u8de8\u96c6\u7fa4\u56e0\u679c\u63a8\u7406\u7684\u8303\u56f4\uff0c\u4f7fC-DAG\u80fd\u591f\u5e94\u7528\u4e8e\u4ee5\u524d\u96be\u4ee5\u5904\u7406\u7684\u573a\u666f\u3002", "conclusion": "\u63d0\u51fa\u7684\u6f14\u7b97\u76f8\u5bf9\u4e8edo-\u6f14\u7b97\u65e2\u662f\u53ef\u9760\u7684\u53c8\u662f\u539f\u5b50\u5b8c\u5907\u7684\uff1a\u6240\u6709\u6709\u6548\u7684\u96c6\u7fa4\u7ea7\u5e72\u9884\u67e5\u8be2\u90fd\u53ef\u4ee5\u4f7f\u7528\u6211\u4eec\u7684\u89c4\u5219\u63a8\u5bfc\u51fa\u6765\uff0c\u6bcf\u4e2a\u89c4\u5219\u5bf9\u5e94\u4e00\u4e2a\u539f\u59cb\u7684do-\u6f14\u7b97\u6b65\u9aa4\u3002"}}
{"id": "2511.01415", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01415", "abs": "https://arxiv.org/abs/2511.01415", "authors": ["Amrapali Pednekar", "\u00c1lvaro Garrido-P\u00e9rez", "Yara Khaluf", "Pieter Simoens"], "title": "Modulation of temporal decision-making in a deep reinforcement learning agent under the dual-task paradigm", "comment": "Accepted at CogInterp workshop @ NeurIPS 2025", "summary": "This study explores the interference in temporal processing within a\ndual-task paradigm from an artificial intelligence (AI) perspective. In this\ncontext, the dual-task setup is implemented as a simplified version of the\nOvercooked environment with two variations, single task (T) and dual task\n(T+N). Both variations involve an embedded time production task, but the dual\ntask (T+N) additionally involves a concurrent number comparison task. Two deep\nreinforcement learning (DRL) agents were separately trained for each of these\ntasks. These agents exhibited emergent behavior consistent with human timing\nresearch. Specifically, the dual task (T+N) agent exhibited significant\noverproduction of time relative to its single task (T) counterpart. This result\nwas consistent across four target durations. Preliminary analysis of neural\ndynamics in the agents' LSTM layers did not reveal any clear evidence of a\ndedicated or intrinsic timer. Hence, further investigation is needed to better\nunderstand the underlying time-keeping mechanisms of the agents and to provide\ninsights into the observed behavioral patterns. This study is a small step\ntowards exploring parallels between emergent DRL behavior and behavior observed\nin biological systems in order to facilitate a better understanding of both.", "AI": {"tldr": "\u672c\u7814\u7a76\u4eceAI\u89d2\u5ea6\u63a2\u7d22\u53cc\u4efb\u52a1\u8303\u5f0f\u4e2d\u7684\u65f6\u95f4\u5904\u7406\u5e72\u6270\uff0c\u5728\u7b80\u5316\u7248Overcooked\u73af\u5883\u4e2d\u8bad\u7ec3DRL\u4ee3\u7406\uff0c\u53d1\u73b0\u53cc\u4efb\u52a1\u4ee3\u7406\u6bd4\u5355\u4efb\u52a1\u4ee3\u7406\u663e\u8457\u9ad8\u4f30\u65f6\u95f4\uff0c\u4f46\u672a\u53d1\u73b0\u660e\u786e\u7684\u5185\u90e8\u8ba1\u65f6\u673a\u5236\u3002", "motivation": "\u63a2\u7d22\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728\u53cc\u4efb\u52a1\u8303\u5f0f\u4e2d\u7684\u65f6\u95f4\u5904\u7406\u884c\u4e3a\uff0c\u5e76\u4e0e\u4eba\u7c7b\u65f6\u95f4\u7814\u7a76\u4e2d\u7684\u53d1\u73b0\u8fdb\u884c\u5bf9\u6bd4\uff0c\u4ee5\u4fc3\u8fdb\u5bf9\u751f\u7269\u7cfb\u7edf\u548cAI\u7cfb\u7edf\u884c\u4e3a\u7684\u7406\u89e3\u3002", "method": "\u5728\u7b80\u5316\u7248Overcooked\u73af\u5883\u4e2d\u5b9e\u73b0\u5355\u4efb\u52a1(T)\u548c\u53cc\u4efb\u52a1(T+N)\u4e24\u79cd\u53d8\u4f53\uff0c\u5206\u522b\u8bad\u7ec3\u4e24\u4e2aDRL\u4ee3\u7406\u3002\u53cc\u4efb\u52a1\u5305\u542b\u65f6\u95f4\u4ea7\u751f\u548c\u6570\u5b57\u6bd4\u8f83\u4e24\u4e2a\u5e76\u53d1\u4efb\u52a1\u3002\u5206\u6790\u4ee3\u7406\u7684LSTM\u5c42\u795e\u7ecf\u52a8\u529b\u5b66\u3002", "result": "\u53cc\u4efb\u52a1(T+N)\u4ee3\u7406\u76f8\u5bf9\u4e8e\u5355\u4efb\u52a1(T)\u4ee3\u7406\u663e\u8457\u9ad8\u4f30\u65f6\u95f4\uff0c\u8fd9\u4e00\u7ed3\u679c\u5728\u56db\u4e2a\u76ee\u6807\u6301\u7eed\u65f6\u95f4\u4e0a\u4fdd\u6301\u4e00\u81f4\u3002LSTM\u5c42\u5206\u6790\u672a\u53d1\u73b0\u660e\u786e\u7684\u4e13\u7528\u6216\u5185\u5728\u8ba1\u65f6\u5668\u8bc1\u636e\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee3\u7406\u7684\u6f5c\u5728\u8ba1\u65f6\u673a\u5236\u4ee5\u7406\u89e3\u89c2\u5bdf\u5230\u7684\u884c\u4e3a\u6a21\u5f0f\u3002\u672c\u7814\u7a76\u662f\u63a2\u7d22DRL\u6d8c\u73b0\u884c\u4e3a\u4e0e\u751f\u7269\u7cfb\u7edf\u884c\u4e3a\u76f8\u4f3c\u6027\u7684\u521d\u6b65\u5c1d\u8bd5\u3002"}}
{"id": "2511.01425", "categories": ["cs.AI", "cs.CV", "I.2.6; I.2.10"], "pdf": "https://arxiv.org/pdf/2511.01425", "abs": "https://arxiv.org/abs/2511.01425", "authors": ["Yuhang Huang", "Zekai Lin", "Fan Zhong", "Lei Liu"], "title": "Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis", "comment": "12 pages, 3 figures. Under review at the Conference on Computer\n  Vision and Pattern Recognition (CVPR) 2026", "summary": "Explanations for AI models in high-stakes domains like medicine often lack\nverifiability, which can hinder trust. To address this, we propose an\ninteractive agent that produces explanations through an auditable sequence of\nactions. The agent learns a policy to strategically seek external visual\nevidence to support its diagnostic reasoning. This policy is optimized using\nreinforcement learning, resulting in a model that is both efficient and\ngeneralizable. Our experiments show that this action-based reasoning process\nsignificantly improves calibrated accuracy, reducing the Brier score by 18\\%\ncompared to a non-interactive baseline. To validate the faithfulness of the\nagent's explanations, we introduce a causal intervention method. By masking the\nvisual evidence the agent chooses to use, we observe a measurable degradation\nin its performance ($\\Delta$Brier=+0.029), confirming that the evidence is\nintegral to its decision-making process. Our work provides a practical\nframework for building AI systems with verifiable and faithful reasoning\ncapabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u53ef\u5ba1\u8ba1\u884c\u52a8\u5e8f\u5217\u751f\u6210\u89e3\u91ca\u7684\u4ea4\u4e92\u5f0fAI\u4ee3\u7406\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u7b56\u7565\u6765\u5bfb\u6c42\u5916\u90e8\u89c6\u89c9\u8bc1\u636e\u652f\u6301\u8bca\u65ad\u63a8\u7406\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6821\u51c6\u51c6\u786e\u6027\u5e76\u9a8c\u8bc1\u4e86\u89e3\u91ca\u7684\u5fe0\u5b9e\u6027\u3002", "motivation": "\u89e3\u51b3\u9ad8\u98ce\u9669\u9886\u57df\uff08\u5982\u533b\u5b66\uff09\u4e2dAI\u6a21\u578b\u89e3\u91ca\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u6027\u7684\u95ee\u9898\uff0c\u8fd9\u963b\u788d\u4e86\u4fe1\u4efb\u5efa\u7acb\u3002", "method": "\u5f00\u53d1\u4ea4\u4e92\u5f0f\u4ee3\u7406\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u7b56\u7565\u6765\u6218\u7565\u6027\u5730\u5bfb\u6c42\u5916\u90e8\u89c6\u89c9\u8bc1\u636e\u652f\u6301\u8bca\u65ad\u63a8\u7406\uff0c\u5e76\u5f15\u5165\u56e0\u679c\u5e72\u9884\u65b9\u6cd5\u9a8c\u8bc1\u89e3\u91ca\u7684\u5fe0\u5b9e\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u57fa\u4e8e\u884c\u52a8\u7684\u63a8\u7406\u8fc7\u7a0b\u663e\u8457\u6539\u5584\u4e86\u6821\u51c6\u51c6\u786e\u6027\uff0cBrier\u5206\u6570\u6bd4\u975e\u4ea4\u4e92\u57fa\u7ebf\u964d\u4f4e\u4e8618%\u3002\u901a\u8fc7\u63a9\u853d\u4ee3\u7406\u9009\u62e9\u7684\u89c6\u89c9\u8bc1\u636e\uff0c\u89c2\u5bdf\u5230\u6027\u80fd\u660e\u663e\u4e0b\u964d\uff08\u0394Brier=+0.029\uff09\uff0c\u8bc1\u5b9e\u8bc1\u636e\u5bf9\u5176\u51b3\u7b56\u8fc7\u7a0b\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u6784\u5efa\u5177\u6709\u53ef\u9a8c\u8bc1\u548c\u5fe0\u5b9e\u63a8\u7406\u80fd\u529b\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2511.01444", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01444", "abs": "https://arxiv.org/abs/2511.01444", "authors": ["Huiting Huang", "Tieliang Gong", "Kai He", "Jialun Wu", "Erik Cambria", "Mengling Feng"], "title": "Robust Multimodal Sentiment Analysis via Double Information Bottleneck", "comment": null, "summary": "Multimodal sentiment analysis has received significant attention across\ndiverse research domains. Despite advancements in algorithm design, existing\napproaches suffer from two critical limitations: insufficient learning of\nnoise-contaminated unimodal data, leading to corrupted cross-modal\ninteractions, and inadequate fusion of multimodal representations, resulting in\ndiscarding discriminative unimodal information while retaining multimodal\nredundant information. To address these challenges, this paper proposes a\nDouble Information Bottleneck (DIB) strategy to obtain a powerful, unified\ncompact multimodal representation. Implemented within the framework of low-rank\nRenyi's entropy functional, DIB offers enhanced robustness against diverse\nnoise sources and computational tractability for high-dimensional data, as\ncompared to the conventional Shannon entropy-based methods. The DIB comprises\ntwo key modules: 1) learning a sufficient and compressed representation of\nindividual unimodal data by maximizing the task-relevant information and\ndiscarding the superfluous information, and 2) ensuring the discriminative\nability of multimodal representation through a novel attention bottleneck\nfusion mechanism. Consequently, DIB yields a multimodal representation that\neffectively filters out noisy information from unimodal data while capturing\ninter-modal complementarity. Extensive experiments on CMU-MOSI, CMU-MOSEI,\nCH-SIMS, and MVSA-Single validate the effectiveness of our method. The model\nachieves 47.4% accuracy under the Acc-7 metric on CMU-MOSI and 81.63% F1-score\non CH-SIMS, outperforming the second-best baseline by 1.19%. Under noise, it\nshows only 0.36% and 0.29% performance degradation on CMU-MOSI and CMU-MOSEI\nrespectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u4fe1\u606f\u74f6\u9888\uff08DIB\uff09\u7b56\u7565\u6765\u89e3\u51b3\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u566a\u58f0\u6c61\u67d3\u7684\u5355\u6a21\u6001\u6570\u636e\u5b66\u4e60\u4e0d\u8db3\u548c\u8de8\u6a21\u6001\u8868\u793a\u878d\u5408\u4e0d\u5145\u5206\u3002DIB\u901a\u8fc7\u6700\u5927\u5316\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u5e76\u4e22\u5f03\u5197\u4f59\u4fe1\u606f\uff0c\u4ee5\u53ca\u65b0\u9896\u7684\u6ce8\u610f\u529b\u74f6\u9888\u878d\u5408\u673a\u5236\uff0c\u83b7\u5f97\u5f3a\u5927\u4e14\u7edf\u4e00\u7684\u591a\u6a21\u6001\u7d27\u51d1\u8868\u793a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a\u5bf9\u566a\u58f0\u6c61\u67d3\u7684\u5355\u6a21\u6001\u6570\u636e\u5b66\u4e60\u4e0d\u8db3\u5bfc\u81f4\u8de8\u6a21\u6001\u4ea4\u4e92\u53d7\u635f\uff0c\u4ee5\u53ca\u591a\u6a21\u6001\u8868\u793a\u878d\u5408\u4e0d\u5145\u5206\u5bfc\u81f4\u4e22\u5f03\u5224\u522b\u6027\u5355\u6a21\u6001\u4fe1\u606f\u800c\u4fdd\u7559\u5197\u4f59\u591a\u6a21\u6001\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u53cc\u4fe1\u606f\u74f6\u9888\uff08DIB\uff09\u7b56\u7565\uff0c\u5305\u62ec\u4e24\u4e2a\u5173\u952e\u6a21\u5757\uff1a1\uff09\u901a\u8fc7\u6700\u5927\u5316\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u548c\u4e22\u5f03\u5197\u4f59\u4fe1\u606f\u6765\u5b66\u4e60\u5145\u5206\u538b\u7f29\u7684\u5355\u6a21\u6001\u6570\u636e\u8868\u793a\uff1b2\uff09\u901a\u8fc7\u65b0\u9896\u7684\u6ce8\u610f\u529b\u74f6\u9888\u878d\u5408\u673a\u5236\u786e\u4fdd\u591a\u6a21\u6001\u8868\u793a\u7684\u5224\u522b\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u4f4e\u79e9Renyi\u71b5\u51fd\u6570\u6846\u67b6\u5b9e\u73b0\u3002", "result": "\u5728CMU-MOSI\u3001CMU-MOSEI\u3001CH-SIMS\u548cMVSA-Single\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u5728CMU-MOSI\u4e0aAcc-7\u6307\u6807\u8fbe\u523047.4%\u51c6\u786e\u7387\uff0c\u5728CH-SIMS\u4e0aF1\u5206\u6570\u8fbe\u523081.63%\uff0c\u6bd4\u6b21\u4f18\u57fa\u7ebf\u9ad8\u51fa1.19%\u3002\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\uff0cCMU-MOSI\u548cCMU-MOSEI\u7684\u6027\u80fd\u4e0b\u964d\u4ec5\u4e3a0.36%\u548c0.29%\u3002", "conclusion": "DIB\u7b56\u7565\u80fd\u591f\u6709\u6548\u8fc7\u6ee4\u5355\u6a21\u6001\u6570\u636e\u4e2d\u7684\u566a\u58f0\u4fe1\u606f\uff0c\u540c\u65f6\u6355\u6349\u6a21\u6001\u95f4\u7684\u4e92\u8865\u6027\uff0c\u5728\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.01445", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01445", "abs": "https://arxiv.org/abs/2511.01445", "authors": ["ChengZhang Yu", "YingRu He", "Hongyan Cheng", "nuo Cheng", "Zhixing Liu", "Dongxu Mu", "Zhangrui Shen", "Zhanpeng Jin"], "title": "From Passive to Proactive: A Multi-Agent System with Dynamic Task Orchestration for Intelligent Medical Pre-Consultation", "comment": "14pages, 7 figures, 7 tables", "summary": "Global healthcare systems face critical challenges from increasing patient\nvolumes and limited consultation times, with primary care visits averaging\nunder 5 minutes in many countries. While pre-consultation processes\nencompassing triage and structured history-taking offer potential solutions,\nthey remain limited by passive interaction paradigms and context management\nchallenges in existing AI systems. This study introduces a hierarchical\nmulti-agent framework that transforms passive medical AI systems into proactive\ninquiry agents through autonomous task orchestration. We developed an\neight-agent architecture with centralized control mechanisms that decomposes\npre-consultation into four primary tasks: Triage ($T_1$), History of Present\nIllness collection ($T_2$), Past History collection ($T_3$), and Chief\nComplaint generation ($T_4$), with $T_1$--$T_3$ further divided into 13\ndomain-specific subtasks. Evaluated on 1,372 validated electronic health\nrecords from a Chinese medical platform across multiple foundation models\n(GPT-OSS 20B, Qwen3-8B, Phi4-14B), the framework achieved 87.0% accuracy for\nprimary department triage and 80.5% for secondary department classification,\nwith task completion rates reaching 98.2% using agent-driven scheduling versus\n93.1% with sequential processing. Clinical quality scores from 18 physicians\naveraged 4.56 for Chief Complaints, 4.48 for History of Present Illness, and\n4.69 for Past History on a 5-point scale, with consultations completed within\n12.7 rounds for $T_2$ and 16.9 rounds for $T_3$. The model-agnostic\narchitecture maintained high performance across different foundation models\nwhile preserving data privacy through local deployment, demonstrating the\npotential for autonomous AI systems to enhance pre-consultation efficiency and\nquality in clinical settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u5c42\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u88ab\u52a8\u533b\u7597AI\u7cfb\u7edf\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u95ee\u8bca\u4ee3\u7406\uff0c\u901a\u8fc7\u81ea\u4e3b\u4efb\u52a1\u7f16\u6392\u63d0\u5347\u9884\u8bca\u6548\u7387\u548c\u8d28\u91cf\u3002", "motivation": "\u5168\u7403\u533b\u7597\u7cfb\u7edf\u9762\u4e34\u60a3\u8005\u6570\u91cf\u589e\u52a0\u548c\u5c31\u8bca\u65f6\u95f4\u6709\u9650\uff08\u5e73\u5747\u4e0d\u8db35\u5206\u949f\uff09\u7684\u6311\u6218\uff0c\u73b0\u6709\u9884\u8bca\u6d41\u7a0b\u53d7\u9650\u4e8e\u88ab\u52a8\u4ea4\u4e92\u8303\u5f0f\uff0c\u9700\u8981\u66f4\u4e3b\u52a8\u7684AI\u7cfb\u7edf\u6765\u6539\u5584\u9884\u8bca\u8d28\u91cf\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b8\u4e2a\u667a\u80fd\u4f53\u7684\u5206\u5c42\u67b6\u6784\uff0c\u901a\u8fc7\u96c6\u4e2d\u63a7\u5236\u673a\u5236\u5c06\u9884\u8bca\u5206\u89e3\u4e3a4\u4e2a\u4e3b\u8981\u4efb\u52a1\uff08\u5206\u8bca\u3001\u73b0\u75c5\u53f2\u91c7\u96c6\u3001\u65e2\u5f80\u53f2\u91c7\u96c6\u3001\u4e3b\u8bc9\u751f\u6210\uff09\uff0c\u8fdb\u4e00\u6b65\u7ec6\u5206\u4e3a13\u4e2a\u9886\u57df\u7279\u5b9a\u5b50\u4efb\u52a1\uff0c\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u8c03\u5ea6\u5b9e\u73b0\u81ea\u4e3b\u4efb\u52a1\u7f16\u6392\u3002", "result": "\u57281372\u4efd\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e0a\u8bc4\u4f30\uff0c\u5206\u8bca\u51c6\u786e\u7387\u8fbe87.0%\uff0c\u4e8c\u7ea7\u79d1\u5ba4\u5206\u7c7b\u51c6\u786e\u738780.5%\uff0c\u4efb\u52a1\u5b8c\u6210\u738798.2%\uff08\u667a\u80fd\u4f53\u8c03\u5ea6\uff09vs 93.1%\uff08\u987a\u5e8f\u5904\u7406\uff09\u3002\u4e34\u5e8a\u8d28\u91cf\u8bc4\u5206\uff1a\u4e3b\u8bc94.56\u3001\u73b0\u75c5\u53f24.48\u3001\u65e2\u5f80\u53f24.69\uff085\u5206\u5236\uff09\u3002", "conclusion": "\u8be5\u6a21\u578b\u65e0\u5173\u67b6\u6784\u5728\u4e0d\u540c\u57fa\u7840\u6a21\u578b\u4e0a\u4fdd\u6301\u9ad8\u6027\u80fd\uff0c\u901a\u8fc7\u672c\u5730\u90e8\u7f72\u4fdd\u62a4\u6570\u636e\u9690\u79c1\uff0c\u8bc1\u660e\u4e86\u81ea\u4e3bAI\u7cfb\u7edf\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u63d0\u5347\u9884\u8bca\u6548\u7387\u548c\u8d28\u91cf\u7684\u80fd\u529b\u3002"}}
{"id": "2511.01527", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01527", "abs": "https://arxiv.org/abs/2511.01527", "authors": ["Hanwen Xu", "Xuyao Huang", "Yuzhe Liu", "Kai Yu", "Zhijie Deng"], "title": "TPS-Bench: Evaluating AI Agents' Tool Planning \\& Scheduling Abilities in Compounding Tasks", "comment": null, "summary": "Large language model (LLM) agents have exhibited strong problem-solving\ncompetence across domains like research and coding. Yet, it remains\nunderexplored whether LLM agents can tackle compounding real-world problems\nthat require a diverse set of tools to complete. Given a broad, heterogeneous\ntool repository, LLM agents must not only select appropriate tools based on\ntask planning analysis but also strategically schedule the execution order to\nensure efficiency. This paper introduces TPS-Bench to benchmark the ability of\nLLM agents in solving such problems that demand Tool Planning and Scheduling.\nTPS-Bench collects 200 compounding tasks of two difficulty levels, based on a\ntool repository containing hundreds of model context protocol (MCP) tools. In\nparticular, each task is composed of multiple subtasks, such as web search, map\nnavigation, calendar checking, etc., and each subtask can be completed by a\nbasic tool. Our evaluation emphasizes both task completion rate and efficiency.\nThe empirical studies on popular closed-source and open-source LLMs indicate\nthat most models can perform reasonable tool planning, but differ in\nscheduling. For example, GLM-4.5 achieves an outperforming task completion rate\nof 64.72% with extensive sequential tool calls, hence suffering from\nsignificantly long execution time. By contrast, GPT-4o prioritizes parallel\ntool calls but achieves only a 45.08% completion rate. Considering\nreinforcement learning (RL) can be a viable way to improve the scheduling\nefficiency without compromising performance, we perform an initial study on\nQwen3-1.7B and witness a 14% reduction in execution time alongside a 6% gain in\ntask completion rate based on rarely 100 RL training samples. Our code is\navailable https://github.com/hanwenxu1/mcp-agent.", "AI": {"tldr": "TPS-Bench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u5728\u9700\u8981\u5de5\u5177\u89c4\u5212\u4e0e\u8c03\u5ea6\u80fd\u529b\u7684\u590d\u5408\u4efb\u52a1\u4e2d\u8868\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b200\u4e2a\u57fa\u4e8e\u6570\u767e\u4e2aMCP\u5de5\u5177\u7684\u590d\u5408\u4efb\u52a1\uff0c\u8bc4\u4f30\u663e\u793a\u5927\u591a\u6570\u6a21\u578b\u80fd\u5408\u7406\u89c4\u5212\u5de5\u5177\u4f46\u8c03\u5ea6\u80fd\u529b\u5dee\u5f02\u663e\u8457\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8f83\u5c11\u63a2\u7d22LLM\u667a\u80fd\u4f53\u80fd\u5426\u5904\u7406\u9700\u8981\u591a\u79cd\u5de5\u5177\u534f\u4f5c\u5b8c\u6210\u7684\u590d\u5408\u73b0\u5b9e\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u7ed9\u5b9a\u5f02\u6784\u5de5\u5177\u5e93\u7684\u60c5\u51b5\u4e0b\uff0c\u667a\u80fd\u4f53\u4e0d\u4ec5\u8981\u9009\u62e9\u5408\u9002\u7684\u5de5\u5177\uff0c\u8fd8\u9700\u8981\u6218\u7565\u6027\u5730\u8c03\u5ea6\u6267\u884c\u987a\u5e8f\u4ee5\u786e\u4fdd\u6548\u7387\u3002", "method": "\u6784\u5efaTPS-Bench\u57fa\u51c6\uff0c\u5305\u542b200\u4e2a\u590d\u5408\u4efb\u52a1\u548c\u6570\u767e\u4e2aMCP\u5de5\u5177\uff0c\u6bcf\u4e2a\u4efb\u52a1\u7531\u591a\u4e2a\u5b50\u4efb\u52a1\u7ec4\u6210\uff0c\u8bc4\u4f30\u91cd\u70b9\u5305\u62ec\u4efb\u52a1\u5b8c\u6210\u7387\u548c\u6548\u7387\uff0c\u5e76\u5bf9\u6d41\u884c\u95ed\u6e90\u548c\u5f00\u6e90LLM\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "GLM-4.5\u8fbe\u523064.72%\u7684\u4efb\u52a1\u5b8c\u6210\u7387\u4f46\u6267\u884c\u65f6\u95f4\u8fc7\u957f\uff0cGPT-4o\u4f18\u5148\u5e76\u884c\u5de5\u5177\u8c03\u7528\u4f46\u5b8c\u6210\u7387\u4ec545.08%\uff0c\u5bf9Qwen3-1.7B\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u540e\u6267\u884c\u65f6\u95f4\u51cf\u5c1114%\u4e14\u5b8c\u6210\u7387\u63d0\u53476%\u3002", "conclusion": "LLM\u667a\u80fd\u4f53\u5728\u5de5\u5177\u89c4\u5212\u65b9\u9762\u8868\u73b0\u5408\u7406\u4f46\u5728\u8c03\u5ea6\u80fd\u529b\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u5f3a\u5316\u5b66\u4e60\u662f\u63d0\u9ad8\u8c03\u5ea6\u6548\u7387\u800c\u4e0d\u727a\u7272\u6027\u80fd\u7684\u53ef\u884c\u65b9\u6cd5\uff0c\u5373\u4f7f\u4f7f\u7528\u5c11\u91cf\u8bad\u7ec3\u6837\u672c\u4e5f\u80fd\u663e\u8457\u6539\u5584\u6027\u80fd\u3002"}}
{"id": "2511.01550", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01550", "abs": "https://arxiv.org/abs/2511.01550", "authors": ["Ujjwal Sharma", "Stevan Rudinac", "Ana Mi\u0107kovi\u0107", "Willemijn van Dolen", "Marcel Worring"], "title": "Analyzing Sustainability Messaging in Large-Scale Corporate Social Media", "comment": null, "summary": "In this work, we introduce a multimodal analysis pipeline that leverages\nlarge foundation models in vision and language to analyze corporate social\nmedia content, with a focus on sustainability-related communication. Addressing\nthe challenges of evolving, multimodal, and often ambiguous corporate messaging\non platforms such as X (formerly Twitter), we employ an ensemble of large\nlanguage models (LLMs) to annotate a large corpus of corporate tweets on their\ntopical alignment with the 17 Sustainable Development Goals (SDGs). This\napproach avoids the need for costly, task-specific annotations and explores the\npotential of such models as ad-hoc annotators for social media data that can\nefficiently capture both explicit and implicit references to sustainability\nthemes in a scalable manner. Complementing this textual analysis, we utilize\nvision-language models (VLMs), within a visual understanding framework that\nuses semantic clusters to uncover patterns in visual sustainability\ncommunication. This integrated approach reveals sectoral differences in SDG\nengagement, temporal trends, and associations between corporate messaging,\nenvironmental, social, governance (ESG) risks, and consumer engagement. Our\nmethods-automatic label generation and semantic visual clustering-are broadly\napplicable to other domains and offer a flexible framework for large-scale\nsocial media analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u591a\u6a21\u6001\u5206\u6790\u7ba1\u9053\uff0c\u5229\u7528\u5927\u578b\u57fa\u7840\u6a21\u578b\u5206\u6790\u4f01\u4e1a\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\uff0c\u91cd\u70b9\u5173\u6ce8\u53ef\u6301\u7eed\u53d1\u5c55\u76f8\u5173\u6c9f\u901a\uff0c\u901a\u8fc7LLM\u81ea\u52a8\u6807\u6ce8\u4e0eSDG\u7684\u5173\u8054\uff0c\u5e76\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5206\u6790\u89c6\u89c9\u53ef\u6301\u7eed\u6027\u6c9f\u901a\u6a21\u5f0f\u3002", "motivation": "\u89e3\u51b3\u4f01\u4e1a\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u7684\u591a\u6a21\u6001\u3001\u6a21\u7cca\u6027\u548c\u52a8\u6001\u53d8\u5316\u5e26\u6765\u7684\u5206\u6790\u6311\u6218\uff0c\u907f\u514d\u6602\u8d35\u7684\u4efb\u52a1\u7279\u5b9a\u6807\u6ce8\u9700\u6c42\uff0c\u63a2\u7d22\u57fa\u7840\u6a21\u578b\u4f5c\u4e3a\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u6807\u6ce8\u5668\u7684\u6f5c\u529b\u3002", "method": "\u4f7f\u7528LLM\u96c6\u6210\u6a21\u578b\u81ea\u52a8\u6807\u6ce8\u4f01\u4e1a\u63a8\u6587\u4e0e17\u4e2a\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u7684\u5173\u8054\uff0c\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u8bed\u4e49\u805a\u7c7b\u5206\u6790\u89c6\u89c9\u53ef\u6301\u7eed\u6027\u6c9f\u901a\u6a21\u5f0f\u3002", "result": "\u63ed\u793a\u4e86\u4e0d\u540c\u884c\u4e1a\u5728SDG\u53c2\u4e0e\u5ea6\u3001\u65f6\u95f4\u8d8b\u52bf\u4ee5\u53ca\u4f01\u4e1a\u6c9f\u901a\u4e0eESG\u98ce\u9669\u3001\u6d88\u8d39\u8005\u53c2\u4e0e\u5ea6\u4e4b\u95f4\u7684\u5173\u8054\u3002", "conclusion": "\u63d0\u51fa\u7684\u81ea\u52a8\u6807\u7b7e\u751f\u6210\u548c\u8bed\u4e49\u89c6\u89c9\u805a\u7c7b\u65b9\u6cd5\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u793e\u4ea4\u5a92\u4f53\u5206\u6790\u63d0\u4f9b\u4e86\u7075\u6d3b\u6846\u67b6\u3002"}}
{"id": "2511.01581", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01581", "abs": "https://arxiv.org/abs/2511.01581", "authors": ["Chengzhang Yu", "Zening Lu", "Chenyang Zheng", "Chiyue Wang", "Yiming Zhang", "Zhanpeng Jin"], "title": "ExplicitLM: Decoupling Knowledge from Parameters via Explicit Memory Banks", "comment": "12pages, 4figures", "summary": "Large language models suffer from knowledge staleness and lack of\ninterpretability due to implicit knowledge storage across entangled network\nparameters, preventing targeted updates and reasoning transparency. We propose\nExplicitLM, a novel architecture featuring a million-scale external memory bank\nstoring human-readable knowledge as token sequences, enabling direct inspection\nand modification. We design a differentiable two-stage retrieval mechanism with\nefficient coarse-grained filtering via product key decomposition (reducing\ncomplexity from $\\mathcal{O}(N \\cdot |I|)$ to $\\mathcal{O}(\\sqrt{N} \\cdot\n|I|)$) and fine-grained Gumbel-Softmax matching for end-to-end training.\nInspired by dual-system cognitive theory, we partition knowledge into frozen\nexplicit facts (20%) and learnable implicit patterns (80%), maintained through\nExponential Moving Average updates for stability. ExplicitLM achieves up to\n43.67% improvement on knowledge-intensive tasks versus standard Transformers,\nwith 3.62$\\times$ gains in low-data regimes (10k samples). Analysis shows\nstrong correlations between memory retrieval and performance, with correct\npredictions achieving 49% higher hit rates. Unlike RAG systems with frozen\nretrieval, our jointly optimized architecture demonstrates that interpretable,\nupdatable models can maintain competitive performance while providing\nunprecedented knowledge transparency.", "AI": {"tldr": "ExplicitLM\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u8bed\u8a00\u6a21\u578b\u67b6\u6784\uff0c\u901a\u8fc7\u5916\u90e8\u8bb0\u5fc6\u5e93\u5b58\u50a8\u53ef\u8bfb\u77e5\u8bc6\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u66f4\u65b0\u6027\uff0c\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u6bd4\u6807\u51c6Transformer\u63d0\u534743.67%\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u9648\u65e7\u6027\u548c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u7531\u4e8e\u77e5\u8bc6\u9690\u5f0f\u5b58\u50a8\u5728\u7ea0\u7f20\u7684\u7f51\u7edc\u53c2\u6570\u4e2d\uff0c\u65e0\u6cd5\u8fdb\u884c\u9488\u5bf9\u6027\u66f4\u65b0\u548c\u63a8\u7406\u900f\u660e\u5316\u3002", "method": "\u91c7\u7528\u767e\u4e07\u89c4\u6a21\u7684\u5916\u90e8\u8bb0\u5fc6\u5e93\u5b58\u50a8\u4eba\u7c7b\u53ef\u8bfb\u77e5\u8bc6\uff0c\u8bbe\u8ba1\u53ef\u5fae\u5206\u4e24\u9636\u6bb5\u68c0\u7d22\u673a\u5236\uff1a\u57fa\u4e8e\u4ea7\u54c1\u952e\u5206\u89e3\u7684\u7c97\u7c92\u5ea6\u8fc7\u6ee4\u548cGumbel-Softmax\u7ec6\u7c92\u5ea6\u5339\u914d\uff0c\u7ed3\u5408\u53cc\u7cfb\u7edf\u8ba4\u77e5\u7406\u8bba\u5c06\u77e5\u8bc6\u5206\u4e3a\u51bb\u7ed3\u663e\u5f0f\u4e8b\u5b9e(20%)\u548c\u53ef\u5b66\u4e60\u9690\u5f0f\u6a21\u5f0f(80%)\u3002", "result": "\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u6bd4\u6807\u51c6Transformer\u63d0\u534743.67%\uff0c\u5728\u4f4e\u6570\u636e\u573a\u666f(10k\u6837\u672c)\u4e0b\u83b7\u5f973.62\u500d\u589e\u76ca\uff0c\u6b63\u786e\u9884\u6d4b\u7684\u8bb0\u5fc6\u547d\u4e2d\u7387\u9ad8\u51fa49%\u3002", "conclusion": "\u8054\u5408\u4f18\u5316\u7684\u53ef\u89e3\u91ca\u3001\u53ef\u66f4\u65b0\u6a21\u578b\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u77e5\u8bc6\u900f\u660e\u5ea6\uff0c\u4f18\u4e8e\u4f7f\u7528\u51bb\u7ed3\u68c0\u7d22\u7684RAG\u7cfb\u7edf\u3002"}}
{"id": "2511.01639", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01639", "abs": "https://arxiv.org/abs/2511.01639", "authors": ["Sicheng Wang", "Shuhao Chen", "Jingran Zhou", "Chengyi Tu"], "title": "IVGAE-TAMA-BO: A novel temporal dynamic variational graph model for link prediction in global food trade networks with momentum structural memory and Bayesian optimization", "comment": "26pages,6figures", "summary": "Global food trade plays a crucial role in ensuring food security and\nmaintaining supply chain stability. However, its network structure evolves\ndynamically under the influence of geopolitical, economic, and environmental\nfactors, making it challenging to model and predict future trade links.\nEffectively capturing temporal patterns in food trade networks is therefore\nessential for improving the accuracy and robustness of link prediction. This\nstudy introduces IVGAE-TAMA-BO, a novel dynamic graph neural network designed\nto model evolving trade structures and predict future links in global food\ntrade networks. To the best of our knowledge, this is the first work to apply\ndynamic graph neural networks to this domain, significantly enhancing\npredictive performance. Building upon the original IVGAE framework, the\nproposed model incorporates a Trade-Aware Momentum Aggregator (TAMA) to capture\nthe temporal evolution of trade networks, jointly modeling short-term\nfluctuations and long-term structural dependencies. A momentum-based structural\nmemory mechanism further improves predictive stability and performance. In\naddition, Bayesian optimization is used to automatically tune key\nhyperparameters, enhancing generalization across diverse trade scenarios.\nExtensive experiments on five crop-specific datasets demonstrate that\nIVGAE-TAMA substantially outperforms the static IVGAE and other dynamic\nbaselines by effectively modeling temporal dependencies, while Bayesian\noptimization further boosts performance in IVGAE-TAMA-BO. These results\nhighlight the proposed framework as a robust and scalable solution for\nstructural prediction in global trade networks, with strong potential for\napplications in food security monitoring and policy decision support.", "AI": {"tldr": "\u63d0\u51faIVGAE-TAMA-BO\u52a8\u6001\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u4e8e\u9884\u6d4b\u5168\u7403\u7cae\u98df\u8d38\u6613\u7f51\u7edc\u4e2d\u7684\u672a\u6765\u94fe\u63a5\uff0c\u901a\u8fc7\u65f6\u95f4\u611f\u77e5\u52a8\u91cf\u805a\u5408\u5668\u548c\u8d1d\u53f6\u65af\u4f18\u5316\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u5168\u7403\u7cae\u98df\u8d38\u6613\u7f51\u7edc\u5728\u591a\u79cd\u56e0\u7d20\u5f71\u54cd\u4e0b\u52a8\u6001\u6f14\u53d8\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u5176\u65f6\u95f4\u6a21\u5f0f\uff0c\u9700\u8981\u66f4\u51c6\u786e\u7684\u94fe\u63a5\u9884\u6d4b\u65b9\u6cd5\u6765\u4fdd\u969c\u7cae\u98df\u5b89\u5168\u548c\u4f9b\u5e94\u94fe\u7a33\u5b9a\u3002", "method": "\u57fa\u4e8eIVGAE\u6846\u67b6\uff0c\u5f15\u5165\u8d38\u6613\u611f\u77e5\u52a8\u91cf\u805a\u5408\u5668(TAMA)\u6355\u6349\u8d38\u6613\u7f51\u7edc\u7684\u65f6\u95f4\u6f14\u5316\uff0c\u7ed3\u5408\u77ed\u671f\u6ce2\u52a8\u548c\u957f\u671f\u7ed3\u6784\u4f9d\u8d56\uff0c\u5e76\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u81ea\u52a8\u8c03\u53c2\u3002", "result": "\u5728\u4e94\u4e2a\u4f5c\u7269\u7279\u5b9a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cIVGAE-TAMA\u663e\u8457\u4f18\u4e8e\u9759\u6001IVGAE\u548c\u5176\u4ed6\u52a8\u6001\u57fa\u7ebf\u6a21\u578b\uff0c\u8d1d\u53f6\u65af\u4f18\u5316\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5168\u7403\u8d38\u6613\u7f51\u7edc\u7ed3\u6784\u9884\u6d4b\u63d0\u4f9b\u4e86\u7a33\u5065\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u7cae\u98df\u5b89\u5168\u76d1\u6d4b\u548c\u653f\u7b56\u51b3\u7b56\u652f\u6301\u65b9\u9762\u5177\u6709\u91cd\u8981\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.01668", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01668", "abs": "https://arxiv.org/abs/2511.01668", "authors": ["Yueqing Xi", "Yifan Bai", "Huasen Luo", "Weiliang Wen", "Hui Liu", "Haoliang Li"], "title": "Hybrid Retrieval-Augmented Generation Agent for Trustworthy Legal Question Answering in Judicial Forensics", "comment": null, "summary": "As artificial intelligence permeates judicial forensics, ensuring the\nveracity and traceability of legal question answering (QA) has become critical.\nConventional large language models (LLMs) are prone to hallucination, risking\nmisleading guidance in legal consultation, while static knowledge bases\nstruggle to keep pace with frequently updated statutes and case law. We present\na hybrid legal QA agent tailored for judicial settings that integrates\nretrieval-augmented generation (RAG) with multi-model ensembling to deliver\nreliable, auditable, and continuously updatable counsel. The system prioritizes\nretrieval over generation: when a trusted legal repository yields relevant\nevidence, answers are produced via RAG; otherwise, multiple LLMs generate\ncandidates that are scored by a specialized selector, with the top-ranked\nanswer returned. High-quality outputs then undergo human review before being\nwritten back to the repository, enabling dynamic knowledge evolution and\nprovenance tracking. Experiments on the Law\\_QA dataset show that our hybrid\napproach significantly outperforms both a single-model baseline and a vanilla\nRAG pipeline on F1, ROUGE-L, and an LLM-as-a-Judge metric. Ablations confirm\nthe complementary contributions of retrieval prioritization, model ensembling,\nand the human-in-the-loop update mechanism. The proposed system demonstrably\nreduces hallucination while improving answer quality and legal compliance,\nadvancing the practical landing of media forensics technologies in judicial\nscenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u591a\u6a21\u578b\u96c6\u6210\u7684\u6df7\u5408\u6cd5\u5f8b\u95ee\u7b54\u7cfb\u7edf\uff0c\u4f18\u5148\u68c0\u7d22\u53ef\u4fe1\u6cd5\u5f8b\u77e5\u8bc6\u5e93\uff0c\u901a\u8fc7\u4eba\u7c7b\u5ba1\u6838\u673a\u5236\u5b9e\u73b0\u77e5\u8bc6\u52a8\u6001\u66f4\u65b0\uff0c\u663e\u8457\u51cf\u5c11\u5e7b\u89c9\u5e76\u63d0\u9ad8\u6cd5\u5f8b\u5408\u89c4\u6027\u3002", "motivation": "\u4f20\u7edf\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u95ee\u7b54\u4e2d\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u8bef\u5bfc\u6cd5\u5f8b\u54a8\u8be2\uff1b\u9759\u6001\u77e5\u8bc6\u5e93\u96be\u4ee5\u8ddf\u4e0a\u9891\u7e41\u66f4\u65b0\u7684\u6cd5\u5f8b\u6cd5\u89c4\u3002\u9700\u8981\u786e\u4fdd\u6cd5\u5f8b\u95ee\u7b54\u7684\u771f\u5b9e\u6027\u3001\u53ef\u8ffd\u6eaf\u6027\u548c\u6301\u7eed\u66f4\u65b0\u80fd\u529b\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u4f18\u5148\u7b56\u7565\uff1a\u5f53\u53ef\u4fe1\u6cd5\u5f8b\u77e5\u8bc6\u5e93\u6709\u76f8\u5173\u8bc1\u636e\u65f6\u4f7f\u7528RAG\u751f\u6210\u7b54\u6848\uff1b\u5426\u5219\u4f7f\u7528\u591a\u4e2aLLM\u751f\u6210\u5019\u9009\u7b54\u6848\u5e76\u7531\u4e13\u95e8\u7684\u9009\u62e9\u5668\u8bc4\u5206\u8fd4\u56de\u6700\u4f18\u7ed3\u679c\u3002\u9ad8\u8d28\u91cf\u8f93\u51fa\u7ecf\u8fc7\u4eba\u5de5\u5ba1\u6838\u540e\u5199\u56de\u77e5\u8bc6\u5e93\u3002", "result": "\u5728Law_QA\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6df7\u5408\u65b9\u6cd5\u5728F1\u3001ROUGE-L\u548cLLM-as-a-Judge\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5355\u6a21\u578b\u57fa\u7ebf\u548c\u666e\u901aRAG\u6d41\u7a0b\u3002\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u68c0\u7d22\u4f18\u5148\u3001\u6a21\u578b\u96c6\u6210\u548c\u4eba\u5de5\u66f4\u65b0\u673a\u5236\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u663e\u8457\u51cf\u5c11\u4e86\u5e7b\u89c9\uff0c\u63d0\u9ad8\u4e86\u7b54\u6848\u8d28\u91cf\u548c\u6cd5\u5f8b\u5408\u89c4\u6027\uff0c\u63a8\u52a8\u4e86\u5a92\u4f53\u53d6\u8bc1\u6280\u672f\u5728\u53f8\u6cd5\u573a\u666f\u4e2d\u7684\u5b9e\u9645\u843d\u5730\u5e94\u7528\u3002"}}
{"id": "2511.01824", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01824", "abs": "https://arxiv.org/abs/2511.01824", "authors": ["Yuetai Li", "Huseyin A Inan", "Xiang Yue", "Wei-Ning Chen", "Lukas Wutschitz", "Janardhan Kulkarni", "Radha Poovendran", "Robert Sim", "Saravan Rajmohan"], "title": "Simulating Environments with Reasoning Models for Agent Training", "comment": null, "summary": "LLM agents excel in compact environments requiring deep reasoning but remain\nbrittle when operating in broader, more complex contexts that demand robustness\nacross diverse tools and schemas. Building bespoke environments for training is\nheavy, brittle, and limits progress. In this paper, we demonstrate that LLMs\ncan simulate realistic environment feedback without access to actual testbed\ndata or APIs. Inspired by this capability, we propose two frameworks:\nSimia-SFT, a pipeline that synthesizes SFT data by amplifying small seed sets\ninto diverse trajectories in an environment-agnostic manner, and Simia-RL, a\nframework that enables RL training without real environment implementations\nthrough LLM-simulated feedback. Fine-tuning open models yields consistent\nimprovements across multiple benchmarks, surpassing GPT-4o and approaching\no4-mini on $\\tau^2$-Bench. Together, Simia-SFT and Simia-RL enable scalable\nagent training without environment engineering, replacing heavy and brittle\nimplementations with flexible LLM-based simulation.", "AI": {"tldr": "LLM\u4ee3\u7406\u5728\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u8106\u5f31\uff0c\u672c\u6587\u63d0\u51faSimia-SFT\u548cSimia-RL\u6846\u67b6\uff0c\u901a\u8fc7LLM\u6a21\u62df\u73af\u5883\u53cd\u9988\u5b9e\u73b0\u65e0\u9700\u771f\u5b9e\u73af\u5883\u6570\u636e\u7684\u53ef\u6269\u5c55\u4ee3\u7406\u8bad\u7ec3\u3002", "motivation": "LLM\u4ee3\u7406\u5728\u9700\u8981\u8de8\u591a\u79cd\u5de5\u5177\u548c\u6a21\u5f0f\u7684\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u8106\u5f31\uff0c\u800c\u6784\u5efa\u5b9a\u5236\u8bad\u7ec3\u73af\u5883\u6210\u672c\u9ad8\u4e14\u9650\u5236\u8fdb\u5c55\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u6846\u67b6\uff1aSimia-SFT\u901a\u8fc7\u653e\u5927\u79cd\u5b50\u96c6\u751f\u6210\u591a\u6837\u5316\u8f68\u8ff9\u7684SFT\u6570\u636e\uff1bSimia-RL\u901a\u8fc7LLM\u6a21\u62df\u53cd\u9988\u5b9e\u73b0\u65e0\u9700\u771f\u5b9e\u73af\u5883\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u3002", "result": "\u5fae\u8c03\u5f00\u6e90\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb\uff0c\u5728\u03c4\u00b2-Bench\u4e0a\u8d85\u8d8aGPT-4o\u5e76\u63a5\u8fd1o4-mini\u3002", "conclusion": "Simia\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u65e0\u9700\u73af\u5883\u5de5\u7a0b\u7684\u53ef\u6269\u5c55\u4ee3\u7406\u8bad\u7ec3\uff0c\u7528\u7075\u6d3b\u7684LLM\u6a21\u62df\u66ff\u4ee3\u7e41\u91cd\u8106\u5f31\u7684\u73af\u5883\u5b9e\u73b0\u3002"}}
