<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 6]
- [cs.AI](#cs.AI) [Total: 39]
- [cs.IT](#cs.IT) [Total: 4]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Entanglement Purification With Finite Latency Classical Communication in Quantum Networks](https://arxiv.org/abs/2509.03667)
*Vivek Vasan,Alexander Nico-Katz,Boulat A. Bash,Daniel C. Kilper,Marco Ruffini*

Main category: cs.NI

TL;DR: 分析量子网络中纠缠纯化协议在非瞬时经典通信条件下的性能，确定成功区域和资源需求


<details>
  <summary>Details</summary>
Motivation: 量子网络中纠缠对在存储期间会因环境退相干而降低保真度，纠缠纯化需要经典通信协调，但通信延迟会导致空闲期使状态进一步退相干，需要评估实际网络条件下的可行性

Method: 使用微观Lindblad方法处理量子动力学，基于当前城域IP网络延迟统计和量子内存测试台参数，分析BBPSSW和DEJMPS协议在各种网络条件下的性能

Result: 确定了纠缠纯化成功和失败的区域（通过保真度等值线划分），计算了完成多轮纯化协议所需的总纠缠对数量，以及超过应用特定阈值的纯化保真度纠缠对的稳态吞吐量

Conclusion: 为在当前和近未来网络部署纠缠纯化提供了延迟预算、内存质量目标和资源开销估计

Abstract: Quantum networks rely on high fidelity entangled pairs distributed to nodes,
but maintaining their fidelity is challenged by environmental decoherence
during storage. Entanglement purification is used to restore fidelity, but the
idle periods imposed by the associated classical communication delays
counteract this goal by exposing the states to further decoherence. In this
work, we analyze the practical viability of entanglement purification protocols
(BBPSSW, DEJMPS), under non-instantaneous classical coordination over Internet
protocol (IP) communications networks. We present a comprehensive performance
evaluation of these protocols in various network conditions for a range of
quantum memory technologies. We employ a microscopic Lindblad treatment of the
underlying quantum dynamics, and use current-generation metropolitan IP network
latency statistics and parameters drawn from quantum memory testbeds. In doing
so we identify the regions in which entanglement purification succeeds and
fails, delineated by break-even iso-fidelity contours in the phase space. We
then determine the total number of entangled pairs required to complete a
multi-round purification protocol, and the steady-state throughput of entangled
pairs with purified fidelities that exceed application-specific thresholds.
This provides latency budgets, memory quality targets, and resource-overhead
estimates for deploying purification on current and near-future networks.

</details>


### [2] [Drift Plus Optimistic Penalty -- A Learning Framework for Stochastic Network Optimization](https://arxiv.org/abs/2509.03762)
*Sathwik Chadaga,Eytan Modiano*

Main category: cs.NI

TL;DR: 该论文研究队列网络中路由和调度的联合优化问题，在传输成本未知的情况下，通过结合Lyapunov漂移加惩罚优化和多臂老虎机技术，提出了一种网络控制策略，实现了次线性遗憾界。


<details>
  <summary>Details</summary>
Motivation: 解决队列网络中路由和调度问题，其中边传输成本未知且只能通过选择传输获得噪声观测，需要在保证网络稳定性的同时优化吞吐量和成本，存在探索-利用权衡的挑战。

Method: 使用Lyapunov漂移加惩罚优化技术和多臂老虎机方法，开发网络控制策略，将队列稳定性约束转化为优化目标的一部分。

Result: 提出的策略实现了O(√T log T)的次线性遗憾界，相比完全了解到达和成本信息的最优策略，性能损失随时间的增长而减缓。

Conclusion: 该论文成功解决了未知传输成本下的联合路由调度问题，提出的控制策略在保证网络稳定性的同时实现了接近最优的性能，并通过仿真验证了次线性遗憾性能。

Abstract: We consider the problem of joint routing and scheduling in queueing networks,
where the edge transmission costs are unknown. At each time-slot, the network
controller receives noisy observations of transmission costs only for those
edges it selects for transmission. The network controller's objective is to
make routing and scheduling decisions so that the total expected cost is
minimized. This problem exhibits an exploration-exploitation trade-off,
however, previous bandit-style solutions cannot be directly applied to this
problem due to the queueing dynamics. In order to ensure network stability, the
network controller needs to optimize throughput and cost simultaneously. We
show that the best achievable cost is lower bounded by the solution to a static
optimization problem, and develop a network control policy using techniques
from Lyapunov drift-plus-penalty optimization and multi-arm bandits. We show
that the policy achieves a sub-linear regret of order $O(\sqrt{T}\log T)$, as
compared to the best policy that has complete knowledge of arrivals and costs.
Finally, we evaluate the proposed policy using simulations and show that its
regret is indeed sub-linear.

</details>


### [3] [A Versatile and Programmable UAV Platform for Radio Access Network and End-to-End Cellular Measurements](https://arxiv.org/abs/2509.03818)
*Sherwan Jalal Abdullah,Sravan Reddy Chintareddy,Victor S. Frost,Shawn Keshmiri,Morteza Hashemi*

Main category: cs.NI

TL;DR: 开发基于无人机的移动网络性能测量平台，用于农村和困难地形区域的网络覆盖和质量测试，通过空中操作收集RAN信号和端到端性能指标


<details>
  <summary>Details</summary>
Motivation: 传统众包方法在农村地区因人口密度低和地形困难而不足，需要更高效、安全的网络测试方案

Method: 使用无人机平台集成机载计算单元和商用蜂窝调制解调器，通过地理空间映射和统计技术分析收集的数据

Result: 实验显示高空接收信号功率改善但信号质量因邻区干扰而下降，系统在大部分区域保持可接受的信号质量和吞吐性能

Conclusion: 强无线电信号指标不一定能转化为一致的空间覆盖，无人机平台为农村网络测试提供了有效解决方案

Abstract: In this work, we develop a measurement platform to capture mobile network
performance metrics including coverage and quality of service in regions where
conventional coverage testing approaches are frequently time-intensive,
labor-demanding, and occasionally hazardous. Traditionally, crowd-sourcing
methods are used to collect cellular network performance metrics. However,
these approaches are inadequate in rural areas due to low-density population,
and difficult terrain. The platform described here is a UAV-based and is
designed to investigate the mobile network performance through aerial
operations and gather Radio Access Network (RAN) signal alongside end-to-end
network performance metrics. Our platform gathers metrics through the
integration of an onboard computation unit and commercial off-the-shelf
cellular modem. The gathered data are subsequently analyzed and displayed using
geospatial mapping utilities and statistical techniques to deliver key
observations on cellular network performance. Experimental results showed that
the received signal power improves at higher altitudes due to enhanced
line-of-sight (LoS) conditions as expected. However, the signal quality
degrades as a result of increased interference from neighboring cells. The
analysis reveals that for most of the geographic area covered in the initial
experiments the system maintained acceptable signal quality, with adequate
throughput performance for both uplink and downlink communications, while
maintaining satisfactory round-trip time characteristics. Notably, the
experiment showed that a strong radio signal metric for a given cell does not
necessarily translate to consistent spatial coverage across the tested region.

</details>


### [4] [Indoor Positioning with Wi-Fi Location: A Survey of IEEE 802.11mc/az/bk Fine Timing Measurement Research](https://arxiv.org/abs/2509.03901)
*Katarzyna Kosek-Szott,Szymon Szott,Wojciech Ciezobka,Maksymilian Wojnar,Krzysztof Rusek,Jonathan Segev*

Main category: cs.NI

TL;DR: 这篇论文是一个关于IEEE 802.11mc FTM协议在室内定位领域的综述性研究，统计了超180篇相关研究论文，分析了FTM的实际精度、改进方法、应用场景和安全问题，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 虽然室内定位技术在家庭、办公室和工业网络中具有重要作用，但对于IEEE 802.11mc FTM协议及其最新增强功能的专门调查仍然缺失。论文填补了这一研究空白，以支持未来一代设备的室内定位需求。

Method: 采用系统性的文献调研方法，分类和评估了180多篇与FTM相关的研究论文。研究内容包括：FTM的实际定位精度、通过机器学习等方法提高精度的技术、FTM与其他室内定位系统的结合、基于FTM的应用开发以及安全问题的分析。

Result: 研究结果显示，FTM协议在室内定位领域具有很大潜力，主要因为Wi-Fi网络的高可用性、FTM的高精度以及设备支持度。论文还涵盖了最新的FTM增强功能，如来自802.11az和802.11bk修议案的新特性。

Conclusion: 论文总结了FTM在室内定位领域的重要研究成果，并明确了未来的研究方向。FTM协议通过不断的技术发展和协议更新，将在室内定位技术中发挥趋势性作用，为智能家居、办公自动化和工业IoT应用提供基础支撑。

Abstract: Indoor positioning is an enabling technology for home, office, and industrial
network users because it provides numerous information and communication
technology (ICT) and Internet of things (IoT) functionalities such as indoor
navigation, smart meter localization, asset tracking, support for emergency
services, and detection of hazardous situations. The IEEE 802.11mc fine timing
measurement (FTM) protocol (commercially known as Wi-Fi Location) has great
potential to enable indoor positioning in future generation devices, primarily
because of the high availability of Wi-Fi networks, FTM's high accuracy and
device support. Furthermore, new FTM enhancements are available in the released
(802.11az) and recently completed (802.11bk) amendments. Despite the multitude
of literature reviews on indoor positioning, a survey dedicated to FTM and its
recent enhancements has so far been lacking. We fill this gap by classifying
and reviewing over 180 research papers related to the practical accuracy
achieved with FTM, methods for improving its accuracy (also with machine
learning), combining FTM with other indoor positioning systems, FTM-based
applications, and security issues. Based on the conducted survey, we summarize
the most important research achievements and formulate open areas for further
research.

</details>


### [5] [Autonomous Task Offloading of Vehicular Edge Computing with Parallel Computation Queues](https://arxiv.org/abs/2509.03935)
*Sungho Cho,Sung Il Choi,Seung Hyun Oh,Ian P. Roberts,Sang Hyun Lee*

Main category: cs.NI

TL;DR: 提出了一种基于网络协作的车辆边缘计算任务卸载方案，通过预测边缘服务器瞬时处理能力和考虑队列离散变量，实现全局最优的延迟减少性能


<details>
  <summary>Details</summary>
Motivation: 解决车辆边缘计算网络中资源利用不足和负载拥塞的问题，最小化车辆用户的整体等待延迟

Method: 基于网络协作的任务卸载解决方案，通过预测边缘服务器瞬时处理能力识别过载服务器，并考虑队列离散变量进行精确估计

Result: 理论和数值双重评估显示，所提方案相比现有方法实现了全局最优的延迟减少性能，在真实地图虚拟环境中的可行性测试得到验证

Conclusion: 该技术能够有效解决组合优化挑战，通过精确的过载服务器识别和队列管理实现最优性能

Abstract: This work considers a parallel task execution strategy in vehicular edge
computing (VEC) networks, where edge servers are deployed along the roadside to
process offloaded computational tasks of vehicular users. To minimize the
overall waiting delay among vehicular users, a novel task offloading solution
is implemented based on the network cooperation balancing resource
under-utilization and load congestion. Dual evaluation through theoretical and
numerical ways shows that the developed solution achieves a globally optimal
delay reduction performance compared to existing methods, which is also
approved by the feasibility test over a real-map virtual environment. The
in-depth analysis reveals that predicting the instantaneous processing power of
edge servers facilitates the identification of overloaded servers, which is
critical for determining network delay. By considering discrete variables of
the queue, the proposed technique's precise estimation can effectively address
these combinatorial challenges to achieve optimal performance.

</details>


### [6] [Analyzing the Effect of an Extreme Weather Event on Telecommunications and Information Technology: Insights from 30 Days of Flooding](https://arxiv.org/abs/2509.04219)
*Leandro Márcio Bertholdo,Renan Barreto Paredes,Gabriela de Lima Marin,Cesar A. H. Loureiro,Milton Kaoru Kashiwakura Pedro de Botelho Marcos*

Main category: cs.NI

TL;DR: 巴西里约格拉德布勒州2024年5月气候灾害期间的电信基础设施弹性研究，通过网络测量、光纤切断报告和互联网交换中心数据构建综合数据集，分析网络中断与水文因素的关联性。


<details>
  <summary>Details</summary>
Motivation: 研穵2024年5月巴西里约格拉德布勒州严重降雨导致的电信基础设施损坏情况，评估信息通信技术基础设施在极端气候事件中的弹性和耐受能力。

Method: 构建综合的电信数据集，包括互联网测量、光纤切断报告和互联网交换中心路由数据，并将网络中断与水文因素进行相关性分析。

Result: 初步发现揭示了连接恢复趋势、基础设施脏漏和用户行为变化。数据集显示了光纤网络、数据中心和互联网流量在极端事件中的弹性特征。

Conclusion: 该研究构建的综合数据集为灾害恢复策略和健壮电信系统的发展提供了重要支持，并为未来研究信息通信技术基础设施的耐受能力提供了实证基础。

Abstract: In May 2024, weeks of severe rainfall in Rio Grande do Sul, Brazil caused
widespread damage to infrastructure, impacting over 400 cities and 2.3 million
people. This study presents the construction of comprehensive
telecommunications datasets during this climatic event, encompassing Internet
measurements, fiber cut reports, and Internet Exchange routing data. By
correlating network disruptions with hydrological and operational factors, the
dataset offers insights into the resilience of fiber networks, data centers,
and Internet traffic during critical events. For each scenario, we investigate
failures related to the Information and Communication Technology infrastructure
and highlight the challenges faced when its resilience is critically tested.
Preliminary findings reveal trends in connectivity restoration, infrastructure
vulnerabilities, and user behavior changes. These datasets and pre-analysis aim
to support future research on disaster recovery strategies and the development
of robust telecommunications systems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [PG-Agent: An Agent Powered by Page Graph](https://arxiv.org/abs/2509.03536)
*Weizhi Chen,Ziwei Wang,Leyang Yang,Sheng Zhou,Xiaoxuan Tang,Jiajun Bu,Yong Li,Wei Jiang*

Main category: cs.AI

TL;DR: 这篇论文提出了PG-Agent框架，通过将顺序GUI操作转换为页面图并结合RAG技术，提升了GUI机器人的环境感知能力和演示性能。


<details>
  <summary>Details</summary>
Motivation: 现有GUI机器人使用顺序多步操作作为知识，无法抓取页面间复杂的迁移关系，导致环境感知不深入且新场景演示性差。

Method: 设计自动化流水线将顺序播放转换为页面图，显式建模页面图结构；结合RAG技术从页面图中检索GUI感知指南；提出任务分解策略的多机器人框架PG-Agent。

Result: 在多个标准测试集上进行了广泛实验，证明了PG-Agent的有效性，即使用有限的播放来构建页面图也能获得良好效果。

Conclusion: 通过页面图建模和RAG技术，PG-Agent能够更好地感知GUI环境并演示到新场景，为GUI机器人提供了更好的知识表示和演示能力。

Abstract: Graphical User Interface (GUI) agents possess significant commercial and
social value, and GUI agents powered by advanced multimodal large language
models (MLLMs) have demonstrated remarkable potential. Currently, existing GUI
agents usually utilize sequential episodes of multi-step operations across
pages as the prior GUI knowledge, which fails to capture the complex transition
relationship between pages, making it challenging for the agents to deeply
perceive the GUI environment and generalize to new scenarios. Therefore, we
design an automated pipeline to transform the sequential episodes into page
graphs, which explicitly model the graph structure of the pages that are
naturally connected by actions. To fully utilize the page graphs, we further
introduce Retrieval-Augmented Generation (RAG) technology to effectively
retrieve reliable perception guidelines of GUI from them, and a tailored
multi-agent framework PG-Agent with task decomposition strategy is proposed to
be injected with the guidelines so that it can generalize to unseen scenarios.
Extensive experiments on various benchmarks demonstrate the effectiveness of
PG-Agent, even with limited episodes for page graph construction.

</details>


### [8] [Multilinear and Linear Programs for Partially Identifiable Queries in Quasi-Markovian Structural Causal Models](https://arxiv.org/abs/2509.03548)
*João P. Arroyo,João G. Rodrigues,Daniel Lawand,Denis D. Mauá,Junkyu Lee,Radu Marinescu,Alex Gray,Eduardo R. Laurentino,Fabio G. Cozman*

Main category: cs.AI

TL;DR: 该论文研究准马尔可夫因果模型中部分可识别查询的概率边界计算问题，提出了基于列生成技术的新算法，通过辅助线性整数程序序列来高效计算概率边界。


<details>
  <summary>Details</summary>
Motivation: 在因果模型中，当外生变量未被完全指定时，可能无法精确计算感兴趣的概率值。研究旨在为这类部分可识别查询提供有效的概率边界计算方法。

Method: 针对单干预场景，应用列生成技术通过一系列辅助线性整数程序来计算概率边界，证明了外生变量多项式基数表示的可能性。

Result: 实验表明列生成技术优于现有方法，能够更高效地计算概率边界。

Conclusion: 提出的算法通过利用内生变量的输入概率简化了多线性规划的构建，为部分可识别因果查询的概率边界计算提供了有效的解决方案。

Abstract: We investigate partially identifiable queries in a class of causal models. We
focus on acyclic Structural Causal Models that are quasi-Markovian (that is,
each endogenous variable is connected with at most one exogenous confounder).
We look into scenarios where endogenous variables are observed (and a
distribution over them is known), while exogenous variables are not fully
specified. This leads to a representation that is in essence a Bayesian network
where the distribution of root variables is not uniquely determined. In such
circumstances, it may not be possible to precisely compute a probability value
of interest. We thus study the computation of tight probability bounds, a
problem that has been solved by multilinear programming in general, and by
linear programming when a single confounded component is intervened upon. We
present a new algorithm to simplify the construction of such programs by
exploiting input probabilities over endogenous variables. For scenarios with a
single intervention, we apply column generation to compute a probability bound
through a sequence of auxiliary linear integer programs, thus showing that a
representation with polynomial cardinality for exogenous variables is possible.
Experiments show column generation techniques to be superior to existing
methods.

</details>


### [9] [Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method](https://arxiv.org/abs/2509.03550)
*Tonghe Li,Jixin Liu,Weili Zeng,Hao Jiang*

Main category: cs.AI

TL;DR: 本文提出Diffusion-AC框架，将扩散概率模型引入空中交通冲突检测与解决任务，通过多模态决策能力显著提升安全性和性能


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习方法在冲突检测与解决中存在"单模态偏差"，导致决策灵活性不足和决策死锁问题，需要更灵活的多模态决策方法

Method: 提出Diffusion-AC框架，将策略建模为由价值函数引导的反向去噪过程，生成丰富的高质量多模态动作分布，并采用密度递进安全课程训练机制

Result: 在最具挑战性的高密度场景中，成功率高达94.1%，近距空中碰撞发生率比次优基线降低约59%，显著提升系统安全边际

Conclusion: 扩散概率模型为安全关键型冲突解决任务提供了有效的多模态决策能力，Diffusion-AC框架在复杂动态约束下展现出卓越的决策灵活性和安全性

Abstract: In the context of continuously rising global air traffic, efficient and safe
Conflict Detection and Resolution (CD&R) is paramount for air traffic
management. Although Deep Reinforcement Learning (DRL) offers a promising
pathway for CD&R automation, existing approaches commonly suffer from a
"unimodal bias" in their policies. This leads to a critical lack of
decision-making flexibility when confronted with complex and dynamic
constraints, often resulting in "decision deadlocks." To overcome this
limitation, this paper pioneers the integration of diffusion probabilistic
models into the safety-critical task of CD&R, proposing a novel autonomous
conflict resolution framework named Diffusion-AC. Diverging from conventional
methods that converge to a single optimal solution, our framework models its
policy as a reverse denoising process guided by a value function, enabling it
to generate a rich, high-quality, and multimodal action distribution. This core
architecture is complemented by a Density-Progressive Safety Curriculum (DPSC),
a training mechanism that ensures stable and efficient learning as the agent
progresses from sparse to high-density traffic environments. Extensive
simulation experiments demonstrate that the proposed method significantly
outperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the
most challenging high-density scenarios, Diffusion-AC not only maintains a high
success rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions
(NMACs) by approximately 59% compared to the next-best-performing baseline,
significantly enhancing the system's safety margin. This performance leap stems
from its unique multimodal decision-making capability, which allows the agent
to flexibly switch to effective alternative maneuvers.

</details>


### [10] [Handling Infinite Domain Parameters in Planning Through Best-First Search with Delayed Partial Expansions](https://arxiv.org/abs/2509.03953)
*Ángel Aso-Mollar,Diego Aineto,Enrico Scala,Eva Onaindia*

Main category: cs.AI

TL;DR: 提出了一种新的启发式搜索算法，将控制参数作为真正的决策点处理，而不是作为约束条件，通过延迟部分扩展机制在无限决策空间中进行搜索


<details>
  <summary>Details</summary>
Motivation: 现有方法将控制参数作为嵌入式约束处理，而不是作为搜索空间中的决策点，这限制了搜索效率。需要一种能够显式处理控制参数作为真正决策点的方法

Method: 开发了一种最佳优先的启发式搜索算法，采用延迟部分扩展的概念，在控制参数定义的无限决策空间中进行系统搜索，而不是完全扩展状态

Result: 该算法在涉及控制参数的规划问题求解中与现有方法相比具有竞争力，并在特定条件下证明了极限完备性

Conclusion: 将控制参数作为显式决策点处理的搜索算法是解决包含控制参数的规划问题的有效替代方案，延迟部分扩展机制能够有效处理无限决策空间

Abstract: In automated planning, control parameters extend standard action
representations through the introduction of continuous numeric decision
variables. Existing state-of-the-art approaches have primarily handled control
parameters as embedded constraints alongside other temporal and numeric
restrictions, and thus have implicitly treated them as additional constraints
rather than as decision points in the search space. In this paper, we propose
an efficient alternative that explicitly handles control parameters as true
decision points within a systematic search scheme. We develop a best-first,
heuristic search algorithm that operates over infinite decision spaces defined
by control parameters and prove a notion of completeness in the limit under
certain conditions. Our algorithm leverages the concept of delayed partial
expansion, where a state is not fully expanded but instead incrementally
expands a subset of its successors. Our results demonstrate that this novel
search algorithm is a competitive alternative to existing approaches for
solving planning problems involving control parameters.

</details>


### [11] [Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents](https://arxiv.org/abs/2509.03581)
*Davide Paglieri,Bartłomiej Cupiał,Jonathan Cook,Ulyana Piterbarg,Jens Tuyls,Edward Grefenstette,Jakob Nicolaus Foerster,Jack Parker-Holder,Tim Rocktäschel*

Main category: cs.AI

TL;DR: 该论文提出了一种动态规划框架，让LLM智能体能够灵活决定何时进行规划，通过监督微调和强化学习两阶段训练，在长时程任务中实现了更高的样本效率和更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法如ReAct要求LLM在每次行动前都进行规划，这计算成本高昂且在长时程任务中性能下降，而完全不规划又会限制性能表现。需要一种动态规划方法来平衡计算效率和任务性能。

Method: 提出两阶段训练流程：1）在多样化合成数据上进行监督微调，为动态规划做准备；2）在长时程环境中使用强化学习来精炼这种能力。

Result: 在Crafter环境中的实验表明，动态规划智能体具有更高的样本效率，能持续实现更复杂的目标，并且能够有效利用人类编写的规划来超越其独立能力。

Conclusion: 这是首个探索训练LLM智能体进行动态测试时计算分配的研究，为更高效、自适应和可控的智能体系统开辟了新途径。

Abstract: Training large language models (LLMs) to reason via reinforcement learning
(RL) significantly improves their problem-solving capabilities. In agentic
settings, existing methods like ReAct prompt LLMs to explicitly plan before
every action; however, we demonstrate that always planning is computationally
expensive and degrades performance on long-horizon tasks, while never planning
further limits performance. To address this, we introduce a conceptual
framework formalizing dynamic planning for LLM agents, enabling them to
flexibly decide when to allocate test-time compute for planning. We propose a
simple two-stage training pipeline: (1) supervised fine-tuning on diverse
synthetic data to prime models for dynamic planning, and (2) RL to refine this
capability in long-horizon environments. Experiments on the Crafter environment
show that dynamic planning agents trained with this approach are more
sample-efficient and consistently achieve more complex objectives.
Additionally, we demonstrate that these agents can be effectively steered by
human-written plans, surpassing their independent capabilities. To our
knowledge, this work is the first to explore training LLM agents for dynamic
test-time compute allocation in sequential decision-making tasks, paving the
way for more efficient, adaptive, and controllable agentic systems.

</details>


### [12] [Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE](https://arxiv.org/abs/2509.03626)
*Zahra Zehtabi Sabeti Moghaddam,Zeinab Dehghani,Maneeha Rani,Koorosh Aslansefat,Bhupesh Kumar Mishra,Rameez Raja Kureshi,Dhavalkumar Thakker*

Main category: cs.AI

TL;DR: KG-SMILE是一个基于扰动的框架，为图RAG提供token和组件级可解释性，通过识别对生成输出影响最大的图实体和关系来提高透明度


<details>
  <summary>Details</summary>
Motivation: 解决生成式AI（如LLMs）产生幻觉和不可验证声明的问题，特别是在医疗等敏感领域需要精确性的场景中，RAG虽然提高了准确性但仍不透明且依赖数据质量

Method: 开发了方法无关的基于扰动的框架，应用受控扰动、计算相似性并训练加权线性替代模型，使用SMILE方法实现知识图谱的可解释性

Result: KG-SMILE在保真度、忠实度、一致性、稳定性和准确性等综合归因指标上表现出色，产生稳定且与人类对齐的解释

Conclusion: KG-SMILE能够在模型有效性和可解释性之间取得平衡，促进机器学习技术的更大透明度和信任度

Abstract: Generative AI, such as Large Language Models (LLMs), has achieved impressive
progress but still produces hallucinations and unverifiable claims, limiting
reliability in sensitive domains. Retrieval-Augmented Generation (RAG) improves
accuracy by grounding outputs in external knowledge, especially in domains like
healthcare, where precision is vital. However, RAG remains opaque and
essentially a black box, heavily dependent on data quality. We developed a
method-agnostic, perturbation-based framework that provides token and
component-level interoperability for Graph RAG using SMILE and named it as
Knowledge-Graph (KG)-SMILE. By applying controlled perturbations, computing
similarities, and training weighted linear surrogates, KG-SMILE identifies the
graph entities and relations most influential to generated outputs, thereby
making RAG more transparent. We evaluate KG-SMILE using comprehensive
attribution metrics, including fidelity, faithfulness, consistency, stability,
and accuracy. Our findings show that KG-SMILE produces stable, human-aligned
explanations, demonstrating its capacity to balance model effectiveness with
interpretability and thereby fostering greater transparency and trust in
machine learning technologies.

</details>


### [13] [CausalARC: Abstract Reasoning with Causal World Models](https://arxiv.org/abs/2509.03636)
*Jacqueline Maasch,John Kalantari,Kia Khezeli*

Main category: cs.AI

TL;DR: CausalARC是一个用于AI推理的测试平台，专注于低数据和分布外场景，基于因果世界模型提供观察、干预和反事实反馈。


<details>
  <summary>Details</summary>
Motivation: 解决AI在有限数据和分布偏移下适应新问题设置的推理需求，需要一个能够提供因果反馈的测试环境。

Method: 构建基于结构因果模型的因果世界模型，通过数据增强提供观察、干预和反事实的少样本上下文学习演示。

Result: 开发了CausalARC测试平台，展示了在四个语言模型评估设置中的应用：测试时训练的抽象推理、上下文学习的反事实推理、程序合成和因果发现。

Conclusion: CausalARC为AI推理提供了一个具有因果基础的实验测试平台，能够评估模型在低数据和分布外场景下的推理能力。

Abstract: Reasoning requires adaptation to novel problem settings under limited data
and distribution shift. This work introduces CausalARC: an experimental testbed
for AI reasoning in low-data and out-of-distribution regimes, modeled after the
Abstraction and Reasoning Corpus (ARC). Each CausalARC reasoning task is
sampled from a fully specified causal world model, formally expressed as a
structural causal model. Principled data augmentations provide observational,
interventional, and counterfactual feedback about the world model in the form
of few-shot, in-context learning demonstrations. As a proof-of-concept, we
illustrate the use of CausalARC for four language model evaluation settings:
(1) abstract reasoning with test-time training, (2) counterfactual reasoning
with in-context learning, (3) program synthesis, and (4) causal discovery with
logical reasoning.

</details>


### [14] [Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations](https://arxiv.org/abs/2509.03644)
*François Olivier,Zied Bouraoui*

Main category: cs.AI

TL;DR: 这篇论文提出了一种原型神经符号系统Embodied-LM，通过基于图像模式的体验基础表征来改善大语言模型的逻辑推理能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在逻辑推理方面存在错误，缺乏像人类一样的健壮心智表征。需要基于体验的认知结构来改善理解和推理能力。

Method: 使用图像模式基础理解和逻辑推理，通过声明式空间推理在答案集编程中实现。将认知结构形式化为可执行程序。

Result: 证明LLM可以被引导通过体验认知结构来解释场景，这些结构可以形式化为可执行程序，并支持更有效的逻辑推理和更好的可解释性。

Conclusion: 虽然当前实现主要关注空间原语，但为维括更复杂和动态表征的计算基础。

Abstract: Despite significant progress in natural language understanding, Large
Language Models (LLMs) remain error-prone when performing logical reasoning,
often lacking the robust mental representations that enable human-like
comprehension. We introduce a prototype neurosymbolic system, Embodied-LM, that
grounds understanding and logical reasoning in schematic representations based
on image schemas-recurring patterns derived from sensorimotor experience that
structure human cognition. Our system operationalizes the spatial foundations
of these cognitive structures using declarative spatial reasoning within Answer
Set Programming. Through evaluation on logical deduction problems, we
demonstrate that LLMs can be guided to interpret scenarios through embodied
cognitive structures, that these structures can be formalized as executable
programs, and that the resulting representations support effective logical
reasoning with enhanced interpretability. While our current implementation
focuses on spatial primitives, it establishes the computational foundation for
incorporating more complex and dynamic representations.

</details>


### [15] [Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning](https://arxiv.org/abs/2509.03646)
*Haozhe Wang,Qixin Xu,Che Liu,Junhong Wu,Fangzhen Lin,Wenhu Chen*

Main category: cs.AI

TL;DR: 论文揭示了强化学习提升大语言模型推理能力的内在机制，发现推理层次结构的涌现现象，并提出HICRA算法通过聚焦高影响力规划token来显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习已被证明能有效提升大语言模型的复杂推理能力，但其成功背后的机制仍然不明确。研究者希望揭示RL优化过程中的关键动态和瓶颈。

Method: 通过分析发现推理层次结构的涌现现象，提出HIerarchy-Aware Credit Assignment (HICRA)算法，该算法专注于优化高影响力的规划token，而不是对所有token施加均等的优化压力。

Result: HICRA算法显著优于强基线方法，验证了语义熵作为衡量策略探索的优越指标，相比token级熵等误导性指标更具指导意义。

Conclusion: 聚焦策略瓶颈是解锁高级推理的关键，HICRA通过层次感知的信用分配机制有效提升了强化学习在大语言模型推理优化中的效率。

Abstract: Reinforcement Learning (RL) has proven highly effective at enhancing the
complex reasoning abilities of Large Language Models (LLMs), yet underlying
mechanisms driving this success remain largely opaque. Our analysis reveals
that puzzling phenomena like ``aha moments", ``length-scaling'' and entropy
dynamics are not disparate occurrences but hallmarks of an emergent reasoning
hierarchy, akin to the separation of high-level strategic planning from
low-level procedural execution in human cognition. We uncover a compelling
two-phase dynamic: initially, a model is constrained by procedural correctness
and must improve its low-level skills. The learning bottleneck then decisively
shifts, with performance gains being driven by the exploration and mastery of
high-level strategic planning. This insight exposes a core inefficiency in
prevailing RL algorithms like GRPO, which apply optimization pressure
agnostically and dilute the learning signal across all tokens. To address this,
we propose HIerarchy-Aware Credit Assignment (HICRA), an algorithm that
concentrates optimization efforts on high-impact planning tokens. HICRA
significantly outperforms strong baselines, demonstrating that focusing on this
strategic bottleneck is key to unlocking advanced reasoning. Furthermore, we
validate semantic entropy as a superior compass for measuring strategic
exploration over misleading metrics such as token-level entropy.

</details>


### [16] [An Empirical Evaluation of Factors Affecting SHAP Explanation of Time Series Classification](https://arxiv.org/abs/2509.03649)
*Davide Italo Serramazza,Nikos Papadeas,Zahraa Abdallah,Georgiana Ifrim*

Main category: cs.AI

TL;DR: 本文研究了时间序列分类中SHAP解释方法的优化，发现分段数量比具体分段算法对解释质量影响更大，等长分段优于大多数定制算法，并提出了一种新的基于段长的归因归一化技术。


<details>
  <summary>Details</summary>
Motivation: SHAP方法在时间序列分类中计算复杂度高，现有研究通过分段聚合来降低计算成本，但最优分段策略选择仍是一个开放问题。

Method: 研究了8种不同的时间序列分割算法，使用InterpretTime和AUC Difference两种评估方法，在多元和单变量时间序列上进行实验。

Result: 发现分段数量对解释质量影响大于具体分段方法，等长分段表现优于大多数定制算法，新提出的长度加权归一化技术能持续提升归因质量。

Conclusion: 在时间序列解释中，简单的等长分段配合长度加权归一化是实用且有效的策略，分段数量是影响解释质量的关键因素。

Abstract: Explainable AI (XAI) has become an increasingly important topic for
understanding and attributing the predictions made by complex Time Series
Classification (TSC) models. Among attribution methods, SHapley Additive
exPlanations (SHAP) is widely regarded as an excellent attribution method; but
its computational complexity, which scales exponentially with the number of
features, limits its practicality for long time series. To address this, recent
studies have shown that aggregating features via segmentation, to compute a
single attribution value for a group of consecutive time points, drastically
reduces SHAP running time. However, the choice of the optimal segmentation
strategy remains an open question. In this work, we investigated eight
different Time Series Segmentation algorithms to understand how segment
compositions affect the explanation quality. We evaluate these approaches using
two established XAI evaluation methodologies: InterpretTime and AUC Difference.
Through experiments on both Multivariate (MTS) and Univariate Time Series
(UTS), we find that the number of segments has a greater impact on explanation
quality than the specific segmentation method. Notably, equal-length
segmentation consistently outperforms most of the custom time series
segmentation algorithms. Furthermore, we introduce a novel attribution
normalisation technique that weights segments by their length and we show that
it consistently improves attribution quality.

</details>


### [17] [PersonaTeaming: Exploring How Introducing Personas Can Improve Automated AI Red-Teaming](https://arxiv.org/abs/2509.03728)
*Wesley Hanwen Deng,Sunnie S. Y. Kim,Akshita Jha,Ken Holstein,Motahhare Eslami,Lauren Wilcox,Leon A Gatys*

Main category: cs.AI

TL;DR: 人格化红队测试方法PersonaTeaming，通过在对手提示生成中引入不同人设，显著提高了AI模型攻击成功率（最高提升144.1%），同时保持提示多样性。


<details>
  <summary>Details</summary>
Motivation: 当前自动化红队测试方法忽视了人员身份和背景对测试策略的影响，而人工红队测试中身份因素对风险发现至关重要。需要将人身份因素结合到自动化测试中。

Method: 提出PersonaTeaming方法：1）基于"红队专家"或"普通AI用户"人设进行提示突变；2）发展动态人设生成算法，自动生成适配不同种子提示的人设类型；3）开发新的"突变距离"指标来补充现有的多样性测量。

Result: 实验结果显示，通过人设突变方法，对比最先进的RainbowPlus方法，攻击成功率最高提升了144.1%，同时保持了提示的多样性。

Conclusion: 人设突变能够有效提高自动化红队测试的效果，为未来研究提供了自动化与人工红队测试相结合的新方向。

Abstract: Recent developments in AI governance and safety research have called for
red-teaming methods that can effectively surface potential risks posed by AI
models. Many of these calls have emphasized how the identities and backgrounds
of red-teamers can shape their red-teaming strategies, and thus the kinds of
risks they are likely to uncover. While automated red-teaming approaches
promise to complement human red-teaming by enabling larger-scale exploration of
model behavior, current approaches do not consider the role of identity. As an
initial step towards incorporating people's background and identities in
automated red-teaming, we develop and evaluate a novel method, PersonaTeaming,
that introduces personas in the adversarial prompt generation process to
explore a wider spectrum of adversarial strategies. In particular, we first
introduce a methodology for mutating prompts based on either "red-teaming
expert" personas or "regular AI user" personas. We then develop a dynamic
persona-generating algorithm that automatically generates various persona types
adaptive to different seed prompts. In addition, we develop a set of new
metrics to explicitly measure the "mutation distance" to complement existing
diversity measurements of adversarial prompts. Our experiments show promising
improvements (up to 144.1%) in the attack success rates of adversarial prompts
through persona mutation, while maintaining prompt diversity, compared to
RainbowPlus, a state-of-the-art automated red-teaming method. We discuss the
strengths and limitations of different persona types and mutation methods,
shedding light on future opportunities to explore complementarities between
automated and human red-teaming approaches.

</details>


### [18] [The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs](https://arxiv.org/abs/2509.03730)
*Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez*

Main category: cs.AI

TL;DR: 该研究系统分析了LLM的人格特质，发现指令对齐能稳定特质表达但自我报告无法可靠预测行为，人格注入能改变自我报告但对实际行为影响有限


<details>
  <summary>Details</summary>
Motivation: 理解LLM是否表现出类似人类的人格特质模式，以及这些特质是否能预测行为，现有研究主要依赖简化的自我报告而缺乏行为验证

Method: 从三个维度系统分析LLM人格：(1)训练阶段特质配置的动态演变；(2)自我报告特质在行为任务中的预测效度；(3)人格注入等干预措施对自我报告和行为的影响

Result: 指令对齐显著稳定特质表达并增强特质相关性，但自我报告特质无法可靠预测行为，人格注入能成功引导自我报告但对实际行为影响很小或不一致

Conclusion: 研究挑战了关于LLM人格的假设，强调需要区分表面特质表达和行为一致性，在对齐和可解释性方面需要更深入的评估

Abstract: Personality traits have long been studied as predictors of human
behavior.Recent advances in Large Language Models (LLMs) suggest similar
patterns may emerge in artificial systems, with advanced LLMs displaying
consistent behavioral tendencies resembling human traits like agreeableness and
self-regulation. Understanding these patterns is crucial, yet prior work
primarily relied on simplified self-reports and heuristic prompting, with
little behavioral validation. In this study, we systematically characterize LLM
personality across three dimensions: (1) the dynamic emergence and evolution of
trait profiles throughout training stages; (2) the predictive validity of
self-reported traits in behavioral tasks; and (3) the impact of targeted
interventions, such as persona injection, on both self-reports and behavior.
Our findings reveal that instructional alignment (e.g., RLHF, instruction
tuning) significantly stabilizes trait expression and strengthens trait
correlations in ways that mirror human data. However, these self-reported
traits do not reliably predict behavior, and observed associations often
diverge from human patterns. While persona injection successfully steers
self-reports in the intended direction, it exerts little or inconsistent effect
on actual behavior. By distinguishing surface-level trait expression from
behavioral consistency, our findings challenge assumptions about LLM
personality and underscore the need for deeper evaluation in alignment and
interpretability.

</details>


### [19] [Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation](https://arxiv.org/abs/2509.03736)
*James Mooney,Josef Woldense,Zheng Robert Jia,Shirley Anugrah Hayati,My Ha Nguyen,Vipul Raheja,Dongyeop Kang*

Main category: cs.AI

TL;DR: 这篇论文通过实验研究发现，虽然大语言模型能够生成与人类相似的调查数据，但其内部状态在不同实验设置下显示出显著的不一致性，无法真正替代真实人类参与者。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型生成的合成代理是否能够作为真实人类参与者的替代品，尤其是考察代理是否具有内部一致性。

Method: 设计了一个研究方案，包括(a)揭示代理的内部状态，(b)在基本对话环境中检验代理行为，通过对比不同实验设置下的行为来评估内部一致性。

Result: 在不同模型家族和模型大小上都发现了显著的内部不一致性。虽然代理能生成与人类对应者相似的响应，但在不同实验情境下行为不一致。

Conclusion: 大语言模型生成的合成代理缺乏内部一致性，这是他们无法准确替代真实人类参与者的关键问题，对人类主体研究中使用人工智能代理提出了重要警示。

Abstract: The impressive capabilities of Large Language Models (LLMs) have fueled the
notion that synthetic agents can serve as substitutes for real participants in
human-subject research. In an effort to evaluate the merits of this claim,
social science researchers have largely focused on whether LLM-generated survey
data corresponds to that of a human counterpart whom the LLM is prompted to
represent. In contrast, we address a more fundamental question: Do agents
maintain internal consistency, retaining similar behaviors when examined under
different experimental settings? To this end, we develop a study designed to
(a) reveal the agent's internal state and (b) examine agent behavior in a basic
dialogue setting. This design enables us to explore a set of behavioral
hypotheses to assess whether an agent's conversation behavior is consistent
with what we would expect from their revealed internal state. Our findings on
these hypotheses show significant internal inconsistencies in LLMs across model
families and at differing model sizes. Most importantly, we find that, although
agents may generate responses matching those of their human counterparts, they
fail to be internally consistent, representing a critical gap in their
capabilities to accurately substitute for real participants in human-subject
research. Our simulation code and data are publicly accessible.

</details>


### [20] [RAGuard: A Novel Approach for in-context Safe Retrieval Augmented Generation for LLMs](https://arxiv.org/abs/2509.03768)
*Connor Walker,Koorosh Aslansefat,Mohammad Naveed Akram,Yiannis Papadopoulos*

Main category: cs.AI

TL;DR: RAGuard是一个增强的检索增强生成框架，专门为海上风电维护设计，通过并行查询技术手册和安全关键文档，显著提升安全召回率从接近0%到50%以上，同时保持技术召回率在60%以上。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型在处理高度专业化或意外场景时存在安全风险，特别是在海上风电维护等关键领域，需要确保技术准确性和安全性。

Method: 提出RAGuard框架，采用并行查询两个索引（技术知识库和安全文档库），分配独立的检索预算；进一步开发SafetyClamp扩展，通过获取更大的候选池并进行硬钳位来保证安全槽位。

Result: 在稀疏(BM25)、稠密(Dense Passage Retrieval)和混合检索范式下评估，安全召回率从RAG的接近0%提升到RAGuard的50%以上，技术召回率保持在60%以上。

Conclusion: RAGuard和SafetyClamp有潜力为关键维护场景中LLM驱动的决策支持建立新的安全保证标准。

Abstract: Accuracy and safety are paramount in Offshore Wind (OSW) maintenance, yet
conventional Large Language Models (LLMs) often fail when confronted with
highly specialised or unexpected scenarios. We introduce RAGuard, an enhanced
Retrieval-Augmented Generation (RAG) framework that explicitly integrates
safety-critical documents alongside technical manuals.By issuing parallel
queries to two indices and allocating separate retrieval budgets for knowledge
and safety, RAGuard guarantees both technical depth and safety coverage. We
further develop a SafetyClamp extension that fetches a larger candidate pool,
"hard-clamping" exact slot guarantees to safety. We evaluate across sparse
(BM25), dense (Dense Passage Retrieval) and hybrid retrieval paradigms,
measuring Technical Recall@K and Safety Recall@K. Both proposed extensions of
RAG show an increase in Safety Recall@K from almost 0\% in RAG to more than
50\% in RAGuard, while maintaining Technical Recall above 60\%. These results
demonstrate that RAGuard and SafetyClamp have the potential to establish a new
standard for integrating safety assurance into LLM-powered decision support in
critical maintenance contexts.

</details>


### [21] [Leveraging LLM-Based Agents for Intelligent Supply Chain Planning](https://arxiv.org/abs/2509.03811)
*Yongzhi Qi,Jiaheng Yin,Jianshen Zhang,Dongyang Geng,Zhengyu Chen,Hao Hu,Wei Qi,Zuo-Jun Max Shen*

Main category: cs.AI

TL;DR: 基于大语言模型构建供应链规划组件(SCPA)，通过理解领域知识、任务分解和工具使用，在JD.com真实场景中实现了劳务减少和关键指标提升


<details>
  <summary>Details</summary>
Motivation: 解决电子商务平台供应链规划中的数据收集、长期规划制定、动态调整以及可解释性、效率和可靠性等实践挑战

Method: 构建SCPA框架，能够理解领域知识、理解运营商需求、分解任务、利用或创建新工具，返回基于证据的规划报告

Result: 在JD.com真实场景中部署，有效减少了劳务工作量，提高了准确性、库存可用性等关键指标

Conclusion: 证明了LLM-agent在供应链领域的可行性，为AI技术在实际供应链管理问题中的应用提供了新方向

Abstract: In supply chain management, planning is a critical concept. The movement of
physical products across different categories, from suppliers to warehouse
management, to sales, and logistics transporting them to customers, entails the
involvement of many entities. It covers various aspects such as demand
forecasting, inventory management, sales operations, and replenishment. How to
collect relevant data from an e-commerce platform's perspective, formulate
long-term plans, and dynamically adjust them based on environmental changes,
while ensuring interpretability, efficiency, and reliability, is a practical
and challenging problem. In recent years, the development of AI technologies,
especially the rapid progress of large language models, has provided new tools
to address real-world issues. In this work, we construct a Supply Chain
Planning Agent (SCPA) framework that can understand domain knowledge,
comprehend the operator's needs, decompose tasks, leverage or create new tools,
and return evidence-based planning reports. We deploy this framework in
JD.com's real-world scenario, demonstrating the feasibility of LLM-agent
applications in the supply chain. It effectively reduced labor and improved
accuracy, stock availability, and other key metrics.

</details>


### [22] [Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning](https://arxiv.org/abs/2509.03817)
*Wei Yang,Jesse Thomason*

Main category: cs.AI

TL;DR: 提出了Meta-Policy Deliberation Framework (MPDF)和SoftRankPO算法，通过让LLM智能体学习元认知策略来提升多智能体推理能力，在数学和通用推理基准上取得了4-5%的准确率提升


<details>
  <summary>Details</summary>
Motivation: 现有多智能体LLM系统的固定协作协议限制了推理效果，忽视了智能体内部的元认知能力（如不确定性、置信度等），需要让智能体能够基于内部认知状态自适应调整策略

Method: MPDF框架让智能体学习去中心化的元认知动作策略（Persist、Refine、Concede），并开发SoftRankPO强化学习算法，通过基于平滑正态分位数映射的奖励排序来稳定训练过程

Result: 在五个数学和通用推理基准测试中，MPDF+SoftRankPO相比六种最先进的启发式和基于学习的多智能体推理算法，平均准确率绝对提升了4-5%

Conclusion: 这项工作提出了学习自适应元认知策略的新范式，将重点从设计固定协议转向学习动态的、深思熟虑的策略，为多智能体LLM系统提供了新的发展方向

Abstract: Multi-agent systems of large language models (LLMs) show promise for complex
reasoning, but their effectiveness is often limited by fixed collaboration
protocols. These frameworks typically focus on macro-level orchestration while
overlooking agents' internal deliberative capabilities. This critical
meta-cognitive blindspot treats agents as passive executors unable to adapt
their strategy based on internal cognitive states like uncertainty or
confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where
agents learn a decentralized policy over a set of high-level meta-cognitive
actions: Persist, Refine, and Concede. To overcome the instability of
traditional policy gradients in this setting, we develop SoftRankPO, a novel
reinforcement learning algorithm. SoftRankPO stabilizes training by shaping
advantages based on the rank of rewards mapped through smooth normal quantiles,
making the learning process robust to reward variance. Experiments show that
MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across
five mathematical and general reasoning benchmarks compared to six
state-of-the-art heuristic and learning-based multi-agent reasoning algorithms.
Our work presents a paradigm for learning adaptive, meta-cognitive policies for
multi-agent LLM systems, shifting the focus from designing fixed protocols to
learning dynamic, deliberative strategies.

</details>


### [23] [What Would an LLM Do? Evaluating Policymaking Capabilities of Large Language Models](https://arxiv.org/abs/2509.03827)
*Pierre Le Coz,Jia An Liu,Debarun Bhattacharjya,Georgina Curto,Serge Stinckwich*

Main category: cs.AI

TL;DR: 本文评估了大型语言模型在无家可归问题政策制定中与领域专家的对齐程度，开发了包含四个地理区域的决策场景基准，并通过基于代理的模型模拟政策的社会影响。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理非结构化数据、探索灵活场景和处理多样化情境因素方面具有独特优势，可能为社会政策制定提供新见解，特别是在影响全球1.5亿人的无家可归问题上。

Method: 开发了包含南本德、巴塞罗那、约翰内斯堡和澳门四个地区政策选择的决策场景基准，基于人类发展的能力方法概念框架，并建立了连接基准政策与基于代理模型的自动化流程。

Result: 研究结果显示利用LLMs进行社会政策制定具有良好潜力，在引入负责任的安全护栏和情境校准后，LLMs能够以规模化替代政策的形式为人类提供有价值的见解。

Conclusion: 通过与当地领域专家合作引入负责任的安全护栏和情境校准，大型语言模型可以为社会政策制定提供有价值的规模化见解。

Abstract: Large language models (LLMs) are increasingly being adopted in high-stakes
domains. Their capacity to process vast amounts of unstructured data, explore
flexible scenarios, and handle a diversity of contextual factors can make them
uniquely suited to provide new insights for the complexity of social
policymaking. This article evaluates whether LLMs' are aligned with domain
experts (and among themselves) to inform social policymaking on the subject of
homelessness alleviation - a challenge affecting over 150 million people
worldwide. We develop a novel benchmark comprised of decision scenarios with
policy choices across four geographies (South Bend, USA; Barcelona, Spain;
Johannesburg, South Africa; Macau SAR, China). The policies in scope are
grounded in the conceptual framework of the Capability Approach for human
development. We also present an automated pipeline that connects the
benchmarked policies to an agent-based model, and we explore the social impact
of the recommended policies through simulated social scenarios. The paper
results reveal promising potential to leverage LLMs for social policy making.
If responsible guardrails and contextual calibrations are introduced in
collaboration with local domain experts, LLMs can provide humans with valuable
insights, in the form of alternative policies at scale.

</details>


### [24] [An Agentic Model Context Protocol Framework for Medical Concept Standardization](https://arxiv.org/abs/2509.03828)
*Jaerong Ahn,Andrew Wen,Nan Wang,Heling Jia,Zhiyi Yue,Sunyang Fu,Hongfang Liu*

Main category: cs.AI

TL;DR: 基于Model Context Protocol的无训练、防幻觉的OMOP CDM医学术语映射系统，通过外部资源查询提高映射效率和准确性


<details>
  <summary>Details</summary>
Motivation: OMOP CDM数据标准化过程中，源医学术语向标准概念的映射工作资源浪费且容易出错，而大语言模型存在幻觉问题不适合直接临床部署

Method: 采用Model Context Protocol(MCP)标准化框架，允许LLM与外部资源和工具交互，实现零训练、可解释的映射系统

Result: 系统能够提供实时词汇查询和结构化推理输出，显著提高了映射效率和准确性，适合直接用于探索和生产环境

Conclusion: 基于MCP的方法为OMOP CDM数据标准化提供了一种高效、准确且无需训练的映射解决方案，免除了LLM幻觉问题对临床部署的影响

Abstract: The Observational Medical Outcomes Partnership (OMOP) common data model (CDM)
provides a standardized representation of heterogeneous health data to support
large-scale, multi-institutional research. One critical step in data
standardization using OMOP CDM is the mapping of source medical terms to OMOP
standard concepts, a procedure that is resource-intensive and error-prone.
While large language models (LLMs) have the potential to facilitate this
process, their tendency toward hallucination makes them unsuitable for clinical
deployment without training and expert validation. Here, we developed a
zero-training, hallucination-preventive mapping system based on the Model
Context Protocol (MCP), a standardized and secure framework allowing LLMs to
interact with external resources and tools. The system enables explainable
mapping and significantly improves efficiency and accuracy with minimal effort.
It provides real-time vocabulary lookups and structured reasoning outputs
suitable for immediate use in both exploratory and production environments.

</details>


### [25] [A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai](https://arxiv.org/abs/2509.03830)
*Kaizhen Tan,Yufan Wu,Yuxuan Liu,Haoran Zeng*

Main category: cs.AI

TL;DR: 这篇论文提出了一种多维度AI框架，利用社交媒体多模态数据分析历史城区游客感知，通过视觉关注点、颜色主题和情感挖掘来提供可持续城市规划支持。


<details>
  <summary>Details</summary>
Motivation: 理解游客对历史城区的感知对于保护文化遗产和可持续城市规划至关重要，现有研究缺乏整体性的多模态数据分析方法。

Method: 采用多模态AI框架，整合社交媒体照片和评论数据，包括：精调语义分割模型识别视觉关注点、聚类方法提取主导颜色、混合规则和BERT模型的情感分析，从四个维度评估游客满意度。

Result: 在上海12个历史城区的应用显示：发现了美学吸引力和情感响应的空间差异，社交媒体照片与实际街景在颜色主题上存在显著差异，反映了视觉期望与实际环境的差距。

Conclusion: 该框架提供了一种整合的、数据驱动的方法来解码游客感知，为旅游业、遗产保护和公共空间设计的管理决策提供了重要依据。

Abstract: Historic urban quarters play a vital role in preserving cultural heritage
while serving as vibrant spaces for tourism and everyday life. Understanding
how tourists perceive these environments is essential for sustainable,
human-centered urban planning. This study proposes a multidimensional
AI-powered framework for analyzing tourist perception in historic urban
quarters using multimodal data from social media. Applied to twelve historic
quarters in central Shanghai, the framework integrates focal point extraction,
color theme analysis, and sentiment mining. Visual focus areas are identified
from tourist-shared photos using a fine-tuned semantic segmentation model. To
assess aesthetic preferences, dominant colors are extracted using a clustering
method, and their spatial distribution across quarters is analyzed. Color
themes are further compared between social media photos and real-world street
views, revealing notable shifts. This divergence highlights potential gaps
between visual expectations and the built environment, reflecting both
stylistic preferences and perceptual bias. Tourist reviews are evaluated
through a hybrid sentiment analysis approach combining a rule-based method and
a multi-task BERT model. Satisfaction is assessed across four dimensions:
tourist activities, built environment, service facilities, and business
formats. The results reveal spatial variations in aesthetic appeal and
emotional response. Rather than focusing on a single technical innovation, this
framework offers an integrated, data-driven approach to decoding tourist
perception and contributes to informed decision-making in tourism, heritage
conservation, and the design of aesthetically engaging public spaces.

</details>


### [26] [Continuous Monitoring of Large-Scale Generative AI via Deterministic Knowledge Graph Structures](https://arxiv.org/abs/2509.03857)
*Kishor Datta Gupta,Mohd Ariful Haque,Hasmot Ali,Marufa Kamal,Syed Bahauddin Alam,Mohammad Ashiqur Rahman*

Main category: cs.AI

TL;DR: 通过构建确定性知识图和LLM生成知识图的对比分析，提出了一种可扩展的实时监控方法来评估生成式AI的可靠性


<details>
  <summary>Details</summary>
Motivation: 解决生成式AI模型的可靠性问题（如幽灵、语义偏移、偏见），充当黑盒模型的透明评估方法，充当主观人工评估的局限性

Method: 构建两种并行知识图：确定性KG（规则基础构建）和LLM生成KG（实时文本数据流生成），采用KG指标（ICR、IPR、CI）进行结构偏移和语义差异量化，通过历史结构指标分布设置动态异常阈值

Result: 开发了一种自动化实时监控框架，能够连续计算两种KG之间的偏移，主动识别和标记显著偏移，及时检测语义异常或幽灵

Conclusion: 通过确定性和动态生成知识图之间的结构化、指标驱动比较，提供了一种稳健且可扩展的生成式AI可靠性评估框架

Abstract: Generative AI (GEN AI) models have revolutionized diverse application domains
but present substantial challenges due to reliability concerns, including
hallucinations, semantic drift, and inherent biases. These models typically
operate as black-boxes, complicating transparent and objective evaluation.
Current evaluation methods primarily depend on subjective human assessment,
limiting scalability, transparency, and effectiveness. This research proposes a
systematic methodology using deterministic and Large Language Model
(LLM)-generated Knowledge Graphs (KGs) to continuously monitor and evaluate GEN
AI reliability. We construct two parallel KGs: (i) a deterministic KG built
using explicit rule-based methods, predefined ontologies, domain-specific
dictionaries, and structured entity-relation extraction rules, and (ii) an
LLM-generated KG dynamically derived from real-time textual data streams such
as live news articles. Utilizing real-time news streams ensures authenticity,
mitigates biases from repetitive training, and prevents adaptive LLMs from
bypassing predefined benchmarks through feedback memorization. To quantify
structural deviations and semantic discrepancies, we employ several established
KG metrics, including Instantiated Class Ratio (ICR), Instantiated Property
Ratio (IPR), and Class Instantiation (CI). An automated real-time monitoring
framework continuously computes deviations between deterministic and
LLM-generated KGs. By establishing dynamic anomaly thresholds based on
historical structural metric distributions, our method proactively identifies
and flags significant deviations, thus promptly detecting semantic anomalies or
hallucinations. This structured, metric-driven comparison between deterministic
and dynamically generated KGs delivers a robust and scalable evaluation
framework.

</details>


### [27] [Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata](https://arxiv.org/abs/2509.03863)
*Sina Khajehabdollahi,Gautier Hamon,Marko Cvjetko,Pierre-Yves Oudeyer,Clément Moulin-Frier,Cédric Colas*

Main category: cs.AI

TL;DR: 提出E&E混合策略，结合局部新颖性搜索和基于视觉语言模型的语义目标导向探索，在连续细胞自动机中发现更多样化的视觉模式


<details>
  <summary>Details</summary>
Motivation: 传统新颖性搜索方法在探索高维行为空间时容易陷入局部最优，无法到达遥远未探索区域，需要新的探索策略来突破局部新颖性边界

Method: E&E策略交替进行局部新颖性扩展和目标导向远征，利用视觉语言模型生成语义目标描述来驱动探索，在概念对齐的语义空间中评估新颖性和生成目标

Result: 在Flow Lenia连续细胞自动机上测试，E&E比现有方法发现更多样化解决方案，远征产生的解决方案对长期探索影响更大，能解锁新的行为生态位

Conclusion: E&E能够突破局部新颖性边界，以人类可理解的方式探索行为景观，为人工生命等领域的开放探索提供了有前景的模板

Abstract: Discovering diverse visual patterns in continuous cellular automata (CA) is
challenging due to the vastness and redundancy of high-dimensional behavioral
spaces. Traditional exploration methods like Novelty Search (NS) expand locally
by mutating known novel solutions but often plateau when local novelty is
exhausted, failing to reach distant, unexplored regions. We introduce
Expedition and Expansion (E&E), a hybrid strategy where exploration alternates
between local novelty-driven expansions and goal-directed expeditions. During
expeditions, E&E leverages a Vision-Language Model (VLM) to generate linguistic
goals--descriptions of interesting but hypothetical patterns that drive
exploration toward uncharted regions. By operating in semantic spaces that
align with human perception, E&E both evaluates novelty and generates goals in
conceptually meaningful ways, enhancing the interpretability and relevance of
discovered behaviors. Tested on Flow Lenia, a continuous CA known for its rich,
emergent behaviors, E&E consistently uncovers more diverse solutions than
existing exploration methods. A genealogical analysis further reveals that
solutions originating from expeditions disproportionately influence long-term
exploration, unlocking new behavioral niches that serve as stepping stones for
subsequent search. These findings highlight E&E's capacity to break through
local novelty boundaries and explore behavioral landscapes in human-aligned,
interpretable ways, offering a promising template for open-ended exploration in
artificial life and beyond.

</details>


### [28] [FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace](https://arxiv.org/abs/2509.03890)
*Yineng Yan,Xidong Wang,Jin Seng Cheng,Ran Hu,Wentao Guan,Nahid Farahmand,Hengte Lin,Yue Li*

Main category: cs.AI

TL;DR: Facebook Marketplace Assistant (FaMA) 是一个基于大语言模型的智能助手，通过自然语言交互简化C2C电商平台的复杂操作，实现98%的任务成功率和2倍的交互速度提升。


<details>
  <summary>Details</summary>
Motivation: C2C电商平台的复杂GUI界面给买卖双方带来操作负担，需要一种更直观的交互方式来简化用户体验。

Method: 开发基于LLM的智能代理FaMA，通过自然语言命令解析来自动化关键工作流程，为买卖双方提供对话式入口。

Result: FaMA在复杂任务上达到98%的成功率，交互时间缩短至原来的50%（2倍速度提升）。

Conclusion: 基于LLM的对话式智能代理为传统应用界面提供了轻量级且更易访问的替代方案，能显著提升电商平台用户体验。

Abstract: The emergence of agentic AI, powered by Large Language Models (LLMs), marks a
paradigm shift from reactive generative systems to proactive, goal-oriented
autonomous agents capable of sophisticated planning, memory, and tool use. This
evolution presents a novel opportunity to address long-standing challenges in
complex digital environments. Core tasks on Consumer-to-Consumer (C2C)
e-commerce platforms often require users to navigate complex Graphical User
Interfaces (GUIs), making the experience time-consuming for both buyers and
sellers. This paper introduces a novel approach to simplify these interactions
through an LLM-powered agentic assistant. This agent functions as a new,
conversational entry point to the marketplace, shifting the primary interaction
model from a complex GUI to an intuitive AI agent. By interpreting natural
language commands, the agent automates key high-friction workflows. For
sellers, this includes simplified updating and renewal of listings, and the
ability to send bulk messages. For buyers, the agent facilitates a more
efficient product discovery process through conversational search. We present
the architecture for Facebook Marketplace Assistant (FaMA), arguing that this
agentic, conversational paradigm provides a lightweight and more accessible
alternative to traditional app interfaces, allowing users to manage their
marketplace activities with greater efficiency. Experiments show FaMA achieves
a 98% task success rate on solving complex tasks on the marketplace and enables
up to a 2x speedup on interaction time.

</details>


### [29] [A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning](https://arxiv.org/abs/2509.03906)
*Qika Lin,Yifan Zhu,Bin Pu,Ling Huang,Haoran Luo,Jingying Ma,Zhen Peng,Tianzhe Zhao,Fangzhi Xu,Jian Zhang,Kai He,Zhonghong Ou,Swapnil Mishra,Mengling Feng*

Main category: cs.AI

TL;DR: DeepMedix-R1是一个用于胸部X光片解读的医学基础模型，通过三阶段训练实现透明推理和局部可解释性，在报告生成和视觉问答任务上显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前医学基础模型以黑盒方式生成答案，缺乏透明的推理过程和局部可解释性，阻碍了临床实际部署。

Method: 采用顺序训练流程：先在精选的CXR指令数据上微调获得基础解读能力，然后通过高质量合成推理样本实现冷启动推理，最后通过在线强化学习优化推理质量和生成性能。

Result: 在报告生成任务上比LLaVA-Rad和MedGemma分别提升14.54%和31.32%，在视觉问答任务上比MedGemma和CheXagent分别提升57.75%和23.06%。专家评审显示推理步骤的可解释性和临床合理性显著优于Qwen2.5-VL-7B模型。

Conclusion: 该工作推动了医学基础模型向整体性、透明性和临床可操作性方向发展，为CXR解读提供了更可靠的解决方案。

Abstract: Medical foundation models (FMs) have shown tremendous promise amid the rapid
advancements in artificial intelligence (AI) technologies. However, current
medical FMs typically generate answers in a black-box manner, lacking
transparent reasoning processes and locally grounded interpretability, which
hinders their practical clinical deployments. To this end, we introduce
DeepMedix-R1, a holistic medical FM for chest X-ray (CXR) interpretation. It
leverages a sequential training pipeline: initially fine-tuned on curated CXR
instruction data to equip with fundamental CXR interpretation capabilities,
then exposed to high-quality synthetic reasoning samples to enable cold-start
reasoning, and finally refined via online reinforcement learning to enhance
both grounded reasoning quality and generation performance. Thus, the model
produces both an answer and reasoning steps tied to the image's local regions
for each query. Quantitative evaluation demonstrates substantial improvements
in report generation (e.g., 14.54% and 31.32% over LLaVA-Rad and MedGemma) and
visual question answering (e.g., 57.75% and 23.06% over MedGemma and CheXagent)
tasks. To facilitate robust assessment, we propose Report Arena, a benchmarking
framework using advanced language models to evaluate answer quality, further
highlighting the superiority of DeepMedix-R1. Expert review of generated
reasoning steps reveals greater interpretability and clinical plausibility
compared to the established Qwen2.5-VL-7B model (0.7416 vs. 0.2584 overall
preference). Collectively, our work advances medical FM development toward
holistic, transparent, and clinically actionable modeling for CXR
interpretation.

</details>


### [30] [World Model Implanting for Test-time Adaptation of Embodied Agents](https://arxiv.org/abs/2509.03956)
*Minjong Yoo,Jinwoo Jang,Sihyung Yoon,Honguk Woo*

Main category: cs.AI

TL;DR: WorMI框架通过将LLM推理能力与领域特定世界模型结合，实现具身智能体在未见领域的零样本和少样本自适应


<details>
  <summary>Details</summary>
Motivation: 解决具身AI中智能体在新领域需要大量数据收集和重新训练的问题，实现跨域鲁棒自适应

Method: 原型化世界模型检索+轨迹抽象表示匹配+世界级复合注意力机制，实现测试时模型组合和知识融合

Result: 在VirtualHome和ALFWorld基准测试中优于多个基于LLM的方法，展现卓越的零样本和少样本性能

Conclusion: WorMI框架为具身智能体提供了可扩展的实时部署解决方案，在适应性和数据效率关键场景中具有重要价值

Abstract: In embodied AI, a persistent challenge is enabling agents to robustly adapt
to novel domains without requiring extensive data collection or retraining. To
address this, we present a world model implanting framework (WorMI) that
combines the reasoning capabilities of large language models (LLMs) with
independently learned, domain-specific world models through test-time
composition. By allowing seamless implantation and removal of the world models,
the embodied agent's policy achieves and maintains cross-domain adaptability.
In the WorMI framework, we employ a prototype-based world model retrieval
approach, utilizing efficient trajectory-based abstract representation
matching, to incorporate relevant models into test-time composition. We also
develop a world-wise compound attention method that not only integrates the
knowledge from the retrieved world models but also aligns their intermediate
representations with the reasoning model's representation within the agent's
policy. This framework design effectively fuses domain-specific knowledge from
multiple world models, ensuring robust adaptation to unseen domains. We
evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating
superior zero-shot and few-shot performance compared to several LLM-based
approaches across a range of unseen domains. These results highlight the
frameworks potential for scalable, real-world deployment in embodied agent
scenarios where adaptability and data efficiency are essential.

</details>


### [31] [Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent](https://arxiv.org/abs/2509.03990)
*Chunlong Wu,Zhibo Qu*

Main category: cs.AI

TL;DR: MPR是一个混合框架，通过将LLM生成的反思整合到结构化元策略内存中，在推理时通过软内存引导解码和硬规则可接受性检查来提升代理性能，无需模型权重更新。


<details>
  <summary>Details</summary>
Motivation: 现有反思策略产生的是临时性、任务特定的痕迹，无法跨任务重用；而基于强化学习的方法需要大量参数更新和计算资源。需要一种既能重用纠正知识又保持语言反思适应性的方法。

Method: 提出Meta-Policy Reflexion (MPR)框架，将LLM反思整合为结构化谓词式元策略内存(MPM)，在推理时使用软内存引导解码和硬规则可接受性检查(HAC)两种机制。

Result: 在基于AlfWorld的文本代理环境中，相比Reflexion基线，MPR在执行准确性和鲁棒性方面获得一致提升，规则可接受性检查进一步提高了稳定性。

Conclusion: MPR能够外部化可重用的纠正知识而不需要模型权重更新，强制执行领域约束以减少不安全或无效动作，同时保持基于语言反思的适应性。

Abstract: Large language model (LLM) agents achieve impressive single-task performance
but commonly exhibit repeated failures, inefficient exploration, and limited
cross-task adaptability. Existing reflective strategies (e.g., Reflexion,
ReAct) improve per-episode behavior but typically produce ephemeral,
task-specific traces that are not reused across tasks. Reinforcement-learning
based alternatives can produce transferable policies but require substantial
parameter updates and compute. In this work we introduce Meta-Policy Reflexion
(MPR): a hybrid framework that consolidates LLM-generated reflections into a
structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at
inference time through two complementary mechanisms soft memory-guided decoding
and hard rule admissibility checks(HAC). MPR (i) externalizes reusable
corrective knowledge without model weight updates, (ii) enforces domain
constraints to reduce unsafe or invalid actions, and (iii) retains the
adaptability of language-based reflection. We formalize the MPM representation,
present algorithms for update and decoding, and validate the approach in a
text-based agent environment following the experimental protocol described in
the provided implementation (AlfWorld-based). Empirical results reported in the
supplied material indicate consistent gains in execution accuracy and
robustness when compared to Reflexion baselines; rule admissibility further
improves stability. We analyze mechanisms that explain these gains, discuss
scalability and failure modes, and outline future directions for multimodal and
multi?agent extensions.

</details>


### [32] [AutoPBO: LLM-powered Optimization for Local Search PBO Solvers](https://arxiv.org/abs/2509.04007)
*Jinyuan Li,Yi Chu,Yiwen Sun,Mengchuan Zou,Shaowei Cai*

Main category: cs.AI

TL;DR: AutoPBO是一个基于大语言模型的框架，用于自动优化伪布尔优化(PBO)局部搜索求解器，在多个基准测试中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 伪布尔优化是组合问题建模的强大框架，局部搜索求解器性能优异但设计需要大量专家工作和手动调优。大语言模型在算法设计自动化方面展现潜力，但在优化PBO求解器方面尚未探索。

Method: 提出了AutoPBO框架，利用大语言模型自动增强PBO局部搜索求解器，通过自动化方式改进求解器的内部启发式策略。

Result: 在四个公共基准测试（包括真实世界基准、PB竞赛基准、整数线性规划基准和组合基准）上，AutoPBO相比6个最先进竞争对手（包括NuPBO、OraSLS、PBO-IHS、RoundingSat、Gurobi和SCIP）表现出显著改进，在保持竞争力的同时超越了之前的局部搜索方法。

Conclusion: AutoPBO为自动化局部搜索求解器设计提供了一种有前景的方法，证明了大语言模型在优化组合优化求解器方面的有效性。

Abstract: Pseudo-Boolean Optimization (PBO) provides a powerful framework for modeling
combinatorial problems through pseudo-Boolean (PB) constraints. Local search
solvers have shown excellent performance in PBO solving, and their efficiency
is highly dependent on their internal heuristics to guide the search. Still,
their design often requires significant expert effort and manual tuning in
practice. While Large Language Models (LLMs) have demonstrated potential in
automating algorithm design, their application to optimizing PBO solvers
remains unexplored. In this work, we introduce AutoPBO, a novel LLM-powered
framework to automatically enhance PBO local search solvers. We conduct
experiments on a broad range of four public benchmarks, including one
real-world benchmark, a benchmark from PB competition, an integer linear
programming optimization benchmark, and a crafted combinatorial benchmark, to
evaluate the performance improvement achieved by AutoPBO and compare it with
six state-of-the-art competitors, including two local search PBO solvers NuPBO
and OraSLS, two complete PB solvers PBO-IHS and RoundingSat, and two mixed
integer programming (MIP) solvers Gurobi and SCIP. AutoPBO demonstrates
significant improvements over previous local search approaches, while
maintaining competitive performance compared to state-of-the-art competitors.
The results suggest that AutoPBO offers a promising approach to automating
local search solver design.

</details>


### [33] [CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning](https://arxiv.org/abs/2509.04027)
*Zeyu Gan,Hao Yi,Yong Liu*

Main category: cs.AI

TL;DR: CoT-Space框架将LLM推理重新定义为连续语义空间中的优化过程，从理论和实验上证明了最优思维链长度的收敛性，解决了传统token级RL与推理级思维过程不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 传统token级强化学习框架无法与多步推理过程（如思维链）的推理级性质对齐，存在显著的理论空白，需要新的理论框架来指导推理能力的发展。

Method: 提出CoT-Space理论框架，将LLM推理从离散的token预测任务重新构建为连续推理级语义空间中的优化过程，从噪声视角和风险视角分析该过程。

Result: 理论分析表明最优思维链长度的收敛是欠拟合和过拟合之间基本权衡的自然结果，大量实验为理论发现提供了强有力的实证验证。

Conclusion: 该框架不仅为过度思考等实证现象提供了连贯解释，还为未来开发更有效和可泛化的推理智能体奠定了坚实的理论基础。

Abstract: Reinforcement Learning (RL) has become a pivotal approach for enhancing the
reasoning capabilities of Large Language Models (LLMs). However, a significant
theoretical gap persists, as traditional token-level RL frameworks fail to
align with the reasoning-level nature of complex, multi-step thought processes
like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space,
a novel theoretical framework that recasts LLM reasoning from a discrete
token-prediction task to an optimization process within a continuous,
reasoning-level semantic space. By analyzing this process from both a noise
perspective and a risk perspective, we demonstrate that the convergence to an
optimal CoT length is a natural consequence of the fundamental trade-off
between underfitting and overfitting. Furthermore, extensive experiments
provide strong empirical validation for our theoretical findings. Our framework
not only provides a coherent explanation for empirical phenomena such as
overthinking but also offers a solid theoretical foundation to guide the future
development of more effective and generalizable reasoning agents.

</details>


### [34] [Oruga: An Avatar of Representational Systems Theory](https://arxiv.org/abs/2509.04041)
*Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng*

Main category: cs.AI

TL;DR: Oruga是一个实现表示系统理论(RST)的框架，包含核心数据结构、通信语言和结构转换引擎，旨在让机器像人类一样灵活使用不同表示形式


<details>
  <summary>Details</summary>
Motivation: 人类能够灵活使用各种表示形式（如图表、类比等），希望让机器也具备这种能力以更好地与人类协作

Method: 基于表示系统理论(RST)，开发了Oruga系统，包含核心数据结构、专用通信语言和结构转换引擎，使用结构转移方法进行表示转换

Result: 实现了Oruga系统的核心框架和语言，能够执行结构转换操作

Conclusion: Oruga为机器实现灵活表示转换提供了理论基础和实现框架，是向人机兼容性迈出的重要一步

Abstract: Humans use representations flexibly. We draw diagrams, change representations
and exploit creative analogies across different domains. We want to harness
this kind of power and endow machines with it to make them more compatible with
human use. Previously we developed Representational Systems Theory (RST) to
study the structure and transformations of representations. In this paper we
present Oruga (caterpillar in Spanish; a symbol of transformation), an
implementation of various aspects of RST. Oruga consists of a core of data
structures corresponding to concepts in RST, a language for communicating with
the core, and an engine for producing transformations using a method we call
structure transfer. In this paper we present an overview of the core and
language of Oruga, with a brief example of the kind of transformation that
structure transfer can execute.

</details>


### [35] [Intermediate Languages Matter: Formal Languages and LLMs affect Neurosymbolic Reasoning](https://arxiv.org/abs/2509.04083)
*Alexander Beiser,David Penz,Nysret Musliu*

Main category: cs.AI

TL;DR: 本文研究发现，在神经符号LLM推理中，形式语言的选择是一个被忽视但关键的因素，会影响推理性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在形式推理能力方面仍有不足，神经符号LLM推理方法使用LLM作为自然语言到形式语言的翻译器，但其成功因素尚不清楚，特别是形式语言选择的影响。

Method: 通过比较四种形式语言在三个数据集和七个LLM上的表现，分析形式语言选择对句法和语义推理能力的影响。

Result: 研究发现形式语言的选择显著影响神经符号推理的性能，不同LLM受到的影响程度各不相同。

Conclusion: 形式语言的选择是神经符号LLM推理成功的关键因素之一，需要根据具体任务和模型特性进行优化选择。

Abstract: Large language models (LLMs) achieve astonishing results on a wide range of
tasks. However, their formal reasoning ability still lags behind. A promising
approach is Neurosymbolic LLM reasoning. It works by using LLMs as translators
from natural to formal languages and symbolic solvers for deriving correct
results. Still, the contributing factors to the success of Neurosymbolic LLM
reasoning remain unclear. This paper demonstrates that one previously
overlooked factor is the choice of the formal language. We introduce the
intermediate language challenge: selecting a suitable formal language for
neurosymbolic reasoning. By comparing four formal languages across three
datasets and seven LLMs, we show that the choice of formal language affects
both syntactic and semantic reasoning capabilities. We also discuss the varying
effects across different LLMs.

</details>


### [36] [Hybrid Reinforcement Learning and Search for Flight Trajectory Planning](https://arxiv.org/abs/2509.04100)
*Alberto Luise,Michele Lombardi,Florent Teichteil Koenigsbuch*

Main category: cs.AI

TL;DR: 使用强化学习预计近优飞行路径，通过约束搜索空间来加速空中路径规划优化，在燃油消耗几乎不变的情况下实现计算速度提升50%


<details>
  <summary>Details</summary>
Motivation: 在突发情况下需要快速重新计算飞行路径，传统规划器计算速度较慢，需要一种方法来加速路径优化过程

Method: 训练强化学习组件预先计算近优路径，然后用这些路径作为约束来限制基础规划器的搜索空间，在指定距离范围内寻找解决方案

Result: 在空客A320飞机性能模型上的实验结果显示，燃油消耗与无约束规划器几乎相同（偏差通常在1%以内），同时计算速度提高了达50%

Conclusion: 该方法通过结合强化学习和搜索规划器，在保持近优解质量的同时显著提高了计算效率，特别适用于紧急情况下的飞行路径重新规划

Abstract: This paper explores the combination of Reinforcement Learning (RL) and
search-based path planners to speed up the optimization of flight paths for
airliners, where in case of emergency a fast route re-calculation can be
crucial. The fundamental idea is to train an RL Agent to pre-compute
near-optimal paths based on location and atmospheric data and use those at
runtime to constrain the underlying path planning solver and find a solution
within a certain distance from the initial guess. The approach effectively
reduces the size of the solver's search space, significantly speeding up route
optimization. Although global optimality is not guaranteed, empirical results
conducted with Airbus aircraft's performance models show that fuel consumption
remains nearly identical to that of an unconstrained solver, with deviations
typically within 1%. At the same time, computation speed can be improved by up
to 50% as compared to using a conventional solver alone.

</details>


### [37] [Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker](https://arxiv.org/abs/2509.04125)
*Tarik Zaciragic,Aske Plaat,K. Joost Batenburg*

Main category: cs.AI

TL;DR: 研究分析了DQN和CFR两种算法在Leduc Hold'em扑克游戏中是否表现出诈唬行为，发现两者都表现出诈唬但方式不同，成功诈唬率相近，表明诈唬是游戏本质而非算法特性


<details>
  <summary>Details</summary>
Motivation: 在扑克游戏中诈唬是不可预测性的重要技能，但现有计算机扑克研究多关注胜率等性能指标，忽略了诈唬行为的分析

Method: 设计实验让基于强化学习的DQN算法和基于博弈论的CFR算法在Leduc Hold'em中对战，记录并分析它们的行动

Result: DQN和CFR都表现出诈唬行为但方式不同，虽然尝试诈唬的比率不同，但成功诈唬（对手弃牌）的百分比大致相同

Conclusion: 诈唬是扑克游戏的基本要素而非算法特性，未来工作应研究不同诈唬风格和完整扑克游戏

Abstract: In the game of poker, being unpredictable, or bluffing, is an essential
skill. When humans play poker, they bluff. However, most works on
computer-poker focus on performance metrics such as win rates, while bluffing
is overlooked. In this paper we study whether two popular algorithms, DQN
(based on reinforcement learning) and CFR (based on game theory), exhibit
bluffing behavior in Leduc Hold'em, a simplified version of poker. We designed
an experiment where we let the DQN and CFR agent play against each other while
we log their actions. We find that both DQN and CFR exhibit bluffing behavior,
but they do so in different ways. Although both attempt to perform bluffs at
different rates, the percentage of successful bluffs (where the opponent folds)
is roughly the same. This suggests that bluffing is an essential aspect of the
game, not of the algorithm. Future work should look at different bluffing
styles and at the full game of poker. Code at
https://github.com/TarikZ03/Bluffing-by-DQN-and-CFR-in-Leduc-Hold-em-Poker-Codebase.

</details>


### [38] [The human biological advantage over AI](https://arxiv.org/abs/2509.04130)
*William Stewart*

Main category: cs.AI

TL;DR: 论文认为即使AI在能力上超越人类，但由于缺乏中枢神经系统（CNS）带来的情感体验和道德理解，AI永远无法真正取代人类成为宇宙的领导者


<details>
  <summary>Details</summary>
Motivation: 探讨AI是否能够真正超越人类成为宇宙的领导者，特别是在AGI可能实现的背景下

Method: 通过分析人类中枢神经系统（CNS）与AI的本质区别，论证情感体验和道德理解对人类领导地位的重要性

Result: AI虽然可能在各种能力指标上超越人类，但由于无法拥有生物性的CNS来体验情感和真正理解行为后果，无法发展出可持续的伦理体系

Conclusion: 宇宙领导权的最佳基础始终是DNA而非硅基技术，人类因其生物特性而具备AI无法替代的领导资格

Abstract: Recent advances in AI raise the possibility that AI systems will one day be
able to do anything humans can do, only better. If artificial general
intelligence (AGI) is achieved, AI systems may be able to understand, reason,
problem solve, create, and evolve at a level and speed that humans will
increasingly be unable to match, or even understand. These possibilities raise
a natural question as to whether AI will eventually become superior to humans,
a successor "digital species", with a rightful claim to assume leadership of
the universe. However, a deeper consideration suggests the overlooked
differentiator between human beings and AI is not the brain, but the central
nervous system (CNS), providing us with an immersive integration with physical
reality. It is our CNS that enables us to experience emotion including pain,
joy, suffering, and love, and therefore to fully appreciate the consequences of
our actions on the world around us. And that emotional understanding of the
consequences of our actions is what is required to be able to develop
sustainable ethical systems, and so be fully qualified to be the leaders of the
universe. A CNS cannot be manufactured or simulated; it must be grown as a
biological construct. And so, even the development of consciousness will not be
sufficient to make AI systems superior to humans. AI systems may become more
capable than humans on almost every measure and transform our society. However,
the best foundation for leadership of our universe will always be DNA, not
silicon.

</details>


### [39] [Towards an Action-Centric Ontology for Cooking Procedures Using Temporal Graphs](https://arxiv.org/abs/2509.04159)
*Aarush Kumbhakern,Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das*

Main category: cs.AI

TL;DR: 提出了一种可扩展的域特定语言（DSL），通过有向动作图表示烹饪操作，形成了一个以动作为中心的烹饪本体论


<details>
  <summary>Details</summary>
Motivation: 烹饪过程具有内在的复杂性和模糊性，需要形式化表达烹饪操作以支持精确的机器理解和自动化执行

Method: 设计了一种可扩展的域特定语言，将菜谱表示为有向动作图，包含过程、传输、环境、并发性和组合结构

Result: 初步手工评估显示该DSL在英式早餐菜谱上具有较强的表达能力和适用性，适合未来的自动化菜谱分析和执行

Conclusion: 这项工作是构建以动作为中心的烹饪本体论的初步尝试，通过时间图实现结构化的机器理解、精确解释和可扩展的烹饪自动化

Abstract: Formalizing cooking procedures remains a challenging task due to their
inherent complexity and ambiguity. We introduce an extensible domain-specific
language for representing recipes as directed action graphs, capturing
processes, transfers, environments, concurrency, and compositional structure.
Our approach enables precise, modular modeling of complex culinary workflows.
Initial manual evaluation on a full English breakfast recipe demonstrates the
DSL's expressiveness and suitability for future automated recipe analysis and
execution. This work represents initial steps towards an action-centric
ontology for cooking, using temporal graphs to enable structured machine
understanding, precise interpretation, and scalable automation of culinary
processes - both in home kitchens and professional culinary settings.

</details>


### [40] [Domain size asymptotics for Markov logic networks](https://arxiv.org/abs/2509.04192)
*Vera Koponen*

Main category: cs.AI

TL;DR: 该论文研究了马尔可夫逻辑网络（MLN）在域大小趋于无穷大时的分布特性，分析了三种具体MLN示例的极限行为，并证明了量化自由MLN与提升贝叶斯网络在渐近意义上的不可比性。


<details>
  <summary>Details</summary>
Motivation: 研究MLN在无限大域上的分布特性，探索不同软约束对随机结构极限行为的影响，以及比较不同形式主义在渐近表达能力上的差异。

Method: 通过分析三种具体MLN示例：（1）单一元关系符号的量化自由MLN；（2）偏好较少三角形/团结构的MLN；（3）偏好较少高度数顶点的MLN，研究其在大域上的极限行为。

Result: 发现不同软约束会导致截然不同的极限行为，权重可能影响也可能不影响极限行为；证明了量化自由MLN与提升贝叶斯网络在渐近意义上的不可比性；显示MLN分布在大域上会集中在与均匀分布完全不同的区域。

Conclusion: MLN的软约束选择对渐近行为有重要影响，不同形式主义在表达能力上存在根本差异，大域上MLN分布会偏离均匀分布集中在特定区域。

Abstract: A Markov logic network (MLN) determines a probability distribution on the set
of structures, or ``possible worlds'', with an arbitrary finite domain. We
study the properties of such distributions as the domain size tends to
infinity. Three types of concrete examples of MLNs will be considered, and the
properties of random structures with domain sizes tending to infinity will be
studied: (1) Arbitrary quantifier-free MLNs over a language with only one
relation symbol which has arity 1. In this case we give a pretty complete
characterization of the possible limit behaviours of random structures. (2) An
MLN that favours graphs with fewer triangles (or more generally, fewer
k-cliques). As a corollary of the analysis a ``$\delta$-approximate 0-1 law''
for first-order logic is obtained. (3) An MLN that favours graphs with fewer
vertices with degree higher than a fixed (but arbitrary) number. The analysis
shows that depending on which ``soft constraints'' an MLN uses the limit
behaviour of random structures can be quite different, and the weights of the
soft constraints may, or may not, have influence on the limit behaviour. It
will also be demonstrated, using (1), that quantifier-free MLNs and lifted
Bayesian networks (in a broad sense) are asymptotically incomparable, roughly
meaning that there is a sequence of distributions on possible worlds with
increasing domain sizes that can be defined by one of the formalisms but not
even approximated by the other. In a rather general context it is also shown
that on large domains the distribution determined by an MLN concentrates almost
all its probability mass on a totally different part of the space of possible
worlds than the uniform distribution does.

</details>


### [41] [Evaluating Quality of Gaming Narratives Co-created with AI](https://arxiv.org/abs/2509.04239)
*Arturo Valdivia,Paolo Burelli*

Main category: cs.AI

TL;DR: 一种基于Delphi研究结构的结构化方法，通过故事设计专家评估AI生成游戏故事质量，并使用Kano模型分析对玩家满意度的影响。


<details>
  <summary>Details</summary>
Motivation: 为了给游戏开发者提供一种系统化的方法来评估和优化AI生成的游戏故事质量，确定哪些质量维度对玩家满意度最为重要。

Method: 采用Delphi研究结构，组织故事设计专家小组，综合文献中的故事质量维度和专家见解，并将其映射到Kano模型框架中进行分析。

Result: 得到了一套能够指导游戏开发者在与生成式AI协同创作游戏故事时优先考虑哪些质量维度的结果。

Conclusion: 该结构化方法有助于提高AI生成游戏故事的质量，通过明确关键质量指标来优化玩家体验和满意度。

Abstract: This paper proposes a structured methodology to evaluate AI-generated game
narratives, leveraging the Delphi study structure with a panel of narrative
design experts. Our approach synthesizes story quality dimensions from
literature and expert insights, mapping them into the Kano model framework to
understand their impact on player satisfaction. The results can inform game
developers on prioritizing quality aspects when co-creating game narratives
with generative AI.

</details>


### [42] [EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn Negotiation](https://arxiv.org/abs/2509.04310)
*Yunbo Long,Liming Xu,Lukas Beckenbauer,Yuhan Liu,Alexandra Brintrup*

Main category: cs.AI

TL;DR: EvoEmo是一个进化强化学习框架，通过优化动态情感表达来提升LLM在复杂多轮谈判中的表现，解决了现有方法忽视情感功能作用的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在谈判中主要生成被动、偏好驱动的情感响应，容易被对手操纵和战略利用，忽视了情感在谈判中的功能性作用。

Method: 提出EvoEmo框架，将情感状态转换建模为马尔可夫决策过程，采用基于种群的遗传优化算法，在不同谈判场景中演化高奖励情感策略。

Result: EvoEmo在广泛实验和消融研究中始终优于普通策略和固定情感策略基线，实现了更高的成功率、效率和买家节省。

Conclusion: 自适应情感表达对于构建更有效的多轮谈判LLM代理至关重要，EvoEmo框架为此提供了有效解决方案。

Abstract: Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models
(LLMs) has demonstrated that agents can engage in \textit{complex},
\textit{multi-turn} negotiations, opening new avenues for agentic AI. However,
existing LLM agents largely overlook the functional role of emotions in such
negotiations, instead generating passive, preference-driven emotional responses
that make them vulnerable to manipulation and strategic exploitation by
adversarial counterparts. To address this gap, we present EvoEmo, an
evolutionary reinforcement learning framework that optimizes dynamic emotional
expression in negotiations. EvoEmo models emotional state transitions as a
Markov Decision Process and employs population-based genetic optimization to
evolve high-reward emotion policies across diverse negotiation scenarios. We
further propose an evaluation framework with two baselines -- vanilla
strategies and fixed-emotion strategies -- for benchmarking emotion-aware
negotiation. Extensive experiments and ablation studies show that EvoEmo
consistently outperforms both baselines, achieving higher success rates, higher
efficiency, and increased buyer savings. This findings highlight the importance
of adaptive emotional expression in enabling more effective LLM agents for
multi-turn negotiation.

</details>


### [43] [Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes](https://arxiv.org/abs/2509.04317)
*Isidoro Tamassia,Wendelin Böhmer*

Main category: cs.AI

TL;DR: 本文分析了AlphaZero框架在测试环境可能发生变化时的部署问题，通过简单修改标准框架显著提升了性能表现，即使在低规划预算下也有效。


<details>
  <summary>Details</summary>
Motivation: AlphaZero框架通常假设训练和测试环境相同，这限制了其实际应用。本文旨在解决AlphaZero代理在测试环境可能发生变化时的部署挑战。

Method: 通过对标准AlphaZero框架进行简单修改的组合方法，包括调整蒙特卡洛规划和策略价值神经网络的使用方式，以适应环境变化。

Result: 实验证明这些修改能显著提升性能，特别是在低规划预算的设置下表现优异。代码已在GitHub上公开。

Conclusion: 通过简单的框架修改，AlphaZero能够有效应对测试环境变化的问题，扩展了其在实际应用中的适用性。

Abstract: The AlphaZero framework provides a standard way of combining Monte Carlo
planning with prior knowledge provided by a previously trained policy-value
neural network. AlphaZero usually assumes that the environment on which the
neural network was trained will not change at test time, which constrains its
applicability. In this paper, we analyze the problem of deploying AlphaZero
agents in potentially changed test environments and demonstrate how the
combination of simple modifications to the standard framework can significantly
boost performance, even in settings with a low planning budget available. The
code is publicly available on GitHub.

</details>


### [44] [Psychologically Enhanced AI Agents](https://arxiv.org/abs/2509.04343)
*Maciej Besta,Shriram Chandran,Robert Gerstenberger,Mathis Lindner,Marcin Chrapek,Sebastian Hermann Martschat,Taraneh Ghandi,Patrick Iff,Hubert Niewiadomski,Piotr Nyczyk,Jürgen Müller,Torsten Hoefler*

Main category: cs.AI

TL;DR: MBTI-in-Thoughts框架通过MBTI人格类型提示工程增强LLM智能体，无需微调即可实现心理人格条件化，在认知和情感两个维度控制行为表现。


<details>
  <summary>Details</summary>
Motivation: 将心理学理论（如MBTI）与LLM行为设计相结合，通过人格条件化增强AI智能体的行为表现和一致性，为心理增强型AI奠定基础。

Method: 使用提示工程为LLM智能体注入不同MBTI人格原型，通过官方16Personalities测试自动验证特质持久性，支持结构化多智能体通信协议实验。

Result: 人格条件化在不同任务中产生一致、可解释的行为偏差：情感表达型智能体在叙事生成中表现优异，分析型智能体在博弈论设置中采用更稳定策略；交互前自我反思能提高合作和推理质量。

Conclusion: 该方法可无缝推广到其他心理学框架（如Big Five、HEXACO、Enneagram），为无需微调的心理增强型AI智能体提供了有效基础框架。

Abstract: We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of
Large Language Model (LLM) agents through psychologically grounded personality
conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method
primes agents with distinct personality archetypes via prompt engineering,
enabling control over behavior along two foundational axes of human psychology,
cognition and affect. We show that such personality priming yields consistent,
interpretable behavioral biases across diverse tasks: emotionally expressive
agents excel in narrative generation, while analytically primed agents adopt
more stable strategies in game-theoretic settings. Our framework supports
experimenting with structured multi-agent communication protocols and reveals
that self-reflection prior to interaction improves cooperation and reasoning
quality. To ensure trait persistence, we integrate the official 16Personalities
test for automated verification. While our focus is on MBTI, we show that our
approach generalizes seamlessly to other psychological frameworks such as Big
Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior
design, we establish a foundation for psychologically enhanced AI agents
without any fine-tuning.

</details>


### [45] [ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory](https://arxiv.org/abs/2509.04439)
*Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin*

Main category: cs.AI

TL;DR: 该论文提出了概念级记忆方法，通过从推理轨迹中抽象出可重用的模块化概念，在测试时实现持续学习，无需权重更新，在ARC-AGI基准上取得了7.5%的相对性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的推理时扩展方法虽然能让LLMs执行更长的推理轨迹，但这些轨迹中的模式和见解在上下文窗口重置后就被丢弃。外部记忆可以持久化这些发现，但现有方法主要基于实例级记忆，缺乏可重用性和扩展性。

Method: 提出概念级记忆方法：从解决方案轨迹中提取可重用的模块化抽象概念，以自然语言形式存储。对于新查询，选择性检索相关概念并整合到提示中，实现测试时持续学习。设计了新的抽象策略和检索方法。

Result: 在ARC-AGI基准测试中，相比无记忆基线获得7.5%的相对性能提升，性能随推理计算量持续扩展。抽象概念在所有测试的计算规模上都优于基线，动态更新记忆比固定记忆设置表现更好。

Conclusion: 概念级记忆方法有效实现了测试时持续学习，通过抽象和重用推理模式，使LLMs能够自我改进。该方法为构建更可扩展和可重用的外部记忆系统提供了新方向。

Abstract: While inference-time scaling enables LLMs to carry out increasingly long and
capable reasoning traces, the patterns and insights uncovered during these
traces are immediately discarded once the context window is reset for a new
query. External memory is a natural way to persist these discoveries, and
recent work has shown clear benefits for reasoning-intensive tasks. We see an
opportunity to make such memories more broadly reusable and scalable by moving
beyond instance-based memory entries (e.g. exact query/response pairs, or
summaries tightly coupled with the original problem context) toward
concept-level memory: reusable, modular abstractions distilled from solution
traces and stored in natural language. For future queries, relevant concepts
are selectively retrieved and integrated into the prompt, enabling test-time
continual learning without weight updates. Our design introduces new strategies
for abstracting takeaways from rollouts and retrieving entries for new queries,
promoting reuse and allowing memory to expand with additional experiences. On
the challenging ARC-AGI benchmark, our method yields a 7.5% relative gain over
a strong no-memory baseline with performance continuing to scale with inference
compute. We find abstract concepts to be the most consistent memory design,
outscoring the baseline at all tested inference compute scales. Moreover, we
confirm that dynamically updating memory during test-time outperforms an
otherwise identical fixed memory setting with additional attempts, supporting
the hypothesis that solving more problems and abstracting more patterns to
memory enables further solutions in a form of self-improvement. Code available
at https://github.com/matt-seb-ho/arc_memo.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [46] [Distributed MIMO With Over-the-Air Phase Calibration Integrated Into the TDD Flow](https://arxiv.org/abs/2509.03722)
*Khac-Hoang Ngo,Erik G. Larsson*

Main category: cs.IT

TL;DR: 本文提出了一种在分布式MIMO系统中通过调整TDD时隙结构来集成AP间无线相位校准的方法，分析了校准资源开销与系统频谱效率的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 分布式MIMO系统中多个AP需要周期性相位校准以实现联合相干波束成形，传统方法需要专门的校准资源，本文旨在将校准过程集成到TDD流程中以提高效率。

Method: 通过适当调整TDD时隙结构中的上下行切换点，创建短时间段供AP之间进行无线测量，实现相位校准。该方法可扩展到大型网络，并分析了共轭波束成形和迫零波束成形下的资源效率权衡。

Result: 研究结果表明，通过无线AP间测量进行相位校准的分布式MIMO系统是可行的，校准过程可以成功集成到TDD流程中。

Conclusion: 该方法为分布式MIMO系统的实际部署提供了有效的相位校准解决方案，通过优化TDD时隙结构实现了校准与通信的无缝集成。

Abstract: Reciprocity-based, joint coherent downlink beamforming from multiple access
points (APs) in distributed multiple-input multiple-output (MIMO) with
independent local oscillators (LOs) requires the APs to be periodically
phase-calibrated (a.k.a. phase-synchronized or phase-aligned). Such phase
alignment can be accomplished by bidirectional over-the-air measurements
between the APs. In this paper, we show how such over-the-air measurements can
be integrated into the time-division duplexing (TDD) flow by appropriately
shifting the uplink/downlink switching points of the TDD slot structure,
creating short time segments during which APs can measure on one another. We
also show how this technique scales to large networks. Furthermore, we
analytically characterize the tradeoff between the amount of resources spent on
calibration measurements and the resulting spectral efficiency of the system,
when conjugate beamforming or zero-forcing beamforming is used. The results
demonstrate the feasibility of distributed MIMO with phase-calibration through
over-the-air inter-AP measurements integrated into the TDD flow.

</details>


### [47] [Two-Timescale Sum-Rate Maximization for Movable Antenna Enhanced Systems](https://arxiv.org/abs/2509.04062)
*Xintai Chen,Biqian Feng,Yongpeng Wu,Derrick Wing Kwan Ng,Robert Schober*

Main category: cs.IT

TL;DR: 提出了一种基于可移动天线的多用户MIMO下行系统，通过两时间尺度优化最大化平均可实现和速率，采用梯度上升和CSSCA算法进行优化


<details>
  <summary>Details</summary>
Motivation: 利用可移动天线技术提升无线通信性能，通过优化天线位置和协方差矩阵设计来提高系统容量和可行性

Method: 采用两时间尺度优化：短期问题使用梯度上升算法优化接收天线位置向量，长期问题使用CSSCA算法优化发射天线位置和协方差矩阵；并提出平面移动模式和PDD-SSCA算法

Result: 数值结果表明，所提出的两时间尺度MA增强系统设计相比基准方案显著提高了平均可实现和速率和问题可行性

Conclusion: 可移动天线技术结合两时间尺度优化能有效提升多用户MIMO系统性能，平面移动模式和PDD-SSCA算法提供了高效实用的解决方案

Abstract: This paper studies a novel movable antenna (MA)-enhanced multiuser
multiple-input multiple-output downlink system designed to improve wireless
communication performance. We aim to maximize the average achievable sum rate
through two-timescale optimization exploiting instantaneous channel state
information at the receiver (I-CSIR) for receive antenna position vector (APV)
design and statistical channel state information at the transmitter (S-CSIT)
for transmit APV and covariance matrix design. We first decompose the resulting
stochastic optimization problem into a series of short-term problems and one
long-term problem. Then, a gradient ascent algorithm is proposed to obtain
suboptimal receive APVs for the short-term problems for given I-CSIR samples.
Based on the output of the gradient ascent algorithm, a series of convex
objective/feasibility surrogates for the long-term problem are constructed and
solved utilizing the constrained stochastic successive convex approximation
(CSSCA) algorithm. Furthermore, we propose a planar movement mode for the
receive MAs to facilitate efficient antenna movement and the development of a
low-complexity primal-dual decomposition-based stochastic successive convex
approximation (PDD-SSCA) algorithm, which finds Karush-Kuhn-Tucker (KKT)
solutions almost surely. Our numerical results reveal that, for both the
general and the planar movement modes, the proposed two-timescale MA-enhanced
system design significantly improves the average achievable sum rate and the
feasibility of the formulated problem compared to benchmark schemes.

</details>


### [48] [Design of RIS-UAV-Assisted LEO Satellite Constellation Communication](https://arxiv.org/abs/2509.04136)
*Wenfei Yao,Xiaoming Chen,Qi Wang,Xingyu Peng*

Main category: cs.IT

TL;DR: 本文提出一种新颖的低轨道卫星组网通信框架，通过RIS-UAV协同优化来提升多用户设备的通信质量，并采用统计CSI来降低频寄开销。


<details>
  <summary>Details</summary>
Motivation: 解决卫星与地面长距离通信质量下降问题，以及多卫星协作中频道状态信息获取开销过大的挑战。

Method: 使用统计CSI，推导用户每次道速率的近但准确表达式，采用交替优化算法聚合优化卫星根数形成、RIS相位偏移和UAV飞行轨迹。

Result: 广泛模拟实验证明了所提算法在频谱效率方面显著优于基准算法。

Conclusion: 该框架有效提升了LEO卫星组网的通信性能，为6G网络全球覆盖提供了有力支撑。

Abstract: Low Earth orbit (LEO) satellite constellations play a pivotal role in
sixth-generation (6G) wireless networks by providing global coverage, massive
connections, and huge capacity. In this paper, we present a novel LEO satellite
constellation communication framework, where a reconfigurable intelligent
surface-mounted unmanned aerial vehicle (RIS-UAV) is deployed to improve the
communication quality of multiple terrestrial user equipments (UEs) under the
condition of long distance between satellite and ground. To reduce the overhead
for channel state information (CSI) acquisition with multiple-satellite
collaboration, statistical CSI (sCSI) is utilized in the system. In such a
situation, we first derive an approximated but exact expression for ergodic
rate of each UE. Then, we aim to maximize the minimum approximated UE ergodic
rate by the proposed alternating optimization (AO)-based algorithm that jointly
optimizes LEO satellite beamforming, RIS phase shift, and UAV trajectory.
Finally, extensive simulations are conducted to demonstrate the superiority of
the proposed algorithm in terms of spectrum efficiency over baseline
algorithms.

</details>


### [49] [Non-Reed-Solomon Type MDS Codes from Elliptic Curves](https://arxiv.org/abs/2509.04247)
*Puyin Wang,Wei Liu,Jinquan Luo,Dengxin Zhai*

Main category: cs.IT

TL;DR: 通过椭圆曲线构建了新的MDS码家族，长度接近理论极限，且可证明不等价于Reed-Solomon码


<details>
  <summary>Details</summary>
Motivation: 提供比传统Reed-Solomon码更灵活的MDS码构建方法，充分利用椭圆曲线的数学特性来提高码长

Method: 采用支撑在阵点上的除子和多个不同点的除子构建码，让构建方法更为一般化，避免依赖无穷远点

Result: 构建出长度约为(q + 1 + ∼2√q)/2的MDS码，证明了这些码与RS码不等价，并显示了已知上界的紧性

Conclusion: 该方法为构建长MDS码提供了新的途径，在代数码理论中具有重要意义，展示了椭圆曲线在码理论中的潜力

Abstract: In this paper, we present a new family of MDS codes derived from elliptic
curves. These codes attain lengths close to the theoretical maximum and are
provably inequivalent to Reed-Solomon (RS) codes. Unlike many previous
constructions that rely on the point at infinity, our approach allows for more
general choices: we consider divisors supported on affine points and divisors
consisting of multiple distinct points. This broader framework enables the
construction of codes with length approximately $(q + 1 + \lfloor 2\sqrt{q}
\rfloor)/2$, further illustrating the tightness of known upper bounds on
elliptic MDS code lengths. A detailed comparison shows that our codes are not
covered by earlier results. Moreover, we show that their inequivalence to RS
codes by explicitly computing the rank of the Schur product of their generator
matrices.

</details>
