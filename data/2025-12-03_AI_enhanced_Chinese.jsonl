{"id": "2512.02149", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02149", "abs": "https://arxiv.org/abs/2512.02149", "authors": ["Cristina Fern\u00e1ndez-C\u00f3rdoba", "Sergi S\u00e1nchez-Arag\u00f3n", "Merc\u00e8 Villanueva"], "title": "Weight distributions of simplex codes over finite chain rings and their Gray map images", "comment": "23 pages", "summary": "A linear code of length $n$ over a finite chain ring $R$ with residue field $\\F_q$ is a $R$-submodule of $R^n$. A $R$-linear code is a code over $\\F_q$ (not necessarily linear) which is the generalized Gray map image of a linear code over $R$. These codes can be seen as a generalization of the linear codes over $\\Z_{p^s}$ with $p$ prime and $s \\geq 1$. In this paper, we present the construction of linear simplex codes over $R$ and their corresponding $R$-linear simplex codes of type $\u03b1$ and $\u03b2$. Moreover, we show the fundamental parameters of these codes, including their minimum Hamming distance, as well as their complete weight distributions. We also study whether these simplex codes are optimal with respect to the Griesmer-type bound.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u6709\u9650\u94fe\u73af\u4e0a\u7ebf\u6027\u5355\u7eaf\u5f62\u7801\u53ca\u5176\u5bf9\u5e94R-\u7ebf\u6027\u5355\u7eaf\u5f62\u7801\u7684\u6784\u9020\u4e0e\u6027\u8d28\u5206\u6790", "motivation": "\u5c06Z_{p^s}\u4e0a\u7684\u7ebf\u6027\u7801\u63a8\u5e7f\u5230\u66f4\u4e00\u822c\u7684\u6709\u9650\u94fe\u73afR\u4e0a\uff0c\u7814\u7a76R-\u7ebf\u6027\u7801\u4f5c\u4e3a\u5e7f\u4e49Gray\u6620\u5c04\u4e0b\u7ebf\u6027\u7801\u7684\u50cf\uff0c\u63a2\u7d22\u8fd9\u7c7b\u5e7f\u4e49\u7ebf\u6027\u7801\u7684\u6784\u9020\u4e0e\u6027\u8d28", "method": "\u6784\u9020\u6709\u9650\u94fe\u73afR\u4e0a\u7684\u7ebf\u6027\u5355\u7eaf\u5f62\u7801\u53ca\u5176\u5bf9\u5e94\u7684R-\u7ebf\u6027\u5355\u7eaf\u5f62\u7801\uff08\u03b1\u578b\u548c\u03b2\u578b\uff09\uff0c\u5206\u6790\u5176\u57fa\u672c\u53c2\u6570\u5305\u62ec\u6700\u5c0f\u6c49\u660e\u8ddd\u79bb\u548c\u5b8c\u5168\u91cd\u91cf\u5206\u5e03\uff0c\u5e76\u7814\u7a76\u5176\u76f8\u5bf9\u4e8eGriesmer\u578b\u754c\u7684\u4f18\u5316\u6027", "result": "\u7ed9\u51fa\u4e86\u7ebf\u6027\u5355\u7eaf\u5f62\u7801\u548cR-\u7ebf\u6027\u5355\u7eaf\u5f62\u7801\u7684\u6784\u9020\u65b9\u6cd5\uff0c\u786e\u5b9a\u4e86\u5b83\u4eec\u7684\u57fa\u672c\u53c2\u6570\u548c\u5b8c\u5168\u91cd\u91cf\u5206\u5e03\uff0c\u5e76\u5206\u6790\u4e86\u8fd9\u4e9b\u7801\u76f8\u5bf9\u4e8eGriesmer\u578b\u754c\u7684\u4f18\u5316\u6027\u8d28", "conclusion": "\u6210\u529f\u5c06\u5355\u7eaf\u5f62\u7801\u7684\u6982\u5ff5\u63a8\u5e7f\u5230\u6709\u9650\u94fe\u73af\u4e0a\uff0c\u5efa\u7acb\u4e86\u5b8c\u6574\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u6709\u9650\u94fe\u73af\u4e0a\u7684\u7f16\u7801\u7406\u8bba\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u548c\u7ed3\u679c"}}
{"id": "2512.02255", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02255", "abs": "https://arxiv.org/abs/2512.02255", "authors": ["Kunnathully Sadanandan Sanila", "Rickard Nilsson", "Emad Ibrahim", "Neelakandan Rajamohan"], "title": "Low-Power Double RIS-Assisted Mobile LEO Satellite Communications", "comment": "Published in 2025 IEEE Wireless Communications and Networking Conference (WCNC)", "summary": "We propose a low-power mobile low earth orbit (LEO) satellite communication architecture, employing double reconfigurable intelligent surfaces (RIS) to enhance energy efficiency and signal performance. With a distance between RISs that satisfies the far-field requirement, this architecture positions one small RIS each in the near-field of the satellite's antenna and the user on the ground. Moreover, we develop a path loss model for the double-RIS communication link, considering the near-field and far-field effects. Further, with the help of dual-stage beamforming, the proposed system maximizes the signal power and minimizes power consumption. Simulation results show that the proposed architecture can reduce the power consumption with 40 dB in the uplink, with a small $0.25^2$ $\\text{m}^2$ RIS near the user, to communicate in energy-constrained LEO satellite communication circumstances.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u91c7\u7528\u53cc\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(RIS)\u7684\u4f4e\u529f\u8017\u79fb\u52a8LEO\u536b\u661f\u901a\u4fe1\u67b6\u6784\uff0c\u901a\u8fc7\u8fd1\u573a\u548c\u8fdc\u573a\u6548\u5e94\u4f18\u5316\u80fd\u91cf\u6548\u7387\u548c\u4fe1\u53f7\u6027\u80fd", "motivation": "\u5728\u80fd\u91cf\u53d7\u9650\u7684LEO\u536b\u661f\u901a\u4fe1\u73af\u5883\u4e2d\uff0c\u9700\u8981\u964d\u4f4e\u529f\u8017\u5e76\u63d0\u9ad8\u4fe1\u53f7\u6027\u80fd\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u9700\u6c42", "method": "\u91c7\u7528\u53ccRIS\u67b6\u6784\uff0c\u4e00\u4e2aRIS\u5728\u536b\u661f\u5929\u7ebf\u8fd1\u573a\uff0c\u53e6\u4e00\u4e2a\u5728\u7528\u6237\u8fd1\u573a\uff0cRIS\u95f4\u8ddd\u6ee1\u8db3\u8fdc\u573a\u8981\u6c42\uff1b\u5efa\u7acb\u8003\u8651\u8fd1\u573a\u548c\u8fdc\u573a\u6548\u5e94\u7684\u53ccRIS\u8def\u5f84\u635f\u8017\u6a21\u578b\uff1b\u4f7f\u7528\u53cc\u7ea7\u6ce2\u675f\u6210\u5f62\u6700\u5927\u5316\u4fe1\u53f7\u529f\u7387\u5e76\u6700\u5c0f\u5316\u529f\u8017", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u5728\u4e0a\u884c\u94fe\u8def\u4e2d\uff0c\u4f7f\u75280.25\u5e73\u65b9\u7c73\u7684\u5c0f\u578bRIS\u9760\u8fd1\u7528\u6237\u65f6\uff0c\u529f\u8017\u53ef\u964d\u4f4e40dB", "conclusion": "\u63d0\u51fa\u7684\u53ccRIS\u67b6\u6784\u80fd\u6709\u6548\u964d\u4f4eLEO\u536b\u661f\u901a\u4fe1\u7cfb\u7edf\u7684\u529f\u8017\uff0c\u7279\u522b\u9002\u7528\u4e8e\u80fd\u91cf\u53d7\u9650\u7684\u901a\u4fe1\u73af\u5883"}}
{"id": "2512.02257", "categories": ["cs.IT", "math.RT"], "pdf": "https://arxiv.org/pdf/2512.02257", "abs": "https://arxiv.org/abs/2512.02257", "authors": ["Ryan Leal", "Jingtong Sun", "Juan Pablo Vigneaux"], "title": "Entropies associated with orbits of finite groups", "comment": null, "summary": "For certain groups, parabolic subgroups appear as stabilizers of flags of sets or vector spaces. Quotients by these parabolic subgroups represent orbits of flags, and their cardinalities asymptotically reveal entropies (as rates of exponential or superexponential growth). The multiplicative \"chain rules\" that involve these cardinalities induce, asymptotically, additive analogues for entropies. Many traditional formulas in information theory correspond to quotients of symmetric groups, which are a particular kind of reflection group; in this case, the cardinalities of orbits are given by multinomial coefficients and are asymptotically related to Shannon entropy. One can treat similarly quotients of the general linear groups over a finite field; in this case, the cardinalities of orbits are given by $q$-multinomials and are asymptotically related to the Tsallis 2-entropy. In this contribution, we consider other finite reflection groups as well as the symplectic group as an example of a classical group over a finite field (groups of Lie type). In both cases, the groups are classified by Dynkin diagrams into infinite series of similar groups $A_n$, $B_n$, $C_n$, $D_n$ and a finite number of exceptional ones. The $A_n$ series consists of the symmetric groups (reflection case) and general linear groups (Lie case). Some of the other series, studied here from an information-theoretic perspective for the first time, are linked to new entropic functionals.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u4fe1\u606f\u8bba\u4e2d\u7684\u71b5\u516c\u5f0f\u4e0e\u7fa4\u8bba\u4e2d\u7684\u8f68\u9053\u8ba1\u6570\u8054\u7cfb\u8d77\u6765\uff0c\u6269\u5c55\u4e86\u4f20\u7edfShannon\u71b5\u548cTsallis\u71b5\u4e0e\u5bf9\u79f0\u7fa4\u548c\u4e00\u822c\u7ebf\u6027\u7fa4\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u7814\u7a76\u4e86\u5176\u4ed6\u53cd\u5c04\u7fa4\u548c\u5178\u578b\u7fa4\uff0c\u53d1\u73b0\u4e86\u65b0\u7684\u71b5\u6cdb\u51fd\u3002", "motivation": "\u4f20\u7edf\u4fe1\u606f\u8bba\u516c\u5f0f\u4e3b\u8981\u5bf9\u5e94\u5bf9\u79f0\u7fa4\uff08Shannon\u71b5\uff09\u548c\u4e00\u822c\u7ebf\u6027\u7fa4\uff08Tsallis 2-\u71b5\uff09\uff0c\u4f5c\u8005\u5e0c\u671b\u5c06\u8fd9\u79cd\u7fa4\u8bba-\u4fe1\u606f\u8bba\u5bf9\u5e94\u5173\u7cfb\u6269\u5c55\u5230\u5176\u4ed6\u7c7b\u578b\u7684\u7fa4\uff0c\u7279\u522b\u662f\u5176\u4ed6\u53cd\u5c04\u7fa4\u548c\u5178\u578b\u7fa4\uff08\u5982\u8f9b\u7fa4\uff09\uff0c\u4ee5\u53d1\u73b0\u65b0\u7684\u71b5\u6cdb\u51fd\u3002", "method": "\u901a\u8fc7\u7814\u7a76\u6709\u9650\u53cd\u5c04\u7fa4\u548c\u6709\u9650\u57df\u4e0a\u5178\u578b\u7fa4\uff08\u674e\u578b\u7fa4\uff09\u7684\u629b\u7269\u5b50\u7fa4\u5546\u7a7a\u95f4\uff0c\u5206\u6790\u8f68\u9053\u57fa\u6570\u7684\u6e10\u8fd1\u884c\u4e3a\u3002\u8fd9\u4e9b\u7fa4\u6309Dynkin\u56fe\u5206\u7c7b\u4e3a\u65e0\u9650\u7cfb\u5217A_n\u3001B_n\u3001C_n\u3001D_n\u548c\u6709\u9650\u4e2a\u4f8b\u5916\u7fa4\uff0c\u5176\u4e2dA_n\u7cfb\u5217\u5bf9\u5e94\u5df2\u77e5\u7ed3\u679c\uff0c\u4f5c\u8005\u9996\u6b21\u4ece\u4fe1\u606f\u8bba\u89d2\u5ea6\u7814\u7a76\u5176\u4ed6\u7cfb\u5217\u3002", "result": "\u53d1\u73b0\u4e86B_n\u3001C_n\u3001D_n\u7b49\u7cfb\u5217\u7fa4\u5bf9\u5e94\u7684\u65b0\u71b5\u6cdb\u51fd\uff0c\u8fd9\u4e9b\u6cdb\u51fd\u901a\u8fc7\u8f68\u9053\u57fa\u6570\u7684\u6e10\u8fd1\u884c\u4e3a\u4e0e\u4fe1\u606f\u8bba\u4e2d\u7684\u71b5\u6982\u5ff5\u76f8\u8054\u7cfb\u3002\u5bf9\u79f0\u7fa4\uff08A_n\u53cd\u5c04\u60c5\u51b5\uff09\u5bf9\u5e94Shannon\u71b5\uff0c\u4e00\u822c\u7ebf\u6027\u7fa4\uff08A_n\u674e\u60c5\u51b5\uff09\u5bf9\u5e94Tsallis 2-\u71b5\uff0c\u800c\u5176\u4ed6\u7cfb\u5217\u5bf9\u5e94\u65b0\u7684\u71b5\u51fd\u6570\u3002", "conclusion": "\u7fa4\u8bba\u4e2d\u7684\u8f68\u9053\u8ba1\u6570\u4e0e\u4fe1\u606f\u8bba\u4e2d\u7684\u71b5\u516c\u5f0f\u4e4b\u95f4\u5b58\u5728\u6df1\u523b\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u8fd9\u79cd\u5173\u7cfb\u4e0d\u4ec5\u9650\u4e8e\u4f20\u7edf\u7684\u5bf9\u79f0\u7fa4\u548c\u4e00\u822c\u7ebf\u6027\u7fa4\uff0c\u8fd8\u6269\u5c55\u5230\u5176\u4ed6\u53cd\u5c04\u7fa4\u548c\u5178\u578b\u7fa4\uff0c\u4e3a\u4fe1\u606f\u8bba\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u5b66\u57fa\u7840\u548c\u71b5\u6cdb\u51fd\u3002"}}
{"id": "2512.02325", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02325", "abs": "https://arxiv.org/abs/2512.02325", "authors": ["Guodong Wang", "Hongwei Liu", "Jinquan Luo"], "title": "New Constructions of Non-GRS MDS Codes, Recovery and Determination Algorithms for GRS Codes", "comment": null, "summary": "In this paper, we propose a new method for constructing a class of non-GRS MDS codes. The lengths of these codes can reach up to $\\frac{q+3}{2}$ (for finite fields of odd characteristic) and $\\frac{q+4}{2}$ (for even characteristic), respectively. Owing to their special structure, we can use the Cauchy matrix method to obtain the necessary and sufficient conditions for these codes to be MDS codes and non-GRS MDS codes. Additionally, the inequivalence between these codes and twisted GRS codes is analyzed. Furthermore, we analyze the relationships among several existing classes of codes used for constructing non-GRS MDS codes, propose explicit constructions, and discuss the lengths of non-GRS MDS codes based on these constructions. Finally, we design two efficient algorithms to address two main problems in GRS code research, i.e., determining whether an unknown code $C$ is a GRS code from its generator matrix $G$, and recovering the key vectors $\\bm\u03b1$ and $\\bm{v}$ such that $C = \\GRS_{n,k}(\\bm\u03b1, \\bm{v})$ if $C$ is indeed a GRS code. A computational complexity comparison of the proposed algorithms ($O(nk+n)$) with that of the Sidelnikov-Shestakov attack (exceeding $O(qk^2n+qk^3)$) shows that our methods offer superior computational efficiency.", "AI": {"tldr": "\u63d0\u51fa\u6784\u9020\u975eGRS MDS\u7801\u7684\u65b0\u65b9\u6cd5\uff0c\u5206\u6790\u5176\u4e0e\u626d\u66f2GRS\u7801\u7684\u4e0d\u7b49\u4ef7\u6027\uff0c\u5e76\u8bbe\u8ba1\u9ad8\u6548\u7b97\u6cd5\u89e3\u51b3GRS\u7801\u8bc6\u522b\u548c\u5bc6\u94a5\u6062\u590d\u95ee\u9898\u3002", "motivation": "\u73b0\u6709GRS\u7801\u5728\u5bc6\u7801\u5b66\u5e94\u7528\u4e2d\u5b58\u5728\u5b89\u5168\u9690\u60a3\uff08\u5982Sidelnikov-Shestakov\u653b\u51fb\uff09\uff0c\u9700\u8981\u6784\u9020\u975eGRS\u7684MDS\u7801\u4ee5\u589e\u5f3a\u5b89\u5168\u6027\uff0c\u540c\u65f6\u9700\u8981\u9ad8\u6548\u7b97\u6cd5\u6765\u8bc6\u522bGRS\u7801\u548c\u6062\u590d\u5176\u53c2\u6570\u3002", "method": "1. \u63d0\u51fa\u6784\u9020\u975eGRS MDS\u7801\u7684\u65b0\u65b9\u6cd5\uff0c\u7801\u957f\u53ef\u8fbe(q+3)/2\uff08\u5947\u7279\u5f81\uff09\u548c(q+4)/2\uff08\u5076\u7279\u5f81\uff09\uff1b2. \u4f7f\u7528\u67ef\u897f\u77e9\u9635\u65b9\u6cd5\u5206\u6790MDS\u548c\u975eGRS\u6761\u4ef6\uff1b3. \u5206\u6790\u4e0e\u626d\u66f2GRS\u7801\u7684\u4e0d\u7b49\u4ef7\u6027\uff1b4. \u8bbe\u8ba1\u4e24\u4e2a\u9ad8\u6548\u7b97\u6cd5\uff1aGRS\u7801\u8bc6\u522b\u7b97\u6cd5\uff08\u590d\u6742\u5ea6O(nk+n)\uff09\u548c\u5bc6\u94a5\u5411\u91cf\u6062\u590d\u7b97\u6cd5\u3002", "result": "1. \u6784\u9020\u51fa\u957f\u5ea6\u8fbe\u5230\u7406\u8bba\u754c\u9650\u7684\u975eGRS MDS\u7801\uff1b2. \u8bc1\u660e\u4e86\u65b0\u6784\u9020\u7801\u4e0e\u626d\u66f2GRS\u7801\u7684\u4e0d\u7b49\u4ef7\u6027\uff1b3. \u63d0\u51fa\u7684\u7b97\u6cd5\u590d\u6742\u5ea6\u663e\u8457\u4f18\u4e8eSidelnikov-Shestakov\u653b\u51fb\uff08O(nk+n) vs O(qk\u00b2n+qk\u00b3)\uff09\uff1b4. \u5206\u6790\u4e86\u73b0\u6709\u5404\u7c7b\u975eGRS MDS\u7801\u6784\u9020\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u6784\u9020\u975eGRS MDS\u7801\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9ad8\u6548\u7684GRS\u7801\u8bc6\u522b\u548c\u53c2\u6570\u6062\u590d\u7b97\u6cd5\uff0c\u5728\u7801\u957f\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u90fd\u6709\u663e\u8457\u6539\u8fdb\uff0c\u4e3a\u5bc6\u7801\u5b66\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5b89\u5168\u7684\u7f16\u7801\u65b9\u6848\u3002"}}
{"id": "2512.02297", "categories": ["cs.NI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.02297", "abs": "https://arxiv.org/abs/2512.02297", "authors": ["Philip Rodgers", "Paul Harvey"], "title": "The xApp Store: A Framework for xApp Onboarding and Deployment in O-RAN", "comment": "Accepted to ANMS'25", "summary": "5G and beyond mobile telecommunication networks are increasingly embracing software technologies in their operation and control, similar to what has powered the growth of the cloud. This is most recently seen in the radio access network (RAN). In this new approach, the RAN is increasingly controlled by software applications known as xApps, and opens the door to third party development of xApps bringing diversity to the ecosystem, similar to mobile phone apps. This model aligns closely with the controllers in the ITU-T architecture for autonomous networks, and provides a pathway towards autonomous operation in the RAN. Unfortunately, no marketplace to host or supply xApps currently exists.\n  This work describes our experiences in leveraging open-source O-RAN implementations to design and develop an xApp store.", "AI": {"tldr": "\u57fa\u4e8e\u5f00\u6e90O-RAN\u5b9e\u73b0\u8bbe\u8ba1\u548c\u5f00\u53d1xApp\u5e94\u7528\u5546\u5e97\u7684\u7ecf\u9a8c\u5206\u4eab", "motivation": "5G\u53ca\u672a\u6765\u79fb\u52a8\u901a\u4fe1\u7f51\u7edc\u6b63\u50cf\u4e91\u8ba1\u7b97\u4e00\u6837\u62e5\u62b1\u8f6f\u4ef6\u6280\u672f\uff0c\u7279\u522b\u662f\u5728\u65e0\u7ebf\u63a5\u5165\u7f51(RAN)\u4e2d\u3002RAN\u73b0\u5728\u8d8a\u6765\u8d8a\u591a\u5730\u7531\u79f0\u4e3axApps\u7684\u8f6f\u4ef6\u5e94\u7528\u7a0b\u5e8f\u63a7\u5236\uff0c\u8fd9\u4e3a\u7b2c\u4e09\u65b9\u5f00\u53d1xApps\u6253\u5f00\u4e86\u5927\u95e8\uff0c\u7c7b\u4f3c\u4e8e\u624b\u673a\u5e94\u7528\u751f\u6001\u3002\u7136\u800c\uff0c\u76ee\u524d\u8fd8\u6ca1\u6709\u4e00\u4e2a\u53ef\u4ee5\u6258\u7ba1\u6216\u4f9b\u5e94xApps\u7684\u5e02\u573a\u5e73\u53f0\u3002", "method": "\u5229\u7528\u5f00\u6e90O-RAN\u5b9e\u73b0\u6765\u8bbe\u8ba1\u548c\u5f00\u53d1xApp\u5e94\u7528\u5546\u5e97", "result": "\u8bba\u6587\u63cf\u8ff0\u4e86\u57fa\u4e8e\u5f00\u6e90O-RAN\u5b9e\u73b0\u8bbe\u8ba1\u548c\u5f00\u53d1xApp\u5e94\u7528\u5546\u5e97\u7684\u5177\u4f53\u7ecf\u9a8c", "conclusion": "\u901a\u8fc7\u5f00\u53d1xApp\u5e94\u7528\u5546\u5e97\uff0c\u4e3aO-RAN\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u7b2c\u4e09\u65b9xApps\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e02\u573a\u5e73\u53f0\uff0c\u4fc3\u8fdb\u4e86RAN\u8f6f\u4ef6\u5e94\u7528\u7684\u591a\u6837\u5316\u548c\u751f\u6001\u7cfb\u7edf\u53d1\u5c55\uff0c\u4e3a\u5b9e\u73b0\u81ea\u4e3b\u7f51\u7edc\u8fd0\u8425\u63d0\u4f9b\u4e86\u9014\u5f84\u3002"}}
{"id": "2512.02272", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02272", "abs": "https://arxiv.org/abs/2512.02272", "authors": ["Ali Diab", "Adel Chehade", "Edoardo Ragusa", "Paolo Gastaldo", "Rodolfo Zunino", "Amer Baghdadi", "Mostafa Rizk"], "title": "Intrusion Detection on Resource-Constrained IoT Devices with Hardware-Aware ML and DL", "comment": "Accepted at the 2025 IEEE International Conference on Emerging Trends in Engineering and Computing (ETECOM). Recipient of the ETECOM 2025 Best Paper Award", "summary": "This paper proposes a hardware-aware intrusion detection system (IDS) for Internet of Things (IoT) and Industrial IoT (IIoT) networks; it targets scenarios where classification is essential for fast, privacy-preserving, and resource-efficient threat detection. The goal is to optimize both tree-based machine learning (ML) models and compact deep neural networks (DNNs) within strict edge-device constraints. This allows for a fair comparison and reveals trade-offs between model families. We apply constrained grid search for tree-based classifiers and hardware-aware neural architecture search (HW-NAS) for 1D convolutional neural networks (1D-CNNs). Evaluation on the Edge-IIoTset benchmark shows that selected models meet tight flash, RAM, and compute limits: LightGBM achieves 95.3% accuracy using 75 KB flash and 1.2 K operations, while the HW-NAS-optimized CNN reaches 97.2% with 190 KB flash and 840 K floating-point operations (FLOPs). We deploy the full pipeline on a Raspberry Pi 3 B Plus, confirming that tree-based models operate within 30 ms and that CNNs remain suitable when accuracy outweighs latency. These results highlight the practicality of hardware-constrained model design for real-time IDS at the edge.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9IoT/IIoT\u7f51\u7edc\u7684\u786c\u4ef6\u611f\u77e5\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff0c\u5728\u8fb9\u7f18\u8bbe\u5907\u4e25\u683c\u7ea6\u675f\u4e0b\u4f18\u5316\u6811\u6a21\u578b\u548c\u7d27\u51d1DNN\uff0c\u5b9e\u73b0\u5feb\u901f\u3001\u9690\u79c1\u4fdd\u62a4\u3001\u8d44\u6e90\u9ad8\u6548\u7684\u5a01\u80c1\u68c0\u6d4b\u3002", "motivation": "IoT/IIoT\u7f51\u7edc\u9700\u8981\u5feb\u901f\u3001\u9690\u79c1\u4fdd\u62a4\u4e14\u8d44\u6e90\u9ad8\u6548\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff0c\u4f46\u8fb9\u7f18\u8bbe\u5907\u6709\u4e25\u683c\u7684\u5b58\u50a8\u3001\u5185\u5b58\u548c\u8ba1\u7b97\u9650\u5236\uff0c\u9700\u8981\u4f18\u5316\u6a21\u578b\u4ee5\u9002\u5e94\u8fd9\u4e9b\u7ea6\u675f\u3002", "method": "\u91c7\u7528\u7ea6\u675f\u7f51\u683c\u641c\u7d22\u4f18\u5316\u6811\u57fa\u5206\u7c7b\u5668\uff08\u5982LightGBM\uff09\uff0c\u4f7f\u7528\u786c\u4ef6\u611f\u77e5\u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff08HW-NAS\uff09\u4f18\u53161D-CNN\uff1b\u5728Edge-IIoTset\u57fa\u51c6\u4e0a\u8bc4\u4f30\uff0c\u5e76\u5728Raspberry Pi 3 B Plus\u4e0a\u90e8\u7f72\u5b8c\u6574\u6d41\u6c34\u7ebf\u3002", "result": "LightGBM\u8fbe\u523095.3%\u51c6\u786e\u7387\uff0c\u4ec5\u970075KB\u95ea\u5b58\u548c1.2K\u64cd\u4f5c\uff1bHW-NAS\u4f18\u5316\u7684CNN\u8fbe\u523097.2%\u51c6\u786e\u7387\uff0c\u9700\u8981190KB\u95ea\u5b58\u548c840K FLOPs\u3002\u6811\u6a21\u578b\u572830ms\u5185\u8fd0\u884c\uff0cCNN\u5728\u7cbe\u5ea6\u4f18\u5148\u65f6\u4ecd\u9002\u7528\u3002", "conclusion": "\u786c\u4ef6\u7ea6\u675f\u6a21\u578b\u8bbe\u8ba1\u5bf9\u4e8e\u8fb9\u7f18\u5b9e\u65f6\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u5177\u6709\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u6811\u6a21\u578b\u548cCNN\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u5404\u6709\u4f18\u52bf\uff0c\u4e3aIoT/IIoT\u5b89\u5168\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02080", "categories": ["cs.AI", "cs.FL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02080", "abs": "https://arxiv.org/abs/2512.02080", "authors": ["PIerre Dantas", "Lucas Cordeiro", "Youcheng Sun", "Waldir Junior"], "title": "The 4/$\u03b4$ Bound: Designing Predictable LLM-Verifier Systems for Formal Method Guarantee", "comment": "32 pages, 9 figures", "summary": "The idea of using Formal Verification tools with large language models (LLMs) has enabled scaling software verification beyond manual workflows. However, current methods remain unreliable. Without a solid theoretical footing, the refinement process can wander; sometimes it settles, sometimes it loops back, and sometimes it breaks away from any stable trajectory. This work bridges this critical gap by developing an LLM-Verifier Convergence Theorem, providing the first formal framework with provable guarantees for termination and convergence. We model the interaction between the LLM and the verifier as a discrete-time Markov Chain, with state transitions determined by a key parameter: the error-reduction probability ($\u03b4$). The procedure reaching the Verified state almost surely demonstrates that the program terminates for any $\u03b4> 0$, with an expected iteration count bounded by $\\mathbb{E}[n] \\leq 4/\u03b4$. We then stress-tested this prediction in an extensive empirical campaign comprising more than 90,000 trials. The empirical results match the theory with striking consistency. Every single run reached verification, and the convergence factor clustered tightly around $C_f\\approx$ 1.0. Consequently, the bound mirrors the system's actual behavior. The evidence is sufficiently robust to support dividing the workflow into three distinct operating zones: marginal, practical, and high-performance. Consequently, we establish the design thresholds with absolute confidence. Together, the theoretical guarantee and the experimental evidence provide a clearer architectural foundation for LLM-assisted verification. Heuristic tuning no longer has to be carried out by the system. Engineers gain a framework that supports predictable resource planning and performance budgeting, precisely what is needed before deploying these pipelines into safety-critical software environments.", "AI": {"tldr": "\u63d0\u51faLLM-Verifier\u6536\u655b\u5b9a\u7406\uff0c\u4e3aLLM\u4e0e\u5f62\u5f0f\u9a8c\u8bc1\u5de5\u5177\u7684\u4ea4\u4e92\u63d0\u4f9b\u9996\u4e2a\u5177\u6709\u53ef\u8bc1\u660e\u7ec8\u6b62\u6027\u548c\u6536\u655b\u6027\u4fdd\u8bc1\u7684\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u9884\u6d4b\u3002", "motivation": "\u5f53\u524d\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u5f62\u5f0f\u9a8c\u8bc1\u5de5\u5177\u7ed3\u5408\u7684\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u9760\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5bfc\u81f4\u9a8c\u8bc1\u8fc7\u7a0b\u4e0d\u7a33\u5b9a\uff08\u53ef\u80fd\u6536\u655b\u3001\u5faa\u73af\u6216\u53d1\u6563\uff09\uff0c\u9650\u5236\u4e86\u5728\u5b89\u5168\u5173\u952e\u8f6f\u4ef6\u73af\u5883\u4e2d\u7684\u53ef\u9760\u5e94\u7528\u3002", "method": "\u5c06LLM\u4e0e\u9a8c\u8bc1\u5668\u7684\u4ea4\u4e92\u5efa\u6a21\u4e3a\u79bb\u6563\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe\uff0c\u72b6\u6001\u8f6c\u79fb\u7531\u9519\u8bef\u51cf\u5c11\u6982\u7387\u03b4\u51b3\u5b9a\u3002\u63d0\u51faLLM-Verifier\u6536\u655b\u5b9a\u7406\uff0c\u8bc1\u660e\u5bf9\u4e8e\u4efb\u610f\u03b4>0\uff0c\u8fc7\u7a0b\u51e0\u4e4e\u5fc5\u7136\u8fbe\u5230\u9a8c\u8bc1\u72b6\u6001\uff0c\u4e14\u671f\u671b\u8fed\u4ee3\u6b21\u6570\u6709\u754cE[n]\u22644/\u03b4\u3002\u901a\u8fc7\u8d85\u8fc790,000\u6b21\u8bd5\u9a8c\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u7406\u8bba\u9884\u6d4b\u4e0e\u5b9e\u8bc1\u7ed3\u679c\u9ad8\u5ea6\u4e00\u81f4\uff1a\u6240\u6709\u8fd0\u884c\u90fd\u6210\u529f\u8fbe\u5230\u9a8c\u8bc1\uff0c\u6536\u655b\u56e0\u5b50\u7d27\u5bc6\u805a\u96c6\u5728Cf\u22481.0\u9644\u8fd1\u3002\u57fa\u4e8e\u6b64\u5c06\u5de5\u4f5c\u6d41\u5212\u5206\u4e3a\u4e09\u4e2a\u64cd\u4f5c\u533a\u57df\uff08\u8fb9\u7f18\u3001\u5b9e\u7528\u3001\u9ad8\u6027\u80fd\uff09\uff0c\u5e76\u5efa\u7acb\u4e86\u53ef\u9760\u7684\u8bbe\u8ba1\u9608\u503c\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3aLLM\u8f85\u52a9\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u9a8c\u8bc1\u636e\uff0c\u4f7f\u5de5\u7a0b\u5e08\u80fd\u591f\u8fdb\u884c\u53ef\u9884\u6d4b\u7684\u8d44\u6e90\u89c4\u5212\u548c\u6027\u80fd\u9884\u7b97\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u8f6f\u4ef6\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u67b6\u6784\u57fa\u7840\u3002"}}
{"id": "2512.02332", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02332", "abs": "https://arxiv.org/abs/2512.02332", "authors": ["Yuqing Zhu", "Yuan-Hsun Lo", "Yan Lin", "Yijin Zhang"], "title": "Age of Information for Constrained Scheduling with Imperfect Feedback", "comment": null, "summary": "This paper considers a downlink system where an access point sends the monitored status of multiple sources to multiple users. By jointly accounting for imperfect feedback and constrained transmission rate, which are key limited factors in practical systems, we aim to design scheduling algorithms to optimize the age of information (AoI) over the infinite time horizon. For zero feedback under the generate-at-will traffic, we derive a closed-form lower bound of achievable AoI, which, to the best of our knowledge, reflects the impact of zero feedback for the first time, and propose a policy that achieves this bound in many cases by jointly applying rate splitting and modular arithmetic. For zero feedback under the Bernoulli traffic, we develop a drift-plus-penalty (DPP) policy with a threshold structure based on the theory of Lyapunov optimization and provide a closed-form performance guarantee. Furthermore, we extend the design of this DPP policy to support general imperfect feedback without increasing the online computational complexity. Numerical results verify our theoretical analysis and the AoI advantage of the proposed policies over state-of-the-art policies.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u591a\u7528\u6237\u4e0b\u884c\u94fe\u8def\u7cfb\u7edf\u4e2d\u8003\u8651\u4e0d\u5b8c\u7f8e\u53cd\u9988\u548c\u53d7\u9650\u4f20\u8f93\u901f\u7387\u4e0b\u7684AoI\u4f18\u5316\u8c03\u5ea6\u7b97\u6cd5\uff0c\u9488\u5bf9\u96f6\u53cd\u9988\u548c\u4f2f\u52aa\u5229\u6d41\u91cf\u573a\u666f\u63d0\u51fa\u4e86\u591a\u79cd\u7b56\u7565\uff0c\u5e76\u6269\u5c55\u5230\u4e00\u822c\u4e0d\u5b8c\u7f8e\u53cd\u9988\u573a\u666f\u3002", "motivation": "\u5b9e\u9645\u7cfb\u7edf\u4e2d\u5b58\u5728\u4e0d\u5b8c\u7f8e\u53cd\u9988\u548c\u53d7\u9650\u4f20\u8f93\u901f\u7387\u8fd9\u4e24\u4e2a\u5173\u952e\u9650\u5236\u56e0\u7d20\uff0c\u73b0\u6709\u7814\u7a76\u672a\u80fd\u5145\u5206\u53cd\u6620\u8fd9\u4e9b\u56e0\u7d20\u5bf9\u4fe1\u606f\u5e74\u9f84(AoI)\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u96f6\u53cd\u9988\u573a\u666f\u4e0b\u3002", "method": "1) \u9488\u5bf9\u96f6\u53cd\u9988\u7684generate-at-will\u6d41\u91cf\uff0c\u63a8\u5bfc\u4e86\u53ef\u8fbe\u5230AoI\u7684\u95ed\u5f0f\u4e0b\u754c\uff0c\u63d0\u51fa\u7ed3\u5408\u901f\u7387\u5206\u5272\u548c\u6a21\u8fd0\u7b97\u7684\u7b56\u7565\uff1b2) \u9488\u5bf9\u96f6\u53cd\u9988\u7684\u4f2f\u52aa\u5229\u6d41\u91cf\uff0c\u57fa\u4e8eLyapunov\u4f18\u5316\u7406\u8bba\u5f00\u53d1\u4e86\u5177\u6709\u9608\u503c\u7ed3\u6784\u7684DPP\u7b56\u7565\uff1b3) \u5c06DPP\u7b56\u7565\u6269\u5c55\u5230\u4e00\u822c\u4e0d\u5b8c\u7f8e\u53cd\u9988\u573a\u666f\uff0c\u4fdd\u6301\u5728\u7ebf\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0d\u53d8\u3002", "result": "1) \u96f6\u53cd\u9988\u573a\u666f\u4e0b\u9996\u6b21\u63a8\u5bfc\u4e86\u53cd\u6620\u96f6\u53cd\u9988\u5f71\u54cd\u7684\u95ed\u5f0fAoI\u4e0b\u754c\uff0c\u63d0\u51fa\u7684\u7b56\u7565\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u80fd\u8fbe\u5230\u8be5\u4e0b\u754c\uff1b2) \u4e3a\u4f2f\u52aa\u5229\u6d41\u91cf\u63d0\u4f9b\u4e86\u95ed\u5f0f\u6027\u80fd\u4fdd\u8bc1\uff1b3) \u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u548c\u6240\u63d0\u7b56\u7565\u76f8\u5bf9\u4e8e\u73b0\u6709\u7b56\u7565\u7684AoI\u4f18\u52bf\u3002", "conclusion": "\u8bba\u6587\u6210\u529f\u89e3\u51b3\u4e86\u5b9e\u9645\u7cfb\u7edf\u4e2d\u4e0d\u5b8c\u7f8e\u53cd\u9988\u548c\u53d7\u9650\u4f20\u8f93\u901f\u7387\u4e0b\u7684AoI\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u8c03\u5ea6\u7b97\u6cd5\u5728\u591a\u79cd\u573a\u666f\u4e0b\u90fd\u80fd\u6709\u6548\u964d\u4f4e\u4fe1\u606f\u5e74\u9f84\uff0c\u4e3a\u5b9e\u9645\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u7684AoI\u4f18\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u548c\u5b9e\u7528\u65b9\u6848\u3002"}}
{"id": "2512.02276", "categories": ["cs.NI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02276", "abs": "https://arxiv.org/abs/2512.02276", "authors": ["Adel Chehade", "Edoardo Ragusa", "Paolo Gastaldo", "Rodolfo Zunino"], "title": "Adversarial Robustness of Traffic Classification under Resource Constraints: Input Structure Matters", "comment": "Accepted at the 2025 IEEE International Symposium on Networks, Computers and Communications (ISNCC)", "summary": "Traffic classification (TC) plays a critical role in cybersecurity, particularly in IoT and embedded contexts, where inspection must often occur locally under tight hardware constraints. We use hardware-aware neural architecture search (HW-NAS) to derive lightweight TC models that are accurate, efficient, and deployable on edge platforms. Two input formats are considered: a flattened byte sequence and a 2D packet-wise time series; we examine how input structure affects adversarial vulnerability when using resource-constrained models. Robustness is assessed against white-box attacks, specifically Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD). On USTC-TFC2016, both HW-NAS models achieve over 99% clean-data accuracy while remaining within 65k parameters and 2M FLOPs. Yet under perturbations of strength 0.1, their robustness diverges: the flat model retains over 85% accuracy, while the time-series variant drops below 35%. Adversarial fine-tuning delivers robust gains, with flat-input accuracy exceeding 96% and the time-series variant recovering over 60 percentage points in robustness, all without compromising efficiency. The results underscore how input structure influences adversarial vulnerability, and show that even compact, resource-efficient models can attain strong robustness, supporting their practical deployment in secure edge-based TC.", "AI": {"tldr": "\u4f7f\u7528\u786c\u4ef6\u611f\u77e5\u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff08HW-NAS\uff09\u5f00\u53d1\u8f7b\u91cf\u7ea7\u6d41\u91cf\u5206\u7c7b\u6a21\u578b\uff0c\u7814\u7a76\u8f93\u5165\u7ed3\u6784\uff08\u6241\u5e73\u5b57\u8282\u5e8f\u5217vs 2D\u65f6\u95f4\u5e8f\u5217\uff09\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u9c81\u68d2\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u5bf9\u6297\u6027\u5fae\u8c03\u63d0\u5347\u6a21\u578b\u5b89\u5168\u6027\u3002", "motivation": "\u5728\u7269\u8054\u7f51\u548c\u5d4c\u5165\u5f0f\u73af\u5883\u4e2d\uff0c\u6d41\u91cf\u5206\u7c7b\u9700\u8981\u5728\u786c\u4ef6\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u672c\u5730\u6267\u884c\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65e2\u51c6\u786e\u53c8\u9ad8\u6548\u7684\u8f7b\u91cf\u7ea7\u6a21\u578b\u3002\u540c\u65f6\uff0c\u8fd9\u4e9b\u6a21\u578b\u9700\u8981\u5177\u5907\u5bf9\u6297\u5bf9\u6297\u6027\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u4ee5\u786e\u4fdd\u7f51\u7edc\u5b89\u5168\u3002", "method": "\u91c7\u7528\u786c\u4ef6\u611f\u77e5\u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff08HW-NAS\uff09\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u6d41\u91cf\u5206\u7c7b\u6a21\u578b\uff0c\u8003\u8651\u4e24\u79cd\u8f93\u5165\u683c\u5f0f\uff1a\u6241\u5e73\u5b57\u8282\u5e8f\u5217\u548c2D\u5305\u7ea7\u65f6\u95f4\u5e8f\u5217\u3002\u8bc4\u4f30\u6a21\u578b\u5728FGSM\u548cPGD\u767d\u76d2\u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u901a\u8fc7\u5bf9\u6297\u6027\u5fae\u8c03\u63d0\u5347\u6a21\u578b\u5b89\u5168\u6027\u3002", "result": "\u5728USTC-TFC2016\u6570\u636e\u96c6\u4e0a\uff0c\u4e24\u79cdHW-NAS\u6a21\u578b\u5728\u5e72\u51c0\u6570\u636e\u4e0a\u90fd\u8fbe\u523099%\u4ee5\u4e0a\u7684\u51c6\u786e\u7387\uff0c\u53c2\u6570\u91cf\u5c0f\u4e8e65k\uff0c\u8ba1\u7b97\u91cf\u5c0f\u4e8e2M FLOPs\u3002\u4f46\u5728\u5f3a\u5ea60.1\u7684\u6270\u52a8\u4e0b\uff0c\u6241\u5e73\u6a21\u578b\u4fdd\u630185%\u4ee5\u4e0a\u51c6\u786e\u7387\uff0c\u800c\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u964d\u81f335%\u4ee5\u4e0b\u3002\u5bf9\u6297\u6027\u5fae\u8c03\u540e\uff0c\u6241\u5e73\u6a21\u578b\u51c6\u786e\u7387\u8d85\u8fc796%\uff0c\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u9c81\u68d2\u6027\u63d0\u534760\u4e2a\u767e\u5206\u70b9\uff0c\u4e14\u4e0d\u727a\u7272\u6548\u7387\u3002", "conclusion": "\u8f93\u5165\u7ed3\u6784\u663e\u8457\u5f71\u54cd\u6a21\u578b\u7684\u5bf9\u6297\u6027\u8106\u5f31\u6027\uff0c\u6241\u5e73\u8f93\u5165\u683c\u5f0f\u6bd4\u65f6\u95f4\u5e8f\u5217\u683c\u5f0f\u66f4\u5177\u9c81\u68d2\u6027\u3002\u901a\u8fc7\u5bf9\u6297\u6027\u5fae\u8c03\uff0c\u5373\u4f7f\u662f\u7d27\u51d1\u7684\u8d44\u6e90\u9ad8\u6548\u6a21\u578b\u4e5f\u80fd\u83b7\u5f97\u5f3a\u5927\u7684\u9c81\u68d2\u6027\uff0c\u652f\u6301\u5176\u5728\u5b89\u5168\u8fb9\u7f18\u6d41\u91cf\u5206\u7c7b\u4e2d\u7684\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2512.02170", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02170", "abs": "https://arxiv.org/abs/2512.02170", "authors": ["Pritam Deka", "Barry Devereux"], "title": "Flowchart2Mermaid: A Vision-Language Model Powered System for Converting Flowcharts into Editable Diagram Code", "comment": "Submitted to EACL 2026 Demo Track", "summary": "Flowcharts are common tools for communicating processes but are often shared as static images that cannot be easily edited or reused. We present \\textsc{Flowchart2Mermaid}, a lightweight web system that converts flowchart images into editable Mermaid.js code which is a markup language for visual workflows, using a detailed system prompt and vision-language models. The interface supports mixed-initiative refinement through inline text editing, drag-and-drop node insertion, and natural-language commands interpreted by an integrated AI assistant. Unlike prior image-to-diagram tools, our approach produces a structured, version-controllable textual representation that remains synchronized with the rendered diagram. We further introduce evaluation metrics to assess structural accuracy, flow correctness, syntax validity, and completeness across multiple models.", "AI": {"tldr": "Flowchart2Mermaid\uff1a\u4e00\u4e2a\u8f7b\u91cf\u7ea7Web\u7cfb\u7edf\uff0c\u53ef\u5c06\u6d41\u7a0b\u56fe\u56fe\u50cf\u8f6c\u6362\u4e3a\u53ef\u7f16\u8f91\u7684Mermaid.js\u4ee3\u7801\uff0c\u652f\u6301\u6df7\u5408\u4e3b\u52a8\u5f0f\u7f16\u8f91\u548cAI\u52a9\u624b", "motivation": "\u6d41\u7a0b\u56fe\u901a\u5e38\u4ee5\u9759\u6001\u56fe\u50cf\u5f62\u5f0f\u5206\u4eab\uff0c\u96be\u4ee5\u7f16\u8f91\u548c\u91cd\u7528\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5c06\u5176\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u3001\u7248\u672c\u53ef\u63a7\u7684\u6587\u672c\u8868\u793a", "method": "\u4f7f\u7528\u8be6\u7ec6\u7684\u7cfb\u7edf\u63d0\u793a\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7Web\u754c\u9762\u5c06\u6d41\u7a0b\u56fe\u56fe\u50cf\u8f6c\u6362\u4e3aMermaid.js\u4ee3\u7801\uff0c\u652f\u6301\u6587\u672c\u7f16\u8f91\u3001\u62d6\u653e\u8282\u70b9\u63d2\u5165\u548c\u81ea\u7136\u8bed\u8a00\u547d\u4ee4", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u751f\u6210\u7ed3\u6784\u5316\u3001\u7248\u672c\u53ef\u63a7\u6587\u672c\u8868\u793a\u7684\u7cfb\u7edf\uff0c\u8be5\u8868\u793a\u4e0e\u6e32\u67d3\u7684\u56fe\u8868\u4fdd\u6301\u540c\u6b65\uff0c\u5e76\u5f15\u5165\u4e86\u8bc4\u4f30\u7ed3\u6784\u51c6\u786e\u6027\u3001\u6d41\u7a0b\u6b63\u786e\u6027\u3001\u8bed\u6cd5\u6709\u6548\u6027\u548c\u5b8c\u6574\u6027\u7684\u6307\u6807", "conclusion": "\u76f8\u6bd4\u4e4b\u524d\u7684\u56fe\u50cf\u8f6c\u56fe\u8868\u5de5\u5177\uff0c\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u3001\u53ef\u7f16\u8f91\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u6d41\u7a0b\u56fe\u66f4\u6613\u4e8e\u91cd\u7528\u548c\u534f\u4f5c"}}
{"id": "2512.02353", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02353", "abs": "https://arxiv.org/abs/2512.02353", "authors": ["Ruizhe Wang", "Hong Ren", "Cunhua Pan", "Ruisong Weng", "Jiangzhou Wang"], "title": "A Cyclic Shift Embedded Pilot based Channel Estimation for Multi-User MIMO-OTFS systems with fractional delay and Doppler", "comment": null, "summary": "Orthogonal time frequency space (OTFS) modulation has been proposed to meet the demand for reliable communication in high-mobility scenarios for future wireless networks. However, in multi-user OTFS systems, conventional embedded pilot schemes require independent pilot allocation for each user, leading to linearly increasing pilot overhead. To address these issues, in this paper, we investigate the uplink channel estimation and pilot design for multi-user multiple-input multiple-output (MIMO)-OTFS systems. We propose a multi-dimensional decomposition-based channel estimation algorithm. Specifically, the proposed algorithm first estimates the angles of arrivals (AoAs) via subspace decomposition-based method. A spatial projection matrix, constructed from the estimated AOAs, decouples the received signal by propagation path subspace, effectively mitigating inter-path interference. The remaining fractional delay and Doppler can be obtained by a compressed sensing (CS)-based off-grid channel estimation method. Furthermore, to reduce the pilot overhead in multi-user OTFS systems, this paper proposes a novel cyclic shift embedded pilot (CSEP) structure, which can reuse users through cyclic shift-orthogonality of Zadoff-Chu (ZC) sequences. Compared with conventional embedded pilot structures, the CSEP structure can save over 30\\% of pilot overhead. Finally, an imporved channel estimation method based on the CSEP structure is proposed. Simulation results demonstrate that it achieves superior performance in channel estimation. Moreover, the proposed CSEP structure and channel estimation algorithm achieve a favorable balance between computational complexity, estimation accuracy, and bit error rate (BER) performance.", "AI": {"tldr": "\u63d0\u51fa\u591a\u7528\u6237MIMO-OTFS\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\u4e0e\u5bfc\u9891\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u591a\u7ef4\u5206\u89e3\u7684\u4fe1\u9053\u4f30\u8ba1\u7b97\u6cd5\u548c\u5faa\u73af\u79fb\u4f4d\u5d4c\u5165\u5f0f\u5bfc\u9891\u7ed3\u6784\uff0c\u663e\u8457\u964d\u4f4e\u5bfc\u9891\u5f00\u9500\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u591a\u7528\u6237OTFS\u7cfb\u7edf\u4e2d\uff0c\u4f20\u7edf\u5d4c\u5165\u5f0f\u5bfc\u9891\u65b9\u6848\u9700\u8981\u4e3a\u6bcf\u4e2a\u7528\u6237\u72ec\u7acb\u5206\u914d\u5bfc\u9891\uff0c\u5bfc\u81f4\u5bfc\u9891\u5f00\u9500\u7ebf\u6027\u589e\u52a0\u3002\u4e3a\u6ee1\u8db3\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u4e0b\u7684\u53ef\u9760\u901a\u4fe1\u9700\u6c42\uff0c\u9700\u8981\u89e3\u51b3\u591a\u7528\u6237MIMO-OTFS\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\u548c\u5bfc\u9891\u8bbe\u8ba1\u95ee\u9898\u3002", "method": "1. \u63d0\u51fa\u57fa\u4e8e\u591a\u7ef4\u5206\u89e3\u7684\u4fe1\u9053\u4f30\u8ba1\u7b97\u6cd5\uff1a\u9996\u5148\u901a\u8fc7\u5b50\u7a7a\u95f4\u5206\u89e3\u65b9\u6cd5\u4f30\u8ba1\u5230\u8fbe\u89d2\uff0c\u6784\u5efa\u7a7a\u95f4\u6295\u5f71\u77e9\u9635\u89e3\u8026\u63a5\u6536\u4fe1\u53f7\uff1b\u7136\u540e\u4f7f\u7528\u57fa\u4e8e\u538b\u7f29\u611f\u77e5\u7684\u79bb\u7f51\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\u83b7\u53d6\u5269\u4f59\u5206\u6570\u65f6\u5ef6\u548c\u591a\u666e\u52d2\u9891\u79fb\u30022. \u63d0\u51fa\u5faa\u73af\u79fb\u4f4d\u5d4c\u5165\u5f0f\u5bfc\u9891\u7ed3\u6784\uff1a\u5229\u7528Zadoff-Chu\u5e8f\u5217\u7684\u5faa\u73af\u79fb\u4f4d\u6b63\u4ea4\u6027\u5b9e\u73b0\u7528\u6237\u590d\u7528\uff0c\u51cf\u5c11\u5bfc\u9891\u5f00\u9500\u30023. \u57fa\u4e8eCSEP\u7ed3\u6784\u6539\u8fdb\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff1a1. \u63d0\u51fa\u7684\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\u6027\u80fd\u4f18\u8d8a\uff1b2. CSEP\u7ed3\u6784\u76f8\u6bd4\u4f20\u7edf\u5d4c\u5165\u5f0f\u5bfc\u9891\u7ed3\u6784\u53ef\u8282\u7701\u8d85\u8fc730%\u7684\u5bfc\u9891\u5f00\u9500\uff1b3. \u6574\u4f53\u65b9\u6848\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u3001\u4f30\u8ba1\u7cbe\u5ea6\u548c\u8bef\u7801\u7387\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u591a\u7528\u6237MIMO-OTFS\u7cfb\u7edf\u4fe1\u9053\u4f30\u8ba1\u4e0e\u5bfc\u9891\u8bbe\u8ba1\u65b9\u6848\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5bfc\u9891\u5f00\u9500\u5927\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u7ef4\u5206\u89e3\u7b97\u6cd5\u548c\u5faa\u73af\u79fb\u4f4d\u5bfc\u9891\u7ed3\u6784\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u3001\u4f4e\u5f00\u9500\u7684\u4fe1\u9053\u4f30\u8ba1\uff0c\u4e3a\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u4e0b\u7684\u53ef\u9760\u901a\u4fe1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02193", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02193", "abs": "https://arxiv.org/abs/2512.02193", "authors": ["Alexander Boyd", "Franz Nowak", "David Hyland", "Manuel Baltieri", "Fernando E. Rosas"], "title": "From monoliths to modules: Decomposing transducers for efficient world modelling", "comment": null, "summary": "World models have been recently proposed as sandbox environments in which AI agents can be trained and evaluated before deployment. Although realistic world models often have high computational demands, efficient modelling is usually possible by exploiting the fact that real-world scenarios tend to involve subcomponents that interact in a modular manner. In this paper, we explore this idea by developing a framework for decomposing complex world models represented by transducers, a class of models generalising POMDPs. Whereas the composition of transducers is well understood, our results clarify how to invert this process, deriving sub-transducers operating on distinct input-output subspaces, enabling parallelizable and interpretable alternatives to monolithic world modelling that can support distributed inference. Overall, these results lay a groundwork for bridging the structural transparency demanded by AI safety and the computational efficiency required for real-world inference.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u7528\u4e8e\u5c06\u590d\u6742\u7684\u4e16\u754c\u6a21\u578b\uff08\u7528transducer\u8868\u793a\uff09\u5206\u89e3\u4e3a\u53ef\u5e76\u884c\u5904\u7406\u7684\u5b50transducer\uff0c\u4ece\u800c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u5e76\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u6a21\u578b\u901a\u5e38\u8ba1\u7b97\u9700\u6c42\u9ad8\uff0c\u4f46\u771f\u5b9e\u573a\u666f\u5f80\u5f80\u5305\u542b\u6a21\u5757\u5316\u4ea4\u4e92\u7684\u5b50\u7ec4\u4ef6\u3002\u4e3a\u4e86\u5728AI\u5b89\u5168\u6240\u9700\u7684\u900f\u660e\u6027\u548c\u5b9e\u9645\u63a8\u7406\u6240\u9700\u7684\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u5efa\u7acb\u6865\u6881\uff0c\u9700\u8981\u5f00\u53d1\u53ef\u5206\u89e3\u7684\u4e16\u754c\u6a21\u578b\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u7528\u4e8e\u5c06\u8868\u793a\u4e3atransducer\uff08\u4e00\u79cd\u63a8\u5e7fPOMDP\u7684\u6a21\u578b\u7c7b\uff09\u7684\u590d\u6742\u4e16\u754c\u6a21\u578b\u5206\u89e3\u3002\u8be5\u65b9\u6cd5\u53cd\u8f6c\u4e86transducer\u7ec4\u5408\u8fc7\u7a0b\uff0c\u63a8\u5bfc\u51fa\u5728\u72ec\u7acb\u8f93\u5165-\u8f93\u51fa\u5b50\u7a7a\u95f4\u4e0a\u8fd0\u884c\u7684\u5b50transducer\u3002", "result": "\u5b9e\u73b0\u4e86\u53ef\u5e76\u884c\u5316\u548c\u53ef\u89e3\u91ca\u7684\u6a21\u5757\u5316\u4e16\u754c\u5efa\u6a21\u66ff\u4ee3\u65b9\u6848\uff0c\u652f\u6301\u5206\u5e03\u5f0f\u63a8\u7406\u3002\u4e3aAI\u5b89\u5168\u7684\u7ed3\u6784\u900f\u660e\u6027\u548c\u5b9e\u9645\u63a8\u7406\u7684\u8ba1\u7b97\u6548\u7387\u9700\u6c42\u4e4b\u95f4\u5efa\u7acb\u4e86\u57fa\u7840\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u590d\u6742\u4e16\u754c\u6a21\u578b\u7684\u5206\u89e3\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u4f7f\u5f97\u5728\u4fdd\u6301\u6a21\u578b\u900f\u660e\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u6210\u4e3a\u53ef\u80fd\uff0c\u6709\u52a9\u4e8eAI\u7cfb\u7edf\u7684\u5b89\u5168\u90e8\u7f72\u3002"}}
{"id": "2512.02397", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02397", "abs": "https://arxiv.org/abs/2512.02397", "authors": ["Emanuele Bossi", "C. Tyler Diggans", "Abd AlRahman R. AlMomani"], "title": "Boltzmann-Shannon Index: A Geometric-Aware Measure of Clustering Balance", "comment": null, "summary": "We introduce the Boltzmann-Shannon Index (BSI), a normalized measure for clustered continuous data that captures the interaction between frequency-based and geometry-based probability distributions. Building on ideas from geometric coarse-graining and information theory, the BSI quantifies how well a partition reflects both the population of each cluster and its effective geometric extent. We illustrate its behavior on synthetic Gaussian mixtures, the Iris benchmark, and a high-imbalance resource-allocation scenario, showing that the index provides a coherent assessment even when traditional metrics give incomplete or misleading signals. Moreover, in resource-allocation settings, we demonstrate that BSI not only detects severe density-geometry inconsistency with high sensitivity, but also offers a smooth, optimization-ready objective that naturally favors allocations balancing demographic weight with each group's effective spread in the outcome space, while providing a smooth, gradient-friendly regularizer that can be easily embedded in modern policy-making and algorithmic governance optimization frameworks.", "AI": {"tldr": "\u63d0\u51faBoltzmann-Shannon\u6307\u6570(BSI)\uff0c\u4e00\u79cd\u7528\u4e8e\u805a\u7c7b\u8fde\u7eed\u6570\u636e\u7684\u5f52\u4e00\u5316\u5ea6\u91cf\uff0c\u6355\u6349\u57fa\u4e8e\u9891\u7387\u548c\u57fa\u4e8e\u51e0\u4f55\u7684\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "motivation": "\u4f20\u7edf\u805a\u7c7b\u5ea6\u91cf\u5728\u8bc4\u4f30\u805a\u7c7b\u8d28\u91cf\u65f6\u5f80\u5f80\u53ea\u5173\u6ce8\u9891\u7387\u5206\u5e03\u6216\u51e0\u4f55\u5206\u5e03\uff0c\u65e0\u6cd5\u540c\u65f6\u53cd\u6620\u805a\u7c7b\u7684\u4eba\u53e3\u7edf\u8ba1\u6743\u91cd\u548c\u51e0\u4f55\u6269\u5c55\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u5206\u914d\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u5e73\u8861\u8fd9\u4e24\u65b9\u9762\u56e0\u7d20\u3002", "method": "\u57fa\u4e8e\u51e0\u4f55\u7c97\u7c92\u5316\u548c\u4fe1\u606f\u7406\u8bba\u601d\u60f3\uff0cBSI\u91cf\u5316\u5206\u533a\u5982\u4f55\u53cd\u6620\u6bcf\u4e2a\u805a\u7c7b\u7684\u4eba\u53e3\u7edf\u8ba1\u548c\u6709\u6548\u51e0\u4f55\u8303\u56f4\uff0c\u901a\u8fc7\u7ed3\u5408\u9891\u7387\u57fa\u548c\u51e0\u4f55\u57fa\u6982\u7387\u5206\u5e03\u6765\u8bc4\u4f30\u805a\u7c7b\u8d28\u91cf\u3002", "result": "\u5728\u5408\u6210\u9ad8\u65af\u6df7\u5408\u3001Iris\u57fa\u51c6\u548c\u9ad8\u4e0d\u5e73\u8861\u8d44\u6e90\u5206\u914d\u573a\u666f\u4e2d\uff0cBSI\u63d0\u4f9b\u4e86\u8fde\u8d2f\u7684\u8bc4\u4f30\uff0c\u5373\u4f7f\u5728\u4f20\u7edf\u6307\u6807\u7ed9\u51fa\u4e0d\u5b8c\u6574\u6216\u8bef\u5bfc\u4fe1\u53f7\u65f6\u4e5f\u80fd\u6709\u6548\u5de5\u4f5c\u3002\u5728\u8d44\u6e90\u5206\u914d\u4e2d\uff0cBSI\u80fd\u9ad8\u7075\u654f\u5ea6\u68c0\u6d4b\u5bc6\u5ea6-\u51e0\u4f55\u4e0d\u4e00\u81f4\u6027\u3002", "conclusion": "BSI\u4e0d\u4ec5\u662f\u4e00\u4e2a\u6709\u6548\u7684\u805a\u7c7b\u8bc4\u4f30\u6307\u6807\uff0c\u8fd8\u80fd\u4f5c\u4e3a\u5e73\u6ed1\u3001\u4f18\u5316\u5c31\u7eea\u7684\u76ee\u6807\u51fd\u6570\uff0c\u81ea\u7136\u5730\u652f\u6301\u5e73\u8861\u4eba\u53e3\u7edf\u8ba1\u6743\u91cd\u4e0e\u7ed3\u679c\u7a7a\u95f4\u4e2d\u6709\u6548\u6269\u5c55\u7684\u8d44\u6e90\u5206\u914d\uff0c\u4e3a\u73b0\u4ee3\u653f\u7b56\u5236\u5b9a\u548c\u7b97\u6cd5\u6cbb\u7406\u63d0\u4f9b\u68af\u5ea6\u53cb\u597d\u7684\u6b63\u5219\u5316\u5668\u3002"}}
{"id": "2512.02347", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02347", "abs": "https://arxiv.org/abs/2512.02347", "authors": ["Anjali Yadav", "Arya Agarwal", "Alok Kumar", "Tushar S. Muratkar", "Gaurav S. Kasbekar"], "title": "Coalitional Game Framework for Multicast in Wireless Networks", "comment": null, "summary": "We consider a wireless network in which there is a transmitter and a set of users, all of whom want to download a popular file from the transmitter. Using the framework of cooperative game theory, we investigate conditions under which users have incentives to cooperate among themselves to form coalitions for the purpose of receiving the file via multicast from the transmitter. First, using the solution concept of core, we investigate conditions under which it is beneficial for all users to cooperate, i.e., the grand coalition is stable. We provide several sets of sufficient conditions under which the core is non-empty as well as those under which the core is empty. Next, we use the concept of $\\mathbb{D}_c$-stability to identify a set of sufficient conditions under which the users in the network form a certain fixed number of coalitions such that all the users within each coalition cooperate among themselves. Our analytical results show how the values of different system parameters, e.g., data rates of different users, transmit and receive power, file size, bandwidth cost, etc., influence stability properties of coalitions, and provide a systematic approach to evaluating cooperation of users for multicast. We also study cooperation among different users using numerical computations. The problem of coalition formation in the context of multicast addressed in this paper is fundamental, and our analysis provides new insights into the feasibility of stable cooperative multicast strategies, contributing to a deeper understanding of cooperation in wireless networks.", "AI": {"tldr": "\u7814\u7a76\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7528\u6237\u901a\u8fc7\u5408\u4f5c\u5f62\u6210\u8054\u76df\u8fdb\u884c\u7ec4\u64ad\u4e0b\u8f7d\u7684\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u5206\u6790\u6838\u5fc3\u89e3\u7684\u5b58\u5728\u6027\u548cD_c\u7a33\u5b9a\u6027\uff0c\u63a2\u8ba8\u7cfb\u7edf\u53c2\u6570\u5bf9\u8054\u76df\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\u3002", "motivation": "\u5728\u65e0\u7ebf\u7f51\u7edc\u4e2d\uff0c\u591a\u4e2a\u7528\u6237\u90fd\u5e0c\u671b\u4ece\u53d1\u5c04\u673a\u4e0b\u8f7d\u540c\u4e00\u4e2a\u70ed\u95e8\u6587\u4ef6\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u7528\u6237\u4e4b\u95f4\u662f\u5426\u6709\u6fc0\u52b1\u8fdb\u884c\u5408\u4f5c\u5f62\u6210\u8054\u76df\uff0c\u4ee5\u4fbf\u901a\u8fc7\u7ec4\u64ad\u65b9\u5f0f\u63a5\u6536\u6587\u4ef6\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u5229\u7528\u7f51\u7edc\u8d44\u6e90\u3002", "method": "\u4f7f\u7528\u5408\u4f5c\u535a\u5f08\u8bba\u6846\u67b6\uff0c\u9996\u5148\u91c7\u7528\u6838\u5fc3\u89e3\u6982\u5ff5\u5206\u6790\u5927\u8054\u76df\u7684\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u8bc6\u522b\u6838\u5fc3\u975e\u7a7a\u548c\u7a7a\u7684\u6761\u4ef6\uff1b\u7136\u540e\u4f7f\u7528D_c\u7a33\u5b9a\u6027\u6982\u5ff5\u5206\u6790\u56fa\u5b9a\u6570\u91cf\u8054\u76df\u5f62\u6210\u7684\u6761\u4ef6\uff1b\u6700\u540e\u901a\u8fc7\u6570\u503c\u8ba1\u7b97\u9a8c\u8bc1\u5206\u6790\u7ed3\u679c\u3002", "result": "\u5206\u6790\u7ed3\u679c\u8868\u660e\uff0c\u4e0d\u540c\u7cfb\u7edf\u53c2\u6570\uff08\u5982\u7528\u6237\u6570\u636e\u901f\u7387\u3001\u53d1\u5c04\u548c\u63a5\u6536\u529f\u7387\u3001\u6587\u4ef6\u5927\u5c0f\u3001\u5e26\u5bbd\u6210\u672c\u7b49\uff09\u7684\u503c\u4f1a\u5f71\u54cd\u8054\u76df\u7684\u7a33\u5b9a\u6027\u7279\u6027\u3002\u63d0\u4f9b\u4e86\u8bc4\u4f30\u7528\u6237\u7ec4\u64ad\u5408\u4f5c\u53ef\u884c\u6027\u7684\u7cfb\u7edf\u65b9\u6cd5\uff0c\u5e76\u8bc6\u522b\u4e86\u7a33\u5b9a\u5408\u4f5c\u7ec4\u64ad\u7b56\u7565\u7684\u6761\u4ef6\u3002", "conclusion": "\u672c\u6587\u89e3\u51b3\u4e86\u7ec4\u64ad\u80cc\u666f\u4e0b\u8054\u76df\u5f62\u6210\u7684\u57fa\u672c\u95ee\u9898\uff0c\u4e3a\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7a33\u5b9a\u5408\u4f5c\u7ec4\u64ad\u7b56\u7565\u7684\u53ef\u884c\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u66f4\u6df1\u5165\u5730\u7406\u89e3\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u5408\u4f5c\u884c\u4e3a\u3002"}}
{"id": "2512.02228", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02228", "abs": "https://arxiv.org/abs/2512.02228", "authors": ["Shubhi Asthana", "Bing Zhang", "Chad DeLuca", "Ruchi Mahindru", "Hima Patel"], "title": "STRIDE: A Systematic Framework for Selecting AI Modalities -- Agentic AI, AI Assistants, or LLM Calls", "comment": "10 pages, 4 Figures, 5 Tables Paper presented at NeurIPS 2025 LAW workshop: Bridging Language, Agent, and World Models", "summary": "The rapid shift from stateless large language models (LLMs) to autonomous, goal-driven agents raises a central question: When is agentic AI truly necessary? While agents enable multi-step reasoning, persistent memory, and tool orchestration, deploying them indiscriminately leads to higher cost, complexity, and risk.\n  We present STRIDE (Systematic Task Reasoning Intelligence Deployment Evaluator), a framework that provides principled recommendations for selecting between three modalities: (i) direct LLM calls, (ii) guided AI assistants, and (iii) fully autonomous agentic AI. STRIDE integrates structured task decomposition, dynamism attribution, and self-reflection requirement analysis to produce an Agentic Suitability Score, ensuring that full agentic autonomy is reserved for tasks with inherent dynamism or evolving context.\n  Evaluated across 30 real-world tasks spanning SRE, compliance, and enterprise automation, STRIDE achieved 92% accuracy in modality selection, reduced unnecessary agent deployments by 45%, and cut resource costs by 37%. Expert validation over six months in SRE and compliance domains confirmed its practical utility, with domain specialists agreeing that STRIDE effectively distinguishes between tasks requiring simple LLM calls, guided assistants, or full agentic autonomy. This work reframes agent adoption as a necessity-driven design decision, ensuring autonomy is applied only when its benefits justify the costs.", "AI": {"tldr": "STRIDE\u6846\u67b6\u5e2e\u52a9\u51b3\u5b9a\u4f55\u65f6\u4f7f\u7528AI\u4ee3\u7406\uff1a\u901a\u8fc7\u4efb\u52a1\u5206\u89e3\u3001\u52a8\u6001\u6027\u8bc4\u4f30\u548c\u81ea\u53cd\u601d\u9700\u6c42\u5206\u6790\uff0c\u4e3a\u4efb\u52a1\u63a8\u8350\u6700\u5408\u9002\u7684AI\u90e8\u7f72\u6a21\u5f0f\uff08\u76f4\u63a5LLM\u8c03\u7528\u3001\u5f15\u5bfc\u5f0f\u52a9\u624b\u6216\u5b8c\u5168\u81ea\u4e3b\u4ee3\u7406\uff09\uff0c\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u4ee3\u7406\u90e8\u7f72\u3002", "motivation": "\u968f\u7740AI\u4ece\u65e0\u72b6\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5411\u81ea\u4e3b\u76ee\u6807\u9a71\u52a8\u4ee3\u7406\u7684\u5feb\u901f\u8f6c\u53d8\uff0c\u9700\u8981\u89e3\u51b3\u4e00\u4e2a\u6838\u5fc3\u95ee\u9898\uff1a\u4f55\u65f6\u771f\u6b63\u9700\u8981\u4ee3\u7406\u5f0fAI\uff1f\u4e0d\u52a0\u533a\u5206\u5730\u90e8\u7f72\u4ee3\u7406\u4f1a\u5bfc\u81f4\u6210\u672c\u3001\u590d\u6742\u6027\u548c\u98ce\u9669\u589e\u52a0\uff0c\u56e0\u6b64\u9700\u8981\u539f\u5219\u6027\u7684\u6846\u67b6\u6765\u51b3\u5b9a\u4f55\u65f6\u4f7f\u7528\u4ee3\u7406\u3002", "method": "\u63d0\u51faSTRIDE\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u4efb\u52a1\u5206\u89e3\u3001\u52a8\u6001\u6027\u5f52\u56e0\u548c\u81ea\u53cd\u601d\u9700\u6c42\u5206\u6790\uff0c\u8ba1\u7b97\u4ee3\u7406\u9002\u7528\u6027\u5206\u6570\uff0c\u4e3a\u4efb\u52a1\u63a8\u8350\u4e09\u79cd\u90e8\u7f72\u6a21\u5f0f\u4e4b\u4e00\uff1a\u76f4\u63a5LLM\u8c03\u7528\u3001\u5f15\u5bfc\u5f0fAI\u52a9\u624b\u6216\u5b8c\u5168\u81ea\u4e3b\u4ee3\u7406\u5f0fAI\u3002", "result": "\u572830\u4e2a\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\uff08\u6db5\u76d6SRE\u3001\u5408\u89c4\u548c\u4f01\u4e1a\u81ea\u52a8\u5316\uff09\u4e2d\u8bc4\u4f30\uff0cSTRIDE\u5728\u6a21\u5f0f\u9009\u62e9\u4e0a\u8fbe\u523092%\u51c6\u786e\u7387\uff0c\u51cf\u5c1145%\u4e0d\u5fc5\u8981\u7684\u4ee3\u7406\u90e8\u7f72\uff0c\u964d\u4f4e37%\u8d44\u6e90\u6210\u672c\u3002\u516d\u4e2a\u6708\u4e13\u5bb6\u9a8c\u8bc1\u786e\u8ba4\u5176\u5b9e\u9645\u6548\u7528\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c06\u4ee3\u7406\u91c7\u7528\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5fc5\u8981\u6027\u9a71\u52a8\u7684\u8bbe\u8ba1\u51b3\u7b56\uff0c\u786e\u4fdd\u81ea\u4e3b\u6027\u53ea\u5728\u6536\u76ca\u8bc1\u660e\u6210\u672c\u5408\u7406\u65f6\u624d\u88ab\u5e94\u7528\uff0c\u4e3aAI\u90e8\u7f72\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7684\u51b3\u7b56\u6846\u67b6\u3002"}}
{"id": "2512.02449", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02449", "abs": "https://arxiv.org/abs/2512.02449", "authors": ["Brendon McBain", "Yi Hong", "Emanuele Viterbo"], "title": "Optimal Handover Strategies in LEO Satellite Networks", "comment": "13 pages, 4 figures. Submitted to IEEE Transactions on Communications", "summary": "Existing theoretical analyses of satellite mega-constellations often rely on restrictive assumptions, such as short serving times, or lack tractability when evaluating realistic handover strategies. Motivated by these limitations, this paper develops a general analytical framework for accurately characterising the ergodic capacity of low Earth orbit (LEO) satellite networks under arbitrary handover strategies. Specifically, we model the transmission link as shadowed-Rician fading and introduce the persistent satellite channel, wherein the channel process is governed by an i.i.d. renewal process under mild assumptions of uncoordinated handover decisions and knowledge of satellite ephemeris and fading parameters. Within this framework, we derive the ergodic capacity (persistent capacity) of the persistent satellite channel using renewal theory and establish its relation to the non-persistent capacity studied in prior work. To address computational challenges, we present closed-form upper and lower bounds on persistent capacity. The optimal handover problem is formulated as a non-linear fractional program, obtaining an explicit decision rule via a variant of Dinkelbach's algorithm. We further demonstrate that a simpler handover strategy maximising serving capacity closely approximates the optimal strategy, providing practical insights for designing high-throughput LEO satellite communication systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5206\u6790LEO\u536b\u661f\u7f51\u7edc\u5bb9\u91cf\u7684\u901a\u7528\u6846\u67b6\uff0c\u8003\u8651\u4efb\u610f\u5207\u6362\u7b56\u7565\uff0c\u63a8\u5bfc\u6301\u4e45\u5bb9\u91cf\u53ca\u5176\u4e0a\u4e0b\u754c\uff0c\u5e76\u7ed9\u51fa\u6700\u4f18\u5207\u6362\u51b3\u7b56\u89c4\u5219\u3002", "motivation": "\u73b0\u6709\u536b\u661f\u661f\u5ea7\u7406\u8bba\u5206\u6790\u5b58\u5728\u9650\u5236\u6027\u5047\u8bbe\uff08\u5982\u77ed\u670d\u52a1\u65f6\u95f4\uff09\uff0c\u6216\u5728\u8bc4\u4f30\u5b9e\u9645\u5207\u6362\u7b56\u7565\u65f6\u7f3a\u4e4f\u53ef\u5904\u7406\u6027\uff0c\u9700\u8981\u66f4\u901a\u7528\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u5c06\u4f20\u8f93\u94fe\u8def\u5efa\u6a21\u4e3a\u9634\u5f71Rician\u8870\u843d\uff0c\u5f15\u5165\u6301\u4e45\u536b\u661f\u4fe1\u9053\u6982\u5ff5\uff08\u4fe1\u9053\u8fc7\u7a0b\u7531i.i.d.\u66f4\u65b0\u8fc7\u7a0b\u63a7\u5236\uff09\uff0c\u5229\u7528\u66f4\u65b0\u7406\u8bba\u63a8\u5bfc\u6301\u4e45\u5bb9\u91cf\uff0c\u5efa\u7acb\u95ed\u5f0f\u4e0a\u4e0b\u754c\uff0c\u5c06\u6700\u4f18\u5207\u6362\u95ee\u9898\u516c\u5f0f\u5316\u4e3a\u975e\u7ebf\u6027\u5206\u5f0f\u89c4\u5212\uff0c\u4f7f\u7528Dinkelbach\u7b97\u6cd5\u53d8\u4f53\u83b7\u5f97\u663e\u5f0f\u51b3\u7b56\u89c4\u5219\u3002", "result": "\u63a8\u5bfc\u51fa\u6301\u4e45\u536b\u661f\u4fe1\u9053\u7684\u904d\u5386\u5bb9\u91cf\uff08\u6301\u4e45\u5bb9\u91cf\uff09\uff0c\u5efa\u7acb\u4e86\u4e0e\u5148\u524d\u7814\u7a76\u7684\u975e\u6301\u4e45\u5bb9\u91cf\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u95ed\u5f0f\u4e0a\u4e0b\u754c\uff0c\u83b7\u5f97\u4e86\u6700\u4f18\u5207\u6362\u7684\u663e\u5f0f\u51b3\u7b56\u89c4\u5219\uff0c\u5e76\u8bc1\u660e\u6700\u5927\u5316\u670d\u52a1\u5bb9\u91cf\u7684\u7b80\u5316\u5207\u6362\u7b56\u7565\u80fd\u5f88\u597d\u5730\u903c\u8fd1\u6700\u4f18\u7b56\u7565\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u51c6\u786e\u8868\u5f81LEO\u536b\u661f\u7f51\u7edc\u5728\u4efb\u610f\u5207\u6362\u7b56\u7565\u4e0b\u7684\u5bb9\u91cf\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u63d0\u51fa\u7684\u7b80\u5316\u5207\u6362\u7b56\u7565\u4e3a\u8bbe\u8ba1\u9ad8\u541e\u5410\u91cfLEO\u536b\u661f\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2512.02370", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02370", "abs": "https://arxiv.org/abs/2512.02370", "authors": ["Hongyang Pan", "Bin Lin", "Yanheng Liu", "Shuang Liang", "Chau Yuen"], "title": "Diffusion-Model-enhanced Multiobjective Optimization for Improving Forest Monitoring Efficiency in UAV-enabled Internet-of-Things", "comment": null, "summary": "The Internet-of-Things (IoT) is widely applied for forest monitoring, since the sensor nodes (SNs) in IoT network are low-cost and have computing ability to process the monitoring data. To further improve the performance of forest monitoring, uncrewed aerial vehicles (UAVs) are employed as the data processors to enhance computing capability. However, efficient forest monitoring with limited energy budget and computing resource presents a significant challenge. For this purpose, this paper formulates a multi-objective optimization framework to simultaneously consider three optimization objectives, which are minimizing the maximum computing delay, minimizing the total motion energy consumption, and minimizing the maximum computing resource, corresponding to efficient forest monitoring, energy consumption reduction, and computing resource control, respectively. Due to the hybrid solution space that consists of continuous and discrete solutions, we propose a diffusion model-enhanced improved multi-objective grey wolf optimizer (IMOGWO) to solve the formulated framework. The simulation results show that the proposed IMOGWO outperforms other benchmarks for solving the formulated framework. Specifically, for a small-scale network with $6$ UAVs and $50$ SNs, compared to the suboptimal benchmark, IMOGWO reduces the motion energy consumption and the computing resource by $53.32\\%$ and $9.83\\%$, respectively, while maintaining computing delay at the same level. Similarly, for a large-scale network with $8$ UAVs and $100$ SNs, IMOGWO achieves reductions of $41.81\\%$ in motion energy consumption and $7.93\\%$ in computing resource, with the computing delay also remaining comparable.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u589e\u5f3a\u7684\u591a\u76ee\u6807\u7070\u72fc\u4f18\u5316\u5668\uff08IMOGWO\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u68ee\u6797\u76d1\u6d4b\u4e2d\u65e0\u4eba\u673a\u8f85\u52a9\u7269\u8054\u7f51\u7cfb\u7edf\u7684\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u65e8\u5728\u540c\u65f6\u6700\u5c0f\u5316\u8ba1\u7b97\u5ef6\u8fdf\u3001\u8fd0\u52a8\u80fd\u8017\u548c\u8ba1\u7b97\u8d44\u6e90\u3002", "motivation": "\u68ee\u6797\u76d1\u6d4b\u4e2d\u7269\u8054\u7f51\u4f20\u611f\u5668\u8282\u70b9\u8ba1\u7b97\u80fd\u529b\u6709\u9650\uff0c\u867d\u7136\u65e0\u4eba\u673a\u53ef\u4ee5\u4f5c\u4e3a\u79fb\u52a8\u8ba1\u7b97\u5904\u7406\u5668\u589e\u5f3a\u8ba1\u7b97\u80fd\u529b\uff0c\u4f46\u9762\u4e34\u7740\u6709\u9650\u80fd\u91cf\u9884\u7b97\u548c\u8ba1\u7b97\u8d44\u6e90\u4e0b\u7684\u9ad8\u6548\u76d1\u6d4b\u6311\u6218\u3002\u9700\u8981\u540c\u65f6\u4f18\u5316\u8ba1\u7b97\u5ef6\u8fdf\u3001\u80fd\u8017\u548c\u8d44\u6e90\u4f7f\u7528\u3002", "method": "\u6784\u5efa\u4e86\u540c\u65f6\u6700\u5c0f\u5316\u6700\u5927\u8ba1\u7b97\u5ef6\u8fdf\u3001\u603b\u8fd0\u52a8\u80fd\u8017\u548c\u6700\u5927\u8ba1\u7b97\u8d44\u6e90\u7684\u4e09\u76ee\u6807\u4f18\u5316\u6846\u67b6\u3002\u9488\u5bf9\u6df7\u5408\u89e3\u7a7a\u95f4\uff08\u8fde\u7eed\u548c\u79bb\u6563\u89e3\uff09\uff0c\u63d0\u51fa\u4e86\u6269\u6563\u6a21\u578b\u589e\u5f3a\u7684\u6539\u8fdb\u591a\u76ee\u6807\u7070\u72fc\u4f18\u5316\u5668\uff08IMOGWO\uff09\u3002", "result": "IMOGWO\u5728\u89e3\u51b3\u8be5\u4f18\u5316\u6846\u67b6\u65f6\u4f18\u4e8e\u5176\u4ed6\u57fa\u51c6\u65b9\u6cd5\u3002\u5728\u5c0f\u89c4\u6a21\u7f51\u7edc\uff086\u67b6\u65e0\u4eba\u673a\uff0c50\u4e2a\u4f20\u611f\u5668\u8282\u70b9\uff09\u4e2d\uff0c\u76f8\u6bd4\u6b21\u4f18\u57fa\u51c6\uff0c\u8fd0\u52a8\u80fd\u8017\u964d\u4f4e53.32%\uff0c\u8ba1\u7b97\u8d44\u6e90\u51cf\u5c119.83%\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u5ef6\u8fdf\u6c34\u5e73\u3002\u5728\u5927\u89c4\u6a21\u7f51\u7edc\uff088\u67b6\u65e0\u4eba\u673a\uff0c100\u4e2a\u4f20\u611f\u5668\u8282\u70b9\uff09\u4e2d\uff0c\u8fd0\u52a8\u80fd\u8017\u964d\u4f4e41.81%\uff0c\u8ba1\u7b97\u8d44\u6e90\u51cf\u5c117.93%\uff0c\u8ba1\u7b97\u5ef6\u8fdf\u4fdd\u6301\u76f8\u5f53\u3002", "conclusion": "\u63d0\u51fa\u7684IMOGWO\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u68ee\u6797\u76d1\u6d4b\u4e2d\u65e0\u4eba\u673a\u8f85\u52a9\u7269\u8054\u7f51\u7cfb\u7edf\u7684\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u5728\u964d\u4f4e\u80fd\u8017\u548c\u8d44\u6e90\u4f7f\u7528\u7684\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6027\u80fd\uff0c\u4e3a\u9ad8\u6548\u68ee\u6797\u76d1\u6d4b\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02230", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02230", "abs": "https://arxiv.org/abs/2512.02230", "authors": ["Rory Milsom"], "title": "Benchmarking LLM Agents for Wealth-Management Workflows", "comment": "56 pages, 8 figures, The University of Edinburgh", "summary": "Modern work relies on an assortment of digital collaboration tools, yet routine processes continue to suffer from human error and delay. To address this gap, this dissertation extends TheAgentCompany with a finance-focused environment and investigates whether a general purpose LLM agent can complete representative wealth-management tasks both accurately and economically. This study introduces synthetic domain data, enriches colleague simulations, and prototypes an automatic task-generation pipeline. The study aims to create and assess an evaluation set that can meaningfully measure an agent's fitness for assistant-level wealth management work. We construct a benchmark of 12 task-pairs for wealth management assistants spanning retrieval, analysis, and synthesis/communication, with explicit acceptance criteria and deterministic graders. We seeded a set of new finance-specific data and introduced a high vs. low-autonomy variant of every task. The paper concluded that agents are limited less by mathematical reasoning and more so by end-to-end workflow reliability, and meaningfully affected by autonomy level, and that incorrect evaluation of models have hindered benchmarking.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6269\u5c55\u4e86TheAgentCompany\u5e73\u53f0\uff0c\u521b\u5efa\u4e86\u8d22\u5bcc\u7ba1\u7406\u9886\u57df\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u7814\u7a76\u901a\u7528LLM\u4ee3\u7406\u80fd\u5426\u51c6\u786e\u4e14\u7ecf\u6d4e\u5730\u5b8c\u6210\u8d22\u5bcc\u7ba1\u7406\u4efb\u52a1\uff0c\u53d1\u73b0\u4ee3\u7406\u7684\u4e3b\u8981\u9650\u5236\u5728\u4e8e\u7aef\u5230\u7aef\u5de5\u4f5c\u6d41\u53ef\u9760\u6027\u800c\u975e\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u4ee3\u5de5\u4f5c\u4f9d\u8d56\u5404\u79cd\u6570\u5b57\u534f\u4f5c\u5de5\u5177\uff0c\u4f46\u5e38\u89c4\u6d41\u7a0b\u4ecd\u53d7\u4eba\u4e3a\u9519\u8bef\u548c\u5ef6\u8fdf\u56f0\u6270\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7814\u7a76\u901a\u7528LLM\u4ee3\u7406\u662f\u5426\u80fd\u5728\u8d22\u5bcc\u7ba1\u7406\u4efb\u52a1\u4e2d\u65e2\u51c6\u786e\u53c8\u7ecf\u6d4e\u5730\u5de5\u4f5c\uff0c\u4e3a\u8bc4\u4f30\u4ee3\u7406\u5728\u52a9\u7406\u7ea7\u8d22\u5bcc\u7ba1\u7406\u5de5\u4f5c\u4e2d\u7684\u9002\u7528\u6027\u521b\u5efa\u6709\u610f\u4e49\u7684\u8bc4\u4f30\u96c6\u3002", "method": "\u6269\u5c55TheAgentCompany\u5e73\u53f0\uff0c\u521b\u5efa\u8d22\u52a1\u5bfc\u5411\u7684\u73af\u5883\uff1b\u5f15\u5165\u5408\u6210\u9886\u57df\u6570\u636e\uff1b\u4e30\u5bcc\u540c\u4e8b\u6a21\u62df\uff1b\u539f\u578b\u5316\u81ea\u52a8\u4efb\u52a1\u751f\u6210\u7ba1\u9053\uff1b\u6784\u5efa\u5305\u542b12\u4e2a\u4efb\u52a1\u5bf9\u7684\u8d22\u5bcc\u7ba1\u7406\u52a9\u7406\u57fa\u51c6\uff0c\u6db5\u76d6\u68c0\u7d22\u3001\u5206\u6790\u548c\u7efc\u5408/\u6c9f\u901a\u4efb\u52a1\uff1b\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u521b\u5efa\u9ad8\u81ea\u4e3b\u6027\u548c\u4f4e\u81ea\u4e3b\u6027\u53d8\u4f53\uff1b\u4f7f\u7528\u660e\u786e\u7684\u9a8c\u6536\u6807\u51c6\u548c\u786e\u5b9a\u6027\u8bc4\u5206\u5668\u3002", "result": "\u4ee3\u7406\u7684\u4e3b\u8981\u9650\u5236\u4e0d\u5728\u4e8e\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u800c\u5728\u4e8e\u7aef\u5230\u7aef\u5de5\u4f5c\u6d41\u7684\u53ef\u9760\u6027\uff1b\u81ea\u4e3b\u6027\u6c34\u5e73\u5bf9\u4ee3\u7406\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff1b\u4e0d\u6b63\u786e\u7684\u6a21\u578b\u8bc4\u4f30\u963b\u788d\u4e86\u57fa\u51c6\u6d4b\u8bd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u7528LLM\u4ee3\u7406\u5728\u8d22\u5bcc\u7ba1\u7406\u4efb\u52a1\u4e2d\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\u662f\u5de5\u4f5c\u6d41\u53ef\u9760\u6027\u800c\u975e\u6570\u5b66\u80fd\u529b\uff0c\u81ea\u4e3b\u6027\u6c34\u5e73\u662f\u5173\u952e\u5f71\u54cd\u56e0\u7d20\uff0c\u9700\u8981\u6539\u8fdb\u8bc4\u4f30\u65b9\u6cd5\u4ee5\u51c6\u786e\u8861\u91cf\u4ee3\u7406\u5728\u4e13\u4e1a\u9886\u57df\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2512.02461", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02461", "abs": "https://arxiv.org/abs/2512.02461", "authors": ["Peng Zhang", "Jian Dang", "Miaowen Wen", "Ziyang Liu", "Chen Zhao", "Huaifeng Shi", "Chengsheng Pan", "Zaichen Zhang"], "title": "Artificial Noise Aided Physical Layer Security for Near-Field MIMO with Fluid Antenna Systems", "comment": null, "summary": "With the evolution of wireless systems toward large-scale arrays and high-frequency reconfigurable architectures, fluid antenna systems (FAS) operating in the near-field (NF) regime provide new degrees of freedom (DoF) for physical layer security (PLS). This paper proposes an artificial-noise (AN)-aided PLS scheme for NF fluid-antenna multiple-input multiple-output (FA-MIMO) systems, with joint beamforming (BF) and AN design for both compact and large arrays. An alternating-optimization (AO) framework addresses the sparsity-constrained non-convex design by splitting it into a continuous BF/AN joint-design subproblem and a discrete FAS port-selection subproblem. Closed-form fully digital BF/AN solutions are obtained via a generalized spectral water-filling procedure within a block coordinate descent (BCD) surrogate and realized by a hardware-efficient hybrid beamforming (HBF) architecture that embeds AN in the baseband without extra radio-frequency (RF) chains. For FAS port selection, a row-energy based prune--refit rule, aligned with Karush--Kuhn--Tucker (KKT) conditions of a group-sparsity surrogate, enables efficient active-port determination. Simulation results confirm that the proposed design exploits the geometry and position-domain DoF of FAS and significantly improves secrecy performance, particularly for non-extremely-large arrays where NF beam focusing alone is inadequate.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u8fd1\u573a\u6d41\u4f53\u5929\u7ebfMIMO\u7cfb\u7edf\u7684\u4eba\u5de5\u566a\u58f0\u8f85\u52a9\u7269\u7406\u5c42\u5b89\u5168\u65b9\u6848\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\u8054\u5408\u8bbe\u8ba1\u6ce2\u675f\u6210\u5f62\u548c\u4eba\u5de5\u566a\u58f0\uff0c\u5229\u7528\u6d41\u4f53\u5929\u7ebf\u7684\u51e0\u4f55\u548c\u4f4d\u7f6e\u81ea\u7531\u5ea6\u63d0\u5347\u4fdd\u5bc6\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u65e0\u7ebf\u7cfb\u7edf\u5411\u5927\u89c4\u6a21\u9635\u5217\u548c\u9ad8\u9891\u53ef\u91cd\u6784\u67b6\u6784\u6f14\u8fdb\uff0c\u8fd1\u573a\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u4e3a\u7269\u7406\u5c42\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u7684\u81ea\u7531\u5ea6\u3002\u73b0\u6709\u65b9\u6848\u5728\u975e\u6781\u5927\u9635\u5217\u4e2d\u4ec5\u9760\u8fd1\u573a\u6ce2\u675f\u805a\u7126\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u5b89\u5168\u6027\u80fd\uff0c\u9700\u8981\u5229\u7528\u6d41\u4f53\u5929\u7ebf\u7684\u51e0\u4f55\u548c\u4f4d\u7f6e\u81ea\u7531\u5ea6\u6765\u589e\u5f3a\u4fdd\u5bc6\u6027\u3002", "method": "\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\u5904\u7406\u7a00\u758f\u7ea6\u675f\u975e\u51f8\u8bbe\u8ba1\uff0c\u5206\u4e3a\u8fde\u7eed\u6ce2\u675f\u6210\u5f62/\u4eba\u5de5\u566a\u58f0\u8054\u5408\u8bbe\u8ba1\u5b50\u95ee\u9898\u548c\u79bb\u6563\u6d41\u4f53\u5929\u7ebf\u7aef\u53e3\u9009\u62e9\u5b50\u95ee\u9898\u3002\u901a\u8fc7\u5e7f\u4e49\u8c31\u6ce8\u6c34\u8fc7\u7a0b\u83b7\u5f97\u95ed\u5f0f\u5168\u6570\u5b57\u6ce2\u675f\u6210\u5f62/\u4eba\u5de5\u566a\u58f0\u89e3\uff0c\u5e76\u901a\u8fc7\u786c\u4ef6\u9ad8\u6548\u7684\u6df7\u5408\u6ce2\u675f\u6210\u5f62\u67b6\u6784\u5b9e\u73b0\u3002\u5bf9\u4e8e\u7aef\u53e3\u9009\u62e9\uff0c\u91c7\u7528\u57fa\u4e8e\u884c\u80fd\u91cf\u7684\u4fee\u526a-\u91cd\u62df\u5408\u89c4\u5219\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u8bbe\u8ba1\u80fd\u6709\u6548\u5229\u7528\u6d41\u4f53\u5929\u7ebf\u7684\u51e0\u4f55\u548c\u4f4d\u7f6e\u81ea\u7531\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u4fdd\u5bc6\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u975e\u6781\u5927\u9635\u5217\u4e2d\uff0c\u4ec5\u9760\u8fd1\u573a\u6ce2\u675f\u805a\u7126\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u5b89\u5168\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8fd1\u573a\u6d41\u4f53\u5929\u7ebfMIMO\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u4eba\u5de5\u566a\u58f0\u8f85\u52a9\u7269\u7406\u5c42\u5b89\u5168\u65b9\u6848\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u3001\u4eba\u5de5\u566a\u58f0\u548c\u7aef\u53e3\u9009\u62e9\uff0c\u5145\u5206\u5229\u7528\u4e86\u6d41\u4f53\u5929\u7ebf\u5728\u8fd1\u573a\u533a\u57df\u7684\u81ea\u7531\u5ea6\u4f18\u52bf\uff0c\u4e3a\u672a\u6765\u5927\u89c4\u6a21\u9635\u5217\u7cfb\u7edf\u7684\u5b89\u5168\u901a\u4fe1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02398", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02398", "abs": "https://arxiv.org/abs/2512.02398", "authors": ["Zhiyu Zhou", "Xin Zhe Khooi", "Satis Kumar Permal", "Mun Choon Chan"], "title": "ProtO-RU: An O-RAN Split-7.2 Radio Unit using SDRs", "comment": "9 pages, 12 figures", "summary": "We present ProtO-RU, the first open source, software-defined O-RAN Split-7.2 Radio Unit built using SDRs and commodity CPUs. Unlike proprietary hardware-based commercial O-RUs, ProtO-RU is built on the open-source srsRAN software stack, and it is fully programmable. We demonstrate that ProtO-RU integrates with the srsRAN and OpenAirInterface5G CU/DU stacks, supports both TDD and FDD duplexing modes, and interoperates with commercial 5G UEs. Our evaluation shows that ProtO-RU remains stable under sustained load with multiple UEs and delivers throughput comparable to Split-8 and commercial O-RUs. ProtO-RU opens up new opportunities for RU-level innovations and lowers the barrier of entry for end-to-end O-RAN research.", "AI": {"tldr": "ProtO-RU\u662f\u9996\u4e2a\u57fa\u4e8eSDR\u548c\u5546\u7528CPU\u7684\u5f00\u6e90\u8f6f\u4ef6\u5b9a\u4e49O-RAN Split-7.2\u65e0\u7ebf\u5355\u5143\uff0c\u91c7\u7528srsRAN\u8f6f\u4ef6\u6808\uff0c\u652f\u6301TDD/FDD\u6a21\u5f0f\uff0c\u80fd\u4e0e\u5546\u75285G\u7ec8\u7aef\u4e92\u64cd\u4f5c\uff0c\u6027\u80fd\u4e0e\u5546\u7528O-RU\u76f8\u5f53\u3002", "motivation": "\u5f53\u524dO-RAN\u65e0\u7ebf\u5355\u5143\u591a\u4e3a\u4e13\u6709\u786c\u4ef6\uff0c\u7f3a\u4e4f\u5f00\u6e90\u53ef\u7f16\u7a0b\u65b9\u6848\uff0c\u9650\u5236\u4e86RU\u7ea7\u522b\u7684\u521b\u65b0\u548c\u7aef\u5230\u7aefO-RAN\u7814\u7a76\u7684\u95e8\u69db\u3002", "method": "\u57fa\u4e8e\u5f00\u6e90srsRAN\u8f6f\u4ef6\u6808\uff0c\u4f7f\u7528\u8f6f\u4ef6\u5b9a\u4e49\u65e0\u7ebf\u7535\u548c\u5546\u7528CPU\u6784\u5efa\u8f6f\u4ef6\u5b9a\u4e49\u7684O-RU\uff0c\u652f\u6301\u4e0esrsRAN\u548cOpenAirInterface5G CU/DU\u6808\u96c6\u6210\u3002", "result": "ProtO-RU\u5728\u591a\u7528\u6237\u6301\u7eed\u8d1f\u8f7d\u4e0b\u4fdd\u6301\u7a33\u5b9a\uff0c\u541e\u5410\u91cf\u4e0eSplit-8\u548c\u5546\u7528O-RU\u76f8\u5f53\uff0c\u652f\u6301TDD/FDD\u6a21\u5f0f\uff0c\u80fd\u4e0e\u5546\u75285G\u7ec8\u7aef\u4e92\u64cd\u4f5c\u3002", "conclusion": "ProtO-RU\u4e3aRU\u7ea7\u522b\u521b\u65b0\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\uff0c\u964d\u4f4e\u4e86\u7aef\u5230\u7aefO-RAN\u7814\u7a76\u7684\u95e8\u69db\uff0c\u662f\u9996\u4e2a\u5f00\u6e90\u8f6f\u4ef6\u5b9a\u4e49\u7684O-RAN Split-7.2\u65e0\u7ebf\u5355\u5143\u3002"}}
{"id": "2512.02261", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02261", "abs": "https://arxiv.org/abs/2512.02261", "authors": ["Lewen Yan", "Jilin Mei", "Tianyi Zhou", "Lige Huang", "Jie Zhang", "Dongrui Liu", "Jing Shao"], "title": "TradeTrap: Are LLM-based Trading Agents Truly Reliable and Faithful?", "comment": null, "summary": "LLM-based trading agents are increasingly deployed in real-world financial markets to perform autonomous analysis and execution. However, their reliability and robustness under adversarial or faulty conditions remain largely unexamined, despite operating in high-risk, irreversible financial environments. We propose TradeTrap, a unified evaluation framework for systematically stress-testing both adaptive and procedural autonomous trading agents. TradeTrap targets four core components of autonomous trading agents: market intelligence, strategy formulation, portfolio and ledger handling, and trade execution, and evaluates their robustness under controlled system-level perturbations. All evaluations are conducted in a closed-loop historical backtesting setting on real US equity market data with identical initial conditions, enabling fair and reproducible comparisons across agents and attacks. Extensive experiments show that small perturbations at a single component can propagate through the agent decision loop and induce extreme concentration, runaway exposure, and large portfolio drawdowns across both agent types, demonstrating that current autonomous trading agents can be systematically misled at the system level. Our code is available at https://github.com/Yanlewen/TradeTrap.", "AI": {"tldr": "TradeTrap\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u6027\u5730\u538b\u529b\u6d4b\u8bd5\u81ea\u9002\u5e94\u548c\u7a0b\u5e8f\u5316\u81ea\u4e3b\u4ea4\u6613\u4ee3\u7406\uff0c\u901a\u8fc7\u9488\u5bf9\u5e02\u573a\u60c5\u62a5\u3001\u7b56\u7565\u5236\u5b9a\u3001\u6295\u8d44\u7ec4\u5408\u4e0e\u8d26\u672c\u5904\u7406\u3001\u4ea4\u6613\u6267\u884c\u56db\u4e2a\u6838\u5fc3\u7ec4\u4ef6\u65bd\u52a0\u53d7\u63a7\u6270\u52a8\uff0c\u63ed\u793a\u5f53\u524d\u81ea\u4e3b\u4ea4\u6613\u4ee3\u7406\u5728\u7cfb\u7edf\u5c42\u9762\u6613\u88ab\u8bef\u5bfc\u7684\u8106\u5f31\u6027\u3002", "motivation": "LLM\u9a71\u52a8\u7684\u4ea4\u6613\u4ee3\u7406\u5728\u771f\u5b9e\u91d1\u878d\u5e02\u573a\u4e2d\u90e8\u7f72\u8d8a\u6765\u8d8a\u591a\uff0c\u4f46\u5176\u5728\u5bf9\u6297\u6027\u6216\u6545\u969c\u6761\u4ef6\u4e0b\u7684\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u68c0\u9a8c\uff0c\u800c\u91d1\u878d\u73af\u5883\u5177\u6709\u9ad8\u98ce\u9669\u548c\u4e0d\u53ef\u9006\u7684\u7279\u70b9\uff0c\u8fd9\u79cd\u5b89\u5168\u6f0f\u6d1e\u53ef\u80fd\u5e26\u6765\u4e25\u91cd\u540e\u679c\u3002", "method": "\u63d0\u51faTradeTrap\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\uff0c\u9488\u5bf9\u81ea\u4e3b\u4ea4\u6613\u4ee3\u7406\u7684\u56db\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff08\u5e02\u573a\u60c5\u62a5\u3001\u7b56\u7565\u5236\u5b9a\u3001\u6295\u8d44\u7ec4\u5408\u4e0e\u8d26\u672c\u5904\u7406\u3001\u4ea4\u6613\u6267\u884c\uff09\u65bd\u52a0\u7cfb\u7edf\u7ea7\u6270\u52a8\uff0c\u5728\u771f\u5b9e\u7f8e\u56fd\u80a1\u7968\u5e02\u573a\u6570\u636e\u7684\u95ed\u73af\u5386\u53f2\u56de\u6d4b\u73af\u5883\u4e2d\u8fdb\u884c\u516c\u5e73\u53ef\u91cd\u590d\u7684\u6bd4\u8f83\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5355\u4e2a\u7ec4\u4ef6\u7684\u5c0f\u5e45\u6270\u52a8\u4f1a\u901a\u8fc7\u4ee3\u7406\u51b3\u7b56\u5faa\u73af\u4f20\u64ad\uff0c\u5bfc\u81f4\u6781\u7aef\u96c6\u4e2d\u3001\u5931\u63a7\u655e\u53e3\u548c\u5927\u5e45\u6295\u8d44\u7ec4\u5408\u56de\u64a4\uff0c\u8bc1\u660e\u5f53\u524d\u81ea\u4e3b\u4ea4\u6613\u4ee3\u7406\u5728\u7cfb\u7edf\u5c42\u9762\u53ef\u88ab\u7cfb\u7edf\u6027\u8bef\u5bfc\u3002", "conclusion": "\u5f53\u524d\u81ea\u4e3b\u4ea4\u6613\u4ee3\u7406\u5b58\u5728\u7cfb\u7edf\u6027\u8106\u5f31\u6027\uff0c\u9700\u8981\u66f4\u4e25\u683c\u7684\u9c81\u68d2\u6027\u8bc4\u4f30\u548c\u5b89\u5168\u4fdd\u969c\u63aa\u65bd\uff0cTradeTrap\u6846\u67b6\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u4ea4\u6613\u4ee3\u7406\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2512.02468", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02468", "abs": "https://arxiv.org/abs/2512.02468", "authors": ["Ioannis Krikidis", "Valentin Gilbert"], "title": "Quantum Optimization in Wireless Communication Systems: Principles and Applications", "comment": "IEEE Communications Magazine, 2026", "summary": "Quantum optimization is poised to play a transformative role in the design of next-generation wireless communication systems by addressing key computational and technological challenges. This paper provides an overview of the principles of adiabatic quantum computing, the foundation of quantum optimization, and explores its two primary computational models: quantum annealing and the gate-based quantum approximate optimization algorithm. By highlighting their core features, performance benefits, limitations, and distinctions, we position these methods as promising tools for advancing wireless communication system design. As a case study, we examine the design of passive reconfigurable intelligent surface beamforming with binary phase-shift resolution, supported by experimental results obtained from real-world quantum hardware.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u91cf\u5b50\u4f18\u5316\u5728\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u7edd\u70ed\u91cf\u5b50\u8ba1\u7b97\u539f\u7406\u53ca\u5176\u4e24\u79cd\u4e3b\u8981\u8ba1\u7b97\u6a21\u578b\uff08\u91cf\u5b50\u9000\u706b\u548c\u95e8\u57fa\u91cf\u5b50\u8fd1\u4f3c\u4f18\u5316\u7b97\u6cd5\uff09\uff0c\u5e76\u901a\u8fc7\u65e0\u6e90\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u6848\u4f8b\u5c55\u793a\u4e86\u5b9e\u9645\u91cf\u5b50\u786c\u4ef6\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002", "motivation": "\u91cf\u5b50\u4f18\u5316\u6709\u671b\u89e3\u51b3\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u5173\u952e\u8ba1\u7b97\u548c\u6280\u672f\u6311\u6218\uff0c\u901a\u8fc7\u5229\u7528\u91cf\u5b50\u8ba1\u7b97\u7684\u4f18\u52bf\u6765\u63a8\u52a8\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u7684\u8fdb\u6b65\u3002", "method": "\u57fa\u4e8e\u7edd\u70ed\u91cf\u5b50\u8ba1\u7b97\u539f\u7406\uff0c\u63a2\u8ba8\u4e86\u4e24\u79cd\u4e3b\u8981\u8ba1\u7b97\u6a21\u578b\uff1a\u91cf\u5b50\u9000\u706b\u548c\u95e8\u57fa\u91cf\u5b50\u8fd1\u4f3c\u4f18\u5316\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u65e0\u6e90\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u4f7f\u7528\u771f\u5b9e\u91cf\u5b50\u786c\u4ef6\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u8bba\u6587\u5c55\u793a\u4e86\u91cf\u5b50\u4f18\u5316\u65b9\u6cd5\u5728\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0c\u901a\u8fc7\u771f\u5b9e\u91cf\u5b50\u786c\u4ef6\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65e0\u6e90\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u91cf\u5b50\u9000\u706b\u548c\u91cf\u5b50\u8fd1\u4f3c\u4f18\u5316\u7b97\u6cd5\u662f\u63a8\u52a8\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u7684\u6709\u524d\u666f\u7684\u5de5\u5177\uff0c\u91cf\u5b50\u4f18\u5316\u5c06\u5728\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u53d1\u6325\u53d8\u9769\u6027\u4f5c\u7528\u3002"}}
{"id": "2512.02454", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02454", "abs": "https://arxiv.org/abs/2512.02454", "authors": ["Gianluca Cena", "Pietro Chiavassa", "Gabriele Formis", "Stefano Scanzio"], "title": "Widening the Coverage of Reference Broadcast Infrastructure Synchronization in Wi-Fi Networks", "comment": "preprint accepted, 8 pages, 2025", "summary": "Precise clock synchronization protocols are increasingly used to ensure that all the nodes in a network share the very same time base. They enable several mechanisms aimed at improving determinism at both the application and communication levels, which makes them highly relevant to industrial environments. Reference Broadcast Infrastructure Synchronization (RBIS) is a solution specifically conceived for Wi-Fi that exploits existing beacons and can run on commercial devices. In this paper, an evolution of RBIS is presented, we call DOMINO, whose coverage area is much larger than the single Wi-Fi infrastructure network, potentially including the whole plant. In particular, wireless stations that can see more than one access point at the same time behave as boundary clocks and propagate the reference time across overlapping networks.", "AI": {"tldr": "DOMINO\u662fRBIS\u534f\u8bae\u7684\u6f14\u8fdb\u7248\u672c\uff0c\u901a\u8fc7\u8fb9\u754c\u65f6\u949f\u673a\u5236\u5c06Wi-Fi\u65f6\u95f4\u540c\u6b65\u6269\u5c55\u5230\u6574\u4e2a\u5de5\u5382\u8303\u56f4\uff0c\u800c\u4e0d\u4ec5\u9650\u4e8e\u5355\u4e2a\u7f51\u7edc\u57fa\u7840\u8bbe\u65bd\u3002", "motivation": "\u7cbe\u786e\u65f6\u949f\u540c\u6b65\u534f\u8bae\u5bf9\u5de5\u4e1a\u73af\u5883\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709RBIS\u65b9\u6848\u4ec5\u9002\u7528\u4e8e\u5355\u4e2aWi-Fi\u7f51\u7edc\uff0c\u65e0\u6cd5\u8986\u76d6\u6574\u4e2a\u5de5\u5382\u8303\u56f4\u3002\u9700\u8981\u6269\u5c55\u540c\u6b65\u8303\u56f4\u4ee5\u652f\u6301\u5927\u89c4\u6a21\u5de5\u4e1a\u5e94\u7528\u3002", "method": "\u63d0\u51faDOMINO\u534f\u8bae\uff0c\u5229\u7528\u80fd\u591f\u540c\u65f6\u770b\u5230\u591a\u4e2a\u63a5\u5165\u70b9\u7684\u65e0\u7ebf\u7ad9\u70b9\u4f5c\u4e3a\u8fb9\u754c\u65f6\u949f\uff0c\u5728\u91cd\u53e0\u7f51\u7edc\u95f4\u4f20\u64ad\u53c2\u8003\u65f6\u95f4\uff0c\u4ece\u800c\u6269\u5c55\u540c\u6b65\u8986\u76d6\u8303\u56f4\u3002", "result": "DOMINO\u7684\u8986\u76d6\u533a\u57df\u8fdc\u5927\u4e8e\u5355\u4e2aWi-Fi\u57fa\u7840\u8bbe\u65bd\u7f51\u7edc\uff0c\u53ef\u6f5c\u5728\u8986\u76d6\u6574\u4e2a\u5de5\u5382\u8303\u56f4\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u65f6\u95f4\u540c\u6b65\u3002", "conclusion": "DOMINO\u4f5c\u4e3aRBIS\u7684\u6f14\u8fdb\u7248\u672c\uff0c\u901a\u8fc7\u8fb9\u754c\u65f6\u949f\u673a\u5236\u6210\u529f\u6269\u5c55\u4e86Wi-Fi\u65f6\u95f4\u540c\u6b65\u7684\u8303\u56f4\uff0c\u4e3a\u5de5\u4e1a\u73af\u5883\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u65f6\u95f4\u540c\u6b65\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02280", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.02280", "abs": "https://arxiv.org/abs/2512.02280", "authors": ["Noorbakhsh Amiri Golilarz", "Sindhuja Penchala", "Shahram Rahimi"], "title": "Bridging the Gap: Toward Cognitive Autonomy in Artificial Intelligence", "comment": null, "summary": "Artificial intelligence has advanced rapidly across perception, language, reasoning, and multimodal domains. Yet despite these achievements, modern AI systems remain fundamentally limited in their ability to self-monitor, self-correct, and regulate their behavior autonomously in dynamic contexts. This paper identifies and analyzes seven core deficiencies that constrain contemporary AI models: the absence of intrinsic self-monitoring, lack of meta-cognitive awareness, fixed and non-adaptive learning mechanisms, inability to restructure goals, lack of representational maintenance, insufficient embodied feedback, and the absence of intrinsic agency. Alongside identifying these limitations, we also outline a forward-looking perspective on how AI may evolve beyond them through architectures that mirror neurocognitive principles. We argue that these structural limitations prevent current architectures, including deep learning and transformer-based systems, from achieving robust generalization, lifelong adaptability, and real-world autonomy. Drawing on a comparative analysis of artificial systems and biological cognition [7], and integrating insights from AI research, cognitive science, and neuroscience, we outline how these capabilities are absent in current models and why scaling alone cannot resolve them. We conclude by advocating for a paradigmatic shift toward cognitively grounded AI (cognitive autonomy) capable of self-directed adaptation, dynamic representation management, and intentional, goal-oriented behavior, paired with reformative oversight mechanisms [8] that ensure autonomous systems remain interpretable, governable, and aligned with human values.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u5f53\u524dAI\u7cfb\u7edf\u7684\u4e03\u5927\u6838\u5fc3\u7f3a\u9677\uff0c\u4e3b\u5f20\u5411\u57fa\u4e8e\u8ba4\u77e5\u539f\u7406\u7684AI\u8303\u5f0f\u8f6c\u53d8\uff0c\u4ee5\u5b9e\u73b0\u771f\u6b63\u7684\u81ea\u4e3b\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u611f\u77e5\u3001\u8bed\u8a00\u3001\u63a8\u7406\u548c\u591a\u6a21\u6001\u9886\u57df\u53d6\u5f97\u4e86\u5feb\u901f\u8fdb\u5c55\uff0c\u4f46\u73b0\u4ee3AI\u7cfb\u7edf\u5728\u81ea\u6211\u76d1\u63a7\u3001\u81ea\u6211\u7ea0\u6b63\u548c\u81ea\u4e3b\u884c\u4e3a\u8c03\u8282\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\u3002\u8fd9\u4e9b\u9650\u5236\u963b\u788d\u4e86AI\u5b9e\u73b0\u7a33\u5065\u7684\u6cdb\u5316\u3001\u7ec8\u8eab\u9002\u5e94\u6027\u548c\u73b0\u5b9e\u4e16\u754c\u81ea\u4e3b\u6027\u3002", "method": "\u901a\u8fc7\u8bc6\u522b\u548c\u5206\u6790\u5f53\u4ee3AI\u6a21\u578b\u7684\u4e03\u5927\u6838\u5fc3\u7f3a\u9677\uff1a\u7f3a\u4e4f\u5185\u5728\u81ea\u6211\u76d1\u63a7\u3001\u5143\u8ba4\u77e5\u610f\u8bc6\u7f3a\u5931\u3001\u56fa\u5b9a\u975e\u9002\u5e94\u6027\u5b66\u4e60\u673a\u5236\u3001\u65e0\u6cd5\u91cd\u6784\u76ee\u6807\u3001\u7f3a\u4e4f\u8868\u5f81\u7ef4\u62a4\u3001\u4e0d\u8db3\u7684\u5177\u8eab\u53cd\u9988\u3001\u4ee5\u53ca\u5185\u5728\u80fd\u52a8\u6027\u7f3a\u5931\u3002\u7ed3\u5408\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u3001\u8ba4\u77e5\u79d1\u5b66\u548c\u795e\u7ecf\u79d1\u5b66\u7684\u89c1\u89e3\uff0c\u8fdb\u884c\u4eba\u5de5\u7cfb\u7edf\u4e0e\u751f\u7269\u8ba4\u77e5\u7684\u6bd4\u8f83\u5206\u6790\u3002", "result": "\u8bba\u6587\u6307\u51fa\u5f53\u524d\u67b6\u6784\uff08\u5305\u62ec\u6df1\u5ea6\u5b66\u4e60\u548c\u57fa\u4e8eTransformer\u7684\u7cfb\u7edf\uff09\u5b58\u5728\u7ed3\u6784\u6027\u9650\u5236\uff0c\u4ec5\u9760\u6269\u5c55\u89c4\u6a21\u65e0\u6cd5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002\u8fd9\u4e9b\u9650\u5236\u963b\u788d\u4e86AI\u5b9e\u73b0\u771f\u6b63\u7684\u81ea\u4e3b\u6027\u3001\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u4e3b\u5f20\u5411\u57fa\u4e8e\u8ba4\u77e5\u539f\u7406\u7684AI\u8303\u5f0f\u8f6c\u53d8\uff0c\u53d1\u5c55\u5177\u6709\u8ba4\u77e5\u81ea\u4e3b\u6027\u7684\u7cfb\u7edf\uff0c\u80fd\u591f\u8fdb\u884c\u81ea\u6211\u5bfc\u5411\u7684\u9002\u5e94\u3001\u52a8\u6001\u8868\u5f81\u7ba1\u7406\u548c\u6709\u610f\u56fe\u7684\u76ee\u6807\u5bfc\u5411\u884c\u4e3a\uff0c\u540c\u65f6\u914d\u5907\u6539\u9769\u6027\u76d1\u7763\u673a\u5236\u4ee5\u786e\u4fdd\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u6cbb\u7406\u6027\u548c\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u4e00\u81f4\u6027\u3002"}}
{"id": "2512.02582", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02582", "abs": "https://arxiv.org/abs/2512.02582", "authors": ["Bach Hung Luu", "Sinh Cong Lam", "Nam Hoang Nguyen"], "title": "Deep Q-Learning-Driven Power Control for Enhanced Noma User Performance", "comment": "16 pages, 5 figures", "summary": "Cell-edge users (CEUs) in cellular networks typically suffer from poor channel conditions due to long distances from serving base stations and physical obstructions, resulting in much lower data rates compared to cell-center users (CCUs). This paper proposes an Unmanned Aerial Vehicles (UAV)-assisted cellular network with intelligent power control to address the performance gap between CEUs and CCUs. Unlike conventional approaches that either deploy UAVs for all users or use no UAV assistance, our model uses a distance-based criterion where only users beyond a reference distance receive UAV relay assistance. Each UAV operates as an amplify-and-forward relay, enabling assisted users to receive signals from both the base station and the UAV simultaneously, thereby achieving diversity gain. To optimize transmission power allocation across base stations, we employ a Deep Q-Network (DQN) learning framework that learns power control policies without requiring accurate channel models. Simulation results show that the proposed approach achieves a peak average rate of 2.28 bps/Hz at the optimal reference distance of 400m, which represents a 3.6% improvement compared to networks without UAV assistance and 0.9% improvement compared to networks where all users receive UAV support. The results also reveal that UAV altitude and reference distance are critical factors affecting system performance, with lower altitudes providing better performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e0\u4eba\u673a\u8f85\u52a9\u7684\u8702\u7a9d\u7f51\u7edc\u667a\u80fd\u529f\u7387\u63a7\u5236\u65b9\u6848\uff0c\u901a\u8fc7\u8ddd\u79bb\u5224\u636e\u9009\u62e9\u8fb9\u7f18\u7528\u6237\u8fdb\u884c\u65e0\u4eba\u673a\u4e2d\u7ee7\uff0c\u4f7f\u7528DQN\u4f18\u5316\u529f\u7387\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8fb9\u7f18\u7528\u6237\u6027\u80fd\u3002", "motivation": "\u8702\u7a9d\u7f51\u7edc\u4e2d\u8fb9\u7f18\u7528\u6237\u7531\u4e8e\u8ddd\u79bb\u57fa\u7ad9\u8fdc\u3001\u5b58\u5728\u7269\u7406\u906e\u6321\uff0c\u4fe1\u9053\u6761\u4ef6\u5dee\uff0c\u6570\u636e\u901f\u7387\u8fdc\u4f4e\u4e8e\u4e2d\u5fc3\u7528\u6237\uff0c\u5b58\u5728\u6027\u80fd\u5dee\u8ddd\u95ee\u9898\u9700\u8981\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u65e0\u4eba\u673a\u8f85\u52a9\u8702\u7a9d\u7f51\u7edc\u67b6\u6784\uff0c\u91c7\u7528\u8ddd\u79bb\u5224\u636e\uff08\u4ec5\u8ddd\u79bb\u8d85\u8fc7\u53c2\u8003\u503c\u7684\u7528\u6237\u83b7\u5f97\u65e0\u4eba\u673a\u4e2d\u7ee7\uff09\uff0c\u65e0\u4eba\u673a\u4f5c\u4e3a\u653e\u5927\u8f6c\u53d1\u4e2d\u7ee7\uff0c\u7528\u6237\u540c\u65f6\u63a5\u6536\u57fa\u7ad9\u548c\u65e0\u4eba\u673a\u4fe1\u53f7\u83b7\u5f97\u5206\u96c6\u589e\u76ca\uff0c\u4f7f\u7528\u6df1\u5ea6Q\u7f51\u7edc\u5b66\u4e60\u529f\u7387\u63a7\u5236\u7b56\u7565\u3002", "result": "\u5728\u6700\u4f18\u53c2\u8003\u8ddd\u79bb400m\u65f6\u8fbe\u5230\u5cf0\u503c\u5e73\u5747\u901f\u73872.28bps/Hz\uff0c\u76f8\u6bd4\u65e0\u65e0\u4eba\u673a\u8f85\u52a9\u7f51\u7edc\u63d0\u53473.6%\uff0c\u76f8\u6bd4\u6240\u6709\u7528\u6237\u90fd\u83b7\u5f97\u65e0\u4eba\u673a\u652f\u6301\u7684\u7f51\u7edc\u63d0\u53470.9%\u3002\u65e0\u4eba\u673a\u9ad8\u5ea6\u548c\u53c2\u8003\u8ddd\u79bb\u662f\u5173\u952e\u5f71\u54cd\u56e0\u7d20\uff0c\u8f83\u4f4e\u9ad8\u5ea6\u6027\u80fd\u66f4\u597d\u3002", "conclusion": "\u57fa\u4e8e\u8ddd\u79bb\u5224\u636e\u7684\u65e0\u4eba\u673a\u8f85\u52a9\u7f51\u7edc\u7ed3\u5408DQN\u529f\u7387\u63a7\u5236\u80fd\u6709\u6548\u7f29\u5c0f\u8fb9\u7f18\u7528\u6237\u4e0e\u4e2d\u5fc3\u7528\u6237\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u667a\u80fd\u529f\u7387\u5206\u914d\u7b56\u7565\u65e0\u9700\u7cbe\u786e\u4fe1\u9053\u6a21\u578b\uff0c\u65e0\u4eba\u673a\u9ad8\u5ea6\u548c\u53c2\u8003\u8ddd\u79bb\u4f18\u5316\u5bf9\u7cfb\u7edf\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2512.02455", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02455", "abs": "https://arxiv.org/abs/2512.02455", "authors": ["Pietro Chiavassa", "Stefano Scanzio", "Gianluca Cena"], "title": "Wi-Fi Rate Adaptation for Moving Equipment in Industrial Environments", "comment": "preprint accepted, 4 pages, 2025", "summary": "Wi-Fi is currently considered one of the most promising solutions for interconnecting mobile equipment (e.g., autonomous mobile robots and active exoskeletons) in industrial environments. However, relability requirements imposed by the industrial context, such as ensuring bounded transmission latency, are a major challenge for over-the-air communication. One of the aspects of Wi-Fi technology that greatly affects the probability of a packet reaching its destination is the selection of the appropriate transmission rate. Rate adaptation algorithms are in charge of this operation, but their design and implementation are not regulated by the IEEE 802.11 standard. One of the most popular solutions, available as open source, is Minstrel, which is the default choice for the Linux Kernel. In this paper, Minstrel performance is evaluated for both static and mobility scenarios. Our analysis focuses on metrics of interest for industrial contexts, i.e., latency and packet loss ratio, and serves as a preliminary evaluation for the future development of enhanced rate adaptation algorithms based on centralized digital twins.", "AI": {"tldr": "\u8bc4\u4f30Wi-Fi\u901f\u7387\u81ea\u9002\u5e94\u7b97\u6cd5Minstrel\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u6027\u80fd\uff0c\u91cd\u70b9\u5173\u6ce8\u9759\u6001\u548c\u79fb\u52a8\u573a\u666f\u4e0b\u7684\u5ef6\u8fdf\u548c\u4e22\u5305\u7387\uff0c\u4e3a\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684\u589e\u5f3a\u7b97\u6cd5\u5f00\u53d1\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "Wi-Fi\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7528\u4e8e\u8fde\u63a5\u79fb\u52a8\u8bbe\u5907\uff08\u5982\u81ea\u4e3b\u79fb\u52a8\u673a\u5668\u4eba\u548c\u4e3b\u52a8\u5916\u9aa8\u9abc\uff09\u5177\u6709\u524d\u666f\uff0c\u4f46\u5de5\u4e1a\u73af\u5883\u5bf9\u53ef\u9760\u6027\u548c\u6709\u754c\u4f20\u8f93\u5ef6\u8fdf\u7684\u8981\u6c42\u5f88\u9ad8\u3002\u901f\u7387\u81ea\u9002\u5e94\u7b97\u6cd5\u5bf9\u6570\u636e\u5305\u4f20\u8f93\u6210\u529f\u7387\u5f71\u54cd\u5f88\u5927\uff0c\u800cMinstrel\u4f5c\u4e3aLinux\u5185\u6838\u9ed8\u8ba4\u7b97\u6cd5\uff0c\u5176\u6027\u80fd\u5728\u5de5\u4e1a\u573a\u666f\u4e0b\u9700\u8981\u8bc4\u4f30\u3002", "method": "\u5bf9Minstrel\u901f\u7387\u81ea\u9002\u5e94\u7b97\u6cd5\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\uff0c\u5305\u62ec\u9759\u6001\u573a\u666f\u548c\u79fb\u52a8\u573a\u666f\u3002\u5206\u6790\u91cd\u70b9\u653e\u5728\u5de5\u4e1a\u73af\u5883\u5173\u5fc3\u7684\u6307\u6807\u4e0a\uff1a\u5ef6\u8fdf\u548c\u4e22\u5305\u7387\u3002\u7814\u7a76\u4e3a\u672a\u6765\u57fa\u4e8e\u96c6\u4e2d\u5f0f\u6570\u5b57\u5b6a\u751f\u7684\u589e\u5f3a\u901f\u7387\u81ea\u9002\u5e94\u7b97\u6cd5\u5f00\u53d1\u63d0\u4f9b\u521d\u6b65\u8bc4\u4f30\u3002", "result": "\u8bba\u6587\u63d0\u4f9b\u4e86Minstrel\u7b97\u6cd5\u5728\u9759\u6001\u548c\u79fb\u52a8\u573a\u666f\u4e0b\u7684\u6027\u80fd\u8bc4\u4f30\u7ed3\u679c\uff0c\u91cd\u70b9\u5173\u6ce8\u5ef6\u8fdf\u548c\u4e22\u5305\u7387\u6307\u6807\u3002\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u540e\u7eed\u5f00\u53d1\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684\u589e\u5f3a\u901f\u7387\u81ea\u9002\u5e94\u7b97\u6cd5\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "Minstrel\u901f\u7387\u81ea\u9002\u5e94\u7b97\u6cd5\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u6027\u80fd\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\uff0c\u7279\u522b\u662f\u9488\u5bf9\u6709\u754c\u5ef6\u8fdf\u8981\u6c42\u3002\u57fa\u4e8e\u96c6\u4e2d\u5f0f\u6570\u5b57\u5b6a\u751f\u7684\u589e\u5f3a\u7b97\u6cd5\u662f\u672a\u6765\u7684\u53d1\u5c55\u65b9\u5411\uff0c\u672c\u6587\u7684\u8bc4\u4f30\u4e3a\u6b64\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u6027\u80fd\u57fa\u51c6\u3002"}}
{"id": "2512.02282", "categories": ["cs.AI", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.02282", "abs": "https://arxiv.org/abs/2512.02282", "authors": ["Han Luo", "Guy Laban"], "title": "DialogGuard: Multi-Agent Psychosocial Safety Evaluation of Sensitive LLM Responses", "comment": null, "summary": "Large language models (LLMs) now mediate many web-based mental-health, crisis, and other emotionally sensitive services, yet their psychosocial safety in these settings remains poorly understood and weakly evaluated. We present DialogGuard, a multi-agent framework for assessing psychosocial risks in LLM-generated responses along five high-severity dimensions: privacy violations, discriminatory behaviour, mental manipulation, psychological harm, and insulting behaviour. DialogGuard can be applied to diverse generative models through four LLM-as-a-judge pipelines, including single-agent scoring, dual-agent correction, multi-agent debate, and stochastic majority voting, grounded in a shared three-level rubric usable by both human annotators and LLM judges. Using PKU-SafeRLHF with human safety annotations, we show that multi-agent mechanisms detect psychosocial risks more accurately than non-LLM baselines and single-agent judging; dual-agent correction and majority voting provide the best trade-off between accuracy, alignment with human ratings, and robustness, while debate attains higher recall but over-flags borderline cases. We release Dialog-Guard as open-source software with a web interface that provides per-dimension risk scores and explainable natural-language rationales. A formative study with 12 practitioners illustrates how it supports prompt design, auditing, and supervision of web-facing applications for vulnerable users.", "AI": {"tldr": "DialogGuard\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u5fc3\u7406\u5065\u5eb7\u7b49\u654f\u611f\u573a\u666f\u4e2d\u7684\u5fc3\u7406\u793e\u4f1a\u98ce\u9669\uff0c\u5305\u542b\u4e94\u79cd\u9ad8\u98ce\u9669\u7ef4\u5ea6\u548c\u56db\u79cd\u8bc4\u4f30\u6d41\u7a0b\uff0c\u6bd4\u5355\u667a\u80fd\u4f53\u8bc4\u4f30\u66f4\u51c6\u786e\u3002", "motivation": "\u5f53\u524dLLM\u5df2\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5fc3\u7406\u5065\u5eb7\u3001\u5371\u673a\u5e72\u9884\u7b49\u60c5\u611f\u654f\u611f\u670d\u52a1\uff0c\u4f46\u5176\u5728\u8fd9\u4e9b\u573a\u666f\u4e2d\u7684\u5fc3\u7406\u793e\u4f1a\u5b89\u5168\u6027\u4ecd\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\u548c\u6709\u6548\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faDialogGuard\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u8bc4\u4f30\u9690\u79c1\u4fb5\u72af\u3001\u6b67\u89c6\u884c\u4e3a\u3001\u5fc3\u7406\u64cd\u7eb5\u3001\u5fc3\u7406\u4f24\u5bb3\u548c\u4fae\u8fb1\u884c\u4e3a\u4e94\u4e2a\u9ad8\u98ce\u9669\u7ef4\u5ea6\uff1b\u91c7\u7528\u56db\u79cdLLM-as-a-judge\u6d41\u7a0b\uff1a\u5355\u667a\u80fd\u4f53\u8bc4\u5206\u3001\u53cc\u667a\u80fd\u4f53\u4fee\u6b63\u3001\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u548c\u968f\u673a\u591a\u6570\u6295\u7968\uff0c\u57fa\u4e8e\u5171\u4eab\u7684\u4e09\u7ea7\u8bc4\u5206\u6807\u51c6\u3002", "result": "\u4f7f\u7528PKU-SafeRLHF\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u591a\u667a\u80fd\u4f53\u673a\u5236\u6bd4\u975eLLM\u57fa\u7ebf\u548c\u5355\u667a\u80fd\u4f53\u8bc4\u4f30\u66f4\u51c6\u786e\u5730\u68c0\u6d4b\u5fc3\u7406\u793e\u4f1a\u98ce\u9669\uff1b\u53cc\u667a\u80fd\u4f53\u4fee\u6b63\u548c\u591a\u6570\u6295\u7968\u5728\u51c6\u786e\u6027\u3001\u4e0e\u4eba\u5de5\u8bc4\u5206\u5bf9\u9f50\u5ea6\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8fbe\u5230\u6700\u4f73\u5e73\u8861\uff1b\u8fa9\u8bba\u673a\u5236\u53ec\u56de\u7387\u66f4\u9ad8\u4f46\u5bb9\u6613\u8fc7\u5ea6\u6807\u8bb0\u8fb9\u754c\u6848\u4f8b\u3002", "conclusion": "DialogGuard\u4f5c\u4e3a\u5f00\u6e90\u8f6f\u4ef6\u53d1\u5e03\uff0c\u63d0\u4f9b\u7f51\u9875\u754c\u9762\u663e\u793a\u5404\u7ef4\u5ea6\u98ce\u9669\u5206\u6570\u548c\u53ef\u89e3\u91ca\u7684\u81ea\u7136\u8bed\u8a00\u7406\u7531\uff1b\u5bf912\u540d\u4ece\u4e1a\u8005\u7684\u5f62\u6210\u6027\u7814\u7a76\u8868\u660e\uff0c\u8be5\u6846\u67b6\u652f\u6301\u9762\u5411\u8106\u5f31\u7528\u6237\u7684\u7f51\u7edc\u5e94\u7528\u8fdb\u884c\u63d0\u793a\u8bbe\u8ba1\u3001\u5ba1\u8ba1\u548c\u76d1\u7763\u3002"}}
{"id": "2512.02747", "categories": ["cs.IT", "math.CO", "math.NT"], "pdf": "https://arxiv.org/pdf/2512.02747", "abs": "https://arxiv.org/abs/2512.02747", "authors": ["Jiaxu Hu", "Kenneth J. Roche"], "title": "Digit-Indexed q-ary SEC-DED Codes with Near-Hamming Overhead", "comment": "13 pages, 1 figure, 3 tables. Interactive demo: https://sltracer.github.io/ECC_Paper_Website_Demo/index_SEC_TED_en.html", "summary": "We present a simple $q$-ary family of single-error-correcting, double-error-detecting (SEC--DED) linear codes whose parity checks are tied directly to the base-$p$ ($q=p$ prime) digits of the coordinate index. For blocklength $n=p^r$ the construction uses only $r+1$ parity checks -- \\emph{near-Hamming} overhead -- and admits an index-based decoder that runs in a single pass with constant-time location and magnitude recovery from the syndromes. Based on the prototype, we develop two extensions: Code A1, which removes specific redundant trits to achieve higher information rate and support variable-length encoding; and Code A2, which incorporates two group-sum checks together with a 3-wise XOR linear independence condition on index subsets, yielding a ternary distance-4 (SEC--TED) variant. Furthermore, we demonstrate how the framework generalizes via $n$-wise XOR linearly independent sets to construct codes with distance $d = n + 1$, notably recovering the ternary Golay code for $n = 5$ -- showing both structural generality and a serendipitous link to optimal classical codes.\n  Our contribution is not optimality but \\emph{implementational simplicity} and an \\emph{array-friendly} structure: the checks are digitwise and global sums, the mapping from syndromes to error location is explicit, and the SEC--TED upgrade is modular. We position the scheme against classical $q$-ary Hamming and SPC/product-code baselines and provide a small comparison of parity overhead, decoding work, and two-error behavior.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7b80\u5355\u7684q\u8fdb\u5236\u5355\u7ea0\u53cc\u68c0(SEC-DED)\u7ebf\u6027\u7801\u65cf\uff0c\u5176\u6821\u9a8c\u4f4d\u4e0e\u5750\u6807\u7d22\u5f15\u7684p\u8fdb\u5236\u6570\u5b57\u76f4\u63a5\u76f8\u5173\uff0c\u5177\u6709\u8fd1\u6c49\u660e\u7801\u5f00\u9500\u548c\u5e38\u6570\u65f6\u95f4\u89e3\u7801\uff0c\u5e76\u6269\u5c55\u5230\u66f4\u9ad8\u8ddd\u79bb\u7801", "motivation": "\u4f20\u7edf\u7ea0\u9519\u7801\u5b9e\u73b0\u590d\u6742\uff0c\u9700\u8981\u5f00\u53d1\u7ed3\u6784\u7b80\u5355\u3001\u6613\u4e8e\u5b9e\u73b0\u3001\u9635\u5217\u53cb\u597d\u7684\u7f16\u7801\u65b9\u6848\uff0c\u7279\u522b\u662f\u5177\u6709\u660e\u786e\u9519\u8bef\u5b9a\u4f4d\u6620\u5c04\u548c\u6a21\u5757\u5316\u5347\u7ea7\u80fd\u529b\u7684\u7801", "method": "\u57fa\u4e8e\u5750\u6807\u7d22\u5f15\u7684p\u8fdb\u5236\u6570\u5b57\u6784\u5efa\u6821\u9a8c\u4f4d\uff0c\u5757\u957fn=p^r\u65f6\u4ec5\u9700r+1\u4e2a\u6821\u9a8c\u4f4d\u3002\u5f00\u53d1\u4e24\u79cd\u6269\u5c55\uff1aA1\u7801\u901a\u8fc7\u79fb\u9664\u7279\u5b9a\u5197\u4f59\u4e09\u8fdb\u5236\u4f4d\u63d0\u9ad8\u4fe1\u606f\u7387\uff1bA2\u7801\u7ed3\u5408\u4e24\u7ec4\u548c\u6821\u9a8c\u4e0e3-wise XOR\u7ebf\u6027\u72ec\u7acb\u6761\u4ef6\uff0c\u5b9e\u73b0\u8ddd\u79bb4\u7684\u4e09\u8fdb\u5236\u7801", "result": "\u6784\u5efa\u4e86\u5177\u6709\u8fd1\u6c49\u660e\u7801\u5f00\u9500\u7684\u7b80\u5355SEC-DED\u7801\uff0c\u652f\u6301\u5e38\u6570\u65f6\u95f4\u9519\u8bef\u5b9a\u4f4d\u548c\u5e45\u5ea6\u6062\u590d\u3002\u6269\u5c55\u7248\u672cA1\u63d0\u9ad8\u4fe1\u606f\u7387\uff0cA2\u5b9e\u73b0\u8ddd\u79bb4\u7684\u4e09\u8fdb\u5236SEC-TED\u7801\u3002\u6846\u67b6\u53ef\u63a8\u5e7f\u5230\u8ddd\u79bbd=n+1\u7684\u7801\uff0c\u751a\u81f3\u6062\u590d\u4e86\u4e09\u8fdb\u5236Golay\u7801", "conclusion": "\u8d21\u732e\u5728\u4e8e\u5b9e\u73b0\u7b80\u5355\u6027\u548c\u9635\u5217\u53cb\u597d\u7ed3\u6784\uff0c\u800c\u975e\u6700\u4f18\u6027\u3002\u6821\u9a8c\u4f4d\u662f\u6570\u5b57\u4f4d\u548c\u5168\u5c40\u548c\uff0c\u9519\u8bef\u5b9a\u4f4d\u6620\u5c04\u660e\u786e\uff0cSEC-TED\u5347\u7ea7\u6a21\u5757\u5316\u3002\u4e0e\u7ecf\u5178q\u8fdb\u5236\u6c49\u660e\u7801\u548cSPC/\u4e58\u79ef\u7801\u57fa\u51c6\u76f8\u6bd4\uff0c\u5728\u5947\u5076\u6821\u9a8c\u5f00\u9500\u3001\u89e3\u7801\u5de5\u4f5c\u548c\u53cc\u9519\u8bef\u884c\u4e3a\u65b9\u9762\u5177\u6709\u4f18\u52bf"}}
{"id": "2512.02649", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02649", "abs": "https://arxiv.org/abs/2512.02649", "authors": ["Sameera Bandaranayake", "Amirreza Moradi", "Tanja Suomalainen", "Harri Saarnisaari", "Pasi Karppinen", "Payal Gupta", "Jaap van de Beek"], "title": "Rural Connectivity Inequalities in Finland and Sweden: Evidence, Measures, and Policy Reflections", "comment": null, "summary": "Persistent rural-urban disparities in broadband connectivity remain a major policy challenge, even in digitally advanced countries. This paper examines how these inequalities manifest in northern Finland and Sweden, where sparse populations, long distances, and seasonal variations in demand create persistent gaps in service quality and reliability. Drawing on survey data (n = 148), in-depth interviews, and spatial analysis, the study explores the lived experience of connectivity in Arctic rural communities and introduces a novel Cellular Coverage Inequality (CCI) Index. The index combines measures of rurality and network performance to quantify spatial disparities that are masked by national coverage statistics. Results reveal that headline indicators overstate inclusiveness, while local users report chronic connectivity gaps affecting work, safety, and access to services. Building on these findings, the paper outlines policy reflections in six areas: shared infrastructure and roaming frameworks, spectrum flexibility for rural operators, performance-based Quality-of-Service monitoring, standardized and transparent reporting, temporal and seasonal capacity management, and digital-skills initiatives. Together, these recommendations highlight the need for multidimensional metrics and governance mechanisms that link technical performance, spatial equity, and user experience. The analysis contributes to ongoing debates on how broadband policy in sparsely populated regions can move beyond nominal coverage targets toward genuine inclusion and reliability.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u82ac\u5170\u548c\u745e\u5178\u5317\u90e8\u519c\u6751\u5730\u533a\u7684\u5bbd\u5e26\u8fde\u63a5\u4e0d\u5e73\u7b49\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u8702\u7a9d\u8986\u76d6\u4e0d\u5e73\u7b49\u6307\u6570\uff08CCI\uff09\uff0c\u63ed\u793a\u4e86\u56fd\u5bb6\u7edf\u8ba1\u6570\u636e\u63a9\u76d6\u7684\u7a7a\u95f4\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u4e86\u516d\u9879\u653f\u7b56\u5efa\u8bae\u3002", "motivation": "\u5373\u4f7f\u5728\u6570\u5b57\u5316\u5148\u8fdb\u56fd\u5bb6\uff0c\u57ce\u4e61\u5bbd\u5e26\u8fde\u63a5\u5dee\u8ddd\u4ecd\u7136\u662f\u91cd\u5927\u653f\u7b56\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u8fd9\u4e9b\u4e0d\u5e73\u7b49\u5728\u82ac\u5170\u548c\u745e\u5178\u5317\u90e8\u7684\u8868\u73b0\uff0c\u8fd9\u4e9b\u5730\u533a\u4eba\u53e3\u7a00\u758f\u3001\u8ddd\u79bb\u9065\u8fdc\u3001\u9700\u6c42\u5b63\u8282\u6027\u53d8\u5316\u5bfc\u81f4\u670d\u52a1\u8d28\u91cf\u5dee\u8ddd\u6301\u7eed\u5b58\u5728\u3002", "method": "\u91c7\u7528\u6df7\u5408\u7814\u7a76\u65b9\u6cd5\uff1a\u8c03\u67e5\u6570\u636e\uff08n=148\uff09\u3001\u6df1\u5ea6\u8bbf\u8c08\u548c\u7a7a\u95f4\u5206\u6790\uff0c\u63a2\u7d22\u5317\u6781\u519c\u6751\u793e\u533a\u7684\u8fde\u63a5\u4f53\u9a8c\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u8702\u7a9d\u8986\u76d6\u4e0d\u5e73\u7b49\u6307\u6570\uff08CCI\uff09\uff0c\u8be5\u6307\u6570\u7ed3\u5408\u4e86\u519c\u6751\u6027\u548c\u7f51\u7edc\u6027\u80fd\u7684\u6d4b\u91cf\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6807\u9898\u6307\u6807\u5938\u5927\u4e86\u5305\u5bb9\u6027\uff0c\u800c\u672c\u5730\u7528\u6237\u62a5\u544a\u4e86\u5f71\u54cd\u5de5\u4f5c\u3001\u5b89\u5168\u548c\u83b7\u53d6\u670d\u52a1\u7684\u6162\u6027\u8fde\u63a5\u5dee\u8ddd\u3002CCI\u6307\u6570\u63ed\u793a\u4e86\u88ab\u56fd\u5bb6\u8986\u76d6\u7edf\u8ba1\u6570\u636e\u63a9\u76d6\u7684\u7a7a\u95f4\u4e0d\u5e73\u7b49\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u516d\u9879\u653f\u7b56\u5efa\u8bae\uff1a\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u548c\u6f2b\u6e38\u6846\u67b6\u3001\u519c\u6751\u8fd0\u8425\u5546\u7684\u9891\u8c31\u7075\u6d3b\u6027\u3001\u57fa\u4e8e\u6027\u80fd\u7684\u670d\u52a1\u8d28\u91cf\u76d1\u63a7\u3001\u6807\u51c6\u5316\u900f\u660e\u62a5\u544a\u3001\u65f6\u95f4\u548c\u5b63\u8282\u6027\u5bb9\u91cf\u7ba1\u7406\u3001\u6570\u5b57\u6280\u80fd\u5021\u8bae\u3002\u5f3a\u8c03\u9700\u8981\u591a\u7ef4\u6307\u6807\u548c\u6cbb\u7406\u673a\u5236\uff0c\u5c06\u6280\u672f\u6027\u80fd\u3001\u7a7a\u95f4\u516c\u5e73\u548c\u7528\u6237\u4f53\u9a8c\u8054\u7cfb\u8d77\u6765\u3002"}}
{"id": "2512.02283", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02283", "abs": "https://arxiv.org/abs/2512.02283", "authors": ["Bin Xu", "Ayan Banerjee", "Sandeep K. S. Gupta"], "title": "Model Recovery at the Edge under Resource Constraints for Physical AI", "comment": "Published in ECAI 2025, Frontiers in Artificial Intelligence and Applications, volume 413, pages 3904-3911", "summary": "Model Recovery (MR) enables safe, explainable decision making in mission-critical autonomous systems (MCAS) by learning governing dynamical equations, but its deployment on edge devices is hindered by the iterative nature of neural ordinary differential equations (NODEs), which are inefficient on FPGAs. Memory and energy consumption are the main concerns when applying MR on edge devices for real-time operation. We propose MERINDA, a novel FPGA-accelerated MR framework that replaces iterative solvers with a parallelizable neural architecture equivalent to NODEs. MERINDA achieves nearly 11x lower DRAM usage and 2.2x faster runtime compared to mobile GPUs. Experiments reveal an inverse relationship between memory and energy at fixed accuracy, highlighting MERINDA's suitability for resource-constrained, real-time MCAS.", "AI": {"tldr": "MERINDA\u662f\u4e00\u4e2aFPGA\u52a0\u901f\u7684\u6a21\u578b\u6062\u590d\u6846\u67b6\uff0c\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u4efb\u52a1\u5173\u952e\u81ea\u4e3b\u7cfb\u7edf\uff0c\u901a\u8fc7\u5e76\u884c\u5316\u795e\u7ecf\u67b6\u6784\u66ff\u4ee3\u8fed\u4ee3\u6c42\u89e3\u5668\uff0c\u663e\u8457\u964d\u4f4e\u5185\u5b58\u548c\u80fd\u8017\u3002", "motivation": "\u6a21\u578b\u6062\u590d\uff08MR\uff09\u5bf9\u4e8e\u4efb\u52a1\u5173\u952e\u81ea\u4e3b\u7cfb\u7edf\u7684\u5b89\u5168\u53ef\u89e3\u91ca\u51b3\u7b56\u5f88\u91cd\u8981\uff0c\u4f46\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u795e\u7ecfODE\u7684\u8fed\u4ee3\u7279\u6027\u5728FPGA\u4e0a\u6548\u7387\u4f4e\u4e0b\uff0c\u5185\u5b58\u548c\u80fd\u8017\u662f\u4e3b\u8981\u95ee\u9898\u3002", "method": "\u63d0\u51faMERINDA\u6846\u67b6\uff0c\u7528\u5e76\u884c\u5316\u795e\u7ecf\u67b6\u6784\u66ff\u4ee3\u795e\u7ecfODE\u4e2d\u7684\u8fed\u4ee3\u6c42\u89e3\u5668\uff0c\u8be5\u67b6\u6784\u5728\u529f\u80fd\u4e0a\u7b49\u540c\u4e8eNODEs\uff0c\u4e13\u95e8\u9488\u5bf9FPGA\u52a0\u901f\u8bbe\u8ba1\u3002", "result": "\u76f8\u6bd4\u79fb\u52a8GPU\uff0cMERINDA\u5b9e\u73b0\u4e86\u8fd111\u500d\u7684DRAM\u4f7f\u7528\u964d\u4f4e\u548c2.2\u500d\u7684\u8fd0\u884c\u901f\u5ea6\u63d0\u5347\u3002\u5b9e\u9a8c\u663e\u793a\u5728\u56fa\u5b9a\u7cbe\u5ea6\u4e0b\u5185\u5b58\u548c\u80fd\u8017\u5b58\u5728\u53cd\u6bd4\u5173\u7cfb\u3002", "conclusion": "MERINDA\u7279\u522b\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u5b9e\u65f6\u4efb\u52a1\u5173\u952e\u81ea\u4e3b\u7cfb\u7edf\uff0c\u901a\u8fc7FPGA\u52a0\u901f\u89e3\u51b3\u4e86\u6a21\u578b\u6062\u590d\u5728\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u7684\u5185\u5b58\u548c\u80fd\u8017\u74f6\u9888\u3002"}}
{"id": "2512.02767", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02767", "abs": "https://arxiv.org/abs/2512.02767", "authors": ["Rostislav Matveev", "Andrei Romashchenko"], "title": "Structural Properties of Entropic Vectors and Stability of the Ingleton Inequality", "comment": "25 pages", "summary": "We study constrained versions of the Ingleton inequality in the entropic setting and quantify its stability under small violations of conditional independence. Although the classical Ingleton inequality fails for general entropy profiles, it is known to hold under certain exact independence constraints. We focus on the regime where selected conditional mutual information terms are small (but not zero), and the inequality continues to hold up to controlled error terms. A central technical tool is a structural lemma that materializes part of the mutual information between two random variables, implicitly capturing the effect of infinitely many non-Shannon--type inequalities. This leads to conceptually transparent proofs without explicitly invoking such infinite families. Some of our bounds recover, in a unified way, what can also be deduced from the infinite families of inequalities of Mat\u00fa\u0161 (2007) and of Dougherty--Freiling--Zeger (2011), while others appear to be new.", "AI": {"tldr": "\u7814\u7a76\u71b5\u6846\u67b6\u4e0bIngleton\u4e0d\u7b49\u5f0f\u7684\u7ea6\u675f\u7248\u672c\u53ca\u5176\u5728\u6761\u4ef6\u72ec\u7acb\u6027\u5c0f\u7834\u574f\u4e0b\u7684\u7a33\u5b9a\u6027\uff0c\u5efa\u7acb\u4e86\u53d7\u63a7\u8bef\u5dee\u4e0b\u7684\u4e0d\u7b49\u5f0f\u4fdd\u6301", "motivation": "\u7ecf\u5178Ingleton\u4e0d\u7b49\u5f0f\u5728\u4e00\u822c\u71b5\u5206\u5e03\u4e2d\u4e0d\u6210\u7acb\uff0c\u4f46\u5728\u67d0\u4e9b\u7cbe\u786e\u72ec\u7acb\u6027\u7ea6\u675f\u4e0b\u6210\u7acb\u3002\u7814\u7a76\u5728\u6761\u4ef6\u4e92\u4fe1\u606f\u9879\u5f88\u5c0f\uff08\u4f46\u4e0d\u4e3a\u96f6\uff09\u65f6\u7684\u4e0d\u7b49\u5f0f\u7a33\u5b9a\u6027", "method": "\u4f7f\u7528\u7ed3\u6784\u5f15\u7406\u5177\u4f53\u5316\u90e8\u5206\u4e92\u4fe1\u606f\uff0c\u9690\u542b\u6355\u83b7\u65e0\u9650\u591a\u975eShannon\u578b\u4e0d\u7b49\u5f0f\u6548\u5e94\uff0c\u63d0\u4f9b\u6982\u5ff5\u6e05\u6670\u7684\u8bc1\u660e\u800c\u65e0\u9700\u663e\u5f0f\u8c03\u7528\u65e0\u9650\u4e0d\u7b49\u5f0f\u65cf", "result": "\u5f97\u5230\u53d7\u63a7\u8bef\u5dee\u4e0bIngleton\u4e0d\u7b49\u5f0f\u7684\u7a33\u5b9a\u6027\u7ed3\u679c\uff0c\u90e8\u5206\u7ed3\u679c\u7edf\u4e00\u6062\u590d\u4e86Mat\u00fa\u0161\u548cDougherty-Freiling-Zeger\u7684\u65e0\u9650\u4e0d\u7b49\u5f0f\u65cf\u63a8\u8bba\uff0c\u90e8\u5206\u7ed3\u679c\u662f\u65b0\u7684", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5f15\u7406\u65b9\u6cd5\uff0c\u5728\u6761\u4ef6\u72ec\u7acb\u6027\u5c0f\u7834\u574f\u4e0b\u5efa\u7acb\u4e86Ingleton\u4e0d\u7b49\u5f0f\u7684\u7a33\u5b9a\u6027\u7406\u8bba\uff0c\u4e3a\u71b5\u4e0d\u7b49\u5f0f\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2"}}
{"id": "2512.02843", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02843", "abs": "https://arxiv.org/abs/2512.02843", "authors": ["Israel Leyva-Mayorga", "Shashi Raj Pandey", "Petar Popovski", "Fabio Saggese", "Beatriz Soret", "Cedomir Stefanovic"], "title": "ISAC-Powered Distributed Matching and Resource Allocation in Multi-band NTN", "comment": "Accepted for publication in Proc. Asilomar Conference on Signals, Systems, and Computers 2025", "summary": "Scalability is a major challenge in non-geostationary orbit (NGSO) satellite networks due to the massive number of ground users sharing the limited sub-6 GHz spectrum. Using K- and higher bands is a promising alternative to increase the accessible bandwidth, but these bands are subject to significant atmospheric attenuation, notably rainfall, which can lead to degraded performance and link outages. We present an integrated sensing and communications (ISAC)-powered framework for resilient and efficient operation of multi-band satellite networks. It is based on distributed mechanisms for atmospheric sensing, cell-to-satellite matching, and resource allocation (RA) in a 5G Non-Terrestrial Network (NTN) wide-area scenario with quasi-Earth fixed cells and a beam hopping mechanism. Results with a multi-layer multi-band constellation with satellites operating in the S- and K-bands demonstrate the benefits of our framework for ISAC-powered multi-band systems, which achieves 73% higher throughput per user when compared to single S- and K-band systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u7684\u591a\u9891\u6bb5\u536b\u661f\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u5927\u6c14\u611f\u77e5\u3001\u5c0f\u533a-\u536b\u661f\u5339\u914d\u548c\u8d44\u6e90\u5206\u914d\u673a\u5236\uff0c\u57285G\u975e\u5730\u9762\u7f51\u7edc\u4e2d\u5b9e\u73b0\u5f39\u6027\u9ad8\u6548\u8fd0\u884c\uff0c\u76f8\u6bd4\u5355\u9891\u6bb5\u7cfb\u7edf\u63d0\u534773%\u7684\u7528\u6237\u541e\u5410\u91cf\u3002", "motivation": "\u975e\u5bf9\u5730\u9759\u6b62\u8f68\u9053\uff08NGSO\uff09\u536b\u661f\u7f51\u7edc\u9762\u4e34\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u5927\u91cf\u5730\u9762\u7528\u6237\u5171\u4eab\u6709\u9650\u7684sub-6 GHz\u9891\u8c31\u3002\u867d\u7136\u4f7f\u7528K\u9891\u6bb5\u53ca\u66f4\u9ad8\u9891\u6bb5\u53ef\u589e\u52a0\u53ef\u7528\u5e26\u5bbd\uff0c\u4f46\u8fd9\u4e9b\u9891\u6bb5\u53d7\u5927\u6c14\u8870\u51cf\uff08\u7279\u522b\u662f\u964d\u96e8\uff09\u5f71\u54cd\u4e25\u91cd\uff0c\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u548c\u94fe\u8def\u4e2d\u65ad\u3002", "method": "\u63d0\u51faISAC\u9a71\u52a8\u7684\u591a\u9891\u6bb5\u536b\u661f\u7f51\u7edc\u6846\u67b6\uff0c\u5305\u542b\u5206\u5e03\u5f0f\u5927\u6c14\u611f\u77e5\u3001\u5c0f\u533a-\u536b\u661f\u5339\u914d\u548c\u8d44\u6e90\u5206\u914d\u673a\u5236\u3002\u57285G\u975e\u5730\u9762\u7f51\u7edc\uff08NTN\uff09\u5e7f\u57df\u573a\u666f\u4e2d\uff0c\u91c7\u7528\u51c6\u5730\u7403\u56fa\u5b9a\u5c0f\u533a\u548c\u6ce2\u675f\u8df3\u53d8\u673a\u5236\uff0c\u901a\u8fc7\u591a\u5c42\u591a\u9891\u6bb5\u661f\u5ea7\uff08S\u9891\u6bb5\u548cK\u9891\u6bb5\u536b\u661f\uff09\u5b9e\u73b0\u3002", "result": "\u5728\u591a\u5c42\u591a\u9891\u6bb5\u661f\u5ea7\uff08S\u9891\u6bb5\u548cK\u9891\u6bb5\u536b\u661f\uff09\u7684\u6d4b\u8bd5\u4e2d\uff0c\u8be5ISAC\u9a71\u52a8\u7684\u591a\u9891\u6bb5\u7cfb\u7edf\u76f8\u6bd4\u5355S\u9891\u6bb5\u548c\u5355K\u9891\u6bb5\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e8673%\u66f4\u9ad8\u7684\u6bcf\u7528\u6237\u541e\u5410\u91cf\u3002", "conclusion": "ISAC\u9a71\u52a8\u7684\u591a\u9891\u6bb5\u536b\u661f\u7f51\u7edc\u6846\u67b6\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u5927\u6c14\u8870\u51cf\u6311\u6218\uff0c\u901a\u8fc7\u667a\u80fd\u611f\u77e5\u548c\u8d44\u6e90\u5206\u914d\u5b9e\u73b0\u5f39\u6027\u9ad8\u6548\u8fd0\u884c\uff0c\u663e\u8457\u63d0\u5347\u536b\u661f\u7f51\u7edc\u6027\u80fd\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2512.02302", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02302", "abs": "https://arxiv.org/abs/2512.02302", "authors": ["Varun Kumar Dasoju", "Qingsu Cheng", "Zeyun Yu"], "title": "Breast Cell Segmentation Under Extreme Data Constraints: Quantum Enhancement Meets Adaptive Loss Stabilization", "comment": "9 pages, 3 figures, 2 tables", "summary": "Annotating medical images demands significant time and expertise, often requiring pathologists to invest hundreds of hours in labeling mammary epithelial nuclei datasets. We address this critical challenge by achieving 95.5% Dice score using just 599 training images for breast cell segmentation, where just 4% of pixels represent breast tissue and 60% of images contain no breast regions. Our framework uses quantum-inspired edge enhancement via multi-scale Gabor filters creating a fourth input channel, enhancing boundary detection where inter-annotator variations reach +/- 3 pixels. We present a stabilized multi-component loss function that integrates adaptive Dice loss with boundary-aware terms and automatic positive weighting to effectively address severe class imbalance, where mammary epithelial cell regions comprise only 0.1%-20% of the total image area. Additionally, a complexity-based weighted sampling strategy is introduced to prioritize the challenging mammary epithelial cell regions. The model employs an EfficientNet-B7/UNet++ architecture with a 4-to-3 channel projection, enabling the use of pretrained weights despite limited medical imaging data. Finally, robust validation is achieved through exponential moving averaging and statistical outlier detection, ensuring reliable performance estimates on a small validation set (129 images). Our framework achieves a Dice score of 95.5% +/- 0.3% and an IoU of 91.2% +/- 0.4%. Notably, quantum-based enhancement contributes to a 2.1% improvement in boundary accuracy, while weighted sampling increases small lesion detection by 3.8%. By achieving groundbreaking performance with limited annotations, our approach significantly reduces the medical expert time required for dataset creation, addressing a fundamental bottleneck in clinical perception AI development.", "AI": {"tldr": "\u4f7f\u7528\u91cf\u5b50\u542f\u53d1\u7684\u8fb9\u7f18\u589e\u5f3a\u548c\u7a33\u5b9a\u591a\u7ec4\u4ef6\u635f\u5931\u51fd\u6570\uff0c\u4ec5\u9700599\u5f20\u8bad\u7ec3\u56fe\u50cf\u5c31\u5728\u4e73\u817a\u7ec6\u80de\u5206\u5272\u4e2d\u8fbe\u523095.5% Dice\u5206\u6570\uff0c\u663e\u8457\u51cf\u5c11\u533b\u5b66\u56fe\u50cf\u6807\u6ce8\u5de5\u4f5c\u91cf\u3002", "motivation": "\u533b\u5b66\u56fe\u50cf\u6807\u6ce8\u9700\u8981\u5927\u91cf\u65f6\u95f4\u548c\u4e13\u5bb6\u77e5\u8bc6\uff0c\u7279\u522b\u662f\u4e73\u817a\u4e0a\u76ae\u7ec6\u80de\u5206\u5272\u4e2d\u6570\u636e\u7a00\u7f3a\u4e14\u7c7b\u522b\u6781\u5ea6\u4e0d\u5e73\u8861\uff08\u4e73\u817a\u7ec4\u7ec7\u4ec5\u5360\u56fe\u50cf\u76840.1%-20%\uff09\uff0c\u8fd9\u6210\u4e3a\u4e34\u5e8a\u611f\u77e5AI\u53d1\u5c55\u7684\u4e3b\u8981\u74f6\u9888\u3002", "method": "1) \u4f7f\u7528\u591a\u5c3a\u5ea6Gabor\u6ee4\u6ce2\u5668\u8fdb\u884c\u91cf\u5b50\u542f\u53d1\u5f0f\u8fb9\u7f18\u589e\u5f3a\uff0c\u521b\u5efa\u7b2c\u56db\u8f93\u5165\u901a\u9053\u6539\u5584\u8fb9\u754c\u68c0\u6d4b\uff1b2) \u63d0\u51fa\u7a33\u5b9a\u591a\u7ec4\u4ef6\u635f\u5931\u51fd\u6570\uff0c\u6574\u5408\u81ea\u9002\u5e94Dice\u635f\u5931\u3001\u8fb9\u754c\u611f\u77e5\u9879\u548c\u81ea\u52a8\u6b63\u6837\u672c\u52a0\u6743\uff1b3) \u5f15\u5165\u57fa\u4e8e\u590d\u6742\u5ea6\u7684\u52a0\u6743\u91c7\u6837\u7b56\u7565\uff0c\u4f18\u5148\u5904\u7406\u6311\u6218\u6027\u533a\u57df\uff1b4) \u91c7\u7528EfficientNet-B7/UNet++\u67b6\u6784\uff0c\u901a\u8fc74\u52303\u901a\u9053\u6295\u5f71\u5229\u7528\u9884\u8bad\u7ec3\u6743\u91cd\uff1b5) \u901a\u8fc7\u6307\u6570\u79fb\u52a8\u5e73\u5747\u548c\u7edf\u8ba1\u5f02\u5e38\u503c\u68c0\u6d4b\u8fdb\u884c\u9c81\u68d2\u9a8c\u8bc1\u3002", "result": "\u5728\u4ec5599\u5f20\u8bad\u7ec3\u56fe\u50cf\u4e0a\u8fbe\u523095.5% \u00b1 0.3% Dice\u5206\u6570\u548c91.2% \u00b1 0.4% IoU\u3002\u91cf\u5b50\u589e\u5f3a\u4f7f\u8fb9\u754c\u51c6\u786e\u7387\u63d0\u53472.1%\uff0c\u52a0\u6743\u91c7\u6837\u4f7f\u5c0f\u75c5\u7076\u68c0\u6d4b\u63d0\u53473.8%\u3002\u5728\u4ec5\u6709129\u5f20\u56fe\u50cf\u7684\u9a8c\u8bc1\u96c6\u4e0a\u83b7\u5f97\u53ef\u9760\u6027\u80fd\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u7684\u91cf\u5b50\u542f\u53d1\u8fb9\u7f18\u589e\u5f3a\u3001\u7a33\u5b9a\u635f\u5931\u51fd\u6570\u548c\u667a\u80fd\u91c7\u6837\u7b56\u7565\uff0c\u5728\u6709\u9650\u6807\u6ce8\u6570\u636e\u4e0b\u5b9e\u73b0\u4e86\u7a81\u7834\u6027\u6027\u80fd\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u533b\u5b66\u4e13\u5bb6\u521b\u5efa\u6570\u636e\u96c6\u6240\u9700\u65f6\u95f4\uff0c\u89e3\u51b3\u4e86\u4e34\u5e8a\u611f\u77e5AI\u53d1\u5c55\u7684\u6839\u672c\u74f6\u9888\u3002"}}
{"id": "2512.02941", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02941", "abs": "https://arxiv.org/abs/2512.02941", "authors": ["Wittawat Kositwattanarerk", "Gretchen L. Matthews", "Emily McMillon", "Tunchanok Yutitumsatit"], "title": "Pseudocodewords of quantum, quasi-cyclic, and spatially-coupled LDPC codes: a fundamental cone perspective", "comment": null, "summary": "While low-density parity-check (LDPC) codes are near capacity-achieving when paired with iterative decoders, these decoders may not output a codeword due to the existence of pseudocodewords. Thus, pseudocodewords have been studied to give insight into the performance of modern decoders including iterative and linear programming decoders. These pseudocodewords are found to be dependent on the parity-check matrix of the code and the particular decoding algorithm used. In this paper, we consider LP decoding, which has been linked to graph cover decoding, providing functions which capture these pseudocodewords. In particular, we analyze the underlying structure of pseudocodewords from quantum stabilizer codes that arise from LP decoding, quasi-cyclic LDPC codes, and spatially-coupled LDPC codes.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u91cf\u5b50\u7a33\u5b9a\u5b50\u7801\u3001\u51c6\u5faa\u73afLDPC\u7801\u548c\u7a7a\u95f4\u8026\u5408LDPC\u7801\u5728LP\u89e3\u7801\u4e0b\u4ea7\u751f\u7684\u4f2a\u7801\u5b57\u5e95\u5c42\u7ed3\u6784", "motivation": "\u867d\u7136LDPC\u7801\u4e0e\u8fed\u4ee3\u89e3\u7801\u5668\u7ed3\u5408\u65f6\u63a5\u8fd1\u5bb9\u91cf\u6781\u9650\uff0c\u4f46\u8fd9\u4e9b\u89e3\u7801\u5668\u53ef\u80fd\u7531\u4e8e\u4f2a\u7801\u5b57\u7684\u5b58\u5728\u800c\u65e0\u6cd5\u8f93\u51fa\u6709\u6548\u7801\u5b57\u3002\u4f2a\u7801\u5b57\u7684\u7814\u7a76\u6709\u52a9\u4e8e\u7406\u89e3\u73b0\u4ee3\u89e3\u7801\u5668\uff08\u5305\u62ec\u8fed\u4ee3\u89e3\u7801\u548c\u7ebf\u6027\u89c4\u5212\u89e3\u7801\uff09\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u91c7\u7528\u7ebf\u6027\u89c4\u5212\uff08LP\uff09\u89e3\u7801\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e0e\u56fe\u8986\u76d6\u89e3\u7801\u76f8\u5173\u8054\uff0c\u80fd\u591f\u6355\u83b7\u4f2a\u7801\u5b57\u3002\u91cd\u70b9\u5206\u6790\u91cf\u5b50\u7a33\u5b9a\u5b50\u7801\u3001\u51c6\u5faa\u73afLDPC\u7801\u548c\u7a7a\u95f4\u8026\u5408LDPC\u7801\u5728LP\u89e3\u7801\u4e0b\u4ea7\u751f\u7684\u4f2a\u7801\u5b57\u5e95\u5c42\u7ed3\u6784\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4f2a\u7801\u5b57\u4f9d\u8d56\u4e8e\u7801\u7684\u5947\u5076\u6821\u9a8c\u77e9\u9635\u548c\u7279\u5b9a\u7684\u89e3\u7801\u7b97\u6cd5\u3002\u901a\u8fc7LP\u89e3\u7801\u4e0e\u56fe\u8986\u76d6\u89e3\u7801\u7684\u8054\u7cfb\uff0c\u63d0\u4f9b\u4e86\u6355\u83b7\u8fd9\u4e9b\u4f2a\u7801\u5b57\u7684\u51fd\u6570\u3002", "conclusion": "\u5bf9\u91cf\u5b50\u7a33\u5b9a\u5b50\u7801\u3001\u51c6\u5faa\u73afLDPC\u7801\u548c\u7a7a\u95f4\u8026\u5408LDPC\u7801\u5728LP\u89e3\u7801\u4e0b\u4f2a\u7801\u5b57\u7ed3\u6784\u7684\u5206\u6790\uff0c\u4e3a\u7406\u89e3\u73b0\u4ee3\u89e3\u7801\u5668\u6027\u80fd\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u89e3\u7801\u7b97\u6cd5\u8bbe\u8ba1\u3002"}}
{"id": "2512.02861", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02861", "abs": "https://arxiv.org/abs/2512.02861", "authors": ["Oscar G. Lira", "Oscar M. Caicedo", "Nelson L. S. Da Fonseca"], "title": "Network Self-Configuration based on Fine-Tuned Small Language Models", "comment": "16 pages, 11 figures, 3 tables", "summary": "As modern networks grow in scale and complexity, manual configuration becomes increasingly inefficient and prone to human error. While intent-driven self-configuration using large language models has shown significant promise, such models remain computationally expensive, resource-intensive, and often raise privacy concerns because they typically rely on external cloud infrastructure. This work introduces SLM_netconfig, a fine-tuned small language model framework that uses an agent-based architecture and parameter-efficient adaptation techniques to translate configuration intents expressed as natural language requirements or questions into syntactically and semantically valid network configurations. The system is trained on a domain-specific dataset generated through a pipeline derived from vendor documentation, ensuring strong alignment with real-world configuration practices. Extensive evaluation shows that SLM_netconfig, when using its question-to-configuration model, achieves higher syntactic accuracy and goal accuracy than LLM-NetCFG while substantially reducing translation latency and producing concise, interpretable configurations. These results demonstrate that fine-tuned small language models, as implemented in SLM_netconfig, can deliver efficient, accurate, and privacy-preserving automated configuration generation entirely on-premise, making them a practical and scalable solution for modern autonomous network configuration.", "AI": {"tldr": "SLM_netconfig\u662f\u4e00\u4e2a\u57fa\u4e8e\u5fae\u8c03\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7f51\u7edc\u914d\u7f6e\u6846\u67b6\uff0c\u4f7f\u7528\u4ee3\u7406\u67b6\u6784\u548c\u53c2\u6570\u9ad8\u6548\u9002\u5e94\u6280\u672f\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u8f6c\u6362\u4e3a\u6709\u6548\u7f51\u7edc\u914d\u7f6e\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u51c6\u786e\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u672c\u5730\u81ea\u52a8\u5316\u914d\u7f6e\u3002", "motivation": "\u968f\u7740\u7f51\u7edc\u89c4\u6a21\u548c\u590d\u6742\u6027\u589e\u957f\uff0c\u624b\u52a8\u914d\u7f6e\u6548\u7387\u4f4e\u4e0b\u4e14\u6613\u51fa\u9519\u3002\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u610f\u56fe\u9a71\u52a8\u914d\u7f6e\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u8d44\u6e90\u5bc6\u96c6\uff0c\u4e14\u4f9d\u8d56\u5916\u90e8\u4e91\u57fa\u7840\u8bbe\u65bd\u5f15\u53d1\u9690\u79c1\u62c5\u5fe7\u3002", "method": "\u91c7\u7528\u5fae\u8c03\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u7ed3\u5408\u4ee3\u7406\u67b6\u6784\u548c\u53c2\u6570\u9ad8\u6548\u9002\u5e94\u6280\u672f\uff0c\u4f7f\u7528\u4ece\u5382\u5546\u6587\u6863\u751f\u6210\u7684\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u5230\u7f51\u7edc\u914d\u7f6e\u7684\u8f6c\u6362\u3002", "result": "SLM_netconfig\u5728\u95ee\u9898\u5230\u914d\u7f6e\u6a21\u578b\u4e0a\uff0c\u6bd4LLM-NetCFG\u83b7\u5f97\u66f4\u9ad8\u7684\u8bed\u6cd5\u51c6\u786e\u6027\u548c\u76ee\u6807\u51c6\u786e\u6027\uff0c\u663e\u8457\u964d\u4f4e\u7ffb\u8bd1\u5ef6\u8fdf\uff0c\u751f\u6210\u7b80\u6d01\u53ef\u89e3\u91ca\u7684\u914d\u7f6e\u3002", "conclusion": "\u5fae\u8c03\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u9ad8\u6548\u3001\u51c6\u786e\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u81ea\u52a8\u5316\u914d\u7f6e\u751f\u6210\uff0c\u5b8c\u5168\u5728\u672c\u5730\u8fd0\u884c\uff0c\u662f\u73b0\u4ee3\u81ea\u4e3b\u7f51\u7edc\u914d\u7f6e\u7684\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02306", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02306", "abs": "https://arxiv.org/abs/2512.02306", "authors": ["Boyu Zhu", "Xiaofei Wen", "Wenjie Jacky Mo", "Tinghui Zhu", "Yanan Xie", "Peng Qi", "Muhao Chen"], "title": "OmniGuard: Unified Omni-Modal Guardrails with Deliberate Reasoning", "comment": null, "summary": "Omni-modal Large Language Models (OLLMs) that process text, images, videos, and audio introduce new challenges for safety and value guardrails in human-AI interaction. Prior guardrail research largely targets unimodal settings and typically frames safeguarding as binary classification, which limits robustness across diverse modalities and tasks. To address this gap, we propose OmniGuard, the first family of omni-modal guardrails that performs safeguarding across all modalities with deliberate reasoning ability. To support the training of OMNIGUARD, we curate a large, comprehensive omni-modal safety dataset comprising over 210K diverse samples, with inputs that cover all modalities through both unimodal and cross-modal samples. Each sample is annotated with structured safety labels and carefully curated safety critiques from expert models through targeted distillation. Extensive experiments on 15 benchmarks show that OmniGuard achieves strong effectiveness and generalization across a wide range of multimodal safety scenarios. Importantly, OmniGuard provides a unified framework that enforces policies and mitigates risks in omni-modalities, paving the way toward building more robust and capable omnimodal safeguarding systems.", "AI": {"tldr": "OmniGuard\u662f\u9996\u4e2a\u5168\u6a21\u6001\u5b89\u5168\u62a4\u680f\u7cfb\u7edf\uff0c\u901a\u8fc7\u7cbe\u5fc3\u7b56\u5212\u7684\u5927\u578b\u6570\u636e\u96c6\u548c\u4e13\u5bb6\u6a21\u578b\u84b8\u998f\uff0c\u4e3a\u5904\u7406\u6587\u672c\u3001\u56fe\u50cf\u3001\u89c6\u9891\u548c\u97f3\u9891\u7684\u5168\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u7edf\u4e00\u7684\u5b89\u5168\u4fdd\u969c\u6846\u67b6\u3002", "motivation": "\u5168\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u591a\u79cd\u6a21\u6001\u6570\u636e\u65f6\uff0c\u73b0\u6709\u5b89\u5168\u62a4\u680f\u7814\u7a76\u4e3b\u8981\u9488\u5bf9\u5355\u6a21\u6001\u573a\u666f\uff0c\u91c7\u7528\u4e8c\u5143\u5206\u7c7b\u65b9\u6cd5\uff0c\u7f3a\u4e4f\u8de8\u6a21\u6001\u7684\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\uff0c\u9700\u8981\u65b0\u7684\u5b89\u5168\u4fdd\u969c\u65b9\u6848\u3002", "method": "\u63d0\u51faOmniGuard\u6846\u67b6\uff0c\u6784\u5efa\u5305\u542b21\u4e07+\u591a\u6837\u672c\u7684\u5168\u6a21\u6001\u5b89\u5168\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u6240\u6709\u6a21\u6001\u7684\u5355\u6a21\u6001\u548c\u8de8\u6a21\u6001\u6837\u672c\uff0c\u901a\u8fc7\u4e13\u5bb6\u6a21\u578b\u84b8\u998f\u751f\u6210\u7ed3\u6784\u5316\u5b89\u5168\u6807\u7b7e\u548c\u5b89\u5168\u8bc4\u4f30\u3002", "result": "\u572815\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cOmniGuard\u5728\u5e7f\u6cdb\u7684\u591a\u6a21\u6001\u5b89\u5168\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u591f\u7edf\u4e00\u6267\u884c\u7b56\u7565\u5e76\u964d\u4f4e\u5168\u6a21\u6001\u98ce\u9669\u3002", "conclusion": "OmniGuard\u4e3a\u6784\u5efa\u66f4\u9c81\u68d2\u548c\u5f3a\u5927\u7684\u5168\u6a21\u6001\u5b89\u5168\u4fdd\u969c\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u5168\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6311\u6218\u3002"}}
{"id": "2512.02340", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.02340", "abs": "https://arxiv.org/abs/2512.02340", "authors": ["Qiyao Xue", "Weichen Liu", "Shiqi Wang", "Haoming Wang", "Yuyang Wu", "Wei Gao"], "title": "Reasoning Path and Latent State Analysis for Multi-view Visual Spatial Reasoning: A Cognitive Science Perspective", "comment": "23 pages, 37 figures", "summary": "Spatial reasoning is a core aspect of human intelligence that allows perception, inference and planning in 3D environments. However, current vision-language models (VLMs) struggle to maintain geometric coherence and cross-view consistency for spatial reasoning in multi-view settings. We attribute this gap to the lack of fine-grained benchmarks that isolate multi-view reasoning from single-view perception and temporal factors. To address this, we present ReMindView-Bench, a cognitively grounded benchmark for evaluating how VLMs construct, align and maintain spatial mental models across complementary viewpoints. ReMindView-Bench systematically varies viewpoint spatial pattern and query type to probe key factors of spatial cognition. Evaluations of 15 current VLMs reveals consistent failures in cross-view alignment and perspective-taking in multi-view spatial reasoning, motivating deeper analysis on the reasoning process. Explicit phase-wise analysis using LLM-as-a-judge and self-consistency prompting shows that VLMs perform well on in-frame perception but degrade sharply when integrating information across views. Implicit analysis, including linear probing and entropy dynamics, further show progressive loss of task-relevant information and uncertainty separation between correct and incorrect trajectories. These results provide a cognitively grounded diagnosis of VLM spatial reasoning and reveal how multi-view spatial mental models are formed, degraded and destabilized across reasoning phases. The ReMindView-Bench benchmark is available at https://huggingface.co/datasets/Xue0823/ReMindView-Bench, and the source codes of benchmark construction and VLM reasoning analysis are available at https://github.com/pittisl/ReMindView-Bench.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86ReMindView-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u89c6\u89d2\u7a7a\u95f4\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u8de8\u89c6\u89d2\u5bf9\u9f50\u548c\u89c6\u89d2\u8f6c\u6362\u65b9\u9762\u5b58\u5728\u7cfb\u7edf\u6027\u5931\u8d25\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u89c6\u89d2\u8bbe\u7f6e\u4e2d\u8fdb\u884c\u7a7a\u95f4\u63a8\u7406\u65f6\uff0c\u96be\u4ee5\u4fdd\u6301\u51e0\u4f55\u4e00\u81f4\u6027\u548c\u8de8\u89c6\u89d2\u4e00\u81f4\u6027\u3002\u7f3a\u4e4f\u80fd\u591f\u5c06\u591a\u89c6\u89d2\u63a8\u7406\u4e0e\u5355\u89c6\u89d2\u611f\u77e5\u548c\u65f6\u95f4\u56e0\u7d20\u5206\u79bb\u7684\u7ec6\u7c92\u5ea6\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u63d0\u51fa\u4e86ReMindView-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7cfb\u7edf\u6027\u5730\u53d8\u5316\u89c6\u89d2\u7a7a\u95f4\u6a21\u5f0f\u548c\u67e5\u8be2\u7c7b\u578b\u6765\u63a2\u6d4b\u7a7a\u95f4\u8ba4\u77e5\u7684\u5173\u952e\u56e0\u7d20\u3002\u4f7f\u7528\u663e\u6027\u5206\u9636\u6bb5\u5206\u6790\uff08LLM\u4f5c\u4e3a\u8bc4\u5224\u548c\u81ea\u4e00\u81f4\u6027\u63d0\u793a\uff09\u548c\u9690\u6027\u5206\u6790\uff08\u7ebf\u6027\u63a2\u6d4b\u548c\u71b5\u52a8\u6001\uff09\u6765\u8bca\u65ad\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u8bc4\u4f30\u4e8615\u4e2a\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u8de8\u89c6\u89d2\u5bf9\u9f50\u548c\u89c6\u89d2\u8f6c\u6362\u65b9\u9762\u5b58\u5728\u4e00\u81f4\u6027\u5931\u8d25\u3002\u6a21\u578b\u5728\u5e27\u5185\u611f\u77e5\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u8de8\u89c6\u89d2\u4fe1\u606f\u6574\u5408\u65f6\u6027\u80fd\u6025\u5267\u4e0b\u964d\u3002\u9690\u6027\u5206\u6790\u663e\u793a\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u9010\u6e10\u4e22\u5931\uff0c\u6b63\u786e\u4e0e\u9519\u8bef\u8f68\u8ff9\u4e4b\u95f4\u7684\u4e0d\u786e\u5b9a\u6027\u5206\u79bb\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8ba4\u77e5\u79d1\u5b66\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7a7a\u95f4\u63a8\u7406\u8bca\u65ad\uff0c\u63ed\u793a\u4e86\u591a\u89c6\u89d2\u7a7a\u95f4\u5fc3\u7406\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5982\u4f55\u5f62\u6210\u3001\u9000\u5316\u548c\u5931\u7a33\u3002ReMindView-Bench\u57fa\u51c6\u6d4b\u8bd5\u53ef\u7528\u4e8e\u6df1\u5165\u5206\u6790\u591a\u89c6\u89d2\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2512.02358", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02358", "abs": "https://arxiv.org/abs/2512.02358", "authors": ["Ran Zhang", "Kun Ouyang", "Tiancheng Ma", "Yida Yang", "Dong Fang"], "title": "Beyond Playtesting: A Generative Multi-Agent Simulation System for Massively Multiplayer Online Games", "comment": null, "summary": "Optimizing numerical systems and mechanism design is crucial for enhancing player experience in Massively Multiplayer Online (MMO) games. Traditional optimization approaches rely on large-scale online experiments or parameter tuning over predefined statistical models, which are costly, time-consuming, and may disrupt player experience. Although simplified offline simulation systems are often adopted as alternatives, their limited fidelity prevents agents from accurately mimicking real player reasoning and reactions to interventions. To address these limitations, we propose a generative agent-based MMO simulation system empowered by Large Language Models (LLMs). By applying Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on large-scale real player behavioral data, we adapt LLMs from general priors to game-specific domains, enabling realistic and interpretable player decision-making. In parallel, a data-driven environment model trained on real gameplay logs reconstructs dynamic in-game systems. Experiments demonstrate strong consistency with real-world player behaviors and plausible causal responses under interventions, providing a reliable, interpretable, and cost-efficient framework for data-driven numerical design optimization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u751f\u6210\u5f0f\u667a\u80fd\u4f53MMO\u6a21\u62df\u7cfb\u7edf\uff0c\u7528\u4e8e\u4f18\u5316\u6e38\u620f\u6570\u503c\u7cfb\u7edf\u548c\u673a\u5236\u8bbe\u8ba1\uff0c\u901a\u8fc7SFT\u548cRL\u8bad\u7ec3LLM\u6a21\u62df\u771f\u5b9e\u73a9\u5bb6\u884c\u4e3a\uff0c\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u7684\u73af\u5883\u6a21\u578b\uff0c\u63d0\u4f9b\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u4f18\u5316\u6846\u67b6\u3002", "motivation": "\u4f20\u7edfMMO\u6e38\u620f\u4f18\u5316\u65b9\u6cd5\u4f9d\u8d56\u5927\u89c4\u6a21\u5728\u7ebf\u5b9e\u9a8c\u6216\u57fa\u4e8e\u9884\u5b9a\u4e49\u7edf\u8ba1\u6a21\u578b\u7684\u53c2\u6570\u8c03\u4f18\uff0c\u6210\u672c\u9ad8\u3001\u8017\u65f6\u957f\u4e14\u53ef\u80fd\u5e72\u6270\u73a9\u5bb6\u4f53\u9a8c\u3002\u73b0\u6709\u79bb\u7ebf\u6a21\u62df\u7cfb\u7edf\u4fdd\u771f\u5ea6\u6709\u9650\uff0c\u65e0\u6cd5\u51c6\u786e\u6a21\u62df\u771f\u5b9e\u73a9\u5bb6\u7684\u63a8\u7406\u548c\u5e72\u9884\u53cd\u5e94\u3002", "method": "1. \u57fa\u4e8eLLM\u7684\u751f\u6210\u5f0f\u667a\u80fd\u4f53\u6a21\u62df\u7cfb\u7edf\uff1b2. \u5728\u5927\u89c4\u6a21\u771f\u5b9e\u73a9\u5bb6\u884c\u4e3a\u6570\u636e\u4e0a\u5e94\u7528\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u5f3a\u5316\u5b66\u4e60(RL)\uff0c\u5c06LLM\u4ece\u901a\u7528\u5148\u9a8c\u9002\u5e94\u5230\u6e38\u620f\u7279\u5b9a\u9886\u57df\uff1b3. \u57fa\u4e8e\u771f\u5b9e\u6e38\u620f\u65e5\u5fd7\u8bad\u7ec3\u6570\u636e\u9a71\u52a8\u7684\u73af\u5883\u6a21\u578b\uff0c\u91cd\u5efa\u52a8\u6001\u6e38\u620f\u7cfb\u7edf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u7cfb\u7edf\u4e0e\u771f\u5b9e\u4e16\u754c\u73a9\u5bb6\u884c\u4e3a\u5177\u6709\u5f3a\u4e00\u81f4\u6027\uff0c\u5728\u5e72\u9884\u4e0b\u80fd\u4ea7\u751f\u5408\u7406\u7684\u56e0\u679c\u54cd\u5e94\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u6570\u503c\u8bbe\u8ba1\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u6846\u67b6\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eLLM\u7684\u751f\u6210\u5f0f\u667a\u80fd\u4f53MMO\u6a21\u62df\u7cfb\u7edf\u89e3\u51b3\u4e86\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u9ad8\u4fdd\u771f\u6a21\u62df\u771f\u5b9e\u73a9\u5bb6\u884c\u4e3a\uff0c\u4e3a\u6e38\u620f\u6570\u503c\u7cfb\u7edf\u548c\u673a\u5236\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u9760\u7684\u4f18\u5316\u5de5\u5177\u3002"}}
{"id": "2512.02389", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02389", "abs": "https://arxiv.org/abs/2512.02389", "authors": ["David X. Wu", "Shreyas Kapur", "Anant Sahai", "Stuart Russell"], "title": "Synthetic Error Injection Fails to Elicit Self-Correction In Language Models", "comment": "13 pages, 12 figures", "summary": "Reinforcement learning has become the dominant paradigm for eliciting reasoning and self-correction capabilities in large language models, but its computational expense motivates exploration of alternatives. Inspired by techniques from autonomous driving and robotics, we investigate whether supervised learning with synthetic error injection can induce self-correction abilities in language models. Our approach inserts artificial errors into reasoning chains, masks them, and supervises the model to recognize and correct these mistakes. Despite the intuitive appeal of this method, we find that it fails to significantly improve performance even on simple synthetic tasks across multiple models. Moreover, even when the model catches its own error, it often parrots the original mistake. We find that the distribution shift of synthetic errors to on-policy errors significantly degrades the error-correction capabilities of the fine-tuned model, even with good synthetic coverage of on-policy errors. Our results help explain why on-policy reinforcement learning methods have proven uniquely effective for eliciting self-correction.", "AI": {"tldr": "\u76d1\u7763\u5b66\u4e60\u7ed3\u5408\u4eba\u5de5\u9519\u8bef\u6ce8\u5165\u65e0\u6cd5\u6709\u6548\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6211\u7ea0\u9519\u80fd\u529b\uff0c\u5373\u4f7f\u6a21\u578b\u80fd\u53d1\u73b0\u9519\u8bef\u4e5f\u5e38\u91cd\u590d\u539f\u9519\u8bef\uff0c\u5206\u5e03\u504f\u79fb\u662f\u4e3b\u8981\u539f\u56e0", "motivation": "\u5f3a\u5316\u5b66\u4e60\u867d\u7136\u80fd\u6fc0\u53d1\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u548c\u81ea\u6211\u7ea0\u9519\u80fd\u529b\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u63a2\u7d22\u66ff\u4ee3\u65b9\u6cd5\u3002\u53d7\u81ea\u52a8\u9a7e\u9a76\u548c\u673a\u5668\u4eba\u6280\u672f\u542f\u53d1\uff0c\u7814\u7a76\u76d1\u7763\u5b66\u4e60\u7ed3\u5408\u4eba\u5de5\u9519\u8bef\u6ce8\u5165\u662f\u5426\u80fd\u8bf1\u5bfc\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6211\u7ea0\u9519\u80fd\u529b\u3002", "method": "\u5728\u63a8\u7406\u94fe\u4e2d\u63d2\u5165\u4eba\u5de5\u9519\u8bef\uff0c\u63a9\u76d6\u8fd9\u4e9b\u9519\u8bef\uff0c\u7136\u540e\u76d1\u7763\u6a21\u578b\u8bc6\u522b\u548c\u7ea0\u6b63\u8fd9\u4e9b\u9519\u8bef\u3002\u901a\u8fc7\u5408\u6210\u9519\u8bef\u6ce8\u5165\u7684\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u6d4b\u8bd5\u5176\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\u7684\u6548\u679c\u3002", "result": "\u8be5\u65b9\u6cd5\u5373\u4f7f\u5728\u7b80\u5355\u7684\u5408\u6210\u4efb\u52a1\u4e0a\u4e5f\u65e0\u6cd5\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002\u5373\u4f7f\u6a21\u578b\u80fd\u53d1\u73b0\u81ea\u5df1\u7684\u9519\u8bef\uff0c\u4e5f\u5e38\u5e38\u91cd\u590d\u539f\u6765\u7684\u9519\u8bef\u3002\u5408\u6210\u9519\u8bef\u4e0e\u5728\u7ebf\u7b56\u7565\u9519\u8bef\u4e4b\u95f4\u7684\u5206\u5e03\u504f\u79fb\u663e\u8457\u964d\u4f4e\u4e86\u5fae\u8c03\u6a21\u578b\u7684\u7ea0\u9519\u80fd\u529b\uff0c\u5373\u4f7f\u5408\u6210\u9519\u8bef\u80fd\u5f88\u597d\u5730\u8986\u76d6\u5728\u7ebf\u7b56\u7565\u9519\u8bef\u3002", "conclusion": "\u76d1\u7763\u5b66\u4e60\u7ed3\u5408\u4eba\u5de5\u9519\u8bef\u6ce8\u5165\u65e0\u6cd5\u6709\u6548\u66ff\u4ee3\u5f3a\u5316\u5b66\u4e60\u6765\u6fc0\u53d1\u81ea\u6211\u7ea0\u9519\u80fd\u529b\u3002\u5206\u5e03\u504f\u79fb\u95ee\u9898\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u5728\u7ebf\u7b56\u7565\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u6fc0\u53d1\u81ea\u6211\u7ea0\u9519\u65b9\u9762\u5177\u6709\u72ec\u7279\u6548\u679c\u3002"}}
{"id": "2512.02436", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02436", "abs": "https://arxiv.org/abs/2512.02436", "authors": ["Agostino Capponi", "Alfio Gliozzo", "Brian Zhu"], "title": "Semantic Trading: Agentic AI for Clustering and Relationship Discovery in Prediction Markets", "comment": null, "summary": "Prediction markets allow users to trade on outcomes of real-world events, but are prone to fragmentation through overlapping questions, implicit equivalences, and hidden contradictions across markets. We present an agentic AI pipeline that autonomously (i) clusters markets into coherent topical groups using natural-language understanding over contract text and metadata, and (ii) identifies within-cluster market pairs whose resolved outcomes exhibit strong dependence, including same-outcome (correlated) and different-outcome (anti-correlated) relationships. Using a historical dataset of resolved markets on Polymarket, we evaluate the accuracy of the agent's relational predictions. We then translate discovered relationships into a simple trading strategy to quantify how these relationships map to actionable signals. Results show that agent-identified relationships achieve roughly 60-70% accuracy, and their induced trading strategies earn about 20% average returns over week-long horizons, highlighting the ability of agentic AI and large language models to uncover latent semantic structure in prediction markets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2aAI\u4ee3\u7406\u7ba1\u9053\uff0c\u81ea\u52a8\u805a\u7c7b\u9884\u6d4b\u5e02\u573a\u5e76\u8bc6\u522b\u5e02\u573a\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u901a\u8fc7\u4ea4\u6613\u7b56\u7565\u9a8c\u8bc1\u53d1\u73b0\u7684\u5173\u7cfb\u80fd\u5e26\u6765\u7ea620%\u7684\u5468\u6536\u76ca\u3002", "motivation": "\u9884\u6d4b\u5e02\u573a\u5b58\u5728\u788e\u7247\u5316\u95ee\u9898\uff0c\u5305\u62ec\u91cd\u53e0\u95ee\u9898\u3001\u9690\u542b\u7b49\u4ef7\u5173\u7cfb\u548c\u9690\u85cf\u77db\u76fe\uff0c\u8fd9\u963b\u788d\u4e86\u5e02\u573a\u6548\u7387\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u81ea\u52a8\u53d1\u73b0\u5e02\u573a\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\u548c\u4f9d\u8d56\u7ed3\u6784\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2aAI\u4ee3\u7406\u7ba1\u9053\uff1a1) \u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u5bf9\u5e02\u573a\u5408\u540c\u6587\u672c\u548c\u5143\u6570\u636e\u8fdb\u884c\u805a\u7c7b\uff0c\u5f62\u6210\u8fde\u8d2f\u7684\u4e3b\u9898\u7ec4\uff1b2) \u8bc6\u522b\u7ec4\u5185\u5e02\u573a\u5bf9\u4e4b\u95f4\u7684\u5f3a\u4f9d\u8d56\u5173\u7cfb\uff0c\u5305\u62ec\u76f8\u540c\u7ed3\u679c\uff08\u6b63\u76f8\u5173\uff09\u548c\u4e0d\u540c\u7ed3\u679c\uff08\u8d1f\u76f8\u5173\uff09\u7684\u5173\u7cfb\u3002", "result": "\u5728Polymarket\u5386\u53f2\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff1aAI\u8bc6\u522b\u7684\u5173\u7cfb\u51c6\u786e\u7387\u8fbe\u5230\u7ea660-70%\uff1b\u57fa\u4e8e\u8fd9\u4e9b\u5173\u7cfb\u6784\u5efa\u7684\u7b80\u5355\u4ea4\u6613\u7b56\u7565\u5728\u5468\u65f6\u95f4\u8303\u56f4\u5185\u83b7\u5f97\u7ea620%\u7684\u5e73\u5747\u6536\u76ca\u3002", "conclusion": "AI\u4ee3\u7406\u548c\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6709\u6548\u53d1\u73b0\u9884\u6d4b\u5e02\u573a\u4e2d\u6f5c\u5728\u7684\u8bed\u4e49\u7ed3\u6784\uff0c\u8bc6\u522b\u7684\u5173\u7cfb\u5177\u6709\u5b9e\u9645\u4ea4\u6613\u4ef7\u503c\uff0c\u4e3a\u5e02\u573a\u5206\u6790\u548c\u4ea4\u6613\u7b56\u7565\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2512.02472", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02472", "abs": "https://arxiv.org/abs/2512.02472", "authors": ["Wenhao Yu", "Zhenwen Liang", "Chengsong Huang", "Kishan Panaganti", "Tianqing Fang", "Haitao Mi", "Dong Yu"], "title": "Guided Self-Evolving LLMs with Minimal Human Supervision", "comment": null, "summary": "AI self-evolution has long been envisioned as a path toward superintelligence, where models autonomously acquire, refine, and internalize knowledge from their own learning experiences. Yet in practice, unguided self-evolving systems often plateau quickly or even degrade as training progresses. These failures arise from issues such as concept drift, diversity collapse, and mis-evolution, as models reinforce their own biases and converge toward low-entropy behaviors. To enable models to self-evolve in a stable and controllable manner while minimizing reliance on human supervision, we introduce R-Few, a guided Self-Play Challenger-Solver framework that incorporates lightweight human oversight through in-context grounding and mixed training. At each iteration, the Challenger samples a small set of human-labeled examples to guide synthetic question generation, while the Solver jointly trains on human and synthetic examples under an online, difficulty-based curriculum. Across math and general reasoning benchmarks, R-Few achieves consistent and iterative improvements. For example, Qwen3-8B-Base improves by +3.0 points over R-Zero on math tasks and achieves performance on par with General-Reasoner, despite the latter being trained on 20 times more human data. Ablation studies confirm the complementary contributions of grounded challenger training and curriculum-based solver training, and further analysis shows that R-Few mitigates drift, yielding more stable and controllable co-evolutionary dynamics.", "AI": {"tldr": "R-Few\u662f\u4e00\u4e2a\u5f15\u5bfc\u5f0f\u81ea\u6211\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u4eba\u7c7b\u76d1\u7763\uff08\u4e0a\u4e0b\u6587grounding\u548c\u6df7\u5408\u8bad\u7ec3\uff09\u5b9e\u73b0\u7a33\u5b9a\u53ef\u63a7\u7684AI\u81ea\u6211\u8fdb\u5316\uff0c\u5728\u6570\u5b66\u548c\u901a\u7528\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u6301\u7eed\u8fed\u4ee3\u6539\u8fdb\u3002", "motivation": "AI\u81ea\u6211\u8fdb\u5316\u88ab\u8ba4\u4e3a\u662f\u901a\u5411\u8d85\u667a\u80fd\u7684\u8def\u5f84\uff0c\u4f46\u5b9e\u8df5\u4e2d\u65e0\u5f15\u5bfc\u7684\u81ea\u6211\u8fdb\u5316\u7cfb\u7edf\u5f80\u5f80\u5feb\u901f\u5e73\u53f0\u5316\u751a\u81f3\u9000\u5316\uff0c\u5b58\u5728\u6982\u5ff5\u6f02\u79fb\u3001\u591a\u6837\u6027\u5d29\u6e83\u548c\u9519\u8bef\u8fdb\u5316\u7b49\u95ee\u9898\u3002\u9700\u8981\u5b9e\u73b0\u7a33\u5b9a\u53ef\u63a7\u7684\u81ea\u6211\u8fdb\u5316\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u5bf9\u4eba\u7c7b\u76d1\u7763\u7684\u4f9d\u8d56\u3002", "method": "\u63d0\u51faR-Few\u6846\u67b6\uff1a\u5f15\u5bfc\u5f0f\u81ea\u6211\u5bf9\u5f08\u6311\u6218\u8005-\u6c42\u89e3\u5668\u6846\u67b6\u3002\u6311\u6218\u8005\u91c7\u6837\u5c11\u91cf\u4eba\u7c7b\u6807\u6ce8\u793a\u4f8b\u6307\u5bfc\u5408\u6210\u95ee\u9898\u751f\u6210\uff0c\u6c42\u89e3\u5668\u5728\u5728\u7ebf\u96be\u5ea6\u8bfe\u7a0b\u4e0b\u8054\u5408\u8bad\u7ec3\u4eba\u7c7b\u548c\u5408\u6210\u793a\u4f8b\u3002\u5305\u542b\u4e0a\u4e0b\u6587grounding\u548c\u6df7\u5408\u8bad\u7ec3\u3002", "result": "\u5728\u6570\u5b66\u548c\u901a\u7528\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cR-Few\u5b9e\u73b0\u4e00\u81f4\u4e14\u8fed\u4ee3\u7684\u6539\u8fdb\u3002\u4f8b\u5982\uff0cQwen3-8B-Base\u5728\u6570\u5b66\u4efb\u52a1\u4e0a\u6bd4R-Zero\u63d0\u53473.0\u5206\uff0c\u6027\u80fd\u4e0e\u4f7f\u752820\u500d\u4eba\u7c7b\u6570\u636e\u8bad\u7ec3\u7684General-Reasoner\u76f8\u5f53\u3002\u6d88\u878d\u7814\u7a76\u786e\u8ba4\u4e86grounded\u6311\u6218\u8005\u8bad\u7ec3\u548c\u8bfe\u7a0b\u6c42\u89e3\u5668\u8bad\u7ec3\u7684\u4e92\u8865\u8d21\u732e\u3002", "conclusion": "R-Few\u901a\u8fc7\u8f7b\u91cf\u7ea7\u4eba\u7c7b\u76d1\u7763\u5b9e\u73b0\u4e86\u7a33\u5b9a\u53ef\u63a7\u7684\u81ea\u6211\u8fdb\u5316\uff0c\u7f13\u89e3\u4e86\u6f02\u79fb\u95ee\u9898\uff0c\u4ea7\u751f\u66f4\u7a33\u5b9a\u53ef\u63a7\u7684\u534f\u540c\u8fdb\u5316\u52a8\u6001\uff0c\u4e3aAI\u81ea\u6211\u8fdb\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02499", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02499", "abs": "https://arxiv.org/abs/2512.02499", "authors": ["Yongkai Liu", "Helena Feng", "Bin Jiang", "Yixin Wang", "Max Wintermark", "David S. Liebeskind", "Michael Moseley", "Maarten Lansberg", "Gregory Albers", "Jeremy Heit", "Greg Zaharchuk"], "title": "COPE: Chain-Of-Thought Prediction Engine for Open-Source Large Language Model Based Stroke Outcome Prediction from Clinical Notes", "comment": null, "summary": "Predicting outcomes in acute ischemic stroke (AIS) guides clinical decision-making, patient counseling, and resource allocation. Clinical notes contain rich contextual information, but their unstructured nature limits their use in traditional predictive models. We developed and evaluated the Chain-of-Thought (CoT) Outcome Prediction Engine (COPE), a reasoning-enhanced large language model framework, for predicting 90-day functional outcomes after AIS from unstructured clinical notes. This study included 464 AIS patients with discharge summaries and 90-day modified Rankin Scale (mRS) scores. COPE uses a two-step CoT framework based on sequential open-source LLaMA-3-8B models: the first generates clinical reasoning, and the second outputs an mRS prediction. We compared COPE with GPT-4.1, ClinicalBERT, a structured variable-based machine learning model (Clinical ML), and a single-step LLM without CoT. Performance was evaluated using mean absolute error (MAE), accuracy within +/-1 mRS point, and exact accuracy. COPE achieved an MAE of 1.01 (95% CI 0.92-1.11), +/-1 accuracy of 74.4% (69.9, 78.8%), and exact accuracy of 32.8% (28.0, 37.6%), comparable to GPT-4.1 and superior to ClinicalBERT [MAE 1.24 (1.13-1.36)], Clinical ML [1.28 (1.18-1.39)], and the single-step LLM [1.20 (1.09-1.33)]. Subgroup analyses showed consistent performance across sex and age, with slightly higher error among older patients, those undergoing thrombectomy, and those with longer summaries. These findings demonstrate that COPE, a lightweight, interpretable, and privacy-preserving open-source framework, provides an accurate and practical solution for outcome prediction from unstructured clinical text.", "AI": {"tldr": "COPE\u662f\u4e00\u4e2a\u57fa\u4e8e\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u7684LLM\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u7b14\u8bb0\u9884\u6d4b\u6025\u6027\u7f3a\u8840\u6027\u5352\u4e2d90\u5929\u529f\u80fd\u7ed3\u5c40\uff0c\u6027\u80fd\u4e0eGPT-4.1\u76f8\u5f53\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4e34\u5e8a\u7b14\u8bb0\u5305\u542b\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4f46\u5176\u975e\u7ed3\u6784\u5316\u7279\u6027\u9650\u5236\u4e86\u5728\u4f20\u7edf\u9884\u6d4b\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u8fdb\u884c\u51c6\u786e\u9884\u540e\u9884\u6d4b\u7684\u65b9\u6cd5\u3002", "method": "COPE\u91c7\u7528\u4e24\u6b65\u94fe\u5f0f\u601d\u7ef4\u6846\u67b6\uff1a\u7b2c\u4e00\u6b65LLaMA-3-8B\u751f\u6210\u4e34\u5e8a\u63a8\u7406\uff0c\u7b2c\u4e8c\u6b65\u8f93\u51fa\u6539\u826fRankin\u91cf\u8868\u9884\u6d4b\u3002\u4e0eGPT-4.1\u3001ClinicalBERT\u3001\u7ed3\u6784\u5316\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u5355\u6b65LLM\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "COPE\u7684MAE\u4e3a1.01\uff0c\u00b11\u51c6\u786e\u738774.4%\uff0c\u7cbe\u786e\u51c6\u786e\u738732.8%\uff0c\u6027\u80fd\u4e0eGPT-4.1\u76f8\u5f53\uff0c\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002\u5728\u4e0d\u540c\u4e9a\u7ec4\u4e2d\u8868\u73b0\u4e00\u81f4\uff0c\u4f46\u5728\u8001\u5e74\u60a3\u8005\u3001\u63a5\u53d7\u8840\u6813\u5207\u9664\u672f\u60a3\u8005\u548c\u8f83\u957f\u6458\u8981\u60a3\u8005\u4e2d\u8bef\u5dee\u7565\u9ad8\u3002", "conclusion": "COPE\u4f5c\u4e3a\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u5f00\u6e90\u6846\u67b6\uff0c\u4e3a\u4ece\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u6587\u672c\u8fdb\u884c\u7ed3\u5c40\u9884\u6d4b\u63d0\u4f9b\u4e86\u51c6\u786e\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02530", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02530", "abs": "https://arxiv.org/abs/2512.02530", "authors": ["Yuxiang He", "Jian Zhao", "Yuchen Yuan", "Tianle Zhang", "Wei Cai", "Haojie Cheng", "Ziyan Shi", "Ming Zhu", "Haichuan Tang", "Chi Zhang", "Xuelong Li"], "title": "Aetheria: A multimodal interpretable content safety framework based on multi-agent debate and collaboration", "comment": "https://github.com/Herrieson/Aetheria", "summary": "The exponential growth of digital content presents significant challenges for content safety. Current moderation systems, often based on single models or fixed pipelines, exhibit limitations in identifying implicit risks and providing interpretable judgment processes. To address these issues, we propose Aetheria, a multimodal interpretable content safety framework based on multi-agent debate and collaboration.Employing a collaborative architecture of five core agents, Aetheria conducts in-depth analysis and adjudication of multimodal content through a dynamic, mutually persuasive debate mechanism, which is grounded by RAG-based knowledge retrieval.Comprehensive experiments on our proposed benchmark (AIR-Bench) validate that Aetheria not only generates detailed and traceable audit reports but also demonstrates significant advantages over baselines in overall content safety accuracy, especially in the identification of implicit risks. This framework establishes a transparent and interpretable paradigm, significantly advancing the field of trustworthy AI content moderation.", "AI": {"tldr": "Aetheria\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u4e0e\u534f\u4f5c\u7684\u591a\u6a21\u6001\u53ef\u89e3\u91ca\u5185\u5bb9\u5b89\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u4e94\u4e2a\u6838\u5fc3\u667a\u80fd\u4f53\u7684\u534f\u4f5c\u67b6\u6784\uff0c\u7ed3\u5408RAG\u77e5\u8bc6\u68c0\u7d22\uff0c\u5b9e\u73b0\u6df1\u5ea6\u5206\u6790\u548c\u88c1\u51b3\uff0c\u663e\u8457\u63d0\u5347\u5185\u5bb9\u5b89\u5168\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728\u9690\u5f0f\u98ce\u9669\u8bc6\u522b\u65b9\u9762\u3002", "motivation": "\u6570\u5b57\u5185\u5bb9\u7684\u6307\u6570\u589e\u957f\u7ed9\u5185\u5bb9\u5b89\u5168\u5e26\u6765\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u5355\u4e00\u6a21\u578b\u6216\u56fa\u5b9a\u6d41\u6c34\u7ebf\u7684\u5ba1\u6838\u7cfb\u7edf\u5728\u8bc6\u522b\u9690\u5f0f\u98ce\u9669\u548c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u5224\u65ad\u8fc7\u7a0b\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faAetheria\u6846\u67b6\uff0c\u91c7\u7528\u4e94\u4e2a\u6838\u5fc3\u667a\u80fd\u4f53\u7684\u534f\u4f5c\u67b6\u6784\uff0c\u901a\u8fc7\u52a8\u6001\u7684\u76f8\u4e92\u8bf4\u670d\u8fa9\u8bba\u673a\u5236\u5bf9\u591a\u6a21\u6001\u5185\u5bb9\u8fdb\u884c\u6df1\u5ea6\u5206\u6790\u548c\u88c1\u51b3\uff0c\u57fa\u4e8eRAG\u7684\u77e5\u8bc6\u68c0\u7d22\u63d0\u4f9b\u652f\u6301\u3002", "result": "\u5728\u63d0\u51fa\u7684\u57fa\u51c6\u6d4b\u8bd5AIR-Bench\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u9a8c\u8bc1\uff0cAetheria\u4e0d\u4ec5\u80fd\u751f\u6210\u8be6\u7ec6\u4e14\u53ef\u8ffd\u6eaf\u7684\u5ba1\u6838\u62a5\u544a\uff0c\u800c\u4e14\u5728\u6574\u4f53\u5185\u5bb9\u5b89\u5168\u51c6\u786e\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u9690\u5f0f\u98ce\u9669\u8bc6\u522b\u65b9\u9762\u3002", "conclusion": "\u8be5\u6846\u67b6\u5efa\u7acb\u4e86\u4e00\u4e2a\u900f\u660e\u4e14\u53ef\u89e3\u91ca\u7684\u8303\u5f0f\uff0c\u663e\u8457\u63a8\u8fdb\u4e86\u53ef\u4fe1AI\u5185\u5bb9\u5ba1\u6838\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.02558", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02558", "abs": "https://arxiv.org/abs/2512.02558", "authors": ["Yufei Xiao", "Shangfei Wang"], "title": "Empathy Level Prediction in Multi-Modal Scenario with Supervisory Documentation Assistance", "comment": null, "summary": "Prevalent empathy prediction techniques primarily concentrate on a singular modality, typically textual, thus neglecting multi-modal processing capabilities. They also overlook the utilization of certain privileged information, which may encompass additional empathetic content. In response, we introduce an advanced multi-modal empathy prediction method integrating video, audio, and text information. The method comprises the Multi-Modal Empathy Prediction and Supervisory Documentation Assisted Training. We use pre-trained networks in the empathy prediction network to extract features from various modalities, followed by a cross-modal fusion. This process yields a multi-modal feature representation, which is employed to predict empathy labels. To enhance the extraction of text features, we incorporate supervisory documents as privileged information during the assisted training phase. Specifically, we apply the Latent Dirichlet Allocation model to identify potential topic distributions to constrain text features. These supervisory documents, created by supervisors, focus on the counseling topics and the counselor's display of empathy. Notably, this privileged information is only available during training and is not accessible during the prediction phase. Experimental results on the multi-modal and dialogue empathy datasets demonstrate that our approach is superior to the existing methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u878d\u5408\u89c6\u9891\u3001\u97f3\u9891\u548c\u6587\u672c\u7684\u591a\u6a21\u6001\u5171\u60c5\u9884\u6d4b\u65b9\u6cd5\uff0c\u5229\u7528\u76d1\u7763\u6587\u6863\u4f5c\u4e3a\u7279\u6743\u4fe1\u606f\u589e\u5f3a\u8bad\u7ec3\u6548\u679c", "motivation": "\u73b0\u6709\u5171\u60c5\u9884\u6d4b\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5355\u4e00\u6a21\u6001\uff08\u901a\u5e38\u662f\u6587\u672c\uff09\uff0c\u5ffd\u7565\u4e86\u591a\u6a21\u6001\u5904\u7406\u80fd\u529b\uff0c\u4e5f\u6ca1\u6709\u5145\u5206\u5229\u7528\u7279\u6743\u4fe1\u606f\uff08\u5982\u989d\u5916\u7684\u5171\u60c5\u5185\u5bb9\uff09", "method": "1. \u591a\u6a21\u6001\u5171\u60c5\u9884\u6d4b\uff1a\u4f7f\u7528\u9884\u8bad\u7ec3\u7f51\u7edc\u63d0\u53d6\u89c6\u9891\u3001\u97f3\u9891\u548c\u6587\u672c\u7279\u5f81\uff0c\u8fdb\u884c\u8de8\u6a21\u6001\u878d\u5408\u5f97\u5230\u591a\u6a21\u6001\u7279\u5f81\u8868\u793a\uff1b2. \u76d1\u7763\u6587\u6863\u8f85\u52a9\u8bad\u7ec3\uff1a\u5728\u8bad\u7ec3\u9636\u6bb5\u5f15\u5165\u76d1\u7763\u6587\u6863\u4f5c\u4e3a\u7279\u6743\u4fe1\u606f\uff0c\u4f7f\u7528LDA\u6a21\u578b\u8bc6\u522b\u6f5c\u5728\u4e3b\u9898\u5206\u5e03\u6765\u7ea6\u675f\u6587\u672c\u7279\u5f81", "result": "\u5728\u591a\u6a21\u6001\u548c\u5bf9\u8bdd\u5171\u60c5\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "conclusion": "\u63d0\u51fa\u7684\u591a\u6a21\u6001\u5171\u60c5\u9884\u6d4b\u65b9\u6cd5\u6709\u6548\u6574\u5408\u4e86\u591a\u79cd\u6a21\u6001\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u76d1\u7763\u6587\u6863\u8f85\u52a9\u8bad\u7ec3\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4e3a\u5171\u60c5\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.02589", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02589", "abs": "https://arxiv.org/abs/2512.02589", "authors": ["Junyi Hou", "Andre Lin Huikai", "Nuo Chen", "Yiwei Gong", "Bingsheng He"], "title": "PaperDebugger: A Plugin-Based Multi-Agent System for In-Editor Academic Writing, Review, and Editing", "comment": null, "summary": "Large language models are increasingly embedded into academic writing workflows, yet existing assistants remain external to the editor, preventing deep interaction with document state, structure, and revision history. This separation makes it impossible to support agentic, context-aware operations directly within LaTeX editors such as Overleaf. We present PaperDebugger, an in-editor, multi-agent, and plugin-based academic writing assistant that brings LLM-driven reasoning directly into the writing environment. Enabling such in-editor interaction is technically non-trivial: it requires reliable bidirectional synchronization with the editor, fine-grained version control and patching, secure state management, multi-agent scheduling, and extensible communication with external tools. PaperDebugger addresses these challenges through a Chrome-approved extension, a Kubernetes-native orchestration layer, and a Model Context Protocol (MCP) toolchain that integrates literature search, reference lookup, document scoring, and revision pipelines. Our demo showcases a fully integrated workflow, including localized edits, structured reviews, parallel agent execution, and diff-based updates, encapsulated within a minimal-intrusion user interface (UI). Early aggregated analytics demonstrate active user engagement and validate the practicality of an editor-native, agentic writing assistant. More details about this demo and video could be found at https://github.com/PaperDebugger/PaperDebugger.", "AI": {"tldr": "PaperDebugger\uff1a\u4e00\u4e2a\u57fa\u4e8e\u591a\u4ee3\u7406\u7684LaTeX\u7f16\u8f91\u5668\u63d2\u4ef6\uff0c\u5c06LLM\u9a71\u52a8\u7684\u5b66\u672f\u5199\u4f5c\u52a9\u624b\u76f4\u63a5\u96c6\u6210\u5230Overleaf\u7b49\u7f16\u8f91\u73af\u5883\u4e2d\uff0c\u652f\u6301\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6587\u6863\u64cd\u4f5c\u548c\u7248\u672c\u63a7\u5236\u3002", "motivation": "\u73b0\u6709AI\u5199\u4f5c\u52a9\u624b\u4e0e\u7f16\u8f91\u5668\u5206\u79bb\uff0c\u65e0\u6cd5\u6df1\u5ea6\u4ea4\u4e92\u6587\u6863\u72b6\u6001\u3001\u7ed3\u6784\u548c\u4fee\u8ba2\u5386\u53f2\uff0c\u9650\u5236\u4e86\u5728LaTeX\u7f16\u8f91\u5668\u4e2d\u8fdb\u884c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4ee3\u7406\u64cd\u4f5c\u3002", "method": "\u901a\u8fc7Chrome\u6269\u5c55\u3001Kubernetes\u539f\u751f\u7f16\u6392\u5c42\u548c\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u5de5\u5177\u94fe\uff0c\u5b9e\u73b0\u53ef\u9760\u7684\u53cc\u5411\u540c\u6b65\u3001\u7ec6\u7c92\u5ea6\u7248\u672c\u63a7\u5236\u3001\u5b89\u5168\u72b6\u6001\u7ba1\u7406\u3001\u591a\u4ee3\u7406\u8c03\u5ea6\u548c\u5916\u90e8\u5de5\u5177\u96c6\u6210\u3002", "result": "\u5f00\u53d1\u4e86\u5b8c\u5168\u96c6\u6210\u7684\u5de5\u4f5c\u6d41\u6f14\u793a\uff0c\u5305\u62ec\u672c\u5730\u5316\u7f16\u8f91\u3001\u7ed3\u6784\u5316\u8bc4\u5ba1\u3001\u5e76\u884c\u4ee3\u7406\u6267\u884c\u548c\u57fa\u4e8e\u5dee\u5f02\u7684\u66f4\u65b0\uff0c\u65e9\u671f\u805a\u5408\u5206\u6790\u663e\u793a\u79ef\u6781\u7684\u7528\u6237\u53c2\u4e0e\u5ea6\u3002", "conclusion": "PaperDebugger\u9a8c\u8bc1\u4e86\u7f16\u8f91\u5668\u539f\u751f\u3001\u4ee3\u7406\u5f0f\u5199\u4f5c\u52a9\u624b\u7684\u5b9e\u7528\u6027\uff0c\u4e3a\u5b66\u672f\u5199\u4f5c\u63d0\u4f9b\u4e86\u6df1\u5ea6\u96c6\u6210\u7684AI\u8f85\u52a9\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02605", "categories": ["cs.AI", "cs.MA", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02605", "abs": "https://arxiv.org/abs/2512.02605", "authors": ["Pengju Lu"], "title": "IACT: A Self-Organizing Recursive Model for General AI Agents: A Technical White Paper on the Architecture Behind kragent.ai", "comment": "13 pages, 2 figures, 1 table", "summary": "This technical white paper introduces the Interactive Agents Call Tree (IACT), a computational model designed to address the limitations of static, hard-coded agent workflows. Unlike traditional systems that require pre-defined graphs or specialized programming, IACT operates as a general-purpose autonomous system driven purely by user dialogue. Given a high-level objective, the system autonomously grows a dynamic, recursive agent topology incrementally tailored to the problem's structure. This allows it to scale its organizational complexity to match open-ended tasks. To mitigate the error propagation inherent in unidirectional function calls, IACT introduces interactional redundancy by replacing rigid invocations with bidirectional, stateful dialogues. This mechanism enables runtime error correction and ambiguity resolution. We describe the architecture, design principles, and practical lessons behind the production deployment of this model in the kragent.ai system, presenting qualitative evidence from real-world workflows rather than exhaustive benchmark results.", "AI": {"tldr": "IACT\u662f\u4e00\u4e2a\u901a\u8fc7\u7528\u6237\u5bf9\u8bdd\u9a71\u52a8\u7684\u901a\u7528\u81ea\u4e3b\u7cfb\u7edf\uff0c\u80fd\u591f\u52a8\u6001\u751f\u6210\u9012\u5f52\u4ee3\u7406\u62d3\u6251\u7ed3\u6784\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u9884\u5b9a\u4e49\u5de5\u4f5c\u6d41\uff0c\u5b9e\u73b0\u8fd0\u884c\u65f6\u9519\u8bef\u7ea0\u6b63\u548c\u6a21\u7cca\u6027\u89e3\u51b3\u3002", "motivation": "\u89e3\u51b3\u9759\u6001\u786c\u7f16\u7801\u4ee3\u7406\u5de5\u4f5c\u6d41\u7684\u5c40\u9650\u6027\uff0c\u4f20\u7edf\u7cfb\u7edf\u9700\u8981\u9884\u5b9a\u4e49\u56fe\u6216\u4e13\u95e8\u7f16\u7a0b\uff0c\u65e0\u6cd5\u7075\u6d3b\u9002\u5e94\u5f00\u653e\u4efb\u52a1\u3002", "method": "\u57fa\u4e8e\u7528\u6237\u5bf9\u8bdd\u9a71\u52a8\uff0c\u81ea\u4e3b\u6784\u5efa\u52a8\u6001\u9012\u5f52\u4ee3\u7406\u62d3\u6251\u7ed3\u6784\uff0c\u91c7\u7528\u53cc\u5411\u6709\u72b6\u6001\u5bf9\u8bdd\u66ff\u4ee3\u5355\u5411\u51fd\u6570\u8c03\u7528\uff0c\u5b9e\u73b0\u4ea4\u4e92\u5197\u4f59\u548c\u8fd0\u884c\u65f6\u9519\u8bef\u7ea0\u6b63\u3002", "result": "\u5728kragent.ai\u7cfb\u7edf\u4e2d\u6210\u529f\u90e8\u7f72\uff0c\u901a\u8fc7\u5b9e\u9645\u5de5\u4f5c\u6d41\u5c55\u793a\u5176\u80fd\u529b\uff0c\u800c\u975e\u4f9d\u8d56\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u3002", "conclusion": "IACT\u6a21\u578b\u80fd\u591f\u6839\u636e\u95ee\u9898\u7ed3\u6784\u52a8\u6001\u6269\u5c55\u7ec4\u7ec7\u590d\u6742\u6027\uff0c\u6709\u6548\u7f13\u89e3\u9519\u8bef\u4f20\u64ad\uff0c\u4e3a\u5f00\u653e\u4efb\u52a1\u63d0\u4f9b\u7075\u6d3b\u7684\u81ea\u4e3b\u7cfb\u7edf\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02610", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02610", "abs": "https://arxiv.org/abs/2512.02610", "authors": ["Yubo Hou", "Mohamed Ragab", "Min Wu", "Chee-Keong Kwoh", "Xiaoli Li", "Zhenghua Chen"], "title": "Target-specific Adaptation and Consistent Degradation Alignment for Cross-Domain Remaining Useful Life Prediction", "comment": null, "summary": "Accurate prediction of the Remaining Useful Life (RUL) in machinery can significantly diminish maintenance costs, enhance equipment up-time, and mitigate adverse outcomes. Data-driven RUL prediction techniques have demonstrated commendable performance. However, their efficacy often relies on the assumption that training and testing data are drawn from the same distribution or domain, which does not hold in real industrial settings. To mitigate this domain discrepancy issue, prior adversarial domain adaptation methods focused on deriving domain-invariant features. Nevertheless, they overlook target-specific information and inconsistency characteristics pertinent to the degradation stages, resulting in suboptimal performance. To tackle these issues, we propose a novel domain adaptation approach for cross-domain RUL prediction named TACDA. Specifically, we propose a target domain reconstruction strategy within the adversarial adaptation process, thereby retaining target-specific information while learning domain-invariant features. Furthermore, we develop a novel clustering and pairing strategy for consistent alignment between similar degradation stages. Through extensive experiments, our results demonstrate the remarkable performance of our proposed TACDA method, surpassing state-of-the-art approaches with regard to two different evaluation metrics. Our code is available at https://github.com/keyplay/TACDA.", "AI": {"tldr": "\u63d0\u51faTACDA\u65b9\u6cd5\u7528\u4e8e\u8de8\u57df\u5269\u4f59\u4f7f\u7528\u5bff\u547d\u9884\u6d4b\uff0c\u901a\u8fc7\u76ee\u6807\u57df\u91cd\u6784\u7b56\u7565\u4fdd\u7559\u76ee\u6807\u7279\u5b9a\u4fe1\u606f\uff0c\u5e76\u91c7\u7528\u805a\u7c7b\u914d\u5bf9\u7b56\u7565\u5b9e\u73b0\u9000\u5316\u9636\u6bb5\u4e00\u81f4\u6027\u5bf9\u9f50\uff0c\u663e\u8457\u63d0\u5347\u8de8\u57df\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u9a71\u52a8\u7684RUL\u9884\u6d4b\u65b9\u6cd5\u5047\u8bbe\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u6765\u81ea\u76f8\u540c\u5206\u5e03\uff0c\u4f46\u5b9e\u9645\u5de5\u4e1a\u73af\u5883\u4e2d\u5b58\u5728\u57df\u5dee\u5f02\u95ee\u9898\u3002\u5148\u524d\u5bf9\u6297\u57df\u9002\u5e94\u65b9\u6cd5\u4ec5\u5173\u6ce8\u57df\u4e0d\u53d8\u7279\u5f81\uff0c\u5ffd\u7565\u4e86\u76ee\u6807\u7279\u5b9a\u4fe1\u606f\u548c\u9000\u5316\u9636\u6bb5\u7684\u4e00\u81f4\u6027\u7279\u5f81\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u63d0\u51faTACDA\u65b9\u6cd5\uff1a1\uff09\u5728\u5bf9\u6297\u9002\u5e94\u8fc7\u7a0b\u4e2d\u5f15\u5165\u76ee\u6807\u57df\u91cd\u6784\u7b56\u7565\uff0c\u5728\u5b66\u4e60\u57df\u4e0d\u53d8\u7279\u5f81\u7684\u540c\u65f6\u4fdd\u7559\u76ee\u6807\u7279\u5b9a\u4fe1\u606f\uff1b2\uff09\u5f00\u53d1\u805a\u7c7b\u914d\u5bf9\u7b56\u7565\uff0c\u5728\u76f8\u4f3c\u9000\u5316\u9636\u6bb5\u4e4b\u95f4\u8fdb\u884c\u4e00\u81f4\u6027\u5bf9\u9f50\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\uff0cTACDA\u65b9\u6cd5\u5728\u4e24\u79cd\u4e0d\u540c\u8bc4\u4f30\u6307\u6807\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u8de8\u57dfRUL\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "TACDA\u65b9\u6cd5\u901a\u8fc7\u76ee\u6807\u57df\u91cd\u6784\u548c\u9000\u5316\u9636\u6bb5\u4e00\u81f4\u6027\u5bf9\u9f50\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u57dfRUL\u9884\u6d4b\u4e2d\u7684\u57df\u5dee\u5f02\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02633", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02633", "abs": "https://arxiv.org/abs/2512.02633", "authors": ["Mattia Giuri", "Mathias Jackermeier", "Alessandro Abate"], "title": "Zero-Shot Instruction Following in RL via Structured LTL Representations", "comment": "ICML 2025 Workshop on Programmatic Representations for Agent Learning", "summary": "Linear temporal logic (LTL) is a compelling framework for specifying complex, structured tasks for reinforcement learning (RL) agents. Recent work has shown that interpreting LTL instructions as finite automata, which can be seen as high-level programs monitoring task progress, enables learning a single generalist policy capable of executing arbitrary instructions at test time. However, existing approaches fall short in environments where multiple high-level events (i.e., atomic propositions) can be true at the same time and potentially interact in complicated ways. In this work, we propose a novel approach to learning a multi-task policy for following arbitrary LTL instructions that addresses this shortcoming. Our method conditions the policy on sequences of simple Boolean formulae, which directly align with transitions in the automaton, and are encoded via a graph neural network (GNN) to yield structured task representations. Experiments in a complex chess-based environment demonstrate the advantages of our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7f16\u7801\u5e03\u5c14\u516c\u5f0f\u5e8f\u5217\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b66\u4e60\u9075\u5faa\u4efb\u610fLTL\u6307\u4ee4\u7684\u591a\u4efb\u52a1\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u4e2a\u9ad8\u5c42\u4e8b\u4ef6\u540c\u65f6\u53d1\u751f\u4e14\u590d\u6742\u4ea4\u4e92\u73af\u5883\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u5c06LTL\u6307\u4ee4\u89e3\u91ca\u4e3a\u6709\u9650\u81ea\u52a8\u673a\u7684\u65b9\u6cd5\u5728\u591a\u4e2a\u539f\u5b50\u547d\u9898\u540c\u65f6\u4e3a\u771f\u4e14\u53ef\u80fd\u590d\u6742\u4ea4\u4e92\u7684\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u6539\u8fdb\u591a\u4efb\u52a1\u7b56\u7565\u5b66\u4e60\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7b80\u5355\u5e03\u5c14\u516c\u5f0f\u5e8f\u5217\u7684\u7b56\u7565\u6761\u4ef6\u5316\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u516c\u5f0f\u76f4\u63a5\u5bf9\u5e94\u81ea\u52a8\u673a\u4e2d\u7684\u8f6c\u79fb\uff0c\u5e76\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u7f16\u7801\u4ee5\u4ea7\u751f\u7ed3\u6784\u5316\u4efb\u52a1\u8868\u793a\u3002", "result": "\u5728\u590d\u6742\u7684\u57fa\u4e8e\u8c61\u68cb\u7684\u73af\u5883\u4e2d\u8fdb\u884c\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u591a\u4e2a\u9ad8\u5c42\u4e8b\u4ef6\u540c\u65f6\u53d1\u751f\u4e14\u590d\u6742\u4ea4\u4e92\u7684\u73af\u5883\uff0c\u4e3a\u9075\u5faa\u4efb\u610fLTL\u6307\u4ee4\u7684\u591a\u4efb\u52a1\u7b56\u7565\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02677", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02677", "abs": "https://arxiv.org/abs/2512.02677", "authors": ["Zhiyuan He"], "title": "Exploring Depth Generalization in Large Language Models for Solving Recursive Logic Tasks", "comment": null, "summary": "Large language models have demonstrated remarkable capabilities across many tasks, yet face significant challenges when dealing with recursive reasoning problems, those requiring the resolution of nested hierarchical structures. While prior research has extensively studied length generalization (a model's ability to handle longer sequences than seen during training), we investigate a distinct and underexplored limitation: depth generalization. Here, depth refers to the number of nested levels in a hierarchical problem, such as the layers of parentheses in a mathematical expression or the nesting of logical clauses in a Boolean formula. Our work reveals that standard transformer architectures struggle with problems involving deeper recursion than encountered during training, even when they perform well on longer but non-nested sequences. This limitation stems from their inability to maintain stack-like behavior, the capacity to track and resolve multiple levels of nested dependencies. Through systematic analysis, we demonstrate how this architectural constraint leads to rapid performance decay as the depth of the recursion increases. To address this challenge, we develop a novel looped locate-and-replace pipeline that decomposes recursive problems into manageable subcomponents. The approach employs two specialized models: a locator that identifies solvable subexpressions and a replacer that evaluates these components while preserving the overall structure. We evaluated this method in three carefully designed domains: Boolean algebra, recursive arithmetic, and propositional logic, each with a controllable depth of recursion. We show that our method effectively alleviates the performance decay when tested on out-of-distribution recursion depth.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53d1\u73b0\u6807\u51c6Transformer\u6a21\u578b\u5728\u5904\u7406\u6df1\u5ea6\u9012\u5f52\u63a8\u7406\u95ee\u9898\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5373\u4f7f\u5b83\u4eec\u80fd\u5904\u7406\u66f4\u957f\u7684\u5e8f\u5217\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5faa\u73af\u5b9a\u4f4d\u66ff\u6362\u7ba1\u9053\u65b9\u6cd5\u6765\u89e3\u51b3\u6df1\u5ea6\u6cdb\u5316\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bb8\u591a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5904\u7406\u9012\u5f52\u63a8\u7406\u95ee\u9898\uff08\u9700\u8981\u89e3\u51b3\u5d4c\u5957\u5c42\u6b21\u7ed3\u6784\u7684\u95ee\u9898\uff09\u65f6\u9762\u4e34\u6311\u6218\u3002\u5148\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u957f\u5ea6\u6cdb\u5316\uff0c\u800c\u672c\u6587\u7814\u7a76\u4e00\u4e2a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u9650\u5236\uff1a\u6df1\u5ea6\u6cdb\u5316\uff0c\u5373\u6a21\u578b\u5904\u7406\u6bd4\u8bad\u7ec3\u65f6\u66f4\u6df1\u5d4c\u5957\u5c42\u6b21\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5faa\u73af\u5b9a\u4f4d\u66ff\u6362\u7ba1\u9053\u65b9\u6cd5\uff0c\u5c06\u9012\u5f52\u95ee\u9898\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u7684\u5b50\u7ec4\u4ef6\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u4e24\u4e2a\u4e13\u95e8\u6a21\u578b\uff1a\u5b9a\u4f4d\u5668\u8bc6\u522b\u53ef\u89e3\u7684\u5b50\u8868\u8fbe\u5f0f\uff0c\u66ff\u6362\u5668\u8bc4\u4f30\u8fd9\u4e9b\u7ec4\u4ef6\u540c\u65f6\u4fdd\u6301\u6574\u4f53\u7ed3\u6784\u3002", "result": "\u5728\u5e03\u5c14\u4ee3\u6570\u3001\u9012\u5f52\u7b97\u672f\u548c\u547d\u9898\u903b\u8f91\u4e09\u4e2a\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u9886\u57df\u8fdb\u884c\u8bc4\u4f30\uff0c\u6bcf\u4e2a\u9886\u57df\u90fd\u6709\u53ef\u63a7\u7684\u9012\u5f52\u6df1\u5ea6\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6d4b\u8bd5\u8d85\u51fa\u5206\u5e03\u8303\u56f4\u7684\u9012\u5f52\u6df1\u5ea6\u65f6\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u6027\u80fd\u8870\u51cf\u95ee\u9898\u3002", "conclusion": "\u6807\u51c6Transformer\u67b6\u6784\u5728\u5904\u7406\u6bd4\u8bad\u7ec3\u65f6\u66f4\u6df1\u7684\u9012\u5f52\u95ee\u9898\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u8fd9\u6e90\u4e8e\u5b83\u4eec\u65e0\u6cd5\u7ef4\u6301\u7c7b\u4f3c\u6808\u7684\u884c\u4e3a\u3002\u63d0\u51fa\u7684\u5faa\u73af\u5b9a\u4f4d\u66ff\u6362\u7ba1\u9053\u65b9\u6cd5\u4e3a\u89e3\u51b3\u6df1\u5ea6\u6cdb\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02699", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02699", "abs": "https://arxiv.org/abs/2512.02699", "authors": ["Hyeongseop Rha", "Jeong Hun Yeo", "Junil Won", "Se Jin Park", "Yong Man Ro"], "title": "Learning What to Attend First: Modality-Importance-Guided Reasoning for Reliable Multimodal Emotion Understanding", "comment": "16 pages, 8 figures", "summary": "In this paper, we present Modality-Importance-Guided Reasoning (MIGR), a framework designed to improve the reliability of reasoning-based multimodal emotion understanding in multimodal large language models. Although existing methods have advanced emotion understanding, they often suffer from reasoning drift: models gradually rely on their own generated text instead of multimodal evidence, and their explanations are overly shaped by visually initiated reasoning paths. To address these issues, we introduce Modality Importance (MI), a simple yet effective mechanism for identifying the emotion-dominant modality. Using MI, MIGR reorganizes reasoning sequences so that explanations begin from the modality most critical to the target emotion, preventing early reasoning from being misled by less informative cues. Our two-stage framework-comprising modality-aligned supervised fine-tuning and modality-aware reward optimization-encourages models to generate emotionally grounded, causally relevant, and coherence-preserving explanations. Experimental results on the DFEW benchmark show that MIGR substantially improves reasoning reliability, decreasing instances of correct predictions accompanied by emotionally inconsistent explanations from 18.10% to 7.37%. These results confirm the benefit of initiating reasoning from the emotion-dominant modality.", "AI": {"tldr": "MIGR\u6846\u67b6\u901a\u8fc7\u6a21\u6001\u91cd\u8981\u6027\u5f15\u5bfc\u63a8\u7406\uff0c\u6539\u5584\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u611f\u7406\u89e3\u53ef\u9760\u6027\uff0c\u51cf\u5c11\u63a8\u7406\u6f02\u79fb\u95ee\u9898", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u63a8\u7406\u6f02\u79fb\u95ee\u9898\uff1a\u6a21\u578b\u9010\u6e10\u4f9d\u8d56\u81ea\u8eab\u751f\u6210\u7684\u6587\u672c\u800c\u975e\u591a\u6a21\u6001\u8bc1\u636e\uff0c\u4e14\u89e3\u91ca\u8fc7\u5ea6\u53d7\u89c6\u89c9\u4e3b\u5bfc\u63a8\u7406\u8def\u5f84\u5f71\u54cd\uff0c\u5bfc\u81f4\u60c5\u611f\u7406\u89e3\u4e0d\u53ef\u9760", "method": "\u5f15\u5165\u6a21\u6001\u91cd\u8981\u6027\u673a\u5236\u8bc6\u522b\u60c5\u611f\u4e3b\u5bfc\u6a21\u6001\uff0c\u636e\u6b64\u91cd\u7ec4\u63a8\u7406\u5e8f\u5217\uff0c\u4f7f\u89e3\u91ca\u4ece\u6700\u5173\u952e\u6a21\u6001\u5f00\u59cb\uff1b\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u6a21\u6001\u5bf9\u9f50\u76d1\u7763\u5fae\u8c03\u548c\u6a21\u6001\u611f\u77e5\u5956\u52b1\u4f18\u5316", "result": "\u5728DFEW\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMIGR\u663e\u8457\u63d0\u5347\u63a8\u7406\u53ef\u9760\u6027\uff0c\u5c06\u6b63\u786e\u9884\u6d4b\u4f46\u60c5\u611f\u4e0d\u4e00\u81f4\u89e3\u91ca\u7684\u6bd4\u4f8b\u4ece18.10%\u964d\u81f37.37%", "conclusion": "\u4ece\u60c5\u611f\u4e3b\u5bfc\u6a21\u6001\u5f00\u59cb\u63a8\u7406\u80fd\u6709\u6548\u6539\u5584\u591a\u6a21\u6001\u60c5\u611f\u7406\u89e3\u7684\u53ef\u9760\u6027\uff0c\u6a21\u6001\u91cd\u8981\u6027\u5f15\u5bfc\u7684\u63a8\u7406\u6846\u67b6\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2512.02713", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02713", "abs": "https://arxiv.org/abs/2512.02713", "authors": ["Theodoros Aivalis", "Iraklis A. Klampanos", "Antonis Troumpoukis", "Joemon M. Jose"], "title": "Training Data Attribution for Image Generation using Ontology-Aligned Knowledge Graphs", "comment": null, "summary": "As generative models become powerful, concerns around transparency, accountability, and copyright violations have intensified. Understanding how specific training data contributes to a model's output is critical. We introduce a framework for interpreting generative outputs through the automatic construction of ontologyaligned knowledge graphs (KGs). While automatic KG construction from natural text has advanced, extracting structured and ontology-consistent representations from visual content remains challenging -- due to the richness and multi-object nature of images. Leveraging multimodal large language models (LLMs), our method extracts structured triples from images, aligned with a domain-specific ontology. By comparing the KGs of generated and training images, we can trace potential influences, enabling copyright analysis, dataset transparency, and interpretable AI. We validate our method through experiments on locally trained models via unlearning, and on large-scale models through a style-specific experiment. Our framework supports the development of AI systems that foster human collaboration, creativity and stimulate curiosity.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u901a\u8fc7\u6784\u5efa\u672c\u4f53\u5bf9\u9f50\u77e5\u8bc6\u56fe\u8c31\u6765\u89e3\u91ca\u751f\u6210\u6a21\u578b\u8f93\u51fa\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8ffd\u8e2a\u8bad\u7ec3\u6570\u636e\u5bf9\u751f\u6210\u5185\u5bb9\u7684\u5f71\u54cd", "motivation": "\u968f\u7740\u751f\u6210\u6a21\u578b\u80fd\u529b\u589e\u5f3a\uff0c\u900f\u660e\u5ea6\u3001\u95ee\u8d23\u5236\u548c\u7248\u6743\u4fb5\u6743\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u9700\u8981\u7406\u89e3\u8bad\u7ec3\u6570\u636e\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u8f93\u51fa", "method": "\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u56fe\u50cf\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u4e09\u5143\u7ec4\uff0c\u6784\u5efa\u4e0e\u9886\u57df\u672c\u4f53\u5bf9\u9f50\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u901a\u8fc7\u6bd4\u8f83\u751f\u6210\u56fe\u50cf\u548c\u8bad\u7ec3\u56fe\u50cf\u7684KG\u6765\u8ffd\u8e2a\u6f5c\u5728\u5f71\u54cd", "result": "\u901a\u8fc7\u672c\u5730\u6a21\u578b\u53bb\u5b66\u4e60\u548c\u98ce\u683c\u7279\u5b9a\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u652f\u6301\u7248\u6743\u5206\u6790\u3001\u6570\u636e\u96c6\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91caAI", "conclusion": "\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u5f00\u53d1\u4fc3\u8fdb\u4eba\u7c7b\u534f\u4f5c\u3001\u521b\u9020\u529b\u548c\u6fc0\u53d1\u597d\u5947\u5fc3\u7684AI\u7cfb\u7edf"}}
{"id": "2512.02716", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02716", "abs": "https://arxiv.org/abs/2512.02716", "authors": ["Tianyi Zhang", "Xiangyuan Xue", "Lingyan Ruan", "Shiya Fu", "Feng Xia", "Simon D'Alfonso", "Vassilis Kostakos", "Hong Jia"], "title": "Menta: A Small Language Model for On-Device Mental Health Prediction", "comment": null, "summary": "Mental health conditions affect hundreds of millions globally, yet early detection remains limited. While large language models (LLMs) have shown promise in mental health applications, their size and computational demands hinder practical deployment. Small language models (SLMs) offer a lightweight alternative, but their use for social media--based mental health prediction remains largely underexplored. In this study, we introduce Menta, the first optimized SLM fine-tuned specifically for multi-task mental health prediction from social media data. Menta is jointly trained across six classification tasks using a LoRA-based framework, a cross-dataset strategy, and a balanced accuracy--oriented loss. Evaluated against nine state-of-the-art SLM baselines, Menta achieves an average improvement of 15.2\\% across tasks covering depression, stress, and suicidality compared with the best-performing non--fine-tuned SLMs. It also achieves higher accuracy on depression and stress classification tasks compared to 13B-parameter LLMs, while being approximately 3.25x smaller. Moreover, we demonstrate real-time, on-device deployment of Menta on an iPhone 15 Pro Max, requiring only approximately 3GB RAM. Supported by a comprehensive benchmark against existing SLMs and LLMs, Menta highlights the potential for scalable, privacy-preserving mental health monitoring. Code is available at: https://xxue752-nz.github.io/menta-project/", "AI": {"tldr": "Menta\u662f\u9996\u4e2a\u9488\u5bf9\u793e\u4ea4\u5a92\u4f53\u5fc3\u7406\u5065\u5eb7\u9884\u6d4b\u4f18\u5316\u7684\u8f7b\u91cf\u7ea7\u5c0f\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u8d85\u8d8a\u73b0\u6709SLM\u548c\u90e8\u5206LLM\uff0c\u5e76\u80fd\u5728\u79fb\u52a8\u8bbe\u5907\u5b9e\u65f6\u90e8\u7f72\u3002", "motivation": "\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u5f71\u54cd\u5168\u7403\u6570\u4ebf\u4eba\uff0c\u4f46\u65e9\u671f\u68c0\u6d4b\u4ecd\u7136\u6709\u9650\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u4e2d\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u89c4\u6a21\u548c\u8ba1\u7b97\u9700\u6c42\u963b\u788d\u4e86\u5b9e\u9645\u90e8\u7f72\u3002\u5c0f\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5728\u57fa\u4e8e\u793e\u4ea4\u5a92\u4f53\u7684\u5fc3\u7406\u5065\u5eb7\u9884\u6d4b\u65b9\u9762\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5f00\u53d1Menta\u6a21\u578b\uff0c\u91c7\u7528LoRA\u5fae\u8c03\u6846\u67b6\u3001\u8de8\u6570\u636e\u96c6\u7b56\u7565\u548c\u5e73\u8861\u51c6\u786e\u7387\u5bfc\u5411\u7684\u635f\u5931\u51fd\u6570\uff0c\u5728\u516d\u4e2a\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fdb\u884c\u8054\u5408\u8bad\u7ec3\uff0c\u4e13\u95e8\u7528\u4e8e\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u7684\u5fc3\u7406\u5065\u5eb7\u9884\u6d4b\u3002", "result": "Menta\u5728\u6291\u90c1\u3001\u538b\u529b\u548c\u81ea\u6740\u503e\u5411\u7b49\u4efb\u52a1\u4e0a\u6bd4\u6700\u4f73\u975e\u5fae\u8c03SLM\u5e73\u5747\u63d0\u534715.2%\uff0c\u5728\u6291\u90c1\u548c\u538b\u529b\u5206\u7c7b\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u8d85\u8fc7130\u4ebf\u53c2\u6570LLM\uff0c\u6a21\u578b\u5927\u5c0f\u7ea6\u4e3a\u51761/3.25\u3002\u80fd\u5728iPhone 15 Pro Max\u4e0a\u5b9e\u65f6\u90e8\u7f72\uff0c\u4ec5\u9700\u7ea63GB\u5185\u5b58\u3002", "conclusion": "Menta\u5c55\u793a\u4e86\u8f7b\u91cf\u7ea7\u6a21\u578b\u5728\u53ef\u6269\u5c55\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u5fc3\u7406\u5065\u5eb7\u76d1\u6d4b\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2512.02720", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02720", "abs": "https://arxiv.org/abs/2512.02720", "authors": ["He Wang", "Wenyilin Xiao", "Songqiao Han", "Hailiang Huang"], "title": "StockMem: An Event-Reflection Memory Framework for Stock Forecasting", "comment": null, "summary": "Stock price prediction is challenging due to market volatility and its sensitivity to real-time events. While large language models (LLMs) offer new avenues for text-based forecasting, their application in finance is hindered by noisy news data and the lack of explicit answers in text. General-purpose memory architectures struggle to identify the key drivers of price movements. To address this, we propose StockMem, an event-reflection dual-layer memory framework. It structures news into events and mines them along two dimensions: horizontal consolidation integrates daily events, while longitudinal tracking captures event evolution to extract incremental information reflecting market expectation discrepancies. This builds a temporal event knowledge base. By analyzing event-price dynamics, the framework further forms a reflection knowledge base of causal experiences. For prediction, it retrieves analogous historical scenarios and reasons with current events, incremental data, and past experiences. Experiments show StockMem outperforms existing memory architectures and provides superior, explainable reasoning by tracing the information chain affecting prices, enhancing decision transparency in financial forecasting.", "AI": {"tldr": "StockMem\uff1a\u57fa\u4e8e\u4e8b\u4ef6-\u53cd\u601d\u53cc\u5c42\u8bb0\u5fc6\u6846\u67b6\u7684\u80a1\u7968\u4ef7\u683c\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u65b0\u95fb\u4e8b\u4ef6\u548c\u8ffd\u8e2a\u4e8b\u4ef6\u6f14\u5316\u6765\u63d0\u53d6\u5e02\u573a\u9884\u671f\u5dee\u5f02\u4fe1\u606f\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u91d1\u878d\u9884\u6d4b\u3002", "motivation": "\u80a1\u7968\u4ef7\u683c\u9884\u6d4b\u9762\u4e34\u5e02\u573a\u6ce2\u52a8\u6027\u548c\u5b9e\u65f6\u4e8b\u4ef6\u654f\u611f\u6027\u7684\u6311\u6218\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u57fa\u4e8e\u6587\u672c\u7684\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u4f46\u5728\u91d1\u878d\u9886\u57df\u7684\u5e94\u7528\u53d7\u5230\u566a\u58f0\u65b0\u95fb\u6570\u636e\u548c\u6587\u672c\u4e2d\u7f3a\u4e4f\u660e\u786e\u7b54\u6848\u7684\u9650\u5236\u3002\u901a\u7528\u8bb0\u5fc6\u67b6\u6784\u96be\u4ee5\u8bc6\u522b\u4ef7\u683c\u53d8\u52a8\u7684\u5173\u952e\u9a71\u52a8\u56e0\u7d20\u3002", "method": "\u63d0\u51faStockMem\u4e8b\u4ef6-\u53cd\u601d\u53cc\u5c42\u8bb0\u5fc6\u6846\u67b6\uff1a1\uff09\u5c06\u65b0\u95fb\u7ed3\u6784\u5316\u5904\u7406\u4e3a\u4e8b\u4ef6\uff1b2\uff09\u6a2a\u5411\u6574\u5408\u6bcf\u65e5\u4e8b\u4ef6\uff1b3\uff09\u7eb5\u5411\u8ffd\u8e2a\u4e8b\u4ef6\u6f14\u5316\u4ee5\u63d0\u53d6\u53cd\u6620\u5e02\u573a\u9884\u671f\u5dee\u5f02\u7684\u589e\u91cf\u4fe1\u606f\uff0c\u6784\u5efa\u65f6\u5e8f\u4e8b\u4ef6\u77e5\u8bc6\u5e93\uff1b4\uff09\u901a\u8fc7\u5206\u6790\u4e8b\u4ef6-\u4ef7\u683c\u52a8\u6001\u5f62\u6210\u56e0\u679c\u7ecf\u9a8c\u7684\u53cd\u601d\u77e5\u8bc6\u5e93\uff1b5\uff09\u9884\u6d4b\u65f6\u68c0\u7d22\u7c7b\u4f3c\u5386\u53f2\u573a\u666f\uff0c\u7ed3\u5408\u5f53\u524d\u4e8b\u4ef6\u3001\u589e\u91cf\u6570\u636e\u548c\u8fc7\u5f80\u7ecf\u9a8c\u8fdb\u884c\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660eStockMem\u4f18\u4e8e\u73b0\u6709\u8bb0\u5fc6\u67b6\u6784\uff0c\u901a\u8fc7\u8ffd\u8e2a\u5f71\u54cd\u4ef7\u683c\u7684\u4fe1\u606f\u94fe\u63d0\u4f9b\u66f4\u4f18\u4e14\u53ef\u89e3\u91ca\u7684\u63a8\u7406\uff0c\u589e\u5f3a\u4e86\u91d1\u878d\u9884\u6d4b\u7684\u51b3\u7b56\u900f\u660e\u5ea6\u3002", "conclusion": "StockMem\u6846\u67b6\u901a\u8fc7\u4e8b\u4ef6\u7ed3\u6784\u5316\u548c\u6f14\u5316\u8ffd\u8e2a\u6709\u6548\u89e3\u51b3\u4e86\u91d1\u878d\u65b0\u95fb\u6570\u636e\u566a\u58f0\u95ee\u9898\uff0c\u6784\u5efa\u7684\u53cc\u5c42\u8bb0\u5fc6\u7cfb\u7edf\u80fd\u591f\u8bc6\u522b\u4ef7\u683c\u53d8\u52a8\u7684\u5173\u952e\u9a71\u52a8\u56e0\u7d20\uff0c\u4e3a\u80a1\u7968\u9884\u6d4b\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u4e14\u900f\u660e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02726", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02726", "abs": "https://arxiv.org/abs/2512.02726", "authors": ["Md Abdul Kadir", "Sai Suresh Macharla Vasu", "Sidharth S. Nair", "Daniel Sonntag"], "title": "AuditCopilot: Leveraging LLMs for Fraud Detection in Double-Entry Bookkeeping", "comment": null, "summary": "Auditors rely on Journal Entry Tests (JETs) to detect anomalies in tax-related ledger records, but rule-based methods generate overwhelming false positives and struggle with subtle irregularities. We investigate whether large language models (LLMs) can serve as anomaly detectors in double-entry bookkeeping. Benchmarking SoTA LLMs such as LLaMA and Gemma on both synthetic and real-world anonymized ledgers, we compare them against JETs and machine learning baselines. Our results show that LLMs consistently outperform traditional rule-based JETs and classical ML baselines, while also providing natural-language explanations that enhance interpretability. These results highlight the potential of \\textbf{AI-augmented auditing}, where human auditors collaborate with foundation models to strengthen financial integrity.", "AI": {"tldr": "LLMs\u5728\u590d\u5f0f\u8bb0\u8d26\u5f02\u5e38\u68c0\u6d4b\u4e2d\u8d85\u8d8a\u4f20\u7edf\u89c4\u5219\u65b9\u6cd5\u548c\u673a\u5668\u5b66\u4e60\u57fa\u7ebf\uff0c\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u652f\u6301AI\u589e\u5f3a\u5ba1\u8ba1", "motivation": "\u4f20\u7edf\u65e5\u8bb0\u8d26\u6d4b\u8bd5\uff08JETs\uff09\u4ea7\u751f\u5927\u91cf\u8bef\u62a5\u4e14\u96be\u4ee5\u68c0\u6d4b\u7ec6\u5fae\u5f02\u5e38\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u5ba1\u8ba1\u65b9\u6cd5", "method": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u533f\u540d\u8d26\u672c\u4e0a\u5bf9LLaMA\u3001Gemma\u7b49\u6700\u5148\u8fdbLLMs\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e0e\u4f20\u7edfJETs\u548c\u673a\u5668\u5b66\u4e60\u57fa\u7ebf\u6bd4\u8f83", "result": "LLMs\u5728\u5f02\u5e38\u68c0\u6d4b\u4e2d\u6301\u7eed\u4f18\u4e8e\u4f20\u7edf\u89c4\u5219\u65b9\u6cd5\u548c\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u57fa\u7ebf\uff0c\u540c\u65f6\u63d0\u4f9b\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca", "conclusion": "LLMs\u5c55\u793a\u4e86AI\u589e\u5f3a\u5ba1\u8ba1\u7684\u6f5c\u529b\uff0c\u4eba\u7c7b\u5ba1\u8ba1\u5e08\u4e0e\u57fa\u7840\u6a21\u578b\u534f\u4f5c\u53ef\u52a0\u5f3a\u8d22\u52a1\u5b8c\u6574\u6027"}}
{"id": "2512.02731", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02731", "abs": "https://arxiv.org/abs/2512.02731", "authors": ["Przemyslaw Chojecki"], "title": "Self-Improving AI Agents through Self-Play", "comment": null, "summary": "We extend the moduli-theoretic framework of psychometric batteries to the domain of dynamical systems. While previous work established the AAI capability score as a static functional on the space of agent representations, this paper formalizes the agent as a flow $\u03bd_r$ parameterized by computational resource $r$, governed by a recursive Generator-Verifier-Updater (GVU) operator. We prove that this operator generates a vector field on the parameter manifold $\u0398$, and we identify the coefficient of self-improvement $\u03ba$ as the Lie derivative of the capability functional along this flow.\n  The central contribution of this work is the derivation of the Variance Inequality, a spectral condition that is sufficient (under mild regularity) for the stability of self-improvement. We show that a sufficient condition for $\u03ba> 0$ is that, up to curvature and step-size effects, the combined noise of generation and verification must be small enough.\n  We then apply this formalism to unify the recent literature on Language Self-Play (LSP), Self-Correction, and Synthetic Data bootstrapping. We demonstrate that architectures such as STaR, SPIN, Reflexion, GANs and AlphaZero are specific topological realizations of the GVU operator that satisfy the Variance Inequality through filtration, adversarial discrimination, or grounding in formal systems.", "AI": {"tldr": "\u5c06\u5fc3\u7406\u6d4b\u91cf\u7535\u6c60\u7684\u6a21\u6570\u7406\u8bba\u6846\u67b6\u6269\u5c55\u5230\u52a8\u529b\u7cfb\u7edf\u9886\u57df\uff0c\u5c06\u667a\u80fd\u4f53\u5f62\u5f0f\u5316\u4e3a\u7531\u8ba1\u7b97\u8d44\u6e90\u53c2\u6570\u5316\u7684\u6d41\uff0c\u63a8\u5bfc\u51fa\u4fdd\u8bc1\u81ea\u6211\u6539\u8fdb\u7a33\u5b9a\u6027\u7684\u65b9\u5dee\u4e0d\u7b49\u5f0f\u6761\u4ef6\uff0c\u5e76\u7edf\u4e00\u4e86\u8fd1\u671f\u8bed\u8a00\u81ea\u6211\u535a\u5f08\u3001\u81ea\u6211\u7ea0\u6b63\u548c\u5408\u6210\u6570\u636e\u5f15\u5bfc\u7b49\u7814\u7a76\u3002", "motivation": "\u73b0\u6709AAI\u80fd\u529b\u8bc4\u5206\u662f\u667a\u80fd\u4f53\u8868\u793a\u7a7a\u95f4\u4e0a\u7684\u9759\u6001\u6cdb\u51fd\uff0c\u9700\u8981\u5c06\u5176\u6269\u5c55\u5230\u52a8\u529b\u7cfb\u7edf\u9886\u57df\uff0c\u4ee5\u5f62\u5f0f\u5316\u667a\u80fd\u4f53\u968f\u8ba1\u7b97\u8d44\u6e90\u6f14\u5316\u7684\u81ea\u6211\u6539\u8fdb\u8fc7\u7a0b\u3002", "method": "\u5c06\u667a\u80fd\u4f53\u5f62\u5f0f\u5316\u4e3a\u53c2\u6570\u5316\u6d41\u03bd_r\uff0c\u7531\u9012\u5f52\u7684\u751f\u6210\u5668-\u9a8c\u8bc1\u5668-\u66f4\u65b0\u5668(GVU)\u7b97\u5b50\u63a7\u5236\uff0c\u8bc1\u660e\u8be5\u7b97\u5b50\u5728\u53c2\u6570\u6d41\u5f62\u0398\u4e0a\u751f\u6210\u5411\u91cf\u573a\uff0c\u5c06\u81ea\u6211\u6539\u8fdb\u7cfb\u6570\u03ba\u5b9a\u4e49\u4e3a\u80fd\u529b\u6cdb\u51fd\u6cbf\u8be5\u6d41\u7684\u674e\u5bfc\u6570\u3002", "result": "\u63a8\u5bfc\u51fa\u65b9\u5dee\u4e0d\u7b49\u5f0f\u8fd9\u4e00\u8c31\u6761\u4ef6\uff0c\u8bc1\u660e\u5728\u6e29\u548c\u6b63\u5219\u6027\u6761\u4ef6\u4e0b\uff0c\u8be5\u6761\u4ef6\u8db3\u4ee5\u4fdd\u8bc1\u81ea\u6211\u6539\u8fdb\u7684\u7a33\u5b9a\u6027\u3002\u03ba>0\u7684\u5145\u5206\u6761\u4ef6\u662f\u751f\u6210\u548c\u9a8c\u8bc1\u7684\u7ec4\u5408\u566a\u58f0\u8db3\u591f\u5c0f\uff08\u8003\u8651\u66f2\u7387\u548c\u6b65\u957f\u6548\u5e94\uff09\u3002", "conclusion": "\u8be5\u5f62\u5f0f\u5316\u6846\u67b6\u7edf\u4e00\u4e86\u8bed\u8a00\u81ea\u6211\u535a\u5f08\u3001\u81ea\u6211\u7ea0\u6b63\u548c\u5408\u6210\u6570\u636e\u5f15\u5bfc\u7b49\u8fd1\u671f\u7814\u7a76\uff0c\u8868\u660eSTaR\u3001SPIN\u3001Reflexion\u3001GANs\u548cAlphaZero\u7b49\u67b6\u6784\u90fd\u662f\u6ee1\u8db3\u65b9\u5dee\u4e0d\u7b49\u5f0f\u7684GVU\u7b97\u5b50\u7684\u5177\u4f53\u62d3\u6251\u5b9e\u73b0\u3002"}}
{"id": "2512.02735", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02735", "abs": "https://arxiv.org/abs/2512.02735", "authors": ["Anna Rodum Bj\u00f8ru", "Jacob Lysn\u00e6s-Larsen", "Oskar J\u00f8rgensen", "Inga Str\u00fcmke", "Helge Langseth"], "title": "A Framework for Causal Concept-based Model Explanations", "comment": null, "summary": "This work presents a conceptual framework for causal concept-based post-hoc Explainable Artificial Intelligence (XAI), based on the requirements that explanations for non-interpretable models should be understandable as well as faithful to the model being explained. Local and global explanations are generated by calculating the probability of sufficiency of concept interventions. Example explanations are presented, generated with a proof-of-concept model made to explain classifiers trained on the CelebA dataset. Understandability is demonstrated through a clear concept-based vocabulary, subject to an implicit causal interpretation. Fidelity is addressed by highlighting important framework assumptions, stressing that the context of explanation interpretation must align with the context of explanation generation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56e0\u679c\u6982\u5ff5\u7684\u540e\u53ef\u89e3\u91caAI\u6846\u67b6\uff0c\u901a\u8fc7\u6982\u5ff5\u5e72\u9884\u7684\u5145\u5206\u6982\u7387\u751f\u6210\u5c40\u90e8\u548c\u5168\u5c40\u89e3\u91ca\uff0c\u5728CelebA\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u5f3a\u8c03\u89e3\u91ca\u7684\u53ef\u7406\u89e3\u6027\u548c\u5bf9\u6a21\u578b\u7684\u5fe0\u5b9e\u6027", "motivation": "\u9488\u5bf9\u975e\u53ef\u89e3\u91ca\u6a21\u578b\u9700\u8981\u65e2\u6613\u4e8e\u7406\u89e3\u53c8\u5fe0\u5b9e\u4e8e\u539f\u6a21\u578b\u7684\u89e3\u91ca\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u8fd9\u4e24\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u5efa\u7acb\u6982\u5ff5\u5316\u3001\u56e0\u679c\u5316\u7684\u89e3\u91ca\u6846\u67b6", "method": "\u57fa\u4e8e\u56e0\u679c\u6982\u5ff5\u7684\u540e\u53ef\u89e3\u91caAI\u6846\u67b6\uff0c\u901a\u8fc7\u8ba1\u7b97\u6982\u5ff5\u5e72\u9884\u7684\u5145\u5206\u6982\u7387\u751f\u6210\u5c40\u90e8\u548c\u5168\u5c40\u89e3\u91ca\uff0c\u4f7f\u7528\u6982\u5ff5\u5316\u8bcd\u6c47\u8868\uff0c\u5728CelebA\u6570\u636e\u96c6\u4e0a\u6784\u5efa\u6982\u5ff5\u9a8c\u8bc1\u6a21\u578b", "result": "\u5728CelebA\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u793a\u4f8b\u89e3\u91ca\uff0c\u8bc1\u660e\u4e86\u6846\u67b6\u7684\u53ef\u7406\u89e3\u6027\uff08\u901a\u8fc7\u6e05\u6670\u7684\u6982\u5ff5\u8bcd\u6c47\uff09\u548c\u5fe0\u5b9e\u6027\uff08\u901a\u8fc7\u5f3a\u8c03\u6846\u67b6\u5047\u8bbe\u548c\u89e3\u91ca\u4e0a\u4e0b\u6587\u5bf9\u9f50\uff09", "conclusion": "\u63d0\u51fa\u7684\u56e0\u679c\u6982\u5ff5\u540e\u89e3\u91ca\u6846\u67b6\u80fd\u591f\u4e3a\u4e0d\u53ef\u89e3\u91ca\u6a21\u578b\u63d0\u4f9b\u65e2\u6613\u4e8e\u7406\u89e3\u53c8\u5fe0\u5b9e\u4e8e\u6a21\u578b\u7684\u89e3\u91ca\uff0c\u5173\u952e\u5728\u4e8e\u89e3\u91ca\u751f\u6210\u548c\u89e3\u91ca\u89e3\u91ca\u7684\u4e0a\u4e0b\u6587\u5fc5\u987b\u4fdd\u6301\u4e00\u81f4"}}
{"id": "2512.02812", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02812", "abs": "https://arxiv.org/abs/2512.02812", "authors": ["Zijie Lin", "Qilin Cai", "Liang Shen", "Mingjun Xiao"], "title": "Enhancing Automated Paper Reproduction via Prompt-Free Collaborative Agents", "comment": null, "summary": "Automated paper reproduction has emerged as a promising approach to accelerate scientific research, employing multi-step workflow frameworks to systematically convert academic papers into executable code. However, existing frameworks often lack mechanisms to verify and refine the outputs at each generation step, or rely heavily on manually designed prompts for self-refinement, which limits their adaptability and scalability. To address these limitations, we propose a prompt-free collaborative agent framework that automatically enhances the quality of paper-to-code generation. Our approach employs two collaborative agents: a verification agent that examines whether the outputs at each step satisfy the requirements specified in the corresponding system prompt, and a refinement agent that revises the outputs based on the identified issues. Unlike previous methods that require human experts to craft specific refinement prompts for each step, our framework achieves automatic verification and improvement by leveraging only the original system prompts. We integrate our collaborative agents into the Paper2Code framework and conduct comprehensive experiments on PaperBench Code-Dev and Paper2CodeBench datasets. Experimental results demonstrate that our approach significantly improves the accuracy and completeness of reproduced code, achieving performance gains of approximately 15\\% and 13\\%, respectively, compared to the baseline without our agents. Furthermore, comparative experiments against Self-Refine validate the robustness and consistency of our prompt-free approach across different datasets.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u63d0\u793a\u534f\u4f5c\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u9a8c\u8bc1\u548c\u7cbe\u70bc\u4ee3\u7406\u81ea\u52a8\u63d0\u5347\u8bba\u6587\u5230\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u76f8\u6bd4\u57fa\u7ebf\u63d0\u5347\u7ea615%\u51c6\u786e\u7387\u548c13%\u5b8c\u6574\u6027\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u8bba\u6587\u590d\u73b0\u6846\u67b6\u7f3a\u4e4f\u5bf9\u751f\u6210\u8fc7\u7a0b\u5404\u6b65\u9aa4\u8f93\u51fa\u7684\u9a8c\u8bc1\u548c\u7cbe\u70bc\u673a\u5236\uff0c\u6216\u8fc7\u5ea6\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7684\u63d0\u793a\u8fdb\u884c\u81ea\u6211\u7cbe\u70bc\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u65e0\u63d0\u793a\u534f\u4f5c\u4ee3\u7406\u6846\u67b6\uff0c\u5305\u542b\u9a8c\u8bc1\u4ee3\u7406\uff08\u68c0\u67e5\u5404\u6b65\u9aa4\u8f93\u51fa\u662f\u5426\u6ee1\u8db3\u7cfb\u7edf\u63d0\u793a\u8981\u6c42\uff09\u548c\u7cbe\u70bc\u4ee3\u7406\uff08\u57fa\u4e8e\u8bc6\u522b\u95ee\u9898\u4fee\u8ba2\u8f93\u51fa\uff09\uff0c\u4ec5\u5229\u7528\u539f\u59cb\u7cfb\u7edf\u63d0\u793a\u5b9e\u73b0\u81ea\u52a8\u9a8c\u8bc1\u548c\u6539\u8fdb\u3002", "result": "\u5728PaperBench Code-Dev\u548cPaper2CodeBench\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u65e0\u4ee3\u7406\u57fa\u7ebf\uff0c\u51c6\u786e\u7387\u63d0\u5347\u7ea615%\uff0c\u5b8c\u6574\u6027\u63d0\u5347\u7ea613%\u3002\u4e0eSelf-Refine\u5bf9\u6bd4\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u548c\u4e00\u81f4\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65e0\u63d0\u793a\u534f\u4f5c\u4ee3\u7406\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u8bba\u6587\u5230\u4ee3\u7801\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u5b8c\u6574\u6027\uff0c\u65e0\u9700\u4eba\u5de5\u8bbe\u8ba1\u7cbe\u70bc\u63d0\u793a\uff0c\u5177\u6709\u66f4\u597d\u7684\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2512.02814", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02814", "abs": "https://arxiv.org/abs/2512.02814", "authors": ["Yongrui Yu", "Zhongzhen Huang", "Linjie Mu", "Shaoting Zhang", "Xiaofan Zhang"], "title": "Radiologist Copilot: An Agentic Assistant with Orchestrated Tools for Radiology Reporting with Quality Control", "comment": null, "summary": "Radiology reporting is an essential yet time-consuming and error-prone task for radiologists in clinical examinations, especially for volumetric medical images. Rigorous quality control is also critical but tedious, ensuring that the final report meets clinical standards. Existing automated approaches, including radiology report generation methods and medical vision-language models, focus mainly on the report generation phase and neglect the crucial quality control procedure, limiting their capability to provide comprehensive support to radiologists. We propose Radiologist Copilot, an agentic AI assistant equipped with orchestrated tools designed for automated radiology reporting with quality control. Leveraging large language models as the reasoning backbone, the agentic system autonomously selects tools, plans, and executes actions, emulating the behavior of radiologists throughout the holistic radiology reporting process. The orchestrated tools include region localization, think with image paradigm directed region analysis planning, strategic template selection for report generation, quality assessment and feedback-driven adaptive refinement for quality control. Therefore, Radiologist Copilot facilitates accurate, complete, and efficient radiology reporting, assisting radiologists and improving clinical efficiency. Experimental results demonstrate that Radiologist Copilot significantly surpasses other state-of-the-art methods in radiology reporting. The source code will be released upon acceptance.", "AI": {"tldr": "Radiologist Copilot\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u7f16\u6392\u591a\u79cd\u5de5\u5177\u5b9e\u73b0\u81ea\u52a8\u5316\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210\u4e0e\u8d28\u91cf\u63a7\u5236\uff0c\u6a21\u62df\u653e\u5c04\u79d1\u533b\u751f\u5b8c\u6574\u5de5\u4f5c\u6d41\u7a0b\uff0c\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u653e\u5c04\u5b66\u62a5\u544a\u64b0\u5199\u8017\u65f6\u4e14\u6613\u51fa\u9519\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u62a5\u544a\u751f\u6210\u9636\u6bb5\uff0c\u5ffd\u89c6\u4e86\u5173\u952e\u7684\u8d28\u91cf\u63a7\u5236\u73af\u8282\uff0c\u65e0\u6cd5\u4e3a\u653e\u5c04\u79d1\u533b\u751f\u63d0\u4f9b\u5168\u9762\u652f\u6301\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u63a8\u7406\u6838\u5fc3\uff0c\u6784\u5efa\u667a\u80fd\u4f53\u7cfb\u7edf\u81ea\u4e3b\u9009\u62e9\u5de5\u5177\u3001\u89c4\u5212\u548c\u6267\u884c\u52a8\u4f5c\u3002\u7f16\u6392\u7684\u5de5\u5177\u5305\u62ec\uff1a\u533a\u57df\u5b9a\u4f4d\u3001\u57fa\u4e8e\"\u56fe\u50cf\u601d\u7ef4\u8303\u5f0f\"\u7684\u533a\u57df\u5206\u6790\u89c4\u5212\u3001\u6218\u7565\u6a21\u677f\u9009\u62e9\u62a5\u544a\u751f\u6210\u3001\u8d28\u91cf\u8bc4\u4f30\u548c\u53cd\u9988\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u7cbe\u70bc\u8d28\u91cf\u63a7\u5236\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRadiologist Copilot\u5728\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210\u65b9\u9762\u663e\u8457\u8d85\u8d8a\u4e86\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "Radiologist Copilot\u80fd\u591f\u4fc3\u8fdb\u51c6\u786e\u3001\u5b8c\u6574\u3001\u9ad8\u6548\u7684\u653e\u5c04\u5b66\u62a5\u544a\u64b0\u5199\uff0c\u534f\u52a9\u653e\u5c04\u79d1\u533b\u751f\u5e76\u63d0\u9ad8\u4e34\u5e8a\u6548\u7387\u3002\u6e90\u4ee3\u7801\u5c06\u5728\u63a5\u53d7\u540e\u53d1\u5e03\u3002"}}
{"id": "2512.02879", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02879", "abs": "https://arxiv.org/abs/2512.02879", "authors": ["Jef Caers"], "title": "The future of AI in critical mineral exploration", "comment": null, "summary": "The energy transition through increased electrification has put the worlds attention on critical mineral exploration Even with increased investments a decrease in new discoveries has taken place over the last two decades Here I propose a solution to this problem where AI is implemented as the enabler of a rigorous scientific method for mineral exploration that aims to reduce cognitive bias and false positives drive down the cost of exploration I propose a new scientific method that is based on a philosophical approach founded on the principles of Bayesianism and falsification In this approach data acquisition is in the first place seen as a means to falsify human generated hypothesis Decision of what data to acquire next is quantified with verifiable metrics and based on rational decision making A practical protocol is provided that can be used as a template in any exploration campaign However in order to make this protocol practical various form of artificial intelligence are needed I will argue that the most important form are one novel unsupervised learning methods that collaborate with domain experts to better understand data and generate multiple competing geological hypotheses and two humanintheloop AI algorithms that can optimally plan various geological geophysical geochemical and drilling data acquisition where uncertainty reduction of geological hypothesis precedes the uncertainty reduction on grade and tonnage", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8d1d\u53f6\u65af\u4e3b\u4e49\u548c\u8bc1\u4f2a\u539f\u5219\u7684AI\u9a71\u52a8\u79d1\u5b66\u65b9\u6cd5\uff0c\u7528\u4e8e\u51cf\u5c11\u8ba4\u77e5\u504f\u5dee\u3001\u964d\u4f4e\u52d8\u63a2\u6210\u672c\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u5b66\u4e60\u548c\u4eba\u5728\u73afAI\u4f18\u5316\u6570\u636e\u91c7\u96c6\u51b3\u7b56", "motivation": "\u5c3d\u7ba1\u6295\u8d44\u589e\u52a0\uff0c\u4f46\u8fc7\u53bb20\u5e74\u65b0\u77ff\u4ea7\u53d1\u73b0\u51cf\u5c11\uff0c\u9700\u8981\u89e3\u51b3\u8ba4\u77e5\u504f\u5dee\u548c\u5047\u9633\u6027\u95ee\u9898\uff0c\u964d\u4f4e\u52d8\u63a2\u6210\u672c", "method": "\u57fa\u4e8e\u8d1d\u53f6\u65af\u4e3b\u4e49\u548c\u8bc1\u4f2a\u539f\u5219\u7684\u54f2\u5b66\u65b9\u6cd5\uff0c\u5c06\u6570\u636e\u91c7\u96c6\u89c6\u4e3a\u8bc1\u4f2a\u4eba\u7c7b\u5047\u8bbe\u7684\u624b\u6bb5\uff0c\u4f7f\u7528\u53ef\u9a8c\u8bc1\u6307\u6807\u91cf\u5316\u6570\u636e\u91c7\u96c6\u51b3\u7b56\uff0c\u63d0\u51fa\u5305\u542b\u65e0\u76d1\u7763\u5b66\u4e60\uff08\u751f\u6210\u7ade\u4e89\u5730\u8d28\u5047\u8bbe\uff09\u548c\u4eba\u5728\u73afAI\uff08\u4f18\u5316\u5730\u8d28\u3001\u5730\u7403\u7269\u7406\u3001\u5730\u7403\u5316\u5b66\u548c\u94bb\u63a2\u6570\u636e\u91c7\u96c6\uff09\u7684\u5b9e\u7528\u534f\u8bae", "result": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u5728\u4efb\u4f55\u52d8\u63a2\u6d3b\u52a8\u4e2d\u4f7f\u7528\u7684\u6a21\u677f\u534f\u8bae\uff0c\u901a\u8fc7AI\u51cf\u5c11\u8ba4\u77e5\u504f\u5dee\u548c\u5047\u9633\u6027\uff0c\u964d\u4f4e\u52d8\u63a2\u6210\u672c", "conclusion": "AI\u80fd\u591f\u5b9e\u73b0\u4e25\u683c\u7684\u79d1\u5b66\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u4e3b\u4e49\u548c\u8bc1\u4f2a\u539f\u5219\u4f18\u5316\u77ff\u4ea7\u52d8\u63a2\uff0c\u5730\u8d28\u5047\u8bbe\u7684\u4e0d\u786e\u5b9a\u6027\u964d\u4f4e\u4f18\u5148\u4e8e\u54c1\u4f4d\u548c\u50a8\u91cf\u4e0d\u786e\u5b9a\u6027\u964d\u4f4e"}}
{"id": "2512.02914", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02914", "abs": "https://arxiv.org/abs/2512.02914", "authors": ["Zhonghao He", "Tianyi Qiu", "Hirokazu Shirado", "Maarten Sap"], "title": "Martingale Score: An Unsupervised Metric for Bayesian Rationality in LLM Reasoning", "comment": "NeurIPS 2025", "summary": "Recent advances in reasoning techniques have substantially improved the performance of large language models (LLMs), raising expectations for their ability to provide accurate, truthful, and reliable information. However, emerging evidence suggests that iterative reasoning may foster belief entrenchment and confirmation bias, rather than enhancing truth-seeking behavior. In this study, we propose a systematic evaluation framework for belief entrenchment in LLM reasoning by leveraging the Martingale property from Bayesian statistics. This property implies that, under rational belief updating, the expected value of future beliefs should remain equal to the current belief, i.e., belief updates are unpredictable from the current belief. We propose the unsupervised, regression-based Martingale Score to measure violations of this property, which signal deviation from the Bayesian ability of updating on new evidence. In open-ended problem domains including event forecasting, value-laden questions, and academic paper review, we find such violations to be widespread across models and setups, where the current belief positively predicts future belief updates, a phenomenon which we term belief entrenchment. We identify the models, reasoning techniques, and domains more prone to belief entrenchment. Finally, we validate the Martingale Score by showing that it predicts ground-truth accuracy on problem domains where ground truth labels are available. This indicates that, while designed as an unsupervised metric that operates even in domains without access to ground truth, the Martingale Score is a useful proxy of the truth-seeking ability of a reasoning process.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9785\u6027\u8d28\u7684\u65e0\u76d1\u7763\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u4fe1\u5ff5\u56fa\u5316\u73b0\u8c61\uff0c\u53d1\u73b0\u8fed\u4ee3\u63a8\u7406\u53ef\u80fd\u5bfc\u81f4\u786e\u8ba4\u504f\u8bef\u800c\u975e\u771f\u76f8\u5bfb\u6c42\u884c\u4e3a\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u6709\u6240\u63d0\u5347\uff0c\u4f46\u8fed\u4ee3\u63a8\u7406\u53ef\u80fd\u5f3a\u5316\u4fe1\u5ff5\u56fa\u5316\u548c\u786e\u8ba4\u504f\u8bef\uff0c\u800c\u975e\u589e\u5f3a\u771f\u76f8\u5bfb\u6c42\u884c\u4e3a\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30LLM\u63a8\u7406\u4e2d\u7684\u4fe1\u5ff5\u56fa\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8d1d\u53f6\u65af\u7edf\u8ba1\u4e2d\u9785\u6027\u8d28\u7684\u65e0\u76d1\u7763\u8bc4\u4f30\u6846\u67b6\uff0c\u5229\u7528\u56de\u5f52\u65b9\u6cd5\u8ba1\u7b97\u9785\u5206\u6570\u6765\u8861\u91cf\u4fe1\u5ff5\u66f4\u65b0\u662f\u5426\u8fdd\u53cd\u7406\u6027\u66f4\u65b0\u539f\u5219\uff0c\u4ece\u800c\u68c0\u6d4b\u4fe1\u5ff5\u56fa\u5316\u73b0\u8c61\u3002", "result": "\u5728\u4e8b\u4ef6\u9884\u6d4b\u3001\u4ef7\u503c\u8d1f\u8f7d\u95ee\u9898\u548c\u5b66\u672f\u8bba\u6587\u8bc4\u5ba1\u7b49\u591a\u4e2a\u5f00\u653e\u9886\u57df\uff0c\u53d1\u73b0\u4fe1\u5ff5\u56fa\u5316\u73b0\u8c61\u666e\u904d\u5b58\u5728\uff0c\u5f53\u524d\u4fe1\u5ff5\u6b63\u5411\u9884\u6d4b\u672a\u6765\u4fe1\u5ff5\u66f4\u65b0\u3002\u9785\u5206\u6570\u80fd\u9884\u6d4b\u6709\u6807\u7b7e\u9886\u57df\u7684\u771f\u5b9e\u51c6\u786e\u6027\u3002", "conclusion": "\u4fe1\u5ff5\u56fa\u5316\u5728LLM\u63a8\u7406\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u9785\u5206\u6570\u4f5c\u4e3a\u65e0\u76d1\u7763\u6307\u6807\u80fd\u6709\u6548\u8bc4\u4f30\u63a8\u7406\u8fc7\u7a0b\u7684\u771f\u76f8\u5bfb\u6c42\u80fd\u529b\uff0c\u4e3a\u7406\u89e3\u548c\u6539\u8fdbLLM\u63a8\u7406\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2512.03001", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03001", "abs": "https://arxiv.org/abs/2512.03001", "authors": ["Thomas Rivasseau"], "title": "Invasive Context Engineering to Control Large Language Models", "comment": "4 pages", "summary": "Current research on operator control of Large Language Models improves model robustness against adversarial attacks and misbehavior by training on preference examples, prompting, and input/output filtering. Despite good results, LLMs remain susceptible to abuse, and jailbreak probability increases with context length. There is a need for robust LLM security guarantees in long-context situations. We propose control sentences inserted into the LLM context as invasive context engineering to partially solve the problem. We suggest this technique can be generalized to the Chain-of-Thought process to prevent scheming. Invasive Context Engineering does not rely on LLM training, avoiding data shortage pitfalls which arise in training models for long context situations.", "AI": {"tldr": "\u63d0\u51fa\u4fb5\u5165\u5f0f\u4e0a\u4e0b\u6587\u5de5\u7a0b\uff0c\u901a\u8fc7\u63d2\u5165\u63a7\u5236\u8bed\u53e5\u6765\u589e\u5f3aLLM\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e0b\u7684\u5b89\u5168\u6027\uff0c\u9632\u6b62\u8d8a\u72f1\u548c\u6076\u610f\u884c\u4e3a", "motivation": "\u5f53\u524dLLM\u5b89\u5168\u7814\u7a76\u867d\u7136\u901a\u8fc7\u504f\u597d\u8bad\u7ec3\u3001\u63d0\u793a\u5de5\u7a0b\u548c\u8f93\u5165\u8f93\u51fa\u8fc7\u6ee4\u63d0\u9ad8\u4e86\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u4f46LLM\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u653b\u51fb\uff0c\u4e14\u8d8a\u72f1\u6982\u7387\u968f\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u52a0\u800c\u589e\u52a0\uff0c\u9700\u8981\u4e3a\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u63d0\u4f9b\u66f4\u5f3a\u7684\u5b89\u5168\u4fdd\u8bc1", "method": "\u63d0\u51fa\u4fb5\u5165\u5f0f\u4e0a\u4e0b\u6587\u5de5\u7a0b\u6280\u672f\uff0c\u5728LLM\u4e0a\u4e0b\u6587\u4e2d\u63d2\u5165\u63a7\u5236\u8bed\u53e5\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4f9d\u8d56LLM\u8bad\u7ec3\uff0c\u907f\u514d\u4e86\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e0b\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e76\u53ef\u63a8\u5e7f\u5230\u601d\u7ef4\u94fe\u8fc7\u7a0b\u4e2d\u9632\u6b62\u7b56\u7565\u6027\u6b3a\u9a97", "result": "\u8be5\u65b9\u6cd5\u7406\u8bba\u4e0a\u80fd\u591f\u90e8\u5206\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587LLM\u7684\u5b89\u5168\u95ee\u9898\uff0c\u63d0\u4f9b\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5f3a\u7684\u5b89\u5168\u4fdd\u8bc1", "conclusion": "\u4fb5\u5165\u5f0f\u4e0a\u4e0b\u6587\u5de5\u7a0b\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684LLM\u5b89\u5168\u589e\u5f3a\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u957f\u4e0a\u4e0b\u6587\u573a\u666f\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u63a7\u5236\u800c\u975e\u6a21\u578b\u8bad\u7ec3\u6765\u63d0\u9ad8\u5b89\u5168\u6027"}}
{"id": "2512.03005", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03005", "abs": "https://arxiv.org/abs/2512.03005", "authors": ["Dawei Li", "Abdullah Alnaibari", "Arslan Bisharat", "Manny Sandoval", "Deborah Hall", "Yasin Silva", "Huan Liu"], "title": "From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?", "comment": "Under review", "summary": "The rapid advancement of large language models (LLMs) has opened new possibilities for AI for good applications. As LLMs increasingly mediate online communication, their potential to foster empathy and constructive dialogue becomes an important frontier for responsible AI research. This work explores whether LLMs can serve not only as moderators that detect harmful content, but as mediators capable of understanding and de-escalating online conflicts. Our framework decomposes mediation into two subtasks: judgment, where an LLM evaluates the fairness and emotional dynamics of a conversation, and steering, where it generates empathetic, de-escalatory messages to guide participants toward resolution. To assess mediation quality, we construct a large Reddit-based dataset and propose a multi-stage evaluation pipeline combining principle-based scoring, user simulation, and human comparison. Experiments show that API-based models outperform open-source counterparts in both reasoning and intervention alignment when doing mediation. Our findings highlight both the promise and limitations of current LLMs as emerging agents for online social mediation.", "AI": {"tldr": "LLMs\u53ef\u4f5c\u4e3a\u5728\u7ebf\u51b2\u7a81\u8c03\u89e3\u5458\uff0c\u901a\u8fc7\u5224\u65ad\u5bf9\u8bdd\u516c\u5e73\u6027\u548c\u60c5\u611f\u52a8\u6001\uff0c\u5e76\u751f\u6210\u5171\u60c5\u4fe1\u606f\u5f15\u5bfc\u89e3\u51b3\u51b2\u7a81\uff0cAPI\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\u3002", "motivation": "\u968f\u7740LLMs\u8d8a\u6765\u8d8a\u591a\u5730\u4ecb\u5165\u5728\u7ebf\u6c9f\u901a\uff0c\u7814\u7a76\u5b83\u4eec\u80fd\u5426\u4fc3\u8fdb\u5171\u60c5\u548c\u5efa\u8bbe\u6027\u5bf9\u8bdd\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u68c0\u6d4b\u6709\u5bb3\u5185\u5bb9\uff0c\u6210\u4e3a\u8d1f\u8d23\u4efbAI\u7814\u7a76\u7684\u91cd\u8981\u524d\u6cbf\u3002", "method": "\u5c06\u8c03\u89e3\u5206\u89e3\u4e3a\u4e24\u4e2a\u5b50\u4efb\u52a1\uff1a\u5224\u65ad\uff08\u8bc4\u4f30\u5bf9\u8bdd\u516c\u5e73\u6027\u548c\u60c5\u611f\u52a8\u6001\uff09\u548c\u5f15\u5bfc\uff08\u751f\u6210\u5171\u60c5\u3001\u7f13\u548c\u7684\u4fe1\u606f\uff09\u3002\u6784\u5efa\u5927\u578bReddit\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u591a\u9636\u6bb5\u8bc4\u4f30\u6d41\u7a0b\uff0c\u7ed3\u5408\u539f\u5219\u8bc4\u5206\u3001\u7528\u6237\u6a21\u62df\u548c\u4eba\u5de5\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAPI\u6a21\u578b\u5728\u63a8\u7406\u548c\u5e72\u9884\u5bf9\u9f50\u65b9\u9762\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\u3002LLMs\u5728\u5728\u7ebf\u793e\u4ea4\u8c03\u89e3\u65b9\u9762\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u4e5f\u5b58\u5728\u5c40\u9650\u6027\u3002", "conclusion": "\u5f53\u524dLLMs\u4f5c\u4e3a\u5728\u7ebf\u793e\u4ea4\u8c03\u89e3\u65b0\u5174\u4ee3\u7406\u65e2\u6709\u524d\u666f\u4e5f\u6709\u5c40\u9650\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u5347\u5176\u8c03\u89e3\u80fd\u529b\u3002"}}
