{"id": "2512.03096", "categories": ["cs.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.03096", "abs": "https://arxiv.org/abs/2512.03096", "authors": ["Daniel Alarc\u00f3n-Mart\u00edn", "Mari Carmen Aguayo-Torres", "Francisco J. Mart\u00edn-Vega", "Gerardo G\u00f3mez"], "title": "CFO-Robust Detection for 5G PRACH under Fading Channels: Analytical Modeling and Performance Evaluation", "comment": "13 pages, 11 figures, journal", "summary": "The Physical Random Access Channel (PRACH) is essential for initial access and synchronization in both 5G and future 6G networks; however, its detection is highly sensitive to impairments such as high user density, large carrier frequency offset (CFO), and fast fading. Although prior studies have examined PRACH detection, they are often restricted to specific scenarios or lack a comprehensive analytical characterization of performance. We introduce a unified analytical framework that characterizes the statistical distribution of the received power delay profile (PDP) under flat Rayleigh fading and supports both coherent combining (CC) and power combining (PC) repetition strategies. For each strategy, we derive optimal threshold expressions and closed-form detection probabilities. Furthermore, we analyze two key cases depending on the coherence time: identical and independent channel realizations per repetition. Secondly, we exploit the correlation induced by CFO across cyclic shifts to design a novel low-complexity detector that exploits PDP dependencies. Numerical results indicate that PC outperforms CC when repetitions experience independent channels, while CC can be preferable under identical realizations in limited settings. On the other hand, the proposed CFO-aware detector delivers improved robustness under severe CFO conditions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684PRACH\u68c0\u6d4b\u5206\u6790\u6846\u67b6\uff0c\u63a8\u5bfc\u4e86\u76f8\u5e72\u5408\u5e76\u4e0e\u529f\u7387\u5408\u5e76\u7b56\u7565\u7684\u7edf\u8ba1\u5206\u5e03\u548c\u6700\u4f18\u9608\u503c\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5229\u7528CFO\u76f8\u5173\u6027\u7684\u4f4e\u590d\u6742\u5ea6\u68c0\u6d4b\u5668\u3002", "motivation": "PRACH\u68c0\u6d4b\u5bf9\u9ad8\u7528\u6237\u5bc6\u5ea6\u3001\u5927\u8f7d\u6ce2\u9891\u7387\u504f\u79fb\u548c\u5feb\u901f\u8870\u843d\u7b49\u635f\u4f24\u9ad8\u5ea6\u654f\u611f\uff0c\u73b0\u6709\u7814\u7a76\u8981\u4e48\u5c40\u9650\u4e8e\u7279\u5b9a\u573a\u666f\uff0c\u8981\u4e48\u7f3a\u4e4f\u5168\u9762\u7684\u6027\u80fd\u5206\u6790\u8868\u5f81\u3002", "method": "1) \u5efa\u7acb\u7edf\u4e00\u5206\u6790\u6846\u67b6\uff0c\u5728\u5e73\u5766\u745e\u5229\u8870\u843d\u4e0b\u8868\u5f81\u63a5\u6536\u529f\u7387\u5ef6\u8fdf\u5256\u9762\u7684\u7edf\u8ba1\u5206\u5e03\uff0c\u652f\u6301\u76f8\u5e72\u5408\u5e76\u548c\u529f\u7387\u5408\u5e76\u91cd\u590d\u7b56\u7565\uff1b2) \u63a8\u5bfc\u6bcf\u79cd\u7b56\u7565\u7684\u6700\u4f18\u9608\u503c\u8868\u8fbe\u5f0f\u548c\u95ed\u5f0f\u68c0\u6d4b\u6982\u7387\uff1b3) \u5206\u6790\u76f8\u5e72\u65f6\u95f4\u76f8\u5173\u7684\u4e24\u79cd\u5173\u952e\u60c5\u51b5\uff1b4) \u5229\u7528CFO\u5728\u5faa\u73af\u79fb\u4f4d\u4e2d\u5f15\u8d77\u7684\u76f8\u5173\u6027\u8bbe\u8ba1\u65b0\u578b\u4f4e\u590d\u6742\u5ea6\u68c0\u6d4b\u5668\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff1a\u5728\u72ec\u7acb\u4fe1\u9053\u6761\u4ef6\u4e0b\u529f\u7387\u5408\u5e76\u4f18\u4e8e\u76f8\u5e72\u5408\u5e76\uff0c\u800c\u5728\u76f8\u540c\u5b9e\u73b0\u6761\u4ef6\u4e0b\u76f8\u5e72\u5408\u5e76\u53ef\u80fd\u66f4\u4f18\uff1b\u63d0\u51fa\u7684CFO\u611f\u77e5\u68c0\u6d4b\u5668\u5728\u4e25\u91cdCFO\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aPRACH\u68c0\u6d4b\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u5206\u6790\u6846\u67b6\u548c\u4f18\u5316\u7b56\u7565\uff0c\u7279\u522b\u662f\u5728\u9ad8CFO\u6761\u4ef6\u4e0b\u63d0\u51fa\u7684\u65b0\u578b\u68c0\u6d4b\u5668\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u4e3a5G/6G\u7f51\u7edc\u4e2d\u7684\u521d\u59cb\u63a5\u5165\u548c\u540c\u6b65\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u6848\u3002"}}
{"id": "2512.03117", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.03117", "abs": "https://arxiv.org/abs/2512.03117", "authors": ["Peijie Li", "Guangyue Han"], "title": "Strengthening Han's Fourier Entropy-Influence Inequality via an Information-Theoretic Proof", "comment": "4 pages", "summary": "We strengthen Han's Fourier entropy-influence inequality $$ H[\\widehat{f}] \\leq C_{1}I(f) + C_{2}\\sum_{i\\in [n]}I_{i}(f)\\ln\\frac{1}{I_{i}(f)} $$ originally proved for $\\{-1,1\\}$-valued Boolean functions with $C_{1}=3+2\\ln 2$ and $C_{2}=1$. We show, by a short information-theoretic proof, that it in fact holds with sharp constants $C_{1}=C_{2}=1$ for all real-valued Boolean functions of unit $L^{2}$-norm, thereby establishing the inequality as an elementary structural property of Shannon entropy and influence.", "AI": {"tldr": "\u672c\u6587\u6539\u8fdb\u4e86Han\u7684\u5085\u91cc\u53f6\u71b5-\u5f71\u54cd\u4e0d\u7b49\u5f0f\uff0c\u5c06\u5e38\u6570\u4eceC\u2081=3+2ln2\u3001C\u2082=1\u4f18\u5316\u5230C\u2081=C\u2082=1\uff0c\u9002\u7528\u4e8e\u6240\u6709\u5355\u4f4dL\u00b2\u8303\u6570\u7684\u5b9e\u503c\u5e03\u5c14\u51fd\u6570\u3002", "motivation": "Han\u7684\u5085\u91cc\u53f6\u71b5-\u5f71\u54cd\u4e0d\u7b49\u5f0f\u662f\u5e03\u5c14\u51fd\u6570\u5206\u6790\u4e2d\u7684\u91cd\u8981\u7ed3\u679c\uff0c\u4f46\u539f\u59cb\u8bc1\u660e\u4e2d\u7684\u5e38\u6570\u4e0d\u662f\u6700\u4f18\u7684\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u4fe1\u606f\u8bba\u65b9\u6cd5\u83b7\u5f97\u8be5\u4e0d\u7b49\u5f0f\u7684\u5c16\u9510\u5e38\u6570\uff0c\u63ed\u793a\u9999\u519c\u71b5\u4e0e\u5f71\u54cd\u4e4b\u95f4\u7684\u57fa\u672c\u7ed3\u6784\u5173\u7cfb\u3002", "method": "\u91c7\u7528\u7b80\u77ed\u7684\u4fe1\u606f\u8bba\u8bc1\u660e\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5b9e\u503c\u5e03\u5c14\u51fd\u6570\u7684\u5085\u91cc\u53f6\u7cfb\u6570\u4e0e\u5f71\u54cd\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u63a8\u5bfc\u51fa\u6700\u4f18\u5e38\u6570\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u5085\u91cc\u53f6\u71b5-\u5f71\u54cd\u4e0d\u7b49\u5f0f\u5728C\u2081=C\u2082=1\u65f6\u5bf9\u6240\u6709\u5355\u4f4dL\u00b2\u8303\u6570\u7684\u5b9e\u503c\u5e03\u5c14\u51fd\u6570\u6210\u7acb\uff0c\u8fd9\u662f\u8be5\u4e0d\u7b49\u5f0f\u7684\u6700\u4f18\u5e38\u6570\u3002", "conclusion": "\u8be5\u4e0d\u7b49\u5f0f\u4f5c\u4e3a\u9999\u519c\u71b5\u4e0e\u5f71\u54cd\u4e4b\u95f4\u57fa\u672c\u7ed3\u6784\u6027\u8d28\u7684\u4f53\u73b0\uff0c\u901a\u8fc7\u4fe1\u606f\u8bba\u65b9\u6cd5\u83b7\u5f97\u4e86\u5c16\u9510\u5e38\u6570\uff0c\u6df1\u5316\u4e86\u5bf9\u5e03\u5c14\u51fd\u6570\u5085\u91cc\u53f6\u5206\u6790\u7684\u7406\u89e3\u3002"}}
{"id": "2512.03241", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.03241", "abs": "https://arxiv.org/abs/2512.03241", "authors": ["Mohammad Moltafet", "Hamid R. Sadjadpour", "Zouheir Rezki", "Marian Codreanu", "Roy D. Yates"], "title": "Multi-Source M/G/1/1 Queues with Probabilistic Preemption", "comment": null, "summary": "We consider a multi-source status update system consisting of multiple independent sources, a single server, and a single sink. Each source generates packets according to a Poisson process, and packets are served according to a general service time distribution. The system has a capacity of one packet, i.e., no waiting buffer, and is modeled as a multi-source M/G/1/1 queueing system. We introduce a probabilistically preemptive packet management policy, under which an existing packet from the same source in the system is replaced by an arriving packet with a fixed probability. We derive the moment generating functions (MGFs) of the age of information (AoI) and peak AoI (PAoI) for each source under this policy. Numerical results demonstrate the effectiveness of the proposed packet management policy.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u6e90\u72b6\u6001\u66f4\u65b0\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6982\u7387\u62a2\u5360\u5f0f\u6570\u636e\u5305\u7ba1\u7406\u7b56\u7565\uff0c\u63a8\u5bfc\u4e86AoI\u548cPAoI\u7684\u77e9\u751f\u6210\u51fd\u6570\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5728\u591a\u6e90\u72b6\u6001\u66f4\u65b0\u7cfb\u7edf\u4e2d\uff0c\u5982\u4f55\u6709\u6548\u7ba1\u7406\u6570\u636e\u5305\u4ee5\u4f18\u5316\u4fe1\u606f\u5e74\u9f84(AoI)\u662f\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002\u73b0\u6709\u7cfb\u7edf\u901a\u5e38\u91c7\u7528\u5b8c\u5168\u62a2\u5360\u6216\u975e\u62a2\u5360\u7b56\u7565\uff0c\u4f46\u7f3a\u4e4f\u7075\u6d3b\u7684\u6982\u7387\u63a7\u5236\u673a\u5236\u3002", "method": "\u5c06\u7cfb\u7edf\u5efa\u6a21\u4e3a\u591a\u6e90M/G/1/1\u6392\u961f\u7cfb\u7edf\uff0c\u63d0\u51fa\u6982\u7387\u62a2\u5360\u5f0f\u6570\u636e\u5305\u7ba1\u7406\u7b56\u7565\uff1a\u5f53\u540c\u4e00\u6e90\u7684\u65b0\u6570\u636e\u5305\u5230\u8fbe\u65f6\uff0c\u4ee5\u56fa\u5b9a\u6982\u7387\u66ff\u6362\u7cfb\u7edf\u4e2d\u5df2\u6709\u7684\u540c\u6e90\u6570\u636e\u5305\u3002\u63a8\u5bfc\u4e86\u6bcf\u4e2a\u6e90\u7684\u4fe1\u606f\u5e74\u9f84(AoI)\u548c\u5cf0\u503c\u4fe1\u606f\u5e74\u9f84(PAoI)\u7684\u77e9\u751f\u6210\u51fd\u6570\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6982\u7387\u62a2\u5360\u5f0f\u6570\u636e\u5305\u7ba1\u7406\u7b56\u7565\u80fd\u591f\u6709\u6548\u4f18\u5316\u4fe1\u606f\u5e74\u9f84\u6027\u80fd\uff0c\u76f8\u6bd4\u4f20\u7edf\u7b56\u7565\u5177\u6709\u66f4\u597d\u7684\u7075\u6d3b\u6027\u3002", "conclusion": "\u6982\u7387\u62a2\u5360\u5f0f\u7b56\u7565\u4e3a\u591a\u6e90\u72b6\u6001\u66f4\u65b0\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u7684\u6570\u636e\u5305\u7ba1\u7406\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u8c03\u6574\u62a2\u5360\u6982\u7387\u6765\u5e73\u8861\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2512.03326", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.03326", "abs": "https://arxiv.org/abs/2512.03326", "authors": ["Keigo Takeuchi"], "title": "Generalized Orthogonal Approximate Message-Passing for Sublinear Sparsity", "comment": "Long version of a manuscript submitted to IEEE Trans. Inf. Theory", "summary": "This paper addresses the reconstruction of sparse signals from generalized linear measurements. Signal sparsity is assumed to be sublinear in the signal dimension while it was proportional to the signal dimension in conventional research. Approximate message-passing (AMP) has poor convergence properties for sensing matrices beyond standard Gaussian matrices. To solve this convergence issue, generalized orthogonal AMP (GOAMP) is proposed for signals with sublinear sparsity. The main feature of GOAMP is the so-called Onsager correction to realize asymptotic Gaussianity of estimation errors. The Onsager correction in GOAMP is designed via state evolution for orthogonally invariant sensing matrices in the sublinear sparsity limit, where the signal sparsity and measurement dimension tend to infinity at sublinear speed in the signal dimension. When the support of non-zero signals does not contain a neighborhood of the origin, GOAMP using Bayesian denoisers is proved to achieve error-free signal reconstruction for linear measurements if and only if the measurement dimension is larger than a threshold, which is equal to that of AMP for standard Gaussian sensing matrices. Numerical simulations are also presented for linear measurements and 1-bit compressed sensing. When ill-conditioned sensing matrices are used, GOAMP for sublinear sparsity is shown to outperform existing reconstruction algorithms, including generalized AMP for sublinear sparsity.", "AI": {"tldr": "\u9488\u5bf9\u4e9a\u7ebf\u6027\u7a00\u758f\u4fe1\u53f7\u7684\u5e7f\u4e49\u7ebf\u6027\u6d4b\u91cf\u91cd\u5efa\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5e7f\u4e49\u6b63\u4ea4AMP\u7b97\u6cd5\uff0c\u901a\u8fc7Onsager\u6821\u6b63\u5b9e\u73b0\u8bef\u5dee\u7684\u6e10\u8fd1\u9ad8\u65af\u6027\uff0c\u5728\u4e9a\u7ebf\u6027\u7a00\u758f\u6781\u9650\u4e0b\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7814\u7a76\u5047\u8bbe\u4fe1\u53f7\u7a00\u758f\u5ea6\u4e0e\u4fe1\u53f7\u7ef4\u5ea6\u6210\u6b63\u6bd4\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u7a00\u758f\u5ea6\u5f80\u5f80\u662f\u4e9a\u7ebf\u6027\u7684\u3002\u4f20\u7edf\u8fd1\u4f3c\u6d88\u606f\u4f20\u9012\u7b97\u6cd5\u5728\u975e\u6807\u51c6\u9ad8\u65af\u6d4b\u91cf\u77e9\u9635\u4e0b\u6536\u655b\u6027\u5dee\uff0c\u9700\u8981\u9488\u5bf9\u4e9a\u7ebf\u6027\u7a00\u758f\u4fe1\u53f7\u8bbe\u8ba1\u65b0\u7684\u91cd\u5efa\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u5e7f\u4e49\u6b63\u4ea4AMP\u7b97\u6cd5\uff0c\u901a\u8fc7Onsager\u6821\u6b63\u5b9e\u73b0\u4f30\u8ba1\u8bef\u5dee\u7684\u6e10\u8fd1\u9ad8\u65af\u6027\u3002\u8be5\u6821\u6b63\u57fa\u4e8e\u6b63\u4ea4\u4e0d\u53d8\u6d4b\u91cf\u77e9\u9635\u5728\u4e9a\u7ebf\u6027\u7a00\u758f\u6781\u9650\u4e0b\u7684\u72b6\u6001\u6f14\u5316\u8bbe\u8ba1\uff0c\u5176\u4e2d\u4fe1\u53f7\u7a00\u758f\u5ea6\u548c\u6d4b\u91cf\u7ef4\u5ea6\u4ee5\u4e9a\u7ebf\u6027\u901f\u5ea6\u8d8b\u4e8e\u65e0\u7a77\u3002", "result": "\u5f53\u975e\u96f6\u4fe1\u53f7\u652f\u6491\u4e0d\u5305\u542b\u539f\u70b9\u90bb\u57df\u65f6\uff0c\u4f7f\u7528\u8d1d\u53f6\u65af\u53bb\u566a\u5668\u7684GOAMP\u5728\u7ebf\u6027\u6d4b\u91cf\u4e0b\u80fd\u5b9e\u73b0\u65e0\u8bef\u5dee\u4fe1\u53f7\u91cd\u5efa\uff0c\u5f53\u4e14\u4ec5\u5f53\u6d4b\u91cf\u7ef4\u5ea6\u5927\u4e8e\u67d0\u4e2a\u9608\u503c\uff0c\u8be5\u9608\u503c\u4e0e\u6807\u51c6\u9ad8\u65af\u6d4b\u91cf\u77e9\u9635\u4e0bAMP\u7684\u9608\u503c\u76f8\u540c\u3002\u6570\u503c\u6a21\u62df\u663e\u793a\u5728\u75c5\u6001\u6d4b\u91cf\u77e9\u9635\u4e0b\uff0cGOAMP\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\u3002", "conclusion": "GOAMP\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4e9a\u7ebf\u6027\u7a00\u758f\u4fe1\u53f7\u7684\u91cd\u5efa\u95ee\u9898\uff0c\u5728\u6b63\u4ea4\u4e0d\u53d8\u6d4b\u91cf\u77e9\u9635\u4e0b\u5177\u6709\u4f18\u8d8a\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u75c5\u6001\u77e9\u9635\u60c5\u51b5\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\uff0c\u4e3a\u4e9a\u7ebf\u6027\u7a00\u758f\u4fe1\u53f7\u5904\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2512.03048", "categories": ["cs.AI", "cs.CY", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.03048", "abs": "https://arxiv.org/abs/2512.03048", "authors": ["Austin Spizzirri"], "title": "Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation", "comment": "Approx. 3,000 words, 10 pages. Philosophical analysis of AI alignment (process-based / syntropy framework)", "summary": "I argue that AI alignment should be reconceived as architecting syntropic, reasons-responsive agents through process-based, multi-agent, developmental mechanisms rather than encoding fixed human value content. The paper makes three philosophical contributions. First, I articulate the ``specification trap'' argument demonstrating why content-based value specification appears structurally unstable due to the conjunction of the is-ought gap, value pluralism, and the extended frame problem. Second, I propose syntropy -- the recursive reduction of mutual uncertainty between agents through state alignment -- as an information-theoretic framework for understanding multi-agent alignment dynamics. Third, I establish a functional distinction between genuine and simulated moral capacity grounded in compatibilist theories of guidance control, coupled with an embodied experimental paradigm and verification regime providing operational criteria independent of phenomenological claims. This paper represents the philosophical component of a broader research program whose empirical validation is being developed in a separate project currently in preparation. While the framework generates specific, falsifiable predictions about value emergence and moral agency in artificial systems, empirical validation remains pending.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAI\u5bf9\u9f50\u5e94\u91cd\u65b0\u6784\u60f3\u4e3a\u901a\u8fc7\u8fc7\u7a0b\u6027\u3001\u591a\u667a\u80fd\u4f53\u3001\u53d1\u5c55\u6027\u673a\u5236\u6784\u5efa\u5177\u6709\u71b5\u51cf\uff08syntropic\uff09\u548c\u7406\u7531\u54cd\u5e94\u80fd\u529b\u7684\u667a\u80fd\u4f53\uff0c\u800c\u975e\u7f16\u7801\u56fa\u5b9a\u7684\u4eba\u7c7b\u4ef7\u503c\u5185\u5bb9\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5185\u5bb9\u7684\u4ef7\u503c\u89c4\u8303\u65b9\u6cd5\u5b58\u5728\u7ed3\u6784\u6027\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5305\u62ec\"\u662f-\u5e94\u8be5\"\u9e3f\u6c9f\u3001\u4ef7\u503c\u591a\u5143\u4e3b\u4e49\u548c\u6269\u5c55\u6846\u67b6\u95ee\u9898\uff0c\u8fd9\u6784\u6210\u4e86\"\u89c4\u8303\u9677\u9631\"\uff0c\u9700\u8981\u65b0\u7684\u5bf9\u9f50\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e09\u4e2a\u54f2\u5b66\u8d21\u732e\uff1a1) \u9610\u8ff0\"\u89c4\u8303\u9677\u9631\"\u8bba\u8bc1\uff1b2) \u63d0\u51fa\"\u71b5\u51cf\"\u4f5c\u4e3a\u7406\u89e3\u591a\u667a\u80fd\u4f53\u5bf9\u9f50\u52a8\u6001\u7684\u4fe1\u606f\u8bba\u6846\u67b6\uff1b3) \u57fa\u4e8e\u76f8\u5bb9\u8bba\u7684\u6307\u5bfc\u63a7\u5236\u7406\u8bba\u5efa\u7acb\u771f\u5b9e\u4e0e\u6a21\u62df\u9053\u5fb7\u80fd\u529b\u7684\u529f\u80fd\u533a\u5206\uff0c\u5e76\u8bbe\u8ba1\u5177\u8eab\u5b9e\u9a8c\u8303\u5f0f\u548c\u9a8c\u8bc1\u673a\u5236\u3002", "result": "\u5efa\u7acb\u4e86\u65b0\u7684AI\u5bf9\u9f50\u7406\u8bba\u6846\u67b6\uff0c\u751f\u6210\u5173\u4e8e\u4eba\u5de5\u7cfb\u7edf\u4e2d\u4ef7\u503c\u6d8c\u73b0\u548c\u9053\u5fb7\u80fd\u52a8\u6027\u7684\u5177\u4f53\u3001\u53ef\u8bc1\u4f2a\u9884\u6d4b\uff0c\u4f46\u5b9e\u8bc1\u9a8c\u8bc1\u4ecd\u5728\u8fdb\u884c\u4e2d\u3002", "conclusion": "AI\u5bf9\u9f50\u5e94\u4ece\u5185\u5bb9\u7f16\u7801\u8f6c\u5411\u8fc7\u7a0b\u6027\u3001\u53d1\u5c55\u6027\u673a\u5236\uff0c\u901a\u8fc7\u71b5\u51cf\u548c\u7406\u7531\u54cd\u5e94\u6027\u6784\u5efa\u771f\u6b63\u7684\u9053\u5fb7\u80fd\u529b\uff0c\u8fd9\u4e3aAI\u5bf9\u9f50\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u54f2\u5b66\u57fa\u7840\u548c\u65b9\u6cd5\u8bba\u65b9\u5411\u3002"}}
{"id": "2512.03536", "categories": ["cs.NI", "cs.CR", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.03536", "abs": "https://arxiv.org/abs/2512.03536", "authors": ["Pavlo Mykytyn", "Ronald Chitauro", "Onur Yener", "Peter Langendoerfer"], "title": "Mobility Induced Sensitivity of UAV based Nodes to Jamming in Private 5G Airfield Networks An Experimental Study", "comment": "4 pages, 4 figures", "summary": "This work presents an experimental performance evaluation of a private 5G airfield network under controlled directional SDR jamming attacks targeting UAV-based UE nodes. Using a QualiPoc Android UE, mounted as a payload on a quadcopter UAV, we conducted a series of experiments to evaluate signal degradation, handover performance, and ser-vice stability in the presence of constant directional jamming. The conducted experiments aimed to examine the effects of varying travel speeds, altitudes, and moving patterns of a UAV-based UE to record and analyze the key physical-layer and network-layer metrics such as CQI, MCS, RSRP, SINR, BLER, Net PDSCH Throughput and RLF. The re-sults of this work describe the link stability and signal degradation dependencies, caused by the level of mobility of the UAV-based UE nodes during autonomous and automatic operation in private 5G Airfield networks", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u5728\u5b9a\u5411SDR\u5e72\u6270\u653b\u51fb\u4e0b\uff0c\u65e0\u4eba\u673a\u4f5c\u4e3aUE\u8282\u70b9\u5728\u79c1\u67095G\u673a\u573a\u7f51\u7edc\u4e2d\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5206\u6790\u4e86\u4fe1\u53f7\u9000\u5316\u3001\u5207\u6362\u6027\u80fd\u548c\u670d\u52a1\u7a33\u5b9a\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u8bc4\u4f30\u79c1\u67095G\u673a\u573a\u7f51\u7edc\u5728\u9762\u5bf9\u5b9a\u5411\u5e72\u6270\u653b\u51fb\u65f6\u7684\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728\u65e0\u4eba\u673a\u4f5c\u4e3a\u79fb\u52a8\u7528\u6237\u8bbe\u5907\u8282\u70b9\u7684\u573a\u666f\u4e0b\uff0c\u4e86\u89e3\u7f51\u7edc\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u642d\u8f7dQualiPoc Android UE\u7684\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\uff0c\u5728\u53d7\u63a7\u7684\u5b9a\u5411SDR\u5e72\u6270\u73af\u5883\u4e0b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u4e0d\u540c\u98de\u884c\u901f\u5ea6\u3001\u9ad8\u5ea6\u548c\u79fb\u52a8\u6a21\u5f0f\u5bf9\u7f51\u7edc\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u8bb0\u5f55CQI\u3001MCS\u3001RSRP\u3001SINR\u3001BLER\u3001\u541e\u5410\u91cf\u548cRLF\u7b49\u5173\u952e\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u63ed\u793a\u4e86\u65e0\u4eba\u673aUE\u8282\u70b9\u79fb\u52a8\u6027\u6c34\u5e73\u5bf9\u94fe\u8def\u7a33\u5b9a\u6027\u548c\u4fe1\u53f7\u9000\u5316\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5c55\u793a\u4e86\u5728\u79c1\u67095G\u673a\u573a\u7f51\u7edc\u4e2d\u81ea\u4e3b\u548c\u81ea\u52a8\u64cd\u4f5c\u65f6\u7684\u7f51\u7edc\u6027\u80fd\u53d8\u5316\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u79c1\u67095G\u673a\u573a\u7f51\u7edc\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e2d\u7684\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5b9e\u9a8c\u6570\u636e\uff0c\u63ed\u793a\u4e86\u65e0\u4eba\u673a\u79fb\u52a8\u6027\u5bf9\u7f51\u7edc\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\uff0c\u5bf9\u8bbe\u8ba1\u548c\u90e8\u7f72\u6297\u5e72\u6270\u76845G\u7f51\u7edc\u5177\u6709\u53c2\u8003\u4ef7\u503c\u3002"}}
{"id": "2512.03518", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.03518", "abs": "https://arxiv.org/abs/2512.03518", "authors": ["Chaorong Zhang", "Benjamin K. Ng", "Ke Wang", "Hui Xu", "Chan-Tong Lam"], "title": "From Reliability to Security: How RIS-Assisted Adaptive SM and SSK Enhances Wireless Systems", "comment": "Submitted in IEEE journals", "summary": "This paper proposes two novel wireless transmission schemes, namely reconfigurable intelligent surface (RIS)-assisted received adaptive spatial modulation (RASM) scheme and RIS-assisted received adaptive space shift keying (RASSK) scheme, designed to enhance spectral efficiency (SE) and physical layer security (PLS).In both proposed schemes, transmitting bits are dynamically mapped at receive antennas by leveraging the characteristics of the RIS in each time slot, which enables the enhancement of signal-to-noise ratio (SNR) at specific selected antennas with near few power, thus leading a reliable and green wireless communication. This adaptive approach facilitates the conveyance of extra bits to the receiver, which means it needs less cost of radio-frequency chains at transmitter while improving SE. Besides, the proposed schemes offer an inherent PLS security advantage, as the eavesdropper is unable to completely detect signals reflected from the RIS. To comprehensively evaluate the performance of the proposed RASM and RASSK schemes, this paper presents a detailed analytical performance of their spectral efficiency, detection complexity, bit error rate, and secrecy rate, which are accompanied by insightful findings and conclusions. Simulation and analytical results demonstrate the superiority of the proposed schemes, showcasing their improved error performance and robustness against wiretapping, while also highlighting the potential of the RASM and RASSK schemes for future wireless applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u578b\u65e0\u7ebf\u4f20\u8f93\u65b9\u6848\uff1aRIS\u8f85\u52a9\u63a5\u6536\u81ea\u9002\u5e94\u7a7a\u95f4\u8c03\u5236(RASM)\u548cRIS\u8f85\u52a9\u63a5\u6536\u81ea\u9002\u5e94\u7a7a\u95f4\u79fb\u4f4d\u952e\u63a7(RASSK)\uff0c\u65e8\u5728\u63d0\u9ad8\u9891\u8c31\u6548\u7387\u548c\u7269\u7406\u5c42\u5b89\u5168\u6027\u3002", "motivation": "\u4f20\u7edf\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u5728\u9891\u8c31\u6548\u7387\u548c\u7269\u7406\u5c42\u5b89\u5168\u6027\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u5b89\u5168\u4e14\u8282\u80fd\u7684\u4f20\u8f93\u65b9\u6848\u3002RIS\u6280\u672f\u4e3a\u52a8\u6001\u8c03\u6574\u65e0\u7ebf\u4f20\u64ad\u73af\u5883\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\u3002", "method": "\u5229\u7528RIS\u5728\u6bcf\u4e2a\u65f6\u9699\u7684\u7279\u6027\uff0c\u5728\u63a5\u6536\u5929\u7ebf\u5904\u52a8\u6001\u6620\u5c04\u4f20\u8f93\u6bd4\u7279\uff0c\u589e\u5f3a\u7279\u5b9a\u9009\u5b9a\u5929\u7ebf\u7684\u4fe1\u566a\u6bd4\u3002\u8fd9\u79cd\u81ea\u9002\u5e94\u65b9\u6cd5\u80fd\u591f\u5728\u53d1\u5c04\u7aef\u51cf\u5c11\u5c04\u9891\u94fe\u6210\u672c\u7684\u540c\u65f6\uff0c\u5411\u63a5\u6536\u7aef\u4f20\u9012\u989d\u5916\u6bd4\u7279\u3002", "result": "\u63d0\u51fa\u7684RASM\u548cRASSK\u65b9\u6848\u5728\u9891\u8c31\u6548\u7387\u3001\u8bef\u7801\u7387\u548c\u4fdd\u5bc6\u7387\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u5177\u6709\u6539\u8fdb\u7684\u9519\u8bef\u6027\u80fd\u548c\u6297\u7a83\u542c\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u5b9e\u73b0\u8282\u80fd\u901a\u4fe1\u3002", "conclusion": "RIS\u8f85\u52a9\u7684RASM\u548cRASSK\u65b9\u6848\u4e3a\u672a\u6765\u65e0\u7ebf\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u3001\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u5728\u9891\u8c31\u6548\u7387\u3001\u7269\u7406\u5c42\u5b89\u5168\u6027\u548c\u80fd\u6548\u65b9\u9762\u7684\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2512.03072", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.03072", "abs": "https://arxiv.org/abs/2512.03072", "authors": ["Hu Keyi"], "title": "Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI", "comment": null, "summary": "Current AI paradigms, as \"architects of experience,\" face fundamental challenges in explainability and value alignment. This paper introduces \"Weight-Calculatism,\" a novel cognitive architecture grounded in first principles, and demonstrates its potential as a viable pathway toward Artificial General Intelligence (AGI). The architecture deconstructs cognition into indivisible Logical Atoms and two fundamental operations: Pointing and Comparison. Decision-making is formalized through an interpretable Weight-Calculation model (Weight = Benefit * Probability), where all values are traceable to an auditable set of Initial Weights. This atomic decomposition enables radical explainability, intrinsic generality for novel situations, and traceable value alignment. We detail its implementation via a graph-algorithm-based computational engine and a global workspace workflow, supported by a preliminary code implementation and scenario validation. Results indicate that the architecture achieves transparent, human-like reasoning and robust learning in unprecedented scenarios, establishing a practical and theoretical foundation for building trustworthy and aligned AGI.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7b2c\u4e00\u6027\u539f\u7406\u7684\"\u6743\u91cd\u8ba1\u7b97\u4e3b\u4e49\"\u8ba4\u77e5\u67b6\u6784\uff0c\u901a\u8fc7\u903b\u8f91\u539f\u5b50\u548c\u57fa\u672c\u64cd\u4f5c\u5b9e\u73b0\u53ef\u89e3\u91ca\u3001\u53ef\u5bf9\u9f50\u7684\u901a\u7528\u4eba\u5de5\u667a\u80fd", "motivation": "\u5f53\u524dAI\u8303\u5f0f\u5728\u53ef\u89e3\u91ca\u6027\u548c\u4ef7\u503c\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u6839\u672c\u6027\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u8ba4\u77e5\u67b6\u6784\u6765\u6784\u5efa\u53ef\u4fe1\u8d56\u7684\u901a\u7528\u4eba\u5de5\u667a\u80fd", "method": "\u5c06\u8ba4\u77e5\u89e3\u6784\u4e3a\u4e0d\u53ef\u5206\u5272\u7684\u903b\u8f91\u539f\u5b50\u548c\u4e24\u4e2a\u57fa\u672c\u64cd\u4f5c\uff08\u6307\u5411\u548c\u6bd4\u8f83\uff09\uff0c\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u6743\u91cd\u8ba1\u7b97\u6a21\u578b\uff08\u6743\u91cd=\u6536\u76ca\u00d7\u6982\u7387\uff09\u5f62\u5f0f\u5316\u51b3\u7b56\uff0c\u6240\u6709\u503c\u90fd\u53ef\u8ffd\u6eaf\u5230\u53ef\u5ba1\u8ba1\u7684\u521d\u59cb\u6743\u91cd\u96c6", "result": "\u8be5\u67b6\u6784\u5b9e\u73b0\u4e86\u900f\u660e\u7684\u7c7b\u4eba\u63a8\u7406\u548c\u5728\u65b0\u9896\u573a\u666f\u4e2d\u7684\u7a33\u5065\u5b66\u4e60\uff0c\u4e3a\u6784\u5efa\u53ef\u4fe1\u8d56\u548c\u5bf9\u9f50\u7684AGI\u5960\u5b9a\u4e86\u5b9e\u8df5\u548c\u7406\u8bba\u57fa\u7840", "conclusion": "\u6743\u91cd\u8ba1\u7b97\u4e3b\u4e49\u662f\u57fa\u4e8e\u7b2c\u4e00\u6027\u539f\u7406\u7684\u53ef\u884cAGI\u8def\u5f84\uff0c\u901a\u8fc7\u539f\u5b50\u5206\u89e3\u5b9e\u73b0\u6839\u672c\u53ef\u89e3\u91ca\u6027\u3001\u5185\u5728\u901a\u7528\u6027\u548c\u53ef\u8ffd\u6eaf\u7684\u4ef7\u503c\u5bf9\u9f50"}}
{"id": "2512.03569", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.03569", "abs": "https://arxiv.org/abs/2512.03569", "authors": ["Gianluca Cena", "Pietro Chiavassa", "Stefano Scanzio"], "title": "Performance Evaluation of Parallel Wi-Fi Redundancy with Deferral Techniques", "comment": "preprint accepted, 8 pages, 2025", "summary": "Wireless communication is increasingly used in industrial environments, since it supports mobility of interconnected devices. Among the transmission technologies operating in unlicensed bands available to this purpose, Wi-Fi is certainly one of the most interesting, because of its high performance and the relatively low deployment costs. Unfortunately, its dependability is often deemed unsuitable for real-time control systems. In this paper, the use of parallel redundancy is evaluated from a quantitative viewpoint, by considering a number of performance indices that are relevant for soft real-time applications. Analysis is carried out on a large dataset acquired from a real setup, to provide realistic insights on the advantages this kind of approaches can provide. As will be seen, deferred parallel redundancy provides clear advantages in terms of the worst-case transmission latency, at limited costs concerning the amount of consumed spectrum. Hence, it can be practically exploited every time a wireless connection is included in a control loop.", "AI": {"tldr": "\u8bc4\u4f30Wi-Fi\u5e76\u884c\u5197\u4f59\u5728\u5de5\u4e1a\u65e0\u7ebf\u901a\u4fe1\u4e2d\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u771f\u5b9e\u6570\u636e\u96c6\u5206\u6790\u5176\u5bf9\u8f6f\u5b9e\u65f6\u5e94\u7528\u4f20\u8f93\u5ef6\u8fdf\u7684\u6539\u5584\u6548\u679c", "motivation": "Wi-Fi\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u53ef\u9760\u6027\u5e38\u88ab\u8ba4\u4e3a\u4e0d\u9002\u5408\u5b9e\u65f6\u63a7\u5236\u7cfb\u7edf\u3002\u672c\u6587\u65e8\u5728\u4ece\u5b9a\u91cf\u89d2\u5ea6\u8bc4\u4f30\u5e76\u884c\u5197\u4f59\u6280\u672f\u662f\u5426\u80fd\u6539\u5584Wi-Fi\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u6027\u80fd", "method": "\u4f7f\u7528\u771f\u5b9e\u5b9e\u9a8c\u8bbe\u7f6e\u91c7\u96c6\u5927\u91cf\u6570\u636e\u96c6\uff0c\u5206\u6790\u5e76\u884c\u5197\u4f59\u5bf9\u8f6f\u5b9e\u65f6\u5e94\u7528\u76f8\u5173\u6027\u80fd\u6307\u6807\u7684\u5f71\u54cd\uff0c\u7279\u522b\u5173\u6ce8\u5ef6\u8fdf\u4f20\u8f93\u6027\u80fd", "result": "\u5ef6\u8fdf\u5e76\u884c\u5197\u4f59\u5728\u6709\u9650\u9891\u8c31\u6d88\u8017\u6210\u672c\u4e0b\uff0c\u80fd\u663e\u8457\u6539\u5584\u6700\u574f\u60c5\u51b5\u4f20\u8f93\u5ef6\u8fdf\uff0c\u4e3a\u65e0\u7ebf\u63a7\u5236\u73af\u8def\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848", "conclusion": "\u5e76\u884c\u5197\u4f59\u6280\u672f\u53ef\u6709\u6548\u63d0\u5347Wi-Fi\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u6027\u80fd\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5305\u542b\u65e0\u7ebf\u8fde\u63a5\u7684\u63a7\u5236\u73af\u8def\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2512.03612", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.03612", "abs": "https://arxiv.org/abs/2512.03612", "authors": ["Saeed Rasouli", "Hamid Karamikabir"], "title": "Expected Confidence Dependency: A Novel Rough Set-Based Approach to Feature Selection", "comment": "33 pages, 5 figures", "summary": "This paper proposes Expected Confidence Dependency (ECD), a novel, soft computing-oriented, accuracy driven dependency measure for feature selection within the rough set theory framework. Unlike traditional rough set dependency measures that rely on binary characterizations of conditional blocks, ECD assigns confidence-based contributions to individual equivalence blocks and aggregates them through a normalized expectation operator. We formally establish several desirable properties of ECD, including normalization, compatibility with classical dependency, monotonicity, and invariance under structural and label-preserving transformations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u671f\u671b\u7f6e\u4fe1\u5ea6\u7684\u4f9d\u8d56\u5ea6\u91cf\u65b9\u6cd5ECD\uff0c\u7528\u4e8e\u7c97\u7cd9\u96c6\u7406\u8bba\u6846\u67b6\u4e0b\u7684\u7279\u5f81\u9009\u62e9\uff0c\u76f8\u6bd4\u4f20\u7edf\u4e8c\u5143\u8868\u5f81\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u5206\u914d\u548c\u5f52\u4e00\u5316\u671f\u671b\u7b97\u5b50\u6765\u8bc4\u4f30\u7279\u5f81\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "\u4f20\u7edf\u7c97\u7cd9\u96c6\u4f9d\u8d56\u5ea6\u91cf\u65b9\u6cd5\u57fa\u4e8e\u6761\u4ef6\u5757\u7684\u4e8c\u5143\u8868\u5f81\uff0c\u5b58\u5728\u5c40\u9650\u6027\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u7ec6\u3001\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u8f6f\u8ba1\u7b97\u65b9\u6cd5\u6765\u66f4\u597d\u5730\u8bc4\u4f30\u7279\u5f81\u4f9d\u8d56\u5173\u7cfb\uff0c\u4ee5\u6539\u8fdb\u7279\u5f81\u9009\u62e9\u6548\u679c\u3002", "method": "\u63d0\u51fa\u671f\u671b\u7f6e\u4fe1\u4f9d\u8d56\u5ea6\uff08ECD\uff09\uff0c\u4e3a\u5355\u4e2a\u7b49\u4ef7\u5757\u5206\u914d\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u8d21\u732e\u503c\uff0c\u7136\u540e\u901a\u8fc7\u5f52\u4e00\u5316\u671f\u671b\u7b97\u5b50\u8fdb\u884c\u805a\u5408\u3002\u8be5\u65b9\u6cd5\u5728\u7c97\u7cd9\u96c6\u7406\u8bba\u6846\u67b6\u5185\u5de5\u4f5c\uff0c\u662f\u4e00\u79cd\u8f6f\u8ba1\u7b97\u5bfc\u5411\u7684\u7cbe\u5ea6\u9a71\u52a8\u4f9d\u8d56\u5ea6\u91cf\u3002", "result": "\u6b63\u5f0f\u5efa\u7acb\u4e86ECD\u7684\u591a\u4e2a\u7406\u60f3\u6027\u8d28\uff1a\u5f52\u4e00\u5316\u3001\u4e0e\u7ecf\u5178\u4f9d\u8d56\u5ea6\u7684\u517c\u5bb9\u6027\u3001\u5355\u8c03\u6027\uff0c\u4ee5\u53ca\u5728\u7ed3\u6784\u53d8\u6362\u548c\u6807\u7b7e\u4fdd\u6301\u53d8\u6362\u4e0b\u7684\u4e0d\u53d8\u6027\u3002", "conclusion": "ECD\u662f\u4e00\u79cd\u65b0\u9896\u6709\u6548\u7684\u7279\u5f81\u9009\u62e9\u4f9d\u8d56\u5ea6\u91cf\u65b9\u6cd5\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5177\u6709\u7406\u8bba\u4e0a\u7684\u826f\u597d\u6027\u8d28\uff0c\u4e3a\u7c97\u7cd9\u96c6\u6846\u67b6\u4e0b\u7684\u7279\u5f81\u9009\u62e9\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u7684\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2512.03272", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03272", "abs": "https://arxiv.org/abs/2512.03272", "authors": ["Zhiyuan He", "Dingmin Wang"], "title": "When Do Symbolic Solvers Enhance Reasoning in Large Language Models?", "comment": null, "summary": "Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models \"overthink\" by producing lengthy reasoning chains, which can even lead to incorrect answers. A promising direction is the symbolic-solver-integrated approach, which leverages the code generation capabilities of LLMs to translate reasoning tasks into executable code and then solve them with a symbolic solver. In this paper, we explore an open question of when the conventional long-CoT can be enhanced by symbolic solvers. Our experimental results show that the symbolic-solver-integrated method only helps when the problem requires limited implicit reasoning but involves an ample search space. The latest LLMs, like GPT-4o, show better performance on deductive problems with shallow reasoning depth, while the symbolic-solver-integrated method significantly improves the LLMs' performance in constraint satisfaction problems that require repeated backtracks. When a declarative exemplar is provided, even CodeLlama-13B can outperform GPT-4o in difficult Zebra puzzles.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\u4f55\u65f6\u80fd\u589e\u5f3a\u4f20\u7edf\u957f\u601d\u7ef4\u94fe\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u8be5\u65b9\u6cd5\u4ec5\u5728\u95ee\u9898\u9700\u8981\u6709\u9650\u9690\u5f0f\u63a8\u7406\u4f46\u6d89\u53ca\u5145\u8db3\u641c\u7d22\u7a7a\u95f4\u65f6\u6709\u6548\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u751f\u6210\u957f\u601d\u7ef4\u94fe\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u4f1a\u4ea7\u751f\u5927\u91cftoken\u5f00\u9500\uff0c\u4e14\u6a21\u578b\u53ef\u80fd\"\u8fc7\u5ea6\u601d\u8003\"\u4ea7\u751f\u5197\u957f\u63a8\u7406\u94fe\u751a\u81f3\u9519\u8bef\u7b54\u6848\u3002\u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\u5229\u7528LLM\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u5c06\u63a8\u7406\u4efb\u52a1\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u7136\u540e\u7528\u7b26\u53f7\u6c42\u89e3\u5668\u89e3\u51b3\uff0c\u4f46\u4f55\u65f6\u8fd9\u79cd\u96c6\u6210\u65b9\u6cd5\u80fd\u589e\u5f3a\u4f20\u7edf\u957f\u601d\u7ef4\u94fe\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\uff0c\u5229\u7528LLM\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u5c06\u63a8\u7406\u4efb\u52a1\u7ffb\u8bd1\u6210\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u7136\u540e\u4f7f\u7528\u7b26\u53f7\u6c42\u89e3\u5668\u89e3\u51b3\u3002\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u4f20\u7edf\u957f\u601d\u7ef4\u94fe\u65b9\u6cd5\u4e0e\u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\u5728\u4e0d\u540c\u7c7b\u578b\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff1a1) \u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\u4ec5\u5728\u95ee\u9898\u9700\u8981\u6709\u9650\u9690\u5f0f\u63a8\u7406\u4f46\u6d89\u53ca\u5145\u8db3\u641c\u7d22\u7a7a\u95f4\u65f6\u6709\u6548\uff1b2) GPT-4o\u7b49\u6700\u65b0LLM\u5728\u63a8\u7406\u6df1\u5ea6\u8f83\u6d45\u7684\u6f14\u7ece\u95ee\u9898\u4e0a\u8868\u73b0\u66f4\u597d\uff1b3) \u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86LLM\u5728\u9700\u8981\u91cd\u590d\u56de\u6eaf\u7684\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u4e0a\u7684\u6027\u80fd\uff1b4) \u63d0\u4f9b\u58f0\u660e\u6027\u793a\u4f8b\u65f6\uff0c\u5373\u4f7f\u662fCodeLlama-13B\u4e5f\u80fd\u5728\u56f0\u96be\u7684\u6591\u9a6c\u8c1c\u9898\u4e0a\u8d85\u8d8aGPT-4o\u3002", "conclusion": "\u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\u5bf9\u7279\u5b9a\u7c7b\u578b\u7684\u63a8\u7406\u95ee\u9898\uff08\u9700\u8981\u6709\u9650\u9690\u5f0f\u63a8\u7406\u4f46\u6d89\u53ca\u5145\u8db3\u641c\u7d22\u7a7a\u95f4\u7684\u95ee\u9898\uff09\u6709\u663e\u8457\u5e2e\u52a9\uff0c\u7279\u522b\u662f\u5728\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u4e0a\u3002\u8be5\u65b9\u6cd5\u4e3aLLM\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8865\u5145\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5927\u91cf\u641c\u7d22\u548c\u56de\u6eaf\u7684\u573a\u666f\u4e2d\u3002"}}
{"id": "2512.03570", "categories": ["cs.NI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.03570", "abs": "https://arxiv.org/abs/2512.03570", "authors": ["Stefano Scanzio", "Gabriele Formis", "Tullio Facchinetti", "Gianluca Cena"], "title": "Machine Learning to Predict Slot Usage in TSCH Wireless Sensor Networks", "comment": "preprint accepted, 8 pages, 2025", "summary": "Wireless sensor networks (WSNs) are employed across a wide range of industrial applications where ultra-low power consumption is a critical prerequisite. At the same time, these systems must maintain a certain level of determinism to ensure reliable and predictable operation. In this view, time slotted channel hopping (TSCH) is a communication technology that meets both conditions, making it an attractive option for its usage in industrial WSNs. This work proposes the use of machine learning to learn the traffic pattern generated in networks based on the TSCH protocol, in order to turn nodes into a deep sleep state when no transmission is planned and thus to improve the energy efficiency of the WSN. The ability of machine learning models to make good predictions at different network levels in a typical tree network topology was analyzed in depth, showing how their capabilities degrade while approaching the root of the tree. The application of these models on simulated data based on an accurate modeling of wireless sensor nodes indicates that the investigated algorithms can be suitably used to further and substantially reduce the power consumption of a TSCH network.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u5b66\u4e60TSCH\u534f\u8bae\u7f51\u7edc\u7684\u6d41\u91cf\u6a21\u5f0f\uff0c\u901a\u8fc7\u9884\u6d4b\u7a7a\u95f2\u65f6\u6bb5\u8ba9\u8282\u70b9\u8fdb\u5165\u6df1\u5ea6\u7761\u7720\u72b6\u6001\uff0c\u4ece\u800c\u63d0\u9ad8\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u7684\u80fd\u6548\u3002", "motivation": "\u5de5\u4e1a\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u9700\u8981\u8d85\u4f4e\u529f\u8017\u548c\u786e\u5b9a\u6027\u64cd\u4f5c\u3002TSCH\u534f\u8bae\u80fd\u6ee1\u8db3\u8fd9\u4e24\u4e2a\u8981\u6c42\uff0c\u4f46\u4ecd\u6709\u8fdb\u4e00\u6b65\u8282\u80fd\u7684\u7a7a\u95f4\u3002\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u7f51\u7edc\u6d41\u91cf\u6a21\u5f0f\uff0c\u53ef\u4ee5\u5728\u65e0\u4f20\u8f93\u8ba1\u5212\u65f6\u8ba9\u8282\u70b9\u8fdb\u5165\u6df1\u5ea6\u7761\u7720\u72b6\u6001\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u80fd\u6548\u3002", "method": "\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5b66\u4e60\u57fa\u4e8eTSCH\u534f\u8bae\u7684\u7f51\u7edc\u7684\u6d41\u91cf\u6a21\u5f0f\u3002\u5728\u5178\u578b\u7684\u6811\u5f62\u7f51\u7edc\u62d3\u6251\u4e2d\u5206\u6790\u4e0d\u540c\u7f51\u7edc\u5c42\u7ea7\u4e0a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u7814\u7a76\u6a21\u578b\u6027\u80fd\u968f\u63a5\u8fd1\u6811\u6839\u8282\u70b9\u7684\u53d8\u5316\u60c5\u51b5\u3002\u57fa\u4e8e\u65e0\u7ebf\u4f20\u611f\u5668\u8282\u70b9\u7684\u7cbe\u786e\u5efa\u6a21\u8fdb\u884c\u6a21\u62df\u6570\u636e\u9a8c\u8bc1\u3002", "result": "\u5206\u6790\u8868\u660e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u4e0d\u540c\u7f51\u7edc\u5c42\u7ea7\u4e0a\u90fd\u80fd\u505a\u51fa\u826f\u597d\u9884\u6d4b\uff0c\u4f46\u5176\u9884\u6d4b\u80fd\u529b\u5728\u63a5\u8fd1\u6811\u6839\u8282\u70b9\u65f6\u4f1a\u9010\u6e10\u4e0b\u964d\u3002\u6a21\u62df\u7ed3\u679c\u663e\u793a\u6240\u7814\u7a76\u7684\u7b97\u6cd5\u80fd\u591f\u663e\u8457\u964d\u4f4eTSCH\u7f51\u7edc\u7684\u529f\u8017\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5b66\u4e60TSCH\u7f51\u7edc\u7684\u6d41\u91cf\u6a21\u5f0f\uff0c\u901a\u8fc7\u9884\u6d4b\u7a7a\u95f2\u65f6\u6bb5\u8ba9\u8282\u70b9\u8fdb\u5165\u6df1\u5ea6\u7761\u7720\u72b6\u6001\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u7684\u80fd\u91cf\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2512.04077", "categories": ["cs.IT", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.04077", "abs": "https://arxiv.org/abs/2512.04077", "authors": ["Ismail Cosandal", "Sennur Ulukus", "Nail Akar"], "title": "Semi-Markov Decision Process Framework for Age of Incorrect Information Minimization", "comment": null, "summary": "For a remote estimation system, we study age of incorrect information (AoII), which is a recently proposed semantic-aware freshness metric. In particular, we assume an information source observing a discrete-time finite-state Markov chain (DTMC) and employing push-based transmissions of status update packets towards the monitor which is tasked with remote estimation of the source. The source-to-monitor channel delay is assumed to have a general discrete-time phase-type (DPH) distribution, whereas the zero-delay reverse channel ensures that the source has perfect information on AoII and the remote estimate. A multi-threshold transmission policy is employed where packet transmissions are initiated when the AoII process exceeds a threshold which may be different for each estimation value. In this general setting, our goal is to minimize the weighted sum of time average of an arbitrary function of AoII and estimation, and transmission costs, by suitable choice of the thresholds. We formulate the problem as a semi-Markov decision process (SMDP) with the same state-space as the original DTMC to obtain the optimum multi-threshold policy whereas the parameters of the SMDP are obtained by using a novel stochastic tool called dual-regime absorbing Markov chain (DR-AMC), and its corresponding absorption time distribution named as dual-regime DPH (DR-DPH).", "AI": {"tldr": "\u7814\u7a76\u8fdc\u7a0b\u4f30\u8ba1\u7cfb\u7edf\u4e2d\u57fa\u4e8e\u5e74\u9f84\u9519\u8bef\u4fe1\u606f(AoII)\u7684\u591a\u9608\u503c\u4f20\u8f93\u7b56\u7565\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u534a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u548c\u65b0\u578b\u968f\u673a\u5de5\u5177DR-AMC/DR-DPH\u6c42\u89e3\u6700\u4f18\u9608\u503c", "motivation": "\u5728\u8fdc\u7a0b\u4f30\u8ba1\u7cfb\u7edf\u4e2d\uff0c\u4f20\u7edf\u7684\u4fe1\u606f\u65b0\u9c9c\u5ea6\u5ea6\u91cf\u5982AoI(\u4fe1\u606f\u5e74\u9f84)\u65e0\u6cd5\u5145\u5206\u53cd\u6620\u4f30\u8ba1\u8bef\u5dee\u7684\u8bed\u4e49\u4fe1\u606f\u3002AoII(\u9519\u8bef\u4fe1\u606f\u5e74\u9f84)\u4f5c\u4e3a\u4e00\u79cd\u8bed\u4e49\u611f\u77e5\u7684\u65b0\u9c9c\u5ea6\u5ea6\u91cf\uff0c\u80fd\u66f4\u597d\u5730\u6355\u6349\u4f30\u8ba1\u8d28\u91cf\u3002\u7814\u7a76\u5982\u4f55\u5728\u5177\u6709\u4e00\u822c\u79bb\u6563\u65f6\u95f4\u76f8\u578b\u5206\u5e03\u4fe1\u9053\u5ef6\u8fdf\u7684\u7cfb\u7edf\u4e2d\u4f18\u5316AoII\u6027\u80fd\u3002", "method": "\u91c7\u7528\u591a\u9608\u503c\u4f20\u8f93\u7b56\u7565\uff0c\u5f53AoII\u8d85\u8fc7\u7279\u5b9a\u9608\u503c\u65f6\u89e6\u53d1\u4f20\u8f93\u3002\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u534a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(SMDP)\uff0c\u72b6\u6001\u7a7a\u95f4\u4e0e\u539f\u59cb\u79bb\u6563\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe\u76f8\u540c\u3002\u4f7f\u7528\u65b0\u578b\u968f\u673a\u5de5\u5177\u53cc\u673a\u5236\u5438\u6536\u9a6c\u5c14\u53ef\u592b\u94fe(DR-AMC)\u53ca\u5176\u5438\u6536\u65f6\u95f4\u5206\u5e03DR-DPH\u6765\u8ba1\u7b97SMDP\u53c2\u6570\u3002", "result": "\u901a\u8fc7SMDP\u6846\u67b6\u548cDR-AMC/DR-DPH\u5de5\u5177\uff0c\u80fd\u591f\u83b7\u5f97\u6700\u4f18\u7684\u591a\u9608\u503c\u4f20\u8f93\u7b56\u7565\uff0c\u6700\u5c0f\u5316AoII\u51fd\u6570\u548c\u4f20\u8f93\u6210\u672c\u7684\u52a0\u6743\u65f6\u95f4\u5e73\u5747\u503c\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5177\u6709\u4e00\u822c\u4fe1\u9053\u5ef6\u8fdf\u7684\u8fdc\u7a0b\u4f30\u8ba1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684AoII\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u9608\u503c\u7b56\u7565\u548c\u65b0\u578b\u968f\u673a\u5206\u6790\u5de5\u5177\uff0c\u5b9e\u73b0\u4e86\u8bed\u4e49\u611f\u77e5\u65b0\u9c9c\u5ea6\u5ea6\u91cf\u7684\u6027\u80fd\u4f18\u5316\u3002"}}
{"id": "2512.03719", "categories": ["cs.IT", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.03719", "abs": "https://arxiv.org/abs/2512.03719", "authors": ["Seyed Mohammad Azimi-Abarghouyi", "Carlo Fischione", "Kaibin Huang"], "title": "Over-the-Air Federated Learning: Rethinking Edge AI Through Signal Processing", "comment": null, "summary": "Over-the-Air Federated Learning (AirFL) is an emerging paradigm that tightly integrates wireless signal processing and distributed machine learning to enable scalable AI at the network edge. By leveraging the superposition property of wireless signals, AirFL performs communication and model aggregation of the learning process simultaneously, significantly reducing latency, bandwidth, and energy consumption. This article offers a tutorial treatment of AirFL, presenting a novel classification into three design approaches: CSIT-aware, blind, and weighted AirFL. We provide a comprehensive guide to theoretical foundations, performance analysis, complexity considerations, practical limitations, and prospective research directions.", "AI": {"tldr": "AirFL\u662f\u4e00\u79cd\u65b0\u5174\u7684\u8054\u90a6\u5b66\u4e60\u8303\u5f0f\uff0c\u901a\u8fc7\u65e0\u7ebf\u4fe1\u53f7\u53e0\u52a0\u7279\u6027\u540c\u65f6\u8fdb\u884c\u901a\u4fe1\u548c\u6a21\u578b\u805a\u5408\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u3001\u5e26\u5bbd\u548c\u80fd\u8017\u3002\u672c\u6587\u63d0\u4f9b\u4e86AirFL\u7684\u6559\u7a0b\u5f0f\u4ecb\u7ecd\uff0c\u5c06\u5176\u5206\u4e3a\u4e09\u79cd\u8bbe\u8ba1\u65b9\u6cd5\uff1aCSIT\u611f\u77e5\u3001\u76f2\u5f0f\u548c\u52a0\u6743AirFL\u3002", "motivation": "\u968f\u7740\u8fb9\u7f18\u8ba1\u7b97\u548c\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u7684\u53d1\u5c55\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u6574\u5408\u65e0\u7ebf\u4fe1\u53f7\u5904\u7406\u548c\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u3002\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u5728\u901a\u4fe1\u5f00\u9500\u3001\u5ef6\u8fdf\u548c\u80fd\u8017\u65b9\u9762\u5b58\u5728\u74f6\u9888\uff0c\u800cAirFL\u901a\u8fc7\u5229\u7528\u65e0\u7ebf\u4fe1\u53f7\u7684\u53e0\u52a0\u7279\u6027\uff0c\u80fd\u591f\u540c\u65f6\u8fdb\u884c\u901a\u4fe1\u548c\u6a21\u578b\u805a\u5408\uff0c\u4e3a\u8fb9\u7f18AI\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86AirFL\u7684\u4e09\u79cd\u8bbe\u8ba1\u65b9\u6cd5\u5206\u7c7b\uff1a1) CSIT\u611f\u77e5AirFL\uff1a\u5229\u7528\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u8fdb\u884c\u4f18\u5316\u8bbe\u8ba1\uff1b2) \u76f2\u5f0fAirFL\uff1a\u65e0\u9700\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff1b3) \u52a0\u6743AirFL\uff1a\u901a\u8fc7\u52a0\u6743\u673a\u5236\u5904\u7406\u4e0d\u540c\u7528\u6237\u7684\u6570\u636e\u8d28\u91cf\u5dee\u5f02\u3002\u6587\u7ae0\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3001\u6027\u80fd\u5206\u6790\u3001\u590d\u6742\u5ea6\u8003\u8651\u548c\u5b9e\u8df5\u9650\u5236\u7684\u5168\u9762\u6307\u5357\u3002", "result": "\u6587\u7ae0\u7cfb\u7edf\u6027\u5730\u4ecb\u7ecd\u4e86AirFL\u6280\u672f\uff0c\u5efa\u7acb\u4e86\u5b8c\u6574\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u5206\u6790\u4e86\u5404\u79cd\u65b9\u6cd5\u7684\u6027\u80fd\u7279\u5f81\u548c\u9002\u7528\u573a\u666f\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8df5\u8003\u91cf\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5de5\u7a0b\u5e08\u63d0\u4f9b\u4e86AirFL\u7684\u8bbe\u8ba1\u6307\u5357\u548c\u5b9e\u65bd\u53c2\u8003\u3002", "conclusion": "AirFL\u4f5c\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u7684\u8fb9\u7f18AI\u6280\u672f\uff0c\u901a\u8fc7\u65e0\u7ebf\u4fe1\u53f7\u5904\u7406\u4e0e\u8054\u90a6\u5b66\u4e60\u7684\u6df1\u5ea6\u878d\u5408\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6548\u7387\u3002\u6587\u7ae0\u63d0\u51fa\u7684\u4e09\u79cd\u8bbe\u8ba1\u65b9\u6cd5\u4e3a\u4e0d\u540c\u5e94\u7528\u573a\u666f\u63d0\u4f9b\u4e86\u7075\u6d3b\u9009\u62e9\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u5305\u62ec\u6027\u80fd\u4f18\u5316\u3001\u5b9e\u9645\u90e8\u7f72\u6311\u6218\u548c\u65b0\u5174\u5e94\u7528\u63a2\u7d22\u3002"}}
{"id": "2512.03293", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2512.03293", "abs": "https://arxiv.org/abs/2512.03293", "authors": ["Filippo Torresan", "Ryota Kanai", "Manuel Baltieri"], "title": "Prior preferences in active inference agents: soft, hard, and goal shaping", "comment": "41 pages, 23 figures", "summary": "Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4e3b\u52a8\u63a8\u7406\u4e2d\u56db\u79cd\u504f\u597d\u5206\u5e03\u5b9a\u4e49\u65b9\u5f0f\uff08\u786c\u76ee\u6807vs\u8f6f\u76ee\u6807\uff0c\u6709\u65e0\u76ee\u6807\u5851\u9020\uff09\u5728\u7f51\u683c\u4e16\u754c\u5bfc\u822a\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u76ee\u6807\u5851\u9020\u80fd\u63d0\u5347\u6027\u80fd\u4f46\u4f1a\u727a\u7272\u5bf9\u73af\u5883\u7684\u63a2\u7d22\u5b66\u4e60\u3002", "motivation": "\u4e3b\u52a8\u63a8\u7406\u4f7f\u7528\u671f\u671b\u81ea\u7531\u80fd\u4f5c\u4e3a\u89c4\u5212\u51b3\u7b56\u76ee\u6807\uff0c\u4f46\u504f\u597d\u5206\u5e03\u5982\u4f55\u5b9a\u4e49\u53ca\u5176\u5bf9\u63a8\u7406\u5b66\u4e60\u7684\u5f71\u54cd\u5728\u6587\u732e\u4e2d\u5f88\u5c11\u88ab\u5173\u6ce8\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e0d\u540c\u504f\u597d\u5206\u5e03\u5b9a\u4e49\u65b9\u5f0f\u5bf9\u667a\u80fd\u4f53\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u8003\u8651\u4e86\u56db\u79cd\u504f\u597d\u5206\u5e03\u5b9a\u4e49\u65b9\u5f0f\uff1a\u786c\u76ee\u6807vs\u8f6f\u76ee\u6807\uff0c\u4ee5\u53ca\u6709\u65e0\u76ee\u6807\u5851\u9020\uff08\u4e2d\u95f4\u76ee\u6807\uff09\u3002\u5728\u7f51\u683c\u4e16\u754c\u5bfc\u822a\u4efb\u52a1\u4e2d\u6bd4\u8f83\u4e86\u56db\u79cd\u667a\u80fd\u4f53\u7684\u8868\u73b0\u3002", "result": "\u76ee\u6807\u5851\u9020\u80fd\u5e26\u6765\u6700\u4f73\u6574\u4f53\u6027\u80fd\uff08\u4fc3\u8fdb\u5229\u7528\uff09\uff0c\u4f46\u4f1a\u727a\u7272\u5bf9\u73af\u5883\u8f6c\u79fb\u52a8\u6001\u7684\u5b66\u4e60\uff08\u963b\u788d\u63a2\u7d22\uff09\u3002", "conclusion": "\u504f\u597d\u5206\u5e03\u7684\u5b9a\u4e49\u65b9\u5f0f\u663e\u8457\u5f71\u54cd\u4e3b\u52a8\u63a8\u7406\u667a\u80fd\u4f53\u7684\u6027\u80fd\u6743\u8861\uff0c\u76ee\u6807\u5851\u9020\u867d\u7136\u63d0\u5347\u5229\u7528\u6548\u7387\u4f46\u4f1a\u9650\u5236\u63a2\u7d22\u5b66\u4e60\uff0c\u9700\u8981\u5728\u5177\u4f53\u5e94\u7528\u4e2d\u6743\u8861\u8003\u8651\u3002"}}
{"id": "2512.03722", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.03722", "abs": "https://arxiv.org/abs/2512.03722", "authors": ["Lingyi Cai", "Wenjie Fu", "Yuxi Huang", "Ruichen Zhang", "Yinqiu Liu", "Jiawen Kang", "Zehui Xiong", "Tao Jiang", "Dusit Niyato", "Xianbin Wang", "Shiwen Mao", "Xuemin Shen"], "title": "Tutorial on Large Language Model-Enhanced Reinforcement Learning for Wireless Networks", "comment": "30 pages, 12 figures, survey paper", "summary": "Reinforcement Learning (RL) has shown remarkable success in enabling adaptive and data-driven optimization for various applications in wireless networks. However, classical RL suffers from limitations in generalization, learning feedback, interpretability, and sample efficiency in dynamic wireless environments. Large Language Models (LLMs) have emerged as a transformative Artificial Intelligence (AI) paradigm with exceptional capabilities in knowledge generalization, contextual reasoning, and interactive generation, which have demonstrated strong potential to enhance classical RL. This paper serves as a comprehensive tutorial on LLM-enhanced RL for wireless networks. We propose a taxonomy to categorize the roles of LLMs into four critical functions: state perceiver, reward designer, decision-maker, and generator. Then, we review existing studies exploring how each role of LLMs enhances different stages of the RL pipeline. Moreover, we provide a series of case studies to illustrate how to design and apply LLM-enhanced RL in low-altitude economy networking, vehicular networks, and space-air-ground integrated networks. Finally, we conclude with a discussion on potential future directions for LLM-enhanced RL and offer insights into its future development in wireless networks.", "AI": {"tldr": "\u672c\u6587\u662f\u5173\u4e8eLLM\u589e\u5f3aRL\u5728\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u7efc\u5408\u6559\u7a0b\uff0c\u63d0\u51fa\u4e86LLM\u5728RL\u4e2d\u7684\u56db\u79cd\u89d2\u8272\u5206\u7c7b\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5e94\u7528\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5728\u65e0\u7ebf\u7f51\u7edc\u52a8\u6001\u73af\u5883\u4e2d\u5b58\u5728\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3001\u5b66\u4e60\u53cd\u9988\u6709\u9650\u3001\u53ef\u89e3\u91ca\u6027\u5dee\u548c\u6837\u672c\u6548\u7387\u4f4e\u7b49\u95ee\u9898\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u6cdb\u5316\u3001\u4e0a\u4e0b\u6587\u63a8\u7406\u548c\u4ea4\u4e92\u751f\u6210\u65b9\u9762\u5177\u6709\u5353\u8d8a\u80fd\u529b\uff0c\u6709\u671b\u589e\u5f3a\u4f20\u7edfRL\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5206\u7c7b\u6cd5\uff0c\u5c06LLM\u5728RL\u4e2d\u7684\u89d2\u8272\u5206\u4e3a\u56db\u79cd\u5173\u952e\u529f\u80fd\uff1a\u72b6\u6001\u611f\u77e5\u5668\u3001\u5956\u52b1\u8bbe\u8ba1\u5668\u3001\u51b3\u7b56\u5236\u5b9a\u5668\u548c\u751f\u6210\u5668\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793aLLM\u589e\u5f3aRL\u5728\u4f4e\u7a7a\u7ecf\u6d4e\u7f51\u7edc\u3001\u8f66\u8f7d\u7f51\u7edc\u548c\u7a7a\u5929\u5730\u4e00\u4f53\u5316\u7f51\u7edc\u4e2d\u7684\u8bbe\u8ba1\u548c\u5e94\u7528\u65b9\u6cd5\u3002", "result": "\u5efa\u7acb\u4e86LLM\u589e\u5f3aRL\u7684\u7cfb\u7edf\u6027\u6846\u67b6\uff0c\u4e3a\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u81ea\u9002\u5e94\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7\u89d2\u8272\u5206\u7c7b\u548c\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86LLM\u5982\u4f55\u5728\u4e0d\u540c\u9636\u6bb5\u589e\u5f3aRL\u7ba1\u9053\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "conclusion": "LLM\u589e\u5f3aRL\u4e3a\u65e0\u7ebf\u7f51\u7edc\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u672a\u6765\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u5176\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u8ba8\u8bba\u4e86\u8be5\u9886\u57df\u672a\u6765\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2512.03872", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.03872", "abs": "https://arxiv.org/abs/2512.03872", "authors": ["Matteo Nerini", "Bruno Clerckx"], "title": "Movable Signals with Dual-Polarized Fixed Intelligent Surfaces: Beyond Diagonal Reflection Matrices", "comment": "Submitted to IEEE for publication", "summary": "This paper investigates wireless systems aided by dual-polarized intelligent surfaces. We compare reconfigurable intelligent surface (RIS), which adjust their reflection matrices, with movable signals operating with fixed intelligent surface (FIS), which adjust the signal frequency while the surface properties remain fixed. For both RIS and FIS, we consider surfaces with a diagonal reflection matrix, named diagonal RIS/FIS, and surfaces with a reflection matrix not limited to being diagonal, named beyond-diagonal RIS/FIS. Movable signals with FIS always outperform RIS, achieving at least a fourfold gain. When transmitter and receiver polarizations differ, beyond-diagonal FIS further enhances performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u53cc\u6781\u5316\u667a\u80fd\u8868\u9762\u8f85\u52a9\u7684\u65e0\u7ebf\u7cfb\u7edf\uff0c\u6bd4\u8f83\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(RIS)\u548c\u56fa\u5b9a\u667a\u80fd\u8868\u9762(FIS)\u914d\u5408\u53ef\u79fb\u52a8\u4fe1\u53f7\u7684\u6027\u80fd\u3002FIS\u59cb\u7ec8\u4f18\u4e8eRIS\uff0c\u81f3\u5c11\u83b7\u5f974\u500d\u589e\u76ca\uff0c\u5f53\u6536\u53d1\u6781\u5316\u4e0d\u540c\u65f6\uff0c\u975e\u5bf9\u89d2FIS\u6027\u80fd\u66f4\u4f73\u3002", "motivation": "\u7814\u7a76\u53cc\u6781\u5316\u667a\u80fd\u8868\u9762\u5728\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\uff0c\u6bd4\u8f83\u4e0d\u540c\u914d\u7f6e\u7684\u667a\u80fd\u8868\u9762\uff08\u53ef\u91cd\u6784\u4e0e\u56fa\u5b9a\uff09\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63a2\u7d22\u6781\u5316\u5dee\u5f02\u6761\u4ef6\u4e0b\u7684\u6700\u4f18\u914d\u7f6e\u65b9\u6848\u3002", "method": "\u6bd4\u8f83\u4e24\u79cd\u667a\u80fd\u8868\u9762\uff1aRIS\uff08\u8c03\u6574\u53cd\u5c04\u77e9\u9635\uff09\u548cFIS\uff08\u56fa\u5b9a\u8868\u9762\u7279\u6027\uff0c\u8c03\u6574\u4fe1\u53f7\u9891\u7387\uff09\u3002\u6bcf\u79cd\u8868\u9762\u53c8\u5206\u4e3a\u5bf9\u89d2\u578b\uff08\u5bf9\u89d2\u53cd\u5c04\u77e9\u9635\uff09\u548c\u975e\u5bf9\u89d2\u578b\uff08\u975e\u5bf9\u89d2\u53cd\u5c04\u77e9\u9635\uff09\u3002\u5206\u6790\u5728\u4e0d\u540c\u6781\u5316\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u5dee\u5f02\u3002", "result": "FIS\u59cb\u7ec8\u4f18\u4e8eRIS\uff0c\u81f3\u5c11\u83b7\u5f974\u500d\u6027\u80fd\u589e\u76ca\u3002\u5f53\u53d1\u5c04\u673a\u548c\u63a5\u6536\u673a\u6781\u5316\u4e0d\u540c\u65f6\uff0c\u975e\u5bf9\u89d2FIS\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u5728\u53cc\u6781\u5316\u667a\u80fd\u8868\u9762\u8f85\u52a9\u7684\u65e0\u7ebf\u7cfb\u7edf\u4e2d\uff0c\u56fa\u5b9a\u667a\u80fd\u8868\u9762\u914d\u5408\u53ef\u79fb\u52a8\u4fe1\u53f7\u6bd4\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u6536\u53d1\u6781\u5316\u4e0d\u540c\u7684\u573a\u666f\u4e0b\uff0c\u975e\u5bf9\u89d2\u56fa\u5b9a\u667a\u80fd\u8868\u9762\u662f\u6700\u4f73\u9009\u62e9\u3002"}}
{"id": "2512.03318", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03318", "abs": "https://arxiv.org/abs/2512.03318", "authors": ["Chandler Smith", "Marwa Abdulhai", "Manfred Diaz", "Marko Tesic", "Rakshit S. Trivedi", "Alexander Sasha Vezhnevets", "Lewis Hammond", "Jesse Clifton", "Minsuk Chang", "Edgar A. Du\u00e9\u00f1ez-Guzm\u00e1n", "John P. Agapiou", "Jayd Matyas", "Danny Karmon", "Akash Kundu", "Aliaksei Korshuk", "Ananya Ananya", "Arrasy Rahman", "Avinaash Anand Kulandaivel", "Bain McHale", "Beining Zhang", "Buyantuev Alexander", "Carlos Saith Rodriguez Rojas", "Caroline Wang", "Chetan Talele", "Chenao Liu", "Chichen Lin", "Diana Riazi", "Di Yang Shi", "Emanuel Tewolde", "Elizaveta Tennant", "Fangwei Zhong", "Fuyang Cui", "Gang Zhao", "Gema Parre\u00f1o Piqueras", "Hyeonggeun Yun", "Ilya Makarov", "Jiaxun Cui", "Jebish Purbey", "Jim Dilkes", "Jord Nguyen", "Lingyun Xiao", "Luis Felipe Giraldo", "Manuela Chacon-Chamorro", "Manuel Sebastian Rios Beltran", "Marta Emili Garc\u00eda Segura", "Mengmeng Wang", "Mogtaba Alim", "Nicanor Quijano", "Nico Schiavone", "Olivia Macmillan-Scott", "Oswaldo Pe\u00f1a", "Peter Stone", "Ram Mohan Rao Kadiyala", "Rolando Fernandez", "Ruben Manrique", "Sunjia Lu", "Sheila A. McIlraith", "Shamika Dhuri", "Shuqing Shi", "Siddhant Gupta", "Sneheel Sarangi", "Sriram Ganapathi Subramanian", "Taehun Cha", "Toryn Q. Klassen", "Wenming Tu", "Weijian Fan", "Wu Ruiyang", "Xue Feng", "Yali Du", "Yang Liu", "Yiding Wang", "Yipeng Kang", "Yoonchang Sung", "Yuxuan Chen", "Zhaowei Zhang", "Zhihan Wang", "Zhiqiang Wu", "Ziang Chen", "Zilong Zheng", "Zixia Jia", "Ziyan Wang", "Dylan Hadfield-Menell", "Natasha Jaques", "Tim Baarslag", "Jose Hernandez-Orallo", "Joel Z. Leibo"], "title": "Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia", "comment": "Published at NeurIPS Datasets and Benchmarks 2025, 10 pages", "summary": "Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical frontier for LLM-based agents, yet existing evaluation methods fail to measure how well these capabilities generalize to novel social situations. In this paper, we introduce a method for evaluating the ability of LLM-based agents to cooperate in zero-shot, mixed-motive environments using Concordia, a natural language multi-agent simulation environment. Our method measures general cooperative intelligence by testing an agent's ability to identify and exploit opportunities for mutual gain across diverse partners and contexts. We present empirical results from the NeurIPS 2024 Concordia Contest, where agents were evaluated on their ability to achieve mutual gains across a suite of diverse scenarios ranging from negotiation to collective action problems. Our findings reveal significant gaps between current agent capabilities and the robust generalization required for reliable cooperation, particularly in scenarios demanding persuasion and norm enforcement.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u5728\u96f6\u6837\u672c\u3001\u6df7\u5408\u52a8\u673a\u73af\u5883\u4e2d\u5408\u4f5c\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528Concordia\u591a\u667a\u80fd\u4f53\u6a21\u62df\u73af\u5883\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u667a\u80fd\u4f53\u5728\u5408\u4f5c\u6cdb\u5316\u80fd\u529b\u4e0a\u7684\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "LLM\u667a\u80fd\u4f53\u5728\u793e\u4f1a\u4e92\u52a8\u65b9\u9762\u5c55\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u8861\u91cf\u8fd9\u4e9b\u80fd\u529b\u5728\u65b0\u9896\u793e\u4ea4\u60c5\u5883\u4e2d\u7684\u6cdb\u5316\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u6df7\u5408\u52a8\u673a\u7684\u5408\u4f5c\u573a\u666f\u4e2d\u3002", "method": "\u5f15\u5165Concordia\u81ea\u7136\u8bed\u8a00\u591a\u667a\u80fd\u4f53\u6a21\u62df\u73af\u5883\uff0c\u901a\u8fc7\u6d4b\u8bd5\u667a\u80fd\u4f53\u5728\u4e0d\u540c\u5408\u4f5c\u4f19\u4f34\u548c\u60c5\u5883\u4e2d\u8bc6\u522b\u548c\u5229\u7528\u4e92\u5229\u673a\u4f1a\u7684\u80fd\u529b\uff0c\u6765\u8bc4\u4f30\u5176\u4e00\u822c\u5408\u4f5c\u667a\u80fd\u3002", "result": "\u57fa\u4e8eNeurIPS 2024 Concordia\u7ade\u8d5b\u7684\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u524d\u667a\u80fd\u4f53\u80fd\u529b\u4e0e\u7a33\u5065\u6cdb\u5316\u6240\u9700\u6c34\u5e73\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u8bf4\u670d\u548c\u89c4\u8303\u6267\u884c\u7684\u573a\u666f\u4e2d\u3002", "conclusion": "LLM\u667a\u80fd\u4f53\u5728\u5408\u4f5c\u80fd\u529b\u65b9\u9762\u4ecd\u9700\u663e\u8457\u6539\u8fdb\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u793e\u4ea4\u60c5\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u8fd9\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2512.04020", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.04020", "abs": "https://arxiv.org/abs/2512.04020", "authors": ["Inocencio Ortiz", "Santiago G\u00f3mez-Guerrero", "Christian E. Schaerer"], "title": "On topological and algebraic structures of categorical random variables", "comment": "18 pages", "summary": "Based on entropy and symmetrical uncertainty (SU), we define a metric for categorical random variables and show that this metric can be promoted into an appropriate quotient space of categorical random variables. Moreover, we also show that there is a natural commutative monoid structure in the same quotient space, which is compatible with the topology induced by the metric, in the sense that the monoid operation is continuous.", "AI": {"tldr": "\u57fa\u4e8e\u71b5\u548c\u5bf9\u79f0\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3a\u5206\u7c7b\u968f\u673a\u53d8\u91cf\u5b9a\u4e49\u4e86\u4e00\u79cd\u5ea6\u91cf\uff0c\u8be5\u5ea6\u91cf\u53ef\u5728\u5206\u7c7b\u968f\u673a\u53d8\u91cf\u7684\u9002\u5f53\u5546\u7a7a\u95f4\u4e2d\u63a8\u5e7f\uff0c\u4e14\u8be5\u5546\u7a7a\u95f4\u5177\u6709\u81ea\u7136\u7684\u4ea4\u6362\u5e7a\u534a\u7fa4\u7ed3\u6784\uff0c\u4e0e\u5ea6\u91cf\u8bf1\u5bfc\u7684\u62d3\u6251\u76f8\u5bb9\u3002", "motivation": "\u4e3a\u5206\u7c7b\u968f\u673a\u53d8\u91cf\u5efa\u7acb\u4e00\u79cd\u5ea6\u91cf\u7ed3\u6784\uff0c\u5e76\u63a2\u7d22\u5176\u4ee3\u6570\u6027\u8d28\u4e0e\u62d3\u6251\u6027\u8d28\u4e4b\u95f4\u7684\u76f8\u5bb9\u5173\u7cfb\u3002", "method": "\u57fa\u4e8e\u71b5\u548c\u5bf9\u79f0\u4e0d\u786e\u5b9a\u6027\u5b9a\u4e49\u5206\u7c7b\u968f\u673a\u53d8\u91cf\u7684\u5ea6\u91cf\uff0c\u6784\u9020\u5546\u7a7a\u95f4\uff0c\u5e76\u8bc1\u660e\u8be5\u7a7a\u95f4\u5177\u6709\u4ea4\u6362\u5e7a\u534a\u7fa4\u7ed3\u6784\u3002", "result": "\u6210\u529f\u5b9a\u4e49\u4e86\u5206\u7c7b\u968f\u673a\u53d8\u91cf\u7684\u5ea6\u91cf\uff0c\u8be5\u5ea6\u91cf\u53ef\u5728\u5546\u7a7a\u95f4\u4e2d\u63a8\u5e7f\uff0c\u4e14\u5546\u7a7a\u95f4\u5177\u6709\u4e0e\u5ea6\u91cf\u62d3\u6251\u76f8\u5bb9\u7684\u8fde\u7eed\u4ea4\u6362\u5e7a\u534a\u7fa4\u8fd0\u7b97\u3002", "conclusion": "\u5206\u7c7b\u968f\u673a\u53d8\u91cf\u53ef\u4ee5\u914d\u5907\u5ea6\u91cf\u7ed3\u6784\uff0c\u5176\u5546\u7a7a\u95f4\u540c\u65f6\u5177\u6709\u4ee3\u6570\uff08\u4ea4\u6362\u5e7a\u534a\u7fa4\uff09\u548c\u62d3\u6251\u7ed3\u6784\uff0c\u4e14\u4e24\u8005\u76f8\u5bb9\uff0c\u4e3a\u4fe1\u606f\u8bba\u4e0e\u4ee3\u6570\u62d3\u6251\u7684\u4ea4\u53c9\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2512.03438", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03438", "abs": "https://arxiv.org/abs/2512.03438", "authors": ["Reuben Tan", "Baolin Peng", "Zhengyuan Yang", "Hao Cheng", "Oier Mees", "Theodore Zhao", "Andrea Tupini", "Isar Meijier", "Qianhui Wu", "Yuncong Yang", "Lars Liden", "Yu Gu", "Sheng Zhang", "Xiaodong Liu", "Lijuan Wang", "Marc Pollefeys", "Yong Jae Lee", "Jianfeng Gao"], "title": "Multimodal Reinforcement Learning with Agentic Verifier for AI Agents", "comment": null, "summary": "Agentic reasoning models trained with multimodal reinforcement learning (MMRL) have become increasingly capable, yet they are almost universally optimized using sparse, outcome-based rewards computed based on the final answers. Richer rewards computed from the reasoning tokens can improve learning significantly by providing more fine-grained guidance. However, it is challenging to compute more informative rewards in MMRL beyond those based on outcomes since different samples may require different scoring functions and teacher models may provide noisy reward signals too. In this paper, we introduce the Argos (Agentic Reward for Grounded & Objective Scoring), a principled reward agent to train multimodal reasoning models for agentic tasks. For each sample, Argos selects from a pool of teacher-model derived and rule-based scoring functions to simultaneously evaluate: (i) final response accuracy, (ii) spatiotemporal localization of referred entities and actions, and (iii) the quality of the reasoning process. We find that by leveraging our agentic verifier across both SFT data curation and RL training, our model achieves state-of-the-art results across multiple agentic tasks such as spatial reasoning, visual hallucination as well as robotics and embodied AI benchmarks. Critically, we demonstrate that just relying on SFT post-training on highly curated reasoning data is insufficient, as agents invariably collapse to ungrounded solutions during RL without our online verification. We also show that our agentic verifier can help to reduce reward-hacking in MMRL. Finally, we also provide a theoretical justification for the effectiveness of Argos through the concept of pareto-optimality.", "AI": {"tldr": "Argos\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u6a21\u6001\u5f3a\u5316\u5b66\u4e60\u7684\u667a\u80fd\u5956\u52b1\u4ee3\u7406\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u5730\u7ec4\u5408\u6559\u5e08\u6a21\u578b\u548c\u89c4\u5219\u8bc4\u5206\u51fd\u6570\u6765\u8bc4\u4f30\u6700\u7ec8\u7b54\u6848\u3001\u65f6\u7a7a\u5b9a\u4f4d\u548c\u63a8\u7406\u8fc7\u7a0b\u8d28\u91cf\uff0c\u663e\u8457\u63d0\u5347\u667a\u80fd\u4f53\u8bad\u7ec3\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5f3a\u5316\u5b66\u4e60\u4e3b\u8981\u4f9d\u8d56\u57fa\u4e8e\u6700\u7ec8\u7ed3\u679c\u7684\u7a00\u758f\u5956\u52b1\uff0c\u7f3a\u4e4f\u5bf9\u63a8\u7406\u8fc7\u7a0b\u7684\u7ec6\u7c92\u5ea6\u6307\u5bfc\u3002\u4e0d\u540c\u6837\u672c\u9700\u8981\u4e0d\u540c\u7684\u8bc4\u5206\u51fd\u6570\uff0c\u4e14\u6559\u5e08\u6a21\u578b\u53ef\u80fd\u63d0\u4f9b\u566a\u58f0\u4fe1\u53f7\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u667a\u80fd\u7684\u5956\u52b1\u673a\u5236\u3002", "method": "\u63d0\u51faArgos\u5956\u52b1\u4ee3\u7406\uff0c\u4e3a\u6bcf\u4e2a\u6837\u672c\u4ece\u6559\u5e08\u6a21\u578b\u548c\u89c4\u5219\u8bc4\u5206\u51fd\u6570\u6c60\u4e2d\u9009\u62e9\u5408\u9002\u7684\u8bc4\u5206\u51fd\u6570\uff0c\u540c\u65f6\u8bc4\u4f30\uff1a1)\u6700\u7ec8\u54cd\u5e94\u51c6\u786e\u6027\uff1b2)\u65f6\u7a7a\u5b9a\u4f4d\u8d28\u91cf\uff1b3)\u63a8\u7406\u8fc7\u7a0b\u8d28\u91cf\u3002\u5728SFT\u6570\u636e\u7b5b\u9009\u548cRL\u8bad\u7ec3\u4e2d\u90fd\u4f7f\u7528\u8be5\u9a8c\u8bc1\u5668\u3002", "result": "\u5728\u7a7a\u95f4\u63a8\u7406\u3001\u89c6\u89c9\u5e7b\u89c9\u3001\u673a\u5668\u4eba\u548c\u5177\u8eabAI\u7b49\u591a\u4e2a\u667a\u80fd\u4f53\u4efb\u52a1\u4e0a\u53d6\u5f97\u6700\u5148\u8fdb\u7ed3\u679c\u3002\u8bc1\u660e\u4ec5\u4f9d\u8d56SFT\u540e\u8bad\u7ec3\u4f1a\u5d29\u6e83\u5230\u975e\u63a5\u5730\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u800c\u5728\u7ebf\u9a8c\u8bc1\u80fd\u9632\u6b62\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u3002", "conclusion": "Argos\u901a\u8fc7\u5e15\u7d2f\u6258\u6700\u4f18\u6027\u7406\u8bba\u8bc1\u660e\u5176\u6709\u6548\u6027\uff0c\u4e3a\u591a\u6a21\u6001\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u7684\u5956\u52b1\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u667a\u80fd\u4f53\u6027\u80fd\u5e76\u51cf\u5c11\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\u3002"}}
{"id": "2512.03528", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.03528", "abs": "https://arxiv.org/abs/2512.03528", "authors": ["Guang Yang", "Tianpei Yang", "Jingwen Qiao", "Yanqing Wu", "Jing Huo", "Xingguo Chen", "Yang Gao"], "title": "Multi-Agent Reinforcement Learning with Communication-Constrained Priors", "comment": null, "summary": "Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u4fe1\u53d7\u9650\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u4e92\u4fe1\u606f\u4f30\u8ba1\u5668\u533a\u5206\u6709\u635f\u548c\u65e0\u635f\u6d88\u606f\u5bf9\u5206\u5e03\u5f0f\u51b3\u7b56\u7684\u5f71\u54cd\uff0c\u5e76\u5c06\u5176\u91cf\u5316\u5230\u5168\u5c40\u5956\u52b1\u4e2d", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u666e\u904d\u5b58\u5728\u6709\u635f\u901a\u4fe1\u95ee\u9898\uff0c\u73b0\u6709\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u901a\u4fe1\u65b9\u6cd5\u7531\u4e8e\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u6709\u9650\uff0c\u96be\u4ee5\u5e94\u7528\u4e8e\u590d\u6742\u52a8\u6001\u7684\u771f\u5b9e\u73af\u5883", "method": "\u63d0\u51fa\u901a\u7528\u901a\u4fe1\u7ea6\u675f\u6a21\u578b\u7edf\u4e00\u63cf\u8ff0\u4e0d\u540c\u573a\u666f\u7684\u901a\u4fe1\u6761\u4ef6\uff0c\u4f5c\u4e3a\u5b66\u4e60\u5148\u9a8c\u533a\u5206\u6709\u635f\u548c\u65e0\u635f\u6d88\u606f\uff1b\u4f7f\u7528\u53cc\u4e92\u4fe1\u606f\u4f30\u8ba1\u5668\u89e3\u8026\u6709\u635f\u548c\u65e0\u635f\u6d88\u606f\u5bf9\u5206\u5e03\u5f0f\u51b3\u7b56\u7684\u5f71\u54cd\uff1b\u5f15\u5165\u901a\u4fe1\u7ea6\u675f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u901a\u4fe1\u6d88\u606f\u5f71\u54cd\u91cf\u5316\u5230\u5168\u5c40\u5956\u52b1", "result": "\u5728\u591a\u4e2a\u901a\u4fe1\u7ea6\u675f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u63d0\u51fa\u7684\u901a\u4fe1\u7ea6\u675f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6709\u635f\u901a\u4fe1\u95ee\u9898\uff0c\u63d0\u9ad8\u5728\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027"}}
{"id": "2512.03549", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03549", "abs": "https://arxiv.org/abs/2512.03549", "authors": ["Yuki Orimo", "Iori Kurata", "Hodaka Mori", "Ryuhei Okuno", "Ryohto Sawada", "Daisuke Okanohara"], "title": "PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks", "comment": null, "summary": "We introduce PARC, a coding agent for the autonomous and robust execution of long-horizon computational tasks. PARC is built on a hierarchical multi-agent architecture incorporating task planning, execution, and a mechanism that evaluates its own actions and their outcomes from an independent context and provides feedback, namely self-assessment and self-feedback. This design enables PARC to detect and correct high-level strategic errors and sustain progress without human intervention. We evaluate PARC across computational science and data science tasks. In materials science, it autonomously reproduces key results from studies on lithium-ion conduction and alloy segregation. In particular, it coordinates dozens of parallel simulation tasks, each requiring roughly 43 hours of computation, managing orchestration, monitoring, and error correction end-to-end. In Kaggle-based experiments, starting from minimal natural-language instructions, PARC conducts data analysis and implements search strategies, producing solutions competitive with human-engineered baselines. These results highlight the potential of integrating a hierarchical multi-agent system with self-assessment and self-feedback to enable AI systems capable of independent, large-scale scientific and analytical work.", "AI": {"tldr": "PARC\u662f\u4e00\u4e2a\u7528\u4e8e\u81ea\u4e3b\u6267\u884c\u957f\u65f6\u7a0b\u8ba1\u7b97\u4efb\u52a1\u7684\u7f16\u7801\u4ee3\u7406\uff0c\u91c7\u7528\u5206\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5177\u5907\u81ea\u6211\u8bc4\u4f30\u548c\u53cd\u9988\u673a\u5236\uff0c\u80fd\u591f\u5728\u6750\u6599\u79d1\u5b66\u548cKaggle\u7ade\u8d5b\u4e2d\u81ea\u4e3b\u5b8c\u6210\u590d\u6742\u4efb\u52a1\u3002", "motivation": "\u5f00\u53d1\u80fd\u591f\u81ea\u4e3b\u6267\u884c\u957f\u65f6\u7a0b\u8ba1\u7b97\u4efb\u52a1\u7684AI\u7cfb\u7edf\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u79d1\u5b66\u548c\u5206\u6790\u5de5\u4f5c\u7684\u81ea\u52a8\u5316\u3002", "method": "\u91c7\u7528\u5206\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5305\u542b\u4efb\u52a1\u89c4\u5212\u3001\u6267\u884c\u3001\u81ea\u6211\u8bc4\u4f30\u548c\u53cd\u9988\u673a\u5236\uff0c\u80fd\u591f\u4ece\u72ec\u7acb\u4e0a\u4e0b\u6587\u8bc4\u4f30\u81ea\u8eab\u884c\u4e3a\u5e76\u7ea0\u6b63\u9ad8\u5c42\u6b21\u6218\u7565\u9519\u8bef\u3002", "result": "\u5728\u6750\u6599\u79d1\u5b66\u4e2d\u6210\u529f\u590d\u73b0\u9502\u79bb\u5b50\u4f20\u5bfc\u548c\u5408\u91d1\u504f\u6790\u7814\u7a76\u7684\u5173\u952e\u7ed3\u679c\uff0c\u534f\u8c03\u6570\u5341\u4e2a\u5e76\u884c\u6a21\u62df\u4efb\u52a1\uff08\u6bcf\u4e2a\u7ea643\u5c0f\u65f6\u8ba1\u7b97\uff09\uff1b\u5728Kaggle\u5b9e\u9a8c\u4e2d\uff0c\u4ece\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u51fa\u53d1\uff0c\u5b9e\u73b0\u6570\u636e\u5206\u6790\u5e76\u4ea7\u751f\u4e0e\u4eba\u5de5\u57fa\u51c6\u7ade\u4e89\u7684\u7ed3\u679c\u3002", "conclusion": "\u5206\u5c42\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7ed3\u5408\u81ea\u6211\u8bc4\u4f30\u548c\u53cd\u9988\u673a\u5236\u80fd\u591f\u5b9e\u73b0AI\u7cfb\u7edf\u72ec\u7acb\u8fdb\u884c\u5927\u89c4\u6a21\u79d1\u5b66\u548c\u5206\u6790\u5de5\u4f5c\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.03560", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.03560", "abs": "https://arxiv.org/abs/2512.03560", "authors": ["Gianni Molinari", "Fabio Ciravegna"], "title": "Reason-Plan-ReAct: A Reasoner-Planner Supervising a ReAct Executor for Complex Enterprise Tasks", "comment": "11 pages, 1 figure, 2 tables, Workshop AAAI 2026 agentic AI Benchmarks and Applications for Enterprise Tasks", "summary": "Despite recent advances, autonomous agents often struggle to solve complex tasks in enterprise domains that require coordinating multiple tools and processing diverse data sources. This struggle is driven by two main limitations. First, single-agent architectures enforce a monolithic plan-execute loop, which directly causes trajectory instability. Second, the requirement to use local open-weight models for data privacy introduces smaller context windows leading to the rapid consumption of context from large tool outputs. To solve this problem we introduce RP-ReAct (Reasoner Planner-ReAct), a novel multi-agent approach that fundamentally decouples strategic planning from low-level execution to achieve superior reliability and efficiency. RP-ReAct consists of a Reasoner Planner Agent (RPA), responsible for planning each sub-step, continuously analysing the execution results using the strong reasoning capabilities of a Large Reasoning Model, and one or multiple Proxy-Execution Agent (PEA) that translates sub-steps into concrete tool interactions using a ReAct approach. Crucially, we incorporate a context-saving strategy within the PEA to mitigate context window overflow by managing large tool outputs via external storage and on-demand access. We evaluate RP-ReAct, on the challenging, multi-domain ToolQA benchmark using a diverse set of six open-weight reasoning models. Our empirical results show that RP-ReAct achieves superior performance and improved generalization ability over state-of-the-art baselines when addressing diverse complex tasks across the evaluated domains. Furthermore we establish the enhanced robustness and stability of our approach across different model scales, paving the way for effective and deployable agentic solutions for enterprises.", "AI": {"tldr": "RP-ReAct\u662f\u4e00\u79cd\u65b0\u578b\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6218\u7565\u89c4\u5212\u4e0e\u4f4e\u7ea7\u6267\u884c\u89e3\u8026\uff0c\u89e3\u51b3\u4f01\u4e1a\u73af\u5883\u4e2d\u81ea\u4e3b\u667a\u80fd\u4f53\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\u7684\u8f68\u8ff9\u4e0d\u7a33\u5b9a\u6027\u548c\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u4f01\u4e1a\u9886\u57df\u590d\u6742\u4efb\u52a1\u9700\u8981\u534f\u8c03\u591a\u4e2a\u5de5\u5177\u548c\u5904\u7406\u591a\u6837\u5316\u6570\u636e\u6e90\uff0c\u4f46\u73b0\u6709\u81ea\u4e3b\u667a\u80fd\u4f53\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u9650\u5236\uff1a1\uff09\u5355\u667a\u80fd\u4f53\u67b6\u6784\u7684\u5355\u4e00\u89c4\u5212-\u6267\u884c\u5faa\u73af\u5bfc\u81f4\u8f68\u8ff9\u4e0d\u7a33\u5b9a\uff1b2\uff09\u6570\u636e\u9690\u79c1\u8981\u6c42\u4f7f\u7528\u672c\u5730\u5f00\u6e90\u6a21\u578b\uff0c\u4f46\u8f83\u5c0f\u4e0a\u4e0b\u6587\u7a97\u53e3\u4f1a\u56e0\u5927\u578b\u5de5\u5177\u8f93\u51fa\u800c\u8fc5\u901f\u8017\u5c3d\u3002", "method": "RP-ReAct\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5305\u542bReasoner Planner Agent\uff08RPA\uff09\u8d1f\u8d23\u4f7f\u7528\u5927\u578b\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u6218\u7565\u89c4\u5212\u548c\u5206\u6790\u6267\u884c\u7ed3\u679c\uff0c\u4ee5\u53ca\u4e00\u4e2a\u6216\u591a\u4e2aProxy-Execution Agent\uff08PEA\uff09\u4f7f\u7528ReAct\u65b9\u6cd5\u5c06\u5b50\u6b65\u9aa4\u8f6c\u6362\u4e3a\u5177\u4f53\u5de5\u5177\u4ea4\u4e92\u3002PEA\u4e2d\u91c7\u7528\u4e0a\u4e0b\u6587\u4fdd\u5b58\u7b56\u7565\uff0c\u901a\u8fc7\u5916\u90e8\u5b58\u50a8\u548c\u6309\u9700\u8bbf\u95ee\u7ba1\u7406\u5927\u578b\u5de5\u5177\u8f93\u51fa\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u591a\u9886\u57dfToolQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528\u516d\u79cd\u4e0d\u540c\u7684\u5f00\u6e90\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0cRP-ReAct\u5728\u6027\u80fd\u3001\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0b\u8868\u73b0\u51fa\u589e\u5f3a\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "RP-ReAct\u901a\u8fc7\u89e3\u8026\u89c4\u5212\u4e0e\u6267\u884c\u3001\u7ba1\u7406\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\uff0c\u4e3a\u4f01\u4e1a\u73af\u5883\u63d0\u4f9b\u4e86\u6709\u6548\u4e14\u53ef\u90e8\u7f72\u7684\u667a\u80fd\u4f53\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u591a\u9886\u57df\u590d\u6742\u4efb\u52a1\u5904\u7406\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2512.03571", "categories": ["cs.AI", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.03571", "abs": "https://arxiv.org/abs/2512.03571", "authors": ["Zhening Li", "Armando Solar-Lezama", "Yisong Yue", "Stephan Zheng"], "title": "EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths", "comment": "65 pages, 2 figures, published in NeurIPS 2025", "summary": "We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce \"probabilistic angelic nondeterminism\" (\"PAN\"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.", "AI": {"tldr": "\u63d0\u51faPAN\u7f16\u7a0b\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u79bb\u6838\u5fc3\u5de5\u4f5c\u6d41\u903b\u8f91\u548c\u63a8\u7406\u65f6\u7b56\u7565\uff0c\u7b80\u5316LLM\u667a\u80fd\u4f53\u5f00\u53d1\uff0c\u5e76\u5b9e\u73b0EnCompass\u6846\u67b6", "motivation": "\u5f53\u524d\u667a\u80fd\u4f53\u7f16\u7a0b\u65b9\u6cd5\u901a\u5e38\u5c06\u6838\u5fc3\u5de5\u4f5c\u6d41\u903b\u8f91\u548c\u63a8\u7406\u65f6\u7b56\u7565\uff08\u5982\u6811\u641c\u7d22\uff09\u8026\u5408\u5728\u4e00\u8d77\uff0c\u8fd9\u79cd\u8026\u5408\u4f7f\u5f97\u5b9e\u9a8c\u4e0d\u540c\u63a8\u7406\u7b56\u7565\u53d8\u5f97\u56f0\u96be", "method": "\u63d0\u51fa\"\u6982\u7387\u5929\u4f7f\u975e\u786e\u5b9a\u6027\"\uff08PAN\uff09\u7f16\u7a0b\u6a21\u578b\uff0c\u5206\u79bb\u5de5\u4f5c\u6d41\u548c\u63a8\u7406\u7b56\u7565\uff1b\u5b9e\u73b0EnCompass\u6846\u67b6\uff0c\u4f7f\u7528Python\u88c5\u9970\u5668\u5c06\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u5e8f\u7f16\u8bd1\u4e3a\u641c\u7d22\u7a7a\u95f4", "result": "\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u8ba9\u7a0b\u5e8f\u5458\u5feb\u901f\u63d0\u9ad8\u667a\u80fd\u4f53\u53ef\u9760\u6027\uff0c\u8f7b\u677e\u5207\u6362\u4e0d\u540c\u63a8\u7406\u65f6\u7b56\u7565\uff0c\u4e14\u53ea\u9700\u5c11\u91cf\u989d\u5916\u7f16\u7801", "conclusion": "PAN\u7f16\u7a0b\u6a21\u578b\u548cEnCompass\u6846\u67b6\u4e3aLLM\u667a\u80fd\u4f53\u5f00\u53d1\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u3001\u53ef\u7ef4\u62a4\u7684\u65b9\u6cd5\uff0c\u89e3\u8026\u4e86\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u548c\u63a8\u7406\u7b56\u7565\u9009\u62e9"}}
{"id": "2512.03607", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03607", "abs": "https://arxiv.org/abs/2512.03607", "authors": ["Yusen Wu", "Xiaotie Deng"], "title": "DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization", "comment": null, "summary": "This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.\n  Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.", "AI": {"tldr": "DeepRule\u662f\u4e00\u4e2a\u7528\u4e8e\u96f6\u552e\u54c1\u7c7b\u548c\u5b9a\u4ef7\u4f18\u5316\u7684\u81ea\u52a8\u5316\u4e1a\u52a1\u89c4\u5219\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u5c42\u67b6\u6784\u89e3\u51b3\u7406\u8bba\u6a21\u578b\u4e0e\u73b0\u5b9e\u7ecf\u6d4e\u590d\u6742\u6027\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7406\u8bba\u6a21\u578b\u4e0e\u771f\u5b9e\u4e16\u754c\u7ecf\u6d4e\u590d\u6742\u6027\u5b58\u5728\u7cfb\u7edf\u6027\u4e0d\u5339\u914d\uff0c\u5177\u4f53\u8868\u73b0\u4e3a\u4e09\u4e2a\u5173\u952e\u5dee\u8ddd\uff1a1) \u975e\u7ed3\u6784\u5316\u6587\u672c\u6570\u636e\u6a21\u6001\u4e0d\u5339\u914d\uff1b2) \u52a8\u6001\u7279\u5f81\u7ea0\u7f20\u6311\u6218\uff1b3) \u591a\u5c42\u4e1a\u52a1\u7ea6\u675f\u5bfc\u81f4\u7684\u8fd0\u8425\u4e0d\u53ef\u884c\u6027\u3002", "method": "\u91c7\u7528\u4e09\u5c42\u67b6\u6784\uff1a1) \u6df7\u5408\u77e5\u8bc6\u878d\u5408\u5f15\u64ce\uff0c\u4f7f\u7528LLM\u6df1\u5ea6\u8bed\u4e49\u89e3\u6790\u975e\u7ed3\u6784\u5316\u6587\u672c\uff1b2) \u535a\u5f08\u8bba\u7ea6\u675f\u4f18\u5316\u673a\u5236\uff0c\u901a\u8fc7\u53cc\u8fb9\u6548\u7528\u51fd\u6570\u52a8\u6001\u534f\u8c03\u4f9b\u5e94\u94fe\u5229\u76ca\uff1b3) \u53ef\u89e3\u91ca\u51b3\u7b56\u84b8\u998f\u63a5\u53e3\uff0c\u5229\u7528LLM\u5f15\u5bfc\u7684\u7b26\u53f7\u56de\u5f52\u4f18\u5316\u5b9a\u4ef7\u7b56\u7565\u548c\u53ef\u5ba1\u8ba1\u4e1a\u52a1\u89c4\u5219\u3002", "result": "\u5728\u771f\u5b9e\u96f6\u552e\u73af\u5883\u4e2d\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u7cfb\u7edf\u6027B2C\u57fa\u7ebf\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5229\u6da6\uff0c\u540c\u65f6\u786e\u4fdd\u8fd0\u8425\u53ef\u884c\u6027\u3002", "conclusion": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u95ed\u73af\u7ba1\u9053\uff0c\u7edf\u4e00\u4e86\u975e\u7ed3\u6784\u5316\u77e5\u8bc6\u6ce8\u5165\u3001\u591a\u667a\u80fd\u4f53\u4f18\u5316\u548c\u53ef\u89e3\u91ca\u7b56\u7565\u5408\u6210\uff0c\u4e3a\u771f\u5b9e\u7ecf\u6d4e\u667a\u80fd\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.03627", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03627", "abs": "https://arxiv.org/abs/2512.03627", "authors": ["Junming Liu", "Yifei Sun", "Weihua Cheng", "Haodong Lei", "Yirong Chen", "Licheng Wen", "Xuemeng Yang", "Daocheng Fu", "Pinlong Cai", "Nianchen Deng", "Yi Yu", "Shuyue Hu", "Botian Shi", "Ding Wang"], "title": "MemVerse: Multimodal Memory for Lifelong Learning Agents", "comment": "11 pages, 2 figures, 2 tables", "summary": "Despite rapid progress in large-scale language and vision models, AI agents still suffer from a fundamental limitation: they cannot remember. Without reliable memory, agents catastrophically forget past experiences, struggle with long-horizon reasoning, and fail to operate coherently in multimodal or interactive environments. We introduce MemVerse, a model-agnostic, plug-and-play memory framework that bridges fast parametric recall with hierarchical retrieval-based memory, enabling scalable and adaptive multimodal intelligence. MemVerse maintains short-term memory for recent context while transforming raw multimodal experiences into structured long-term memories organized as hierarchical knowledge graphs. This design supports continual consolidation, adaptive forgetting, and bounded memory growth. To handle real-time demands, MemVerse introduces a periodic distillation mechanism that compresses essential knowledge from long-term memory into the parametric model, allowing fast, differentiable recall while preserving interpretability. Extensive experiments demonstrate that MemVerse significantly improves multimodal reasoning and continual learning efficiency, empowering agents to remember, adapt, and reason coherently across extended interactions.", "AI": {"tldr": "MemVerse\u662f\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u5373\u63d2\u5373\u7528\u8bb0\u5fc6\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5feb\u901f\u53c2\u6570\u5316\u53ec\u56de\u4e0e\u5206\u5c42\u68c0\u7d22\u5f0f\u8bb0\u5fc6\uff0c\u89e3\u51b3AI\u4ee3\u7406\u7684\u8bb0\u5fc6\u95ee\u9898\uff0c\u652f\u6301\u591a\u6a21\u6001\u6301\u7eed\u5b66\u4e60\u3002", "motivation": "\u5c3d\u7ba1\u5927\u89c4\u6a21\u8bed\u8a00\u548c\u89c6\u89c9\u6a21\u578b\u8fdb\u5c55\u8fc5\u901f\uff0c\u4f46AI\u4ee3\u7406\u4ecd\u7f3a\u4e4f\u8bb0\u5fc6\u80fd\u529b\uff0c\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8\u3001\u957f\u65f6\u63a8\u7406\u56f0\u96be\u4ee5\u53ca\u5728\u591a\u6a21\u6001\u4ea4\u4e92\u73af\u5883\u4e2d\u65e0\u6cd5\u8fde\u8d2f\u64cd\u4f5c\u3002", "method": "MemVerse\u91c7\u7528\u6a21\u578b\u65e0\u5173\u7684\u5373\u63d2\u5373\u7528\u67b6\u6784\uff0c\u7ed3\u5408\u77ed\u671f\u8bb0\u5fc6\u548c\u5206\u5c42\u68c0\u7d22\u5f0f\u957f\u671f\u8bb0\u5fc6\uff08\u7ec4\u7ec7\u4e3a\u5c42\u6b21\u77e5\u8bc6\u56fe\u8c31\uff09\uff0c\u901a\u8fc7\u5468\u671f\u6027\u84b8\u998f\u673a\u5236\u5c06\u957f\u671f\u8bb0\u5fc6\u538b\u7f29\u5230\u53c2\u6570\u6a21\u578b\u4e2d\uff0c\u5b9e\u73b0\u5feb\u901f\u53ef\u5fae\u53ec\u56de\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMemVerse\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u63a8\u7406\u548c\u6301\u7eed\u5b66\u4e60\u6548\u7387\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u5728\u6269\u5c55\u4ea4\u4e92\u4e2d\u8bb0\u5fc6\u3001\u9002\u5e94\u548c\u8fde\u8d2f\u63a8\u7406\u3002", "conclusion": "MemVerse\u901a\u8fc7\u6865\u63a5\u53c2\u6570\u5316\u4e0e\u68c0\u7d22\u5f0f\u8bb0\u5fc6\uff0c\u89e3\u51b3\u4e86AI\u4ee3\u7406\u7684\u8bb0\u5fc6\u74f6\u9888\uff0c\u4e3a\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u81ea\u9002\u5e94\u7684\u591a\u6a21\u6001\u667a\u80fd\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2512.03762", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03762", "abs": "https://arxiv.org/abs/2512.03762", "authors": ["Jiawei Xu", "Fengfeng Wei", "Weineng Chen"], "title": "RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design", "comment": null, "summary": "Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.", "AI": {"tldr": "RoCo\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u89d2\u8272\u534f\u4f5c\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u7cfb\u7edf\uff0c\u901a\u8fc7\u56db\u4e2a\u4e13\u95e8\u89d2\u8272\uff08\u63a2\u7d22\u8005\u3001\u5229\u7528\u8005\u3001\u6279\u8bc4\u8005\u3001\u6574\u5408\u8005\uff09\u534f\u540c\u5de5\u4f5c\uff0c\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u7814\u7a76\u901a\u5e38\u53ea\u8003\u8651\u5355\u4e00\u89d2\u8272\uff0c\u9650\u5236\u4e86\u542f\u53d1\u5f0f\u7684\u591a\u6837\u6027\u548c\u8d28\u91cf\u3002\u9700\u8981\u4e00\u79cd\u591a\u89d2\u8272\u534f\u4f5c\u7cfb\u7edf\u6765\u589e\u5f3a\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faRoCo\u591a\u667a\u80fd\u4f53\u89d2\u8272\u534f\u4f5c\u7cfb\u7edf\uff0c\u5305\u542b\u56db\u4e2a\u4e13\u95e8\u89d2\u8272\uff1a\u63a2\u7d22\u8005\uff08\u521b\u9020\u6027\u3001\u591a\u6837\u6027\u9a71\u52a8\uff09\u3001\u5229\u7528\u8005\uff08\u4fdd\u5b88\u6027\u3001\u6548\u7387\u5bfc\u5411\uff09\u3001\u6279\u8bc4\u8005\uff08\u8bc4\u4f30\u6548\u679c\u5e76\u63d0\u4f9b\u53cd\u9988\uff09\u3001\u6574\u5408\u8005\uff08\u5e73\u8861\u521b\u65b0\u4e0e\u5229\u7528\uff09\u3002\u8fd9\u4e9b\u667a\u80fd\u4f53\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u591a\u8f6e\u8fc7\u7a0b\u8fdb\u884c\u4ea4\u4e92\uff0c\u5305\u62ec\u53cd\u9988\u3001\u7cbe\u70bc\u548c\u7cbe\u82f1\u7a81\u53d8\u3002", "result": "\u5728\u4e94\u4e2a\u4e0d\u540c\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\uff0c\u65e0\u8bba\u662f\u767d\u76d2\u8fd8\u662f\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\uff0cRoCo\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u751f\u6210\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u8d85\u8d8a\u4e86\u5305\u62ecReEvo\u548cHSEvo\u5728\u5185\u7684\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u79cd\u57fa\u4e8e\u89d2\u8272\u7684\u534f\u4f5c\u8303\u5f0f\u4e3a\u7a33\u5065\u4e14\u9ad8\u6027\u80fd\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u5efa\u7acb\u4e86\u65b0\u6807\u51c6\uff0c\u901a\u8fc7\u591a\u89d2\u8272\u534f\u4f5c\u663e\u8457\u63d0\u5347\u4e86\u542f\u53d1\u5f0f\u8bbe\u8ba1\u7684\u591a\u6837\u6027\u548c\u8d28\u91cf\u3002"}}
{"id": "2512.03783", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2512.03783", "abs": "https://arxiv.org/abs/2512.03783", "authors": ["Dongchao Yang", "Songxiang Liu", "Disong Wang", "Yuanyuan Wang", "Guanglu Wan", "Helen Meng"], "title": "Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning", "comment": null, "summary": "Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.", "AI": {"tldr": "Omni-AutoThink\uff1a\u4e00\u79cd\u81ea\u9002\u5e94\u63a8\u7406\u6846\u67b6\uff0c\u6839\u636e\u4efb\u52a1\u96be\u5ea6\u52a8\u6001\u8c03\u6574Omni\u6a21\u578b\u7684\u63a8\u7406\u6df1\u5ea6\uff0c\u63d0\u5347\u591a\u6a21\u6001\u63a8\u7406\u6027\u80fd", "motivation": "\u73b0\u6709Omni\u6a21\u578b\u5b58\u5728\u63a8\u7406\u884c\u4e3a\u50f5\u5316\u7684\u95ee\u9898\uff0c\u8981\u4e48\u5bf9\u7b80\u5355\u95ee\u9898\u8fc7\u5ea6\u63a8\u7406\uff0c\u8981\u4e48\u5728\u9700\u8981\u63a8\u7406\u65f6\u65e0\u6cd5\u6709\u6548\u63a8\u7406\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6839\u636e\u4efb\u52a1\u96be\u5ea6\u81ea\u9002\u5e94\u8c03\u6574\u63a8\u7406\u6df1\u5ea6\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1\uff09\u81ea\u9002\u5e94\u76d1\u7763\u5fae\u8c03\u9636\u6bb5\uff0c\u4f7f\u7528\u5927\u89c4\u6a21\u63a8\u7406\u589e\u5f3a\u6570\u636e\u8d4b\u4e88\u6a21\u578b\u57fa\u7840\u63a8\u7406\u80fd\u529b\uff1b2\uff09\u81ea\u9002\u5e94\u5f3a\u5316\u5b66\u4e60\u9636\u6bb5\uff0c\u57fa\u4e8e\u4efb\u52a1\u590d\u6742\u5ea6\u548c\u5956\u52b1\u53cd\u9988\u4f18\u5316\u63a8\u7406\u884c\u4e3a\u3002\u6784\u5efa\u4e86\u6db5\u76d6\u6587\u672c\u3001\u97f3\u9891\u3001\u89c6\u89c9\u7b49\u591a\u6a21\u6001\u7684\u81ea\u9002\u5e94\u63a8\u7406\u57fa\u51c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u76f8\u6bd4\u5148\u524d\u57fa\u7ebf\u663e\u8457\u63d0\u5347\u4e86\u81ea\u9002\u5e94\u63a8\u7406\u6027\u80fd\u3002\u6240\u6709\u57fa\u51c6\u6570\u636e\u548c\u4ee3\u7801\u5c06\u516c\u5f00\u3002", "conclusion": "Omni-AutoThink\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86Omni\u6a21\u578b\u63a8\u7406\u884c\u4e3a\u50f5\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u63a8\u7406\u6df1\u5ea6\u63d0\u5347\u4e86\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u81ea\u9002\u5e94\u63a8\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u57fa\u51c6\u548c\u5de5\u5177\u3002"}}
{"id": "2512.03887", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03887", "abs": "https://arxiv.org/abs/2512.03887", "authors": ["Saurav Prateek"], "title": "A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)", "comment": null, "summary": "The advancement in Large Language Models has driven the creation of complex agentic systems, such as Deep Research Agents (DRAs), to overcome the limitations of static Retrieval Augmented Generation (RAG) pipelines in handling complex, multi-turn research tasks. This paper introduces the Static Deep Research Agent (Static-DRA), a novel solution built upon a configurable and hierarchical Tree-based static workflow.\n  The core contribution is the integration of two user-tunable parameters, Depth and Breadth, which provide granular control over the research intensity. This design allows end-users to consciously balance the desired quality and comprehensiveness of the research report against the associated computational cost of Large Language Model (LLM) interactions. The agent's architecture, comprising Supervisor, Independent, and Worker agents, facilitates effective multi-hop information retrieval and parallel sub-topic investigation.\n  We evaluate the Static-DRA against the established DeepResearch Bench using the RACE (Reference-based Adaptive Criteria-driven Evaluation) framework. Configured with a depth of 2 and a breadth of 5, and powered by the gemini-2.5-pro model, the agent achieved an overall score of 34.72. Our experiments validate that increasing the configured Depth and Breadth parameters results in a more in-depth research process and a correspondingly higher evaluation score. The Static-DRA offers a pragmatic and resource-aware solution, empowering users with transparent control over the deep research process. The entire source code, outputs and benchmark results are open-sourced at https://github.com/SauravP97/Static-Deep-Research/", "AI": {"tldr": "\u63d0\u51faStatic-DRA\uff1a\u57fa\u65bc\u6a39\u72c0\u975c\u614b\u5de5\u4f5c\u6d41\u7684\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\uff0c\u901a\u904e\u53ef\u8abf\u53c3\u6578Depth\u548cBreadth\u63a7\u5236\u7814\u7a76\u5f37\u5ea6\uff0c\u5e73\u8861\u5831\u544a\u8cea\u91cf\u8207\u8a08\u7b97\u6210\u672c", "motivation": "\u70ba\u514b\u670d\u975c\u614bRAG\u7ba1\u9053\u5728\u8655\u7406\u8907\u96dc\u591a\u8f2a\u7814\u7a76\u4efb\u52d9\u6642\u7684\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u5148\u9032\u7684\u4ee3\u7406\u7cfb\u7d71\u4f86\u9032\u884c\u6df1\u5ea6\u7814\u7a76", "method": "\u8a2d\u8a08\u57fa\u65bc\u6a39\u72c0\u975c\u614b\u5de5\u4f5c\u6d41\u7684\u67b6\u69cb\uff0c\u5305\u542bSupervisor\u3001Independent\u548cWorker\u4ee3\u7406\uff0c\u5f15\u5165Depth\u548cBreadth\u5169\u500b\u7528\u6236\u53ef\u8abf\u53c3\u6578\u63a7\u5236\u7814\u7a76\u6df1\u5ea6\u548c\u5ee3\u5ea6", "result": "\u5728DeepResearch Bench\u4e0a\u4f7f\u7528RACE\u6846\u67b6\u8a55\u4f30\uff0c\u914d\u7f6eDepth=2\u3001Breadth=5\uff0c\u4f7f\u7528gemini-2.5-pro\u6a21\u578b\u7372\u5f9734.72\u5206\uff0c\u9a57\u8b49\u53c3\u6578\u589e\u52a0\u53ef\u63d0\u5347\u7814\u7a76\u6df1\u5ea6\u548c\u8a55\u5206", "conclusion": "Static-DRA\u63d0\u4f9b\u5be6\u7528\u4e14\u8cc7\u6e90\u611f\u77e5\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u8b93\u7528\u6236\u80fd\u900f\u660e\u63a7\u5236\u6df1\u5ea6\u7814\u7a76\u904e\u7a0b\uff0c\u5728\u5831\u544a\u8cea\u91cf\u8207\u8a08\u7b97\u6210\u672c\u9593\u53d6\u5f97\u5e73\u8861"}}
{"id": "2512.03931", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03931", "abs": "https://arxiv.org/abs/2512.03931", "authors": ["Vineel Tummala", "Daniela Inclezan"], "title": "Autonomous Agents and Policy Compliance: A Framework for Reasoning About Penalties", "comment": "27 pages, 5 figures", "summary": "This paper presents a logic programming-based framework for policy-aware autonomous agents that can reason about potential penalties for non-compliance and act accordingly. While prior work has primarily focused on ensuring compliance, our approach considers scenarios where deviating from policies may be necessary to achieve high-stakes goals. Additionally, modeling non-compliant behavior can assist policymakers by simulating realistic human decision-making. Our framework extends Gelfond and Lobo's Authorization and Obligation Policy Language (AOPL) to incorporate penalties and integrates Answer Set Programming (ASP) for reasoning. Compared to previous approaches, our method ensures well-formed policies, accounts for policy priorities, and enhances explainability by explicitly identifying rule violations and their consequences. Building on the work of Harders and Inclezan, we introduce penalty-based reasoning to distinguish between non-compliant plans, prioritizing those with minimal repercussions. To support this, we develop an automated translation from the extended AOPL into ASP and refine ASP-based planning algorithms to account for incurred penalties. Experiments in two domains demonstrate that our framework generates higher-quality plans that avoid harmful actions while, in some cases, also improving computational efficiency. These findings underscore its potential for enhancing autonomous decision-making and informing policy refinement. Under consideration in Theory and Practice of Logic Programming (TPLP).", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u903b\u8f91\u7f16\u7a0b\u7684\u6846\u67b6\uff0c\u4f7f\u81ea\u4e3b\u667a\u80fd\u4f53\u80fd\u63a8\u7406\u653f\u7b56\u8fdd\u89c4\u7684\u60e9\u7f5a\u5e76\u76f8\u5e94\u884c\u52a8\uff0c\u6269\u5c55AOPL\u8bed\u8a00\u7eb3\u5165\u60e9\u7f5a\u673a\u5236\uff0c\u4f7f\u7528ASP\u8fdb\u884c\u63a8\u7406\uff0c\u751f\u6210\u66f4\u4f18\u8ba1\u5212\u5e76\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u786e\u4fdd\u5408\u89c4\u6027\uff0c\u4f46\u5b9e\u9645\u573a\u666f\u4e2d\u53ef\u80fd\u9700\u8981\u504f\u79bb\u653f\u7b56\u4ee5\u5b9e\u73b0\u9ad8\u98ce\u9669\u76ee\u6807\u3002\u540c\u65f6\uff0c\u5efa\u6a21\u4e0d\u5408\u89c4\u884c\u4e3a\u6709\u52a9\u4e8e\u653f\u7b56\u5236\u5b9a\u8005\u6a21\u62df\u771f\u5b9e\u7684\u4eba\u7c7b\u51b3\u7b56\u8fc7\u7a0b\u3002", "method": "\u6269\u5c55Gelfond\u548cLobo\u7684\u6388\u6743\u4e0e\u4e49\u52a1\u653f\u7b56\u8bed\u8a00(AOPL)\u4ee5\u7eb3\u5165\u60e9\u7f5a\u673a\u5236\uff0c\u96c6\u6210\u7b54\u6848\u96c6\u7f16\u7a0b(ASP)\u8fdb\u884c\u63a8\u7406\uff0c\u5f00\u53d1\u4ece\u6269\u5c55AOPL\u5230ASP\u7684\u81ea\u52a8\u7ffb\u8bd1\uff0c\u5e76\u6539\u8fdb\u57fa\u4e8eASP\u7684\u89c4\u5212\u7b97\u6cd5\u4ee5\u8003\u8651\u60e9\u7f5a\u3002", "result": "\u5728\u4e24\u4e2a\u9886\u57df\u7684\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u6846\u67b6\u751f\u6210\u4e86\u66f4\u9ad8\u8d28\u91cf\u7684\u8ba1\u5212\uff0c\u907f\u514d\u4e86\u6709\u5bb3\u884c\u52a8\uff0c\u5e76\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002\u80fd\u591f\u533a\u5206\u4e0d\u5408\u89c4\u8ba1\u5212\uff0c\u4f18\u5148\u9009\u62e9\u60e9\u7f5a\u6700\u5c0f\u7684\u65b9\u6848\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6f5c\u529b\u589e\u5f3a\u81ea\u4e3b\u51b3\u7b56\u80fd\u529b\u5e76\u4e3a\u653f\u7b56\u5b8c\u5584\u63d0\u4f9b\u4fe1\u606f\uff0c\u901a\u8fc7\u660e\u786e\u8bc6\u522b\u89c4\u5219\u8fdd\u53cd\u53ca\u5176\u540e\u679c\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u786e\u4fdd\u653f\u7b56\u683c\u5f0f\u826f\u597d\u5e76\u8003\u8651\u653f\u7b56\u4f18\u5148\u7ea7\u3002"}}
{"id": "2512.03955", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.03955", "abs": "https://arxiv.org/abs/2512.03955", "authors": ["Niklas Jobs", "Luis Miguel Vieira da Silva", "Jayanth Somashekaraiah", "Maximilian Weigand", "David Kube", "Felix Gehlhoff"], "title": "Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol", "comment": "This work has been submitted to IFAC for possible publication", "summary": "Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u5728\u5de5\u4e1a\u81ea\u52a8\u5316\u4e2d\u89c4\u5212\u4e0e\u6267\u884c\u80fd\u529b\u7684\u6807\u51c6\u5316\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5305\u542b\u53ef\u6267\u884c\u7684Blocksworld\u4eff\u771f\u73af\u5883\u548c\u4e94\u4e2a\u590d\u6742\u5ea6\u7c7b\u522b\uff0c\u901a\u8fc7MCP\u534f\u8bae\u5b9e\u73b0\u4e0d\u540c\u667a\u80fd\u4f53\u67b6\u6784\u7684\u65e0\u7f1d\u8fde\u63a5\u548c\u8bc4\u4f30\u3002", "motivation": "\u5de5\u4e1a\u81ea\u52a8\u5316\u9700\u8981\u80fd\u591f\u9002\u5e94\u53d8\u5316\u4efb\u52a1\u548c\u73af\u5883\u7684\u7075\u6d3b\u63a7\u5236\u7b56\u7565\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u5177\u6709\u8fd9\u79cd\u81ea\u9002\u5e94\u89c4\u5212\u548c\u6267\u884c\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u7528\u4e8e\u7cfb\u7edf\u6bd4\u8f83\u7684\u6807\u51c6\u5316\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u5305\u542b\u53ef\u6267\u884c\u4eff\u771f\u73af\u5883\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u57fa\u4e8eBlocksworld\u95ee\u9898\u63d0\u4f9b\u4e94\u4e2a\u590d\u6742\u5ea6\u7c7b\u522b\uff0c\u901a\u8fc7\u96c6\u6210\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u4f5c\u4e3a\u6807\u51c6\u5316\u5de5\u5177\u63a5\u53e3\uff0c\u4f7f\u4e0d\u540c\u667a\u80fd\u4f53\u67b6\u6784\u65e0\u9700\u5b9e\u73b0\u7279\u5b9a\u4fee\u6539\u5373\u53ef\u8fde\u63a5\u548c\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u5355\u667a\u80fd\u4f53\u5b9e\u73b0\u5c55\u793a\u4e86\u57fa\u51c6\u6d4b\u8bd5\u7684\u9002\u7528\u6027\uff0c\u5efa\u7acb\u4e86\u7528\u4e8e\u6bd4\u8f83\u57fa\u4e8eLLM\u7684\u89c4\u5212\u4e0e\u6267\u884c\u65b9\u6cd5\u7684\u5b9a\u91cf\u6307\u6807\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u4e3a\u8bc4\u4f30\u548c\u6bd4\u8f83LLM\u667a\u80fd\u4f53\u5728\u5de5\u4e1a\u81ea\u52a8\u5316\u4e2d\u7684\u81ea\u9002\u5e94\u89c4\u5212\u4e0e\u6267\u884c\u80fd\u529b\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u5e73\u53f0\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8be5\u9886\u57df\u7684\u7814\u7a76\u53d1\u5c55\u3002"}}
