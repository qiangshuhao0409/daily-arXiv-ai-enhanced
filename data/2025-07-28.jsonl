{"id": "2507.18727", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.18727", "abs": "https://arxiv.org/abs/2507.18727", "authors": ["Liangshun Wu", "Wen Chen", "Qingqing Wu", "Xudong Bai", "Kunlun Wang"], "title": "RIS Codebook Index Assignment under Imperfect Control Links Using TSP-Inspired Optimization", "comment": "RIS codebook", "summary": "Reconfigurable Intelligent Surfaces (RIS) promise transformative gains in\nwireless communications by enabling programmable control of the propagation\nenvironment through discrete phase configurations. In practical deployments,\nthe control of RIS phase states is typically managed using finite codebooks,\nwith configuration indices transmitted over low latency, yet imperfect,\nwireless feedback channels. Even rare feedback bit errors can lead to\nsignificant mismatches between intended and applied RIS states, degrading\nsystem performance. This paper addresses the challenge of robust RIS codebook\nindex assignment by formulating it as a combinatorial optimization problem,\nequivalent to the Traveling Salesman Problem (TSP), where codewords are\n\"cities\" and edge weights reflect SNR degradation under codeword confusion. A\nnovel three-phase heuristic algorithm is proposed to solve this, consisting of\na provision phase, a shotgun phase, and a fuzzy concatenation phase. Simulation\nresults show that the method outperforms conventional indexing strategies and\nachieves near-optimal robustness to index errors, while also being scalable and\nhardwareagnostic for real time deployment. Future work includes multiple bits\nerror correction and online adaptive mapping for time varying channels."}
{"id": "2507.18969", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.18969", "abs": "https://arxiv.org/abs/2507.18969", "authors": ["Zeyi Lu", "Xiaoxiao Ma", "Yujun Huang", "Minxiao Chen", "Bin Chen", "Baoyi An", "Shu-Tao Xia"], "title": "EDPC: Accelerating Lossless Compression via Lightweight Probability Models and Decoupled Parallel Dataflow", "comment": null, "summary": "The explosive growth of multi-source multimedia data has significantly\nincreased the demands for transmission and storage, placing substantial\npressure on bandwidth and storage infrastructures. While Autoregressive\nCompression Models (ACMs) have markedly improved compression efficiency through\nprobabilistic prediction, current approaches remain constrained by two critical\nlimitations: suboptimal compression ratios due to insufficient fine-grained\nfeature extraction during probability modeling, and real-time processing\nbottlenecks caused by high resource consumption and low compression speeds. To\naddress these challenges, we propose Efficient Dual-path Parallel Compression\n(EDPC), a hierarchically optimized compression framework that synergistically\nenhances modeling capability and execution efficiency via coordinated dual-path\noperations. At the modeling level, we introduce the Information Flow Refinement\n(IFR) metric grounded in mutual information theory, and design a Multi-path\nByte Refinement Block (MBRB) to strengthen cross-byte dependency modeling via\nheterogeneous feature propagation. At the system level, we develop a Latent\nTransformation Engine (LTE) for compact high-dimensional feature representation\nand a Decoupled Pipeline Compression Architecture (DPCA) to eliminate\nencoding-decoding latency through pipelined parallelization. Experimental\nresults demonstrate that EDPC achieves comprehensive improvements over\nstate-of-the-art methods, including a 2.7x faster compression speed, and a 3.2%\nhigher compression ratio. These advancements establish EDPC as an efficient\nsolution for real-time processing of large-scale multimedia data in\nbandwidth-constrained scenarios. Our code is available at\nhttps://github.com/Magie0/EDPC."}
{"id": "2507.19136", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.19136", "abs": "https://arxiv.org/abs/2507.19136", "authors": ["Jiale Bai", "Hui-Ming Wang", "Liang Jin"], "title": "Dynamic Agile Reconfigurable Intelligent Surface Antenna (DARISA) MIMO: DoF Analysis and Effective DoF Optimization", "comment": "Accepted by IEEE Transactions on Wireless Communications", "summary": "In this paper, we propose a dynamic agile reconfigurable intelligent surface\nantenna (DARISA) array integrated into multi-input multi-output (MIMO)\ntransceivers. Each DARISA comprises a number of metasurface elements activated\nsimultaneously via a parallel feed network. The proposed system enables rapid\nand intelligent phase response adjustments for each metasurface element within\na single symbol duration, facilitating a dynamic agile adjustment of phase\nresponse (DAAPR) strategy. By analyzing the theoretical degrees of freedom\n(DoF) of the DARISA MIMO system under the DAAPR framework, we derive an\nexplicit relationship between DoF and critical system parameters, including\nagility frequentness (i.e., the number of phase adjustments of metasurface\nelements during one symbol period), cluster angular spread of wireless\nchannels, DARISA array size, and the number of transmit/receive DARISAs. The\nDoF result reveals a significant conclusion: when the number of receive DARISAs\nis smaller than that of transmit DARISAs, the DAAPR strategy of the DARISA MIMO\nenhances the overall system DoF. Furthermore, relying on DoF alone to measure\nchannel capacity is insufficient, so we analyze the effective DoF (EDoF) that\nreflects the impacts of the DoF and channel matrix singular value distribution\non capacity. We show channel capacity monotonically increases with EDoF, and\noptimize the agile phase responses of metasurface elements by using fractional\nprogramming (FP) and semidefinite relaxation (SDR) algorithms to maximize the\nEDoF. Simulations validate the theoretical DoF gains and reveal that increasing\nagility frequentness, metasurface element density, and phase quantization\naccuracy can enhance the EDoF. Additionally, densely deployed elements can\ncompensate for the loss in communication performance caused by lower phase\nquantization accuracy."}
{"id": "2507.18834", "categories": ["cs.NI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2507.18834", "abs": "https://arxiv.org/abs/2507.18834", "authors": ["ASM Rizvi", "John Heidemann", "David Plonka"], "title": "Third-Party Assessment of Mobile Performance in the 5G Era", "comment": null, "summary": "The web experience using mobile devices is important since a significant\nportion of the Internet traffic is initiated from mobile devices. In the era of\n5G, users expect a high-performance data network to stream media content and\nfor other latency-sensitive applications. In this paper, we characterize mobile\nexperience in terms of latency, throughput, and stability measured from a\ncommercial, globally-distributed CDN. Unlike prior work, CDN data provides a\nrelatively neutral, carrier-agnostic perspective, providing a clear view of\nmultiple and international providers. Our analysis of mobile client traffic\nshows mobile users sometimes experience markedly low latency, even as low as 6\nms. However, only the top 5% users regularly experience less than 20 ms of\nminimum latency. While 100 Mb/s throughput is not rare, we show around 60%\nusers observe less than 50 Mb/s throughput. We find the minimum mobile latency\nis generally stable at a specific location which can be an important\ncharacteristic for anomaly detection."}
{"id": "2507.19177", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.19177", "abs": "https://arxiv.org/abs/2507.19177", "authors": ["Yi Song", "Hao Xu", "Kai Wan", "Kai-Kit Wong", "Giuseppe Caire", "Shlomo Shamai"], "title": "Achievable Rates for a Distributed Antenna System with No Channel State Information at the Central Processor", "comment": null, "summary": "A recent trend in wireless communications considers the migration of\ntraditional monolithic base stations to the so-called disaggregated\narchitecture, where radio units (RUs) implement only the low-level physical\nlayer functionalities such as demodulation, and A/D conversion, while the\nhigh-level physical layer, such as channel decoding, is implemented as\nsoftware-defined functions running on general-purpose hardware in some remote\ncentral processing unit (CP). The corresponding information theoretic model for\nthe uplink (from the wireless users to the CP) is a multiaccess-relay channel\nwith primitive oblivious relays. The relays (RUs) are oblivious, as they are\nagnostic of the users codebooks, and primitive, since the fronthaul links (from\nRUs to CP) are error-free with limited capacity. This class of networks has\nbeen intensely studied in the information theoretic literature, where several\napproximated or exact (under certain conditions) capacity results have been\nderived. In particular, in the Gaussian case, the model has been analyzed for\nfixed and known channel state. This paper is motivated by the fact that, in\npractice, the channel state is a random process, and it is estimated at the\nbase station side through uplink pilot symbols sent by the users. The pilot\ndimension may take up a large portion of the channel coherence block, i.e., the\nnumber of symbols over which the channel state remains approximately constant.\nHence, sending both pilot and data symbols from the relays to the CP may\nrequire a significant overhead, especially when the fronthaul capacity is\nsmall. As a prototypical problem, we consider the ergodic achievable rate for a\ndiamond network formed by a single user and two relays where the channel state\nis known at the relays, but not known at the CP."}
{"id": "2507.19050", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.19050", "abs": "https://arxiv.org/abs/2507.19050", "authors": ["Qiong Wu", "Yu Xie", "Pingyi Fan", "Dong Qin", "Kezhi Wang", "Nan Cheng", "Khaled B. Letaief"], "title": "Large Language Model-Based Task Offloading and Resource Allocation for Digital Twin Edge Computing Networks", "comment": "This paper has been submitted to IEEE TMC", "summary": "In this paper, we propose a general digital twin edge computing network\ncomprising multiple vehicles and a server. Each vehicle generates multiple\ncomputing tasks within a time slot, leading to queuing challenges when\noffloading tasks to the server. The study investigates task offloading\nstrategies, queue stability, and resource allocation. Lyapunov optimization is\nemployed to transform long-term constraints into tractable short-term\ndecisions. To solve the resulting problem, an in-context learning approach\nbased on large language model (LLM) is adopted, replacing the conventional\nmulti-agent reinforcement learning (MARL) framework. Experimental results\ndemonstrate that the LLM-based method achieves comparable or even superior\nperformance to MARL."}
{"id": "2507.18775", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18775", "abs": "https://arxiv.org/abs/2507.18775", "authors": ["Ilche Georgievski", "Marco Aiello"], "title": "Initial Steps in Integrating Large Reasoning and Action Models for Service Composition", "comment": "16 pages, 3 figures, 19th Symposium and Summer School on\n  Service-Oriented Computing (SummerSOC)", "summary": "Service composition remains a central challenge in building adaptive and\nintelligent software systems, often constrained by limited reasoning\ncapabilities or brittle execution mechanisms. This paper explores the\nintegration of two emerging paradigms enabled by large language models: Large\nReasoning Models (LRMs) and Large Action Models (LAMs). We argue that LRMs\naddress the challenges of semantic reasoning and ecosystem complexity while\nLAMs excel in dynamic action execution and system interoperability. However,\neach paradigm has complementary limitations - LRMs lack grounded action\ncapabilities, and LAMs often struggle with deep reasoning. We propose an\nintegrated LRM-LAM architectural framework as a promising direction for\nadvancing automated service composition. Such a system can reason about service\nrequirements and constraints while dynamically executing workflows, thus\nbridging the gap between intention and execution. This integration has the\npotential to transform service composition into a fully automated,\nuser-friendly process driven by high-level natural language intent."}
{"id": "2507.19458", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.19458", "abs": "https://arxiv.org/abs/2507.19458", "authors": ["Amir Fard", "Arnold X. -X. Yuan"], "title": "Hierarchical Deep Reinforcement Learning Framework for Multi-Year Asset Management Under Budget Constraints", "comment": null, "summary": "Budget planning and maintenance optimization are crucial for infrastructure\nasset management, ensuring cost-effectiveness and sustainability. However, the\ncomplexity arising from combinatorial action spaces, diverse asset\ndeterioration, stringent budget constraints, and environmental uncertainty\nsignificantly limits existing methods' scalability. This paper proposes a\nHierarchical Deep Reinforcement Learning methodology specifically tailored to\nmulti-year infrastructure planning. Our approach decomposes the problem into\ntwo hierarchical levels: a high-level Budget Planner allocating annual budgets\nwithin explicit feasibility bounds, and a low-level Maintenance Planner\nprioritizing assets within the allocated budget. By structurally separating\nmacro-budget decisions from asset-level prioritization and integrating linear\nprogramming projection within a hierarchical Soft Actor-Critic framework, the\nmethod efficiently addresses exponential growth in the action space and ensures\nrigorous budget compliance. A case study evaluating sewer networks of varying\nsizes (10, 15, and 20 sewersheds) illustrates the effectiveness of the proposed\napproach. Compared to conventional Deep Q-Learning and enhanced genetic\nalgorithms, our methodology converges more rapidly, scales effectively, and\nconsistently delivers near-optimal solutions even as network size grows."}
{"id": "2507.19266", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.19266", "abs": "https://arxiv.org/abs/2507.19266", "authors": ["Hitesh Poddar", "Dimitri Gold", "Daewon Lee", "Nan Zhang", "Gokul Sridharan", "Henrik Asplund", "Mansoor Shaf"], "title": "Overview of 3GPP Release 19 Study on Channel Modeling Enhancements to TR 38.901 for 6G", "comment": null, "summary": "Channel models are a fundamental component of wireless communication systems,\nproviding critical insights into the physics of radio wave propagation. As\nwireless systems evolve every decade, the development of accurate and\nstandardized channel models becomes increasingly important for the development,\nevaluation and performance assessment of emerging technologies. An effort to\ndevelop a standardized channel model began around 2000 through the Third\nGeneration Partnership Project (3GPP) and the International Telecommunication\nUnion (ITU) with the aim of addressing a broad range of frequencies from sub-1\nGHz to 100 GHz. Prior efforts focused heavily on sub-6 GHz bands and mmWave\nbands, and there exist some gaps in accurately modeling the 7-24 GHz frequency\nrange, a promising candidate band for 6G. To address these gaps, 3GPP approved\na Release (Rel) 19 channel modeling study. This study resulted in several\nenhancements to the channel models, including the ability to accurately model a\nSuburban Macrocell (SMa) scenario, realistic User Terminal (UT) antenna models,\nvariability in the number of clusters, variability in the number of rays per\ncluster, a framework for capturing variability in power among all\npolarizations, near field (NF) propagation, and spatial non-stationarity (SNS)\neffects, all of which may be crucial for future 6G deployments. This paper\npresents the outcomes of this study and provides an overview of the underlying\nrationale, and key discussions that guided the validation, refinement, and\nenhancements of the 3GPP TR 38.901 channel models."}
{"id": "2507.19096", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.19096", "abs": "https://arxiv.org/abs/2507.19096", "authors": ["Jinbo Hou", "Stefanos Bakirtzis", "Kehai Qiu", "Sichong Liao", "Hui Song", "Haonan Hu", "Kezhi Wang", "Jie Zhang"], "title": "iPLAN: Redefining Indoor Wireless Network Planning Through Large Language Models", "comment": null, "summary": "Efficient indoor wireless network (IWN) planning is crucial for providing\nhigh-quality 5G in-building services. However, traditional meta-heuristic and\nartificial intelligence-based planning methods face significant challenges due\nto the intricate interplay between indoor environments (IEs) and IWN demands.\nIn this article, we present an indoor wireless network Planning with large\nLANguage models (iPLAN) framework, which integrates multi-modal IE\nrepresentations into large language model (LLM)-powered optimizers to improve\nIWN planning. First, we instate the role of LLMs as optimizers, outlining\nembedding techniques for IEs, and introducing two core applications of iPLAN:\n(i) IWN planning based on pre-existing IEs and (ii) joint design of IWN and IE\nfor new wireless-friendly buildings. For the former, we embed essential\ninformation into LLM optimizers by leveraging indoor descriptions,\ndomain-specific knowledge, and performance-driven perception. For the latter,\nwe conceptualize a multi-agent strategy, where intelligent agents\ncollaboratively address key planning sub-tasks in a step-by-step manner while\nensuring optimal trade-offs between the agents. The simulation results\ndemonstrate that iPLAN achieves superior performance in IWN planning tasks and\noptimizes building wireless performance through the joint design of IEs and\nIWNs, exemplifying a paradigm shift in IWN planning."}
{"id": "2507.18795", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18795", "abs": "https://arxiv.org/abs/2507.18795", "authors": ["Fatima Al-Ani", "Molly Wang", "Jevon Charles", "Aaron Ong", "Joshua Forday", "Vinayak Modi"], "title": "Simulation-Driven Reinforcement Learning in Queuing Network Routing Optimization", "comment": null, "summary": "This study focuses on the development of a simulation-driven reinforcement\nlearning (RL) framework for optimizing routing decisions in complex queueing\nnetwork systems, with a particular emphasis on manufacturing and communication\napplications. Recognizing the limitations of traditional queueing methods,\nwhich often struggle with dynamic, uncertain environments, we propose a robust\nRL approach leveraging Deep Deterministic Policy Gradient (DDPG) combined with\nDyna-style planning (Dyna-DDPG). The framework includes a flexible and\nconfigurable simulation environment capable of modeling diverse queueing\nscenarios, disruptions, and unpredictable conditions. Our enhanced Dyna-DDPG\nimplementation incorporates separate predictive models for next-state\ntransitions and rewards, significantly improving stability and sample\nefficiency. Comprehensive experiments and rigorous evaluations demonstrate the\nframework's capability to rapidly learn effective routing policies that\nmaintain robust performance under disruptions and scale effectively to larger\nnetwork sizes. Additionally, we highlight strong software engineering practices\nemployed to ensure reproducibility and maintainability of the framework,\nenabling practical deployment in real-world scenarios."}
{"id": "2507.19274", "categories": ["cs.IT", "math.IT", "15B52, 20C35, 94A12, 60G50, 60G70"], "pdf": "https://arxiv.org/pdf/2507.19274", "abs": "https://arxiv.org/abs/2507.19274", "authors": ["Timm Gilles", "Hartmut Führ"], "title": "Sparse Recovery from Group Orbits", "comment": null, "summary": "While most existing sparse recovery results allow only minimal structure\nwithin the measurement scheme, many practical problems possess significant\nstructure. To address this gap, we present a framework for structured\nmeasurements that are generated by random orbits of a group representation\nassociated with a finite group. We differentiate between two scenarios: one in\nwhich the sampling set is fixed and another in which the sampling set is\nrandomized. For each case, we derive an estimate for the number of measurements\nrequired to ensure that the restricted isometry property holds with high\nprobability. These estimates are contingent upon the specific representation\nemployed. For this reason, we analyze and characterize various representations\nthat yield favorable recovery outcomes, including the left regular\nrepresentation. Our work not only establishes a comprehensive framework for\nsparse recovery of group-structured measurements but also generalizes\nestablished measurement schemes, such as those derived from partial random\ncirculant matrices."}
{"id": "2507.19124", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.19124", "abs": "https://arxiv.org/abs/2507.19124", "authors": ["Muhammad Ahmed Mohsin", "Sagnik Bhattacharya", "Abhiram Gorle", "Muhammad Ali Jamshed", "John M. Cioffi"], "title": "AI Enabled 6G for Semantic Metaverse: Prospects, Challenges and Solutions for Future Wireless VR", "comment": "IEEE Wireless Communications Magazine", "summary": "Wireless support of virtual reality (VR) has challenges when a network has\nmultiple users, particularly for 3D VR gaming, digital AI avatars, and remote\nteam collaboration. This work addresses these challenges through investigation\nof the low-rank channels that inevitably occur when there are more active users\nthan there are degrees of spatial freedom, effectively often the number of\nantennas. The presented approach uses optimal nonlinear transceivers,\nequivalently generalized decision-feedback or successive cancellation for\nuplink and superposition or dirty-paper precoders for downlink. Additionally, a\npowerful optimization approach for the users' energy allocation and decoding\norder appears to provide large improvements over existing methods, effectively\nnearing theoretical optima. As the latter optimization methods pose real-time\nchallenges, approximations using deep reinforcement learning (DRL) are used to\napproximate best performance with much lower (5x at least) complexity.\nExperimental results show significantly larger sum rates and very large power\nsavings to attain the data rates found necessary to support VR. Experimental\nresults show the proposed algorithm outperforms current industry standards like\northogonal multiple access (OMA), non-orthogonal multiple access (NOMA), as\nwell as the highly researched methods in multi-carrier NOMA (MC-NOMA),\nenhancing sum data rate by 39%, 28%, and 16%, respectively, at a given power\nlevel. For the same data rate, it achieves power savings of 75%, 45%, and 40%,\nmaking it ideal for VR applications. Additionally, a near-optimal deep\nreinforcement learning (DRL)-based resource allocation framework for real-time\nuse by being 5x faster and reaching 83% of the global optimum is introduced."}
{"id": "2507.18868", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.18868", "abs": "https://arxiv.org/abs/2507.18868", "authors": ["Alex Noviello", "Claas Beger", "Jacob Groner", "Kevin Ellis", "Weinan Sun"], "title": "A Neuroscience-Inspired Dual-Process Model of Compositional Generalization", "comment": null, "summary": "Systematic compositional generalization - constructing and understanding\nnovel combinations of known building blocks - remains a core challenge for AI\nsystems. Human cognition achieves this flexibility via the interplay of the\nhippocampus (HPC) and prefrontal cortex (PFC): the hippocampus rapidly encodes\nepisodes, and the prefrontal cortex consolidates them into reusable schemas for\nreasoning. Drawing on these insights, we present MIRAGE (Meta-Inference with\nRules and Abstractions from Generalized Experience), a framework that achieves\nsystematic generalization on compositional tasks. MIRAGE has two interacting\nmodules mirroring the brain's deliberative HPC-PFC loop and intuitive\nneocortical pattern recognition. (1) The meta-trained Transformer Neural\nDecomposer, paralleling neocortical \"System 1\" computation, is trained on a\ntask-agnostic stream of randomly sampled compositional grammars and applies one\ndecomposition step per pass, with successive passes iteratively refining the\nsequence representation. (2) The Schema Engine, analogous to the HPC-PFC\n\"System 2\" loop, dynamically extracts, ranks, and applies reusable schemas,\nstoring variable bindings in episodic memory and expanding them when needed. By\nexplicitly equipping the Transformer component of MIRAGE with actively managed\nschematic structures, our model performs systematic compositional operations\nthrough explicit schema application and transformation, relying solely on\nfrozen weights when solving entirely novel tasks. This approach demonstrates\nsystematic compositional generalization on the SCAN benchmark, achieving > 99%\naccuracy on all task splits with only 1.19M parameters in the transformer\nmodule. Ablation studies confirm that MIRAGE's systematicity critically depends\non the quality of extracted schemas and the model's iterative refinement\nprocess."}
{"id": "2507.19309", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.19309", "abs": "https://arxiv.org/abs/2507.19309", "authors": ["Qijun Jiang", "Xiaodan Shao", "Rui Zhang"], "title": "Low-Complexity 6DMA Rotation and Position Optimization Based on Statistical Channel Information", "comment": "arXiv admin note: substantial text overlap with arXiv:2504.20618", "summary": "The six-dimensional movable antenna (6DMA) is a promising technology to fully\nexploit spatial variation in wireless channels by allowing flexible adjustment\nof three-dimensional (3D) positions and rotations of antennas at the\ntransceiver. In this paper, we consider a 6DMA-equipped base station (BS) and\naim to maximize the average sum logarithmic rate of all users served by the BS\nby jointly designing 6DMA surface positions and rotations based on statistical\nchannel information (SCI). Different from prior works on 6DMA design which use\nalternating optimization to iteratively update surface positions and rotations,\nwe propose a new sequential optimization method that first determines the\noptimal rotations and then identifies feasible positions to realize these\nrotations under practical antenna placement constraints. Simulation results\nshow that our proposed optimization scheme significantly reduces the\ncomputational complexity of conventional alternating optimization (AO), while\nachieving communication performance comparable to the AO-based approach and\nsuperior to existing fixed-position/rotation antenna arrays."}
{"id": "2507.19234", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19234", "abs": "https://arxiv.org/abs/2507.19234", "authors": ["Tianfu Wang", "Liwei Deng", "Xi Chen", "Junyang Wang", "Huiguo He", "Leilei Ding", "Wei Wu", "Qilin Fan", "Hui Xiong"], "title": "Virne: A Comprehensive Benchmark for Deep RL-based Network Resource Allocation in NFV", "comment": null, "summary": "Resource allocation (RA) is critical to efficient service deployment in\nNetwork Function Virtualization (NFV), a transformative networking paradigm.\nRecently, deep Reinforcement Learning (RL)-based methods have been showing\npromising potential to address this complexity. However, the lack of a\nsystematic benchmarking framework and thorough analysis hinders the exploration\nof emerging networks and the development of more robust algorithms while\ncausing inconsistent evaluation. In this paper, we introduce Virne, a\ncomprehensive benchmarking framework for the NFV-RA problem, with a focus on\nsupporting deep RL-based methods. Virne provides customizable simulations for\ndiverse network scenarios, including cloud, edge, and 5G environments. It also\nfeatures a modular and extensible implementation pipeline that supports over 30\nmethods of various types, and includes practical evaluation perspectives beyond\neffectiveness, such as scalability, generalization, and scalability.\nFurthermore, we conduct in-depth analysis through extensive experiments to\nprovide valuable insights into performance trade-offs for efficient\nimplementation and offer actionable guidance for future research directions.\nOverall, with its diverse simulations, rich implementations, and extensive\nevaluation capabilities, Virne could serve as a comprehensive benchmark for\nadvancing NFV-RA methods and deep RL applications. The code is publicly\navailable at https://github.com/GeminiLight/virne."}
{"id": "2507.18883", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.18883", "abs": "https://arxiv.org/abs/2507.18883", "authors": ["Wuhao Wang", "Zhiyong Chen"], "title": "Success in Humanoid Reinforcement Learning under Partial Observation", "comment": "11 pages, 3 figures, and 4 tables. Not published anywhere else", "summary": "Reinforcement learning has been widely applied to robotic control, but\neffective policy learning under partial observability remains a major\nchallenge, especially in high-dimensional tasks like humanoid locomotion. To\ndate, no prior work has demonstrated stable training of humanoid policies with\nincomplete state information in the benchmark Gymnasium Humanoid-v4\nenvironment. The objective in this environment is to walk forward as fast as\npossible without falling, with rewards provided for staying upright and moving\nforward, and penalties incurred for excessive actions and external contact\nforces. This research presents the first successful instance of learning under\npartial observability in this environment. The learned policy achieves\nperformance comparable to state-of-the-art results with full state access,\ndespite using only one-third to two-thirds of the original states. Moreover,\nthe policy exhibits adaptability to robot properties, such as variations in\nbody part masses. The key to this success is a novel history encoder that\nprocesses a fixed-length sequence of past observations in parallel. Integrated\ninto a standard model-free algorithm, the encoder enables performance on par\nwith fully observed baselines. We hypothesize that it reconstructs essential\ncontextual information from recent observations, thereby enabling robust\ndecision-making."}
{"id": "2507.19384", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.19384", "abs": "https://arxiv.org/abs/2507.19384", "authors": ["Jing Jiang", "Cailin Wen", "Minquan Cheng"], "title": "On Anti-collusion Codes for Averaging Attack in Multimedia Fingerprinting", "comment": "23 pages", "summary": "Multimedia fingerprinting is a technique to protect the copyrighted contents\nagainst being illegally redistributed under various collusion attack models.\nAveraging attack is the most fair choice for each colluder to avoid detection,\nand also makes the pirate copy have better perceptional quality. This makes\nsuch an attack one of the most feasible approaches to carrying out collusion.\nIn order to trace all the colluders, several types of multimedia fingerprinting\ncodes were introduced to construct fingerprints resistant to averaging attacks\non multimedia contents, such as AND anti-collusion codes (AND-ACCs), binary\nseparable codes (SCs), logical anti-collusion codes (LACCs), binary frameproof\ncodes (FPCs), binary strongly-separable codes (SSCs) and binary secure code\nwith list decoding (SCLDs). Then codes with the rate as high as possible are\ndesired. However, the existing fingerprinting codes have low code rate due to\nthe strong combinatorial structure. The reason is that the previous research\nmethods adopted simple tracing algorithms. In this paper, we first propose\nnovel tracing algorithms and then find appropriate fingerprinting codes with\nweaker combinatorial structure, i.e., the binary strongly identifiable parent\nproperty code for multimedia fingerprinting (SMIPPC) and its concatenated code.\nTheoretical comparisons and numerical comparisons show that SMIPPCs have higher\ncode rates than those of the existing codes due to their weaker combinatorial\nstructures. It is worth noting that SMIPPCs can only trace a part of colluders\nby using the previous tracing algorithm and the concatenated SMIPPC may be not\nan SMIPPC. This implies that our tracing algorithms have strong traceability."}
{"id": "2507.19377", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.19377", "abs": "https://arxiv.org/abs/2507.19377", "authors": ["David Nunez", "Francesc Wilhelmi", "Maksymilian Wojnar", "Katarzyna Kosek-Szott", "Szymon Szott", "Boris Bellalta"], "title": "Deep Reinforcement Learning-Based Scheduling for Wi-Fi Multi-Access Point Coordination", "comment": "Submitted to IEEE Transactions on Machine Learning in Communications\n  and Networking", "summary": "Multi-access point coordination (MAPC) is a key feature of IEEE 802.11bn,\nwith a potential impact on future Wi-Fi networks. MAPC enables joint scheduling\ndecisions across multiple access points (APs) to improve throughput, latency,\nand reliability in dense Wi-Fi deployments. However, implementing efficient\nscheduling policies under diverse traffic and interference conditions in\noverlapping basic service sets (OBSSs) remains a complex task. This paper\npresents a method to minimize the network-wide worst-case latency by\nformulating MAPC scheduling as a sequential decision-making problem and\nproposing a deep reinforcement learning (DRL) mechanism to minimize worst-case\ndelays in OBSS deployments. Specifically, we train a DRL agent using proximal\npolicy optimization (PPO) within an 802.11bn-compatible Gymnasium environment.\nThis environment provides observations of queue states, delay metrics, and\nchannel conditions, enabling the agent to schedule multiple AP-station pairs to\ntransmit simultaneously by leveraging spatial reuse (SR) groups. Simulations\ndemonstrate that our proposed solution outperforms state-of-the-art heuristic\nstrategies across a wide range of network loads and traffic patterns. The\ntrained machine learning (ML) models consistently achieve lower 99th-percentile\ndelays, showing up to a 30% improvement over the best baseline."}
{"id": "2507.18977", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.18977", "abs": "https://arxiv.org/abs/2507.18977", "authors": ["Mehrnoosh Mirtaheri", "Ryan A. Rossi", "Sungchul Kim", "Kanak Mahadik", "Tong Yu", "Xiang Chen", "Mohammad Rostami"], "title": "Towards Improving Long-Tail Entity Predictions in Temporal Knowledge Graphs through Global Similarity and Weighted Sampling", "comment": null, "summary": "Temporal Knowledge Graph (TKG) completion models traditionally assume access\nto the entire graph during training. This overlooks challenges stemming from\nthe evolving nature of TKGs, such as: (i) the model's requirement to generalize\nand assimilate new knowledge, and (ii) the task of managing new or unseen\nentities that often have sparse connections. In this paper, we present an\nincremental training framework specifically designed for TKGs, aiming to\naddress entities that are either not observed during training or have sparse\nconnections. Our approach combines a model-agnostic enhancement layer with a\nweighted sampling strategy, that can be augmented to and improve any existing\nTKG completion method. The enhancement layer leverages a broader, global\ndefinition of entity similarity, which moves beyond mere local neighborhood\nproximity of GNN-based methods. The weighted sampling strategy employed in\ntraining accentuates edges linked to infrequently occurring entities. We\nevaluate our method on two benchmark datasets, and demonstrate that our\nframework outperforms existing methods in total link prediction, inductive link\nprediction, and in addressing long-tail entities. Notably, our method achieves\na 10\\% improvement and a 15\\% boost in MRR for these datasets. The results\nunderscore the potential of our approach in mitigating catastrophic forgetting\nand enhancing the robustness of TKG completion methods, especially in an\nincremental training context"}
{"id": "2507.19415", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.19415", "abs": "https://arxiv.org/abs/2507.19415", "authors": ["Arian Eamaz", "Farhang Yeganegi", "Mojtaba Soltanalian"], "title": "Sample Abundance for Signal Processing: A Brief Introduction", "comment": "arXiv admin note: substantial text overlap with arXiv:2308.00695", "summary": "This paper reports, by way of introduction, on the advances made by our group\nand the broader signal processing community on the concept of sample abundance;\na phenomenon that naturally arises in one-bit and few-bit signal processing\nframeworks. By leveraging large volumes of low-precision measurements, we show\nhow traditionally costly constraints, such as matrix semi-definiteness and rank\nconditions, become redundant, yielding simple overdetermined linear feasibility\nproblems. We illustrate key algorithms, theoretical guarantees via the Finite\nVolume Property, and the sample abundance singularity phenomenon, where\ncomputational complexity sharply drops."}
{"id": "2507.19089", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.19089", "abs": "https://arxiv.org/abs/2507.19089", "authors": ["Shuhao Li", "Weidong Yang", "Yue Cui", "Xiaoxing Liu", "Lingkai Meng", "Lipeng Ma", "Fan Zhang"], "title": "Fine-Grained Traffic Inference from Road to Lane via Spatio-Temporal Graph Node Generation", "comment": null, "summary": "Fine-grained traffic management and prediction are fundamental to key\napplications such as autonomous driving, lane change guidance, and traffic\nsignal control. However, obtaining lane-level traffic data has become a\ncritical bottleneck for data-driven models due to limitations in the types and\nnumber of sensors and issues with the accuracy of tracking algorithms. To\naddress this, we propose the Fine-grained Road Traffic Inference (FRTI) task,\nwhich aims to generate more detailed lane-level traffic information using\nlimited road data, providing a more energy-efficient and cost-effective\nsolution for precise traffic management. This task is abstracted as the first\nscene of the spatio-temporal graph node generation problem. We designed a\ntwo-stage framework--RoadDiff--to solve the FRTI task. solve the FRTI task.\nThis framework leverages the Road-Lane Correlation Autoencoder-Decoder and the\nLane Diffusion Module to fully utilize the limited spatio-temporal dependencies\nand distribution relationships of road data to accurately infer fine-grained\nlane traffic states. Based on existing research, we designed several baseline\nmodels with the potential to solve the FRTI task and conducted extensive\nexperiments on six datasets representing different road conditions to validate\nthe effectiveness of the RoadDiff model in addressing the FRTI task. The\nrelevant datasets and code are available at\nhttps://github.com/ShuhaoLii/RoadDiff."}
{"id": "2507.19109", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.19109", "abs": "https://arxiv.org/abs/2507.19109", "authors": ["Noé Lallouet", "Tristan Cazenave", "Cyrille Enderli"], "title": "Pareto-NRPA: A Novel Monte-Carlo Search Algorithm for Multi-Objective Optimization", "comment": "Preprint ; accepted to ECAI 2025", "summary": "We introduce Pareto-NRPA, a new Monte-Carlo algorithm designed for\nmulti-objective optimization problems over discrete search spaces. Extending\nthe Nested Rollout Policy Adaptation (NRPA) algorithm originally formulated for\nsingle-objective problems, Pareto-NRPA generalizes the nested search and policy\nupdate mechanism to multi-objective optimization. The algorithm uses a set of\npolicies to concurrently explore different regions of the solution space and\nmaintains non-dominated fronts at each level of search. Policy adaptation is\nperformed with respect to the diversity and isolation of sequences within the\nPareto front. We benchmark Pareto-NRPA on two classes of problems: a novel\nbi-objective variant of the Traveling Salesman Problem with Time Windows\nproblem (MO-TSPTW), and a neural architecture search task on well-known\nbenchmarks. Results demonstrate that Pareto-NRPA achieves competitive\nperformance against state-of-the-art multi-objective algorithms, both in terms\nof convergence and diversity of solutions. Particularly, Pareto-NRPA strongly\noutperforms state-of-the-art evolutionary multi-objective algorithms on\nconstrained search spaces. To our knowledge, this work constitutes the first\nadaptation of NRPA to the multi-objective setting."}
{"id": "2507.19132", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.19132", "abs": "https://arxiv.org/abs/2507.19132", "authors": ["Xuetian Chen", "Yinghao Chen", "Xinfeng Yuan", "Zhuo Peng", "Lu Chen", "Yuekeng Li", "Zhoujia Zhang", "Yingqian Huang", "Leyan Huang", "Jiaqing Liang", "Tianbao Xie", "Zhiyong Wu", "Qiushi Sun", "Biqing Qi", "Bowen Zhou"], "title": "OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?", "comment": "Work in progress", "summary": "Computer-using agents have shown strong potential to boost human productivity\nand enable new application forms across platforms. While recent advances have\nled to usable applications, existing benchmarks fail to account for the\ninternal task heterogeneity and the corresponding agent capabilities, as well\nas their alignment with actual user demands-hindering both targeted capability\ndevelopment and the reliable transition of research progress into practical\ndeployment. To bridge the gap, we present OS-MAP, a benchmark for daily\ncomputer-using automation that organizes its 416 realistic tasks across 15\napplications along two key dimensions: a five-level taxonomy of automation and\na generalization scope derived from a real-world user demand hierarchy. To\nenable fine-grained analysis of required capabilities and alignment with\nreal-world scenarios, OS-MAP evaluates agents along two dimensions: automation\nlevel across a five-level taxonomy, and generalization scope across a demand\nhierarchy. This design captures varying levels of required agent autonomy and\ngeneralization, forming a performance-generalization evaluation matrix for\nstructured and comprehensive assessment. Experiments show that even\nState-of-the-Art agents with VLM backbones struggle with higher-level tasks\ninvolving perception, reasoning, and coordination-highlighting the need for a\ndeeper understanding of current strengths and limitations to drive the future\nprogress in computer-using agents research and deployment. All code,\nenvironments, baselines, and data are publicly available at\nhttps://github.com/OS-Copilot/OS-Map."}
{"id": "2507.19172", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.19172", "abs": "https://arxiv.org/abs/2507.19172", "authors": ["Jiyao Wang", "Xiao Yang", "Qingyong Hu", "Jiankai Tang", "Can Liu", "Dengbo He", "Yuntao Wang", "Yingcong Chen", "Kaishun Wu"], "title": "PhysDrive: A Multimodal Remote Physiological Measurement Dataset for In-vehicle Driver Monitoring", "comment": "It is the initial version, not the final version", "summary": "Robust and unobtrusive in-vehicle physiological monitoring is crucial for\nensuring driving safety and user experience. While remote physiological\nmeasurement (RPM) offers a promising non-invasive solution, its translation to\nreal-world driving scenarios is critically constrained by the scarcity of\ncomprehensive datasets. Existing resources are often limited in scale, modality\ndiversity, the breadth of biometric annotations, and the range of captured\nconditions, thereby omitting inherent real-world challenges in driving. Here,\nwe present PhysDrive, the first large-scale multimodal dataset for contactless\nin-vehicle physiological sensing with dedicated consideration on various\nmodality settings and driving factors. PhysDrive collects data from 48 drivers,\nincluding synchronized RGB, near-infrared camera, and raw mmWave radar data,\naccompanied with six synchronized ground truths (ECG, BVP, Respiration, HR, RR,\nand SpO2). It covers a wide spectrum of naturalistic driving conditions,\nincluding driver motions, dynamic natural light, vehicle types, and road\nconditions. We extensively evaluate both signal-processing and deep-learning\nmethods on PhysDrive, establishing a comprehensive benchmark across all\nmodalities, and release full open-source code with compatibility for mainstream\npublic toolboxes. We envision PhysDrive will serve as a foundational resource\nand accelerate research on multimodal driver monitoring and smart-cockpit\nsystems."}
{"id": "2507.19182", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.19182", "abs": "https://arxiv.org/abs/2507.19182", "authors": ["Kuncheng Zou", "Jiahao Mai", "Yonggang Zhang", "Yuyi Wang", "Ondřej Kuželka", "Yuanhong Wang", "Yi Chang"], "title": "Faster Lifting for Ordered Domains with Predecessor Relations", "comment": null, "summary": "We investigate lifted inference on ordered domains with predecessor\nrelations, where the elements of the domain respect a total (cyclic) order, and\nevery element has a distinct (clockwise) predecessor. Previous work has\nexplored this problem through weighted first-order model counting (WFOMC),\nwhich computes the weighted sum of models for a given first-order logic\nsentence over a finite domain. In WFOMC, the order constraint is typically\nencoded by the linear order axiom introducing a binary predicate in the\nsentence to impose a linear ordering on the domain elements. The immediate and\nsecond predecessor relations are then encoded by the linear order predicate.\nAlthough WFOMC with the linear order axiom is theoretically tractable, existing\nalgorithms struggle with practical applications, particularly when the\npredecessor relations are involved. In this paper, we treat predecessor\nrelations as a native part of the axiom and devise a novel algorithm that\ninherently supports these relations. The proposed algorithm not only provides\nan exponential speedup for the immediate and second predecessor relations,\nwhich are known to be tractable, but also handles the general k-th predecessor\nrelations. The extensive experiments on lifted inference tasks and\ncombinatorics math problems demonstrate the efficiency of our algorithm,\nachieving speedups of a full order of magnitude."}
{"id": "2507.19261", "categories": ["cs.AI", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2507.19261", "abs": "https://arxiv.org/abs/2507.19261", "authors": ["Osama Almurshed", "Ashish Kaushal", "Asmail Muftah", "Nitin Auluck", "Omer Rana"], "title": "Knowledge Grafting: A Mechanism for Optimizing AI Model Deployment in Resource-Constrained Environments", "comment": "18 pages, 4 figures, ArXiv preprint - Novel \"knowledge grafting\"\n  technique achieving 88.54% AI model size reduction while improving accuracy\n  for resource-constrained deployment", "summary": "The increasing adoption of Artificial Intelligence (AI) has led to larger,\nmore complex models with numerous parameters that require substantial computing\npower -- resources often unavailable in many real-world application scenarios.\nOur paper addresses this challenge by introducing knowledge grafting, a novel\nmechanism that optimizes AI models for resource-constrained environments by\ntransferring selected features (the scion) from a large donor model to a\nsmaller rootstock model. The approach achieves an 88.54% reduction in model\nsize (from 64.39 MB to 7.38 MB), while improving generalization capability of\nthe model. Our new rootstock model achieves 89.97% validation accuracy (vs.\ndonor's 87.47%), maintains lower validation loss (0.2976 vs. 0.5068), and\nperforms exceptionally well on unseen test data with 90.45% accuracy. It\naddresses the typical size vs performance trade-off, and enables deployment of\nAI frameworks on resource-constrained devices with enhanced performance. We\nhave tested our approach on an agricultural weed detection scenario, however,\nit can be extended across various edge computing scenarios, potentially\naccelerating AI adoption in areas with limited hardware/software support -- by\nmirroring in a similar manner the horticultural grafting enables productive\ncultivation in challenging agri-based environments."}
{"id": "2507.19263", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19263", "abs": "https://arxiv.org/abs/2507.19263", "authors": ["Achille Morenville", "Éric Piette"], "title": "Modeling Uncertainty: Constraint-Based Belief States in Imperfect-Information Games", "comment": null, "summary": "In imperfect-information games, agents must make decisions based on partial\nknowledge of the game state. The Belief Stochastic Game model addresses this\nchallenge by delegating state estimation to the game model itself. This allows\nagents to operate on externally provided belief states, thereby reducing the\nneed for game-specific inference logic. This paper investigates two approaches\nto represent beliefs in games with hidden piece identities: a constraint-based\nmodel using Constraint Satisfaction Problems and a probabilistic extension\nusing Belief Propagation to estimate marginal probabilities. We evaluated the\nimpact of both representations using general-purpose agents across two\ndifferent games. Our findings indicate that constraint-based beliefs yield\nresults comparable to those of probabilistic inference, with minimal\ndifferences in agent performance. This suggests that constraint-based belief\nstates alone may suffice for effective decision-making in many settings."}
{"id": "2507.19364", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.19364", "abs": "https://arxiv.org/abs/2507.19364", "authors": ["Patrick Taillandier", "Jean Daniel Zucker", "Arnaud Grignard", "Benoit Gaudou", "Nghi Quang Huynh", "Alexis Drogoul"], "title": "Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges", "comment": null, "summary": "This position paper examines the use of Large Language Models (LLMs) in\nsocial simulation, analyzing both their potential and their limitations from a\ncomputational social science perspective. The first part reviews recent\nfindings on the ability of LLMs to replicate key aspects of human cognition,\nincluding Theory of Mind reasoning and social inference, while also\nhighlighting significant limitations such as cognitive biases, lack of true\nunderstanding, and inconsistencies in behavior. The second part surveys\nemerging applications of LLMs in multi-agent simulation frameworks, focusing on\nsystem architectures, scale, and validation strategies. Notable projects such\nas Generative Agents (Smallville) and AgentSociety are discussed in terms of\ntheir design choices, empirical grounding, and methodological innovations.\nParticular attention is given to the challenges of behavioral fidelity,\ncalibration, and reproducibility in large-scale LLM-driven simulations. The\nfinal section distinguishes between contexts where LLMs, like other black-box\nsystems, offer direct value-such as interactive simulations and serious\ngames-and those where their use is more problematic, notably in explanatory or\npredictive modeling. The paper concludes by advocating for hybrid approaches\nthat integrate LLMs into traditional agent-based modeling platforms (GAMA,\nNetlogo, etc), enabling modelers to combine the expressive flexibility of\nlanguage-based reasoning with the transparency and analytical rigor of\nclassical rule-based systems."}
{"id": "2507.19372", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.19372", "abs": "https://arxiv.org/abs/2507.19372", "authors": ["Flavio Petruzzellis", "Alberto Testolin", "Alessandro Sperduti"], "title": "Learning neuro-symbolic convergent term rewriting systems", "comment": "48 pages, 31 figures. Submitted for review by Artificial Intelligence\n  Journal", "summary": "Building neural systems that can learn to execute symbolic algorithms is a\nchallenging open problem in artificial intelligence, especially when aiming for\nstrong generalization and out-of-distribution performance. In this work, we\nintroduce a general framework for learning convergent term rewriting systems\nusing a neuro-symbolic architecture inspired by the rewriting algorithm itself.\nWe present two modular implementations of such architecture: the Neural\nRewriting System (NRS) and the Fast Neural Rewriting System (FastNRS). As a\nresult of algorithmic-inspired design and key architectural elements, both\nmodels can generalize to out-of-distribution instances, with FastNRS offering\nsignificant improvements in terms of memory efficiency, training speed, and\ninference time. We evaluate both architectures on four tasks involving the\nsimplification of mathematical formulas and further demonstrate their\nversatility in a multi-domain learning scenario, where a single model is\ntrained to solve multiple types of problems simultaneously. The proposed system\nsignificantly outperforms two strong neural baselines: the Neural Data Router,\na recent transformer variant specifically designed to solve algorithmic\nproblems, and GPT-4o, one of the most powerful general-purpose large-language\nmodels. Moreover, our system matches or outperforms the latest o1-preview model\nfrom OpenAI that excels in reasoning benchmarks."}
{"id": "2507.19458", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.19458", "abs": "https://arxiv.org/abs/2507.19458", "authors": ["Amir Fard", "Arnold X. -X. Yuan"], "title": "Hierarchical Deep Reinforcement Learning Framework for Multi-Year Asset Management Under Budget Constraints", "comment": null, "summary": "Budget planning and maintenance optimization are crucial for infrastructure\nasset management, ensuring cost-effectiveness and sustainability. However, the\ncomplexity arising from combinatorial action spaces, diverse asset\ndeterioration, stringent budget constraints, and environmental uncertainty\nsignificantly limits existing methods' scalability. This paper proposes a\nHierarchical Deep Reinforcement Learning methodology specifically tailored to\nmulti-year infrastructure planning. Our approach decomposes the problem into\ntwo hierarchical levels: a high-level Budget Planner allocating annual budgets\nwithin explicit feasibility bounds, and a low-level Maintenance Planner\nprioritizing assets within the allocated budget. By structurally separating\nmacro-budget decisions from asset-level prioritization and integrating linear\nprogramming projection within a hierarchical Soft Actor-Critic framework, the\nmethod efficiently addresses exponential growth in the action space and ensures\nrigorous budget compliance. A case study evaluating sewer networks of varying\nsizes (10, 15, and 20 sewersheds) illustrates the effectiveness of the proposed\napproach. Compared to conventional Deep Q-Learning and enhanced genetic\nalgorithms, our methodology converges more rapidly, scales effectively, and\nconsistently delivers near-optimal solutions even as network size grows."}
{"id": "2507.19234", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19234", "abs": "https://arxiv.org/abs/2507.19234", "authors": ["Tianfu Wang", "Liwei Deng", "Xi Chen", "Junyang Wang", "Huiguo He", "Leilei Ding", "Wei Wu", "Qilin Fan", "Hui Xiong"], "title": "Virne: A Comprehensive Benchmark for Deep RL-based Network Resource Allocation in NFV", "comment": null, "summary": "Resource allocation (RA) is critical to efficient service deployment in\nNetwork Function Virtualization (NFV), a transformative networking paradigm.\nRecently, deep Reinforcement Learning (RL)-based methods have been showing\npromising potential to address this complexity. However, the lack of a\nsystematic benchmarking framework and thorough analysis hinders the exploration\nof emerging networks and the development of more robust algorithms while\ncausing inconsistent evaluation. In this paper, we introduce Virne, a\ncomprehensive benchmarking framework for the NFV-RA problem, with a focus on\nsupporting deep RL-based methods. Virne provides customizable simulations for\ndiverse network scenarios, including cloud, edge, and 5G environments. It also\nfeatures a modular and extensible implementation pipeline that supports over 30\nmethods of various types, and includes practical evaluation perspectives beyond\neffectiveness, such as scalability, generalization, and scalability.\nFurthermore, we conduct in-depth analysis through extensive experiments to\nprovide valuable insights into performance trade-offs for efficient\nimplementation and offer actionable guidance for future research directions.\nOverall, with its diverse simulations, rich implementations, and extensive\nevaluation capabilities, Virne could serve as a comprehensive benchmark for\nadvancing NFV-RA methods and deep RL applications. The code is publicly\navailable at https://github.com/GeminiLight/virne."}
