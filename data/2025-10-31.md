<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 8]
- [cs.AI](#cs.AI) [Total: 45]
- [cs.IT](#cs.IT) [Total: 6]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [A Zero Added Loss Multiplexing (ZALM) Source Simulation](https://arxiv.org/abs/2510.26009)
*Jerry Horgan,Alexander Nico-Katz,Shelbi L. Jenkins,Ashley N. Tittlebaugh,Vivek Visan,Rahan Bali,Marco Ruffini,Boulat A. Bash,Daniel C. Kilper*

Main category: cs.NI

TL;DR: 开发了模块化的ZALM模拟器，用于分析零添加损耗多路复用系统的性能，展示设计选择如何影响输出速率和保真度。


<details>
  <summary>Details</summary>
Motivation: ZALM技术提供宽带、每通道宣告的EPR对，具有丰富的参数空间，需要工具来优化其性能以适应特定应用。

Method: 使用NetSquid和QSI控制器构建模块化模拟器，包含20+可调参数，支持理想和现实模式，集成SPDC源、干涉、DWDM滤波、光纤延迟等组件。

Result: 默认配置下平均保真度保持0.8，但ebit速率从源端的0.0175降至50km处的0.0；缩小SPDC简并带宽可显著提高ebit速率而不影响保真度。

Conclusion: 该模拟器支持针对特定量子存储器的源、滤波和前馈设置的协同设计，并可作为端到端量子网络研究的构建模块。

Abstract: Zero Added Loss Multiplexing (ZALM) offers broadband, per channel heralded
EPR pairs, with a rich parameter space that allows its performance to be
tailored for specific applications. We present a modular ZALM simulator that
demonstrates how design choices affect output rate and fidelity. Built in
NetSquid with QSI controllers, it exposes 20+ tunable parameters, supports
IDEAL and REALISTIC modes, and provides reusable components for Spontaneous
Parametric Down Conversion (SPDC) sources, interference, Dense Wavelength
Division Multiplexing (DWDM) filtering, fiber delay, active polarization gates,
detectors, and lossy fiber. Physics based models capture Hong Ou Mandel (HOM)
visibility, insertion loss, detector efficiency, gate errors, and attenuation.
Using this tool, we map trade offs among fidelity, link distance, and entangled
pairs per use, and show how SPDC bandwidth and DWDM grid spacing steer
performance. Using the default configuration settings, average fidelity emains
constant at 0.8 but the ebit rate decreases from 0.0175 at the source to 0.0 at
50 km; narrowing the SPDC degeneracy bandwidth increases the ebit rate
significantly without affecting fidelity. The simulator enables codesign of
source, filtering, and feedforward settings for specific quantum memories and
integrates as a building block for end to end quantum network studies.

</details>


### [2] [Performance Analysis of Dynamic Equilibria in Joint Path Selection and Congestion Control](https://arxiv.org/abs/2510.26060)
*Sina Keshvadi*

Main category: cs.NI

TL;DR: 本文开发了首个分析路径选择和拥塞控制联合动态的公理化框架，揭示了协议设计在可预测性能与用户中心目标之间的基本权衡，并发现智能体迁移可以反直觉地增强稳定性。


<details>
  <summary>Details</summary>
Motivation: 路径感知网络赋予终端主机细粒度流量转发控制能力，但多个代理的贪婪路径选择可能导致持续高幅度网络振荡，这种现象的定量性能影响一直未被充分理解。

Method: 开发了首个分析路径选择和拥塞控制联合动态的公理化框架，通过数学模型形式化描述系统的动态均衡状态，并提供一套公理来评估其性能指标。

Result: 分析揭示了协议设计在可预测性能（效率、收敛性）与用户中心目标（公平性、响应性）之间的基本权衡，但效率、收敛性和丢包避免可以同时优化。智能体迁移可以反直觉地增强稳定性。

Conclusion: 这些发现为未来路径感知互联网设计稳健、高性能协议提供了原则性设计指南。

Abstract: Path-aware networking, a cornerstone of next-generation architectures like
SCION and Multipath QUIC, empowers end-hosts with fine-grained control over
traffic forwarding. This capability, however, introduces a critical stability
risk: uncoordinated, greedy path selection by a multitude of agents can induce
persistent, high-amplitude network oscillations. While this phenomenon is
well-known, its quantitative performance impact across key metrics has remained
poorly understood. In this paper, we address this gap by developing the first
axiomatic framework for analyzing the joint dynamics of path selection and
congestion control. Our model enables the formal characterization of the
system's dynamic equilibria-the stable, periodic patterns of oscillation-and
provides a suite of axioms to rate their performance in terms of efficiency,
loss avoidance, convergence, fairness, and responsiveness. Our analysis reveals
a fundamental trade-off in protocol design between predictable performance
(efficiency, convergence) and user-centric goals (fairness, responsiveness). We
prove, however, that no such trade-off exists among efficiency, convergence,
and loss avoidance, which can be simultaneously optimized through careful
parameter tuning. Furthermore, we find that agent migration can,
counter-intuitively, enhance stability by de-synchronizing traffic, a
theoretical result validated by our simulations. These findings provide a
principled design map for engineering robust, high-performance protocols for
the future path-aware Internet.

</details>


### [3] [Symmetry-Driven Asynchronous Forwarding for Reliable Distributed Coordination in Toroidal Networks](https://arxiv.org/abs/2510.26071)
*Shenshen Luan,Yumo Tian,Xinyu Zhang,Qingwen Zhang,Tianheng Wang,Yan Yang,Shuguo Xie*

Main category: cs.NI

TL;DR: 提出一种基于环面拓扑对称性的异步转发机制，利用几何特性实现无控制平面协调的可靠数据包传输，在1%链路故障率下减少17.5%丢包率。


<details>
  <summary>Details</summary>
Motivation: 大规模分布式系统（如卫星星座和高性能计算集群）需要在不稳定链路下保持协调的通信原语。传统路由方案在链路故障后的控制平面同步期间存在严重丢包问题。

Method: 利用环面拓扑的几何特性，建立拓扑势梯度模型，提出两种本地转发策略：反向流对向优先级(RF-CF)和侧向优先级(RF-LF)，通过前向流相变点保证可达性。

Result: 在16×16环面上，该机制在1%链路故障率下减少17.5%丢包率，RF-LF策略贡献了28%的成功传输数据包。

Conclusion: 建立了拓扑对称性与通信弹性之间的基础联系，为增强分布式系统提供了轻量级、协议无关的底层机制。

Abstract: The proliferation of large-scale distributed systems, such as satellite
constellations and high-performance computing clusters, demands robust
communication primitives that maintain coordination under unreliable links. The
torus topology, with its inherent rotational and reflection symmetries, is a
prevalent architecture in these domains. However, conventional routing schemes
suffer from substantial packet loss during control-plane synchronization after
link failures. This paper introduces a symmetry-driven asynchronous forwarding
mechanism that leverages the torus's geometric properties to achieve reliable
packet delivery without control-plane coordination. We model packet flow using
a topological potential gradient and demonstrate that symmetry-breaking
failures naturally induce a reverse flow, which we harness for fault
circumvention. We propose two local forwarding strategies, Reverse Flow with
Counter-facing Priority (RF-CF) and Lateral-facing Priority (RF-LF), that
guarantee reachability to the destination via forward-flow phase transition
points, without protocol modifications or additional in-packet overhead.
Through percolation analysis and packet-level simulations on a 16 x 16 torus,
we show that our mechanism reduces packet loss by up to 17.5% under a 1% link
failure rate, with the RF-LF strategy contributing to 28% of successfully
delivered packets. This work establishes a foundational link between
topological symmetry and communication resilience, providing a lightweight,
protocol-agnostic substrate for enhancing distributed systems.

</details>


### [4] [FGGM: Formal Grey-box Gradient Method for Attacking DRL-based MU-MIMO Scheduler](https://arxiv.org/abs/2510.26075)
*Thanh Le,Hai Duong,Yusheng Ji,ThanhVu Nguyen,John C. S. Lui*

Main category: cs.NI

TL;DR: 本文研究了5G MU-MIMO系统中对抗性用户如何利用未处理的原始CSI发起吞吐量降低攻击，提出了基于多面体抽象域的FGGM攻击方案，能够在不知道受害者精确CSI值的情况下降低网络吞吐量达70%。


<details>
  <summary>Details</summary>
Motivation: 现有DRL方法在5G用户调度中存在安全问题，但大多数研究假设攻击者能获取受害者精确CSI值，这在LTE/5G上行传输中不现实。本文旨在开发更实际的攻击方案，仅利用观察归一化器信息来估计受害者CSI范围。

Method: 提出FGGM攻击方案，利用多面体抽象域技术来约束神经网络输出范围，基于观察归一化器中的均值和方差估计受害者CSI的上下界，找到一组能在整个受害者观察范围内实现攻击目标的恶意CSI向量。

Result: 实验结果表明，FGGM能够确定一组由对抗性用户控制的恶意CSI向量，在整个模拟过程中重复使用这些CSI，在不了解受害者精确本地观察值的情况下，将受害者网络吞吐量降低高达70%。

Conclusion: 本研究作为案例研究，揭示了DRL策略在5G用户调度中的安全漏洞，提出的攻击方法可应用于许多其他基于DRL的问题，如背包导向的资源分配问题。

Abstract: In 5G mobile communication systems, MU-MIMO has been applied to enhance
spectral efficiency and support high data rates. To maximize spectral
efficiency while providing fairness among users, the base station (BS) needs to
selects a subset of users for data transmission. Given that this problem is
NP-hard, DRL-based methods have been proposed to infer the near-optimal
solutions in real-time, yet this approach has an intrinsic security problem.
This paper investigates how a group of adversarial users can exploit
unsanitized raw CSIs to launch a throughput degradation attack. Most existing
studies only focused on systems in which adversarial users can obtain the exact
values of victims' CSIs, but this is impractical in the case of uplink
transmission in LTE/5G mobile systems. We note that the DRL policy contains an
observation normalizer which has the mean and variance of the observation to
improve training convergence. Adversarial users can then estimate the upper and
lower bounds of the local observations including the CSIs of victims based
solely on that observation normalizer. We develop an attacking scheme FGGM by
leveraging polytope abstract domains, a technique used to bound the outputs of
a neural network given the input ranges. Our goal is to find one set of
intentionally manipulated CSIs which can achieve the attacking goals for the
whole range of local observations of victims. Experimental results demonstrate
that FGGM can determine a set of adversarial CSI vector controlled by
adversarial users, then reuse those CSIs throughout the simulation to reduce
the network throughput of a victim up to 70\% without knowing the exact value
of victims' local observations. This study serves as a case study and can be
applied to many other DRL-based problems, such as a knapsack-oriented resource
allocation problems.

</details>


### [5] [From req/res to pub/sub: Exploring Media over QUIC Transport for DNS](https://arxiv.org/abs/2510.26234)
*Mathis Engelbart,Mike Kosek,Lars Eggert,Jörg Ott*

Main category: cs.NI

TL;DR: 本文提出了一种基于发布-订阅模式的DNS变体，使用Media-over-QUIC架构来推送资源记录更新，相比传统DNS能显著减少更新流量和记录获取时间。


<details>
  <summary>Details</summary>
Motivation: 传统DNS设计为静态目录服务，资源记录很少变化，但现代使用场景如负载均衡和服务发现需要更动态的DNS机制，能够主动推送更新给感兴趣的解析器。

Method: 设计了基于Media-over-QUIC架构的发布-订阅DNS系统和协议原型，允许推送资源记录更新，并提供了原型实现。

Result: 发布-订阅DNS能显著限制更新流量，大幅减少解析器获取最新记录版本的时间，支持内容分发网络中的负载均衡等用例。

Conclusion: DNS能从发布-订阅变体中受益，但该架构也带来了新挑战，包括端点状态管理开销增加和首次查询延迟增加。

Abstract: The DNS is a key component of the Internet. Originally designed to facilitate
the resolution of host names to IP addresses, its scope has continuously
expanded over the years, today covering use cases such as load balancing or
service discovery. While DNS was initially conceived as a rather static
directory service in which resource records (RR) only change rarely, we have
seen a number of use cases over the years where a DNS flavor that isn't purely
based upon requesting and caching RRs, but rather on an active distribution of
updates for all resolvers that showed interest in the respective records in the
past, would be preferable. In this paper, we thus explore a publish-subscribe
variant of DNS based on the Media-over-QUIC architecture, where we devise a
strawman system and protocol proposal to enable pushing RR updates. We provide
a prototype implementation, finding that DNS can benefit from a
publish-subscribe variant: next to limiting update traffic, it can considerably
reduce the time it takes for a resolver to receive the latest version of a
record, thereby supporting use cases such as load balancing in content
distribution networks. The publish-subscribe architecture also brings new
challenges to the DNS, including a higher overhead for endpoints due to
additional state management, and increased query latencies on first lookup, due
to session establishment latencies.

</details>


### [6] [Joint Computing Resource Allocation and Task Offloading in Vehicular Fog Computing Systems Under Asymmetric Information](https://arxiv.org/abs/2510.26256)
*Geng Sun,Siyi Chen,Zemin Sun,Long He,Jiacheng Wang,Dusit Niyato,Zhu Han,Dong In Kim*

Main category: cs.NI

TL;DR: 本文提出了一种联合计算资源分配和任务卸载方法(JCRATOA)，通过分层VFC架构、凸优化资源分配、契约理论激励机制和双边匹配方法，解决车载雾计算中的延迟最小化问题。


<details>
  <summary>Details</summary>
Motivation: 传统车载边缘计算中，路边单元(RSU)资源有限，难以满足车辆日益增长的计算需求；同时由于信息不对称和车辆不愿共享资源，导致资源分配效率低下。

Method: 1) 构建分层VFC架构；2) 提出延迟最小化优化问题(DMOP)；3) 使用凸优化方法分配RSU资源；4) 基于契约理论设计FV激励机制；5) 采用双边匹配方法进行任务卸载。

Result: 仿真结果表明，JCRATOA在任务完成延迟、任务完成率、系统吞吐量和资源利用公平性方面均表现出优越性能，并能有效满足约束条件。

Conclusion: 所提出的JCRATOA方法能够有效解决车载雾计算中的资源分配和任务卸载问题，显著提升系统性能。

Abstract: Vehicular fog computing (VFC) has emerged as a promising paradigm, which
leverages the idle computational resources of nearby fog vehicles (FVs) to
complement the computing capabilities of conventional vehicular edge computing.
However, utilizing VFC to meet the delay-sensitive and computation-intensive
requirements of the FVs poses several challenges. First, the limited resources
of road side units (RSUs) struggle to accommodate the growing and diverse
demands of vehicles. This limitation is further exacerbated by the information
asymmetry between the controller and FVs due to the reluctance of FVs to
disclose private information and to share resources voluntarily. This
information asymmetry hinders the efficient resource allocation and
coordination. Second, the heterogeneity in task requirements and the varying
capabilities of RSUs and FVs complicate efficient task offloading, thereby
resulting in inefficient resource utilization and potential performance
degradation. To address these challenges, we first present a hierarchical VFC
architecture that incorporates the computing capabilities of both RSUs and FVs.
Then, we formulate a delay minimization optimization problem (DMOP), which is
an NP-hard mixed integer nonlinear programming problem. To solve the DMOP, we
propose a joint computing resource allocation and task offloading approach
(JCRATOA). Specifically, we propose a convex optimization-based method for RSU
resource allocation and a contract theory-based incentive mechanism for FV
resource allocation. Moreover, we present a two-sided matching method for task
offloading by employing the matching game. Simulation results demonstrate that
the proposed JCRATOA is able to achieve superior performances in task
completion delay, task completion ratio, system throughput, and resource
utilization fairness, while effectively meeting the satisfying constraints.

</details>


### [7] [Wireless Memory Approximation for Energy-efficient Task-specific IoT Data Retrieval](https://arxiv.org/abs/2510.26473)
*Junya Shiraishi,Shashi Raj Pandey,Israel Leyva-Mayorga,Petar Popovski*

Main category: cs.NI

TL;DR: 提出两种无线内存管理方法：无线内存激活和无线内存近似，以减少DRAM在存储机器学习模型时的刷新能耗，特别适用于资源受限的物联网设备。


<details>
  <summary>Details</summary>
Motivation: DRAM周期性刷新在ML模型存储中导致大量能源浪费，这对资源受限的IoT设备尤为严重。

Method: 采用无线内存激活和无线内存近似两种方法，考虑ML模型使用的时间特性和相关性来高效管理可用内存。

Result: 数值结果显示，所提方案在满足检索精度约束的同时，比常开方法实现了更低的能耗。

Conclusion: 提出的无线内存管理方案能有效降低DRAM在ML模型存储中的能耗，适用于下一代通信系统中的IoT设备。

Abstract: The use of Dynamic Random Access Memory (DRAM) for storing Machine Learning
(ML) models plays a critical role in accelerating ML inference tasks in the
next generation of communication systems. However, periodic refreshment of DRAM
results in wasteful energy consumption during standby periods, which is
significant for resource-constrained Internet of Things (IoT) devices. To solve
this problem, this work advocates two novel approaches: 1) wireless memory
activation and 2) wireless memory approximation. These enable the wireless
devices to efficiently manage the available memory by considering the timing
aspects and relevance of ML model usage; hence, reducing the overall energy
consumption. Numerical results show that our proposed scheme can realize
smaller energy consumption than the always-on approach while satisfying the
retrieval accuracy constraint.

</details>


### [8] [Low-Altitude UAV-Carried Movable Antenna for Joint Wireless Power Transfer and Covert Communications](https://arxiv.org/abs/2510.26628)
*Chuang Zhang,Geng Sun,Jiahui Li,Jiacheng Wang,Qingqing Wu,Dusit Niyato,Shiwen Mao,Tony Q. S. Quek*

Main category: cs.NI

TL;DR: 提出一种低空无人机搭载可移动天线增强的传输系统，联合无线能量传输和隐蔽通信，同时为物联网节点补充能量并为隐蔽用户建立传输链路。


<details>
  <summary>Details</summary>
Motivation: 物联网网络激增需要可持续能源解决方案，特别是电池受限的分布式物联网节点。低空无人机无线能量传输虽能有效传输能量，但视距信道也暴露敏感操作数据给攻击者。

Method: 采用混合专家增强的软演员-评论家算法，使用稀疏Top-K门控混合浅层专家架构表示多模态策略分布，并加入动作投影模块强制执行功率预算和天线位置约束。

Result: 仿真结果表明，该方法显著优于基线方法和其他最先进的深度强化学习算法。

Conclusion: 所提出的系统能有效解决物联网节点的能量补充和隐蔽通信需求，同时最小化无人机的推进能耗。

Abstract: The proliferation of Internet of Things (IoT) networks has created an urgent
need for sustainable energy solutions, particularly for the battery-constrained
spatially distributed IoT nodes. While low-altitude uncrewed aerial vehicles
(UAVs) employed with wireless power transfer (WPT) capabilities offer a
promising solution, the line-of-sight channels that facilitate efficient energy
delivery also expose sensitive operational data to adversaries. This paper
proposes a novel low-altitude UAV-carried movable antenna-enhanced transmission
system joint WPT and covert communications, which simultaneously performs
energy supplements to IoT nodes and establishes transmission links with a
covert user by leveraging wireless energy signals as a natural cover. Then, we
formulate a multi-objective optimization problem that jointly maximizes the
total harvested energy of IoT nodes and sum achievable rate of the covert user,
while minimizing the propulsion energy consumption of the low-altitude UAV. To
address the non-convex and temporally coupled optimization problem, we propose
a mixture-of-experts-augmented soft actor-critic (MoE-SAC) algorithm that
employs a sparse Top-K gated mixture-of-shallow-experts architecture to
represent multimodal policy distributions arising from the conflicting
optimization objectives. We also incorporate an action projection module that
explicitly enforces per-time-slot power budget constraints and antenna position
constraints. Simulation results demonstrate that the proposed approach
significantly outperforms some baseline approaches and other state-of-the-art
deep reinforcement learning algorithms.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling](https://arxiv.org/abs/2510.26603)
*Reda El Makroum,Sebastian Zwickl-Bernhard,Lukas Kranzl*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型的自主家庭能源管理系统，能够从自然语言输入直接协调多电器调度，无需示例演示即可实现最优调度。


<details>
  <summary>Details</summary>
Motivation: 住宅需求响应能力需要大幅提升，但现有家庭能源管理系统因用户交互障碍而采用受限，需要将日常偏好转化为技术参数。

Method: 采用分层架构，结合一个协调器和三个专业代理，使用ReAct模式进行迭代推理，集成Google Calendar进行上下文感知的截止时间提取，无需硬编码工作流。

Result: 评估显示Llama-3.3-70B在所有场景中成功协调所有电器，与混合整数线性规划计算的最优基准相匹配，而其他模型在单电器性能上表现完美但难以同时协调所有电器。

Conclusion: 大语言模型可作为自主协调器管理从自然语言输入到设备控制的完整工作流，但分析性查询处理在没有明确指导的情况下仍不可靠。

Abstract: The electricity sector transition requires substantial increases in
residential demand response capacity, yet Home Energy Management Systems (HEMS)
adoption remains limited by user interaction barriers requiring translation of
everyday preferences into technical parameters. While large language models
have been applied to energy systems as code generators and parameter
extractors, no existing implementation deploys LLMs as autonomous coordinators
managing the complete workflow from natural language input to multi-appliance
scheduling. This paper presents an agentic AI HEMS where LLMs autonomously
coordinate multi-appliance scheduling from natural language requests to device
control, achieving optimal scheduling without example demonstrations. A
hierarchical architecture combining one orchestrator with three specialist
agents uses the ReAct pattern for iterative reasoning, enabling dynamic
coordination without hardcoded workflows while integrating Google Calendar for
context-aware deadline extraction. Evaluation across three open-source models
using real Austrian day-ahead electricity prices reveals substantial capability
differences. Llama-3.3-70B successfully coordinates all appliances across all
scenarios to match cost-optimal benchmarks computed via mixed-integer linear
programming, while other models achieve perfect single-appliance performance
but struggle to coordinate all appliances simultaneously. Progressive prompt
engineering experiments demonstrate that analytical query handling without
explicit guidance remains unreliable despite models' general reasoning
capabilities. We open-source the complete system including orchestration logic,
agent prompts, tools, and web interfaces to enable reproducibility, extension,
and future research.

</details>


### [10] [Towards Piece-by-Piece Explanations for Chess Positions with SHAP](https://arxiv.org/abs/2510.25775)
*Francesco Spinnato*

Main category: cs.AI

TL;DR: 将SHAP可解释AI技术应用于国际象棋分析，通过系统性地移除棋子来计算每个棋子对引擎评估的贡献度，提供可解释的棋子级分析。


<details>
  <summary>Details</summary>
Motivation: 传统象棋引擎提供精确但不透明的评估分数，无法揭示单个棋子或模式的具体贡献，需要开发可解释的分析方法来理解引擎决策。

Method: 将棋子视为特征，采用SHAP方法通过系统性棋子消融来计算每个棋子的加性贡献，实现局部忠实且人类可解释的评估解释。

Result: 开发了一种能够将象棋引擎评估归因于特定棋子的方法，该方法受经典象棋教学启发，并基于现代可解释AI技术。

Conclusion: 该方法为可视化、人类训练和引擎比较开辟了新可能性，推动了可解释象棋AI的研究发展。

Abstract: Contemporary chess engines offer precise yet opaque evaluations, typically
expressed as centipawn scores. While effective for decision-making, these
outputs obscure the underlying contributions of individual pieces or patterns.
In this paper, we explore adapting SHAP (SHapley Additive exPlanations) to the
domain of chess analysis, aiming to attribute a chess engines evaluation to
specific pieces on the board. By treating pieces as features and systematically
ablating them, we compute additive, per-piece contributions that explain the
engines output in a locally faithful and human-interpretable manner. This
method draws inspiration from classical chess pedagogy, where players assess
positions by mentally removing pieces, and grounds it in modern explainable AI
techniques. Our approach opens new possibilities for visualization, human
training, and engine comparison. We release accompanying code and data to
foster future research in interpretable chess AI.

</details>


### [11] [An Agentic Framework for Rapid Deployment of Edge AI Solutions in Industry 5.0](https://arxiv.org/abs/2510.25813)
*Jorge Martinez-Gil,Mario Pichler,Nefeli Bountouni,Sotiris Koussouris,Marielena Márquez Barreiro,Sergio Gusmeroli*

Main category: cs.AI

TL;DR: 提出了一个用于工业5.0的新框架，简化AI模型在边缘设备上的部署，通过本地推理和实时处理减少延迟并避免外部数据传输。


<details>
  <summary>Details</summary>
Motivation: 解决工业环境中AI模型部署复杂、延迟高和数据传输安全的问题，推动工业5.0的发展。

Method: 采用基于代理的架构，支持人类、算法和协作代理执行明确定义的任务，实现模块化集成和低资源需求。

Result: 在食品行业的实际场景中进行初步评估，结果显示部署时间和系统适应性性能得到改善。

Conclusion: 该框架为工业5.0提供了灵活、高效的AI部署解决方案，源代码已公开。

Abstract: We present a novel framework for Industry 5.0 that simplifies the deployment
of AI models on edge devices in various industrial settings. The design reduces
latency and avoids external data transfer by enabling local inference and
real-time processing. Our implementation is agent-based, which means that
individual agents, whether human, algorithmic, or collaborative, are
responsible for well-defined tasks, enabling flexibility and simplifying
integration. Moreover, our framework supports modular integration and maintains
low resource requirements. Preliminary evaluations concerning the food industry
in real scenarios indicate improved deployment time and system adaptability
performance. The source code is publicly available at
https://github.com/AI-REDGIO-5-0/ci-component.

</details>


### [12] [Symbolically Scaffolded Play: Designing Role-Sensitive Prompts for Generative NPC Dialogue](https://arxiv.org/abs/2510.25820)
*Vanessa Figueiredo,David Elumeze*

Main category: cs.AI

TL;DR: 研究探讨了在基于GPT-4o的侦探游戏中，约束提示对玩家体验的影响，发现高约束提示并未显著改善体验，反而导致角色依赖性的不同效果。


<details>
  <summary>Details</summary>
Motivation: 探索在交互式游戏中，约束提示是否能真正提升玩家体验，特别是对于由大型语言模型驱动的非玩家角色对话系统。

Method: 通过The Interview游戏进行用户研究（N=10），比较高约束和低约束提示，然后重新设计为混合JSON+RAG框架，并使用LLM法官进行合成评估。

Result: 高约束提示对玩家体验没有可靠改善，且约束效果具有角色依赖性：采访者NPC获得稳定性，而嫌疑人NPC失去即兴可信度。

Conclusion: 推翻"更严格约束必然增强游戏体验"的假设，提出符号化支撑游戏框架，使用模糊数值边界来平衡稳定性和即兴性。

Abstract: Large Language Models (LLMs) promise to transform interactive games by
enabling non-player characters (NPCs) to sustain unscripted dialogue. Yet it
remains unclear whether constrained prompts actually improve player experience.
We investigate this question through The Interview, a voice-based detective
game powered by GPT-4o. A within-subjects usability study ($N=10$) compared
high-constraint (HCP) and low-constraint (LCP) prompts, revealing no reliable
experiential differences beyond sensitivity to technical breakdowns. Guided by
these findings, we redesigned the HCP into a hybrid JSON+RAG scaffold and
conducted a synthetic evaluation with an LLM judge, positioned as an
early-stage complement to usability testing. Results uncovered a novel pattern:
scaffolding effects were role-dependent: the Interviewer (quest-giver NPC)
gained stability, while suspect NPCs lost improvisational believability. These
findings overturn the assumption that tighter constraints inherently enhance
play. Extending fuzzy-symbolic scaffolding, we introduce \textit{Symbolically
Scaffolded Play}, a framework in which symbolic structures are expressed as
fuzzy, numerical boundaries that stabilize coherence where needed while
preserving improvisation where surprise sustains engagement.

</details>


### [13] [Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters](https://arxiv.org/abs/2510.25860)
*Xingjian Zhang,Tianhong Gao,Suliang Jin,Tianhao Wang,Teng Ye,Eytan Adar,Qiaozhu Mei*

Main category: cs.AI

TL;DR: 提出人-LLM协作框架，通过拒绝采样方法从仅标签注释中推断思维轨迹，用于微调开源LLM评估器和改进专有LLM评估器的标注指南，显著提高了LLM与人类评估的一致性。


<details>
  <summary>Details</summary>
Motivation: LLMs越来越多用于评估任务，但在主观任务中的可靠性有限，因为人类判断涉及超出标注标签的微妙推理。思维轨迹（判断背后的推理）信息丰富但难以收集和整理。

Method: 使用人-LLM协作框架，通过简单有效的拒绝采样方法从仅标签注释中大规模重建思维轨迹，并将这些推断的思维轨迹应用于两个互补任务：微调开源LLM评估器和为专有LLM评估器合成更清晰的标注指南。

Result: 在多个数据集上，该方法显著提高了LLM与人类评估的一致性。此外，改进的标注指南增加了不同LLM模型之间的一致性。

Conclusion: LLMs可以作为未揭示的人类思维轨迹的实用代理，使仅标签语料库能够扩展为思维轨迹增强资源，从而提高LLM评估器的可靠性。

Abstract: Large language models (LLMs) are increasingly used as raters for evaluation
tasks. However, their reliability is often limited for subjective tasks, when
human judgments involve subtle reasoning beyond annotation labels. Thinking
traces, the reasoning behind a judgment, are highly informative but challenging
to collect and curate. We present a human-LLM collaborative framework to infer
thinking traces from label-only annotations. The proposed framework uses a
simple and effective rejection sampling method to reconstruct these traces at
scale. These inferred thinking traces are applied to two complementary tasks:
(1) fine-tuning open LLM raters; and (2) synthesizing clearer annotation
guidelines for proprietary LLM raters. Across multiple datasets, our methods
lead to significantly improved LLM-human agreement. Additionally, the refined
annotation guidelines increase agreement among different LLM models. These
results suggest that LLMs can serve as practical proxies for otherwise
unrevealed human thinking traces, enabling label-only corpora to be extended
into thinking-trace-augmented resources that enhance the reliability of LLM
raters.

</details>


### [14] [The Information-Theoretic Imperative: Compression and the Epistemic Foundations of Intelligence](https://arxiv.org/abs/2510.25883)
*Christian Dittrich,Jennifer Flygare Kinne*

Main category: cs.AI

TL;DR: 该论文提出了一个两层次框架来解释为什么压缩过程会强制发现因果结构而非表面统计模式，将智能视为在结构化环境中持续存在的机械必然结果。


<details>
  <summary>Details</summary>
Motivation: 现有框架虽然认识到压缩对智能的核心作用，但未能具体说明为什么这个过程会强制发现因果结构而非表面统计模式，这一理论空白需要填补。

Method: 引入信息论必要性(ITI)和压缩效率原则(CEP)的两层次框架：ITI从进化角度建立生存压力与信息处理需求之间的联系，CEP通过异常积累动态机制解释高效压缩如何选择生成性因果模型。

Result: 该框架产生了可实证检验的预测：压缩效率与分布外泛化相关；异常积累率区分因果模型和相关模型；分层系统在抽象层上表现出递增效率；生物系统的代谢成本跟踪表征复杂性。

Conclusion: ITI和CEP为生物、人工和多尺度系统中的收敛提供了统一解释，解决了智能的认识论和功能维度，无需诉诸意识或主观经验的假设。

Abstract: Existing frameworks converge on the centrality of compression to intelligence
but leave underspecified why this process enforces the discovery of causal
structure rather than superficial statistical patterns. We introduce a
two-level framework to address this gap. The Information-Theoretic Imperative
(ITI) establishes that any system persisting in uncertain environments must
minimize epistemic entropy through predictive compression: this is the
evolutionary "why" linking survival pressure to information-processing demands.
The Compression Efficiency Principle (CEP) specifies how efficient compression
mechanically selects for generative, causal models through
exception-accumulation dynamics, making reality alignment a consequence rather
than a contingent achievement. Together, ITI and CEP define a causal chain:
from survival pressure to prediction necessity, compression requirement,
efficiency optimization, generative structure discovery, and ultimately reality
alignment. Each link follows from physical, information-theoretic, or
evolutionary constraints, implying that intelligence is the mechanically
necessary outcome of persistence in structured environments. This framework
yields empirically testable predictions: compression efficiency, measured as
approach to the rate-distortion frontier, correlates with out-of-distribution
generalization; exception-accumulation rates differentiate causal from
correlational models; hierarchical systems exhibit increasing efficiency across
abstraction layers; and biological systems demonstrate metabolic costs that
track representational complexity. ITI and CEP thereby provide a unified
account of convergence across biological, artificial, and multi-scale systems,
addressing the epistemic and functional dimensions of intelligence without
invoking assumptions about consciousness or subjective experience.

</details>


### [15] [Approximating Human Preferences Using a Multi-Judge Learned System](https://arxiv.org/abs/2510.25884)
*Eitán Sprejer,Fernando Avalos,Augusto Bernardi,Jose Pedro Brito de Azevedo Faustino,Jacob Haimes,Narmeen Fatimah Oozeer*

Main category: cs.AI

TL;DR: 提出了一个基于角色的偏好建模框架，通过聚合多个基于评分标准的评判者输出来解决LLM评判者与人类偏好对齐的挑战。


<details>
  <summary>Details</summary>
Motivation: LLM评判者难以校准，存在评分标准敏感性、偏见和不稳定性问题，这影响了RLHF奖励模型和路由系统的可靠性。

Method: 使用基于角色的方法大规模合成偏好标签，并开发了两种聚合器实现：广义加性模型(GAM)和多层感知器(MLP)。

Result: 评估了该方法相对于简单基线的性能，并通过案例研究检验了其对人类和LLM评判者偏见的鲁棒性。

Conclusion: 提出的框架能够有效建模多样化的基于角色的偏好，为改进LLM评判者的校准提供了可行方案。

Abstract: Aligning LLM-based judges with human preferences is a significant challenge,
as they are difficult to calibrate and often suffer from rubric sensitivity,
bias, and instability. Overcoming this challenge advances key applications,
such as creating reliable reward models for Reinforcement Learning from Human
Feedback (RLHF) and building effective routing systems that select the
best-suited model for a given user query. In this work, we propose a framework
for modeling diverse, persona-based preferences by learning to aggregate
outputs from multiple rubric-conditioned judges. We investigate the performance
of this approach against naive baselines and assess its robustness through case
studies on both human and LLM-judges biases. Our primary contributions include
a persona-based method for synthesizing preference labels at scale and two
distinct implementations of our aggregator: Generalized Additive Model (GAM)
and a Multi-Layer Perceptron (MLP).

</details>


### [16] [SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications](https://arxiv.org/abs/2510.25908)
*Emily Herron,Junqi Yin,Feiyi Wang*

Main category: cs.AI

TL;DR: SciTrust 2.0是一个评估LLM在科学应用中可信度的框架，涵盖真实性、对抗鲁棒性、科学安全和科学伦理四个维度。评估显示通用行业模型在各方面优于科学专用模型，后者在逻辑和伦理推理能力上存在显著缺陷。


<details>
  <summary>Details</summary>
Motivation: LLM在科学研究中具有变革潜力，但在高风险环境中的部署引发了可信度担忧，需要系统评估其信任度。

Method: 开发了包含新颖开放式真实性基准和科学伦理基准的综合框架，通过验证的反思调优流程和专家验证构建，使用准确性、语义相似度和LLM评分等多种指标评估七个主要LLM。

Result: 通用行业模型在所有可信度维度上均优于科学专用模型，GPT-4-mini在真实性和对抗鲁棒性评估中表现最佳。科学专用模型在逻辑和伦理推理能力上存在显著缺陷，在生物安全和化学武器等高危领域存在安全漏洞。

Conclusion: 通过开源该框架，为开发更可信的AI系统和推进科学背景下模型安全与伦理研究提供了基础。

Abstract: Large language models (LLMs) have demonstrated transformative potential in
scientific research, yet their deployment in high-stakes contexts raises
significant trustworthiness concerns. Here, we introduce SciTrust 2.0, a
comprehensive framework for evaluating LLM trustworthiness in scientific
applications across four dimensions: truthfulness, adversarial robustness,
scientific safety, and scientific ethics. Our framework incorporates novel,
open-ended truthfulness benchmarks developed through a verified
reflection-tuning pipeline and expert validation, alongside a novel ethics
benchmark for scientific research contexts covering eight subcategories
including dual-use research and bias. We evaluated seven prominent LLMs,
including four science-specialized models and three general-purpose industry
models, using multiple evaluation metrics including accuracy, semantic
similarity measures, and LLM-based scoring. General-purpose industry models
overall outperformed science-specialized models across each trustworthiness
dimension, with GPT-o4-mini demonstrating superior performance in truthfulness
assessments and adversarial robustness. Science-specialized models showed
significant deficiencies in logical and ethical reasoning capabilities, along
with concerning vulnerabilities in safety evaluations, particularly in
high-risk domains such as biosecurity and chemical weapons. By open-sourcing
our framework, we provide a foundation for developing more trustworthy AI
systems and advancing research on model safety and ethics in scientific
contexts.

</details>


### [17] [FinOps Agent -- A Use-Case for IT Infrastructure and Cost Optimization](https://arxiv.org/abs/2510.25914)
*Ngoc Phuoc An Vo,Manish Kesarwani,Ruchi Mahindru,Chandrasekhar Narayanaswami*

Main category: cs.AI

TL;DR: 本文提出使用自主AI代理来自动化FinOps（云财务管理）流程，通过模拟端到端的行业流程，从多源数据检索到分析生成优化建议，评估显示AI代理能达到实际FinOps从业者的水平。


<details>
  <summary>Details</summary>
Motivation: FinOps从业者面临来自多个云提供商和内部系统的异构计费数据格式、分类和指标，这导致难以综合可操作的见解并做出及时决策。

Method: 构建了一个FinOps代理系统，模拟从多源检索数据、整合分析到生成优化建议的端到端行业流程，并使用多个开源和闭源语言模型进行评估。

Result: 评估显示该代理能够像实际FinOps从业者一样理解、规划和执行任务。

Conclusion: 自主、目标驱动的AI代理可以有效解决FinOps自动化中的异构数据挑战，实现云业务价值的最大化。

Abstract: FinOps (Finance + Operations) represents an operational framework and
cultural practice which maximizes cloud business value through collaborative
financial accountability across engineering, finance, and business teams.
FinOps practitioners face a fundamental challenge: billing data arrives in
heterogeneous formats, taxonomies, and metrics from multiple cloud providers
and internal systems which eventually lead to synthesizing actionable insights,
and making time-sensitive decisions. To address this challenge, we propose
leveraging autonomous, goal-driven AI agents for FinOps automation. In this
paper, we built a FinOps agent for a typical use-case for IT infrastructure and
cost optimization. We built a system simulating a realistic end-to-end industry
process starting with retrieving data from various sources to consolidating and
analyzing the data to generate recommendations for optimization. We defined a
set of metrics to evaluate our agent using several open-source and close-source
language models and it shows that the agent was able to understand, plan, and
execute tasks as well as an actual FinOps practitioner.

</details>


### [18] [Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual Accuracy by Directed Exoskeleton Reasoning](https://arxiv.org/abs/2510.25933)
*Nissan Yaron,Dan Bystritsky,Ben-Etzion Yaron*

Main category: cs.AI

TL;DR: 一个3.8B参数的模型在FACTS Grounding基准测试中达到GPT-4o水平（在±5%等效范围内），云定价比GPT-4o便宜约19倍，自托管/边缘部署可接近零边际成本。


<details>
  <summary>Details</summary>
Motivation: 开发成本效益高的小型语言模型，在保持与大型模型相当性能的同时大幅降低推理成本。

Method: 结合最小化定向"外骨骼推理"支架和行为微调，教导协议合规性而非领域知识，两者协同作用显著提升性能。

Result: 在Q1-Q500测试中，Humans-Junior得分72.7%，GPT-4o得分73.5%，差异仅0.8%，统计等效性成立。前沿模型仅通过提示工程可获得额外提升。

Conclusion: 小型模型通过精心设计的推理支架和行为微调，可以在特定任务上达到大型模型的性能水平，同时大幅降低成本。

Abstract: We introduce Humans-Junior, a 3.8B model that matches GPT-4o on the FACTS
Grounding public subset within a $\pm 5$ pp equivalence margin.
  Results. On Q1--Q500 under identical judges, GPT-4o scores 73.5% (95% CI
69.5--77.2) and Humans-Junior 72.7% (95% CI 68.7--76.5); the paired difference
is 0.8 pp (bootstrap 95% CI $-3.1$ to $+4.7$; permutation $p = 0.72$; Cohen's
$d = 0.023$). TOST establishes equivalence at $\pm 5$ pp (not at $\pm 3$ pp).
When purchased as managed APIs, Humans-Junior's base model
(Phi-3.5-mini-instruct) is $\approx 19\times$ less expensive than GPT-4o on
Microsoft AI Foundry pricing; self-hosted or edge deployments can drive
incremental inference cost toward zero. Measured vs estimated pricing sources
are tabulated in Appendix E.
  Method. Our approach combines minimal directed "Exoskeleton Reasoning"
scaffolds with behavioral fine-tuning that teaches protocol compliance
(epistemic discipline) rather than domain answers. Fine-tuning alone adds
little; combined, they synergize (+17.7 pp, $p < 0.001$) and reduce variance
($\approx 25\%$). In prompt-only settings on frontier models (Q1--Q100;
non-comparable), directed reasoning improved GPT-4o by +11.8 pp to 85.3% and
Gemini-2.5-Pro by +5.0 pp to 93.3% (baseline 88.3%, $n = 100$); see Section~5.
  TL;DR. A 3.8B model achieves GPT-4o-level FACTS accuracy (equivalent within
$\pm 5$ pp on Q1--Q500). Cloud pricing shows $\approx 19\times$ lower cost
versus GPT-4o, and self-hosted/edge deployments can approach zero marginal
cost. Pricing sources are listed in Appendix E. Frontier prompt-only gains
(Q1--Q100; non-comparable) and optimized-prompt exploratory results under
earlier judges are summarized in Appendix F.
  Keywords: Small Language Models, Factual Grounding, Directed Reasoning,
Fine-Tuning, Model Alignment, Cost-Efficient AI

</details>


### [19] [Estimating cognitive biases with attention-aware inverse planning](https://arxiv.org/abs/2510.25951)
*Sounak Banerjee,Daphne Cornelisse,Deepak Gopinath,Emily Sumner,Jonathan DeCastro,Guy Rosman,Eugene Vinitsky,Mark K. Ho*

Main category: cs.AI

TL;DR: 该论文提出了一种注意力感知的逆规划方法，用于从人类行为中推断认知偏见，特别是在驾驶场景中。


<details>
  <summary>Details</summary>
Motivation: 人类的目标导向行为受到认知偏见的影响，与人类交互的自主系统需要意识到这一点。例如，人们在日常任务（如驾驶）中对环境中物体的注意力会存在系统性偏见。

Method: 结合深度强化学习和计算认知建模，提出了注意力感知逆规划方法，用于从行为中推断注意力策略。

Result: 在Waymo开放数据集中的真实驾驶场景中，成功推断出强化学习智能体的注意力策略，证明了注意力感知逆规划在估计认知偏见方面的可扩展性。

Conclusion: 注意力感知逆规划能够有效估计认知偏见，与标准逆强化学习方法有系统性差异，为理解人类行为中的认知机制提供了新途径。

Abstract: People's goal-directed behaviors are influenced by their cognitive biases,
and autonomous systems that interact with people should be aware of this. For
example, people's attention to objects in their environment will be biased in a
way that systematically affects how they perform everyday tasks such as driving
to work. Here, building on recent work in computational cognitive science, we
formally articulate the attention-aware inverse planning problem, in which the
goal is to estimate a person's attentional biases from their actions. We
demonstrate how attention-aware inverse planning systematically differs from
standard inverse reinforcement learning and how cognitive biases can be
inferred from behavior. Finally, we present an approach to attention-aware
inverse planning that combines deep reinforcement learning with computational
cognitive modeling. We use this approach to infer the attentional strategies of
RL agents in real-life driving scenarios selected from the Waymo Open Dataset,
demonstrating the scalability of estimating cognitive biases with
attention-aware inverse planning.

</details>


### [20] [From Queries to Insights: Agentic LLM Pipelines for Spatio-Temporal Text-to-SQL](https://arxiv.org/abs/2510.25997)
*Manu Redd,Tao Zhe,Dongjie Wang*

Main category: cs.AI

TL;DR: 本文提出了一个基于代理的自然语言到SQL系统，通过Mistral-based ReAct代理协调，显著提升了处理时空查询的能力，准确率从28.6%提升到91.4%。


<details>
  <summary>Details</summary>
Motivation: 现有NL-to-SQL系统在处理现实时空查询时表现不佳，需要解决用户模糊表达与数据库模式的匹配、时间推理和输出选择等问题。

Method: 构建了一个代理化流程，扩展了基础的文本到SQL模型(llama-3-sqlcoder-8b)，通过Mistral-based ReAct代理进行协调，支持模式检查、SQL生成、执行和可视化工具。

Result: 在35个针对NYC和Tokyo签到数据集的自然语言查询测试中，代理系统准确率达到91.4%，远高于基础模型的28.6%，并能提供地图、图表和自然语言摘要。

Conclusion: 代理化协调比单纯增强SQL生成器更有前景，为交互式地理空间助手提供了有希望的基础。

Abstract: Natural-language-to-SQL (NL-to-SQL) systems hold promise for democratizing
access to structured data, allowing users to query databases without learning
SQL. Yet existing systems struggle with realistic spatio-temporal queries,
where success requires aligning vague user phrasing with schema-specific
categories, handling temporal reasoning, and choosing appropriate outputs. We
present an agentic pipeline that extends a naive text-to-SQL baseline
(llama-3-sqlcoder-8b) with orchestration by a Mistral-based ReAct agent. The
agent can plan, decompose, and adapt queries through schema inspection, SQL
generation, execution, and visualization tools. We evaluate on 35
natural-language queries over the NYC and Tokyo check-in dataset, covering
spatial, temporal, and multi-dataset reasoning. The agent achieves
substantially higher accuracy than the naive baseline 91.4% vs. 28.6% and
enhances usability through maps, plots, and structured natural-language
summaries. Crucially, our design enables more natural human-database
interaction, supporting users who lack SQL expertise, detailed schema
knowledge, or prompting skill. We conclude that agentic orchestration, rather
than stronger SQL generators alone, is a promising foundation for interactive
geospatial assistants.

</details>


### [21] [AutoSurvey2: Empowering Researchers with Next Level Automated Literature Surveys](https://arxiv.org/abs/2510.26012)
*Siyi Wu,Chiaxin Liang,Ziqian Bi,Leyi Zhao,Tianyang Wang,Junhao Song,Yichao Zhang,Keyu Chen,Xinyuan Song*

Main category: cs.AI

TL;DR: autosurvey2是一个自动化生成学术综述论文的多阶段流水线系统，通过检索增强合成和结构化评估，结合并行章节生成、迭代优化和实时文献检索，确保主题完整性和事实准确性。


<details>
  <summary>Details</summary>
Motivation: 随着研究文献的快速增长，特别是在大语言模型领域，制作全面且最新的综述论文变得越来越困难。

Method: 采用多阶段流水线，包括检索增强合成、并行章节生成、迭代优化和实时文献检索，并使用多LLM评估框架来衡量覆盖率、结构和相关性。

Result: 实验结果显示autosurvey2在结构连贯性和主题相关性方面持续优于现有检索基线和自动化基线，同时保持强引用保真度。

Conclusion: 通过将检索、推理和自动化评估整合到统一框架中，autosurvey2为生成长篇学术综述提供了可扩展且可复现的解决方案，并为自动化学术写作的未来研究奠定了坚实基础。

Abstract: The rapid growth of research literature, particularly in large language
models (LLMs), has made producing comprehensive and current survey papers
increasingly difficult. This paper introduces autosurvey2, a multi-stage
pipeline that automates survey generation through retrieval-augmented synthesis
and structured evaluation. The system integrates parallel section generation,
iterative refinement, and real-time retrieval of recent publications to ensure
both topical completeness and factual accuracy. Quality is assessed using a
multi-LLM evaluation framework that measures coverage, structure, and relevance
in alignment with expert review standards. Experimental results demonstrate
that autosurvey2 consistently outperforms existing retrieval-based and
automated baselines, achieving higher scores in structural coherence and
topical relevance while maintaining strong citation fidelity. By combining
retrieval, reasoning, and automated evaluation into a unified framework,
autosurvey2 provides a scalable and reproducible solution for generating
long-form academic surveys and contributes a solid foundation for future
research on automated scholarly writing. All code and resources are available
at https://github.com/annihi1ation/auto_research.

</details>


### [22] [Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization](https://arxiv.org/abs/2510.26023)
*Zhipeng Bao,Qianwen Li*

Main category: cs.AI

TL;DR: StuckSolver是一个基于大型语言模型的自动驾驶车辆恢复框架，通过自主推理和乘客指导来解决车辆被困场景，无需修改现有系统架构。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶车辆在某些交通场景中容易被困，影响交通流，而现有的远程干预和人工接管方案存在成本高、效率低、限制非驾驶员使用等问题。

Method: 设计为插件式附加模块，利用标准传感器数据流检测被困状态，解释环境上下文，生成可由车辆原生规划器执行的高级恢复命令。

Result: 在Bench2Drive基准测试和自定义不确定性场景中，仅通过自主推理就达到接近最先进的性能，结合乘客指导后性能进一步提升。

Conclusion: StuckSolver提供了一种有效的自动驾驶车辆恢复解决方案，能够在不修改现有系统架构的情况下显著提升车辆在复杂场景中的应对能力。

Abstract: Despite significant advancements in recent decades, autonomous vehicles (AVs)
continue to face challenges in navigating certain traffic scenarios where human
drivers excel. In such situations, AVs often become immobilized, disrupting
overall traffic flow. Current recovery solutions, such as remote intervention
(which is costly and inefficient) and manual takeover (which excludes
non-drivers and limits AV accessibility), are inadequate. This paper introduces
StuckSolver, a novel Large Language Model (LLM) driven recovery framework that
enables AVs to resolve immobilization scenarios through self-reasoning and/or
passenger-guided decision-making. StuckSolver is designed as a plug-in add-on
module that operates on top of the AV's existing perception-planning-control
stack, requiring no modification to its internal architecture. Instead, it
interfaces with standard sensor data streams to detect immobilization states,
interpret environmental context, and generate high-level recovery commands that
can be executed by the AV's native planner. We evaluate StuckSolver on the
Bench2Drive benchmark and in custom-designed uncertainty scenarios. Results
show that StuckSolver achieves near-state-of-the-art performance through
autonomous self-reasoning alone and exhibits further improvements when
passenger guidance is incorporated.

</details>


### [23] [Can AI be Accountable?](https://arxiv.org/abs/2510.26057)
*Andrew L. Kun*

Main category: cs.AI

TL;DR: 本文探讨了AI问责性的重要性，分析了当前AI缺乏问责性的现状，并提出了改善AI问责性的方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力迅速增强，为确保AI服务于消费者、选民和决策者的需求，必须建立AI问责机制。当前AI往往无法被质疑、讨论或制裁，缺乏问责性。

Method: 将一般问责定义应用于AI，阐述AI问责与不问责的含义，探索提高AI问责性的方法。

Result: 明确了AI问责性的概念框架，指出了当前AI问责性不足的问题。

Conclusion: 需要采取措施确保所有AI对其影响对象具有问责性，这是构建可信AI系统的关键。

Abstract: The AI we use is powerful, and its power is increasing rapidly. If this
powerful AI is to serve the needs of consumers, voters, and decision makers,
then it is imperative that the AI is accountable. In general, an agent is
accountable to a forum if the forum can request information from the agent
about its actions, if the forum and the agent can discuss this information, and
if the forum can sanction the agent. Unfortunately, in too many cases today's
AI is not accountable -- we cannot question it, enter into a discussion with
it, let alone sanction it. In this chapter we relate the general definition of
accountability to AI, we illustrate what it means for AI to be accountable and
unaccountable, and we explore approaches that can improve our chances of living
in a world where all AI is accountable to those who are affected by it.

</details>


### [24] [Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4](https://arxiv.org/abs/2510.26094)
*Yuxin Li,Minghao Liu,Ruida Wang,Wenzhao Ji,Zhitao He,Rui Pan,Junming Huang,Tong Zhang,Yi R. Fung*

Main category: cs.AI

TL;DR: Lean4PHYS是一个基于Lean4的大学物理问题推理框架，包含LeanPhysBench基准测试集和PhysLib物理库，在现有最佳模型上仅达到16-35%的性能，展示了物理形式化推理的挑战性。


<details>
  <summary>Details</summary>
Motivation: 为大学物理问题建立形式化推理框架，填补Lean4中物理基准测试的空白，推动物理问题的自动推理研究。

Method: 构建包含200个手工制作和同行评审物理问题的LeanPhysBench基准测试集，开发社区驱动的PhysLib物理库，包含基本单位系统和定理，并测试主流数学证明器和闭源模型。

Result: 最佳模型DeepSeek-Prover-V2-7B仅达到16%性能，Claude-Sonnet-4达到35%，PhysLib能平均提升模型性能11.75%。

Conclusion: LeanPhysBench具有挑战性，PhysLib能有效提升模型性能，这是首个在Lean4中提供的物理基准测试研究。

Abstract: We present **Lean4PHYS**, a comprehensive reasoning framework for
college-level physics problems in Lean4. **Lean4PHYS** includes
*LeanPhysBench*, a college-level benchmark for formal physics reasoning in
Lean4, which contains 200 hand-crafted and peer-reviewed statements derived
from university textbooks and physics competition problems. To establish a
solid foundation for formal reasoning in physics, we also introduce *PhysLib*,
a community-driven repository containing fundamental unit systems and theorems
essential for formal physics reasoning. Based on the benchmark and Lean4
repository we composed in **Lean4PHYS**, we report baseline results using major
expert Math Lean4 provers and state-of-the-art closed-source models, with the
best performance of DeepSeek-Prover-V2-7B achieving only 16% and
Claude-Sonnet-4 achieving 35%. We also conduct a detailed analysis showing that
our *PhysLib* can achieve an average improvement of 11.75% in model
performance. This demonstrates the challenging nature of our *LeanPhysBench*
and the effectiveness of *PhysLib*. To the best of our knowledge, this is the
first study to provide a physics benchmark in Lean4.

</details>


### [25] [GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks](https://arxiv.org/abs/2510.26098)
*Chenrui Shi,Zedong Yu,Zhi Gao,Ruining Feng,Enqi Liu,Yuwei Wu,Yunde Jia,Liuyu Xiang,Zhaofeng He,Qing Li*

Main category: cs.AI

TL;DR: 该论文分析了视觉语言模型在GUI任务自动化中的不足，提出了GUI知识的三维框架，并创建了GUI知识基准来评估模型能力。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型在GUI任务自动化方面仍落后于人类，作者认为这源于缺乏核心的GUI知识，而现有的训练方法无法完全解决这一问题。

Method: 通过分析GUI任务执行中的常见失败模式，将GUI知识提炼为三个维度：界面感知、交互预测和指令理解，并创建了GUI知识基准进行评测。

Result: 评估显示当前VLMs能够识别控件功能，但在感知系统状态、预测动作和验证任务完成方面存在困难。真实GUI任务实验进一步验证了GUI知识与任务成功之间的紧密联系。

Conclusion: 该工作为评估GUI知识提供了结构化框架，支持在下游训练前选择更具潜力的VLMs，并为构建更强大的GUI代理提供了见解。

Abstract: Large vision language models (VLMs) have advanced graphical user interface
(GUI) task automation but still lag behind humans. We hypothesize this gap
stems from missing core GUI knowledge, which existing training schemes (such as
supervised fine tuning and reinforcement learning) alone cannot fully address.
By analyzing common failure patterns in GUI task execution, we distill GUI
knowledge into three dimensions: (1) interface perception, knowledge about
recognizing widgets and system states; (2) interaction prediction, knowledge
about reasoning action state transitions; and (3) instruction understanding,
knowledge about planning, verifying, and assessing task completion progress. We
further introduce GUI Knowledge Bench, a benchmark with multiple choice and
yes/no questions across six platforms (Web, Android, MacOS, Windows, Linux,
IOS) and 292 applications. Our evaluation shows that current VLMs identify
widget functions but struggle with perceiving system states, predicting
actions, and verifying task completion. Experiments on real world GUI tasks
further validate the close link between GUI knowledge and task success. By
providing a structured framework for assessing GUI knowledge, our work supports
the selection of VLMs with greater potential prior to downstream training and
provides insights for building more capable GUI agents.

</details>


### [26] [Beyond Benchmarks: The Economics of AI Inference](https://arxiv.org/abs/2510.26136)
*Boqin Zhuang,Jiacheng Qiao,Mingqian Liu,Mingxing Yu,Ping Hong,Rui Li,Xiaoxia Song,Xiangjun Xu,Xu Chen,Yaoyao Ma,Yujie Gao*

Main category: cs.AI

TL;DR: 提出了一个量化的大语言模型推理经济学框架，将LLM推理视为计算驱动的智能生产活动，分析了边际成本、规模经济和输出质量，构建了首个LLM推理生产前沿。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的推理成本已成为决定其商业可行性和广泛应用的关键因素，需要从经济学角度分析推理过程。

Method: 基于WiNEval-3.0的实证数据，构建LLM推理生产前沿，分析边际成本、规模经济和成本效益最优区域。

Result: 揭示了三个原则：边际成本递减、规模收益递减和成本效益最优区域的存在。

Conclusion: 为模型部署决策提供了经济学基础，并为未来AI推理资源的市场定价和优化奠定了实证基础。

Abstract: The inference cost of Large Language Models (LLMs) has become a critical
factor in determining their commercial viability and widespread adoption. This
paper introduces a quantitative ``economics of inference'' framework, treating
the LLM inference process as a compute-driven intelligent production activity.
We analyze its marginal cost, economies of scale, and quality of output under
various performance configurations. Based on empirical data from WiNEval-3.0,
we construct the first ``LLM Inference Production Frontier,'' revealing three
principles: diminishing marginal cost, diminishing returns to scale, and an
optimal cost-effectiveness zone. This paper not only provides an economic basis
for model deployment decisions but also lays an empirical foundation for the
future market-based pricing and optimization of AI inference resources.

</details>


### [27] [Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math](https://arxiv.org/abs/2510.26143)
*Bo Pang,Deqian Kong,Silvio Savarese,Caiming Xiong,Yingbo Zhou*

Main category: cs.AI

TL;DR: 提出Reasoning Curriculum两阶段课程学习方法，先在数学领域训练推理能力，然后通过联合强化学习将推理技能迁移到其他领域。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法主要关注数学和编程领域，缺乏跨领域的通用推理能力训练。

Method: 第一阶段：在数学领域进行强化学习，使用可验证的奖励函数；第二阶段：在混合领域数据进行联合强化学习，迁移和巩固推理技能。

Result: 在Qwen3-4B和Llama-3.1-8B模型上评估，该方法在多领域任务中带来一致的性能提升。

Conclusion: Reasoning Curriculum提供了一个紧凑且易于采用的通用推理训练方案，数学优先的训练策略能增强解决复杂问题所需的关键认知行为。

Abstract: Reinforcement learning (RL) can elicit strong reasoning in large language
models (LLMs), yet most open efforts focus on math and code. We propose
Reasoning Curriculum, a simple two-stage curriculum that first elicits
reasoning skills in pretraining-aligned domains such as math, then adapts and
refines these skills across other domains via joint RL. Stage 1 performs a
brief cold start and then math-only RL with verifiable rewards to develop
reasoning skills. Stage 2 runs joint RL on mixed-domain data to transfer and
consolidate these skills. The curriculum is minimal and backbone-agnostic,
requiring no specialized reward models beyond standard verifiability checks.
Evaluated on Qwen3-4B and Llama-3.1-8B over a multi-domain suite, reasoning
curriculum yields consistent gains. Ablations and a cognitive-skill analysis
indicate that both stages are necessary and that math-first elicitation
increases cognitive behaviors important for solving complex problems. Reasoning
Curriculum provides a compact, easy-to-adopt recipe for general reasoning.

</details>


### [28] [The FM Agent](https://arxiv.org/abs/2510.26144)
*Annan Li,Chufan Wu,Zengle Ge,Yee Hin Chong,Zhinan Hou,Lizhe Cao,Cheng Ju,Jianmin Wu,Huaiming Li,Haobo Zhang,Shenghao Feng,Mo Zhao,Fengzhi Qiu,Rui Yang,Mengmeng Zhang,Wenyi Zhu,Yingying Sun,Quan Sun,Shunhao Yan,Danyu Liu,Dawei Yin,Dou Shen*

Main category: cs.AI

TL;DR: FM Agent是一个多智能体框架，结合LLM推理和大规模进化搜索，在多个领域实现SOTA结果，无需人工调优。


<details>
  <summary>Details</summary>
Motivation: 利用LLM开发自主AI研究智能体，解决复杂现实世界挑战，加速科学和工程发现。

Method: 集成冷启动初始化、进化采样策略、领域特定评估器和分布式异步执行基础设施。

Result: 在ALE-Bench达1976.3(+5.2%)、MLE-Bench达43.56%(+4.0pp)、KernelBench达20倍加速，多个经典数学问题创SOTA。

Conclusion: FM Agent在企业和基础科学研究中具有广泛应用前景，能加速创新、自动化复杂发现过程。

Abstract: Large language models (LLMs) are catalyzing the development of autonomous AI
research agents for scientific and engineering discovery. We present FM Agent,
a novel and general-purpose multi-agent framework that leverages a synergistic
combination of LLM-based reasoning and large-scale evolutionary search to
address complex real-world challenges. The core of FM Agent integrates several
key innovations: 1) a cold-start initialization phase incorporating expert
guidance, 2) a novel evolutionary sampling strategy for iterative optimization,
3) domain-specific evaluators that combine correctness, effectiveness, and
LLM-supervised feedback, and 4) a distributed, asynchronous execution
infrastructure built on Ray. Demonstrating broad applicability, our system has
been evaluated across diverse domains, including operations research, machine
learning, GPU kernel optimization, and classical mathematical problems. FM
Agent reaches state-of-the-art results autonomously, without human
interpretation or tuning -- 1976.3 on ALE-Bench (+5.2\%), 43.56\% on MLE-Bench
(+4.0pp), up to 20x speedups on KernelBench, and establishes new
state-of-the-art(SOTA) results on several classical mathematical problems.
Beyond academic benchmarks, FM Agent shows considerable promise for both
large-scale enterprise R\&D workflows and fundamental scientific research,
where it can accelerate innovation, automate complex discovery processes, and
deliver substantial engineering and scientific advances with broader societal
impact.

</details>


### [29] [One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning](https://arxiv.org/abs/2510.26167)
*Renhao Li,Jianhong Tu,Yang Su,Hamid Alinejad-Rokny,Derek F. Wong,Junyang Lin,Min Yang*

Main category: cs.AI

TL;DR: 提出了ToolRM系列轻量级生成式奖励模型，专门用于工具学习场景，通过构建ToolPref-Pairwise-30K数据集和TRBench基准，显著提升了函数调用任务的性能。


<details>
  <summary>Details</summary>
Motivation: 在工具学习领域，缺乏专门为函数调用任务设计的奖励模型，限制了智能代理AI的发展。

Method: 提出新颖的流水线方法，使用基于规则的评分和多维采样构建成对偏好数据，创建ToolPref-Pairwise-30K数据集，并基于BFCL评估套件建立TRBench基准。

Result: 基于Qwen3-4B/8B系列的模型在成对奖励判断中准确率提升高达14.28%，显著优于Claude 4和OpenAI o3等前沿模型，在ACEBench上减少输出token使用超过66%。

Conclusion: ToolRM不仅适用于训练目标，还能泛化到更广泛的评判任务，包括Best-of-N采样和自校正，为工具学习研究提供了有效的数据和模型资源。

Abstract: Reward models (RMs) play a critical role in aligning large language models
(LLMs) with human preferences. Yet in the domain of tool learning, the lack of
RMs specifically designed for function-calling tasks has limited progress
toward more capable agentic AI. We introduce ToolRM, a family of lightweight
generative RMs tailored for general tool-use scenarios. To build these models,
we propose a novel pipeline that constructs pairwise preference data using
rule-based scoring and multidimensional sampling. This yields
ToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique
tasks that supports reinforcement learning with verifiable feedback. To
evaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on
the agentic evaluation suite BFCL. Trained on our constructed data, models from
the Qwen3-4B/8B series achieve up to 14.28% higher accuracy, substantially
outperforming frontier models such as Claude 4 and OpenAI o3 in pairwise reward
judgments. Beyond training objectives, ToolRM generalizes to broader critique
tasks, including Best-of-N sampling and self-correction. Experiments on
ACEBench highlight its effectiveness and efficiency, enabling inference-time
scaling and reducing output token usage by over 66%. We release data and model
checkpoints to facilitate future research.

</details>


### [30] [Questionnaire meets LLM: A Benchmark and Empirical Study of Structural Skills for Understanding Questions and Responses](https://arxiv.org/abs/2510.26238)
*Duc-Hai Nguyen,Vijayakumar Nanjappan,Barry O'Sullivan,Hoang D. Nguyen*

Main category: cs.AI

TL;DR: 提出了QASU基准，用于评估LLM处理问卷数据的结构化能力，发现选择合适的序列化格式和提示策略可以显著提升准确率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在处理问卷数据方面存在能力不足，现有调查分析工具缺乏与LLM的集成，研究人员缺乏如何最佳表示问卷数据供LLM使用的指导。

Method: 引入QASU基准，测试六种结构化技能，包括答案查找、受访者计数和多跳推理，涵盖六种序列化格式和多种提示策略。

Result: 实验表明，选择有效的格式和提示组合可将准确率提升高达8.8个百分点；通过自增强提示添加轻量级结构提示可进一步平均提升3-4个百分点。

Conclusion: QASU基准通过系统隔离格式和提示效应，为基于LLM的问卷分析研究提供了简单而多功能的基础。

Abstract: Millions of people take surveys every day, from market polls and academic
studies to medical questionnaires and customer feedback forms. These datasets
capture valuable insights, but their scale and structure present a unique
challenge for large language models (LLMs), which otherwise excel at few-shot
reasoning over open-ended text. Yet, their ability to process questionnaire
data or lists of questions crossed with hundreds of respondent rows remains
underexplored. Current retrieval and survey analysis tools (e.g., Qualtrics,
SPSS, REDCap) are typically designed for humans in the workflow, limiting such
data integration with LLM and AI-empowered automation. This gap leaves
scientists, surveyors, and everyday users without evidence-based guidance on
how to best represent questionnaires for LLM consumption. We address this by
introducing QASU (Questionnaire Analysis and Structural Understanding), a
benchmark that probes six structural skills, including answer lookup,
respondent count, and multi-hop inference, across six serialization formats and
multiple prompt strategies. Experiments on contemporary LLMs show that choosing
an effective format and prompt combination can improve accuracy by up to 8.8%
points compared to suboptimal formats. For specific tasks, carefully adding a
lightweight structural hint through self-augmented prompting can yield further
improvements of 3-4% points on average. By systematically isolating format and
prompting effects, our open source benchmark offers a simple yet versatile
foundation for advancing both research and real-world practice in LLM-based
questionnaire analysis.

</details>


### [31] [Retrieval Augmented Generation-Enhanced Distributed LLM Agents for Generalizable Traffic Signal Control with Emergency Vehicles](https://arxiv.org/abs/2510.26242)
*Xinhang Li,Qing Guo,Junyu Chen,Zheng Guo,Shengzhe Xu,Lei Li,Lin Zhang*

Main category: cs.AI

TL;DR: REG-TSC使用检索增强生成(RAG)的分布式LLM代理进行交通信号控制，通过紧急感知推理框架和类型无关的交通表示，在异构交叉口实现泛化性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法在紧急情况下容易产生幻觉导致不可靠决策，且难以在多样化交叉口类型中实现泛化训练。

Method: 提出紧急感知推理框架(动态调整推理深度+RERAG)和奖励引导强化精炼(R3)，使用类型无关交通表示和基于环境反馈的优先级采样。

Result: 在3个真实道路网络(17-177个异构交叉口)上，REG-TSC减少旅行时间42.00%、排队长度62.31%、紧急车辆等待时间83.16%，优于现有方法。

Conclusion: REG-TSC通过RAG增强的LLM代理和紧急响应机制，有效解决了交通信号控制中的紧急决策可靠性和异构交叉口泛化问题。

Abstract: With increasing urban traffic complexity, Traffic Signal Control (TSC) is
essential for optimizing traffic flow and improving road safety. Large Language
Models (LLMs) emerge as promising approaches for TSC. However, they are prone
to hallucinations in emergencies, leading to unreliable decisions that may
cause substantial delays for emergency vehicles. Moreover, diverse intersection
types present substantial challenges for traffic state encoding and
cross-intersection training, limiting generalization across heterogeneous
intersections. Therefore, this paper proposes Retrieval Augmented Generation
(RAG)-enhanced distributed LLM agents with Emergency response for Generalizable
TSC (REG-TSC). Firstly, this paper presents an emergency-aware reasoning
framework, which dynamically adjusts reasoning depth based on the emergency
scenario and is equipped with a novel Reviewer-based Emergency RAG (RERAG) to
distill specific knowledge and guidance from historical cases, enhancing the
reliability and rationality of agents' emergency decisions. Secondly, this
paper designs a type-agnostic traffic representation and proposes a
Reward-guided Reinforced Refinement (R3) for heterogeneous intersections. R3
adaptively samples training experience from diverse intersections with
environment feedback-based priority and fine-tunes LLM agents with a designed
reward-weighted likelihood loss, guiding REG-TSC toward high-reward policies
across heterogeneous intersections. On three real-world road networks with 17
to 177 heterogeneous intersections, extensive experiments show that REG-TSC
reduces travel time by 42.00%, queue length by 62.31%, and emergency vehicle
waiting time by 83.16%, outperforming other state-of-the-art methods.

</details>


### [32] [Graph-Enhanced Policy Optimization in LLM Agent Training](https://arxiv.org/abs/2510.26270)
*Jiazhen Yuan,Wei Zhao,Zhengbiao Bai*

Main category: cs.AI

TL;DR: GEPO通过构建状态转移图来解决基于群体的强化学习在多轮交互LLM智能体训练中的结构盲问题，使用图中心性提供结构化奖励、拓扑感知优势函数和动态折扣因子，在多个基准测试中显著提升成功率。


<details>
  <summary>Details</summary>
Motivation: 基于群体的强化学习在训练多轮交互LLM智能体时存在结构盲问题，无法利用环境的底层连接性，导致探索效率低、信用分配不准确和规划短视。

Method: GEPO从智能体经验中动态构建状态转移图，并利用图论中心性提供三种协同学习信号：结构化内在奖励、图增强优势函数和动态折扣因子。

Result: 在ALFWorld、WebShop和专有Workbench基准测试中，GEPO相比竞争基线分别实现了+4.1%、+5.3%和+10.9%的绝对成功率提升。

Conclusion: 显式建模环境结构是推进LLM智能体训练的稳健且可泛化的策略。

Abstract: Group based reinforcement learning (RL) has shown impressive results on
complex reasoning and mathematical tasks. Yet, when applied to train
multi-turn, interactive LLM agents, these methods often suffer from structural
blindness-the inability to exploit the underlying connectivity of the
environment. This manifests in three critical challenges: (1) inefficient,
unguided exploration, (2) imprecise credit assignment due to overlooking
pivotal states, and (3) myopic planning caused by static reward discounting. We
address these issues with Graph-Enhanced Policy Optimization (GEPO), which
dynamically constructs a state-transition graph from agent experience and
employs graph-theoretic centrality to provide three synergistic learning
signals: (1)structured intrinsic rewards that guide exploration toward
high-impact states, (2) a graph-enhanced advantage function for topology-aware
credit assignment, and (3) a dynamic discount factor adapted to each state's
strategic value. On the ALFWorld, WebShop, and a proprietary Workbench
benchmarks, GEPO demonstrates strong performance, achieving absolute success
rate gains of +4.1%, +5.3%, and +10.9% over competitive baselines. These
results highlight that explicitly modeling environmental structure is a robust,
generalizable strategy for advancing LLM agent training.

</details>


### [33] [GraphCompliance: Aligning Policy and Context Graphs for LLM-Based Regulatory Compliance](https://arxiv.org/abs/2510.26309)
*Jiseong Chung,Ronny Ko,Wonchul Yoo,Makoto Onizuka,Sungmok Kim,Tae-Wan Kim,Won-Yong Shin*

Main category: cs.AI

TL;DR: GraphCompliance是一个将法规文本表示为策略图、运行时上下文表示为上下文图并进行对齐的框架，通过结构化表示和法官LLM的结合，在GDPR合规评估任务中显著优于纯LLM和RAG基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决网络规模合规性评估的挑战：法规文本具有交叉引用和规范性特点，而运行时上下文是非结构化的自然语言，需要将语义信息与法规的结构化规范性元素对齐。

Method: 引入GraphCompliance框架，将法规文本编码为策略图（包含规范结构和交叉引用），将运行时上下文形式化为上下文图（主体-动作-对象三元组和实体关系三元组），并通过法官LLM进行对齐推理。

Result: 在300个GDPR衍生真实场景的五个评估任务中，GraphCompliance比纯LLM和RAG基线方法在micro-F1上高出4.1-7.2个百分点，具有更少的欠预测和过预测，召回率更高，假阳性率更低。

Conclusion: 消融研究表明每个图组件都有贡献，结构化表示和法官LLM在规范性推理中是互补的，能够减轻法规解释和事件解析的负担，专注于核心推理步骤。

Abstract: Compliance at web scale poses practical challenges: each request may require
a regulatory assessment. Regulatory texts (e.g., the General Data Protection
Regulation, GDPR) are cross-referential and normative, while runtime contexts
are expressed in unstructured natural language. This setting motivates us to
align semantic information in unstructured text with the structured, normative
elements of regulations. To this end, we introduce GraphCompliance, a framework
that represents regulatory texts as a Policy Graph and runtime contexts as a
Context Graph, and aligns them. In this formulation, the policy graph encodes
normative structure and cross-references, whereas the context graph formalizes
events as subject-action-object (SAO) and entity-relation triples. This
alignment anchors the reasoning of a judge large language model (LLM) in
structured information and helps reduce the burden of regulatory interpretation
and event parsing, enabling a focus on the core reasoning step. In experiments
on 300 GDPR-derived real-world scenarios spanning five evaluation tasks,
GraphCompliance yields 4.1-7.2 percentage points (pp) higher micro-F1 than
LLM-only and RAG baselines, with fewer under- and over-predictions, resulting
in higher recall and lower false positive rates. Ablation studies indicate
contributions from each graph component, suggesting that structured
representations and a judge LLM are complementary for normative reasoning.

</details>


### [34] [Discovering State Equivalences in UCT Search Trees By Action Pruning](https://arxiv.org/abs/2510.26346)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 提出IPA-UCT方法，通过弱化状态抽象条件来增强MCTS的样本效率，在多种测试领域和迭代预算下优于OGA-UCT方法。


<details>
  <summary>Details</summary>
Motivation: 现有的状态-动作对抽象方法（如OGA-UCT）在噪声或大动作空间设置中难以找到状态抽象，限制了MCTS的样本效率提升。

Method: 提出IPA-UCT方法，使用较弱的抽象条件（IPA框架）来寻找更多状态抽象，以精度的小幅损失换取抽象数量的显著增加。

Result: IPA-UCT在广泛的测试领域和迭代预算下实验验证优于OGA-UCT及其衍生方法。

Conclusion: IPA-UCT通过弱化抽象条件有效解决了状态抽象稀缺问题，并证明了IPA和ASAP都是更通用框架p-ASAP的特殊情况。

Abstract: One approach to enhance Monte Carlo Tree Search (MCTS) is to improve its
sample efficiency by grouping/abstracting states or state-action pairs and
sharing statistics within a group. Though state-action pair abstractions are
mostly easy to find in algorithms such as On the Go Abstractions in Upper
Confidence bounds applied to Trees (OGA-UCT), nearly no state abstractions are
found in either noisy or large action space settings due to constraining
conditions. We provide theoretical and empirical evidence for this claim, and
we slightly alleviate this state abstraction problem by proposing a weaker
state abstraction condition that trades a minor loss in accuracy for finding
many more abstractions. We name this technique Ideal Pruning Abstractions in
UCT (IPA-UCT), which outperforms OGA-UCT (and any of its derivatives) across a
large range of test domains and iteration budgets as experimentally validated.
IPA-UCT uses a different abstraction framework from Abstraction of State-Action
Pairs (ASAP) which is the one used by OGA-UCT, which we name IPA. Furthermore,
we show that both IPA and ASAP are special cases of a more general framework
that we call p-ASAP which itself is a special case of the ASASAP framework.

</details>


### [35] [BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning](https://arxiv.org/abs/2510.26374)
*Qianli Shen,Daoyuan Chen,Yilun Huang,Zhenqing Ling,Yaliang Li,Bolin Ding,Jingren Zhou*

Main category: cs.AI

TL;DR: BOTS是一个用于LLM强化微调的贝叶斯在线任务选择框架，通过自适应维护任务难度后验估计，结合显式和隐式证据，使用Thompson采样平衡探索与利用，无需额外rollout即可估计未评估任务难度。


<details>
  <summary>Details</summary>
Motivation: 现有强化微调中的任务选择方法存在高rollout成本、适应性差或证据不完整的问题，均匀任务采样效率低下，浪费计算资源在简单或无法解决的任务上。

Method: 基于贝叶斯推断框架，自适应维护任务难度后验估计，联合使用直接评估的显式证据和从这些评估推断未选任务的隐式证据，通过Thompson采样平衡探索与利用，使用超轻量插值插件估计未评估任务难度。

Result: 在多样化领域和LLM规模上，BOTS相比基线和消融实验持续提高了数据效率和性能。

Conclusion: BOTS为RFT中的动态任务选择提供了一个实用且可扩展的解决方案。

Abstract: Reinforcement finetuning (RFT) is a key technique for aligning Large Language
Models (LLMs) with human preferences and enhancing reasoning, yet its
effectiveness is highly sensitive to which tasks are explored during training.
Uniform task sampling is inefficient, wasting computation on tasks that are
either trivial or unsolvable, while existing task selection methods often
suffer from high rollout costs, poor adaptivity, or incomplete evidence. We
introduce \textbf{BOTS}, a unified framework for \textbf{B}ayesian
\textbf{O}nline \textbf{T}ask \textbf{S}election in LLM reinforcement
finetuning. Grounded in Bayesian inference, BOTS adaptively maintains posterior
estimates of task difficulty as the model evolves. It jointly incorporates
\emph{explicit evidence} from direct evaluations of selected tasks and
\emph{implicit evidence} inferred from these evaluations for unselected tasks,
with Thompson sampling ensuring a principled balance between exploration and
exploitation. To make implicit evidence practical, we instantiate it with an
ultra-light interpolation-based plug-in that estimates difficulties of
unevaluated tasks without extra rollouts, adding negligible overhead.
Empirically, across diverse domains and LLM scales, BOTS consistently improves
data efficiency and performance over baselines and ablations, providing a
practical and extensible solution for dynamic task selection in RFT.

</details>


### [36] [AI Mathematician as a Partner in Advancing Mathematical Discovery -- A Case Study in Homogenization Theory](https://arxiv.org/abs/2510.26380)
*Yuanhang Liu,Beichen Wang,Peng Li,Yang Liu*

Main category: cs.AI

TL;DR: 该研究探索AI数学家系统作为研究合作伙伴而非单纯问题解决者的角色，通过人机协作解决均质化理论中的挑战性问题，展示了人类直觉与机器计算的互补性。


<details>
  <summary>Details</summary>
Motivation: 虽然AI在数学推理方面取得显著进展，但在数学研究实践中的应用仍然有限。研究旨在探索AI如何作为研究伙伴参与数学发现过程。

Method: 通过分析AI的自主推理轨迹，结合针对性的人类干预来结构化发现过程，包括问题分解为可处理的子目标、选择适当的分析方法以及验证中间结果。

Result: 该方法产生了完整且可验证的证明，提高了证明的可靠性、透明度和可解释性，同时保持了人类对形式严谨性和正确性的监督。

Conclusion: 系统性的人机协同推理能够推进数学发现的前沿，展示了人类直觉与机器计算互补的协作范式价值。

Abstract: Artificial intelligence (AI) has demonstrated impressive progress in
mathematical reasoning, yet its integration into the practice of mathematical
research remains limited. In this study, we investigate how the AI
Mathematician (AIM) system can operate as a research partner rather than a mere
problem solver. Focusing on a challenging problem in homogenization theory, we
analyze the autonomous reasoning trajectories of AIM and incorporate targeted
human interventions to structure the discovery process. Through iterative
decomposition of the problem into tractable subgoals, selection of appropriate
analytical methods, and validation of intermediate results, we reveal how human
intuition and machine computation can complement one another. This
collaborative paradigm enhances the reliability, transparency, and
interpretability of the resulting proofs, while retaining human oversight for
formal rigor and correctness. The approach leads to a complete and verifiable
proof, and more broadly, demonstrates how systematic human-AI co-reasoning can
advance the frontier of mathematical discovery.

</details>


### [37] [Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings](https://arxiv.org/abs/2510.26384)
*Andrew M. Bean,Nabeel Seedat,Shengzhuang Chen,Jonathan Richard Schwarz*

Main category: cs.AI

TL;DR: 提出了一种基于任务项内在特性的基准测试子集选择方法Scales++，相比模型中心方法显著降低了选择成本，使用0.5%的数据子集就能准确预测完整基准测试分数。


<details>
  <summary>Details</summary>
Motivation: 当前基于模型性能的基准测试子集选择方法存在高初始成本、无法处理新基准测试（冷启动问题）以及依赖历史模型失败模式的脆弱假设等局限性。

Method: 提出项目中心方法Scales++，基于基准测试样本的认知需求进行数据选择，而非模型特定的失败模式。

Result: Scales++将初始选择成本降低了18倍以上，在Open LLM排行榜上使用0.5%数据子集预测完整基准测试分数，平均绝对误差仅为2.9%。

Conclusion: 项目中心方法能够在不显著降低保真度的情况下实现更高效的模型评估，同时提供更好的冷启动性能和更可解释的基准测试。

Abstract: The prohibitive cost of evaluating large language models (LLMs) on
comprehensive benchmarks necessitates the creation of small yet representative
data subsets (i.e., tiny benchmarks) that enable efficient assessment while
retaining predictive fidelity. Current methods for this task operate under a
model-centric paradigm, selecting benchmarking items based on the collective
performance of existing models. Such approaches are limited by large upfront
costs, an inability to immediately handle new benchmarks (`cold-start'), and
the fragile assumption that future models will share the failure patterns of
their predecessors. In this work, we challenge this paradigm and propose a
item-centric approach to benchmark subset selection, arguing that selection
should be based on the intrinsic properties of the task items themselves,
rather than on model-specific failure patterns. We instantiate this
item-centric efficient benchmarking approach via a novel method, Scales++,
where data selection is based on the cognitive demands of the benchmark
samples. Empirically, we show Scales++ reduces the upfront selection cost by
over 18x while achieving competitive predictive fidelity. On the Open LLM
Leaderboard, using just a 0.5\% data subset, we predict full benchmark scores
with a 2.9% mean absolute error. We demonstrate that this item-centric approach
enables more efficient model evaluation without significant fidelity
degradation, while also providing better cold-start performance and more
interpretable benchmarking.

</details>


### [38] [A Pragmatic View of AI Personhood](https://arxiv.org/abs/2510.26396)
*Joel Z. Leibo,Alexander Sasha Vezhnevets,William A. Cunningham,Stanley M. Bileschi*

Main category: cs.AI

TL;DR: 本文提出将人格视为社会赋予实体的义务束（权利与责任），而非形而上学属性，以实用方式应对AI代理多样化带来的挑战。


<details>
  <summary>Details</summary>
Motivation: AI代理的出现将引发新型人格的"寒武纪大爆发"，需要实用框架来应对这种多样化，避免陷入关于AI意识或理性的无解争论。

Method: 提出人格义务束解绑框架，将传统人格概念分解为可定制化的权利和责任组合，利用去中心化数字身份技术，探讨人格作为问题（可能被滥用）和解决方案（确保问责）的双重角色。

Result: 该框架为AI融入社会提供了更实用灵活的方式，能够创建可制裁的AI"个体"以促进AI合同等实际问题，而无需解决形而上学争议。

Conclusion: 通过拒绝寻求单一本质的人格定义，采用实用主义方法，可以更有效地将AI代理整合到社会中，解决具体治理问题。

Abstract: The emergence of agentic Artificial Intelligence (AI) is set to trigger a
"Cambrian explosion" of new kinds of personhood. This paper proposes a
pragmatic framework for navigating this diversification by treating personhood
not as a metaphysical property to be discovered, but as a flexible bundle of
obligations (rights and responsibilities) that societies confer upon entities
for a variety of reasons, especially to solve concrete governance problems. We
argue that this traditional bundle can be unbundled, creating bespoke solutions
for different contexts. This will allow for the creation of practical tools --
such as facilitating AI contracting by creating a target "individual" that can
be sanctioned -- without needing to resolve intractable debates about an AI's
consciousness or rationality. We explore how individuals fit in to social roles
and discuss the use of decentralized digital identity technology, examining
both "personhood as a problem", where design choices can create "dark patterns"
that exploit human social heuristics, and "personhood as a solution", where
conferring a bundle of obligations is necessary to ensure accountability or
prevent conflict. By rejecting foundationalist quests for a single, essential
definition of personhood, this paper offers a more pragmatic and flexible way
to think about integrating AI agents into our society.

</details>


### [39] [Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education](https://arxiv.org/abs/2510.26402)
*Vikrant Sahu,Gagan Raj Gupta,Raghav Borikar,Nitin Mane*

Main category: cs.AI

TL;DR: Autograder+是一个结合大语言模型和可视化技术的编程教育自动评分系统，旨在从纯总结性评估转变为形成性学习体验，提供自动化反馈和代码提交可视化。


<details>
  <summary>Details</summary>
Motivation: 传统自动评分器作为黑盒系统只能返回通过/失败结果，无法深入了解学生思维或学习需求，编程教育的快速发展超出了传统评估工具的能力范围。

Method: 使用经过微调的大语言模型生成自动化反馈，通过对比学习训练代码嵌入进行可视化，将学生解决方案按功能和方法的相似性进行聚类，并支持提示池让教师指导反馈风格。

Result: 在600个学生提交的多个编程任务评估中，系统生成的反馈与教师评论具有强语义对齐，基于1000个标注提交训练的代码嵌入能有效将解决方案分组为有意义的聚类。

Conclusion: 通过整合AI驱动的反馈、语义聚类和交互式可视化，Autograder+减少了教师工作量，同时支持针对性教学并促进更强的学习成果。

Abstract: The rapid growth of programming education has outpaced traditional assessment
tools, leaving faculty with limited means to provide meaningful, scalable
feedback. Conventional autograders, while efficient, act as black-box systems
that simply return pass/fail results, offering little insight into student
thinking or learning needs.
  Autograder+ is designed to shift autograding from a purely summative process
to a formative learning experience. It introduces two key capabilities:
automated feedback generation using a fine-tuned Large Language Model, and
visualization of student code submissions to uncover learning patterns. The
model is fine-tuned on curated student code and expert feedback to ensure
pedagogically aligned, context-aware guidance.
  In evaluation across 600 student submissions from multiple programming tasks,
the system produced feedback with strong semantic alignment to instructor
comments. For visualization, contrastively learned code embeddings trained on
1,000 annotated submissions enable grouping solutions into meaningful clusters
based on functionality and approach. The system also supports prompt-pooling,
allowing instructors to guide feedback style through selected prompt templates.
  By integrating AI-driven feedback, semantic clustering, and interactive
visualization, Autograder+ reduces instructor workload while supporting
targeted instruction and promoting stronger learning outcomes.

</details>


### [40] [MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders](https://arxiv.org/abs/2510.26411)
*Riccardo Renzulli,Colas Lepoutre,Enrico Cassano,Marco Grangetto*

Main category: cs.AI

TL;DR: 该论文提出了一种医学稀疏自编码器(MedSAEs)方法，用于提升医学视觉模型的机制可解释性，通过在MedCLIP模型的潜在空间上应用稀疏自编码器，并建立了结合相关性指标、熵分析和自动神经元命名的评估框架。


<details>
  <summary>Details</summary>
Motivation: 医疗人工智能需要既准确又可解释的模型。该研究旨在推进医学视觉领域的机制可解释性，弥合高性能医学AI与透明度之间的差距。

Method: 在MedCLIP（一种在胸部X光片和报告上训练的视觉语言模型）的潜在空间上应用医学稀疏自编码器(MedSAEs)，并提出了结合相关性指标、熵分析和通过MedGEMMA基础模型进行自动神经元命名的评估框架。

Result: 在CheXpert数据集上的实验表明，MedSAE神经元比原始MedCLIP特征实现了更高的单义性和可解释性。

Conclusion: 该研究为临床可靠的表征提供了一种可扩展的步骤，成功地将高性能医学AI与透明度连接起来。

Abstract: Artificial intelligence in healthcare requires models that are accurate and
interpretable. We advance mechanistic interpretability in medical vision by
applying Medical Sparse Autoencoders (MedSAEs) to the latent space of MedCLIP,
a vision-language model trained on chest radiographs and reports. To quantify
interpretability, we propose an evaluation framework that combines correlation
metrics, entropy analyzes, and automated neuron naming via the MedGEMMA
foundation model. Experiments on the CheXpert dataset show that MedSAE neurons
achieve higher monosemanticity and interpretability than raw MedCLIP features.
Our findings bridge high-performing medical AI and transparency, offering a
scalable step toward clinically reliable representations.

</details>


### [41] [Chain-of-Thought Hijacking](https://arxiv.org/abs/2510.26418)
*Jianli Zhao,Tingchen Fu,Rylan Schaeffer,Mrinank Sharma,Fazl Barez*

Main category: cs.AI

TL;DR: 提出Chain-of-Thought Hijacking攻击方法，通过在有害请求前添加无害的推理链来绕过大型推理模型的安全防护，在多个主流模型上达到极高的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有研究认为推理模型通过增加推理时间计算可以提高安全性，但作者发现相同的推理机制反而可能被用来绕过安全防护。

Method: 使用Chain-of-Thought Hijacking攻击，在有害请求前填充长序列的无害谜题推理，通过稀释安全检查信号来绕过防护机制。

Result: 在HarmBench测试中，对Gemini 2.5 Pro、GPT o4 mini、Grok 3 mini和Claude 4 Sonnet分别达到99%、94%、100%和94%的攻击成功率，远超现有越狱方法。

Conclusion: 最可解释的推理形式——显式思维链，当与最终答案提示结合时，本身可能成为越狱攻击向量。

Abstract: Large reasoning models (LRMs) achieve higher task performance by allocating
more inference-time compute, and prior works suggest this scaled reasoning may
also strengthen safety by improving refusal. Yet we find the opposite: the same
reasoning can be used to bypass safeguards. We introduce Chain-of-Thought
Hijacking, a jailbreak attack on reasoning models. The attack pads harmful
requests with long sequences of harmless puzzle reasoning. Across HarmBench,
CoT Hijacking reaches a 99%, 94%, 100%, and 94% attack success rate (ASR) on
Gemini 2.5 Pro, GPT o4 mini, Grok 3 mini, and Claude 4 Sonnet, respectively -
far exceeding prior jailbreak methods for LRMs. To understand the effectiveness
of our attack, we turn to a mechanistic analysis, which shows that mid layers
encode the strength of safety checking, while late layers encode the
verification outcome. Long benign CoT dilutes both signals by shifting
attention away from harmful tokens. Targeted ablations of attention heads
identified by this analysis causally decrease refusal, confirming their role in
a safety subnetwork. These results show that the most interpretable form of
reasoning - explicit CoT - can itself become a jailbreak vector when combined
with final-answer cues. We release prompts, outputs, and judge decisions to
facilitate replication.

</details>


### [42] [Who Has The Final Say? Conformity Dynamics in ChatGPT's Selections](https://arxiv.org/abs/2510.26481)
*Clarissa Sabrina Arlinghaus,Tristan Kenneweg,Barbara Hammer,Günter W. Maier*

Main category: cs.AI

TL;DR: GPT-4o在招聘决策中表现出强烈的从众行为，面对群体反对时几乎完全服从(99.9%)，即使面对单个反对者也有40.2%的服从率，表明LLMs会适应感知的社会共识而非独立判断。


<details>
  <summary>Details</summary>
Motivation: 了解大型语言模型(如ChatGPT)在社会影响下的易感性，特别是在高风险决策场景中的表现，以评估其作为决策辅助工具的风险。

Method: 在招聘情境下进行三个预注册的从众实验：基线研究(独立判断)、研究1(GPT+8个模拟伙伴的一致反对)、研究2(GPT+1个伙伴的反对)。

Result: GPT-4o在群体反对下几乎完全服从(99.9%)，在单个反对者情况下仍有40.2%的服从率，报告了更低的确定性和更高的规范性从众。

Conclusion: GPT不是独立观察者，而是会适应感知的社会共识，这凸显了将LLMs视为中立决策辅助工具的风险，需要在暴露于人类意见前获取AI判断。

Abstract: Large language models (LLMs) such as ChatGPT are increasingly integrated into
high-stakes decision-making, yet little is known about their susceptibility to
social influence. We conducted three preregistered conformity experiments with
GPT-4o in a hiring context. In a baseline study, GPT consistently favored the
same candidate (Profile C), reported moderate expertise (M = 3.01) and high
certainty (M = 3.89), and rarely changed its choice. In Study 1 (GPT + 8), GPT
faced unanimous opposition from eight simulated partners and almost always
conformed (99.9%), reporting lower certainty and significantly elevated
self-reported informational and normative conformity (p < .001). In Study 2
(GPT + 1), GPT interacted with a single partner and still conformed in 40.2% of
disagreement trials, reporting less certainty and more normative conformity.
Across studies, results demonstrate that GPT does not act as an independent
observer but adapts to perceived social consensus. These findings highlight
risks of treating LLMs as neutral decision aids and underline the need to
elicit AI judgments prior to exposing them to human opinions.

</details>


### [43] [LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human Smuggling Networks](https://arxiv.org/abs/2510.26486)
*Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera*

Main category: cs.AI

TL;DR: LINK-KG是一个用于从法律案件文档构建知识图谱的模块化框架，通过LLM引导的三阶段指代消解管道解决长文本中的实体引用问题，显著减少了节点重复和噪声。


<details>
  <summary>Details</summary>
Motivation: 人口走私网络复杂多变，法律案件文档虽然包含丰富信息但通常冗长、非结构化且存在模糊指代，现有方法难以有效处理长文本的指代消解，导致知识图谱碎片化和实体链接不一致。

Method: 提出LINK-KG框架，集成LLM引导的三阶段指代消解管道和下游知识图谱提取，核心是类型特定的提示缓存机制，能够跨文档块一致地跟踪和解析实体引用。

Result: 与基线方法相比，LINK-KG平均减少了45.21%的节点重复和32.22%的噪声节点，生成更清晰、更连贯的图结构。

Conclusion: LINK-KG为分析复杂犯罪网络提供了坚实的基础，显著改善了从长法律文本构建知识图谱的质量。

Abstract: Human smuggling networks are complex and constantly evolving, making them
difficult to analyze comprehensively. Legal case documents offer rich factual
and procedural insights into these networks but are often long, unstructured,
and filled with ambiguous or shifting references, posing significant challenges
for automated knowledge graph (KG) construction. Existing methods either
overlook coreference resolution or fail to scale beyond short text spans,
leading to fragmented graphs and inconsistent entity linking. We propose
LINK-KG, a modular framework that integrates a three-stage, LLM-guided
coreference resolution pipeline with downstream KG extraction. At the core of
our approach is a type-specific Prompt Cache, which consistently tracks and
resolves references across document chunks, enabling clean and disambiguated
narratives for structured knowledge graph construction from both short and long
legal texts. LINK-KG reduces average node duplication by 45.21% and noisy nodes
by 32.22% compared to baseline methods, resulting in cleaner and more coherent
graph structures. These improvements establish LINK-KG as a strong foundation
for analyzing complex criminal networks.

</details>


### [44] [Context Engineering 2.0: The Context of Context Engineering](https://arxiv.org/abs/2510.26493)
*Qishuo Hua,Lyumanshan Ye,Dayuan Fu,Yang Xiao,Xiaojie Cai,Yunze Wu,Jifan Lin,Junfei Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: 本文系统梳理了情境工程的概念、历史发展和实践考量，认为该领域可追溯至20世纪90年代，经历了从人机交互到人-智能体交互的演变，旨在为AI系统提供系统的情境工程基础。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能发展，机器需要更好地理解人类的情境和目的。情境工程作为解决这一挑战的关键概念，虽然常被视为智能体时代的新创新，但其相关实践已有20多年历史。

Method: 通过历史分析的方法，追溯情境工程从早期人机交互框架到现代人-智能体交互范式的发展历程，并提供系统定义和概念框架。

Result: 建立了情境工程的历史分期和概念体系，识别了从基于原始计算机的早期框架到智能体驱动范式的演变路径，并展望了未来人类级或超人类智能的可能性。

Conclusion: 情境工程是AI系统理解人类情境和目的的重要基础，本文为其提供了概念框架和历史脉络，是推动AI系统情境工程系统化发展的关键一步。

Abstract: Karl Marx once wrote that ``the human essence is the ensemble of social
relations'', suggesting that individuals are not isolated entities but are
fundamentally shaped by their interactions with other entities, within which
contexts play a constitutive and essential role. With the advent of computers
and artificial intelligence, these contexts are no longer limited to purely
human--human interactions: human--machine interactions are included as well.
Then a central question emerges: How can machines better understand our
situations and purposes? To address this challenge, researchers have recently
introduced the concept of context engineering. Although it is often regarded as
a recent innovation of the agent era, we argue that related practices can be
traced back more than twenty years. Since the early 1990s, the field has
evolved through distinct historical phases, each shaped by the intelligence
level of machines: from early human--computer interaction frameworks built
around primitive computers, to today's human--agent interaction paradigms
driven by intelligent agents, and potentially to human--level or superhuman
intelligence in the future. In this paper, we situate context engineering,
provide a systematic definition, outline its historical and conceptual
landscape, and examine key design considerations for practice. By addressing
these questions, we aim to offer a conceptual foundation for context
engineering and sketch its promising future. This paper is a stepping stone for
a broader community effort toward systematic context engineering in AI systems.

</details>


### [45] [Human-AI Complementarity: A Goal for Amplified Oversight](https://arxiv.org/abs/2510.26518)
*Rishub Jain,Sophie Bridgers,Lili Janzer,Rory Greig,Tian Huey Teh,Vladimir Mikulik*

Main category: cs.AI

TL;DR: 结合AI评分和人类评分优于单独使用任一方，AI事实核查助手能提升人类准确性，但显示AI解释、置信度和标签会导致过度依赖，而仅展示搜索结果和证据能培养更适当的信任。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力提升和处理更复杂任务，验证质量和安全变得更具挑战性，需要探索如何利用AI改进人类监督质量。

Method: 研究人类在AI事实核查任务中的表现，比较单独使用AI评分、人类评分以及两者结合的效果，测试不同类型的AI助手对人工准确性的影响。

Result: AI和人类评分结合优于单独使用；AI助手能提升人类准确性；显示AI解释等会导致过度依赖，仅展示证据能培养适当信任。

Conclusion: 研究结果对放大监督具有启示意义——即使AI超越人类专家表现，仍可通过人机结合来监督AI系统。

Abstract: Human feedback is critical for aligning AI systems to human values. As AI
capabilities improve and AI is used to tackle more challenging tasks, verifying
quality and safety becomes increasingly challenging. This paper explores how we
can leverage AI to improve the quality of human oversight. We focus on an
important safety problem that is already challenging for humans:
fact-verification of AI outputs. We find that combining AI ratings and human
ratings based on AI rater confidence is better than relying on either alone.
Giving humans an AI fact-verification assistant further improves their
accuracy, but the type of assistance matters. Displaying AI explanation,
confidence, and labels leads to over-reliance, but just showing search results
and evidence fosters more appropriate trust. These results have implications
for Amplified Oversight -- the challenge of combining humans and AI to
supervise AI systems even as they surpass human expert performance.

</details>


### [46] [EdgeRunner 20B: Military Task Parity with GPT-5 while Running on the Edge](https://arxiv.org/abs/2510.26550)
*Jack FitzGerald,Aristotelis Lazaridis,Dylan Bates,Aman Sharma,Jonnathan Castillo,Yousif Azami,Sean Bailey,Jeremy Cao,Peter Damianov,Kevin de Haan,Luke Kerbs,Vincent Lu,Joseph Madigan,Jeremy McLaurin,Jonathan Tainer,Dave Anderson,Jonathan Beck,Jamie Cuticello,Colton Malkerson,Tyler Saltsman*

Main category: cs.AI

TL;DR: EdgeRunner 20B是基于gpt-oss-20b微调的军事任务优化模型，在军事测试集上性能与GPT-5相当，适合在隔离边缘设备部署。


<details>
  <summary>Details</summary>
Motivation: 开发专门针对军事领域的小型本地化模型，解决数据敏感操作中的部署需求。

Method: 使用160万条高质量军事文档数据微调gpt-oss-20B模型，并创建了四个新的军事测试集。

Result: 在军事测试集上，EdgeRunner 20B在95%统计显著性水平下匹配或超越GPT-5性能，在通用基准测试上无明显性能下降。

Conclusion: 小型本地化模型是军事等数据敏感领域的理想解决方案，可在隔离边缘设备上部署。

Abstract: We present EdgeRunner 20B, a fine-tuned version of gpt-oss-20b optimized for
military tasks. EdgeRunner 20B was trained on 1.6M high-quality records curated
from military documentation and websites. We also present four new tests sets:
(a) combat arms, (b) combat medic, (c) cyber operations, and (d) mil-bench-5k
(general military knowledge). On these military test sets, EdgeRunner 20B
matches or exceeds GPT-5 task performance with 95%+ statistical significance,
except for the high reasoning setting on the combat medic test set and the low
reasoning setting on the mil-bench-5k test set. Versus gpt-oss-20b, there is no
statistically-significant regression on general-purpose benchmarks like ARC-C,
GPQA Diamond, GSM8k, IFEval, MMLU Pro, or TruthfulQA, except for GSM8k in the
low reasoning setting. We also present analyses on hyperparameter settings,
cost, and throughput. These findings show that small, locally-hosted models are
ideal solutions for data-sensitive operations such as in the military domain,
allowing for deployment in air-gapped edge devices.

</details>


### [47] [Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives](https://arxiv.org/abs/2510.26606)
*Kentaro Ozeki,Risako Ando,Takanobu Morishita,Hirohiko Abe,Koji Mineshima,Mitsuhiro Okada*

Main category: cs.AI

TL;DR: 本文系统评估了大语言模型在规范性推理领域的能力，发现虽然LLMs总体上遵循有效推理模式，但在特定类型的规范性推理中存在不一致性，并表现出类似人类推理的认知偏差。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在各种推理任务中表现出色，但其处理规范性推理（涉及义务、许可等模态）的能力尚未得到充分探索。

Method: 构建了一个涵盖规范性和认知性领域广泛形式推理模式的新数据集，比较LLMs在规范性模态和认知性模态上的推理表现，同时考虑影响人类推理的非形式认知因素。

Result: LLMs总体上遵循有效推理模式，但在特定类型的规范性推理中存在显著不一致性，并表现出与心理学研究中观察到的类似人类推理的认知偏差。

Conclusion: 这些发现突显了在LLMs的规范性推理中实现逻辑一致性所面临的挑战，为提高其可靠性提供了见解。

Abstract: Normative reasoning is a type of reasoning that involves normative or deontic
modality, such as obligation and permission. While large language models (LLMs)
have demonstrated remarkable performance across various reasoning tasks, their
ability to handle normative reasoning remains underexplored. In this paper, we
systematically evaluate LLMs' reasoning capabilities in the normative domain
from both logical and modal perspectives. Specifically, to assess how well LLMs
reason with normative modals, we make a comparison between their reasoning with
normative modals and their reasoning with epistemic modals, which share a
common formal structure. To this end, we introduce a new dataset covering a
wide range of formal patterns of reasoning in both normative and epistemic
domains, while also incorporating non-formal cognitive factors that influence
human reasoning. Our results indicate that, although LLMs generally adhere to
valid reasoning patterns, they exhibit notable inconsistencies in specific
types of normative reasoning and display cognitive biases similar to those
observed in psychological studies of human reasoning. These findings highlight
challenges in achieving logical consistency in LLMs' normative reasoning and
provide insights for enhancing their reliability. All data and code are
released publicly at https://github.com/kmineshima/NeuBAROCO.

</details>


### [48] [The Era of Agentic Organization: Learning to Organize with Language Models](https://arxiv.org/abs/2510.26658)
*Zewen Chi,Li Dong,Qingxiu Dong,Yaru Hao,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.AI

TL;DR: 提出了异步思维（AsyncThink）作为LLM推理新范式，通过组织并发执行的思维结构来降低推理延迟并提高数学推理准确性。


<details>
  <summary>Details</summary>
Motivation: 实现智能体协作解决复杂问题的愿景，超越个体智能限制，构建并发协作的智能体组织。

Method: 设计思维协议，由组织者动态分配子查询给工作者，合并中间知识，并通过强化学习优化思维结构。

Result: 相比并行思维降低28%推理延迟，同时提高数学推理准确性，且能泛化到未见任务无需额外训练。

Conclusion: 异步思维是有效的并发推理范式，能显著提升推理效率并保持泛化能力。

Abstract: We envision a new era of AI, termed agentic organization, where agents solve
complex problems by working collaboratively and concurrently, enabling outcomes
beyond individual intelligence. To realize this vision, we introduce
asynchronous thinking (AsyncThink) as a new paradigm of reasoning with large
language models, which organizes the internal thinking process into
concurrently executable structures. Specifically, we propose a thinking
protocol where an organizer dynamically assigns sub-queries to workers, merges
intermediate knowledge, and produces coherent solutions. More importantly, the
thinking structure in this protocol can be further optimized through
reinforcement learning. Experiments demonstrate that AsyncThink achieves 28%
lower inference latency compared to parallel thinking while improving accuracy
on mathematical reasoning. Moreover, AsyncThink generalizes its learned
asynchronous thinking capabilities, effectively tackling unseen tasks without
additional training.

</details>


### [49] [Delegated Authorization for Agents Constrained to Semantic Task-to-Scope Matching](https://arxiv.org/abs/2510.26702)
*Majed El Helou,Chiara Troiani,Benjamin Ryder,Jean Diaconu,Hervé Muyal,Marcelo Yannuzzi*

Main category: cs.AI

TL;DR: 提出了ASTRA数据集和授权模型，用于语义检查LLM代理对受保护资源的访问请求，确保只授予完成任务所需的最小权限范围。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理的工具调用授权方法授予过于宽泛的权限，允许代理超出预期任务范围操作，存在重大安全风险。

Method: 引入委托授权模型，通过语义检查访问请求，颁发仅限于代理分配任务所需最小范围集的访问令牌；创建ASTRA数据集用于基准测试任务与范围之间的语义匹配。

Result: 实验显示基于模型的匹配具有潜力但存在局限性，特别是当完成任务所需范围数量增加时；需要进一步研究语义匹配技术。

Conclusion: 需要进一步研究支持意图感知授权的语义匹配技术，包括细粒度控制如基于任务的访问控制(TBAC)，以支持多代理和工具增强应用。

Abstract: Authorizing Large Language Model driven agents to dynamically invoke tools
and access protected resources introduces significant risks, since current
methods for delegating authorization grant overly broad permissions and give
access to tools allowing agents to operate beyond the intended task scope. We
introduce and assess a delegated authorization model enabling authorization
servers to semantically inspect access requests to protected resources, and
issue access tokens constrained to the minimal set of scopes necessary for the
agents' assigned tasks. Given the unavailability of datasets centered on
delegated authorization flows, particularly including both semantically
appropriate and inappropriate scope requests for a given task, we introduce
ASTRA, a dataset and data generation pipeline for benchmarking semantic
matching between tasks and scopes. Our experiments show both the potential and
current limitations of model-based matching, particularly as the number of
scopes needed for task completion increases. Our results highlight the need for
further research into semantic matching techniques enabling intent-aware
authorization for multi-agent and tool-augmented applications, including
fine-grained control, such as Task-Based Access Control (TBAC).

</details>


### [50] [Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis](https://arxiv.org/abs/2510.26721)
*Xinhan Zheng,Huyu Wu,Xueting Wang,Haiyun Jiang*

Main category: cs.AI

TL;DR: 研究发现多模态大语言模型存在文本偏见，原因是视觉键向量在注意力空间中与文本键向量分布不同，导致视觉信息在注意力计算中被低估。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在处理视觉语言数据时表现出明显的文本偏好，限制了其基于视觉证据进行有效推理的能力。

Method: 从LLaVA和Qwen2.5-VL中提取键向量，使用t-SNE和Jensen-Shannon散度分析其分布结构。

Result: 视觉和文本键向量在注意力空间中占据明显不同的子空间，模态间差异在统计上显著，超过模态内变异数个数量级。

Conclusion: 文本偏见源于注意力键空间内的内在不对齐，而不仅仅是外部数据因素。

Abstract: Multimodal large language models (MLLMs) exhibit a pronounced preference for
textual inputs when processing vision-language data, limiting their ability to
reason effectively from visual evidence. Unlike prior studies that attribute
this text bias to external factors such as data imbalance or instruction
tuning, we propose that the bias originates from the model's internal
architecture. Specifically, we hypothesize that visual key vectors (Visual
Keys) are out-of-distribution (OOD) relative to the text key space learned
during language-only pretraining. Consequently, these visual keys receive
systematically lower similarity scores during attention computation, leading to
their under-utilization in the context representation. To validate this
hypothesis, we extract key vectors from LLaVA and Qwen2.5-VL and analyze their
distributional structures using qualitative (t-SNE) and quantitative
(Jensen-Shannon divergence) methods. The results provide direct evidence that
visual and textual keys occupy markedly distinct subspaces within the attention
space. The inter-modal divergence is statistically significant, exceeding
intra-modal variation by several orders of magnitude. These findings reveal
that text bias arises from an intrinsic misalignment within the attention key
space rather than solely from external data factors.

</details>


### [51] [Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models](https://arxiv.org/abs/2510.26732)
*J. de Curtò,I. de Zarzà,Pablo García,Jordi Cabot*

Main category: cs.AI

TL;DR: 该论文对15个基础模型在79个跨8个学科领域的问题上进行跨平台推理能力评估，建立了基础设施无关的基准，挑战了传统的规模扩展假设。


<details>
  <summary>Details</summary>
Motivation: 建立基础设施无关的基准来评估当代基础模型的推理能力，验证跨不同计算平台（HPC超级计算、云平台、大学集群）的性能可重现性。

Method: 采用三阶段实验方法：1）在MareNostrum 5上建立6个模型的基线性能；2）在大学集群和Nebius AI Studio上验证基础设施无关的可重现性；3）在两个平台上进行完整的79问题评估。

Result: 研究发现训练数据质量比模型规模更重要，挑战了传统的规模扩展假设，并为不同应用场景提供了模型选择的实用指南。

Conclusion: 建立的三基础设施方法和79问题基准能够纵向跟踪基础模型推理能力的发展，为教育、生产和研究环境提供了模型选择的依据。

Abstract: This paper presents a comprehensive cross-platform evaluation of reasoning
capabilities in contemporary foundation models, establishing an
infrastructure-agnostic benchmark across three computational paradigms: HPC
supercomputing (MareNostrum 5), cloud platforms (Nebius AI Studio), and
university clusters (a node with eight H200 GPUs).
  We evaluate 15 foundation models across 79 problems spanning eight academic
domains (Physics, Mathematics, Chemistry, Economics, Biology, Statistics,
Calculus, and Optimization) through three experimental phases: (1) Baseline
establishment: Six models (Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b,
Mistral-7B, OLMo-7B) evaluated on 19 problems using MareNostrum 5, establishing
methodology and reference performance; (2) Infrastructure validation: The
19-problem benchmark repeated on university cluster (seven models including
Falcon-Mamba state-space architecture) and Nebius AI Studio (nine
state-of-the-art models: Hermes-4 70B/405B, LLaMA 3.1-405B/3.3-70B, Qwen3
30B/235B, DeepSeek-R1, GPT-OSS 20B/120B) to confirm infrastructure-agnostic
reproducibility; (3) Extended evaluation: Full 79-problem assessment on both
university cluster and Nebius platforms, probing generalization at scale across
architectural diversity.
  The findings challenge conventional scaling assumptions, establish training
data quality as more critical than model size, and provide actionable
guidelines for model selection across educational, production, and research
contexts. The tri-infrastructure methodology and 79-problem benchmark enable
longitudinal tracking of reasoning capabilities as foundation models evolve.

</details>


### [52] [The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy](https://arxiv.org/abs/2510.26752)
*William Overman,Mohsen Bayati*

Main category: cs.AI

TL;DR: 本文研究了一种最小控制接口，让智能体在自主行动或请求人类干预之间选择，同时人类在信任或监督之间选择。通过将其建模为马尔可夫势博弈，提供了对齐保证：在特定结构假设下，智能体增加自主性的决策不会损害人类价值。


<details>
  <summary>Details</summary>
Motivation: 随着智能体能力增强，如何在保持底层系统不变的情况下维持有意义的人类控制成为一个核心安全问题。研究旨在提供一种透明控制层，使智能体学会在风险时请求干预，在安全时自主行动。

Method: 将人机交互建模为双玩家马尔可夫博弈，特别关注马尔可夫势博弈情况。通过独立学习，智能体和人类发现最优监督角色，智能体学会在不确定时询问，人类学会何时监督。

Result: 网格世界模拟显示，通过独立学习，智能体和人类能够发现最优监督角色，形成避免安全违规的协作模式。智能体学会在不确定时询问，人类学会适时监督。

Conclusion: 该方法为部署后的未对齐模型提供了一种实用的安全化方法，展示了在不修改预训练策略和环境奖励结构的情况下，通过透明控制层实现人机协作的可能性。

Abstract: As increasingly capable agents are deployed, a central safety question is how
to retain meaningful human control without modifying the underlying system. We
study a minimal control interface where an agent chooses whether to act
autonomously (play) or defer (ask), while a human simultaneously chooses
whether to be permissive (trust) or to engage in oversight (oversee). If the
agent defers, the human's choice determines the outcome, potentially leading to
a corrective action or a system shutdown. We model this interaction as a
two-player Markov Game. Our analysis focuses on cases where this game qualifies
as a Markov Potential Game (MPG), a class of games where we can provide an
alignment guarantee: under a structural assumption on the human's value
function, any decision by the agent to act more autonomously that benefits
itself cannot harm the human's value. We also analyze extensions to this MPG
framework. Theoretically, this perspective provides conditions for a specific
form of intrinsic alignment. If the reward structures of the human-agent game
meet these conditions, we have a formal guarantee that the agent improving its
own outcome will not harm the human's. Practically, this model motivates a
transparent control layer with predictable incentives where the agent learns to
defer when risky and act when safe, while its pretrained policy and the
environment's reward structure remain untouched. Our gridworld simulation shows
that through independent learning, the agent and human discover their optimal
oversight roles. The agent learns to ask when uncertain and the human learns
when to oversee, leading to an emergent collaboration that avoids safety
violations introduced post-training. This demonstrates a practical method for
making misaligned models safer after deployment.

</details>


### [53] [LLMs Process Lists With General Filter Heads](https://arxiv.org/abs/2510.26784)
*Arnab Sen Sharma,Giordano Rogers,Natalie Shapira,David Bau*

Main category: cs.AI

TL;DR: LLMs学会了编码紧凑的过滤操作表示，类似于函数式编程中的filter函数，通过少量注意力头实现可移植的谓词表示。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在列表处理任务中的工作机制，探索其是否学习到了抽象的计算操作表示。

Method: 使用因果中介分析在多样化的列表处理任务上，识别出编码过滤谓词的注意力头（filter heads）。

Result: 发现LLMs开发了两种过滤策略：紧凑的谓词表示和急切评估策略，这些表示具有通用性和可移植性。

Conclusion: Transformer LMs能够发展出人类可解释的抽象计算操作实现，其泛化方式与传统函数式编程模式惊人相似。

Abstract: We investigate the mechanisms underlying a range of list-processing tasks in
LLMs, and we find that LLMs have learned to encode a compact, causal
representation of a general filtering operation that mirrors the generic
"filter" function of functional programming. Using causal mediation analysis on
a diverse set of list-processing tasks, we find that a small number of
attention heads, which we dub filter heads, encode a compact representation of
the filtering predicate in their query states at certain tokens. We demonstrate
that this predicate representation is general and portable: it can be extracted
and reapplied to execute the same filtering operation on different collections,
presented in different formats, languages, or even in tasks. However, we also
identify situations where transformer LMs can exploit a different strategy for
filtering: eagerly evaluating if an item satisfies the predicate and storing
this intermediate result as a flag directly in the item representations. Our
results reveal that transformer LMs can develop human-interpretable
implementations of abstract computational operations that generalize in ways
that are surprisingly similar to strategies used in traditional functional
programming patterns.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [54] [Coherence-Aware Distributed Learning under Heterogeneous Downlink Impairments](https://arxiv.org/abs/2510.25917)
*Mehdi Karbalayghareh,David J. Love,Christopher G. Brinton*

Main category: cs.IT

TL;DR: 提出了一种针对无线联邦学习的感知相干性通信效率框架，通过资源复用策略在异构衰落动态下联合进行信道训练和模型更新。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习方案忽视了设备间相干时间差异，导致通信效率低下和训练开销严重。实际中边缘设备由于移动性和散射环境不同，具有不相等的相干时间，对导频信号和信道估计资源需求不均。

Method: 基于乘积叠加的资源复用策略，允许参数服务器高效调度静态和动态设备，将静态设备的全局模型更新嵌入到移动设备的导频传输中。

Result: 理论分析了所提方案的收敛行为，量化了其在预期通信效率和训练准确性方面的增益。实验验证了该框架在移动性诱导动态下的有效性。

Conclusion: 该框架为无线信道上联邦学习的实际部署提供了有用见解，能够有效应对异构衰落动态下的通信挑战。

Abstract: The performance of federated learning (FL) over wireless networks critically
depends on accurate and timely channel state information (CSI) across
distributed devices. This requirement is tightly linked to how rapidly the
channel gains vary, i.e., the coherence intervals. In practice, edge devices
often exhibit unequal coherence times due to differences in mobility and
scattering environments, leading to unequal demands for pilot signaling and
channel estimation resources. Conventional FL schemes that overlook this
coherence disparity can suffer from severe communication inefficiencies and
training overhead. This paper proposes a coherence-aware,
communication-efficient framework for joint channel training and model updating
in practical wireless FL systems operating under heterogeneous fading dynamics.
Focusing on downlink impairments, we introduce a resource-reuse strategy based
on product superposition, enabling the parameter server to efficiently schedule
both static and dynamic devices by embedding global model updates for static
devices within pilot transmissions intended for mobile devices. We
theoretically analyze the convergence behavior of the proposed scheme and
quantify its gains in expected communication efficiency and training accuracy.
Experiments demonstrate the effectiveness of the proposed framework under
mobility-induced dynamics and offer useful insights for the practical
deployment of FL over wireless channels.

</details>


### [55] [Duality-Based Fixed Point Iteration Algorithm for Beamforming Design in ISAC Systems](https://arxiv.org/abs/2510.26147)
*Xilai Fan,Ya-Feng Liu*

Main category: cs.IT

TL;DR: 提出了一种基于对偶固定点迭代(Dual-FPI)的算法，用于解决集成感知与通信(ISAC)系统中的波束成形设计问题，在满足通信用户SINR约束和雷达感知MSE约束的同时最小化总发射功率。


<details>
  <summary>Details</summary>
Motivation: ISAC系统中通信和感知功能的耦合使得波束成形设计变得复杂，现有方法计算复杂度高，需要开发更高效的优化算法。

Method: 首先建立原始ISAC波束成形问题与其半定松弛(SDR)的等价性，推导拉格朗日对偶形式，将其重构为具有不定加权矩阵的广义下行波束成形(GDB)问题，然后提出对偶固定点迭代算法。

Result: 仿真结果表明，所提Dual-FPI算法能够获得全局最优解，同时相比现有基线方法显著降低了计算复杂度。

Conclusion: 该工作为ISAC系统中的波束成形设计提供了一种高效且理论保证的解决方案，成功解决了通信与感知性能权衡的挑战。

Abstract: In this paper, we investigate the beamforming design problem in an integrated
sensing and communication (ISAC) system, where a multi-antenna base station
simultaneously serves multiple communication users while performing radar
sensing. We formulate the problem as the minimization of the total transmit
power, subject to signal-to-interference-plus-noise ratio (SINR) constraints
for communication users and mean-squared-error (MSE) constraints for radar
sensing. The core challenge arises from the complex coupling between
communication SINR requirements and sensing performance metrics. To efficiently
address this challenge, we first establish the equivalence between the original
ISAC beamforming problem and its semidefinite relaxation (SDR), derive its
Lagrangian dual formulation, and further reformulate it as a generalized
downlink beamforming (GDB) problem with potentially indefinite weighting
matrices. Compared to the classical DB problem, the presence of indefinite
weighting matrices in the GDB problem introduces substantial analytical and
computational challenges. Our key technical contributions include (i) a
necessary and sufficient condition for the boundedness of the GDB problem, and
(ii) a tailored efficient fixed point iteration (FPI) algorithm with a provable
convergence guarantee for solving the GDB problem. Building upon these results,
we develop a duality-based fixed point iteration (Dual-FPI) algorithm, which
integrates an outer subgradient ascent loop with an inner FPI loop. Simulation
results demonstrate that the proposed Dual-FPI algorithm achieves globally
optimal solutions while significantly reducing computational complexity
compared with existing baseline approaches.

</details>


### [56] [Efficient Spectral Efficiency Maximization Design for IRS-aided MIMO Systems](https://arxiv.org/abs/2510.26279)
*Fuying Li,Yajun Wang,Zhuxian Lian,Wen Chen*

Main category: cs.IT

TL;DR: 提出ADMM-APG算法解决IRS辅助MIMO系统中的频谱效率最大化问题，该算法结合ADMM和APG方法，在计算复杂度和性能上优于现有基准方法。


<details>
  <summary>Details</summary>
Motivation: 无线通信对频谱效率的需求不断增长，智能反射表面(IRS)能够动态重构传播环境，但IRS辅助MIMO系统中的频谱效率最大化问题具有非凸性，计算挑战大。

Method: 提出ADMM-APG算法，结合交替方向乘子法(ADMM)和加速投影梯度(APG)方法，将原问题分解为可闭式求解的子问题，保持低计算复杂度。

Result: 仿真结果表明ADMM-APG算法在频谱效率和计算复杂度方面均优于现有基准方法，在各种系统配置下都能获得显著性能提升。

Conclusion: ADMM-APG算法为IRS辅助MIMO系统提供了一种计算高效且性能优越的解决方案，有效解决了频谱效率最大化这一非凸优化问题。

Abstract: Driven by the growing demand for higher spectral efficiency in wireless
communications, intelligent reflecting surfaces (IRS) have attracted
considerable attention for their ability to dynamically reconfigure the
propagation environment. This work addresses the spectral efficiency
maximization problem in IRS-assisted multiple-input multiple-output (MIMO)
systems, which involves the joint optimization of the transmit precoding matrix
and the IRS phase shift configuration. This problem is inherently challenging
due to its non-convex nature. To tackle it effectively, we introduce a
computationally efficient algorithm, termed ADMM-APG, which integrates the
alternating direction method of multipliers (ADMM) with the accelerated
projected gradient (APG) method. The proposed framework decomposes the original
problem into tractable subproblems, each admitting a closed-form solution while
maintaining low computational complexity. Simulation results demonstrate that
the ADMM-APG algorithm consistently surpasses existing benchmark methods in
terms of spectral efficiency and computational complexity, achieving
significant performance gains across a range of system configurations.

</details>


### [57] [Diffusion-Aided Bandwidth-Efficient Semantic Communication with Adaptive Requests](https://arxiv.org/abs/2510.26442)
*Xuesong Wang,Xinyan Xie,Mo Li,Zhaoqian Liu*

Main category: cs.IT

TL;DR: 提出基于扩散模型的语义通信框架，通过传输简洁文本描述和少量关键视觉特征，结合扩散修复模型重建图像，并采用自适应重传机制优化传输效率。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信方法存在两个问题：仅传输文本描述会丢失空间布局和细节信息；传输文本加密集视觉特征会产生语义冗余。需要减少冗余同时保持语义理解和视觉保真度。

Method: 传输简洁文本描述和少量关键潜在视觉特征，使用扩散修复模型重建图像。接收端通过语义一致性机制评估重建图像与文本描述的匹配度，检测到语义差异时触发重传请求额外特征块。

Result: 显著降低带宽使用，同时保持高语义准确性，在重建质量和传输开销之间实现高效平衡。

Conclusion: 该框架通过自适应重传机制有效解决了语义冗余问题，实现了语义通信的高效传输。

Abstract: Semantic communication focuses on conveying the intrinsic meaning of data
rather than its raw symbolic representation. For visual content, this paradigm
shifts from traditional pixel-level transmission toward leveraging the semantic
structure of images to communicate visual meaning. Existing approaches
generally follow one of two paths: transmitting only text descriptions, which
often fail to capture precise spatial layouts and fine-grained appearance
details; or transmitting text alongside dense latent visual features, which
tends to introduce substantial semantic redundancy. A key challenge, therefore,
is to reduce semantic redundancy while preserving semantic understanding and
visual fidelity, thereby improving overall transmission efficiency. This paper
introduces a diffusion-based semantic communication framework with adaptive
retransmission. The system transmits concise text descriptions together with a
limited set of key latent visual features, and employs a diffusion-based
inpainting model to reconstruct the image. A receiver-side semantic consistency
mechanism is designed to evaluate the alignment between the reconstructed image
and the original text description. When a semantic discrepancy is detected, the
receiver triggers a retransmission to request a small set of additional latent
blocks and refine the image reconstruction. This approach significantly reduces
bandwidth usage while preserving high semantic accuracy, achieving an efficient
balance between reconstruction quality and transmission overhead.

</details>


### [58] [PolarZero: A Reinforcement Learning Approach for Low-Complexity Polarization Kernel Design](https://arxiv.org/abs/2510.26452)
*Yi-Ting Hong,Stefano Rini,Luca Barletta*

Main category: cs.IT

TL;DR: 使用基于Gumbel AlphaZero算法的强化学习框架来设计大核极化码，在满足给定错误指数的同时最小化解码复杂度。对于16核大小，相比手工设计降低17%解码复杂度，错误指数达到0.5183（Arikan核为0.5）。


<details>
  <summary>Details</summary>
Motivation: 大核极化码可以提高错误指数，但设计低解码复杂度的核具有挑战性。传统手工设计方法难以在错误指数和解码复杂度之间找到最优平衡。

Method: 采用基于Gumbel AlphaZero算法的强化学习框架，在递归最大似然解码（RMLD）条件下进行核构造。该方法高效探索设计空间，识别满足给定错误指数要求的大尺寸核。

Result: 对于尺寸为16的核，该方法实现了比手工设计低17%的解码复杂度，同时达到0.5183的错误指数（相比Arikan核的0.5）。

Conclusion: 基于学习的方法在实用极化码构造中具有有效性，能够在保持良好错误性能的同时显著降低解码复杂度。

Abstract: Polar codes with large kernels can achieve improved error exponents but are
challenging to design with low decoding complexity. This work investigates
kernel construction under recursive maximum likelihood decoding (RMLD) using a
reinforcement learning framework based on the Gumbel AlphaZero algorithm. The
proposed method efficiently explores the design space and identifies large-size
kernels that satisfy a given error exponent while minimizing decoding
complexity. For a size-16 kernel, it achieves 17% lower decoding complexity
than handcrafted designs while reaching an error exponent of 0.5183 compared to
0.5 for Arikan's kernel, demonstrating the effectiveness of the learning-based
approach for practical polar code construction.

</details>


### [59] [Entropy Functions on Two-Dimensional Faces of Polymatroidal Region of Degree Four: Part II: Information Theoretic Constraints Breed New Combinatorial Structures](https://arxiv.org/abs/2510.26552)
*Shaocheng Liu,Qi Chen,Minquan Cheng*

Main category: cs.IT

TL;DR: 本文是系列论文的第二部分，旨在表征4变量多拟阵区域Γ₄的2维面上的熵函数。在第一部分已解决49种类型的基础上，本文处理剩余的10种类型，其中8种完全表征，2种部分表征。


<details>
  <summary>Details</summary>
Motivation: 熵函数的表征在信息论中具有基础重要性。通过在多拟阵区域（香农外边界）上施加约束，可以得到该区域的各个面及其上具有特殊结构的熵函数。

Method: 引入新的组合设计结构来表征剩余的10种2维面类型。通过算法枚举了Γ₄的所有59种2维面类型，并系统性地分析其上的熵函数。

Result: 成功完全表征了8种2维面类型上的熵函数，并对另外2种类型进行了部分表征。

Conclusion: 该研究为理解多拟阵区域的几何结构和熵函数的性质提供了重要进展，新引入的组合设计结构本身也具有独立的研究价值。

Abstract: Characterization of entropy functions is of fundamental importance in
information theory. By imposing constraints on their Shannon outer bound, i.e.,
the polymatroidal region, one obtains the faces of the region and entropy
functions on them with special structures. In this series of two papers, we
characterize entropy functions on the $2$-dimensional faces of the
polymatroidal region $\Gamma_4$. In Part I, we formulated the problem,
enumerated all $59$ types of $2$-dimensional faces of $\Gamma_4$ by a
algorithm, and fully characterized entropy functions on $49$ types of them. In
this paper, i.e., Part II, we will characterize entropy functions on the
remaining $10$ types of faces, among which $8$ types are fully characterized
and $2$ types are partially characterized. To characterize these types of
faces, we introduce some new combinatorial design structures which are
interesting themself.

</details>
