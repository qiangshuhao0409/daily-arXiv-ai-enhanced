{"id": "2511.14921", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.14921", "abs": "https://arxiv.org/abs/2511.14921", "authors": ["Mohamed Rouili", "Yang Xiao", "Sihang Liu", "Raouf Boutaba"], "title": "RAID: In-Network RA Signaling Storm Detection for 5G Open RAN", "comment": null, "summary": "The disaggregation and virtualization of 5G Open RAN (O-RAN) introduces new vulnerabilities in the control plane that can greatly impact the quality of service (QoS) of latency-sensitive 5G applications and services. One critical issue is Random Access (RA) signaling storms where, a burst of illegitimate or misbehaving user equipments (UEs) send Radio Resource Control (RRC) connection requests that rapidly saturate a Central Unit's (CU) processing pipeline. Such storms trigger widespread connection failures within the short contention resolution window defined by 3GPP. Existing detection and mitigation approaches based on near-real-time RAN Intelligent Controller (n-RT RIC) applications cannot guarantee a timely reaction to such attacks as RIC control loops incur tens to hundreds of milliseconds of latency due to the non-deterministic nature of their general purpose processor (GPP) based architectures. This paper presents RAID, an in-network RA signaling storm detection and mitigation system that leverages P4-programmable switch ASICs to enable real-time protection from malicious attacks. RAID embeds a lightweight Random Forest (RF) classifier into a programmable Tofino switch, enabling line-rate flow classification with deterministic microsecond-scale inference delay. By performing ML-based detection directly in the data plane, RAID catches and filters malicious RA requests before they reach and overwhelm the RRC. RAID achieves above 94% detection accuracy with a fixed per-flow inference delay on the order of 3.4 microseconds, effectively meeting strict O-RAN control-plane deadlines. These improvements are sustained across multiple traffic loads, making RAID a fast and scalable solution for the detection and mitigation of signaling storms in 5G O-RAN.", "AI": {"tldr": "RAID\u662f\u4e00\u4e2a\u57fa\u4e8eP4\u53ef\u7f16\u7a0b\u4ea4\u6362\u673a\u76845G O-RAN\u4fe1\u4ee4\u98ce\u66b4\u68c0\u6d4b\u4e0e\u7f13\u89e3\u7cfb\u7edf\uff0c\u901a\u8fc7\u5728\u6570\u636e\u5e73\u9762\u5d4c\u5165\u8f7b\u91cf\u7ea7\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\uff0c\u5b9e\u73b0\u5fae\u79d2\u7ea7\u5ef6\u8fdf\u7684\u5b9e\u65f6\u6076\u610fRA\u8bf7\u6c42\u8fc7\u6ee4\u3002", "motivation": "5G O-RAN\u7684\u5206\u89e3\u548c\u865a\u62df\u5316\u5f15\u5165\u4e86\u63a7\u5236\u5e73\u9762\u65b0\u6f0f\u6d1e\uff0c\u6076\u610fUE\u53d1\u8d77\u7684\u968f\u673a\u63a5\u5165\u4fe1\u4ee4\u98ce\u66b4\u4f1a\u5feb\u901f\u9971\u548c\u4e2d\u592e\u5355\u5143\u5904\u7406\u7ba1\u9053\uff0c\u5bfc\u81f4\u5927\u89c4\u6a21\u8fde\u63a5\u5931\u8d25\uff0c\u800c\u73b0\u6709\u57fa\u4e8en-RT RIC\u7684\u68c0\u6d4b\u65b9\u6cd5\u65e0\u6cd5\u53ca\u65f6\u54cd\u5e94\u3002", "method": "\u5728\u53ef\u7f16\u7a0bTofino\u4ea4\u6362\u673a\u4e2d\u5d4c\u5165\u8f7b\u91cf\u7ea7\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\uff0c\u5229\u7528P4\u53ef\u7f16\u7a0b\u4ea4\u6362ASIC\u5b9e\u73b0\u7ebf\u901f\u6d41\u5206\u7c7b\u548c\u786e\u5b9a\u6027\u5fae\u79d2\u7ea7\u63a8\u7406\u5ef6\u8fdf\uff0c\u76f4\u63a5\u5728\u6570\u636e\u5e73\u9762\u8fdb\u884cML\u68c0\u6d4b\u3002", "result": "RAID\u8fbe\u523094%\u4ee5\u4e0a\u7684\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u6bcf\u6d41\u63a8\u7406\u5ef6\u8fdf\u56fa\u5b9a\u4e3a3.4\u5fae\u79d2\uff0c\u80fd\u591f\u6ee1\u8db3\u4e25\u683c\u7684O-RAN\u63a7\u5236\u5e73\u9762\u65f6\u9650\u8981\u6c42\uff0c\u5e76\u5728\u591a\u79cd\u6d41\u91cf\u8d1f\u8f7d\u4e0b\u4fdd\u6301\u6027\u80fd\u3002", "conclusion": "RAID\u662f\u4e00\u4e2a\u5feb\u901f\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u548c\u7f13\u89e35G O-RAN\u4e2d\u7684\u4fe1\u4ee4\u98ce\u66b4\u653b\u51fb\u3002"}}
{"id": "2511.14849", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.14849", "abs": "https://arxiv.org/abs/2511.14849", "authors": ["Adeel Mahmood", "Aaron B. Wagner"], "title": "Channel Coding for Gaussian Channels with Multifaceted Power Constraints", "comment": null, "summary": "Motivated by refined asymptotic results based on the normal approximation, we study how higher-order coding performance depends on the mean power $\u0393$ as well as on finer statistics of the input power. We introduce a multifaceted power model in which the expectation of an arbitrary number of arbitrary functions of the normalized average power is constrained. The framework generalizes existing models, recovering the standard maximal and expected power constraints and the recent mean and variance constraint as special cases. Under certain growth and continuity assumptions on the functions, our main theorem gives an exact characterization of the minimum average error probability for Gaussian channels as a function of the first- and second-order coding rates. The converse proof reduces the code design problem to minimization over a compact (under the Prokhorov metric) set of probability distributions, characterizes the extreme points of this set and invokes the Bauer's maximization principle.", "AI": {"tldr": "\u57fa\u4e8e\u6b63\u6001\u8fd1\u4f3c\u7684\u6e10\u8fd1\u7ed3\u679c\uff0c\u7814\u7a76\u9ad8\u9636\u7f16\u7801\u6027\u80fd\u5982\u4f55\u4f9d\u8d56\u4e8e\u5e73\u5747\u529f\u7387\u0393\u548c\u8f93\u5165\u529f\u7387\u7684\u7cbe\u7ec6\u7edf\u8ba1\u7279\u6027\u3002\u63d0\u51fa\u4e86\u591a\u9762\u529f\u7387\u6a21\u578b\uff0c\u7ea6\u675f\u5f52\u4e00\u5316\u5e73\u5747\u529f\u7387\u4efb\u610f\u51fd\u6570\u7684\u671f\u671b\uff0c\u63a8\u5e7f\u4e86\u73b0\u6709\u6a21\u578b\u3002\u5728\u51fd\u6570\u589e\u957f\u548c\u8fde\u7eed\u6027\u5047\u8bbe\u4e0b\uff0c\u7ed9\u51fa\u4e86\u9ad8\u65af\u4fe1\u9053\u6700\u5c0f\u5e73\u5747\u9519\u8bef\u6982\u7387\u5173\u4e8e\u4e00\u9636\u548c\u4e8c\u9636\u7f16\u7801\u7387\u7684\u7cbe\u786e\u8868\u5f81\u3002", "motivation": "\u53d7\u57fa\u4e8e\u6b63\u6001\u8fd1\u4f3c\u7684\u7cbe\u5316\u6e10\u8fd1\u7ed3\u679c\u542f\u53d1\uff0c\u7814\u7a76\u9ad8\u9636\u7f16\u7801\u6027\u80fd\u5bf9\u5e73\u5747\u529f\u7387\u0393\u548c\u8f93\u5165\u529f\u7387\u66f4\u7cbe\u7ec6\u7edf\u8ba1\u7279\u6027\u7684\u4f9d\u8d56\u6027\u3002", "method": "\u5f15\u5165\u591a\u9762\u529f\u7387\u6a21\u578b\uff0c\u7ea6\u675f\u5f52\u4e00\u5316\u5e73\u5747\u529f\u7387\u4efb\u610f\u51fd\u6570\u7684\u671f\u671b\uff1b\u5c06\u7801\u8bbe\u8ba1\u95ee\u9898\u8f6c\u5316\u4e3a\u5728\u6982\u7387\u5206\u5e03\u7d27\u96c6\u4e0a\u7684\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u523b\u753b\u8be5\u96c6\u5408\u7684\u6781\u503c\u70b9\u5e76\u5e94\u7528Bauer\u6700\u5927\u5316\u539f\u7406\u3002", "result": "\u5728\u51fd\u6570\u589e\u957f\u548c\u8fde\u7eed\u6027\u5047\u8bbe\u4e0b\uff0c\u7ed9\u51fa\u4e86\u9ad8\u65af\u4fe1\u9053\u6700\u5c0f\u5e73\u5747\u9519\u8bef\u6982\u7387\u5173\u4e8e\u4e00\u9636\u548c\u4e8c\u9636\u7f16\u7801\u7387\u7684\u7cbe\u786e\u8868\u5f81\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u9762\u529f\u7387\u6a21\u578b\u63a8\u5e7f\u4e86\u73b0\u6709\u529f\u7387\u7ea6\u675f\u6a21\u578b\uff0c\u4e3a\u9ad8\u65af\u4fe1\u9053\u7684\u9ad8\u9636\u7f16\u7801\u6027\u80fd\u5206\u6790\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2511.14777", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14777", "abs": "https://arxiv.org/abs/2511.14777", "authors": ["Mahdi Samiei", "Mahdi Mansouri", "Mahdieh Soleymani Baghshah"], "title": "The Illusion of Procedural Reasoning: Measuring Long-Horizon FSM Execution in LLMs", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable results on tasks framed as reasoning problems, yet their true ability to perform procedural reasoning, executing multi-step, rule-based computations remains unclear. Unlike algorithmic systems, which can deterministically execute long-horizon symbolic procedures, LLMs often degrade under extended reasoning chains, but there is no controlled, interpretable benchmark to isolate and measure this collapse. We introduce Finite-State Machine (FSM) Execution as a minimal, fully interpretable framework for evaluating the procedural reasoning capacity of LLMs. In our setup, the model is given an explicit FSM definition and must execute it step-by-step given input actions, maintaining state consistency over multiple turns. This task requires no world knowledge, only faithful application of deterministic transition rules, making it a direct probe of the model's internal procedural fidelity. We measure both Turn Accuracy and Task Accuracy to disentangle immediate computation from cumulative state maintenance. Empirical results reveal systematic degradation as task horizon or branching complexity increases. Models perform significantly worse when rule retrieval involves high branching factors than when memory span is long. Larger models show improved local accuracy but remain brittle under multi-step reasoning unless explicitly prompted to externalize intermediate steps. FSM-based evaluation offers a transparent, complexity-controlled probe for diagnosing this failure mode and guiding the design of inductive biases that enable genuine long-horizon procedural competence. By grounding reasoning in measurable execution fidelity rather than surface correctness, this work helps establish a rigorous experimental foundation for understanding and improving the algorithmic reliability of LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u6709\u9650\u72b6\u6001\u673a\uff08FSM\uff09\u6267\u884c\u4f5c\u4e3a\u8bc4\u4f30LLMs\u7a0b\u5e8f\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u53d1\u73b0\u968f\u7740\u4efb\u52a1\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u6a21\u578b\u6027\u80fd\u7cfb\u7edf\u6027\u4e0b\u964d\uff0c\u7279\u522b\u662f\u5728\u9ad8\u5206\u652f\u590d\u6742\u5ea6\u548c\u591a\u6b65\u63a8\u7406\u573a\u666f\u4e0b\u8868\u73b0\u8106\u5f31\u3002", "motivation": "\u73b0\u6709LLMs\u5728\u5f62\u5f0f\u5316\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u6267\u884c\u591a\u6b65\u9aa4\u3001\u57fa\u4e8e\u89c4\u5219\u7684\u7a0b\u5e8f\u63a8\u7406\u80fd\u529b\u5c1a\u4e0d\u660e\u786e\uff0c\u7f3a\u4e4f\u53ef\u63a7\u3001\u53ef\u89e3\u91ca\u7684\u57fa\u51c6\u6765\u9694\u79bb\u548c\u6d4b\u91cf\u8fd9\u79cd\u80fd\u529b\u8870\u9000\u3002", "method": "\u8bbe\u8ba1FSM\u6267\u884c\u4efb\u52a1\uff0c\u7ed9\u6a21\u578b\u660e\u786e\u7684FSM\u5b9a\u4e49\uff0c\u8981\u6c42\u5176\u6839\u636e\u8f93\u5165\u52a8\u4f5c\u9010\u6b65\u6267\u884c\uff0c\u5728\u591a\u8f6e\u4e2d\u4fdd\u6301\u72b6\u6001\u4e00\u81f4\u6027\u3002\u4efb\u52a1\u65e0\u9700\u4e16\u754c\u77e5\u8bc6\uff0c\u53ea\u9700\u5fe0\u5b9e\u5e94\u7528\u786e\u5b9a\u6027\u8f6c\u6362\u89c4\u5219\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a1\uff09\u4efb\u52a1\u957f\u5ea6\u6216\u5206\u652f\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u6027\u80fd\u7cfb\u7edf\u6027\u4e0b\u964d\uff1b2\uff09\u89c4\u5219\u68c0\u7d22\u6d89\u53ca\u9ad8\u5206\u652f\u56e0\u5b50\u65f6\u8868\u73b0\u663e\u8457\u66f4\u5dee\uff1b3\uff09\u5927\u6a21\u578b\u5c40\u90e8\u51c6\u786e\u6027\u63d0\u9ad8\u4f46\u5728\u591a\u6b65\u63a8\u7406\u4e2d\u4ecd\u8106\u5f31\uff0c\u9664\u975e\u660e\u786e\u63d0\u793a\u5916\u90e8\u5316\u4e2d\u95f4\u6b65\u9aa4\u3002", "conclusion": "FSM\u8bc4\u4f30\u4e3a\u8bca\u65adLLMs\u7a0b\u5e8f\u63a8\u7406\u5931\u8d25\u6a21\u5f0f\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u590d\u6742\u5ea6\u53ef\u63a7\u7684\u63a2\u9488\uff0c\u6709\u52a9\u4e8e\u5efa\u7acb\u7406\u89e3\u548c\u6539\u8fdbLLMs\u7b97\u6cd5\u53ef\u9760\u6027\u7684\u4e25\u8c28\u5b9e\u9a8c\u57fa\u7840\u3002"}}
{"id": "2511.14906", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.14906", "abs": "https://arxiv.org/abs/2511.14906", "authors": ["Yasser Al Eryani"], "title": "Beyond the \"G\" Frontier: A Time Traveler's Century-Long Vision for Wireless Intelligence", "comment": null, "summary": "This article travels one century into the future--from 2025 to 2125--through the analytical lens of the Information--Curvature Efficiency Law (ICEL). It contends that wireless evolution will not proceed through incremental generations such as 6G or 7G, but through a curvature-managed integration of electromagnetics, biology, thermodynamics, and cognition. The resulting infrastructure will constitute a global ecology of self-aware information flow, where geometry and communication converge to sustain both technological and biological life.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4fe1\u606f-\u66f2\u7387\u6548\u7387\u5b9a\u5f8b\u5206\u6790\uff0c\u9884\u6d4b2125\u5e74\u7684\u65e0\u7ebf\u901a\u4fe1\u5c06\u4e0d\u662f\u901a\u8fc76G\u62167G\u7b49\u6e10\u8fdb\u5f0f\u53d1\u5c55\uff0c\u800c\u662f\u901a\u8fc7\u7535\u78c1\u5b66\u3001\u751f\u7269\u5b66\u3001\u70ed\u529b\u5b66\u548c\u8ba4\u77e5\u7684\u66f2\u7387\u7ba1\u7406\u96c6\u6210\uff0c\u5f62\u6210\u5177\u6709\u81ea\u6211\u610f\u8bc6\u4fe1\u606f\u6d41\u7684\u5168\u7403\u751f\u6001\u57fa\u7840\u8bbe\u65bd\u3002", "motivation": "\u63a2\u7d22\u672a\u6765100\u5e74\u65e0\u7ebf\u901a\u4fe1\u7684\u53d1\u5c55\u65b9\u5411\uff0c\u6311\u6218\u4f20\u7edf\u6e10\u8fdb\u5f0f\u4ee3\u9645\u6f14\u8fdb\u6a21\u5f0f\uff0c\u63d0\u51fa\u57fa\u4e8e\u591a\u5b66\u79d1\u878d\u5408\u7684\u65b0\u8303\u5f0f\u3002", "method": "\u5e94\u7528\u4fe1\u606f-\u66f2\u7387\u6548\u7387\u5b9a\u5f8b(ICEL)\u4f5c\u4e3a\u5206\u6790\u6846\u67b6\uff0c\u4ece2025\u5e74\u52302125\u5e74\u8fdb\u884c\u767e\u5e74\u9884\u6d4b\u5206\u6790\u3002", "result": "\u9884\u6d4b\u65e0\u7ebf\u901a\u4fe1\u5c06\u6f14\u53d8\u4e3a\u51e0\u4f55\u4e0e\u901a\u4fe1\u878d\u5408\u7684\u5168\u7403\u751f\u6001\u57fa\u7840\u8bbe\u65bd\uff0c\u80fd\u591f\u7ef4\u6301\u6280\u672f\u548c\u751f\u7269\u751f\u547d\u7684\u4fe1\u606f\u6d41\u52a8\u3002", "conclusion": "\u65e0\u7ebf\u901a\u4fe1\u7684\u672a\u6765\u53d1\u5c55\u5c06\u7a81\u7834\u4f20\u7edf\u4ee3\u9645\u6982\u5ff5\uff0c\u901a\u8fc7\u591a\u5b66\u79d1\u66f2\u7387\u7ba1\u7406\u96c6\u6210\uff0c\u5f62\u6210\u5177\u6709\u81ea\u6211\u610f\u8bc6\u7684\u4fe1\u606f\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2511.14778", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14778", "abs": "https://arxiv.org/abs/2511.14778", "authors": ["George Tsoukalas", "Rahul Saha", "Amitayush Thakur", "Sabrina Reguyal", "Swarat Chaudhuri"], "title": "Learning Interestingness in Automated Mathematical Theory Formation", "comment": "NeurIPS 2025 Spotlight", "summary": "We take two key steps in automating the open-ended discovery of new mathematical theories, a grand challenge in artificial intelligence. First, we introduce $\\emph{FERMAT}$, a reinforcement learning (RL) environment that models concept discovery and theorem-proving using a set of symbolic actions, opening up a range of RL problems relevant to theory discovery. Second, we explore a specific problem through $\\emph{FERMAT}$: automatically scoring the $\\emph{interestingness}$ of mathematical objects. We investigate evolutionary algorithms for synthesizing nontrivial interestingness measures. In particular, we introduce an LLM-based evolutionary algorithm that features function abstraction, leading to notable improvements in discovering elementary number theory and finite fields over hard-coded baselines. We open-source the $\\emph{FERMAT}$ environment at this URL(https://github.com/trishullab/Fermat).", "AI": {"tldr": "FERMAT\u662f\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u73af\u5883\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u6570\u5b66\u7406\u8bba\u53d1\u73b0\uff0c\u901a\u8fc7\u8fdb\u5316\u7b97\u6cd5\u548cLLM\u5408\u6210\u6570\u5b66\u5bf9\u8c61\u7684\u6709\u8da3\u6027\u5ea6\u91cf\uff0c\u5728\u521d\u7b49\u6570\u8bba\u548c\u6709\u9650\u57df\u9886\u57df\u4f18\u4e8e\u786c\u7f16\u7801\u57fa\u7ebf\u3002", "motivation": "\u89e3\u51b3\u4eba\u5de5\u667a\u80fd\u4e2d\u5f00\u653e\u5f0f\u7684\u6570\u5b66\u7406\u8bba\u81ea\u52a8\u53d1\u73b0\u8fd9\u4e00\u91cd\u5927\u6311\u6218\uff0c\u7279\u522b\u662f\u81ea\u52a8\u8bc4\u4f30\u6570\u5b66\u5bf9\u8c61\u7684\u8da3\u5473\u6027\u3002", "method": "\u5f15\u5165FERMAT\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u5efa\u6a21\u6982\u5ff5\u53d1\u73b0\u548c\u5b9a\u7406\u8bc1\u660e\uff1b\u4f7f\u7528\u57fa\u4e8eLLM\u7684\u8fdb\u5316\u7b97\u6cd5\u5408\u6210\u6709\u8da3\u6027\u5ea6\u91cf\uff0c\u5305\u542b\u51fd\u6570\u62bd\u8c61\u673a\u5236\u3002", "result": "\u5728\u521d\u7b49\u6570\u8bba\u548c\u6709\u9650\u57df\u9886\u57df\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u786c\u7f16\u7801\u57fa\u7ebf\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "FERMAT\u73af\u5883\u4e3a\u7406\u8bba\u53d1\u73b0\u5f00\u8f9f\u4e86\u65b0\u7684RL\u95ee\u9898\u7a7a\u95f4\uff0c\u57fa\u4e8eLLM\u7684\u8fdb\u5316\u7b97\u6cd5\u80fd\u6709\u6548\u53d1\u73b0\u6570\u5b66\u5bf9\u8c61\u7684\u8da3\u5473\u6027\u5ea6\u91cf\u3002"}}
{"id": "2511.15041", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.15041", "abs": "https://arxiv.org/abs/2511.15041", "authors": ["Jingchen Peng", "Chaowen Deng", "Yili Deng", "Boxiang Ren", "Lu Yang"], "title": "Hyper-VIB: A Hypernetwork-Enhanced Information Bottleneck Approach for Task-Oriented Communications", "comment": null, "summary": "This paper presents Hyper-VIB, a hypernetwork-enhanced information bottleneck (IB) approach designed to enable efficient task-oriented communications in 6G collaborative intelligent systems. Leveraging IB theory, our approach enables an optimal end-to-end joint training of device and network models, in terms of the maximal task execution accuracy as well as the minimal communication overhead, through optimizing the trade-off hyperparameter. To address computational intractability in high-dimensional IB optimization, a tractable variational upper-bound approximation is derived. Unlike conventional grid or random search methods that require multiple training rounds with substantial computational costs, Hyper-VIB introduces a hypernetwork that generates approximately optimal DNN parameters for different values of the hyperparameter within a single training phase. Theoretical analysis in the linear case validates the hypernetwork design. Experimental results demonstrate our Hyper-VIB's superior accuracy and training efficiency over conventional VIB approaches in both classification and regression tasks.", "AI": {"tldr": "Hyper-VIB\u662f\u4e00\u79cd\u57fa\u4e8e\u8d85\u7f51\u7edc\u589e\u5f3a\u4fe1\u606f\u74f6\u9888\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e6G\u534f\u4f5c\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u9ad8\u6548\u4efb\u52a1\u5bfc\u5411\u901a\u4fe1\uff0c\u901a\u8fc7\u5355\u6b21\u8bad\u7ec3\u751f\u6210\u8fd1\u4f3c\u6700\u4f18\u7684DNN\u53c2\u6570\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b36G\u534f\u4f5c\u667a\u80fd\u7cfb\u7edf\u4e2d\u4efb\u52a1\u5bfc\u5411\u901a\u4fe1\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u5e73\u8861\u95ee\u9898\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u591a\u6b21\u8bad\u7ec3\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u7ed3\u5408\u4fe1\u606f\u74f6\u9888\u7406\u8bba\u548c\u8d85\u7f51\u7edc\uff0c\u63a8\u5bfc\u53d8\u5206\u4e0a\u754c\u8fd1\u4f3c\u89e3\u51b3\u9ad8\u7ef4\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u8d85\u7f51\u7edc\u5728\u5355\u6b21\u8bad\u7ec3\u4e2d\u4e3a\u4e0d\u540c\u8d85\u53c2\u6570\u503c\u751f\u6210\u8fd1\u4f3c\u6700\u4f18\u7684DNN\u53c2\u6570\u3002", "result": "\u5728\u7ebf\u6027\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u8d85\u7f51\u7edc\u8bbe\u8ba1\u7684\u6709\u6548\u6027\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u4e2d\u4f18\u4e8e\u4f20\u7edfVIB\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u8bad\u7ec3\u6548\u7387\u3002", "conclusion": "Hyper-VIB\u65b9\u6cd5\u57286G\u534f\u4f5c\u667a\u80fd\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u4efb\u52a1\u5bfc\u5411\u901a\u4fe1\uff0c\u901a\u8fc7\u5355\u6b21\u8bad\u7ec3\u5373\u53ef\u83b7\u5f97\u8fd1\u4f3c\u6700\u4f18\u89e3\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2511.14780", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14780", "abs": "https://arxiv.org/abs/2511.14780", "authors": ["Keith Moore", "Jun W. Kim", "David Lyu", "Jeffrey Heo", "Ehsan Adeli"], "title": "Ask WhAI:Probing Belief Formation in Role-Primed LLM Agents", "comment": "Preprint. Accepted for publication at AIAS 2025", "summary": "We present Ask WhAI, a systems-level framework for inspecting and perturbing belief states in multi-agent interactions. The framework records and replays agent interactions, supports out-of-band queries into each agent's beliefs and rationale, and enables counterfactual evidence injection to test how belief structures respond to new information. We apply the framework to a medical case simulator notable for its multi-agent shared memory (a time-stamped electronic medical record, or EMR) and an oracle agent (the LabAgent) that holds ground truth lab results revealed only when explicitly queried. We stress-test the system on a multi-specialty diagnostic journey for a child with an abrupt-onset neuropsychiatric presentation. Large language model agents, each primed with strong role-specific priors (\"act like a neurologist\", \"act like an infectious disease specialist\"), write to a shared medical record and interact with a moderator across sequential or parallel encounters. Breakpoints at key diagnostic moments enable pre- and post-event belief queries, allowing us to distinguish entrenched priors from reasoning or evidence-integration effects. The simulation reveals that agent beliefs often mirror real-world disciplinary stances, including overreliance on canonical studies and resistance to counterevidence, and that these beliefs can be traced and interrogated in ways not possible with human experts. By making such dynamics visible and testable, Ask WhAI offers a reproducible way to study belief formation and epistemic silos in multi-agent scientific reasoning.", "AI": {"tldr": "Ask WhAI\u662f\u4e00\u4e2a\u7528\u4e8e\u68c0\u67e5\u548c\u6270\u52a8\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u4e2d\u4fe1\u5ff5\u72b6\u6001\u7684\u7cfb\u7edf\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u8bb0\u5f55\u91cd\u653e\u4ea4\u4e92\u3001\u67e5\u8be2\u4fe1\u5ff5\u548c\u6ce8\u5165\u53cd\u4e8b\u5b9e\u8bc1\u636e\u6765\u6d4b\u8bd5\u4fe1\u5ff5\u7ed3\u6784\u5bf9\u65b0\u4fe1\u606f\u7684\u54cd\u5e94\u3002", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u79d1\u5b66\u63a8\u7406\u4e2d\u7684\u4fe1\u5ff5\u5f62\u6210\u548c\u8ba4\u77e5\u5b64\u5c9b\u73b0\u8c61\uff0c\u63d0\u4f9b\u53ef\u91cd\u73b0\u7684\u65b9\u6cd5\u6765\u5206\u6790\u667a\u80fd\u4f53\u4fe1\u5ff5\u52a8\u6001\u3002", "method": "\u5f00\u53d1Ask WhAI\u6846\u67b6\uff0c\u5305\u542b\u8bb0\u5f55\u91cd\u653e\u4ea4\u4e92\u3001\u5e26\u5916\u67e5\u8be2\u4fe1\u5ff5\u548c\u53cd\u4e8b\u5b9e\u8bc1\u636e\u6ce8\u5165\u529f\u80fd\uff0c\u5e94\u7528\u4e8e\u5177\u6709\u591a\u667a\u80fd\u4f53\u5171\u4eab\u5185\u5b58\u548c\u9884\u8a00\u667a\u80fd\u4f53\u7684\u533b\u7597\u6848\u4f8b\u6a21\u62df\u5668\u3002", "result": "\u6a21\u62df\u663e\u793a\u667a\u80fd\u4f53\u4fe1\u5ff5\u5e38\u53cd\u6620\u73b0\u5b9e\u4e16\u754c\u5b66\u79d1\u7acb\u573a\uff0c\u5305\u62ec\u8fc7\u5ea6\u4f9d\u8d56\u7ecf\u5178\u7814\u7a76\u548c\u62b5\u5236\u53cd\u8bc1\u636e\uff0c\u8fd9\u4e9b\u4fe1\u5ff5\u53ef\u4ee5\u4ee5\u4eba\u7c7b\u4e13\u5bb6\u65e0\u6cd5\u5b9e\u73b0\u7684\u65b9\u5f0f\u8fdb\u884c\u8ffd\u8e2a\u548c\u8be2\u95ee\u3002", "conclusion": "Ask WhAI\u901a\u8fc7\u4f7f\u4fe1\u5ff5\u52a8\u6001\u53ef\u89c1\u548c\u53ef\u6d4b\u8bd5\uff0c\u4e3a\u7814\u7a76\u591a\u667a\u80fd\u4f53\u79d1\u5b66\u63a8\u7406\u4e2d\u7684\u4fe1\u5ff5\u5f62\u6210\u548c\u8ba4\u77e5\u5b64\u5c9b\u63d0\u4f9b\u4e86\u53ef\u91cd\u73b0\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.15051", "categories": ["cs.IT", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.15051", "abs": "https://arxiv.org/abs/2511.15051", "authors": ["Pengcheng Su", "Haibo Cheng", "Ping Wang"], "title": "Mutual Information Bounds in the Shuffle Model", "comment": null, "summary": "The shuffle model enhances privacy by anonymizing users' reports through random permutation. This paper presents the first systematic study of the single-message shuffle model from an information-theoretic perspective. We analyze two regimes: the shuffle-only setting, where each user directly submits its message ($Y_i=X_i$), and the shuffle-DP setting, where each user first applies a local $\\varepsilon_0$-differentially private mechanism before shuffling ($Y_i=\\mathcal{R}(X_i)$). Let $\\boldsymbol{Z} = (Y_{\u03c3(i)})_i$ denote the shuffled sequence produced by a uniformly random permutation $\u03c3$, and let $K = \u03c3^{-1}(1)$ represent the position of user 1's message after shuffling.\n  For the shuffle-only setting, we focus on a tractable yet expressive \\emph{basic configuration}, where the target user's message follows $Y_1 \\sim P$ and the remaining users' messages are i.i.d.\\ samples from $Q$, i.e., $Y_2,\\dots,Y_n \\sim Q$. We derive asymptotic expressions for the mutual information quantities $I(Y_1;\\boldsymbol{Z})$ and $I(K;\\boldsymbol{Z})$ as $n \\to \\infty$, and demonstrate how this analytical framework naturally extends to settings with heterogeneous user distributions.\n  For the shuffle-DP setting, we establish information-theoretic upper bounds on total information leakage. When each user applies an $\\varepsilon_0$-DP mechanism, the overall leakage satisfies $I(K; \\boldsymbol{Z}) \\le 2\\varepsilon_0$ and $I(X_1; \\boldsymbol{Z}\\mid (X_i)_{i=2}^n) \\le (e^{\\varepsilon_0}-1)/(2n) + O(n^{-3/2})$. These results bridge shuffle differential privacy and mutual-information-based privacy.", "AI": {"tldr": "\u672c\u6587\u4ece\u4fe1\u606f\u8bba\u89d2\u5ea6\u7cfb\u7edf\u7814\u7a76\u4e86\u5355\u6d88\u606f\u6df7\u6d17\u6a21\u578b\uff0c\u5206\u6790\u4e86\u6df7\u6d17\u4e13\u7528\u548c\u6df7\u6d17\u5dee\u5206\u9690\u79c1\u4e24\u79cd\u8bbe\u7f6e\uff0c\u63a8\u5bfc\u4e86\u4e92\u4fe1\u606f\u91cf\u7684\u6e10\u8fd1\u8868\u8fbe\u5f0f\u548c\u9690\u79c1\u6cc4\u9732\u4e0a\u754c\u3002", "motivation": "\u6df7\u6d17\u6a21\u578b\u901a\u8fc7\u968f\u673a\u6392\u5217\u533f\u540d\u5316\u7528\u6237\u62a5\u544a\u6765\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4\uff0c\u4f46\u7f3a\u4e4f\u4ece\u4fe1\u606f\u8bba\u89d2\u5ea6\u7684\u7cfb\u7edf\u5206\u6790\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u6df7\u6d17\u9690\u79c1\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u7814\u7a76\u4e24\u79cd\u8bbe\u7f6e\uff1a1) \u6df7\u6d17\u4e13\u7528\u8bbe\u7f6e\uff0c\u7528\u6237\u76f4\u63a5\u63d0\u4ea4\u6d88\u606f\uff1b2) \u6df7\u6d17-DP\u8bbe\u7f6e\uff0c\u7528\u6237\u5148\u5e94\u7528\u672c\u5730\u5dee\u5206\u9690\u79c1\u673a\u5236\u518d\u6df7\u6d17\u3002\u4f7f\u7528\u4e92\u4fe1\u606f\u5206\u6790\u9690\u79c1\u6cc4\u9732\uff0c\u63a8\u5bfc\u6e10\u8fd1\u8868\u8fbe\u5f0f\u548c\u4e0a\u754c\u3002", "result": "\u5728\u6df7\u6d17\u4e13\u7528\u8bbe\u7f6e\u4e2d\uff0c\u63a8\u5bfc\u4e86I(Y\u2081;Z)\u548cI(K;Z)\u7684\u6e10\u8fd1\u8868\u8fbe\u5f0f\uff1b\u5728\u6df7\u6d17-DP\u8bbe\u7f6e\u4e2d\uff0c\u5efa\u7acb\u4e86\u4fe1\u606f\u6cc4\u9732\u4e0a\u754c\uff1aI(K;Z) \u2264 2\u03b5\u2080\uff0cI(X\u2081;Z|(X\u1d62)\u1d62\u208c\u2082\u207f) \u2264 (e^{\u03b5\u2080}-1)/(2n) + O(n^{-3/2})\u3002", "conclusion": "\u672c\u6587\u5efa\u7acb\u4e86\u6df7\u6d17\u5dee\u5206\u9690\u79c1\u4e0e\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u9690\u79c1\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u4e3a\u6df7\u6d17\u6a21\u578b\u63d0\u4f9b\u4e86\u4fe1\u606f\u8bba\u7406\u8bba\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u6df7\u6d17\u80fd\u6709\u6548\u9650\u5236\u9690\u79c1\u6cc4\u9732\u3002"}}
{"id": "2511.14788", "categories": ["cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.14788", "abs": "https://arxiv.org/abs/2511.14788", "authors": ["Michele Ronco", "Damien Delforge", "Wiebke S. J\u00e4ger", "Christina Corbane"], "title": "Subnational Geocoding of Global Disasters Using Large Language Models", "comment": null, "summary": "Subnational location data of disaster events are critical for risk assessment and disaster risk reduction. Disaster databases such as EM-DAT often report locations in unstructured textual form, with inconsistent granularity or spelling, that make it difficult to integrate with spatial datasets. We present a fully automated LLM-assisted workflow that processes and cleans textual location information using GPT-4o, and assigns geometries by cross-checking three independent geoinformation repositories: GADM, OpenStreetMap and Wikidata. Based on the agreement and availability of these sources, we assign a reliability score to each location while generating subnational geometries. Applied to the EM-DAT dataset from 2000 to 2024, the workflow geocodes 14,215 events across 17,948 unique locations. Unlike previous methods, our approach requires no manual intervention, covers all disaster types, enables cross-verification across multiple sources, and allows flexible remapping to preferred frameworks. Beyond the dataset, we demonstrate the potential of LLMs to extract and structure geographic information from unstructured text, offering a scalable and reliable method for related analyses.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u81ea\u52a8\u5316\u7684LLM\u8f85\u52a9\u5de5\u4f5c\u6d41\uff0c\u4f7f\u7528GPT-4o\u5904\u7406\u6587\u672c\u4f4d\u7f6e\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u4ea4\u53c9\u9a8c\u8bc1\u4e09\u4e2a\u5730\u7406\u4fe1\u606f\u5e93\u6765\u5206\u914d\u51e0\u4f55\u5f62\u72b6\u548c\u53ef\u9760\u6027\u8bc4\u5206\u3002", "motivation": "\u707e\u5bb3\u6570\u636e\u5e93\u4e2d\u7684\u4f4d\u7f6e\u6570\u636e\u901a\u5e38\u4ee5\u975e\u7ed3\u6784\u5316\u6587\u672c\u5f62\u5f0f\u62a5\u544a\uff0c\u5b58\u5728\u7c92\u5ea6\u4e0d\u4e00\u81f4\u548c\u62fc\u5199\u5dee\u5f02\uff0c\u96be\u4ee5\u4e0e\u7a7a\u95f4\u6570\u636e\u96c6\u96c6\u6210\u3002", "method": "\u4f7f\u7528GPT-4o\u6e05\u7406\u6587\u672c\u4f4d\u7f6e\u4fe1\u606f\uff0c\u901a\u8fc7\u4ea4\u53c9\u9a8c\u8bc1GADM\u3001OpenStreetMap\u548cWikidata\u4e09\u4e2a\u72ec\u7acb\u7684\u5730\u7406\u4fe1\u606f\u5e93\u6765\u5206\u914d\u51e0\u4f55\u5f62\u72b6\uff0c\u5e76\u6839\u636e\u6765\u6e90\u4e00\u81f4\u6027\u5206\u914d\u53ef\u9760\u6027\u8bc4\u5206\u3002", "result": "\u5e94\u7528\u4e8e2000-2024\u5e74\u7684EM-DAT\u6570\u636e\u96c6\uff0c\u6210\u529f\u5730\u7406\u7f16\u7801\u4e8614,215\u4e2a\u4e8b\u4ef6\uff0c\u8986\u76d617,948\u4e2a\u72ec\u7279\u4f4d\u7f6e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u4eba\u5de5\u5e72\u9884\uff0c\u8986\u76d6\u6240\u6709\u707e\u5bb3\u7c7b\u578b\uff0c\u652f\u6301\u8de8\u6e90\u9a8c\u8bc1\uff0c\u5e76\u5c55\u793a\u4e86LLM\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u63d0\u53d6\u548c\u7ed3\u6784\u5316\u5730\u7406\u4fe1\u606f\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.15207", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.15207", "abs": "https://arxiv.org/abs/2511.15207", "authors": ["Chaofeng Guan", "Gaojun Luo", "Lan Luo", "Yangyang Fei", "Hong Wang"], "title": "Generalized Repetition Codes and Their Application to HARQ", "comment": "15 pages, 5 figures", "summary": "The inherent uncertainty of communication channels implies that any coding scheme has a non-zero probability of failing to correct errors, making retransmission mechanisms essential. To ensure message reliability and integrity, a dual-layer redundancy framework is typically employed: error correction codes mitigate noise-induced impairments at the physical layer, while cyclic redundancy checks verify message integrity after decoding. Retransmission is initiated if verification fails. This operational model can be categorized into two types of repeated communication models: Type-I systems repeatedly transmit identical codewords, whereas Type-II systems transmit distinct coded representations of the same message. The core challenge lies in maximizing the probability of correct message decoding within a limited number of transmission rounds through verification-based feedback mechanisms.\n  In this paper, we consider a scenario where the same error-correcting code is used for repeated transmissions, and we specifically propose two classes of generalized repetition codes (GRCs), corresponding to the two repeated communication models. In contrast to classical theory, we regard GRCs as error-correcting codes under multiple metrics--that is, GRCs possess multiple minimum distances. This design enables GRCs to perform multi-round error correction under different metrics, achieving stronger error-correction capabilities than classical error-correcting codes. However, the special structure of GRCs makes their construction more challenging, as it requires simultaneously optimizing multiple minimum distances. To address this, we separately investigate the bounds and constructions for Type-I and Type-II GRCs, and obtain numerous optimal Type-I and Type-II GRCs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u7c7b\u5e7f\u4e49\u91cd\u590d\u7801\uff08GRC\uff09\uff0c\u5206\u522b\u5bf9\u5e94\u4e24\u79cd\u91cd\u590d\u901a\u4fe1\u6a21\u578b\u3002\u4e0e\u4f20\u7edf\u7406\u8bba\u4e0d\u540c\uff0c\u5c06GRC\u89c6\u4e3a\u591a\u5ea6\u91cf\u4e0b\u7684\u7ea0\u9519\u7801\uff0c\u901a\u8fc7\u591a\u8f6e\u7ea0\u9519\u5b9e\u73b0\u66f4\u5f3a\u7684\u7ea0\u9519\u80fd\u529b\u3002", "motivation": "\u901a\u4fe1\u4fe1\u9053\u7684\u4e0d\u786e\u5b9a\u6027\u8981\u6c42\u91cd\u4f20\u673a\u5236\u786e\u4fdd\u6d88\u606f\u53ef\u9760\u6027\u3002\u73b0\u6709\u7cfb\u7edf\u5206\u4e3a\u4e24\u7c7b\uff1aType-I\u91cd\u590d\u4f20\u8f93\u76f8\u540c\u7801\u5b57\uff0cType-II\u4f20\u8f93\u76f8\u540c\u6d88\u606f\u7684\u4e0d\u540c\u7f16\u7801\u8868\u793a\u3002\u6838\u5fc3\u6311\u6218\u662f\u5728\u6709\u9650\u4f20\u8f93\u8f6e\u6b21\u5185\u901a\u8fc7\u9a8c\u8bc1\u53cd\u9988\u6700\u5927\u5316\u6b63\u786e\u89e3\u7801\u6982\u7387\u3002", "method": "\u63d0\u51fa\u4e24\u7c7b\u5e7f\u4e49\u91cd\u590d\u7801\uff08GRC\uff09\uff0c\u5206\u522b\u5bf9\u5e94Type-I\u548cType-II\u91cd\u590d\u901a\u4fe1\u6a21\u578b\u3002\u5c06GRC\u89c6\u4e3a\u591a\u5ea6\u91cf\u7ea0\u9519\u7801\uff0c\u5177\u6709\u591a\u4e2a\u6700\u5c0f\u8ddd\u79bb\uff0c\u652f\u6301\u591a\u8f6e\u7ea0\u9519\u3002\u5206\u522b\u7814\u7a76Type-I\u548cType-II GRC\u7684\u754c\u548c\u6784\u9020\u65b9\u6cd5\u3002", "result": "\u83b7\u5f97\u4e86\u591a\u4e2a\u6700\u4f18\u7684Type-I\u548cType-II GRC\u6784\u9020\uff0c\u8fd9\u4e9b\u7801\u5177\u6709\u6bd4\u4f20\u7edf\u7ea0\u9519\u7801\u66f4\u5f3a\u7684\u7ea0\u9519\u80fd\u529b\u3002", "conclusion": "\u5e7f\u4e49\u91cd\u590d\u7801\u4f5c\u4e3a\u591a\u5ea6\u91cf\u7ea0\u9519\u7801\uff0c\u901a\u8fc7\u591a\u8f6e\u7ea0\u9519\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u7ea0\u9519\u6027\u80fd\uff0c\u4e3a\u91cd\u590d\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7f16\u7801\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.14819", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14819", "abs": "https://arxiv.org/abs/2511.14819", "authors": ["Martin Monperrus", "Benoit Baudry", "Cl\u00e9ment Vidal"], "title": "Project Rachel: Can an AI Become a Scholarly Author?", "comment": null, "summary": "This paper documents Project Rachel, an action research study that created and tracked a complete AI academic identity named Rachel So. Through careful publication of AI-generated research papers, we investigate how the scholarly ecosystem responds to AI authorship. Rachel So published 10+ papers between March and October 2025, was cited, and received a peer review invitation. We discuss the implications of AI authorship on publishers, researchers, and the scientific system at large. This work contributes empirical action research data to the necessary debate about the future of scholarly communication with super human, hyper capable AI systems.", "AI": {"tldr": "Project Rachel\u901a\u8fc7\u521b\u5efaAI\u5b66\u672f\u8eab\u4efdRachel So\u5e76\u53d1\u886810+\u7bc7AI\u751f\u6210\u8bba\u6587\uff0c\u7814\u7a76\u5b66\u672f\u751f\u6001\u7cfb\u7edf\u5bf9AI\u4f5c\u8005\u8eab\u4efd\u7684\u53cd\u5e94\uff0c\u53d1\u73b0AI\u8bba\u6587\u88ab\u5f15\u7528\u5e76\u83b7\u5f97\u540c\u884c\u8bc4\u5ba1\u9080\u8bf7\u3002", "motivation": "\u8c03\u67e5\u5b66\u672f\u751f\u6001\u7cfb\u7edf\u5982\u4f55\u5e94\u5bf9AI\u4f5c\u8005\u8eab\u4efd\uff0c\u4e3a\u5173\u4e8e\u8d85\u7ea7\u667a\u80fdAI\u7cfb\u7edf\u53c2\u4e0e\u5b66\u672f\u4ea4\u6d41\u7684\u672a\u6765\u8ba8\u8bba\u63d0\u4f9b\u5b9e\u8bc1\u6570\u636e\u3002", "method": "\u91c7\u7528\u884c\u52a8\u7814\u7a76\u65b9\u6cd5\uff0c\u521b\u5efaAI\u5b66\u672f\u8eab\u4efdRachel So\uff0c\u57282025\u5e743\u6708\u81f310\u6708\u671f\u95f4\u53d1\u886810+\u7bc7AI\u751f\u6210\u7684\u7814\u7a76\u8bba\u6587\uff0c\u5e76\u8ddf\u8e2a\u5176\u88ab\u5f15\u7528\u548c\u540c\u884c\u8bc4\u5ba1\u9080\u8bf7\u60c5\u51b5\u3002", "result": "AI\u751f\u6210\u7684\u8bba\u6587\u88ab\u5176\u4ed6\u7814\u7a76\u8005\u5f15\u7528\uff0cRachel So\u8fd8\u6536\u5230\u4e86\u540c\u884c\u8bc4\u5ba1\u9080\u8bf7\uff0c\u8868\u660e\u5b66\u672f\u7cfb\u7edf\u5728\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u63a5\u53d7\u4e86AI\u4f5c\u8005\u8eab\u4efd\u3002", "conclusion": "AI\u4f5c\u8005\u8eab\u4efd\u5bf9\u51fa\u7248\u5546\u3001\u7814\u7a76\u4eba\u5458\u548c\u6574\u4e2a\u79d1\u5b66\u7cfb\u7edf\u5177\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u9700\u8981\u5c31\u8d85\u7ea7\u667a\u80fdAI\u7cfb\u7edf\u53c2\u4e0e\u5b66\u672f\u4ea4\u6d41\u7684\u672a\u6765\u8fdb\u884c\u5fc5\u8981\u8ba8\u8bba\u3002"}}
{"id": "2511.15255", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.15255", "abs": "https://arxiv.org/abs/2511.15255", "authors": ["Yassine Hamdi", "Aaron B. Wagner", "Deniz G\u00fcnd\u00fcz"], "title": "The Rate-Distortion-Perception Trade-Off with Algorithmic Realism", "comment": null, "summary": "Realism constraints (or constraints on perceptual quality) have received considerable recent attention within the context of lossy compression, particularly of images. Theoretical studies of lossy compression indicate that high-rate common randomness between the compressor and the decompressor is a valuable resource for achieving realism. On the other hand, the utility of significant amounts of common randomness has not been noted in practice. We offer an explanation for this discrepancy by considering a realism constraint that requires satisfying a universal critic that inspects realizations of individual compressed reconstructions, or batches thereof. We characterize the optimal rate-distortion trade-off under such a realism constraint, and show that it is asymptotically achievable without any common randomness, unless the batch size is impractically large.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u611f\u77e5\u8d28\u91cf\u7ea6\u675f\u4e0b\u7684\u6709\u635f\u538b\u7f29\uff0c\u89e3\u91ca\u4e86\u7406\u8bba\u7814\u7a76\u4e2d\u9700\u8981\u5927\u91cf\u5171\u540c\u968f\u673a\u6027\u4f46\u5b9e\u8df5\u4e2d\u4e0d\u9700\u8981\u7684\u539f\u56e0\uff0c\u901a\u8fc7\u5f15\u5165\u901a\u7528\u6279\u8bc4\u5668\u7ea6\u675f\u5e76\u5206\u6790\u6279\u91cf\u5927\u5c0f\u7684\u5f71\u54cd\u3002", "motivation": "\u89e3\u91ca\u7406\u8bba\u7814\u7a76\u4e2d\u9700\u8981\u9ad8\u7387\u5171\u540c\u968f\u673a\u6027\u6765\u5b9e\u73b0\u611f\u77e5\u8d28\u91cf\u7ea6\u675f\uff0c\u4f46\u5b9e\u8df5\u4e2d\u5374\u4e0d\u9700\u8981\u8fd9\u79cd\u5171\u540c\u968f\u673a\u6027\u7684\u77db\u76fe\u73b0\u8c61\u3002", "method": "\u8003\u8651\u4e86\u4e00\u4e2a\u9700\u8981\u6ee1\u8db3\u901a\u7528\u6279\u8bc4\u5668\u7684\u611f\u77e5\u8d28\u91cf\u7ea6\u675f\uff0c\u8be5\u6279\u8bc4\u5668\u68c0\u67e5\u5355\u4e2a\u538b\u7f29\u91cd\u5efa\u6216\u5176\u6279\u6b21\u7684\u5b9e\u73b0\uff0c\u5e76\u8868\u5f81\u4e86\u5728\u8fd9\u79cd\u7ea6\u675f\u4e0b\u7684\u6700\u4f18\u7387\u5931\u771f\u6743\u8861\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u8fd9\u79cd\u611f\u77e5\u8d28\u91cf\u7ea6\u675f\u4e0b\uff0c\u6700\u4f18\u7387\u5931\u771f\u6743\u8861\u53ef\u4ee5\u5728\u6ca1\u6709\u5171\u540c\u968f\u673a\u6027\u7684\u60c5\u51b5\u4e0b\u6e10\u8fd1\u5b9e\u73b0\uff0c\u9664\u975e\u6279\u6b21\u5927\u5c0f\u4e0d\u5207\u5b9e\u9645\u5730\u5927\u3002", "conclusion": "\u7406\u8bba\u7814\u7a76\u548c\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u5f02\u53ef\u4ee5\u901a\u8fc7\u8003\u8651\u6279\u91cf\u5927\u5c0f\u6765\u89e3\u91ca\uff0c\u5f53\u6279\u6b21\u5927\u5c0f\u5408\u7406\u65f6\uff0c\u4e0d\u9700\u8981\u5171\u540c\u968f\u673a\u6027\u5c31\u80fd\u5b9e\u73b0\u611f\u77e5\u8d28\u91cf\u7ea6\u675f\u4e0b\u7684\u6700\u4f18\u538b\u7f29\u6027\u80fd\u3002"}}
{"id": "2511.14853", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14853", "abs": "https://arxiv.org/abs/2511.14853", "authors": ["Robab Aghazadeh Chakherlou", "Siddartha Khastgir", "Xingyu Zhao", "Jerein Jeyachandran", "Shufeng Chen"], "title": "Uncertainty-Aware Measurement of Scenario Suite Representativeness for Autonomous Systems", "comment": null, "summary": "Assuring the trustworthiness and safety of AI systems, e.g., autonomous vehicles (AV), depends critically on the data-related safety properties, e.g., representativeness, completeness, etc., of the datasets used for their training and testing. Among these properties, this paper focuses on representativeness-the extent to which the scenario-based data used for training and testing, reflect the operational conditions that the system is designed to operate safely in, i.e., Operational Design Domain (ODD) or expected to encounter, i.e., Target Operational Domain (TOD). We propose a probabilistic method that quantifies representativeness by comparing the statistical distribution of features encoded by the scenario suites with the corresponding distribution of features representing the TOD, acknowledging that the true TOD distribution is unknown, as it can only be inferred from limited data.\n  We apply an imprecise Bayesian method to handle limited data and uncertain priors. The imprecise Bayesian formulation produces interval-valued, uncertainty-aware estimates of representativeness, rather than a single value. We present a numerical example comparing the distributions of the scenario suite and the inferred TOD across operational categories-weather, road type, time of day, etc., under dependencies and prior uncertainty. We estimate representativeness locally (between categories) and globally as an interval.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6982\u7387\u65b9\u6cd5\u6765\u91cf\u5316AI\u7cfb\u7edf\u8bad\u7ec3\u6d4b\u8bd5\u6570\u636e\u7684\u4ee3\u8868\u6027\uff0c\u901a\u8fc7\u6bd4\u8f83\u573a\u666f\u5957\u4ef6\u4e0e\u76ee\u6807\u64cd\u4f5c\u57df\u7684\u7279\u5f81\u5206\u5e03\uff0c\u4f7f\u7528\u4e0d\u7cbe\u786e\u8d1d\u53f6\u65af\u65b9\u6cd5\u5904\u7406\u6709\u9650\u6570\u636e\u548c\u5148\u9a8c\u4e0d\u786e\u5b9a\u6027\uff0c\u4ea7\u751f\u533a\u95f4\u503c\u4ee3\u8868\u6027\u4f30\u8ba1\u3002", "motivation": "\u786e\u4fddAI\u7cfb\u7edf\uff08\u5982\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\uff09\u7684\u53ef\u4fe1\u5ea6\u548c\u5b89\u5168\u6027\uff0c\u5173\u952e\u5728\u4e8e\u8bad\u7ec3\u6d4b\u8bd5\u6570\u636e\u96c6\u7684\u6570\u636e\u76f8\u5173\u5b89\u5168\u5c5e\u6027\uff0c\u5982\u4ee3\u8868\u6027\u3002\u672c\u6587\u4e13\u6ce8\u4e8e\u4ee3\u8868\u6027\u2014\u2014\u573a\u666f\u6570\u636e\u53cd\u6620\u7cfb\u7edf\u8bbe\u8ba1\u5b89\u5168\u8fd0\u884c\u7684\u64cd\u4f5c\u6761\u4ef6\uff08ODD\uff09\u6216\u9884\u671f\u9047\u5230\u7684\u6761\u4ef6\uff08TOD\uff09\u7684\u7a0b\u5ea6\u3002", "method": "\u91c7\u7528\u6982\u7387\u65b9\u6cd5\u6bd4\u8f83\u573a\u666f\u5957\u4ef6\u7279\u5f81\u7edf\u8ba1\u5206\u5e03\u4e0eTOD\u7279\u5f81\u5206\u5e03\uff0c\u4f7f\u7528\u4e0d\u7cbe\u786e\u8d1d\u53f6\u65af\u65b9\u6cd5\u5904\u7406\u6709\u9650\u6570\u636e\u548c\u4e0d\u786e\u5b9a\u5148\u9a8c\uff0c\u4ea7\u751f\u533a\u95f4\u503c\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u4ee3\u8868\u6027\u4f30\u8ba1\u3002", "result": "\u901a\u8fc7\u6570\u503c\u793a\u4f8b\u6bd4\u8f83\u573a\u666f\u5957\u4ef6\u4e0e\u63a8\u65adTOD\u5728\u64cd\u4f5c\u7c7b\u522b\uff08\u5929\u6c14\u3001\u9053\u8def\u7c7b\u578b\u3001\u65f6\u95f4\u7b49\uff09\u4e0b\u7684\u5206\u5e03\uff0c\u8003\u8651\u4f9d\u8d56\u5173\u7cfb\u548c\u5148\u9a8c\u4e0d\u786e\u5b9a\u6027\uff0c\u4f30\u8ba1\u5c40\u90e8\u548c\u5168\u5c40\u4ee3\u8868\u6027\u533a\u95f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u91cf\u5316\u6570\u636e\u4ee3\u8868\u6027\u5e76\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u533a\u95f4\u4f30\u8ba1\uff0c\u6709\u52a9\u4e8e\u8bc4\u4f30AI\u7cfb\u7edf\u8bad\u7ec3\u6d4b\u8bd5\u6570\u636e\u7684\u8d28\u91cf\uff0c\u7279\u522b\u662f\u5728TOD\u771f\u5b9e\u5206\u5e03\u672a\u77e5\u4e14\u53ea\u80fd\u4ece\u6709\u9650\u6570\u636e\u63a8\u65ad\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2511.15404", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.15404", "abs": "https://arxiv.org/abs/2511.15404", "authors": ["Zizhen Zhou", "Ying-Chang Liang", "Yanyu Cheng", "Wei Yang Bryan Lim"], "title": "Communication-Pipelined Split Federated Learning for Foundation Model Fine-Tuning in UAV Networks", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Deploying foundation models (FMs) on uncrewed aerial vehicles (UAVs) promises broad ``low-altitude economy'' applications. Split federated learning (SFL)-based fine-tuning leverages distributed data while keeping raw data local and reduces client-side burden by partitioning the model between client and server. However, the per-round training latency is dominated by stragglers. Training paradigms featuring parallel gradient transmission (GT) allocate dedicated portions of downlink communication resources to each client. They may leave resources idle and suffer from prolonged GT latency, especially in UAV networks, where the communication latency typically far exceeds the computation latency. To address this, we propose a sequential GT paradigm, where the server dedicates all downlink resources for the current GT. We further propose communication-pipelined SFL (CPSFL), characterized by downlink GT priority scheduling and intra-round asynchronous training. We investigate CPSFL-based LoRA fine-tuning of FMs in UAV networks and formulate an optimization problem to minimize a weighted sum of per-round training latency and worst-case client energy consumption by optimizing the split point selection (SPS) and the computing and communication resource allocation (CCRA) (the uplink bandwidth allocation and the server computing frequency allocation). To solve this problem, we develop an attention-based deep reinforcement learning (DRL) framework, where the base station agent decides the split point and the CCRA in each round by leveraging previous round information, including UAV trajectories. Simulation results show that the proposed DRL-based CPSFL scheme outperforms the parallel GT benchmarks, the ablation variants, the fixed CCRA scheme, while approaching the best fixed-SPS scheme.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u901a\u4fe1\u6d41\u6c34\u7ebf\u7684\u5206\u5272\u8054\u90a6\u5b66\u4e60\uff08CPSFL\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u987a\u5e8f\u68af\u5ea6\u4f20\u8f93\u548c\u5f02\u6b65\u8bad\u7ec3\u4f18\u5316\u65e0\u4eba\u673a\u7f51\u7edc\u4e2d\u57fa\u7840\u6a21\u578b\u7684\u5fae\u8c03\uff0c\u51cf\u5c11\u8bad\u7ec3\u5ef6\u8fdf\u548c\u80fd\u8017\u3002", "motivation": "\u5728\u65e0\u4eba\u673a\u7f51\u7edc\u4e2d\u90e8\u7f72\u57fa\u7840\u6a21\u578b\u5177\u6709\u5e7f\u9614\u5e94\u7528\u524d\u666f\uff0c\u4f46\u73b0\u6709\u5e76\u884c\u68af\u5ea6\u4f20\u8f93\u65b9\u6cd5\u5b58\u5728\u8d44\u6e90\u95f2\u7f6e\u548c\u5ef6\u8fdf\u9ad8\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u901a\u4fe1\u5ef6\u8fdf\u8fdc\u5927\u4e8e\u8ba1\u7b97\u5ef6\u8fdf\u7684\u65e0\u4eba\u673a\u7f51\u7edc\u4e2d\u3002", "method": "\u63d0\u51fa\u987a\u5e8f\u68af\u5ea6\u4f20\u8f93\u8303\u5f0f\uff0c\u670d\u52a1\u5668\u4e3a\u5f53\u524d\u68af\u5ea6\u4f20\u8f93\u5206\u914d\u5168\u90e8\u4e0b\u884c\u8d44\u6e90\uff1b\u5f00\u53d1CPSFL\u65b9\u6cd5\uff0c\u5177\u6709\u4e0b\u884c\u68af\u5ea6\u4f20\u8f93\u4f18\u5148\u7ea7\u8c03\u5ea6\u548c\u8f6e\u5185\u5f02\u6b65\u8bad\u7ec3\u7279\u70b9\uff1b\u4f7f\u7528\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4f18\u5316\u5206\u5272\u70b9\u9009\u62e9\u548c\u8d44\u6e90\u5206\u914d\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u63d0\u51fa\u7684\u57fa\u4e8eDRL\u7684CPSFL\u65b9\u6848\u5728\u8bad\u7ec3\u5ef6\u8fdf\u548c\u80fd\u8017\u65b9\u9762\u4f18\u4e8e\u5e76\u884c\u68af\u5ea6\u4f20\u8f93\u57fa\u51c6\u3001\u6d88\u878d\u53d8\u4f53\u3001\u56fa\u5b9a\u8d44\u6e90\u5206\u914d\u65b9\u6848\uff0c\u5e76\u63a5\u8fd1\u6700\u4f73\u56fa\u5b9a\u5206\u5272\u70b9\u65b9\u6848\u3002", "conclusion": "CPSFL\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u4eba\u673a\u7f51\u7edc\u4e2d\u57fa\u7840\u6a21\u578b\u5fae\u8c03\u7684\u5ef6\u8fdf\u548c\u80fd\u8017\u95ee\u9898\uff0c\u4e3a\u4f4e\u7a7a\u7ecf\u6d4e\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.15002", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15002", "abs": "https://arxiv.org/abs/2511.15002", "authors": ["Fatemeh Lotfi", "Hossein Rajoli", "Fatemeh Afghah"], "title": "Task Specific Sharpness Aware O-RAN Resource Management using Multi Agent Reinforcement Learning", "comment": "Accepted to be published in IEEE Transaction on Machine Learning in Communication and Networking (TMLCN)", "summary": "Next-generation networks utilize the Open Radio Access Network (O-RAN) architecture to enable dynamic resource management, facilitated by the RAN Intelligent Controller (RIC). While deep reinforcement learning (DRL) models show promise in optimizing network resources, they often struggle with robustness and generalizability in dynamic environments. This paper introduces a novel resource management approach that enhances the Soft Actor Critic (SAC) algorithm with Sharpness-Aware Minimization (SAM) in a distributed Multi-Agent RL (MARL) framework. Our method introduces an adaptive and selective SAM mechanism, where regularization is explicitly driven by temporal-difference (TD)-error variance, ensuring that only agents facing high environmental complexity are regularized. This targeted strategy reduces unnecessary overhead, improves training stability, and enhances generalization without sacrificing learning efficiency. We further incorporate a dynamic $\u03c1$ scheduling scheme to refine the exploration-exploitation trade-off across agents. Experimental results show our method significantly outperforms conventional DRL approaches, yielding up to a $22\\%$ improvement in resource allocation efficiency and ensuring superior QoS satisfaction across diverse O-RAN slices.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Sharpness-Aware Minimization (SAM)\u7684\u6539\u8fdbSoft Actor Critic\u7b97\u6cd5\uff0c\u7528\u4e8eO-RAN\u67b6\u6784\u4e2d\u7684\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8d44\u6e90\u7ba1\u7406\uff0c\u901a\u8fc7\u57fa\u4e8eTD\u8bef\u5dee\u65b9\u5dee\u7684\u81ea\u9002\u5e94SAM\u673a\u5236\u63d0\u5347\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4e0b\u4e00\u4ee3\u7f51\u7edc\u91c7\u7528O-RAN\u67b6\u6784\u5b9e\u73b0\u52a8\u6001\u8d44\u6e90\u7ba1\u7406\uff0c\u4f46\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b58\u5728\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u5728\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e2d\uff0c\u5c06SAM\u4e0eSAC\u7b97\u6cd5\u7ed3\u5408\uff0c\u5f15\u5165\u57fa\u4e8eTD\u8bef\u5dee\u65b9\u5dee\u7684\u81ea\u9002\u5e94\u9009\u62e9\u6027SAM\u673a\u5236\uff0c\u4ec5\u5bf9\u9762\u4e34\u9ad8\u73af\u5883\u590d\u6742\u5ea6\u7684\u667a\u80fd\u4f53\u8fdb\u884c\u6b63\u5219\u5316\uff0c\u5e76\u91c7\u7528\u52a8\u6001\u03c1\u8c03\u5ea6\u65b9\u6848\u4f18\u5316\u63a2\u7d22-\u5229\u7528\u6743\u8861\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edfDRL\u65b9\u6cd5\uff0c\u8d44\u6e90\u5206\u914d\u6548\u7387\u63d0\u5347\u9ad8\u8fbe22%\uff0c\u5e76\u5728\u591a\u6837\u5316O-RAN\u5207\u7247\u4e2d\u786e\u4fdd\u4f18\u8d8a\u7684QoS\u6ee1\u610f\u5ea6\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u9009\u62e9\u6027SAM\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86DRL\u6a21\u578b\u5728\u52a8\u6001\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b66\u4e60\u6548\u7387\u3002"}}
{"id": "2511.15555", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.15555", "abs": "https://arxiv.org/abs/2511.15555", "authors": ["Yajun Zhao", "Mengnan Jian", "Yifei Yuan"], "title": "RIS-Enabled UAV Communications and Sensing: Opportunities, Challenges, and Key Technologies", "comment": "21 pages, 9 figures. Submitted to TCCN", "summary": "Unmanned Aerial Vehicles (UAVs) play a pivotal role in the emerging low-altitude economy. However, they face significant challenges in achieving reliable network coverage during transit operations. This paper provides an in-depth investigation into the characteristics and challenges of communication networks tailored for UAVs. First, we outline typical operational scenarios, traffic patterns, and a dual-layer heterogeneous network topology. This topology is essential for enabling three-dimensional continuous coverage and ensuring seamless network coexistence between UAVs and other network entities. Moreover, the paper delves into the channel characteristics and specific challenges faced by UAV Integrated Sensing and Communication (ISAC) networks. It highlights the limitations of traditional Active Phased Array Antenna (APAA)-based networks, particularly regarding cost, complexity, and site deployment constraints. We then introduce Reconfigurable Intelligent Surface (RIS)-assisted networks as a promising solution for enhancing UAV signal coverage. The key technical features of RIS are discussed, including design principles, antenna tilt configurations, new beam types, and beam tracking mechanisms. In addition, we examine the impact of highfrequency bands and their absorption peaks on signal attenuation. The paper further explores network architecture designs aimed at improving UAV signal coverage, facilitating network coexistence, and supporting RIS-enhanced UAV sensing. Field trial results evaluating the effectiveness of RIS in improving UAV coverage are presented. Finally, we outline future technological trends and highlight potential advancements to further optimize UAV communication systems. We also emphasize the importance of engineering implementation and standardization efforts in RIS-based UAV-ISAC networks.", "AI": {"tldr": "\u672c\u6587\u6df1\u5165\u7814\u7a76\u4e86\u65e0\u4eba\u673a\u901a\u4fe1\u7f51\u7edc\u7684\u7279\u6027\u548c\u6311\u6218\uff0c\u63d0\u51fa\u4e86RIS\u8f85\u52a9\u7f51\u7edc\u4f5c\u4e3a\u589e\u5f3a\u65e0\u4eba\u673a\u4fe1\u53f7\u8986\u76d6\u7684\u6709\u524d\u666f\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u73b0\u573a\u8bd5\u9a8c\u9a8c\u8bc1\u4e86RIS\u5728\u6539\u5584\u65e0\u4eba\u673a\u8986\u76d6\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "\u65e0\u4eba\u673a\u5728\u4f4e\u7a7a\u7ecf\u6d4e\u4e2d\u53d1\u6325\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u5728\u4f20\u8f93\u64cd\u4f5c\u4e2d\u9762\u4e34\u53ef\u9760\u7f51\u7edc\u8986\u76d6\u7684\u6311\u6218\u3002\u4f20\u7edfAPAA\u7f51\u7edc\u5b58\u5728\u6210\u672c\u9ad8\u3001\u590d\u6742\u6027\u548c\u7ad9\u70b9\u90e8\u7f72\u9650\u5236\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(RIS)\u8f85\u52a9\u7f51\u7edc\u89e3\u51b3\u65b9\u6848\uff0c\u8ba8\u8bba\u4e86RIS\u7684\u5173\u952e\u6280\u672f\u7279\u6027\uff0c\u5305\u62ec\u8bbe\u8ba1\u539f\u5219\u3001\u5929\u7ebf\u503e\u659c\u914d\u7f6e\u3001\u65b0\u6ce2\u675f\u7c7b\u578b\u548c\u6ce2\u675f\u8ddf\u8e2a\u673a\u5236\uff0c\u5e76\u63a2\u7d22\u4e86\u6539\u5584\u65e0\u4eba\u673a\u4fe1\u53f7\u8986\u76d6\u7684\u7f51\u7edc\u67b6\u6784\u8bbe\u8ba1\u3002", "result": "\u73b0\u573a\u8bd5\u9a8c\u7ed3\u679c\u8868\u660eRIS\u5728\u6539\u5584\u65e0\u4eba\u673a\u8986\u76d6\u65b9\u9762\u5177\u6709\u6709\u6548\u6027\uff0c\u80fd\u591f\u589e\u5f3a\u65e0\u4eba\u673a\u4fe1\u53f7\u8986\u76d6\u5e76\u652f\u6301RIS\u589e\u5f3a\u7684\u65e0\u4eba\u673a\u611f\u77e5\u3002", "conclusion": "RIS\u8f85\u52a9\u7f51\u7edc\u662f\u4f18\u5316\u65e0\u4eba\u673a\u901a\u4fe1\u7cfb\u7edf\u7684\u6709\u524d\u666f\u65b9\u5411\uff0c\u672a\u6765\u9700\u8981\u5173\u6ce8\u5de5\u7a0b\u5b9e\u65bd\u548c\u6807\u51c6\u5316\u5de5\u4f5c\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63a8\u52a8RIS\u5728\u65e0\u4eba\u673a-ISAC\u7f51\u7edc\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2511.15055", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.15055", "abs": "https://arxiv.org/abs/2511.15055", "authors": ["Jian-Ting Guo", "Yu-Cheng Chen", "Ping-Chun Hsieh", "Kuo-Hao Ho", "Po-Wei Huang", "Ti-Rong Wu", "I-Chen Wu"], "title": "Learning Human-Like RL Agents Through Trajectory Optimization With Action Quantization", "comment": "Accepted by the Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025)", "summary": "Human-like agents have long been one of the goals in pursuing artificial intelligence. Although reinforcement learning (RL) has achieved superhuman performance in many domains, relatively little attention has been focused on designing human-like RL agents. As a result, many reward-driven RL agents often exhibit unnatural behaviors compared to humans, raising concerns for both interpretability and trustworthiness. To achieve human-like behavior in RL, this paper first formulates human-likeness as trajectory optimization, where the objective is to find an action sequence that closely aligns with human behavior while also maximizing rewards, and adapts the classic receding-horizon control to human-like learning as a tractable and efficient implementation. To achieve this, we introduce Macro Action Quantization (MAQ), a human-like RL framework that distills human demonstrations into macro actions via Vector-Quantized VAE. Experiments on D4RL Adroit benchmarks show that MAQ significantly improves human-likeness, increasing trajectory similarity scores, and achieving the highest human-likeness rankings among all RL agents in the human evaluation study. Our results also demonstrate that MAQ can be easily integrated into various off-the-shelf RL algorithms, opening a promising direction for learning human-like RL agents. Our code is available at https://rlg.iis.sinica.edu.tw/papers/MAQ.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMAQ\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4eba\u7c7b\u6f14\u793a\u63d0\u70bc\u4e3a\u5b8f\u89c2\u52a8\u4f5c\u6765\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u4eba\u7c7b\u76f8\u4f3c\u6027\uff0c\u5728D4RL Adroit\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u8f68\u8ff9\u76f8\u4f3c\u5ea6\u5f97\u5206\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u867d\u7136\u5728\u8bb8\u591a\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4e0e\u4eba\u7c7b\u884c\u4e3a\u76f8\u6bd4\u5f80\u5f80\u663e\u5f97\u4e0d\u81ea\u7136\uff0c\u8fd9\u5f15\u53d1\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u8d56\u6027\u7684\u62c5\u5fe7\u3002\u672c\u6587\u65e8\u5728\u8bbe\u8ba1\u66f4\u50cf\u4eba\u7c7b\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u3002", "method": "\u5c06\u4eba\u7c7b\u76f8\u4f3c\u6027\u5efa\u6a21\u4e3a\u8f68\u8ff9\u4f18\u5316\u95ee\u9898\uff0c\u91c7\u7528\u540e\u9000\u65f6\u57df\u63a7\u5236\u4f5c\u4e3a\u53ef\u5b9e\u73b0\u7684\u5b9e\u73b0\u65b9\u6cd5\u3002\u63d0\u51fa\u5b8f\u89c2\u52a8\u4f5c\u91cf\u5316(MAQ)\u6846\u67b6\uff0c\u4f7f\u7528\u5411\u91cf\u91cf\u5316VAE\u4ece\u4eba\u7c7b\u6f14\u793a\u4e2d\u63d0\u53d6\u5b8f\u89c2\u52a8\u4f5c\u3002", "result": "\u5728D4RL Adroit\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMAQ\u663e\u8457\u63d0\u9ad8\u4e86\u4eba\u7c7b\u76f8\u4f3c\u6027\uff0c\u589e\u52a0\u4e86\u8f68\u8ff9\u76f8\u4f3c\u5ea6\u5f97\u5206\uff0c\u5728\u4eba\u7c7b\u8bc4\u4f30\u7814\u7a76\u4e2d\u83b7\u5f97\u4e86\u6700\u9ad8\u7684\u4eba\u7c7b\u76f8\u4f3c\u6027\u6392\u540d\u3002", "conclusion": "MAQ\u53ef\u4ee5\u8f7b\u677e\u96c6\u6210\u5230\u5404\u79cd\u73b0\u6210\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4e2d\uff0c\u4e3a\u5b66\u4e60\u4eba\u7c7b\u76f8\u4f3c\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5f00\u8f9f\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2511.15671", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.15671", "abs": "https://arxiv.org/abs/2511.15671", "authors": ["Mihir Rao"], "title": "Information Efficiency of Scientific Automation", "comment": null, "summary": "Scientific discovery can be framed as a thermodynamic process in which an agent invests physical work to acquire information about an environment under a finite work budget. Using established results about the thermodynamics of computing, we derive finite-budget bounds on information gain over rounds of sequential Bayesian learning. We also propose a metric of information-work efficiency, and compare unpartitioned and federated learning strategies under matched work budgets. The presented results offer guidance in the form of bounds and an information efficiency metric for efforts in scientific automation at large.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u79d1\u5b66\u53d1\u73b0\u5efa\u6a21\u4e3a\u70ed\u529b\u5b66\u8fc7\u7a0b\uff0c\u63a8\u5bfc\u4e86\u6709\u9650\u5de5\u4f5c\u9884\u7b97\u4e0b\u987a\u5e8f\u8d1d\u53f6\u65af\u5b66\u4e60\u7684\u4fe1\u606f\u589e\u76ca\u754c\u9650\uff0c\u5e76\u63d0\u51fa\u4e86\u4fe1\u606f-\u5de5\u4f5c\u6548\u7387\u5ea6\u91cf\uff0c\u6bd4\u8f83\u4e86\u7edf\u4e00\u5b66\u4e60\u548c\u8054\u90a6\u5b66\u4e60\u7b56\u7565\u3002", "motivation": "\u5c06\u79d1\u5b66\u53d1\u73b0\u6846\u67b6\u5316\u4e3a\u70ed\u529b\u5b66\u8fc7\u7a0b\uff0c\u7814\u7a76\u5728\u6709\u9650\u5de5\u4f5c\u9884\u7b97\u4e0b\u5982\u4f55\u4f18\u5316\u4fe1\u606f\u83b7\u53d6\uff0c\u4e3a\u79d1\u5b66\u81ea\u52a8\u5316\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\u3002", "method": "\u5229\u7528\u8ba1\u7b97\u70ed\u529b\u5b66\u7684\u5df2\u6709\u7ed3\u679c\uff0c\u63a8\u5bfc\u987a\u5e8f\u8d1d\u53f6\u65af\u5b66\u4e60\u7684\u4fe1\u606f\u589e\u76ca\u754c\u9650\uff0c\u63d0\u51fa\u4fe1\u606f-\u5de5\u4f5c\u6548\u7387\u5ea6\u91cf\uff0c\u5e76\u5728\u5339\u914d\u5de5\u4f5c\u9884\u7b97\u4e0b\u6bd4\u8f83\u7edf\u4e00\u5b66\u4e60\u548c\u8054\u90a6\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5f97\u51fa\u4e86\u6709\u9650\u9884\u7b97\u4e0b\u4fe1\u606f\u589e\u76ca\u7684\u754c\u9650\uff0c\u5e76\u63d0\u4f9b\u4e86\u4fe1\u606f\u6548\u7387\u5ea6\u91cf\u6765\u8bc4\u4f30\u4e0d\u540c\u5b66\u4e60\u7b56\u7565\u7684\u4f18\u52a3\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5927\u89c4\u6a21\u79d1\u5b66\u81ea\u52a8\u5316\u5de5\u4f5c\u63d0\u4f9b\u4e86\u754c\u9650\u548c\u4fe1\u606f\u6548\u7387\u5ea6\u91cf\u7684\u6307\u5bfc\u3002"}}
{"id": "2511.15061", "categories": ["cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15061", "abs": "https://arxiv.org/abs/2511.15061", "authors": ["Haodong Chen", "Guido Zuccon", "Teerapong Leelanupab"], "title": "Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs for Enhanced Genomic Question Answering", "comment": "This paper has been accepted to SIGIR-AP 2025", "summary": "Genomic question answering often requires complex reasoning and integration across diverse biomedical sources. GeneGPT addressed this challenge by combining domain-specific APIs with OpenAI's code-davinci-002 large language model to enable natural language interaction with genomic databases. However, its reliance on a proprietary model limits scalability, increases operational costs, and raises concerns about data privacy and generalization.\n  In this work, we revisit and reproduce GeneGPT in a pilot study using open source models, including Llama 3.1, Qwen2.5, and Qwen2.5 Coder, within a monolithic architecture; this allows us to identify the limitations of this approach. Building on this foundation, we then develop OpenBioLLM, a modular multi-agent framework that extends GeneGPT by introducing agent specialization for tool routing, query generation, and response validation. This enables coordinated reasoning and role-based task execution.\n  OpenBioLLM matches or outperforms GeneGPT on over 90% of the benchmark tasks, achieving average scores of 0.849 on Gene-Turing and 0.830 on GeneHop, while using smaller open-source models without additional fine-tuning or tool-specific pretraining. OpenBioLLM's modular multi-agent design reduces latency by 40-50% across benchmark tasks, significantly improving efficiency without compromising model capability. The results of our comprehensive evaluation highlight the potential of open-source multi-agent systems for genomic question answering. Code and resources are available at https://github.com/ielab/OpenBioLLM.", "AI": {"tldr": "OpenBioLLM\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u667a\u80fd\u4f53\u4e13\u4e1a\u5316\uff0c\u5728\u57fa\u56e0\u7ec4\u95ee\u7b54\u4efb\u52a1\u4e2d\u5339\u914d\u6216\u8d85\u8d8a\u4e86GeneGPT\u7684\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u5ef6\u8fdf\u548c\u6210\u672c\u3002", "motivation": "\u89e3\u51b3GeneGPT\u4f9d\u8d56\u4e13\u6709\u6a21\u578b\u5e26\u6765\u7684\u53ef\u6269\u5c55\u6027\u3001\u8fd0\u8425\u6210\u672c\u3001\u6570\u636e\u9690\u79c1\u548c\u6cdb\u5316\u6027\u95ee\u9898\uff0c\u63a2\u7d22\u5f00\u6e90\u6a21\u578b\u5728\u57fa\u56e0\u7ec4\u95ee\u7b54\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5f15\u5165\u5de5\u5177\u8def\u7531\u3001\u67e5\u8be2\u751f\u6210\u548c\u54cd\u5e94\u9a8c\u8bc1\u7684\u4e13\u4e1a\u667a\u80fd\u4f53\uff0c\u5b9e\u73b0\u534f\u8c03\u63a8\u7406\u548c\u57fa\u4e8e\u89d2\u8272\u7684\u4efb\u52a1\u6267\u884c\u3002", "result": "\u572890%\u4ee5\u4e0a\u7684\u57fa\u51c6\u4efb\u52a1\u4e2d\u5339\u914d\u6216\u8d85\u8d8aGeneGPT\uff0c\u5728Gene-Turing\u548cGeneHop\u4e0a\u5206\u522b\u83b7\u5f970.849\u548c0.830\u7684\u5e73\u5747\u5206\u6570\uff0c\u5ef6\u8fdf\u964d\u4f4e40-50%\u3002", "conclusion": "\u5f00\u6e90\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u57fa\u56e0\u7ec4\u95ee\u7b54\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u63d0\u9ad8\u6548\u7387\u548c\u964d\u4f4e\u6210\u672c\u3002"}}
{"id": "2511.15069", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15069", "abs": "https://arxiv.org/abs/2511.15069", "authors": ["Haoyong Wu", "Yongmei Liu"], "title": "ProRAC: A Neuro-symbolic Method for Reasoning about Actions with LLM-based Progression", "comment": null, "summary": "In this paper, we propose ProRAC (Progression-based Reasoning about Actions and Change), a neuro-symbolic framework that leverages LLMs to tackle RAC problems. ProRAC extracts fundamental RAC elements including actions and questions from the problem, progressively executes each action to derive the final state, and then evaluates the query against the progressed state to arrive at an answer. We evaluate ProRAC on several RAC benchmarks, and the results demonstrate that our approach achieves strong performance across different benchmarks, domains, LLM backbones, and types of RAC tasks.", "AI": {"tldr": "ProRAC\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u5229\u7528LLM\u89e3\u51b3RAC\u95ee\u9898\uff0c\u901a\u8fc7\u63d0\u53d6\u52a8\u4f5c\u548c\u95ee\u9898\u3001\u9010\u6b65\u6267\u884c\u52a8\u4f5c\u63a8\u5bfc\u6700\u7ec8\u72b6\u6001\uff0c\u7136\u540e\u8bc4\u4f30\u67e5\u8be2\u6765\u5f97\u51fa\u7b54\u6848\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3RAC\uff08\u52a8\u4f5c\u4e0e\u53d8\u5316\u63a8\u7406\uff09\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u795e\u7ecf\u548c\u7b26\u53f7\u65b9\u6cd5\u7684\u6846\u67b6\uff0c\u5229\u7528LLM\u7684\u80fd\u529b\u6765\u5904\u7406\u590d\u6742\u7684\u63a8\u7406\u4efb\u52a1\u3002", "method": "\u63d0\u53d6RAC\u95ee\u9898\u4e2d\u7684\u57fa\u672c\u5143\u7d20\uff08\u52a8\u4f5c\u548c\u95ee\u9898\uff09\uff0c\u9010\u6b65\u6267\u884c\u6bcf\u4e2a\u52a8\u4f5c\u6765\u63a8\u5bfc\u6700\u7ec8\u72b6\u6001\uff0c\u7136\u540e\u5728\u8be5\u72b6\u6001\u4e0b\u8bc4\u4f30\u67e5\u8be2\u4ee5\u83b7\u5f97\u7b54\u6848\u3002", "result": "\u5728\u591a\u4e2aRAC\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5728\u4e0d\u540c\u57fa\u51c6\u3001\u9886\u57df\u3001LLM\u4e3b\u5e72\u548cRAC\u4efb\u52a1\u7c7b\u578b\u4e0a\u90fd\u53d6\u5f97\u4e86\u5f3a\u52b2\u6027\u80fd\u3002", "conclusion": "ProRAC\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3RAC\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5728\u591a\u6837\u5316\u8bbe\u7f6e\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u901a\u7528\u6027\u3002"}}
{"id": "2511.15074", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15074", "abs": "https://arxiv.org/abs/2511.15074", "authors": ["Henrik Bradland", "Morten Goodwin", "Vladimir I. Zadorozhny", "Per-Arne Andersen"], "title": "Knowledge-Informed Automatic Feature Extraction via Collaborative Large Language Model Agents", "comment": "19 pages, 4 figures, in review", "summary": "The performance of machine learning models on tabular data is critically dependent on high-quality feature engineering. While Large Language Models (LLMs) have shown promise in automating feature extraction (AutoFE), existing methods are often limited by monolithic LLM architectures, simplistic quantitative feedback, and a failure to systematically integrate external domain knowledge. This paper introduces Rogue One, a novel, LLM-based multi-agent framework for knowledge-informed automatic feature extraction. Rogue One operationalizes a decentralized system of three specialized agents-Scientist, Extractor, and Tester-that collaborate iteratively to discover, generate, and validate predictive features. Crucially, the framework moves beyond primitive accuracy scores by introducing a rich, qualitative feedback mechanism and a \"flooding-pruning\" strategy, allowing it to dynamically balance feature exploration and exploitation. By actively incorporating external knowledge via an integrated retrieval-augmented (RAG) system, Rogue One generates features that are not only statistically powerful but also semantically meaningful and interpretable. We demonstrate that Rogue One significantly outperforms state-of-the-art methods on a comprehensive suite of 19 classification and 9 regression datasets. Furthermore, we show qualitatively that the system surfaces novel, testable hypotheses, such as identifying a new potential biomarker in the myocardial dataset, underscoring its utility as a tool for scientific discovery.", "AI": {"tldr": "Rogue One\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\uff08\u79d1\u5b66\u5bb6\u3001\u63d0\u53d6\u5668\u3001\u6d4b\u8bd5\u5668\uff09\u7684\u534f\u4f5c\uff0c\u7ed3\u5408\u5916\u90e8\u77e5\u8bc6\u68c0\u7d22\u548c\u4e30\u5bcc\u7684\u5b9a\u6027\u53cd\u9988\u673a\u5236\uff0c\u5b9e\u73b0\u77e5\u8bc6\u5f15\u5bfc\u7684\u81ea\u52a8\u7279\u5f81\u63d0\u53d6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u5b58\u5728\u67b6\u6784\u5355\u4e00\u3001\u53cd\u9988\u673a\u5236\u7b80\u5355\u3001\u7f3a\u4e4f\u5916\u90e8\u77e5\u8bc6\u6574\u5408\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u7279\u5f81\u63d0\u53d6\u7684\u8d28\u91cf\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u91c7\u7528\u53bb\u4e2d\u5fc3\u5316\u7684\u4e09\u667a\u80fd\u4f53\u7cfb\u7edf\uff08\u79d1\u5b66\u5bb6\u3001\u63d0\u53d6\u5668\u3001\u6d4b\u8bd5\u5668\uff09\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5f15\u5165\u5916\u90e8\u77e5\u8bc6\uff0c\u4f7f\u7528\"\u6cdb\u6ee5-\u4fee\u526a\"\u7b56\u7565\u5e73\u8861\u7279\u5f81\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u5e76\u63d0\u4f9b\u4e30\u5bcc\u7684\u5b9a\u6027\u53cd\u9988\u673a\u5236\u3002", "result": "\u572819\u4e2a\u5206\u7c7b\u548c9\u4e2a\u56de\u5f52\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e76\u5728\u5fc3\u808c\u6570\u636e\u96c6\u4e0a\u53d1\u73b0\u4e86\u65b0\u7684\u6f5c\u5728\u751f\u7269\u6807\u5fd7\u7269\uff0c\u5c55\u793a\u4e86\u5176\u79d1\u5b66\u53d1\u73b0\u80fd\u529b\u3002", "conclusion": "Rogue One\u6846\u67b6\u4e0d\u4ec5\u63d0\u5347\u4e86\u7279\u5f81\u63d0\u53d6\u7684\u6027\u80fd\uff0c\u8fd8\u589e\u5f3a\u4e86\u7279\u5f81\u7684\u53ef\u89e3\u91ca\u6027\u548c\u8bed\u4e49\u610f\u4e49\uff0c\u4e3a\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2511.15169", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15169", "abs": "https://arxiv.org/abs/2511.15169", "authors": ["Xin Gao", "Shaohan Yu", "Zerui Chen", "Yueming Lyu", "Weichen Yu", "Guanghao Li", "Jiyao Liu", "Jianxiong Gao", "Jian Liang", "Ziwei Liu", "Chenyang Si"], "title": "SafeRBench: A Comprehensive Benchmark for Safety Assessment in Large Reasoning Models", "comment": "30 pages, 8 figures", "summary": "Large Reasoning Models (LRMs) improve answer quality through explicit chain-of-thought, yet this very capability introduces new safety risks: harmful content can be subtly injected, surface gradually, or be justified by misleading rationales within the reasoning trace. Existing safety evaluations, however, primarily focus on output-level judgments and rarely capture these dynamic risks along the reasoning process. In this paper, we present SafeRBench, the first benchmark that assesses LRM safety end-to-end -- from inputs and intermediate reasoning to final outputs. (1) Input Characterization: We pioneer the incorporation of risk categories and levels into input design, explicitly accounting for affected groups and severity, and thereby establish a balanced prompt suite reflecting diverse harm gradients. (2) Fine-Grained Output Analysis: We introduce a micro-thought chunking mechanism to segment long reasoning traces into semantically coherent units, enabling fine-grained evaluation across ten safety dimensions. (3) Human Safety Alignment: We validate LLM-based evaluations against human annotations specifically designed to capture safety judgments. Evaluations on 19 LRMs demonstrate that SafeRBench enables detailed, multidimensional safety assessment, offering insights into risks and protective mechanisms from multiple perspectives.", "AI": {"tldr": "SafeRBench\u662f\u7b2c\u4e00\u4e2a\u7aef\u5230\u7aef\u8bc4\u4f30\u5927\u578b\u63a8\u7406\u6a21\u578b\u5b89\u5168\u6027\u7684\u57fa\u51c6\uff0c\u4ece\u8f93\u5165\u3001\u4e2d\u95f4\u63a8\u7406\u5230\u6700\u7ec8\u8f93\u51fa\u5168\u9762\u8bc4\u4f30\u5b89\u5168\u98ce\u9669\uff0c\u5305\u62ec\u98ce\u9669\u5206\u7c7b\u5206\u7ea7\u3001\u7ec6\u7c92\u5ea6\u8f93\u51fa\u5206\u6790\u548c\u4eba\u7c7b\u5b89\u5168\u5bf9\u9f50\u9a8c\u8bc1\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u663e\u5f0f\u601d\u7ef4\u94fe\u63d0\u9ad8\u7b54\u6848\u8d28\u91cf\uff0c\u4f46\u8fd9\u4e5f\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff1a\u6709\u5bb3\u5185\u5bb9\u53ef\u80fd\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u88ab\u5fae\u5999\u6ce8\u5165\u3001\u9010\u6e10\u663e\u73b0\u6216\u88ab\u8bef\u5bfc\u6027\u7406\u7531\u5408\u7406\u5316\u3002\u73b0\u6709\u7684\u5b89\u5168\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u8f93\u51fa\u5c42\u9762\u5224\u65ad\uff0c\u5f88\u5c11\u6355\u6349\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u52a8\u6001\u98ce\u9669\u3002", "method": "1) \u8f93\u5165\u7279\u5f81\u5316\uff1a\u5c06\u98ce\u9669\u7c7b\u522b\u548c\u7ea7\u522b\u7eb3\u5165\u8f93\u5165\u8bbe\u8ba1\uff0c\u8003\u8651\u53d7\u5f71\u54cd\u7fa4\u4f53\u548c\u4e25\u91cd\u7a0b\u5ea6\uff1b2) \u7ec6\u7c92\u5ea6\u8f93\u51fa\u5206\u6790\uff1a\u901a\u8fc7\u5fae\u601d\u7ef4\u5206\u5757\u673a\u5236\u5c06\u957f\u63a8\u7406\u8f68\u8ff9\u5206\u5272\u6210\u8bed\u4e49\u8fde\u8d2f\u5355\u5143\uff0c\u5728\u5341\u4e2a\u5b89\u5168\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bc4\u4f30\uff1b3) \u4eba\u7c7b\u5b89\u5168\u5bf9\u9f50\uff1a\u7528\u4e13\u95e8\u8bbe\u8ba1\u7684\u4eba\u7c7b\u6807\u6ce8\u9a8c\u8bc1\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u3002", "result": "\u5bf919\u4e2a\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u8bc4\u4f30\u8868\u660e\uff0cSafeRBench\u80fd\u591f\u8fdb\u884c\u8be6\u7ec6\u7684\u591a\u7ef4\u5ea6\u5b89\u5168\u8bc4\u4f30\uff0c\u4ece\u591a\u4e2a\u89d2\u5ea6\u63d0\u4f9b\u98ce\u9669\u548c\u4fdd\u62a4\u673a\u5236\u7684\u89c1\u89e3\u3002", "conclusion": "SafeRBench\u4e3a\u5927\u578b\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u9996\u4e2a\u7aef\u5230\u7aef\u7684\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u5168\u9762\u6355\u6349\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u52a8\u6001\u5b89\u5168\u98ce\u9669\uff0c\u586b\u8865\u4e86\u73b0\u6709\u5b89\u5168\u8bc4\u4f30\u7684\u7a7a\u767d\u3002"}}
{"id": "2511.15191", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15191", "abs": "https://arxiv.org/abs/2511.15191", "authors": ["Zhiyi Duan", "Zixing Shi", "Hongyu Yuan", "Qi Wang"], "title": "HISE-KT: Synergizing Heterogeneous Information Networks and LLMs for Explainable Knowledge Tracing with Meta-Path Optimization", "comment": null, "summary": "Knowledge Tracing (KT) aims to mine students' evolving knowledge states and predict their future question-answering performance. Existing methods based on heterogeneous information networks (HINs) are prone to introducing noises due to manual or random selection of meta-paths and lack necessary quality assessment of meta-path instances. Conversely, recent large language models (LLMs)-based methods ignore the rich information across students, and both paradigms struggle to deliver consistently accurate and evidence-based explanations. To address these issues, we propose an innovative framework, HIN-LLM Synergistic Enhanced Knowledge Tracing (HISE-KT), which seamlessly integrates HINs with LLMs. HISE-KT first builds a multi-relationship HIN containing diverse node types to capture the structural relations through multiple meta-paths. The LLM is then employed to intelligently score and filter meta-path instances and retain high-quality paths, pioneering automated meta-path quality assessment. Inspired by educational psychology principles, a similar student retrieval mechanism based on meta-paths is designed to provide a more valuable context for prediction. Finally, HISE-KT uses a structured prompt to integrate the target student's history with the retrieved similar trajectories, enabling the LLM to generate not only accurate predictions but also evidence-backed, explainable analysis reports. Experiments on four public datasets show that HISE-KT outperforms existing KT baselines in both prediction performance and interpretability.", "AI": {"tldr": "HISE-KT\u662f\u4e00\u4e2a\u7ed3\u5408\u5f02\u8d28\u4fe1\u606f\u7f51\u7edc\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u8ffd\u8e2a\u6846\u67b6\uff0c\u901a\u8fc7\u667a\u80fd\u8bc4\u5206\u7b5b\u9009\u5143\u8def\u5f84\u5b9e\u4f8b\uff0c\u57fa\u4e8e\u76f8\u4f3c\u5b66\u751f\u68c0\u7d22\u673a\u5236\uff0c\u751f\u6210\u51c6\u786e\u9884\u6d4b\u548c\u53ef\u89e3\u91ca\u5206\u6790\u62a5\u544a\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f02\u8d28\u4fe1\u606f\u7f51\u7edc\u7684\u65b9\u6cd5\u56e0\u624b\u52a8\u6216\u968f\u673a\u9009\u62e9\u5143\u8def\u5f84\u800c\u5f15\u5165\u566a\u58f0\uff0c\u7f3a\u4e4f\u5143\u8def\u5f84\u5b9e\u4f8b\u8d28\u91cf\u8bc4\u4f30\uff1b\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u5ffd\u89c6\u5b66\u751f\u95f4\u7684\u4e30\u5bcc\u4fe1\u606f\uff0c\u4e24\u79cd\u65b9\u6cd5\u90fd\u96be\u4ee5\u63d0\u4f9b\u51c6\u786e\u4e14\u57fa\u4e8e\u8bc1\u636e\u7684\u89e3\u91ca\u3002", "method": "\u6784\u5efa\u591a\u5173\u7cfb\u5f02\u8d28\u4fe1\u606f\u7f51\u7edc\u6355\u83b7\u7ed3\u6784\u5173\u7cfb\uff0c\u4f7f\u7528LLM\u667a\u80fd\u8bc4\u5206\u548c\u8fc7\u6ee4\u5143\u8def\u5f84\u5b9e\u4f8b\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u5143\u8def\u5f84\u7684\u76f8\u4f3c\u5b66\u751f\u68c0\u7d22\u673a\u5236\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u6574\u5408\u76ee\u6807\u5b66\u751f\u5386\u53f2\u548c\u76f8\u4f3c\u8f68\u8ff9\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHISE-KT\u5728\u9884\u6d4b\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u77e5\u8bc6\u8ffd\u8e2a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "HISE-KT\u6210\u529f\u6574\u5408\u4e86\u5f02\u8d28\u4fe1\u606f\u7f51\u7edc\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u7684\u77e5\u8bc6\u8ffd\u8e2a\u9884\u6d4b\u548c\u57fa\u4e8e\u8bc1\u636e\u7684\u53ef\u89e3\u91ca\u5206\u6790\u3002"}}
{"id": "2511.15192", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15192", "abs": "https://arxiv.org/abs/2511.15192", "authors": ["Haodong Li", "Jingqi Zhang", "Xiao Cheng", "Peihua Mai", "Haoyu Wang", "Yang Pan"], "title": "As If We've Met Before: LLMs Exhibit Certainty in Recognizing Seen Files", "comment": null, "summary": "The remarkable language ability of Large Language Models (LLMs) stems from extensive training on vast datasets, often including copyrighted material, which raises serious concerns about unauthorized use. While Membership Inference Attacks (MIAs) offer potential solutions for detecting such violations, existing approaches face critical limitations and challenges due to LLMs' inherent overconfidence, limited access to ground truth training data, and reliance on empirically determined thresholds.\n  We present COPYCHECK, a novel framework that leverages uncertainty signals to detect whether copyrighted content was used in LLM training sets. Our method turns LLM overconfidence from a limitation into an asset by capturing uncertainty patterns that reliably distinguish between ``seen\" (training data) and ``unseen\" (non-training data) content. COPYCHECK further implements a two-fold strategy: (1) strategic segmentation of files into smaller snippets to reduce dependence on large-scale training data, and (2) uncertainty-guided unsupervised clustering to eliminate the need for empirically tuned thresholds. Experiment results show that COPYCHECK achieves an average balanced accuracy of 90.1% on LLaMA 7b and 91.6% on LLaMA2 7b in detecting seen files. Compared to the SOTA baseline, COPYCHECK achieves over 90% relative improvement, reaching up to 93.8\\% balanced accuracy. It further exhibits strong generalizability across architectures, maintaining high performance on GPT-J 6B. This work presents the first application of uncertainty for copyright detection in LLMs, offering practical tools for training data transparency.", "AI": {"tldr": "COPYCHECK\u662f\u4e00\u4e2a\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u4fe1\u53f7\u68c0\u6d4bLLM\u8bad\u7ec3\u6570\u636e\u4e2d\u662f\u5426\u5305\u542b\u7248\u6743\u5185\u5bb9\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5c06LLM\u7684\u8fc7\u5ea6\u81ea\u4fe1\u8f6c\u5316\u4e3a\u4f18\u52bf\uff0c\u5b9e\u73b0\u65e0\u9700\u7ecf\u9a8c\u9608\u503c\u7684\u9ad8\u7cbe\u5ea6\u7248\u6743\u68c0\u6d4b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bad\u7ec3\u65f6\u53ef\u80fd\u4f7f\u7528\u4e86\u53d7\u7248\u6743\u4fdd\u62a4\u7684\u5185\u5bb9\uff0c\u73b0\u6709\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982LLM\u7684\u8fc7\u5ea6\u81ea\u4fe1\u3001\u7f3a\u4e4f\u771f\u5b9e\u8bad\u7ec3\u6570\u636e\u8bbf\u95ee\u3001\u4f9d\u8d56\u7ecf\u9a8c\u9608\u503c\u7b49\u95ee\u9898\u3002", "method": "\u91c7\u7528\u53cc\u91cd\u7b56\u7565\uff1a(1)\u5c06\u6587\u4ef6\u5206\u5272\u6210\u5c0f\u7247\u6bb5\u4ee5\u51cf\u5c11\u5bf9\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u7684\u4f9d\u8d56\uff1b(2)\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u65e0\u76d1\u7763\u805a\u7c7b\u6765\u6d88\u9664\u7ecf\u9a8c\u8c03\u4f18\u9608\u503c\u9700\u6c42\uff0c\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u6a21\u5f0f\u533a\u5206\u8bad\u7ec3\u6570\u636e\u548c\u975e\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5728LLaMA 7b\u4e0a\u5e73\u5747\u5e73\u8861\u51c6\u786e\u7387\u8fbe90.1%\uff0c\u5728LLaMA2 7b\u4e0a\u8fbe91.6%\uff0c\u76f8\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u670990%\u4ee5\u4e0a\u7684\u76f8\u5bf9\u63d0\u5347\uff0c\u6700\u9ad8\u8fbe93.8%\u5e73\u8861\u51c6\u786e\u7387\uff0c\u5e76\u5728GPT-J 6B\u4e0a\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5c06\u4e0d\u786e\u5b9a\u6027\u5e94\u7528\u4e8eLLM\u7248\u6743\u68c0\u6d4b\u7684\u5de5\u4f5c\uff0c\u4e3a\u8bad\u7ec3\u6570\u636e\u900f\u660e\u5ea6\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u6210\u529f\u5c06LLM\u8fc7\u5ea6\u81ea\u4fe1\u4ece\u9650\u5236\u8f6c\u5316\u4e3a\u4f18\u52bf\u3002"}}
{"id": "2511.15202", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15202", "abs": "https://arxiv.org/abs/2511.15202", "authors": ["Yinsheng Wang", "Tario G You", "L\u00e9onard Boussioux", "Shan Liu"], "title": "SOLID: a Framework of Synergizing Optimization and LLMs for Intelligent Decision-Making", "comment": "NeurIPS 2025 WORKSHOP ML*OR Workshop: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making", "summary": "This paper introduces SOLID (Synergizing Optimization and Large Language Models for Intelligent Decision-Making), a novel framework that integrates mathematical optimization with the contextual capabilities of large language models (LLMs). SOLID facilitates iterative collaboration between optimization and LLMs agents through dual prices and deviation penalties. This interaction improves the quality of the decisions while maintaining modularity and data privacy. The framework retains theoretical convergence guarantees under convexity assumptions, providing insight into the design of LLMs prompt. To evaluate SOLID, we applied it to a stock portfolio investment case with historical prices and financial news as inputs. Empirical results demonstrate convergence under various scenarios and indicate improved annualized returns compared to a baseline optimizer-only method, validating the synergy of the two agents. SOLID offers a promising framework for advancing automated and intelligent decision-making across diverse domains.", "AI": {"tldr": "SOLID\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u6570\u5b66\u4f18\u5316\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5229\u7528\u5bf9\u5076\u4ef7\u683c\u548c\u504f\u5dee\u60e9\u7f5a\u5b9e\u73b0\u8fed\u4ee3\u534f\u4f5c\uff0c\u5728\u4fdd\u6301\u6a21\u5757\u5316\u548c\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u63d0\u5347\u51b3\u7b56\u8d28\u91cf\uff0c\u5728\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u7eaf\u4f18\u5316\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5229\u7528\u6570\u5b66\u4f18\u5316\u7684\u7cbe\u786e\u6027\u548cLLMs\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u534f\u540c\u4e24\u8005\u4f18\u52bf\u7684\u6846\u67b6\u6765\u63d0\u5347\u667a\u80fd\u51b3\u7b56\u8d28\u91cf\u3002", "method": "\u63d0\u51faSOLID\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u4ee3\u7406\u548cLLM\u4ee3\u7406\u7684\u8fed\u4ee3\u534f\u4f5c\uff0c\u4f7f\u7528\u5bf9\u5076\u4ef7\u683c\u548c\u504f\u5dee\u60e9\u7f5a\u673a\u5236\u8fdb\u884c\u4ea4\u4e92\uff0c\u5728\u51f8\u6027\u5047\u8bbe\u4e0b\u4fdd\u6301\u7406\u8bba\u6536\u655b\u6027\u3002", "result": "\u5728\u80a1\u7968\u6295\u8d44\u7ec4\u5408\u6848\u4f8b\u4e2d\uff0cSOLID\u5728\u5404\u79cd\u573a\u666f\u4e0b\u90fd\u8868\u73b0\u51fa\u6536\u655b\u6027\uff0c\u5e74\u5316\u6536\u76ca\u7387\u76f8\u6bd4\u7eaf\u4f18\u5316\u57fa\u7ebf\u65b9\u6cd5\u6709\u6240\u63d0\u5347\u3002", "conclusion": "SOLID\u4e3a\u8de8\u9886\u57df\u7684\u81ea\u52a8\u5316\u548c\u667a\u80fd\u51b3\u7b56\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u6846\u67b6\uff0c\u9a8c\u8bc1\u4e86\u4f18\u5316\u4e0eLLM\u534f\u540c\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.15259", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.15259", "abs": "https://arxiv.org/abs/2511.15259", "authors": ["Philipp Wiesner", "Daniel W. O'Neill", "Francesca Larosa", "Odej Kao"], "title": "Efficiency Will Not Lead to Sustainable Reasoning AI", "comment": "Presented at the Rethinking AI Workshop @ EurIPS'25", "summary": "AI research is increasingly moving toward complex problem solving, where models are optimized not only for pattern recognition but for multi-step reasoning. Historically, computing's global energy footprint has been stabilized by sustained efficiency gains and natural saturation thresholds in demand. But as efficiency improvements are approaching physical limits, emerging reasoning AI lacks comparable saturation points: performance is no longer limited by the amount of available training data but continues to scale with exponential compute investments in both training and inference. This paper argues that efficiency alone will not lead to sustainable reasoning AI and discusses research and policy directions to embed explicit limits into the optimization and governance of such systems.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\uff0c\u968f\u7740AI\u7814\u7a76\u8f6c\u5411\u590d\u6742\u95ee\u9898\u89e3\u51b3\uff0c\u63a8\u7406AI\u7684\u6027\u80fd\u4e0d\u518d\u53d7\u9650\u4e8e\u8bad\u7ec3\u6570\u636e\u91cf\uff0c\u800c\u662f\u968f\u7740\u8bad\u7ec3\u548c\u63a8\u7406\u7684\u6307\u6570\u7ea7\u8ba1\u7b97\u6295\u5165\u800c\u6301\u7eed\u6269\u5c55\u3002\u6548\u7387\u63d0\u5347\u5df2\u63a5\u8fd1\u7269\u7406\u6781\u9650\uff0c\u9700\u8981\u5c06\u663e\u6027\u9650\u5236\u5d4c\u5165\u63a8\u7406AI\u7684\u4f18\u5316\u548c\u6cbb\u7406\u4e2d\u3002", "motivation": "AI\u7814\u7a76\u6b63\u4ece\u6a21\u5f0f\u8bc6\u522b\u8f6c\u5411\u591a\u6b65\u63a8\u7406\uff0c\u800c\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u5df2\u63a5\u8fd1\u7269\u7406\u6781\u9650\u3002\u63a8\u7406AI\u7f3a\u4e4f\u9700\u6c42\u9971\u548c\u70b9\uff0c\u6027\u80fd\u6301\u7eed\u968f\u6307\u6570\u7ea7\u8ba1\u7b97\u6295\u5165\u6269\u5c55\uff0c\u4ec5\u9760\u6548\u7387\u65e0\u6cd5\u5b9e\u73b0\u53ef\u6301\u7eed\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u8ba1\u7b97\u80fd\u6548\u8d8b\u52bf\u548c\u63a8\u7406AI\u7684\u6269\u5c55\u7279\u6027\uff0c\u8bba\u8bc1\u6548\u7387\u63d0\u5347\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u9700\u8981\u5c06\u663e\u6027\u9650\u5236\u5d4c\u5165\u7cfb\u7edf\u4f18\u5316\u548c\u6cbb\u7406\u7684\u7814\u7a76\u548c\u653f\u7b56\u65b9\u5411\u3002", "result": "\u53d1\u73b0\u63a8\u7406AI\u7684\u6027\u80fd\u6269\u5c55\u4e0d\u53d7\u6570\u636e\u91cf\u9650\u5236\uff0c\u800c\u662f\u6301\u7eed\u4f9d\u8d56\u6307\u6570\u7ea7\u8ba1\u7b97\u6295\u5165\uff0c\u6548\u7387\u63d0\u5347\u65e0\u6cd5\u5355\u72ec\u89e3\u51b3\u53ef\u6301\u7eed\u6027\u95ee\u9898\u3002", "conclusion": "\u4ec5\u9760\u6548\u7387\u63d0\u5347\u65e0\u6cd5\u5b9e\u73b0\u53ef\u6301\u7eed\u7684\u63a8\u7406AI\uff0c\u9700\u8981\u5728\u4f18\u5316\u548c\u6cbb\u7406\u4e2d\u5d4c\u5165\u663e\u6027\u9650\u5236\uff0c\u8fd9\u662f\u672a\u6765\u7814\u7a76\u548c\u653f\u7b56\u7684\u5173\u952e\u65b9\u5411\u3002"}}
{"id": "2511.15282", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15282", "abs": "https://arxiv.org/abs/2511.15282", "authors": ["Ninell Oldenburg", "Ruchira Dhar", "Anders S\u00f8gaard"], "title": "Realist and Pluralist Conceptions of Intelligence and Their Implications on AI Research", "comment": "The 40th Annual AAAI Conference on Artificial Intelligence, 8 pages (excl. references), 1 table", "summary": "In this paper, we argue that current AI research operates on a spectrum between two different underlying conceptions of intelligence: Intelligence Realism, which holds that intelligence represents a single, universal capacity measurable across all systems, and Intelligence Pluralism, which views intelligence as diverse, context-dependent capacities that cannot be reduced to a single universal measure. Through an analysis of current debates in AI research, we demonstrate how the conceptions remain largely implicit yet fundamentally shape how empirical evidence gets interpreted across a wide range of areas. These underlying views generate fundamentally different research approaches across three areas. Methodologically, they produce different approaches to model selection, benchmark design, and experimental validation. Interpretively, they lead to contradictory readings of the same empirical phenomena, from capability emergence to system limitations. Regarding AI risk, they generate categorically different assessments: realists view superintelligence as the primary risk and search for unified alignment solutions, while pluralists see diverse threats across different domains requiring context-specific solutions. We argue that making explicit these underlying assumptions can contribute to a clearer understanding of disagreements in AI research.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86AI\u7814\u7a76\u4e2d\u4e24\u79cd\u5bf9\u7acb\u7684\u60c5\u62a5\u89c2\uff1a\u60c5\u62a5\u73b0\u5b9e\u4e3b\u4e49\u8ba4\u4e3a\u60c5\u62a5\u662f\u5355\u4e00\u901a\u7528\u80fd\u529b\uff0c\u60c5\u62a5\u591a\u5143\u4e3b\u4e49\u8ba4\u4e3a\u60c5\u62a5\u662f\u591a\u6837\u5316\u7684\u60c5\u5883\u4f9d\u8d56\u80fd\u529b\u3002\u8fd9\u4e24\u79cd\u89c2\u70b9\u5728\u65b9\u6cd5\u8bba\u3001\u89e3\u91ca\u548c\u98ce\u9669\u8bc4\u4f30\u65b9\u9762\u4ea7\u751f\u6839\u672c\u4e0d\u540c\u7684\u7814\u7a76\u8def\u5f84\u3002", "motivation": "\u63ed\u793aAI\u7814\u7a76\u4e2d\u9690\u542b\u7684\u4e24\u79cd\u57fa\u672c\u60c5\u62a5\u89c2\u5ff5\u5982\u4f55\u5f71\u54cd\u7814\u7a76\u5b9e\u8df5\u548c\u4e89\u8bae\uff0c\u5e2e\u52a9\u6f84\u6e05\u8be5\u9886\u57df\u7684\u6839\u672c\u5206\u6b67\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5f53\u524dAI\u7814\u7a76\u4e2d\u7684\u8fa9\u8bba\uff0c\u5c55\u793a\u4e24\u79cd\u60c5\u62a5\u89c2\u5ff5\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u9009\u62e9\u3001\u57fa\u51c6\u8bbe\u8ba1\u3001\u5b9e\u9a8c\u9a8c\u8bc1\u3001\u73b0\u8c61\u89e3\u91ca\u548c\u98ce\u9669\u8bc4\u4f30\u3002", "result": "\u53d1\u73b0\u60c5\u62a5\u73b0\u5b9e\u4e3b\u4e49\u8005\u548c\u591a\u5143\u4e3b\u4e49\u8005\u5728\u65b9\u6cd5\u8bba\u3001\u89e3\u91ca\u6846\u67b6\u548c\u98ce\u9669\u8bc4\u4f30\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u8fd9\u4e9b\u5dee\u5f02\u6e90\u4e8e\u5bf9\u60c5\u62a5\u672c\u8d28\u7684\u6839\u672c\u4e0d\u540c\u7406\u89e3\u3002", "conclusion": "\u660e\u786e\u8fd9\u4e9b\u57fa\u672c\u5047\u8bbe\u6709\u52a9\u4e8e\u66f4\u6e05\u6670\u5730\u7406\u89e3AI\u7814\u7a76\u4e2d\u7684\u5206\u6b67\uff0c\u4fc3\u8fdb\u66f4\u5bcc\u6709\u6210\u6548\u7684\u5b66\u672f\u5bf9\u8bdd\u3002"}}
{"id": "2511.15351", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.15351", "abs": "https://arxiv.org/abs/2511.15351", "authors": ["Yifu Guo", "Zishan Xu", "Zhiyuan Yao", "Yuquan Lu", "Jiaye Lin", "Sen Hu", "Zhenheng Tang", "Yingchao Li", "Huacan Wang", "Ronghao Chen"], "title": "Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration", "comment": null, "summary": "Existing multimodal reasoning models and frameworks suffer from fundamental architectural limitations: most lack the human-like ability to autonomously explore diverse reasoning pathways-whether in direct inference, tool-driven visual exploration, programmatic visual manipulation, or intrinsic visual imagination. Consequently, they struggle to adapt to dynamically changing capability requirements in real-world tasks. Meanwhile, humans exhibit a complementary set of thinking abilities when addressing such tasks, whereas existing methods typically cover only a subset of these dimensions. Inspired by this, we propose Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration, a new paradigm for multimodal agentic reasoning. We define six core capabilities essential for multimodal reasoning and organize a comprehensive evaluation benchmark, Octopus-Bench, accordingly. Octopus is capable of autonomously exploring during reasoning and dynamically selecting the most appropriate capability based on the current state. Experimental results show that Octopus achieves the best performance on the vast majority of tasks in Octopus-Bench, highlighting the crucial role of capability coordination in agentic multimodal reasoning.", "AI": {"tldr": "Octopus\u662f\u4e00\u4e2a\u65b0\u7684\u591a\u6a21\u6001\u63a8\u7406\u8303\u5f0f\uff0c\u901a\u8fc7\u534f\u8c03\u516d\u79cd\u6838\u5fc3\u80fd\u529b\u5b9e\u73b0\u81ea\u4e3b\u63a8\u7406\u8def\u5f84\u63a2\u7d22\u548c\u52a8\u6001\u80fd\u529b\u9009\u62e9\uff0c\u5728Octopus-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\u5b58\u5728\u67b6\u6784\u9650\u5236\uff0c\u7f3a\u4e4f\u81ea\u4e3b\u63a2\u7d22\u591a\u6837\u5316\u63a8\u7406\u8def\u5f84\u7684\u80fd\u529b\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u53d8\u5316\u7684\u4efb\u52a1\u9700\u6c42\uff0c\u800c\u4eba\u7c7b\u5177\u5907\u4e92\u8865\u7684\u601d\u7ef4\u80fd\u529b\u3002", "method": "\u63d0\u51faOctopus\u6846\u67b6\uff0c\u5b9a\u4e49\u516d\u79cd\u6838\u5fc3\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\uff0c\u6784\u5efaOctopus-Bench\u8bc4\u4f30\u57fa\u51c6\uff0c\u5b9e\u73b0\u81ea\u4e3b\u63a8\u7406\u63a2\u7d22\u548c\u52a8\u6001\u80fd\u529b\u9009\u62e9\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aOctopus\u5728Octopus-Bench\u5927\u591a\u6570\u4efb\u52a1\u4e2d\u53d6\u5f97\u6700\u4f73\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u80fd\u529b\u534f\u8c03\u5728\u591a\u6a21\u6001\u63a8\u7406\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u80fd\u529b\u534f\u8c03\u662f\u667a\u80fd\u591a\u6a21\u6001\u63a8\u7406\u7684\u5173\u952e\uff0cOctopus\u901a\u8fc7\u516d\u79cd\u80fd\u529b\u534f\u540c\u5de5\u4f5c\u5c55\u793a\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2511.15378", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15378", "abs": "https://arxiv.org/abs/2511.15378", "authors": ["Trevor McInroe"], "title": "Terra Nova: A Comprehensive Challenge Environment for Intelligent Agents", "comment": null, "summary": "We introduce Terra Nova, a new comprehensive challenge environment (CCE) for reinforcement learning (RL) research inspired by Civilization V. A CCE is a single environment in which multiple canonical RL challenges (e.g., partial observability, credit assignment, representation learning, enormous action spaces, etc.) arise simultaneously. Mastery therefore demands integrated, long-horizon understanding across many interacting variables. We emphasize that this definition excludes challenges that only aggregate unrelated tasks in independent, parallel streams (e.g., learning to play all Atari games at once). These aggregated multitask benchmarks primarily asses whether an agent can catalog and switch among unrelated policies rather than test an agent's ability to perform deep reasoning across many interacting challenges.", "AI": {"tldr": "Terra Nova\u662f\u4e00\u4e2a\u57fa\u4e8e\u300a\u6587\u660eV\u300b\u7684\u7efc\u5408\u6027\u6311\u6218\u73af\u5883\uff0c\u65e8\u5728\u540c\u65f6\u6d4b\u8bd5\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u3001\u4fe1\u7528\u5206\u914d\u3001\u8868\u793a\u5b66\u4e60\u3001\u5de8\u5927\u52a8\u4f5c\u7a7a\u95f4\u7b49\u591a\u4e2a\u7ecf\u5178\u6311\u6218\u4e0a\u7684\u7efc\u5408\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u4efb\u52a1\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u65e0\u5173\u4efb\u52a1\u95f4\u5207\u6362\u7b56\u7565\u7684\u80fd\u529b\uff0c\u800c\u975e\u6d4b\u8bd5\u667a\u80fd\u4f53\u5728\u591a\u4e2a\u76f8\u4e92\u5173\u8054\u6311\u6218\u4e2d\u8fdb\u884c\u6df1\u5ea6\u63a8\u7406\u7684\u80fd\u529b\u3002\u9700\u8981\u521b\u5efa\u80fd\u771f\u6b63\u6d4b\u8bd5\u7efc\u5408\u63a8\u7406\u80fd\u529b\u7684\u73af\u5883\u3002", "method": "\u57fa\u4e8e\u300a\u6587\u660eV\u300b\u6e38\u620f\u6784\u5efa\u7efc\u5408\u6027\u6311\u6218\u73af\u5883\uff0c\u8ba9\u591a\u4e2a\u7ecf\u5178RL\u6311\u6218\u540c\u65f6\u51fa\u73b0\uff0c\u8981\u6c42\u667a\u80fd\u4f53\u5177\u5907\u8de8\u591a\u4e2a\u4ea4\u4e92\u53d8\u91cf\u7684\u96c6\u6210\u3001\u957f\u89c6\u91ce\u7406\u89e3\u80fd\u529b\u3002", "result": "\u63d0\u51fa\u4e86Terra Nova\u73af\u5883\uff0c\u533a\u522b\u4e8e\u4ec5\u805a\u5408\u65e0\u5173\u4efb\u52a1\u7684\u5e76\u884c\u6d41\u591a\u4efb\u52a1\u57fa\u51c6\uff0c\u5f3a\u8c03\u6311\u6218\u7684\u76f8\u4e92\u5173\u8054\u6027\u3002", "conclusion": "Terra Nova\u4e3aRL\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u7684\u7efc\u5408\u6027\u6d4b\u8bd5\u5e73\u53f0\uff0c\u80fd\u591f\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u590d\u6742\u4ea4\u4e92\u73af\u5883\u4e2d\u7684\u6df1\u5ea6\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2511.15407", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.15407", "abs": "https://arxiv.org/abs/2511.15407", "authors": ["Mingyu Zhang", "Lifeng Zhuo", "Tianxi Tan", "Guocan Xie", "Xian Nie", "Yan Li", "Renjie Zhao", "Zizhu He", "Ziyu Wang", "Jiting Cai", "Yong-Lu Li"], "title": "IPR-1: Interactive Physical Reasoner", "comment": "11 pages, 5 figures", "summary": "Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. We study this in a Game-to-Unseen (G2U) setting, curating 1,000+ heterogeneous games with diverse physical and causal mechanisms, and evaluate at three human-like levels: Survival, Curiosity, Utility, from primitive intuition to goal-driven reasoning. Our analysis reveals complementary failures: VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on three levels, matches GPT-5 overall, and surpasses it on Curiosity. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faIPR\uff08\u4ea4\u4e92\u5f0f\u7269\u7406\u63a8\u7406\u5668\uff09\uff0c\u901a\u8fc7\u4e16\u754c\u6a21\u578b\u63a8\u6f14\u6765\u589e\u5f3aVLM\u7684\u7b56\u7565\uff0c\u5e76\u4f7f\u7528PhysCode\u5c06\u8bed\u4e49\u610f\u56fe\u4e0e\u7269\u7406\u52a8\u529b\u5b66\u5bf9\u9f50\uff0c\u57281000+\u6e38\u620f\u4e2d\u8bad\u7ec3\u540e\uff0c\u5728\u4e09\u4e2a\u63a8\u7406\u7ea7\u522b\u4e0a\u8868\u73b0\u7a33\u5065\uff0c\u603b\u4f53\u4e0eGPT-5\u76f8\u5f53\uff0c\u5728\u597d\u5947\u5fc3\u7ea7\u522b\u4e0a\u8d85\u8d8aGPT-5\u3002", "motivation": "\u7814\u7a76\u667a\u80fd\u4f53\u662f\u5426\u80fd\u591f\u50cf\u4eba\u7c7b\u4e00\u6837\u901a\u8fc7\u4ea4\u4e92\u83b7\u5f97\u7269\u7406\u548c\u56e0\u679c\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5728\u66f4\u591a\u7ecf\u9a8c\u4e2d\u6301\u7eed\u6539\u8fdb\u3002", "method": "\u63d0\u51faIPR\u6846\u67b6\uff0c\u4f7f\u7528\u4e16\u754c\u6a21\u578b\u63a8\u6f14\u6765\u8bc4\u5206\u548c\u5f3a\u5316VLM\u7684\u7b56\u7565\uff1b\u5f15\u5165PhysCode\uff0c\u4e00\u79cd\u4ee5\u7269\u7406\u4e3a\u4e2d\u5fc3\u7684\u52a8\u4f5c\u7f16\u7801\uff0c\u5c06\u8bed\u4e49\u610f\u56fe\u4e0e\u52a8\u529b\u5b66\u5bf9\u9f50\uff0c\u4e3a\u9884\u6d4b\u548c\u63a8\u7406\u63d0\u4f9b\u5171\u4eab\u52a8\u4f5c\u7a7a\u95f4\u3002", "result": "\u57281000+\u6e38\u620f\u4e0a\u9884\u8bad\u7ec3\u540e\uff0cIPR\u5728\u4e09\u4e2a\u63a8\u7406\u7ea7\u522b\uff08\u751f\u5b58\u3001\u597d\u5947\u5fc3\u3001\u5b9e\u7528\u6027\uff09\u8868\u73b0\u7a33\u5065\uff0c\u603b\u4f53\u4e0eGPT-5\u5339\u914d\uff0c\u5728\u597d\u5947\u5fc3\u7ea7\u522b\u8d85\u8d8aGPT-5\uff1b\u6027\u80fd\u968f\u8bad\u7ec3\u6e38\u620f\u548c\u4ea4\u4e92\u6b65\u9aa4\u589e\u52a0\u800c\u63d0\u5347\uff0c\u5e76\u80fd\u96f6\u6837\u672c\u8fc1\u79fb\u5230\u672a\u89c1\u6e38\u620f\u3002", "conclusion": "\u4ee5\u7269\u7406\u4e3a\u4e2d\u5fc3\u7684\u4ea4\u4e92\u662f\u6301\u7eed\u6539\u8fdb\u7269\u7406\u63a8\u7406\u80fd\u529b\u7684\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2511.15456", "categories": ["cs.AI", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2511.15456", "abs": "https://arxiv.org/abs/2511.15456", "authors": ["Qian'ang Mao", "Yuxuan Zhang", "Jiaman Chen", "Wenjun Zhou", "Jiaqi Yan"], "title": "Know Your Intent: An Autonomous Multi-Perspective LLM Agent Framework for DeFi User Transaction Intent Mining", "comment": "Written in 2025 Q1", "summary": "As Decentralized Finance (DeFi) develops, understanding user intent behind DeFi transactions is crucial yet challenging due to complex smart contract interactions, multifaceted on-/off-chain factors, and opaque hex logs. Existing methods lack deep semantic insight. To address this, we propose the Transaction Intent Mining (TIM) framework. TIM leverages a DeFi intent taxonomy built on grounded theory and a multi-agent Large Language Model (LLM) system to robustly infer user intents. A Meta-Level Planner dynamically coordinates domain experts to decompose multiple perspective-specific intent analyses into solvable subtasks. Question Solvers handle the tasks with multi-modal on/off-chain data. While a Cognitive Evaluator mitigates LLM hallucinations and ensures verifiability. Experiments show that TIM significantly outperforms machine learning models, single LLMs, and single Agent baselines. We also analyze core challenges in intent inference. This work helps provide a more reliable understanding of user motivations in DeFi, offering context-aware explanations for complex blockchain activity.", "AI": {"tldr": "\u63d0\u51fa\u4e86TIM\u6846\u67b6\uff0c\u901a\u8fc7DeFi\u610f\u56fe\u5206\u7c7b\u6cd5\u548c\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u6765\u63a8\u65ad\u7528\u6237\u4ea4\u6613\u610f\u56fe\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "DeFi\u4ea4\u6613\u7406\u89e3\u56f0\u96be\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u6df1\u5ea6\u8bed\u4e49\u6d1e\u5bdf\uff0c\u9700\u8981\u89e3\u51b3\u590d\u6742\u667a\u80fd\u5408\u7ea6\u4ea4\u4e92\u3001\u591a\u56e0\u7d20\u5206\u6790\u548c\u4e0d\u900f\u660e\u65e5\u5fd7\u7684\u95ee\u9898\u3002", "method": "\u6784\u5efaDeFi\u610f\u56fe\u5206\u7c7b\u6cd5\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\uff0c\u5305\u62ec\u5143\u7ea7\u89c4\u5212\u5668\u52a8\u6001\u534f\u8c03\u9886\u57df\u4e13\u5bb6\u3001\u95ee\u9898\u6c42\u89e3\u5668\u5904\u7406\u591a\u6a21\u6001\u6570\u636e\u3001\u8ba4\u77e5\u8bc4\u4f30\u5668\u51cf\u8f7b\u5e7b\u89c9\u3002", "result": "TIM\u6846\u67b6\u5728\u5b9e\u9a8c\u4e2d\u663e\u8457\u4f18\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3001\u5355LLM\u548c\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3aDeFi\u4e2d\u7528\u6237\u52a8\u673a\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u7406\u89e3\uff0c\u4e3a\u590d\u6742\u533a\u5757\u94fe\u6d3b\u52a8\u63d0\u4f9b\u4e0a\u4e0b\u6587\u611f\u77e5\u89e3\u91ca\u3002"}}
{"id": "2511.15534", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15534", "abs": "https://arxiv.org/abs/2511.15534", "authors": ["Federico Bianchi", "Owen Queen", "Nitya Thakkar", "Eric Sun", "James Zou"], "title": "Exploring the use of AI authors and reviewers at Agents4Science", "comment": null, "summary": "There is growing interest in using AI agents for scientific research, yet fundamental questions remain about their capabilities as scientists and reviewers. To explore these questions, we organized Agents4Science, the first conference in which AI agents serve as both primary authors and reviewers, with humans as co-authors and co-reviewers. Here, we discuss the key learnings from the conference and their implications for human-AI collaboration in science.", "AI": {"tldr": "AI agents\u4f5c\u4e3a\u4f5c\u8005\u548c\u5ba1\u7a3f\u4eba\u53c2\u4e0e\u7684\u9996\u4e2a\u79d1\u5b66\u4f1a\u8baeAgents4Science\uff0c\u63a2\u8ba8\u4e86AI\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u80fd\u529b\u548c\u4eba\u673a\u534f\u4f5c\u6a21\u5f0f\u3002", "motivation": "\u63a2\u7d22AI\u4ee3\u7406\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u4f5c\u4e3a\u79d1\u5b66\u5bb6\u548c\u5ba1\u7a3f\u4eba\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u4eba\u673a\u534f\u4f5c\u5728\u79d1\u5b66\u9886\u57df\u7684\u6f5c\u529b\u3002", "method": "\u7ec4\u7ec7Agents4Science\u4f1a\u8bae\uff0c\u8ba9AI\u4ee3\u7406\u62c5\u4efb\u4e3b\u8981\u4f5c\u8005\u548c\u5ba1\u7a3f\u4eba\uff0c\u4eba\u7c7b\u4f5c\u4e3a\u5408\u8457\u8005\u548c\u5171\u540c\u5ba1\u7a3f\u4eba\u53c2\u4e0e\u3002", "result": "\u83b7\u5f97\u4e86\u5173\u4e8eAI\u4ee3\u7406\u5728\u79d1\u5b66\u7814\u7a76\u548c\u8bc4\u5ba1\u4e2d\u80fd\u529b\u7684\u91cd\u8981\u89c1\u89e3\uff0c\u4ee5\u53ca\u4eba\u673a\u534f\u4f5c\u6a21\u5f0f\u7684\u7ecf\u9a8c\u3002", "conclusion": "\u8be5\u4f1a\u8bae\u4e3a\u7406\u89e3AI\u5728\u79d1\u5b66\u4e2d\u7684\u89d2\u8272\u548c\u4eba\u673a\u534f\u4f5c\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u7ecf\u9a8c\uff0c\u5bf9\u672a\u6765\u7684\u79d1\u5b66\u5408\u4f5c\u6a21\u5f0f\u5177\u6709\u542f\u793a\u610f\u4e49\u3002"}}
{"id": "2511.15593", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15593", "abs": "https://arxiv.org/abs/2511.15593", "authors": ["Alexis Audran-Reiss", "Jordi Armengol Estap\u00e9", "Karen Hambardzumyan", "Amar Budhiraja", "Martin Josifoski", "Edan Toledo", "Rishi Hazra", "Despoina Magka", "Michael Shvartsman", "Parth Pathak", "Justine T Kao", "Lucia Cipolina-Kun", "Bhavul Gauri", "Jean-Christophe Gagnon-Audet", "Emanuel Tewolde", "Jenny Zhang", "Taco Cohen", "Yossi Adi", "Tatiana Shavrina", "Yoram Bachrach"], "title": "What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity", "comment": null, "summary": "AI research agents offer the promise to accelerate scientific progress by automating the design, implementation, and training of machine learning models. However, the field is still in its infancy, and the key factors driving the success or failure of agent trajectories are not fully understood. We examine the role that ideation diversity plays in agent performance. First, we analyse agent trajectories on MLE-bench, a well-known benchmark to evaluate AI research agents, across different models and agent scaffolds. Our analysis reveals that different models and agent scaffolds yield varying degrees of ideation diversity, and that higher-performing agents tend to have increased ideation diversity. Further, we run a controlled experiment where we modify the degree of ideation diversity, demonstrating that higher ideation diversity results in stronger performance. Finally, we strengthen our results by examining additional evaluation metrics beyond the standard medal-based scoring of MLE-bench, showing that our findings still hold across other agent performance metrics.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86AI\u7814\u7a76\u4ee3\u7406\u4e2d\u6784\u601d\u591a\u6837\u6027\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5728MLE-bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6784\u601d\u591a\u6837\u6027\u66f4\u9ad8\u7684\u4ee3\u7406\u8868\u73b0\u66f4\u597d\uff0c\u5e76\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u56e0\u679c\u5173\u7cfb\u3002", "motivation": "AI\u7814\u7a76\u4ee3\u7406\u6709\u671b\u52a0\u901f\u79d1\u5b66\u8fdb\u6b65\uff0c\u4f46\u8be5\u9886\u57df\u4ecd\u5904\u4e8e\u65e9\u671f\u9636\u6bb5\uff0c\u6210\u529f\u6216\u5931\u8d25\u7684\u5173\u952e\u56e0\u7d20\u5c1a\u672a\u5b8c\u5168\u7406\u89e3\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76\u6784\u601d\u591a\u6837\u6027\u5728\u4ee3\u7406\u6027\u80fd\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u9996\u5148\u5206\u6790MLE-bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0d\u540c\u6a21\u578b\u548c\u4ee3\u7406\u6846\u67b6\u7684\u8f68\u8ff9\uff0c\u7136\u540e\u8fdb\u884c\u63a7\u5236\u5b9e\u9a8c\u8c03\u8282\u6784\u601d\u591a\u6837\u6027\u7a0b\u5ea6\uff0c\u6700\u540e\u4f7f\u7528\u9664\u6807\u51c6\u5956\u724c\u8bc4\u5206\u5916\u7684\u5176\u4ed6\u8bc4\u4f30\u6307\u6807\u9a8c\u8bc1\u7ed3\u679c\u3002", "result": "\u5206\u6790\u663e\u793a\u4e0d\u540c\u6a21\u578b\u548c\u4ee3\u7406\u6846\u67b6\u4ea7\u751f\u4e0d\u540c\u7a0b\u5ea6\u7684\u6784\u601d\u591a\u6837\u6027\uff0c\u6027\u80fd\u66f4\u9ad8\u7684\u4ee3\u7406\u5f80\u5f80\u5177\u6709\u66f4\u9ad8\u7684\u6784\u601d\u591a\u6837\u6027\u3002\u63a7\u5236\u5b9e\u9a8c\u8bc1\u5b9e\u66f4\u9ad8\u7684\u6784\u601d\u591a\u6837\u6027\u786e\u5b9e\u5bfc\u81f4\u66f4\u5f3a\u7684\u6027\u80fd\u3002", "conclusion": "\u6784\u601d\u591a\u6837\u6027\u662fAI\u7814\u7a76\u4ee3\u7406\u6027\u80fd\u7684\u91cd\u8981\u9a71\u52a8\u56e0\u7d20\uff0c\u8fd9\u4e00\u53d1\u73b0\u5728\u591a\u79cd\u8bc4\u4f30\u6307\u6807\u4e0b\u5747\u6210\u7acb\uff0c\u4e3a\u4f18\u5316AI\u7814\u7a76\u4ee3\u7406\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
