{"id": "2509.05447", "categories": ["cs.NI", "cs.DM", "cs.LG", "eess.SP", "05-08", "C.2.1; I.2.8; G.2.2"], "pdf": "https://arxiv.org/pdf/2509.05447", "abs": "https://arxiv.org/abs/2509.05447", "authors": ["Zhongyuan Zhao", "Gunjan Verma", "Ananthram Swami", "Santiago Segarra"], "title": "Distributed Link Sparsification for Scalable Scheduling Using Graph Neural Networks (Journal Version)", "comment": "15 pages, 18 figures, accepted to IEEE Transactions on Wireless\n  Communications. This is the extended journal version of the conference paper\n  arXiv:2203.14339 (Z. Zhao, A. Swami and S. Segarra, \"Distributed Link\n  Sparsification for Scalable Scheduling using Graph Neural Networks,\" IEEE\n  ICASSP 2022, pp. 5308-5312, doi: 10.1109/ICASSP43922.2022.9747437 )", "summary": "In wireless networks characterized by dense connectivity, the significant\nsignaling overhead generated by distributed link scheduling algorithms can\nexacerbate issues like congestion, energy consumption, and radio footprint\nexpansion. To mitigate these challenges, we propose a distributed link\nsparsification scheme employing graph neural networks (GNNs) to reduce\nscheduling overhead for delay-tolerant traffic while maintaining network\ncapacity. A GNN module is trained to adjust contention thresholds for\nindividual links based on traffic statistics and network topology, enabling\nlinks to withdraw from scheduling contention when they are unlikely to succeed.\nOur approach is facilitated by a novel offline constrained {unsupervised}\nlearning algorithm capable of balancing two competing objectives: minimizing\nscheduling overhead while ensuring that total utility meets the required level.\nIn simulated wireless multi-hop networks with up to 500 links, our link\nsparsification technique effectively alleviates network congestion and reduces\nradio footprints across four distinct distributed link scheduling protocols.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5206\u5e03\u5f0f\u94fe\u8def\u7a00\u758f\u5316\u65b9\u6848\uff0c\u901a\u8fc7\u8c03\u6574\u7ade\u4e89\u9608\u503c\u51cf\u5c11\u5ef6\u8fdf\u5bb9\u5fcd\u4e1a\u52a1\u7684\u8c03\u5ea6\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u7f51\u7edc\u5bb9\u91cf\u3002", "motivation": "\u5bc6\u96c6\u65e0\u7ebf\u7f51\u7edc\u4e2d\u5206\u5e03\u5f0f\u94fe\u8def\u8c03\u5ea6\u7b97\u6cd5\u4ea7\u751f\u5927\u91cf\u4fe1\u4ee4\u5f00\u9500\uff0c\u5bfc\u81f4\u62e5\u585e\u3001\u80fd\u8017\u548c\u65e0\u7ebf\u7535\u8db3\u8ff9\u6269\u5927\u7b49\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u6a21\u5757\uff0c\u57fa\u4e8e\u6d41\u91cf\u7edf\u8ba1\u548c\u7f51\u7edc\u62d3\u6251\u8c03\u6574\u5404\u94fe\u8def\u7684\u7ade\u4e89\u9608\u503c\uff0c\u4f7f\u4e0d\u592a\u53ef\u80fd\u6210\u529f\u7684\u94fe\u8def\u9000\u51fa\u8c03\u5ea6\u7ade\u4e89\u3002\u91c7\u7528\u79bb\u7ebf\u7ea6\u675f\u65e0\u76d1\u7763\u5b66\u4e60\u7b97\u6cd5\u5e73\u8861\u6700\u5c0f\u5316\u8c03\u5ea6\u5f00\u9500\u548c\u786e\u4fdd\u603b\u6548\u7528\u8fbe\u6807\u4e24\u4e2a\u76ee\u6807\u3002", "result": "\u5728\u6700\u591a500\u4e2a\u94fe\u8def\u7684\u6a21\u62df\u65e0\u7ebf\u591a\u8df3\u7f51\u7edc\u4e2d\uff0c\u8be5\u6280\u672f\u6709\u6548\u7f13\u89e3\u4e86\u7f51\u7edc\u62e5\u585e\u5e76\u51cf\u5c11\u4e86\u56db\u4e2a\u4e0d\u540c\u5206\u5e03\u5f0f\u94fe\u8def\u8c03\u5ea6\u534f\u8bae\u7684\u65e0\u7ebf\u7535\u8db3\u8ff9\u3002", "conclusion": "\u57fa\u4e8eGNN\u7684\u94fe\u8def\u7a00\u758f\u5316\u65b9\u6848\u80fd\u591f\u663e\u8457\u964d\u4f4e\u8c03\u5ea6\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u7f51\u7edc\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5bc6\u96c6\u65e0\u7ebf\u7f51\u7edc\u73af\u5883\u3002"}}
{"id": "2509.05467", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.05467", "abs": "https://arxiv.org/abs/2509.05467", "authors": ["Reshma Prasad", "Maxime Elkael", "Gabriele Gemmi", "Osama M. Bushnaq", "Debashisha Mishra", "Prasanna Raut", "Jennifer Simonjan", "Michele Polese", "Tommaso Melodia"], "title": "Joint Routing, Resource Allocation, and Energy Optimization for Integrated Access and Backhaul with Open RAN", "comment": null, "summary": "As networks evolve towards 6G, Mobile Network Operators (MNOs) must\naccommodate diverse requirements and at the same time manage rising energy\nconsumption. Integrated Access and Backhaul (IAB) networks facilitate dense\ncellular deployments with reduced infrastructure complexity. However, the\nmulti-hop wireless backhauling in IAB networks necessitates proper routing and\nresource allocation decisions to meet the performance requirements. At the same\ntime, cell densification makes energy optimization crucial. This paper\naddresses the joint optimization of routing and resource allocation in IAB\nnetworks through two distinct objectives: energy minimization and throughput\nmaximization. We develop a novel capacity model that links power levels to\nachievable data rates. We propose two practical large-scale approaches to solve\nthe optimization problems and leverage the closed-loop control framework\nintroduced by the Open Radio Access Network (O-RAN) architecture to integrate\nthe solutions. The approaches are evaluated on diverse scenarios built upon\nopen data of two months of traffic collected by network operators in the city\nof Milan, Italy. Results show that the proposed approaches effectively reduces\nnumber of activated nodes to save energy and achieves approximately 100 Mbps of\nminimum data rate per User Equipment (UE) during peak hours of the day using\nspectrum within the Frequency Range (FR) 3, or upper midband. The results\nvalidate the practical applicability of our framework for next-generation IAB\nnetwork deployment and optimization.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4e24\u79cd\u4f18\u5316\u76ee\u6807\uff08\u80fd\u6e90\u6700\u5c0f\u5316\u548c\u541e\u5410\u91cf\u6700\u5927\u5316\uff09\u6765\u89e3\u51b3IAB\u7f51\u7edc\u4e2d\u7684\u8def\u7531\u548c\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u5e76\u57fa\u4e8eO-RAN\u67b6\u6784\u96c6\u6210\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u5b9e\u9645\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "motivation": "\u968f\u77406G\u7f51\u7edc\u7684\u53d1\u5c55\uff0c\u79fb\u52a8\u7f51\u7edc\u8fd0\u8425\u5546\u9700\u8981\u6ee1\u8db3\u591a\u6837\u5316\u9700\u6c42\u540c\u65f6\u7ba1\u7406\u65e5\u76ca\u589e\u957f\u7684\u80fd\u6e90\u6d88\u8017\u3002IAB\u7f51\u7edc\u867d\u7136\u80fd\u591f\u652f\u6301\u5bc6\u96c6\u7ec6\u80de\u90e8\u7f72\uff0c\u4f46\u591a\u8df3\u65e0\u7ebf\u56de\u4f20\u9700\u8981\u5408\u9002\u7684\u8def\u7531\u548c\u8d44\u6e90\u5206\u914d\u51b3\u7b56\uff0c\u540c\u65f6\u7ec6\u80de\u5bc6\u96c6\u5316\u4f7f\u80fd\u6e90\u4f18\u5316\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u9898\u7684\u5bb9\u91cf\u6a21\u578b\uff0c\u5c06\u529f\u7387\u6c34\u5e73\u4e0e\u53ef\u5b9e\u73b0\u7684\u6570\u636e\u901f\u7387\u76f8\u5173\u8054\u3002\u63d0\u51fa\u4e86\u4e24\u79cd\u5b9e\u7528\u7684\u5927\u89c4\u6a21\u65b9\u6cd5\u6765\u89e3\u51b3\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5229\u7528O-RAN\u67b6\u6784\u5f15\u5165\u7684\u95ed\u73af\u63a7\u5236\u6846\u67b6\u6765\u96c6\u6210\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5728\u57fa\u4e8e\u7f51\u7edc\u8fd0\u8425\u5546\u5728\u610f\u5927\u5229\u7c73\u5170\u6536\u96c6\u7684\u4e24\u4e2a\u6708\u6d41\u91cf\u6570\u636e\u6784\u5efa\u7684\u591a\u6837\u5316\u573a\u666f\u4e2d\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u6240\u63d0\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u51cf\u5c11\u6fc0\u6d3b\u8282\u70b9\u6570\u91cf\u4ee5\u8282\u7701\u80fd\u6e90\uff0c\u5e76\u5728\u4f7f\u7528FR3\u9891\u6bb5\u6216\u4e0a\u4e2d\u9891\u6bb5\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u4e00\u5929\u4e2d\u7684\u9ad8\u5cf0\u65f6\u6bb5\u5b9e\u73b0\u6bcf\u4e2a\u7528\u6237\u8bbe\u5907\u7ea6100 Mbps\u7684\u6700\u4f4e\u6570\u636e\u901f\u7387\u3002", "conclusion": "\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u6846\u67b6\u5728\u4e0b\u4e00\u4ee3IAB\u7f51\u7edc\u90e8\u7f72\u548c\u4f18\u5316\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6027\uff0c\u4e3a6G\u7f51\u7edc\u7684\u80fd\u6e90\u6548\u7387\u548c\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.05759", "categories": ["cs.NI", "cs.DB", "cs.DC", "68M10, 68M15"], "pdf": "https://arxiv.org/pdf/2509.05759", "abs": "https://arxiv.org/abs/2509.05759", "authors": ["Jinkun Geng", "Shuai Mu", "Anirudh Sivaraman", "Balaji Prabhakar"], "title": "Tiga: Accelerating Geo-Distributed Transactions with Synchronized Clocks [Technical Report]", "comment": "This is the technical report for our paper accepted by The 31st\n  Symposium on Operating Systems Principles (SOSP'25)", "summary": "This paper presents Tiga, a new design for geo-replicated and scalable\ntransactional databases such as Google Spanner. Tiga aims to commit\ntransactions within 1 wide-area roundtrip time, or 1 WRTT, for a wide range of\nscenarios, while maintaining high throughput with minimal computational\noverhead. Tiga consolidates concurrency control and consensus, completing both\nstrictly serializable execution and consistent replication in a single round.\nIt uses synchronized clocks to proactively order transactions by assigning each\na future timestamp at submission. In most cases, transactions arrive at servers\nbefore their future timestamps and are serialized according to the designated\ntimestamp, requiring 1 WRTT to commit. In rare cases, transactions are delayed\nand proactive ordering fails, in which case Tiga falls back to a slow path,\ncommitting in 1.5--2 WRTTs. Compared to state-of-the-art solutions, Tiga can\ncommit more transactions at 1-WRTT latency, and incurs much less throughput\noverhead. Evaluation results show that Tiga outperforms all baselines,\nachieving 1.3--7.2$\\times$ higher throughput and 1.4--4.6$\\times$ lower\nlatency. Tiga is open-sourced at\nhttps://github.com/New-Consensus-Concurrency-Control/Tiga.", "AI": {"tldr": "Tiga\u662f\u4e00\u4e2a\u65b0\u7684\u5730\u7406\u590d\u5236\u53ef\u6269\u5c55\u4e8b\u52a1\u6570\u636e\u5e93\u8bbe\u8ba1\uff0c\u80fd\u591f\u57281\u4e2a\u5e7f\u57df\u5f80\u8fd4\u65f6\u95f4(WRTT)\u5185\u63d0\u4ea4\u4e8b\u52a1\uff0c\u901a\u8fc7\u6574\u5408\u5e76\u53d1\u63a7\u5236\u548c\u5171\u8bc6\u673a\u5236\uff0c\u4f7f\u7528\u540c\u6b65\u65f6\u949f\u4e3b\u52a8\u4e3a\u4e8b\u52a1\u5206\u914d\u65f6\u95f4\u6233\u6765\u5b9e\u73b0\u9ad8\u6548\u5e8f\u5217\u5316\u3002", "motivation": "\u73b0\u6709\u7684\u5730\u7406\u590d\u5236\u4e8b\u52a1\u6570\u636e\u5e93\u7cfb\u7edf\u5728\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u65b9\u9762\u5b58\u5728\u6027\u80fd\u74f6\u9888\uff0c\u9700\u8981\u8bbe\u8ba1\u4e00\u4e2a\u80fd\u591f\u5728\u5e7f\u57df\u7f51\u7edc\u73af\u5883\u4e0b\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u9ad8\u541e\u5410\u91cf\u7684\u4e8b\u52a1\u5904\u7406\u7cfb\u7edf\u3002", "method": "Tiga\u6574\u5408\u5e76\u53d1\u63a7\u5236\u548c\u5171\u8bc6\u673a\u5236\uff0c\u4f7f\u7528\u540c\u6b65\u65f6\u949f\u4e3b\u52a8\u4e3a\u4e8b\u52a1\u5206\u914d\u672a\u6765\u65f6\u95f4\u6233\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u5b9e\u73b01 WRTT\u63d0\u4ea4\uff0c\u5728\u5f02\u5e38\u60c5\u51b5\u4e0b\u56de\u9000\u52301.5-2 WRTT\u7684\u6162\u8def\u5f84\u3002", "result": "Tiga\u5728\u6027\u80fd\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u76f8\u6bd4\u73b0\u6709\u89e3\u51b3\u65b9\u6848\uff0c\u541e\u5410\u91cf\u63d0\u9ad81.3-7.2\u500d\uff0c\u5ef6\u8fdf\u964d\u4f4e1.4-4.6\u500d\u3002", "conclusion": "Tiga\u901a\u8fc7\u521b\u65b0\u7684\u4e3b\u52a8\u65f6\u95f4\u6233\u6392\u5e8f\u673a\u5236\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u5728\u5e7f\u57df\u7f51\u7edc\u73af\u5883\u4e0b\u9ad8\u6548\u7684\u4e8b\u52a1\u5904\u7406\uff0c\u4e3a\u5730\u7406\u590d\u5236\u6570\u636e\u5e93\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u8bbe\u8ba1\u601d\u8def\u3002"}}
{"id": "2509.05889", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.05889", "abs": "https://arxiv.org/abs/2509.05889", "authors": ["Mahsa Paknejad", "Parisa Fard Moshiri", "Murat Simsek", "Burak Kantarci", "Hussein T. Mouftah"], "title": "On-Dyn-CDA: A Real-Time Cost-Driven Task Offloading Algorithm for Vehicular Networks with Reduced Latency and Task Loss", "comment": "12 pages, 9 figures, accepted to IEEE Internet of Things Journal", "summary": "Real-time task processing is a critical challenge in vehicular networks,\nwhere achieving low latency and minimizing dropped task ratio depend on\nefficient task execution. Our primary objective is to maximize the number of\ncompleted tasks while minimizing overall latency, with a particular focus on\nreducing number of dropped tasks. To this end, we investigate both static and\ndynamic versions of an optimization algorithm. The static version assumes full\ntask availability, while the dynamic version manages tasks as they arrive. We\nalso distinguish between online and offline cases: the online version\nincorporates execution time into the offloading decision process, whereas the\noffline version excludes it, serving as a theoretical benchmark for optimal\nperformance. We evaluate our proposed Online Dynamic Cost-Driven Algorithm\n(On-Dyn-CDA) against these baselines. Notably, the static Particle Swarm\nOptimization (PSO) baseline assumes all tasks are transferred to the RSU and\nprocessed by the MEC, and its offline version disregards execution time, making\nit infeasible for real-time applications despite its optimal performance in\ntheory. Our novel On-Dyn-CDA completes execution in just 0.05 seconds under the\nmost complex scenario, compared to 1330.05 seconds required by Dynamic PSO. It\nalso outperforms Dynamic PSO by 3.42% in task loss and achieves a 29.22%\nreduction in average latency in complex scenarios. Furthermore, it requires\nneither a dataset nor a training phase, and its low computational complexity\nensures efficiency and scalability in dynamic environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7ebf\u52a8\u6001\u6210\u672c\u9a71\u52a8\u7b97\u6cd5(On-Dyn-CDA)\uff0c\u7528\u4e8e\u8f66\u8f86\u7f51\u7edc\u4e2d\u7684\u5b9e\u65f6\u4efb\u52a1\u5904\u7406\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6267\u884c\u65f6\u95f4\u548c\u4efb\u52a1\u4e22\u5931\u7387\u3002", "motivation": "\u8f66\u8f86\u7f51\u7edc\u4e2d\u5b9e\u65f6\u4efb\u52a1\u5904\u7406\u9762\u4e34\u4f4e\u5ef6\u8fdf\u548c\u6700\u5c0f\u5316\u4efb\u52a1\u4e22\u5f03\u7387\u7684\u6311\u6218\uff0c\u9700\u8981\u9ad8\u6548\u7684\u4efb\u52a1\u6267\u884c\u7b97\u6cd5\u6765\u6700\u5927\u5316\u5b8c\u6210\u4efb\u52a1\u6570\u91cf\u5e76\u51cf\u5c11\u6574\u4f53\u5ef6\u8fdf\u3002", "method": "\u7814\u7a76\u4e86\u9759\u6001\u548c\u52a8\u6001\u7248\u672c\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u9759\u6001\u7248\u672c\u5047\u8bbe\u6240\u6709\u4efb\u52a1\u53ef\u7528\uff0c\u52a8\u6001\u7248\u672c\u5904\u7406\u5b9e\u65f6\u5230\u8fbe\u7684\u4efb\u52a1\u3002\u533a\u5206\u5728\u7ebf\u548c\u79bb\u7ebf\u60c5\u51b5\uff0c\u5728\u7ebf\u7248\u672c\u5c06\u6267\u884c\u65f6\u95f4\u7eb3\u5165\u5378\u8f7d\u51b3\u7b56\u8fc7\u7a0b\u3002\u63d0\u51fa\u4e86On-Dyn-CDA\u7b97\u6cd5\u3002", "result": "On-Dyn-CDA\u5728\u6700\u590d\u6742\u573a\u666f\u4e0b\u4ec5\u97000.05\u79d2\u5b8c\u6210\u6267\u884c\uff0c\u76f8\u6bd4\u52a8\u6001PSO\u76841330.05\u79d2\u3002\u4efb\u52a1\u4e22\u5931\u7387\u964d\u4f4e3.42%\uff0c\u5e73\u5747\u5ef6\u8fdf\u51cf\u5c1129.22%\u3002\u65e0\u9700\u6570\u636e\u96c6\u6216\u8bad\u7ec3\u9636\u6bb5\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4f4e\u3002", "conclusion": "On-Dyn-CDA\u7b97\u6cd5\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5177\u6709\u9ad8\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edfPSO\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u8f66\u8f86\u7f51\u7edc\u7684\u5b9e\u65f6\u4efb\u52a1\u5904\u7406\u9700\u6c42\u3002"}}
{"id": "2509.05612", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.05612", "abs": "https://arxiv.org/abs/2509.05612", "authors": ["Zhaolin Wang", "Jiaqi Xu", "Chongjun Ouyang", "Xidong Mu", "Yuanwei Liu"], "title": "Multiport Network Modeling and Optimization for Reconfigurable Pinching-Antenna Systems", "comment": "13 pages, 9 figures", "summary": "A reconfigurable pinching-antenna system (PASS) is presented, endowing\npinching antennas (PAs) with both amplitude- and phase-controllable radiation\nbeyond conventional implementations. To characterize this feature, a general\nand physically consistent model is established for PASS via multiport network\ntheory. Within this model, the fundamental constraint of ideal\nreconfigurability of PAs is identified, allowing the full control of signal\namplitudes and phases. A practical directional-coupler (DC)-based PA model is\nthen proposed, enabling both amplitude-only control and amplitude-constrained\nphase control. Beamforming optimization is investigated for both ideal and\npractical cases: an optimal solution is obtained for ideal PAs, whereas a\nhigh-quality iterative algorithm is developed for DC-based PAs. Numerical\nresults suggest that in single-user scenarios: (i) with optimized PA positions,\nperformance gains arise primarily from amplitude reconfigurability and DC-based\nPAs approach ideal performance, and (ii) with fixed PA positions, both\namplitude and phase reconfigurability are critical and DC-based PAs incur\nnon-negligible loss.", "AI": {"tldr": "\u91cd\u914d\u7f29\u653e\u5929\u7ebf\u7cfb\u7edf(PASS)\u901a\u8fc7\u591a\u7aef\u53e3\u7f51\u7edc\u7406\u8bba\u5efa\u7acb\u6a21\u578b\uff0c\u5b9e\u73b0\u653e\u5c04\u632f\u5e45\u548c\u76f8\u4f4d\u7684\u5168\u63a7\u5236\uff0c\u5e76\u7814\u7a76\u4e86\u7406\u60f3\u548c\u5b9e\u9645\u65b9\u5411\u6027\u8026\u5408\u5668\u57faPAs\u7684\u5f62\u6210\u4f18\u5316\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7f29\u653e\u5929\u7ebf(PA)\u5728\u653e\u5c04\u632f\u5e45\u548c\u76f8\u4f4d\u63a7\u5236\u65b9\u9762\u6709\u9650\uff0c\u9700\u8981\u4e00\u79cd\u91cd\u914d\u7cfb\u7edf\u6765\u6269\u5c55\u5176\u529f\u80fd\uff0c\u5b9e\u73b0\u66f4\u7075\u6d3b\u7684\u653e\u5c04\u7279\u6027\u63a7\u5236\u3002", "method": "\u901a\u8fc7\u591a\u7aef\u53e3\u7f51\u7edc\u7406\u8bba\u5efa\u7acb\u4e00\u4e2a\u901a\u7528\u4e14\u7269\u7406\u4e00\u81f4\u7684PASS\u6a21\u578b\uff0c\u8bc6\u522b\u7406\u60f3\u91cd\u914d\u6027\u7684\u57fa\u672c\u7ea6\u675f\uff0c\u63d0\u51fa\u5b9e\u9645\u7684\u65b9\u5411\u6027\u8026\u5408\u5668\u57faPA\u6a21\u578b\uff0c\u5e76\u7814\u7a76\u7406\u60f3\u548c\u5b9e\u9645\u60c5\u51b5\u4e0b\u7684\u6750\u6599\u5f62\u6210\u4f18\u5316\u95ee\u9898\u3002", "result": "\u6570\u503c\u7ed3\u679c\u663e\u793a\uff1a\u5728\u5355\u7528\u6237\u573a\u666f\u4e2d\uff0c(i)\u4f18\u5316PA\u4f4d\u7f6e\u65f6\uff0c\u6027\u80fd\u63d0\u5347\u4e3b\u8981\u6765\u81ea\u632f\u5e45\u91cd\u914d\u80fd\u529b\uff0cDC\u57faPAs\u63a5\u8fd1\u7406\u60f3\u6027\u80fd\uff1b(ii)\u56fa\u5b9aPA\u4f4d\u7f6e\u65f6\uff0c\u632f\u5e45\u548c\u76f8\u4f4d\u91cd\u914d\u80fd\u529b\u90fd\u5f88\u5173\u952e\uff0cDC\u57faPAs\u4f1a\u5bfc\u81f4\u4e0d\u53ef\u5ffd\u89c6\u7684\u6027\u80fd\u635f\u5931\u3002", "conclusion": "PASS\u7cfb\u7edf\u901a\u8fc7\u591a\u7aef\u7f51\u7edc\u7406\u8bba\u5efa\u6a21\u578b\u5b9e\u73b0\u4e86\u5bf9\u7f29\u653e\u5929\u7ebf\u653e\u5c04\u7279\u6027\u7684\u5168\u9762\u63a7\u5236\uff0c\u65b9\u5411\u6027\u8026\u5408\u5668\u57fa\u5b9e\u73b0\u5728\u4f18\u5316\u4f4d\u7f6e\u65f6\u63a5\u8fd1\u7406\u60f3\u6027\u80fd\uff0c\u4f46\u5728\u56fa\u5b9a\u4f4d\u7f6e\u65f6\u9700\u8981\u8003\u8651\u632f\u5e45\u548c\u76f8\u4f4d\u7684\u5171\u540c\u63a7\u5236\u3002"}}
{"id": "2509.05323", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.05323", "abs": "https://arxiv.org/abs/2509.05323", "authors": ["Adam Cole", "Mick Grierson"], "title": "Attention of a Kiss: Exploring Attention Maps in Video Diffusion for XAIxArts", "comment": "3rd international workshop on eXplainable AI for the Arts (XAIxArts)\n  at the ACM Creativity and Cognition Conference 2025", "summary": "This paper presents an artistic and technical investigation into the\nattention mechanisms of video diffusion transformers. Inspired by early video\nartists who manipulated analog video signals to create new visual aesthetics,\nthis study proposes a method for extracting and visualizing cross-attention\nmaps in generative video models. Built on the open-source Wan model, our tool\nprovides an interpretable window into the temporal and spatial behavior of\nattention in text-to-video generation. Through exploratory probes and an\nartistic case study, we examine the potential of attention maps as both\nanalytical tools and raw artistic material. This work contributes to the\ngrowing field of Explainable AI for the Arts (XAIxArts), inviting artists to\nreclaim the inner workings of AI as a creative medium.", "AI": {"tldr": "\u901a\u8fc7\u63d0\u53d6\u548c\u53ef\u89c6\u5316\u89c6\u9891\u6e23\u679c\u53d8\u6362\u5668\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u5730\u56fe\uff0c\u63a2\u7d22\u6ce8\u610f\u529b\u673a\u5236\u5728\u6587\u672c\u5230\u89c6\u9891\u751f\u6210\u4e2d\u7684\u65f6\u7a7a\u95f4\u884c\u4e3a\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u827a\u672f\u521b\u4f5c\u7684\u539f\u6750\u6599\u3002", "motivation": "\u53d7\u65e9\u671f\u89c6\u9891\u827a\u672f\u5bb6\u64cd\u63a7\u6a21\u62df\u89c6\u9891\u4fe1\u53f7\u7684\u542f\u53d1\uff0c\u63a2\u7d22AI\u6a21\u578b\u5185\u90e8\u5de5\u4f5c\u673a\u5236\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u5c06\u5176\u91cd\u65b0\u5b9a\u4e49\u4e3a\u521b\u610f\u5a92\u4ecb\u3002", "method": "\u57fa\u4e8e\u5f00\u6e90Wan\u6a21\u578b\u5efa\u7acb\u5de5\u5177\uff0c\u63d0\u53d6\u548c\u53ef\u89c6\u5316\u4ea4\u53c9\u6ce8\u610f\u529b\u5730\u56fe\uff0c\u901a\u8fc7\u63a2\u7d22\u6027\u63a2\u9488\u548c\u827a\u672f\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5f00\u53d1\u4e86\u80fd\u591f\u63ed\u793a\u89c6\u9891\u751f\u6210\u6a21\u578b\u65f6\u7a7a\u95f4\u6ce8\u610f\u529b\u884c\u4e3a\u7684\u53ef\u89e3\u91ca\u6027\u5de5\u5177\uff0c\u8bc1\u660e\u4e86\u6ce8\u610f\u529b\u5730\u56fe\u65e2\u53ef\u4f5c\u4e3a\u5206\u6790\u5de5\u5177\u4e5f\u53ef\u4f5c\u4e3a\u827a\u672f\u521b\u4f5c\u539f\u6750\u6599\u7684\u6f5c\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u827a\u672f\u53ef\u89e3\u91caAI\uff08XAIxArts\uff09\u9886\u57df\u505a\u51fa\u8d21\u732e\uff0c\u9f13\u52b1\u827a\u672f\u5bb6\u5c06AI\u5185\u90e8\u5de5\u4f5c\u673a\u5236\u91cd\u65b0\u8ba4\u5b9a\u4e3a\u521b\u610f\u5a92\u4ecb\uff0c\u4fc3\u8fdb\u6280\u672f\u4e0e\u827a\u672f\u7684\u878d\u5408\u3002"}}
{"id": "2509.05936", "categories": ["cs.NI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05936", "abs": "https://arxiv.org/abs/2509.05936", "authors": ["Xuanhao Luo", "Shivesh Madan Nath Jha", "Akruti Sinha", "Zhizhen Li", "Yuchen Liu"], "title": "ALPHA: LLM-Enabled Active Learning for Human-Free Network Anomaly Detection", "comment": "Accepted at 44th IEEE International Performance Computing and\n  Communications Conference (IPCCC 2025)", "summary": "Network log data analysis plays a critical role in detecting security threats\nand operational anomalies. Traditional log analysis methods for anomaly\ndetection and root cause analysis rely heavily on expert knowledge or fully\nsupervised learning models, both of which require extensive labeled data and\nsignificant human effort. To address these challenges, we propose ALPHA, the\nfirst Active Learning Pipeline for Human-free log Analysis. ALPHA integrates\nsemantic embedding, clustering-based representative sampling, and large\nlanguage model (LLM)-assisted few-shot annotation to automate the anomaly\ndetection process. The LLM annotated labels are propagated across clusters,\nenabling large-scale training of an anomaly detector with minimal supervision.\nTo enhance the annotation accuracy, we propose a two-step few-shot refinement\nstrategy that adaptively selects informative prompts based on the LLM's\nobserved error patterns. Extensive experiments on real-world log datasets\ndemonstrate that ALPHA achieves detection accuracy comparable to fully\nsupervised methods while mitigating human efforts in the loop. ALPHA also\nsupports interpretable analysis through LLM-driven root cause explanations in\nthe post-detection stage. These capabilities make ALPHA a scalable and\ncost-efficient solution for truly automated log-based anomaly detection.", "AI": {"tldr": "ALPHA\u662f\u9996\u4e2a\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u4e3b\u52a8\u5b66\u4e60\u65e5\u5fd7\u5206\u6790\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u8bed\u4e49\u5d4c\u5165\u3001\u805a\u7c7b\u91c7\u6837\u548cLLM\u8f85\u52a9\u6807\u6ce8\u5b9e\u73b0\u81ea\u52a8\u5316\u5f02\u5e38\u68c0\u6d4b\uff0c\u5728\u51cf\u5c11\u4eba\u5de5\u6807\u6ce8\u7684\u540c\u65f6\u8fbe\u5230\u4e0e\u5168\u76d1\u7763\u65b9\u6cd5\u76f8\u5f53\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u65e5\u5fd7\u5206\u6790\u65b9\u6cd5\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\u6216\u5168\u76d1\u7763\u5b66\u4e60\uff0c\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u548c\u4eba\u5de5\u52aa\u529b\uff0c\u96be\u4ee5\u5b9e\u73b0\u81ea\u52a8\u5316\u5f02\u5e38\u68c0\u6d4b\u3002", "method": "\u96c6\u6210\u8bed\u4e49\u5d4c\u5165\u3001\u57fa\u4e8e\u805a\u7c7b\u7684\u4ee3\u8868\u6027\u91c7\u6837\u3001LLM\u8f85\u52a9\u5c11\u6837\u672c\u6807\u6ce8\uff0c\u5e76\u63d0\u51fa\u4e24\u6b65\u5c11\u6837\u672c\u4f18\u5316\u7b56\u7565\u81ea\u9002\u5e94\u9009\u62e9\u63d0\u793a\u8bcd\uff0c\u901a\u8fc7\u6807\u7b7e\u4f20\u64ad\u5b9e\u73b0\u5927\u89c4\u6a21\u8bad\u7ec3\u3002", "result": "\u5728\u771f\u5b9e\u65e5\u5fd7\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cALPHA\u5728\u51cf\u5c11\u4eba\u5de5\u53c2\u4e0e\u7684\u540c\u65f6\u8fbe\u5230\u4e86\u4e0e\u5168\u76d1\u7763\u65b9\u6cd5\u76f8\u5f53\u7684\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u5e76\u652f\u6301LLM\u9a71\u52a8\u7684\u53ef\u89e3\u91ca\u6839\u56e0\u5206\u6790\u3002", "conclusion": "ALPHA\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u771f\u6b63\u81ea\u52a8\u5316\u7684\u57fa\u4e8e\u65e5\u5fd7\u7684\u5f02\u5e38\u68c0\u6d4b\u3002"}}
{"id": "2509.05875", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.05875", "abs": "https://arxiv.org/abs/2509.05875", "authors": ["Roberto C. G. Porto", "Rodrigo C. de Lamare"], "title": "Study of Iterative Detection, Decoding and Channel Estimation for RIS-Aided MIMO Networks", "comment": "6 pages, 5 figures", "summary": "This work proposes an iterative detection, decoding and channel estimation\nscheme for multiple-antenna systems assisted by multiple reflective intelligent\nsurfaces (RIS). A novel channel estimation technique that exploits low-density\nparity-check (LDPC) codes and iterative processing is developed to enhance\nestimation accuracy while reducing the number of required pilot symbols. The\nkey idea is to exploit encoded pilots to improve the iterative process,\nenabling the use of not only pilot bits but also parity bits from the coded\npacket to refine channel estimation. Simulations analyze a sub-6 GHz scenario\nwhere the channel propagation is not sparse and multiple RIS are deployed,\nconsidering both LOS and NLOS conditions. Numerical results show significant\nperformance gains for the proposed scheme and estimator over competing\napproaches.", "AI": {"tldr": "\u901a\u8fc7\u8fed\u4ee3\u68c0\u6d4b\u3001\u89e3\u7801\u548c\u9891\u9053\u4f30\u8ba1\u65b9\u6848\uff0c\u5229\u7528LDPC\u7801\u548c\u7f16\u7801\u5bfc\u9891\u63d0\u9ad8\u591aRIS\u52a9\u591a\u5929\u7ebf\u7cfb\u7edf\u7684\u9891\u9053\u4f30\u8ba1\u51c6\u786e\u6027\uff0c\u51cf\u5c11\u5bfc\u9891\u7b26\u53f7\u9700\u6c42", "motivation": "\u89e3\u51b3\u591a\u53cd\u5c04\u667a\u80fd\u8868\u9762(RIS)\u52a9\u529b\u7684\u591a\u5929\u7ebf\u7cfb\u7edf\u4e2d\uff0c\u9891\u9053\u4f30\u8ba1\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u975e\u7a00\u758f\u4f20\u64ad\u73af\u5883\u4e0b\u51cf\u5c11\u5bfc\u9891\u7b26\u53f7\u9700\u6c42\u7684\u540c\u65f6\u63d0\u9ad8\u4f30\u8ba1\u51c6\u786e\u6027", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9898\u7684\u9891\u9053\u4f30\u8ba1\u6280\u672f\uff0c\u5229\u7528\u4f4e\u5bc6\u5ea6\u5947\u5076\u6821\u9a8c(LDPC)\u7801\u548c\u8fed\u4ee3\u5904\u7406\u3002\u5173\u952e\u601d\u60f3\u662f\u5229\u7528\u7f16\u7801\u5bfc\u9891\u6765\u6539\u5584\u8fed\u4ee3\u8fc7\u7a0b\uff0c\u4e0d\u4ec5\u4f7f\u7528\u5bfc\u9891\u6bd4\u7279\u8fd8\u5229\u7528\u7f16\u7801\u5305\u4e2d\u7684\u5947\u5076\u6bd4\u7279\u6765\u7cbe\u70bc\u9891\u9053\u4f30\u8ba1", "result": "\u5728sub-6 GHz\u573a\u666f\u4e0b\u8fdb\u884c\u4e86\u6a21\u62df\uff0c\u8003\u8651\u4e86\u975e\u7a00\u758f\u4f20\u64ad\u3001\u591aRIS\u90e8\u7f72\u4ee5\u53caLOS\u548cNLOS\u6761\u4ef6\u3002\u6570\u503c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6848\u548c\u4f30\u8ba1\u5668\u5728\u6027\u80fd\u4e0a\u8fdc\u8d85\u7ade\u4e89\u65b9\u6848", "conclusion": "\u63d0\u51fa\u7684\u8fed\u4ee3\u68c0\u6d4b\u3001\u89e3\u7801\u548c\u9891\u9053\u4f30\u8ba1\u65b9\u6848\u80fd\u591f\u5728\u591aRIS\u52a9\u529b\u7684\u591a\u5929\u7ebf\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u663e\u8457\u7684\u6027\u80fd\u6536\u76ca\uff0c\u901a\u8fc7\u5229\u7528LDPC\u7801\u548c\u7f16\u7801\u5bfc\u9891\u6709\u6548\u63d0\u9ad8\u4e86\u9891\u9053\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u5e76\u51cf\u5c11\u4e86\u5bfc\u9891\u7b26\u53f7\u7684\u9700\u6c42\u91cf"}}
{"id": "2509.05324", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05324", "abs": "https://arxiv.org/abs/2509.05324", "authors": ["Rongqian Chen", "Shu Hong", "Rifatul Islam", "Mahdi Imani", "G. Gary Tan", "Tian Lan"], "title": "Perception Graph for Cognitive Attack Reasoning in Augmented Reality", "comment": "Accepted by ACM MobiHoc XR Security workshop 2025", "summary": "Augmented reality (AR) systems are increasingly deployed in tactical\nenvironments, but their reliance on seamless human-computer interaction makes\nthem vulnerable to cognitive attacks that manipulate a user's perception and\nseverely compromise user decision-making. To address this challenge, we\nintroduce the Perception Graph, a novel model designed to reason about human\nperception within these systems. Our model operates by first mimicking the\nhuman process of interpreting key information from an MR environment and then\nrepresenting the outcomes using a semantically meaningful structure. We\ndemonstrate how the model can compute a quantitative score that reflects the\nlevel of perception distortion, providing a robust and measurable method for\ndetecting and analyzing the effects of such cognitive attacks.", "AI": {"tldr": "\u63d0\u51faPerception Graph\u6a21\u578b\u6765\u68c0\u6d4b\u548c\u5206\u6790AR\u7cfb\u7edf\u4e2d\u7684\u8ba4\u77e5\u653b\u51fb\uff0c\u901a\u8fc7\u91cf\u5316\u611f\u77e5\u626d\u66f2\u7a0b\u5ea6\u6765\u4fdd\u62a4\u7528\u6237\u51b3\u7b56\u80fd\u529b", "motivation": "AR\u7cfb\u7edf\u5728\u6218\u672f\u73af\u5883\u4e2d\u90e8\u7f72\u589e\u52a0\uff0c\u4f46\u5176\u4f9d\u8d56\u65e0\u7f1d\u4eba\u673a\u4ea4\u4e92\u7684\u7279\u6027\u4f7f\u5176\u5bb9\u6613\u53d7\u5230\u8ba4\u77e5\u653b\u51fb\uff0c\u8fd9\u4e9b\u653b\u51fb\u4f1a\u64cd\u7eb5\u7528\u6237\u611f\u77e5\u5e76\u4e25\u91cd\u635f\u5bb3\u7528\u6237\u51b3\u7b56\u80fd\u529b", "method": "\u5f15\u5165Perception Graph\u6a21\u578b\uff0c\u9996\u5148\u6a21\u62df\u4eba\u7c7b\u4eceMR\u73af\u5883\u4e2d\u89e3\u91ca\u5173\u952e\u4fe1\u606f\u7684\u8fc7\u7a0b\uff0c\u7136\u540e\u7528\u8bed\u4e49\u6709\u610f\u4e49\u7684\u7ed3\u6784\u8868\u793a\u7ed3\u679c\uff0c\u8ba1\u7b97\u53cd\u6620\u611f\u77e5\u626d\u66f2\u7a0b\u5ea6\u7684\u91cf\u5316\u5206\u6570", "result": "\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u7a33\u5065\u4e14\u53ef\u6d4b\u91cf\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u548c\u5206\u6790\u8ba4\u77e5\u653b\u51fb\u7684\u5f71\u54cd", "conclusion": "Perception Graph\u4e3aAR\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u68c0\u6d4b\u548c\u9632\u5fa1\u8ba4\u77e5\u653b\u51fb\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5316\u611f\u77e5\u626d\u66f2\u6765\u4fdd\u62a4\u7528\u6237\u51b3\u7b56\u5b8c\u6574\u6027"}}
{"id": "2509.05938", "categories": ["cs.NI", "C.2; C.2.1; C.2.2"], "pdf": "https://arxiv.org/pdf/2509.05938", "abs": "https://arxiv.org/abs/2509.05938", "authors": ["Alissa Baumeister", "Sina Keshvadi"], "title": "An Axiomatic Analysis of Path Selection Strategies for Multipath Transport in Path-Aware Networks", "comment": "13 pages, submitted in the journal of Complex Networks", "summary": "Path-aware networking architectures like SCION provide end-hosts with\nexplicit control over inter-domain routing, while multipath transport protocols\nlike MPTCP and MPQUIC enable the concurrent use of multiple paths. This\ncombination promises significant gains in performance and policy enforcement,\nbut it also creates a stark trade-off between individual performance\noptimization and overall network stability. This paper quantifies this\ntrade-off through a rigorous axiomatic analysis. We evaluate a spectrum of\nalgorithms, from greedy (Min-RTT) and cooperative (Round-Robin) to hybrid\napproaches (Epsilon-Greedy), against axioms of Efficiency, Loss Avoidance,\nStability, and Fairness in a simulated path-aware environment.\n  Our simulations reveal that purely greedy strategies, while efficient under\nlow contention, induce catastrophic packet loss, increasing by over >18,000% as\nthe number of competing agents grow, due to herd effects that cause severe\nnetwork instability. Conversely, cooperative strategies ensure fairness and\nstability but at the cost of underutilizing high-capacity paths. Crucially, we\ndemonstrate that hybrid strategies resolve this conflict. The Epsilon-Greedy\nalgorithm, for instance, achieves the highest efficiency of all tested\nstrategies in high-contention scenarios while mitigating the instability\ninherent to the greedy approach. Our axiomatic analysis suggests that tunable,\nhybrid algorithms are essential for designing robust and high-performance path\nselection mechanisms for next-generation networks.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u516c\u7406\u5316\u5206\u6790\u91cf\u5316\u4e86\u8def\u5f84\u611f\u77e5\u7f51\u7edc\u4e2d\u4e2a\u4f53\u6027\u80fd\u4f18\u5316\u4e0e\u7f51\u7edc\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u53d1\u73b0\u6df7\u5408\u7b56\u7565\uff08\u5982Epsilon-Greedy\uff09\u5728\u9ad8\u7ade\u4e89\u573a\u666f\u4e0b\u65e2\u80fd\u5b9e\u73b0\u6700\u9ad8\u6548\u7387\uff0c\u53c8\u80fd\u7f13\u89e3\u8d2a\u5a6a\u65b9\u6cd5\u7684\u4e0d\u7a33\u5b9a\u6027\u3002", "motivation": "\u8def\u5f84\u611f\u77e5\u7f51\u7edc\u67b6\u6784\uff08\u5982SCION\uff09\u548c\u591a\u8def\u5f84\u4f20\u8f93\u534f\u8bae\uff08\u5982MPTCP\u3001MPQUIC\uff09\u7684\u7ed3\u5408\u867d\u7136\u80fd\u5e26\u6765\u6027\u80fd\u63d0\u5347\uff0c\u4f46\u4e5f\u4ea7\u751f\u4e86\u4e2a\u4f53\u6027\u80fd\u4f18\u5316\u4e0e\u6574\u4f53\u7f51\u7edc\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u663e\u8457\u6743\u8861\uff0c\u9700\u8981\u91cf\u5316\u5206\u6790\u8fd9\u79cd\u6743\u8861\u5173\u7cfb\u3002", "method": "\u91c7\u7528\u516c\u7406\u5316\u5206\u6790\u65b9\u6cd5\uff0c\u5728\u6a21\u62df\u7684\u8def\u5f84\u611f\u77e5\u73af\u5883\u4e2d\u8bc4\u4f30\u4e86\u4ece\u8d2a\u5a6a\uff08Min-RTT\uff09\u3001\u534f\u4f5c\uff08Round-Robin\uff09\u5230\u6df7\u5408\u65b9\u6cd5\uff08Epsilon-Greedy\uff09\u7684\u4e00\u7cfb\u5217\u7b97\u6cd5\uff0c\u9488\u5bf9\u6548\u7387\u3001\u4e22\u5305\u907f\u514d\u3001\u7a33\u5b9a\u6027\u548c\u516c\u5e73\u6027\u7b49\u516c\u7406\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7eaf\u8d2a\u5a6a\u7b56\u7565\u5728\u4f4e\u7ade\u4e89\u65f6\u9ad8\u6548\uff0c\u4f46\u968f\u7740\u7ade\u4e89\u4ee3\u7406\u6570\u91cf\u589e\u52a0\uff0c\u7531\u4e8e\u7fa4\u4f53\u6548\u5e94\u5bfc\u81f4\u4e25\u91cd\u7f51\u7edc\u4e0d\u7a33\u5b9a\uff0c\u4e22\u5305\u7387\u589e\u52a0\u8d85\u8fc718,000%\uff1b\u534f\u4f5c\u7b56\u7565\u786e\u4fdd\u516c\u5e73\u7a33\u5b9a\u4f46\u65e0\u6cd5\u5145\u5206\u5229\u7528\u9ad8\u5bb9\u91cf\u8def\u5f84\uff1b\u6df7\u5408\u7b56\u7565\uff08\u5982Epsilon-Greedy\uff09\u5728\u9ad8\u7ade\u4e89\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u6700\u9ad8\u6548\u7387\u540c\u65f6\u7f13\u89e3\u4e86\u4e0d\u7a33\u5b9a\u6027\u3002", "conclusion": "\u53ef\u8c03\u8282\u7684\u6df7\u5408\u7b97\u6cd5\u5bf9\u4e8e\u8bbe\u8ba1\u4e0b\u4e00\u4ee3\u7f51\u7edc\u7684\u9c81\u68d2\u9ad8\u6027\u80fd\u8def\u5f84\u9009\u62e9\u673a\u5236\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4e2a\u4f53\u4f18\u5316\u4e0e\u7f51\u7edc\u7a33\u5b9a\u6027\u7684\u51b2\u7a81\u3002"}}
{"id": "2509.06378", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.06378", "abs": "https://arxiv.org/abs/2509.06378", "authors": ["Ye Yuan", "Shuowen Zhang"], "title": "Beyond Diagonal IRS Aided OFDM: Rate Maximization under Frequency-Dependent Reflection", "comment": "To appear in Proc. IEEE Global Communications Conference (Globecom),\n  2025", "summary": "This paper studies a broadband orthogonal frequency division multiplexing\n(OFDM) system aided by a beyond diagonal intelligent reflecting surface\n(BD-IRS), where inter-connections exist among different elements such that the\nreflection matrix can exhibit a beyond diagonal structure. Under practical\ncircuit structures, the reflection matrix of the BD-IRS is generally dependent\non the circuit parameters (e.g., capacitance matrix for all tunable capacitors)\nas well as the operating frequency, which leads to couplings among the BD-IRS\nreflection matrices over different sub-carriers and consequently new challenges\nin the BD-IRS design. Motivated by this, we first model the relationship\nbetween the BD-IRS reflection matrices over different sub-carriers and the\ntunable capacitance matrix, and then formulate the joint optimization problem\nof the tunable capacitance matrix and power allocation over OFDM sub-carriers\nto maximize the achievable rate of the OFDM system. Despite the non-convexity\nof the problem, we propose an effective algorithm for finding a high-quality\nfeasible solution via leveraging alternating optimization and successive convex\napproximation. Numerical results show the superiority of our proposed design\nover benchmark designs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u57fa\u4e8e\u8d85\u5bf9\u89d2\u667a\u80fd\u53cd\u5c04\u9762(BD-IRS)\u7684\u5bbd\u5e26OFDM\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u53ef\u8c03\u7535\u5bb9\u77e9\u9635\u548c\u529f\u7387\u5206\u914d\u6765\u6700\u5927\u5316\u7cfb\u7edf\u53ef\u8fbe\u901f\u7387\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4ea4\u66ff\u4f18\u5316\u548c\u9010\u6b21\u51f8\u903c\u8fd1\u7b97\u6cd5\u3002", "motivation": "\u5728\u5b9e\u9645\u7535\u8def\u7ed3\u6784\u4e0b\uff0cBD-IRS\u7684\u53cd\u5c04\u77e9\u9635\u4f9d\u8d56\u4e8e\u7535\u8def\u53c2\u6570\u548c\u5de5\u4f5c\u9891\u7387\uff0c\u5bfc\u81f4\u4e0d\u540c\u5b50\u8f7d\u6ce2\u95f4\u5b58\u5728\u8026\u5408\uff0c\u7ed9BD-IRS\u8bbe\u8ba1\u5e26\u6765\u65b0\u6311\u6218\u3002", "method": "\u9996\u5148\u5efa\u6a21BD-IRS\u53cd\u5c04\u77e9\u9635\u4e0e\u53ef\u8c03\u7535\u5bb9\u77e9\u9635\u7684\u5173\u7cfb\uff0c\u7136\u540e\u63d0\u51fa\u4ea4\u66ff\u4f18\u5316\u548c\u9010\u6b21\u51f8\u903c\u8fd1\u7b97\u6cd5\u6765\u8054\u5408\u4f18\u5316\u53ef\u8c03\u7535\u5bb9\u77e9\u9635\u548cOFDM\u5b50\u8f7d\u6ce2\u529f\u7387\u5206\u914d\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u8bbe\u8ba1\u65b9\u6848\u4f18\u4e8e\u57fa\u51c6\u8bbe\u8ba1\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5bbd\u5e26OFDM\u7cfb\u7edf\u4e2dBD-IRS\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2509.05325", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05325", "abs": "https://arxiv.org/abs/2509.05325", "authors": ["Liming Xu", "Yunbo Long", "Alexandra Brintrup"], "title": "SynDelay: A Synthetic Dataset for Delivery Delay Prediction", "comment": "This paper incldues 1 figure and 2 tables", "summary": "Artificial intelligence (AI) is transforming supply chain management, yet\nprogress in predictive tasks -- such as delivery delay prediction -- remains\nconstrained by the scarcity of high-quality, openly available datasets.\nExisting datasets are often proprietary, small, or inconsistently maintained,\nhindering reproducibility and benchmarking. We present SynDelay, a synthetic\ndataset designed for delivery delay prediction. Generated using an advanced\ngenerative model trained on real-world data, SynDelay preserves realistic\ndelivery patterns while ensuring privacy. Although not entirely free of noise\nor inconsistencies, it provides a challenging and practical testbed for\nadvancing predictive modelling. To support adoption, we provide baseline\nresults and evaluation metrics as initial benchmarks, serving as reference\npoints rather than state-of-the-art claims. SynDelay is publicly available\nthrough the Supply Chain Data Hub, an open initiative promoting dataset sharing\nand benchmarking in supply chain AI. We encourage the community to contribute\ndatasets, models, and evaluation practices to advance research in this area.\nAll code is openly accessible at https://supplychaindatahub.org.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86SynDelay\u6570\u636e\u96c6\uff0c\u4e00\u4e2a\u7528\u4e8e\u914d\u9001\u5ef6\u8bef\u9884\u6d4b\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u4ee5\u89e3\u51b3\u4f9b\u5e94\u94fe\u7ba1\u7406\u4e2d\u9ad8\u8d28\u91cf\u516c\u5f00\u6570\u636e\u7f3a\u4e4f\u7684\u95ee\u9898\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u5728\u4f9b\u5e94\u94fe\u7ba1\u7406\u4e2d\u7684\u9884\u6d4b\u4efb\u52a1\uff08\u5982\u914d\u9001\u5ef6\u8bef\u9884\u6d4b\uff09\u53d7\u5230\u9ad8\u8d28\u91cf\u516c\u5f00\u6570\u636e\u96c6\u7a00\u7f3a\u7684\u9650\u5236\uff0c\u73b0\u6709\u6570\u636e\u96c6\u5b58\u5728\u4e13\u5229\u6027\u3001\u89c4\u6a21\u5c0f\u6216\u7ef4\u62a4\u4e0d\u4e00\u81f4\u7b49\u95ee\u9898\uff0c\u5f71\u54cd\u4e86\u53ef\u590d\u73b0\u6027\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u8bad\u7ec3\u7684\u5148\u8fdb\u751f\u6210\u6a21\u578b\u521b\u5efaSynDelay\u5408\u6210\u6570\u636e\u96c6\uff0c\u4fdd\u6301\u5b9e\u9645\u914d\u9001\u6a21\u5f0f\u7684\u540c\u65f6\u786e\u4fdd\u9690\u79c1\u6027\u3002", "result": "\u867d\u7136\u6570\u636e\u96c6\u4e0d\u80fd\u5b8c\u5168\u907f\u514d\u566a\u58f0\u6216\u4e0d\u4e00\u81f4\u6027\uff0c\u4f46\u63d0\u4f9b\u4e86\u5177\u6709\u6311\u6218\u6027\u548c\u5b9e\u7528\u6027\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5e76\u63d0\u4f9b\u4e86\u57fa\u51c6\u7ed3\u679c\u548c\u8bc4\u4f30\u6307\u6807\u3002", "conclusion": "SynDelay\u901a\u8fc7Supply Chain Data Hub\u516c\u5f00\u53ef\u7528\uff0c\u4e3a\u4f9b\u5e94\u94feAI\u9884\u6d4b\u6a21\u578b\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u6570\u636e\u652f\u6301\uff0c\u5e76\u9f13\u52b1\u793e\u533a\u8d21\u732e\u6570\u636e\u96c6\u3001\u6a21\u578b\u548c\u8bc4\u4f30\u65b9\u6cd5\u6765\u63a8\u8fdb\u8be5\u9886\u57df\u7684\u7814\u7a76\u3002"}}
{"id": "2509.05946", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.05946", "abs": "https://arxiv.org/abs/2509.05946", "authors": ["Bisheng Wei", "Ruihong Jiang", "Ruichen Zhang", "Yinqiu Liu", "Dusit Niyato", "Yaohua Sun", "Yang Lu", "Yonghui Li", "Shiwen Mao", "Chau Yuen", "Marco Di Renzo", "Mugen Peng"], "title": "Large Language Models for Next-Generation Wireless Network Management: A Survey and Tutorial", "comment": null, "summary": "The rapid advancement toward sixth-generation (6G) wireless networks has\nsignificantly intensified the complexity and scale of optimization problems,\nincluding resource allocation and trajectory design, often formulated as\ncombinatorial problems in large discrete decision spaces. However, traditional\noptimization methods, such as heuristics and deep reinforcement learning (DRL),\nstruggle to meet the demanding requirements of real-time adaptability,\nscalability, and dynamic handling of user intents in increasingly heterogeneous\nand resource-constrained network environments. Large language models (LLMs)\npresent a transformative paradigm by enabling natural language-driven problem\nformulation, context-aware reasoning, and adaptive solution refinement through\nadvanced semantic understanding and structured reasoning capabilities. This\npaper provides a systematic and comprehensive survey of LLM-enabled\noptimization frameworks tailored for wireless networks. We first introduce\nfoundational design concepts and distinguish LLM-enabled methods from\nconventional optimization paradigms. Subsequently, we critically analyze key\nenabling methodologies, including natural language modeling, solver\ncollaboration, and solution verification processes. Moreover, we explore\nrepresentative case studies to demonstrate LLMs' transformative potential in\npractical scenarios such as optimization formulation, low-altitude economy\nnetworking, and intent networking. Finally, we discuss current research\nchallenges, examine prominent open-source frameworks and datasets, and identify\npromising future directions to facilitate robust, scalable, and trustworthy\nLLM-enabled optimization solutions for next-generation wireless networks.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u57286G\u7f51\u7edc\u4f18\u5316\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u9a71\u52a8\u7684\u4f18\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u5b9e\u65f6\u6027\u3001\u6269\u5c55\u6027\u548c\u52a8\u6001\u5904\u7406\u65b9\u9762\u7684\u6311\u6218\u3002", "motivation": "6G\u7f51\u7edc\u4f18\u5316\u95ee\u9898\u7684\u590d\u6742\u6027\u548c\u89c4\u6a21\u8fc5\u901f\u589e\u957f\uff0c\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u65f6\u9002\u5e94\u6027\u3001\u6269\u5c55\u6027\u548c\u52a8\u6001\u5904\u7406\u7528\u6237\u610f\u56fe\u7684\u9700\u6c42\uff0c\u9700\u8981\u627e\u5230\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u9a71\u52a8\u7684\u95ee\u9898\u5f62\u5f0f\u5316\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u548c\u9002\u5e94\u6027\u89e3\u51b3\u65b9\u6848\u7cbe\u70bc\uff0c\u5305\u62ec\u81ea\u7136\u8bed\u8a00\u5efa\u6a21\u3001\u6c42\u89e3\u5668\u534f\u4f5c\u548c\u89e3\u51b3\u65b9\u6848\u9a8c\u8bc1\u7b49\u5173\u952e\u6280\u672f\u3002", "result": "\u901a\u8fc7\u4ee3\u8868\u6027\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86LLMs\u5728\u4f18\u5316\u95ee\u9898\u5f62\u5f0f\u5316\u3001\u4f4e\u7a7a\u7ecf\u6d4e\u7f51\u7edc\u548c\u610f\u56fe\u7f51\u7edc\u7b49\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u8f6c\u578b\u6f5c\u529b\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u63d0\u4f9b\u4e86\u66f4\u5065\u58ee\u3001\u53ef\u6269\u5c55\u548c\u53ef\u4fe1\u8d56\u7684\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8bba\u6587\u4e3a6G\u7f51\u7edc\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684LLM\u4f18\u5316\u6846\u67b6\u8bc4\u4f30\uff0c\u8bc6\u522b\u4e86\u5f53\u524d\u7684\u7814\u7a76\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u66f4\u5065\u58ee\u3001\u53ef\u6269\u5c55\u548c\u53ef\u4fe1\u8d56\u7684LLM\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.06492", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.06492", "abs": "https://arxiv.org/abs/2509.06492", "authors": ["Wilton Kim", "Stanislav Kruglik", "Han Mao Kiah"], "title": "Trace Repair Never Loses to Classical Repair: Exact and Explicit Helper Nodes Selection", "comment": "5 pages, 1 figure", "summary": "We study the repair of Reed--Solomon codes over $\\mathbb{F}=\\mathbb{B}^t$\nusing traces over $\\mathbb{B}$. Building on the trace framework of\nGuruswami--Wootters (2017), recent work of Liu--Wan--Xing (2024) reduced repair\nbandwidth by studying a related subspace $\\mathcal{W}_k$. In this work, we\ndetermine the dimension of $\\mathcal{W}_k$ exactly using cyclotomic cosets and\nprovide an explicit set of helper nodes that attains bandwidth $(n-d-1)\\log\n|\\mathbb{B}|$ bits with $d=\\text{dim}(\\mathcal{W}_k)$. Moreover, we show that\n$(n-d-1)\\le kt$, and so, trace repair never loses to the classical repair.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Reed-Solomon\u7801\u5728\u6269\u5c55\u57df\u4e0a\u7684\u8ffd\u8e2a\u4fee\u590d\u95ee\u9898\uff0c\u7cbe\u786e\u786e\u5b9a\u4e86\u4fee\u590d\u5b50\u7a7a\u95f4\u7684\u7ef4\u5ea6\uff0c\u5e76\u63d0\u4f9b\u4e86\u8fbe\u5230\u6700\u4f18\u4fee\u590d\u5e26\u5bbd\u7684\u663e\u5f0f\u8f85\u52a9\u8282\u70b9\u9009\u62e9\u65b9\u6848\u3002", "motivation": "\u57fa\u4e8eGuruswami-Wootters\u7684\u8ffd\u8e2a\u6846\u67b6\u548cLiu-Wan-Xing\u7684\u6700\u65b0\u5de5\u4f5c\uff0c\u65e8\u5728\u8fdb\u4e00\u6b65\u964d\u4f4eReed-Solomon\u7801\u4fee\u590d\u7684\u5e26\u5bbd\u6d88\u8017\u3002", "method": "\u4f7f\u7528\u5206\u5706\u966a\u96c6\u7406\u8bba\u7cbe\u786e\u786e\u5b9a\u4fee\u590d\u5b50\u7a7a\u95f4W_k\u7684\u7ef4\u5ea6\uff0c\u5e76\u6784\u9020\u663e\u5f0f\u7684\u8f85\u52a9\u8282\u70b9\u96c6\u5408\u6765\u5b9e\u73b0\u6700\u4f18\u5e26\u5bbd\u4fee\u590d\u3002", "result": "\u8bc1\u660e\u4e86\u4fee\u590d\u5e26\u5bbd\u4e3a(n-d-1)log|B|\u6bd4\u7279\uff0c\u5176\u4e2dd=dim(W_k)\uff0c\u4e14(n-d-1)\u2264kt\uff0c\u8868\u660e\u8ffd\u8e2a\u4fee\u590d\u65b9\u6cd5\u4e0d\u52a3\u4e8e\u7ecf\u5178\u4fee\u590d\u65b9\u6848\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3aReed-Solomon\u7801\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0a\u7684\u6700\u4f18\u4fee\u590d\u5e26\u5bbd\u754c\u9650\u548c\u5177\u4f53\u7684\u5b9e\u73b0\u65b9\u6848\uff0c\u5728\u5206\u5e03\u5f0f\u5b58\u50a8\u7cfb\u7edf\u7684\u7ea0\u5220\u7801\u4fee\u590d\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.05330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05330", "abs": "https://arxiv.org/abs/2509.05330", "authors": ["Seyed Muhammad Hossein Mousavi", "Atiye Ilanloo"], "title": "MVRS: The Multimodal Virtual Reality Stimuli-based Emotion Recognition Dataset", "comment": null, "summary": "Automatic emotion recognition has become increasingly important with the rise\nof AI, especially in fields like healthcare, education, and automotive systems.\nHowever, there is a lack of multimodal datasets, particularly involving body\nmotion and physiological signals, which limits progress in the field. To\naddress this, the MVRS dataset is introduced, featuring synchronized recordings\nfrom 13 participants aged 12 to 60 exposed to VR based emotional stimuli\n(relaxation, fear, stress, sadness, joy). Data were collected using eye\ntracking (via webcam in a VR headset), body motion (Kinect v2), and EMG and GSR\nsignals (Arduino UNO), all timestamp aligned. Participants followed a unified\nprotocol with consent and questionnaires. Features from each modality were\nextracted, fused using early and late fusion techniques, and evaluated with\nclassifiers to confirm the datasets quality and emotion separability, making\nMVRS a valuable contribution to multimodal affective computing.", "AI": {"tldr": "MVRS\u6570\u636e\u96c6\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u6570\u636e\u96c6\uff0c\u5305\u542b13\u540d\u53c2\u4e0e\u8005\u7684\u540c\u6b65\u773c\u52a8\u8ffd\u8e2a\u3001\u8eab\u4f53\u8fd0\u52a8\u3001\u808c\u7535\u548c\u76ae\u7535\u4fe1\u53f7\u6570\u636e\uff0c\u901a\u8fc7VR\u60c5\u611f\u523a\u6fc0\u6536\u96c6\uff0c\u9a8c\u8bc1\u4e86\u591a\u6a21\u6001\u878d\u5408\u5728\u60c5\u611f\u8bc6\u522b\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u60c5\u611f\u8bc6\u522b\u9886\u57df\u7f3a\u4e4f\u5305\u542b\u8eab\u4f53\u8fd0\u52a8\u548c\u751f\u7406\u4fe1\u53f7\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u9650\u5236\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u4f7f\u7528VR\u60c5\u611f\u523a\u6fc0\uff08\u653e\u677e\u3001\u6050\u60e7\u3001\u538b\u529b\u3001\u60b2\u4f24\u3001\u559c\u60a6\uff09\uff0c\u540c\u6b65\u91c7\u96c6\u773c\u52a8\u8ffd\u8e2a\u3001\u8eab\u4f53\u8fd0\u52a8\u3001\u808c\u7535\u548c\u76ae\u7535\u4fe1\u53f7\uff0c\u91c7\u7528\u65e9\u671f\u548c\u665a\u671f\u878d\u5408\u6280\u672f\u63d0\u53d6\u7279\u5f81\u5e76\u8fdb\u884c\u5206\u7c7b\u8bc4\u4f30\u3002", "result": "\u6570\u636e\u96c6\u8d28\u91cf\u826f\u597d\uff0c\u60c5\u611f\u7c7b\u522b\u53ef\u5206\u6027\u5f97\u5230\u9a8c\u8bc1\uff0c\u4e3a\u591a\u6a21\u6001\u60c5\u611f\u8ba1\u7b97\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6570\u636e\u8d44\u6e90\u3002", "conclusion": "MVRS\u6570\u636e\u96c6\u586b\u8865\u4e86\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u6570\u636e\u96c6\u7684\u7a7a\u767d\uff0c\u8bc1\u660e\u4e86\u591a\u6a21\u6001\u878d\u5408\u5728\u60c5\u611f\u8bc6\u522b\u4e2d\u7684\u6f5c\u529b\uff0c\u5bf9\u533b\u7597\u3001\u6559\u80b2\u548c\u6c7d\u8f66\u7cfb\u7edf\u7b49\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.06049", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.06049", "abs": "https://arxiv.org/abs/2509.06049", "authors": ["Andrea Tassi", "Oluwatayo Yetunde Kolawole", "Joan Pujol Roig", "Daniel Warren"], "title": "Optimized Split Computing Framework for Edge and Core Devices", "comment": "To appear on IEEE Transactions on Vehicular Technology", "summary": "With mobile networks expected to support services with stringent requirements\nthat ensure high-quality user experience, the ability to apply Feed-Forward\nNeural Network (FFNN) models to User Equipment (UE) use cases has become\ncritical. Given that UEs have limited resources, running FFNNs directly on UEs\nis an intrinsically challenging problem. This letter proposes an optimization\nframework for split computing applications where an FFNN model is partitioned\ninto multiple sections, and executed by UEs, edge- and core-located nodes to\nreduce the required UE computational footprint while containing the inference\ntime. An efficient heuristic strategy for solving the optimization problem is\nalso provided. The proposed framework is shown to be robust in heterogeneous\nsettings, eliminating the need for retraining and reducing the UE's memory\n(CPU) footprint by over 33.6% (60%).", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5206\u5f00\u8ba1\u7b97\u5e94\u7528\u7684\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u524d\u5411\u795e\u7ecf\u7f51\u7edc\u5206\u5272\u5728\u7528\u6237\u8bbe\u5907\u3001\u8fb9\u7f18\u8282\u70b9\u548c\u6838\u5fc3\u8282\u70b9\u4e0a\u6267\u884c\uff0c\u4ee5\u51cf\u5c11\u7528\u6237\u8bbe\u5907\u7684\u8ba1\u7b97\u8d44\u6e90\u5360\u7528\u5e76\u63a7\u5236\u63a8\u7406\u65f6\u95f4\u3002", "motivation": "\u7535\u52a8\u673a\u7f51\u7edc\u9700\u8981\u652f\u6301\u5177\u6709\u4e25\u683c\u8981\u6c42\u7684\u670d\u52a1\uff0c\u786e\u4fdd\u9ad8\u8d28\u91cf\u7528\u6237\u4f53\u9a8c\u3002\u7535\u52a8\u673a\u7f51\u7edc\u9884\u8ba1\u5c06\u652f\u6301\u4e25\u683c\u8981\u6c42\u7684\u670d\u52a1\uff0c\u4ee5\u786e\u4fdd\u9ad8\u8d28\u91cf\u7684\u7528\u6237\u4f53\u9a8c\u3002\u7531\u4e8e\u7528\u6237\u8bbe\u5907\u8d44\u6e90\u6709\u9650\uff0c\u76f4\u63a5\u5728\u7528\u6237\u8bbe\u5907\u4e0a\u8fd0\u884c\u524d\u5411\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u662f\u4e00\u4e2a\u672c\u8d28\u4e0a\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4f18\u5316\u6846\u67b6\uff0c\u5c06\u524d\u5411\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5206\u5272\u6210\u591a\u4e2a\u90e8\u5206\uff0c\u5206\u522b\u5728\u7528\u6237\u8bbe\u5907\u3001\u8fb9\u7f18\u8282\u70b9\u548c\u6838\u5fc3\u8282\u70b9\u4e0a\u6267\u884c\u3002\u8fd8\u63d0\u4f9b\u4e86\u89e3\u51b3\u4f18\u5316\u95ee\u9898\u7684\u9ad8\u6548\u5427\u6d4e\u7b56\u7565\u3002", "result": "\u8bc1\u660e\u8be5\u6846\u67b6\u5728\u5f02\u6784\u73af\u5883\u4e2d\u5177\u6709\u7a33\u5065\u6027\uff0c\u6d88\u9664\u4e86\u91cd\u65b0\u8bad\u7ec3\u7684\u9700\u6c42\uff0c\u5e76\u5c06\u7528\u6237\u8bbe\u5907\u7684\u5185\u5b58\u5360\u7528\u51cf\u5c1133.6%\uff0cCPU\u5360\u7528\u51cf\u5c1160%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5206\u5f00\u8ba1\u7b97\u6709\u6548\u51cf\u5c11\u4e86\u7528\u6237\u8bbe\u5907\u7684\u8ba1\u7b97\u8d1f\u62c5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u8fb9\u7f18\u8ba1\u7b97\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.06670", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.06670", "abs": "https://arxiv.org/abs/2509.06670", "authors": ["Mohammed El Oued"], "title": "On catastrophicity of convolutional codes and their encoders over $\\Z_{p^r}$", "comment": null, "summary": "This paper investigates the existence of minimal $p$-encoders for\nconvolutional codes over $\\mathbb{Z}_{p^r}$, where $p$ is a prime. This\naddresses a conjecture from \\cite{k}, which posits that every such code admits\na minimal $p$-encoder, implying that all convolutional codes over\n$\\mathbb{Z}_{p^r}$ are noncatastrophic when input sequences are restricted to\ncoefficients in $\\{0, \\dots, p-1\\}$. Our contributions include the introduction\nof a new polynomial invariant that characterizes free codes, which enables us\nto establish a necessary and sufficient condition for a free code over\n$\\mathbb{Z}_{p^r}$ to be noncatastrophic in the usual sense (where input\ncoefficients are from $\\mathbb{Z}_{p^r}$). Based on these findings, we affirm\nthe conjecture by providing a constructive method for obtaining a minimal\n$p$-encoder for any convolutional code over $\\mathbb{Z}_{p^r}$.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u5377\u79ef\u7801\u5728Z_{p^r}\u4e0a\u5b58\u5728\u6700\u5c0fp-\u7f16\u7801\u5668\uff0c\u8bc1\u5b9e\u4e86\u76f8\u5173\u731c\u60f3\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u591a\u9879\u5f0f\u4e0d\u53d8\u91cf\u6765\u523b\u753b\u81ea\u7531\u7801\u7684\u975e\u707e\u96be\u6027\u6761\u4ef6\u3002", "motivation": "\u89e3\u51b3\u5173\u4e8eZ_{p^r}\u4e0a\u5377\u79ef\u7801\u5b58\u5728\u6700\u5c0fp-\u7f16\u7801\u5668\u7684\u731c\u60f3\uff0c\u8be5\u731c\u60f3\u6697\u793a\u5f53\u8f93\u5165\u5e8f\u5217\u7cfb\u6570\u9650\u5236\u5728{0,...,p-1}\u65f6\uff0c\u6240\u6709\u6b64\u7c7b\u5377\u79ef\u7801\u90fd\u662f\u975e\u707e\u96be\u6027\u7684\u3002", "method": "\u5f15\u5165\u65b0\u7684\u591a\u9879\u5f0f\u4e0d\u53d8\u91cf\u6765\u523b\u753b\u81ea\u7531\u7801\uff0c\u5efa\u7acb\u81ea\u7531\u7801\u5728Z_{p^r}\u4e0a\u975e\u707e\u96be\u6027\u7684\u5145\u8981\u6761\u4ef6\uff0c\u5e76\u63d0\u4f9b\u6784\u9020\u6027\u65b9\u6cd5\u83b7\u5f97\u6700\u5c0fp-\u7f16\u7801\u5668\u3002", "result": "\u8bc1\u5b9e\u4e86\u731c\u60f3\uff0c\u4e3a\u4efb\u610fZ_{p^r}\u4e0a\u7684\u5377\u79ef\u7801\u63d0\u4f9b\u4e86\u83b7\u5f97\u6700\u5c0fp-\u7f16\u7801\u5668\u7684\u6784\u9020\u65b9\u6cd5\u3002", "conclusion": "\u6240\u6709Z_{p^r}\u4e0a\u7684\u5377\u79ef\u7801\u90fd\u5b58\u5728\u6700\u5c0fp-\u7f16\u7801\u5668\uff0c\u4e14\u5728\u9650\u5236\u8f93\u5165\u7cfb\u6570\u6761\u4ef6\u4e0b\u90fd\u662f\u975e\u707e\u96be\u6027\u7684\uff0c\u8fd9\u901a\u8fc7\u65b0\u7684\u591a\u9879\u5f0f\u4e0d\u53d8\u91cf\u548c\u6784\u9020\u6027\u65b9\u6cd5\u5f97\u5230\u8bc1\u660e\u3002"}}
{"id": "2509.05346", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05346", "abs": "https://arxiv.org/abs/2509.05346", "authors": ["Bo Yuan", "Jiazi Hu"], "title": "Benchmarking Large Language Models for Personalized Guidance in AI-Enhanced Learning", "comment": null, "summary": "While Large Language Models (LLMs) are increasingly envisioned as intelligent\nassistants for personalized learning, systematic head-to-head evaluations\nwithin authentic learning scenarios remain limited. This study conducts an\nempirical comparison of three state-of-the-art LLMs on a tutoring task that\nsimulates a realistic learning setting. Using a dataset comprising a student's\nanswers to ten questions of mixed formats with correctness labels, each LLM is\nrequired to (i) analyze the quiz to identify underlying knowledge components,\n(ii) infer the student's mastery profile, and (iii) generate targeted guidance\nfor improvement. To mitigate subjectivity and evaluator bias, we employ Gemini\nas a virtual judge to perform pairwise comparisons along various dimensions:\naccuracy, clarity, actionability, and appropriateness. Results analyzed via the\nBradley-Terry model indicate that GPT-4o is generally preferred, producing\nfeedback that is more informative and better structured than its counterparts,\nwhile DeepSeek-V3 and GLM-4.5 demonstrate intermittent strengths but lower\nconsistency. These findings highlight the feasibility of deploying LLMs as\nadvanced teaching assistants for individualized support and provide\nmethodological guidance for future empirical research on LLM-driven\npersonalized learning.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9GPT-4o\u3001DeepSeek-V3\u548cGLM-4.5\u4e09\u79cd\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e2a\u6027\u5316\u5b66\u4e60\u8f85\u5bfc\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u5b9e\u8bc1\u6bd4\u8f83\uff0c\u53d1\u73b0GPT-4o\u5728\u63d0\u4f9b\u4fe1\u606f\u4e30\u5bcc\u3001\u7ed3\u6784\u826f\u597d\u7684\u53cd\u9988\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u8bbe\u60f3\u4e3a\u4e2a\u6027\u5316\u5b66\u4e60\u7684\u667a\u80fd\u52a9\u624b\uff0c\u4f46\u5728\u771f\u5b9e\u5b66\u4e60\u573a\u666f\u4e2d\u7684\u7cfb\u7edf\u5316\u5bf9\u6bd4\u8bc4\u4f30\u4ecd\u7136\u6709\u9650\uff0c\u9700\u8981\u5b9e\u8bc1\u7814\u7a76\u6765\u9a8c\u8bc1\u5176\u5b9e\u9645\u6548\u679c\u3002", "method": "\u4f7f\u7528\u5305\u542b\u5b66\u751f\u7b54\u6848\u548c\u6b63\u786e\u6027\u6807\u7b7e\u7684\u6570\u636e\u96c6\uff0c\u8981\u6c42\u6bcf\u4e2aLLM\u5206\u6790\u6d4b\u9a8c\u3001\u63a8\u65ad\u5b66\u751f\u638c\u63e1\u60c5\u51b5\u5e76\u751f\u6210\u9488\u5bf9\u6027\u6307\u5bfc\u3002\u91c7\u7528Gemini\u4f5c\u4e3a\u865a\u62df\u8bc4\u59d4\u8fdb\u884c\u591a\u7ef4\u5ea6\u4e24\u4e24\u6bd4\u8f83\uff0c\u5e76\u4f7f\u7528Bradley-Terry\u6a21\u578b\u5206\u6790\u7ed3\u679c\u3002", "result": "GPT-4o\u603b\u4f53\u4e0a\u66f4\u53d7\u9752\u7750\uff0c\u4ea7\u751f\u7684\u53cd\u9988\u4fe1\u606f\u66f4\u4e30\u5bcc\u3001\u7ed3\u6784\u66f4\u597d\uff1bDeepSeek-V3\u548cGLM-4.5\u5c55\u73b0\u51fa\u95f4\u6b47\u6027\u4f18\u52bf\u4f46\u4e00\u81f4\u6027\u8f83\u4f4e\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u5c06LLMs\u90e8\u7f72\u4e3a\u9ad8\u7ea7\u6559\u5b66\u52a9\u624b\u8fdb\u884c\u4e2a\u6027\u5316\u652f\u6301\u7684\u53ef\u884c\u6027\uff0c\u5e76\u4e3a\u672a\u6765LLM\u9a71\u52a8\u7684\u4e2a\u6027\u5316\u5b66\u4e60\u5b9e\u8bc1\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u6cd5\u5b66\u6307\u5bfc\u3002"}}
{"id": "2509.06245", "categories": ["cs.NI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2509.06245", "abs": "https://arxiv.org/abs/2509.06245", "authors": ["Shyam Kumar Shrestha", "Jonathan Kua", "Shiva Raj Pokhrel"], "title": "Understanding BBRv3 Performance in AQM-Enabled WiFi Networks", "comment": "The 50th IEEE Conference on Local Computer Networks (LCN) October\n  14-16, 2025, Sydney, Australia", "summary": "We present a modular experimental testbed and lightweight visualization tool\nfor evaluating TCP congestion control performance in wireless networks. We\ncompare Google's latest Bottleneck Bandwidth and Round-trip time version 3\n(BBRv3) algorithm with loss-based CUBIC under varying Active Queue Management\n(AQM) schemes, namely PFIFO, FQ-CoDel, and CAKE, on a Wi-Fi link using a\ncommercial MikroTik router. Our real-time dashboard visualizes metrics such as\nthroughput, latency, and fairness across competing flows. Results show that\nBBRv3 significantly improves fairness and convergence under AQM, especially\nwith FQ-CoDel. Our visualization tool and modular testbed provide a practical\nfoundation for evaluating next-generation TCP variants in real-world\nAQM-enabled home wireless networks.", "AI": {"tldr": "\u901a\u8fc7\u6a21\u5757\u5316\u5b9e\u9a8c\u6d4b\u8bd5\u5e8a\u548c\u53ef\u89c6\u5316\u5de5\u5177\u6bd4\u8f83BBRv3\u548cCUBIC\u5728Wi-Fi\u7f51\u7edc\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0BBRv3\u5728AQM\u73af\u5883\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u516c\u5e73\u6027\u548c\u6536\u655b\u6027", "motivation": "\u8bc4\u4f30TCP\u62e5\u585e\u63a7\u5236\u7b97\u6cd5\u5728\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u4e0d\u540c\u4e3b\u52a8\u961f\u5217\u7ba1\u7406(AQM)\u65b9\u6848\u4e0b\u7684\u8868\u73b0", "method": "\u4f7f\u7528\u6a21\u5757\u5316\u5b9e\u9a8c\u6d4b\u8bd5\u5e8a\u548c\u8f7b\u91cf\u7ea7\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u5728MikroTik\u8def\u7531\u5668\u7684Wi-Fi\u94fe\u8def\u4e0a\u6bd4\u8f83BBRv3\u548cCUBIC\u7b97\u6cd5\uff0c\u6d4b\u8bd5\u4e0d\u540cAQM\u65b9\u6848(PFIFO\u3001FQ-CoDel\u3001CAKE)", "result": "BBRv3\u5728AQM\u73af\u5883\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u516c\u5e73\u6027\u548c\u6536\u655b\u6027\uff0c\u5c24\u5176\u662f\u4e0eFQ-CoDel\u7ed3\u5408\u65f6\u6548\u679c\u6700\u4f73", "conclusion": "\u8be5\u53ef\u89c6\u5316\u5de5\u5177\u548c\u6a21\u5757\u5316\u6d4b\u8bd5\u5e8a\u4e3a\u5728\u5b9e\u9645\u5bb6\u5ead\u65e0\u7ebf\u7f51\u7edc\u4e2d\u8bc4\u4f30\u4e0b\u4e00\u4ee3TCP\u53d8\u4f53\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840"}}
{"id": "2509.06692", "categories": ["cs.IT", "cs.DM", "math.IT", "94B25, 94B50, 94B65, 68P30, 68R05"], "pdf": "https://arxiv.org/pdf/2509.06692", "abs": "https://arxiv.org/abs/2509.06692", "authors": ["Mladen Kova\u010devi\u0107", "Keshav Goyal", "Han Mao Kiah"], "title": "Codes Correcting Transpositions of Consecutive Symbols", "comment": null, "summary": "The problem of correcting transpositions (or swaps) of consecutive symbols in\n$ q $-ary strings is studied. A family of codes correcting a transposition at\nan arbitrary location is described and proved to have asymptotically optimal\nredundancy. Additionally, an improved construction is given over a binary\nalphabet. Bounds on the cardinality of codes correcting $ t = \\textrm{const} $\ntranspositions are obtained. A lower bound on the achievable asymptotic rate of\noptimal codes correcting $ t = \\tau n $ transpositions is derived. Finally, a\nconstruction of codes correcting all possible patterns of transpositions is\npresented, and the corresponding lower bound on the zero-error capacity of the\n$ q $-ary transposition channel is stated.", "AI": {"tldr": "\u7814\u7a76q\u5143\u5b57\u7b26\u4e32\u4e2d\u8fde\u7eed\u7b26\u53f7\u8f6c\u7f6e\u9519\u8bef\u7684\u7ea0\u9519\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u591a\u79cd\u7ea0\u9519\u7801\u6784\u9020\u65b9\u6cd5\u5e76\u5206\u6790\u4e86\u5176\u6027\u80fd\u754c\u9650", "motivation": "\u89e3\u51b3q\u5143\u5b57\u7b26\u4e32\u4e2d\u8fde\u7eed\u7b26\u53f7\u8f6c\u7f6e\uff08\u4ea4\u6362\uff09\u9519\u8bef\u7684\u7ea0\u9519\u95ee\u9898\uff0c\u8fd9\u7c7b\u9519\u8bef\u5728\u5b9e\u9645\u901a\u4fe1\u548c\u6570\u636e\u5b58\u50a8\u4e2d\u7ecf\u5e38\u53d1\u751f", "method": "\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u7ea0\u9519\u7801\u6784\u9020\u65b9\u6cd5\uff1a1\uff09\u7ea0\u6b63\u4efb\u610f\u4f4d\u7f6e\u5355\u4e2a\u8f6c\u7f6e\u9519\u8bef\u7684\u7801\u65cf\uff1b2\uff09\u4e8c\u8fdb\u5236\u5b57\u6bcd\u8868\u4e0a\u7684\u6539\u8fdb\u6784\u9020\uff1b3\uff09\u7ea0\u6b63t\u4e2a\u5e38\u6570\u91cf\u8f6c\u7f6e\u9519\u8bef\u7684\u7801\uff1b4\uff09\u7ea0\u6b63\u03c4n\u6bd4\u4f8b\u8f6c\u7f6e\u9519\u8bef\u7684\u7801\uff1b5\uff09\u7ea0\u6b63\u6240\u6709\u53ef\u80fd\u8f6c\u7f6e\u6a21\u5f0f\u7684\u7801\u6784\u9020", "result": "\u8bc1\u660e\u4e86\u6240\u63d0\u7801\u65cf\u5177\u6709\u6e10\u8fd1\u6700\u4f18\u5197\u4f59\u5ea6\uff0c\u83b7\u5f97\u4e86\u7ea0\u6b63t\u4e2a\u8f6c\u7f6e\u9519\u8bef\u7684\u7801\u57fa\u6570\u754c\u9650\uff0c\u63a8\u5bfc\u4e86\u6700\u4f18\u7801\u7684\u6e10\u8fd1\u7387\u4e0b\u754c\uff0c\u7ed9\u51fa\u4e86q\u5143\u8f6c\u7f6e\u4fe1\u9053\u7684\u96f6\u9519\u8bef\u5bb9\u91cf\u4e0b\u754c", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8f6c\u7f6e\u9519\u8bef\u7ea0\u9519\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7684\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u7684\u7f16\u7801\u6784\u9020\uff0c\u5efa\u7acb\u4e86\u76f8\u5173\u6027\u80fd\u754c\u9650\uff0c\u5bf9\u5b9e\u9645\u901a\u4fe1\u7cfb\u7edf\u7684\u9519\u8bef\u63a7\u5236\u5177\u6709\u91cd\u8981\u610f\u4e49"}}
{"id": "2509.05363", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.05363", "abs": "https://arxiv.org/abs/2509.05363", "authors": ["Lijie Ding", "Changwoo Do"], "title": "SasAgent: Multi-Agent AI System for Small-Angle Scattering Data Analysis", "comment": "8 pages, 7 figures", "summary": "We introduce SasAgent, a multi-agent AI system powered by large language\nmodels (LLMs) that automates small-angle scattering (SAS) data analysis by\nleveraging tools from the SasView software and enables user interaction via\ntext input. SasAgent features a coordinator agent that interprets user prompts\nand delegates tasks to three specialized agents for scattering length density\n(SLD) calculation, synthetic data generation, and experimental data fitting.\nThese agents utilize LLM-friendly tools to execute tasks efficiently. These\ntools, including the model data tool, Retrieval-Augmented Generation (RAG)\ndocumentation tool, bump fitting tool, and SLD calculator tool, are derived\nfrom the SasView Python library. A user-friendly Gradio-based interface\nenhances user accessibility. Through diverse examples, we demonstrate\nSasAgent's ability to interpret complex prompts, calculate SLDs, generate\naccurate scattering data, and fit experimental datasets with high precision.\nThis work showcases the potential of LLM-driven AI systems to streamline\nscientific workflows and enhance automation in SAS research.", "AI": {"tldr": "SasAgent\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u4ee3\u7406AI\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u5c0f\u89d2\u6563\u5c04\u6570\u636e\u5206\u6790\uff0c\u901a\u8fc7SasView\u5de5\u5177\u548c\u6587\u672c\u4ea4\u4e92\u5b9e\u73b0\u9ad8\u6548\u79d1\u5b66\u5de5\u4f5c\u6d41", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5c0f\u89d2\u6563\u5c04\u6570\u636e\u5206\u6790\u7684\u590d\u6742\u6027\uff0c\u63d0\u9ad8\u81ea\u52a8\u5316\u6c34\u5e73\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6765\u7b80\u5316\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b", "method": "\u91c7\u7528\u591a\u4ee3\u7406\u67b6\u6784\uff0c\u5305\u62ec\u534f\u8c03\u4ee3\u7406\u548c\u4e09\u4e2a\u4e13\u4e1a\u4ee3\u7406\uff08SLD\u8ba1\u7b97\u3001\u5408\u6210\u6570\u636e\u751f\u6210\u3001\u5b9e\u9a8c\u6570\u636e\u62df\u5408\uff09\uff0c\u4f7f\u7528LLM\u53cb\u597d\u7684\u5de5\u5177\u96c6\u548cGradio\u7528\u6237\u754c\u9762", "result": "\u7cfb\u7edf\u80fd\u591f\u89e3\u91ca\u590d\u6742\u63d0\u793a\u3001\u7cbe\u786e\u8ba1\u7b97\u6563\u5c04\u957f\u5ea6\u5bc6\u5ea6\u3001\u751f\u6210\u51c6\u786e\u6563\u5c04\u6570\u636e\uff0c\u5e76\u4ee5\u9ad8\u7cbe\u5ea6\u62df\u5408\u5b9e\u9a8c\u6570\u636e\u96c6", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86LLM\u9a71\u52a8\u7684AI\u7cfb\u7edf\u5728\u7b80\u5316\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u548c\u589e\u5f3aSAS\u7814\u7a76\u81ea\u52a8\u5316\u65b9\u9762\u7684\u5de8\u5927\u6f5c\u529b"}}
{"id": "2509.06451", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.06451", "abs": "https://arxiv.org/abs/2509.06451", "authors": ["Filippo Bragato", "Tullia Fontana", "Marco Giordani", "Malte Schellmann", "Josef Eichinger", "Michele Zorzi"], "title": "Network-Aware Control of AGVs in an Industrial Scenario: A Simulation Study Based on ROS 2 and Gazebo", "comment": "This paper has been accepted for publication at IEEE International\n  Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC), 2025", "summary": "Networked Control System (NCS) is a paradigm where sensors, controllers, and\nactuators communicate over a shared network. One promising application of NCS\nis the control of Automated Guided Vehicles (AGVs) in the industrial\nenvironment, for example to transport goods efficiently and to autonomously\nfollow predefined paths or routes. In this context, communication and control\nare tightly correlated, a paradigm referred to as Joint Communication and\nControl (JCC), since network issues such as delays or errors can lead to\nsignificant deviations of the AGVs from the planned trajectory. In this paper,\nwe present a simulation framework based on Gazebo and Robot Operating System 2\n(ROS 2) to simulate and visualize, respectively, the complex interaction\nbetween the control of AGVs and the underlying communication network. This\nframework explicitly incorporates communication metrics, such as delay and\npacket loss, and control metrics, especially the Mean Squared Error (MSE)\nbetween the optimal/desired and actual path of the AGV in response to driving\ncommands. Our results shed light into the correlation between the network\nperformance, particularly Packet Reception Ratio (PRR), and accuracy of\ncontrol.", "AI": {"tldr": "\u57fa\u4e8eGazebo\u548cROS 2\u7684\u7efc\u5408\u901a\u4fe1\u4e0e\u63a7\u5236\u6a21\u62df\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u7f51\u7edc\u6027\u80fd\u5bf9AGV\u8f66\u8f68\u8ff9\u63a7\u5236\u7cbe\u5ea6\u7684\u5f71\u54cd", "motivation": "\u7f51\u7edc\u5316\u63a7\u5236\u7cfb\u7edf\u4e2d\uff0c\u901a\u4fe1\u4e0e\u63a7\u5236\u5bc6\u5207\u76f8\u5173\uff0c\u7f51\u7edc\u5ef6\u8fdf\u548c\u9519\u8bef\u53ef\u5bfc\u81f4AGV\u8f66\u8f68\u8ff9\u504f\u79fb\uff0c\u9700\u8981\u7814\u7a76\u4e24\u8005\u7684\u5173\u8054\u6027", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eGazebo\u6a21\u62df\u5668\u548cROS 2\u7684\u53ef\u89c6\u5316\u6a21\u62df\u6846\u67b6\uff0c\u660e\u786e\u7edf\u8ba1\u901a\u4fe1\u6307\u6807\uff08\u5ef6\u8fdf\u3001\u5305\u4e22\u5931\uff09\u548c\u63a7\u5236\u6307\u6807\uff08\u5747\u65b9\u8bef\u5deeMSE\uff09", "result": "\u83b7\u5f97\u4e86\u7f51\u7edc\u6027\u80fd\uff08\u7279\u522b\u662f\u5305\u63a5\u6536\u6bd4PRR\uff09\u4e0e\u63a7\u5236\u7cbe\u5ea6\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u7ed3\u679c", "conclusion": "\u8bc1\u660e\u4e86\u901a\u4fe1\u4e0e\u63a7\u5236\u5728NCS\u4e2d\u7684\u5bc6\u5207\u5173\u8054\uff0c\u63d0\u4f9b\u7684\u6a21\u62df\u6846\u67b6\u6709\u52a9\u4e8e\u5206\u6790\u7f51\u7edc\u95ee\u9898\u5bf9AGV\u8f66\u8f68\u8ff9\u63a7\u5236\u7684\u5f71\u54cd"}}
{"id": "2509.06912", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.06912", "abs": "https://arxiv.org/abs/2509.06912", "authors": ["Zhipeng Li", "Wenjie Ma", "Zhifang Zhang"], "title": "Rate-Optimal Streaming Codes over Three-Node Relay Networks with Burst Erasures", "comment": null, "summary": "This paper investigates streaming codes over three-node relay networks under\nburst packet erasures with a delay constraint $T$. In any sliding window of\n$T+1$ consecutive packets, the source-to-relay and relay-to-destination\nchannels may introduce burst erasures of lengths at most $b_1$ and $b_2$,\nrespectively. Singhvi et al. proposed a construction achieving the optimal code\nrate when $\\max\\{b_1,b_2\\}\\mid (T-b_1-b_2)$. We construct streaming codes with\nthe optimal rate under the condition\n  $T\\geq b_1+b_2+\\frac{b_1b_2}{|b_1-b_2|}$, thereby enriching the family of\nrate-optimal streaming codes for three-node relay networks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e09\u8282\u70b9\u4e2d\u7ee7\u7f51\u7edc\u4e2d\u7684\u6d41\u5f0f\u7f16\u7801\uff0c\u9488\u5bf9\u7a81\u53d1\u5305\u64e6\u9664\u548c\u5ef6\u8fdf\u7ea6\u675fT\uff0c\u63d0\u51fa\u4e86\u5728T\u2265b\u2081+b\u2082+b\u2081b\u2082/|b\u2081-b\u2082|\u6761\u4ef6\u4e0b\u5b9e\u73b0\u6700\u4f18\u7801\u7387\u7684\u6d41\u5f0f\u7801\u6784\u9020\u65b9\u6cd5", "motivation": "\u89e3\u51b3\u4e09\u8282\u70b9\u4e2d\u7ee7\u7f51\u7edc\u4e2d\u7a81\u53d1\u5305\u64e6\u9664\u95ee\u9898\uff0c\u5728\u5ef6\u8fdf\u7ea6\u675f\u4e0b\u5b9e\u73b0\u6700\u4f18\u7801\u7387\u7684\u6d41\u5f0f\u7f16\u7801\uff0c\u6269\u5c55\u73b0\u6709\u6700\u4f18\u7801\u7387\u6784\u9020\u65b9\u6cd5\u7684\u9002\u7528\u8303\u56f4", "method": "\u6784\u9020\u6d41\u5f0f\u7f16\u7801\u65b9\u6848\uff0c\u9488\u5bf9\u6e90-\u4e2d\u7ee7\u548c\u4e2d\u7ee7-\u76ee\u6807\u4fe1\u9053\u5206\u522b\u5b58\u5728\u6700\u5927\u957f\u5ea6b\u2081\u548cb\u2082\u7684\u7a81\u53d1\u64e6\u9664\uff0c\u5728\u6ed1\u52a8\u7a97\u53e3T+1\u4e2a\u8fde\u7eed\u5305\u5185\u6ee1\u8db3\u5ef6\u8fdf\u7ea6\u675f", "result": "\u63d0\u51fa\u4e86\u5728T\u2265b\u2081+b\u2082+b\u2081b\u2082/|b\u2081-b\u2082|\u6761\u4ef6\u4e0b\u80fd\u591f\u5b9e\u73b0\u6700\u4f18\u7801\u7387\u7684\u6d41\u5f0f\u7801\u6784\u9020\uff0c\u4e30\u5bcc\u4e86\u6700\u4f18\u7801\u7387\u6d41\u5f0f\u7801\u7684\u5bb6\u65cf", "conclusion": "\u8be5\u6784\u9020\u65b9\u6cd5\u6269\u5c55\u4e86Singhvi\u7b49\u4eba\u5148\u524d\u5de5\u4f5c\u7684\u6761\u4ef6\uff0c\u4e3a\u4e09\u8282\u70b9\u4e2d\u7ee7\u7f51\u7edc\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u9002\u7528\u7684\u6700\u4f18\u7801\u7387\u6d41\u5f0f\u7f16\u7801\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.05375", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05375", "abs": "https://arxiv.org/abs/2509.05375", "authors": ["Arend Hintze"], "title": "Characterizing Fitness Landscape Structures in Prompt Engineering", "comment": null, "summary": "While prompt engineering has emerged as a crucial technique for optimizing\nlarge language model performance, the underlying optimization landscape remains\npoorly understood. Current approaches treat prompt optimization as a black-box\nproblem, applying sophisticated search algorithms without characterizing the\nlandscape topology they navigate. We present a systematic analysis of fitness\nlandscape structures in prompt engineering using autocorrelation analysis\nacross semantic embedding spaces. Through experiments on error detection tasks\nwith two distinct prompt generation strategies -- systematic enumeration (1,024\nprompts) and novelty-driven diversification (1,000 prompts) -- we reveal\nfundamentally different landscape topologies. Systematic prompt generation\nyields smoothly decaying autocorrelation, while diversified generation exhibits\nnon-monotonic patterns with peak correlation at intermediate semantic\ndistances, indicating rugged, hierarchically structured landscapes.\nTask-specific analysis across 10 error detection categories reveals varying\ndegrees of ruggedness across different error types. Our findings provide an\nempirical foundation for understanding the complexity of optimization in prompt\nengineering landscapes.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u81ea\u76f8\u5173\u5206\u6790\u63ed\u793a\u4e86\u63d0\u793a\u5de5\u7a0b\u4f18\u5316\u666f\u89c2\u7684\u7ed3\u6784\u7279\u5f81\uff0c\u53d1\u73b0\u7cfb\u7edf\u5316\u63d0\u793a\u751f\u6210\u4ea7\u751f\u5e73\u6ed1\u8870\u51cf\u7684\u81ea\u76f8\u5173\uff0c\u800c\u591a\u6837\u5316\u751f\u6210\u5219\u5448\u73b0\u975e\u5355\u8c03\u6a21\u5f0f\uff0c\u8868\u660e\u5b58\u5728\u5d0e\u5c96\u3001\u5206\u5c42\u7ed3\u6784\u7684\u666f\u89c2\u3002", "motivation": "\u867d\u7136\u63d0\u793a\u5de5\u7a0b\u5df2\u6210\u4e3a\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u5176\u5e95\u5c42\u4f18\u5316\u666f\u89c2\u4ecd\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002\u5f53\u524d\u65b9\u6cd5\u5c06\u63d0\u793a\u4f18\u5316\u89c6\u4e3a\u9ed1\u76d2\u95ee\u9898\uff0c\u5e94\u7528\u590d\u6742\u641c\u7d22\u7b97\u6cd5\u4f46\u672a\u63cf\u8ff0\u5176\u5bfc\u822a\u7684\u666f\u89c2\u62d3\u6251\u7ed3\u6784\u3002", "method": "\u4f7f\u7528\u8bed\u4e49\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u81ea\u76f8\u5173\u5206\u6790\u6765\u7cfb\u7edf\u5206\u6790\u63d0\u793a\u5de5\u7a0b\u4e2d\u7684\u9002\u5e94\u5ea6\u666f\u89c2\u7ed3\u6784\u3002\u901a\u8fc7\u5728\u9519\u8bef\u68c0\u6d4b\u4efb\u52a1\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u91c7\u7528\u4e24\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u751f\u6210\u7b56\u7565\uff1a\u7cfb\u7edf\u679a\u4e3e\uff081,024\u4e2a\u63d0\u793a\uff09\u548c\u65b0\u9896\u6027\u9a71\u52a8\u7684\u591a\u6837\u5316\uff081,000\u4e2a\u63d0\u793a\uff09\u3002", "result": "\u53d1\u73b0\u7cfb\u7edf\u5316\u63d0\u793a\u751f\u6210\u4ea7\u751f\u5e73\u6ed1\u8870\u51cf\u7684\u81ea\u76f8\u5173\uff0c\u800c\u591a\u6837\u5316\u751f\u6210\u5448\u73b0\u975e\u5355\u8c03\u6a21\u5f0f\uff0c\u5728\u4e2d\u95f4\u8bed\u4e49\u8ddd\u79bb\u5904\u51fa\u73b0\u5cf0\u503c\u76f8\u5173\u6027\uff0c\u8868\u660e\u5b58\u5728\u5d0e\u5c96\u3001\u5206\u5c42\u7ed3\u6784\u7684\u666f\u89c2\u3002\u8de810\u4e2a\u9519\u8bef\u68c0\u6d4b\u7c7b\u522b\u7684\u4efb\u52a1\u7279\u5b9a\u5206\u6790\u663e\u793a\u4e0d\u540c\u9519\u8bef\u7c7b\u578b\u5177\u6709\u4e0d\u540c\u7a0b\u5ea6\u7684\u5d0e\u5c96\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u7406\u89e3\u63d0\u793a\u5de5\u7a0b\u666f\u89c2\u4e2d\u4f18\u5316\u7684\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u63d0\u793a\u751f\u6210\u7b56\u7565\u4ea7\u751f\u7684\u6839\u672c\u4e0d\u540c\u7684\u666f\u89c2\u62d3\u6251\u7ed3\u6784\u3002"}}
{"id": "2509.06454", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.06454", "abs": "https://arxiv.org/abs/2509.06454", "authors": ["Julia Caleya-Sanchez", "Pablo Mu\u00f1oz", "Jorge S\u00e1nchez-Garrido", "Emilio Florent\u00edn", "Felix Delgado-Ferro", "Pablo Rodriguez-Martin", "Pablo Ameigeiras"], "title": "Empirical Evaluation of a 5G Transparent Clock for Time Synchronization in a TSN-5G Network", "comment": "6 pages, 5 figures", "summary": "Time synchronization is essential for industrial IoT and Industry 4.0/5.0\napplications, but achieving high synchronization accuracy in Time-Sensitive\nNetworking (TSN)-5G networks is challenging due to jitter and asymmetric\ndelays. 3GPP TS 23.501 defines three 5G synchronization modes: time-aware\nsystem, boundary clock (BC), and transparent clock (TC), where TC offers a\npromising solution. However, to the best of our knowledge, there is no\nempirical evaluation of TC in a TSN-5G network. This paper empirically\nevaluates an 5G end-to-end TC in a TSN-5G network, implemented on commercial\nTSN switches with a single clock. For TC development, we compute the residence\ntime in 5G and recover the clock domain at the slave node. We deploy a TSN-5G\ntestbed with commercial equipment for synchronization evaluation by modifying\nthe Precision Timing Protocol (PTP) message transmission rates. Experimental\nresults show a peak-to-peak synchronization of 500 ns, meeting the industrial\nrequirement of < 1 us, with minimal synchronization offsets for specific PTP\nmessage transmission rates.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u5728TSN-5G\u7f51\u7edc\u4e2d\u5b9e\u73b0\u900f\u660e\u65f6\u949f(TC)\u7684\u6027\u80fd\uff0c\u8fbe\u5230\u4e86500\u7eb3\u79d2\u7684\u540c\u6b65\u7cbe\u5ea6\uff0c\u6ee1\u8db3\u5de5\u4e1a\u5e94\u7528<1\u5fae\u79d2\u7684\u8981\u6c42\u3002", "motivation": "\u5de5\u4e1aIoT\u548c\u4ea7\u4e1a4.0/5.0\u5e94\u7528\u9700\u8981\u9ad8\u7cbe\u5ea6\u65f6\u95f4\u540c\u6b65\uff0c\u4f46TSN-5G\u7f51\u7edc\u4e2d\u7684\u632f\u8361\u548c\u975e\u5bf9\u79f0\u5ef6\u8fdf\u5e26\u6765\u6311\u6218\u3002\u867d\u71363GPP\u5b9a\u4e49\u4e86\u900f\u660e\u65f6\u949f\u6a21\u5f0f\uff0c\u4f46\u7f3a\u5c11\u5b9e\u8df5\u9a8c\u8bc1\u3002", "method": "\u5728\u5546\u7528TSN\u4ea4\u6362\u673a\u4e0a\u5b9e\u73b0\u5355\u65f6\u949f5G\u7aef\u5230\u7aefTC\uff0c\u8ba1\u7b975G\u4e2d\u7684\u5c45\u7559\u65f6\u95f4\u5e76\u5728\u4ece\u8282\u70b9\u6062\u590d\u65f6\u949f\u57df\uff0c\u901a\u8fc7\u4fee\u6539PTP\u6d88\u606f\u4f20\u8f93\u901f\u7387\u8fdb\u884c\u540c\u6b65\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5cf0\u5230\u5cf0\u540c\u6b65\u7cbe\u5ea6\u4e3a500\u7eb3\u79d2\uff0c\u8fdc\u8d85\u5de5\u4e1a\u8981\u6c42(<1\u5fae\u79d2)\uff0c\u5bf9\u7279\u5b9aPTP\u6d88\u606f\u4f20\u8f93\u901f\u7387\u53ea\u6709\u6700\u5c0f\u7684\u540c\u6b65\u504f\u5dee\u3002", "conclusion": "\u900f\u660e\u65f6\u949f\u6a21\u5f0f\u5728TSN-5G\u7f51\u7edc\u4e2d\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u65f6\u95f4\u540c\u6b65\uff0c\u4e3a\u5de5\u4e1aIoT\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u65f6\u949f\u540c\u6b65\u65b9\u6848\u3002"}}
{"id": "2509.06919", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.06919", "abs": "https://arxiv.org/abs/2509.06919", "authors": ["Anuj Kumar Bhagat", "Harshdeep Singh", "Ritumoni Sarma"], "title": "Row-Column Twisted Reed-Solomon codes", "comment": null, "summary": "In this article, we present a new class of codes known as row-column twisted\nReed-Solomon codes (abbreviated as RCTRS), motivated by the works of\n\\cite{beelen2017twisted} and \\cite{liu2025column}. We explicitly provide\nconditions for such codes to be MDS and also ensure their existence. By\ndetermining the dimensions of their Schur squares, we prove that these MDS\ncodes are not equivalent to Reed-Solomon codes, thus presenting a new family of\nnon-RS MDS codes. Additionally, we prove that these MDS codes are also not\nequivalent to column twisted Reed-Solomon codes described in\n\\cite{liu2025column}, showing the novelty of our construction.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u884c\u5217\u626d\u66f2Reed-Solomon\u7801(RCTRS)\uff0c\u8bc1\u660e\u5176MDS\u6027\u8d28\u548c\u4e0e\u5176\u4ed6\u7801\u7684\u4e0d\u7b49\u4ef7\u6027", "motivation": "\u53d7\u5230\u626d\u66f2Reed-Solomon\u7801\u548c\u5217\u626d\u66f2Reed-Solomon\u7801\u7684\u542f\u53d1\uff0c\u5c1d\u8bd5\u6784\u9020\u65b0\u7684\u975eRS MDS\u7801\u5bb6\u65cf", "method": "\u901a\u8fc7\u786e\u5b9a\u5176Schur\u5e73\u65b9\u7684\u7ef4\u6570\uff0c\u8bc1\u660e\u8fd9\u4e9bMDS\u7801\u4e0eReed-Solomon\u7801\u4ee5\u53ca\u5217\u626d\u66f2Reed-Solomon\u7801\u7684\u4e0d\u7b49\u4ef7\u6027", "result": "\u6784\u9020\u4e86\u4e00\u7cfb\u5217\u65b0\u7684\u884c\u5217\u626d\u66f2Reed-Solomon\u7801\uff0c\u8bc1\u660e\u5176\u5177\u6709MDS\u6027\u8d28\u4e14\u4e0e\u73b0\u6709\u7801\u7c7b\u4e0d\u7b49\u4ef7", "conclusion": "RCTRS\u7801\u6784\u6210\u4e86\u4e00\u4e2a\u65b0\u7684\u975eRS MDS\u7801\u5bb6\u65cf\uff0c\u4e3a\u7f16\u7801\u7406\u8bba\u63d0\u4f9b\u4e86\u65b0\u7684\u7ed3\u6784"}}
{"id": "2509.05378", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.05378", "abs": "https://arxiv.org/abs/2509.05378", "authors": ["Andreas Motzfeldt", "Joakim Edin", "Casper L. Christensen", "Christian Hardmeier", "Lars Maal\u00f8e", "Anna Rogers"], "title": "Code Like Humans: A Multi-Agent Solution for Medical Coding", "comment": "EMNLP Findings 2025", "summary": "In medical coding, experts map unstructured clinical notes to alphanumeric\ncodes for diagnoses and procedures. We introduce Code Like Humans: a new\nagentic framework for medical coding with large language models. It implements\nofficial coding guidelines for human experts, and it is the first solution that\ncan support the full ICD-10 coding system (+70K labels). It achieves the best\nperformance to date on rare diagnosis codes (fine-tuned discriminative\nclassifiers retain an advantage for high-frequency codes, to which they are\nlimited). Towards future work, we also contribute an analysis of system\nperformance and identify its `blind spots' (codes that are systematically\nundercoded).", "AI": {"tldr": "\u63d0\u51fa\u4e86Code Like Humans\u6846\u67b6\uff0c\u8fd9\u662f\u9996\u4e2a\u652f\u6301\u5b8c\u6574ICD-10\u7f16\u7801\u7cfb\u7edf\uff087\u4e07+\u6807\u7b7e\uff09\u7684\u533b\u7597\u7f16\u7801\u4ee3\u7406\u6846\u67b6\uff0c\u5728\u7f55\u89c1\u8bca\u65ad\u4ee3\u7801\u4e0a\u8fbe\u5230\u6700\u4f73\u6027\u80fd", "motivation": "\u533b\u7597\u7f16\u7801\u9700\u8981\u5c06\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u8bb0\u5f55\u6620\u5c04\u5230\u8bca\u65ad\u548c\u7a0b\u5e8f\u7684\u5b57\u6bcd\u6570\u5b57\u4ee3\u7801\uff0c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u652f\u6301\u5b8c\u6574\u7684ICD-10\u7f16\u7801\u7cfb\u7edf", "method": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u4eba\u7c7b\u4e13\u5bb6\u7684\u5b98\u65b9\u7f16\u7801\u6307\u5357", "result": "\u5728\u7f55\u89c1\u8bca\u65ad\u4ee3\u7801\u4e0a\u8fbe\u5230\u6700\u4f73\u6027\u80fd\uff0c\u4f46\u5fae\u8c03\u5224\u522b\u5206\u7c7b\u5668\u5728\u9ad8\u9891\u4ee3\u7801\u4e0a\u4ecd\u4fdd\u6301\u4f18\u52bf", "conclusion": "\u8d21\u732e\u4e86\u7cfb\u7edf\u6027\u80fd\u5206\u6790\u5e76\u8bc6\u522b\u4e86\u7cfb\u7edf\u6027\u7684'\u76f2\u70b9'\uff08\u88ab\u7cfb\u7edf\u4f4e\u4f30\u7684\u4ee3\u7801\uff09\uff0c\u4e3a\u672a\u6765\u5de5\u4f5c\u6307\u660e\u65b9\u5411"}}
{"id": "2509.06515", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.06515", "abs": "https://arxiv.org/abs/2509.06515", "authors": ["Ege Cem Kirci", "Ayush Mishra", "Laurent Vanbever"], "title": "Five Blind Men and the Internet: Towards an Understanding of Internet Traffic", "comment": "15 pages, 16 figures", "summary": "The Internet, the world's largest and most pervasive network, lacks a\ntransparent, granular view of its traffic patterns, volumes, and growth trends,\nhindering the networking community's understanding of its dynamics. This paper\nleverages publicly available Internet Exchange Point traffic statistics to\naddress this gap, presenting a comprehensive two-year study (2023-2024) from\n472 IXPs worldwide, capturing approximately 300 Tbps of peak daily aggregate\ntraffic by late 2024. Our analysis reveals a 49.2% global traffic increase\n(24.5% annualized), uncovers regionally distinct diurnal patterns and\nevent-driven anomalies, and demonstrates stable utilization rates, reflecting\npredictable infrastructure scaling. By analyzing biases and confirming high\nself-similarity, we establish IXP traffic as a robust proxy for overall\nInternet growth and usage behavior. With transparent, replicable data--covering\n87% of the worldwide IXP port capacity--and plans to release our dataset, this\nstudy offers a verifiable foundation for long-term Internet traffic monitoring.\nIn particular, our findings shed light on the interplay between network design\nand function, providing an accessible framework for researchers and operators\nto explore the Internet's evolving ecosystem.", "AI": {"tldr": "\u901a\u8fc7\u5168\u7403472\u4e2a\u4e92\u8054\u7f51\u4ea4\u6362\u4e2d\u5fc3\u7684\u516c\u5f00\u6d41\u91cf\u6570\u636e\uff0c\u8fd9\u9879\u7814\u7a76\u63ed\u793a\u4e86\u5168\u7403\u4e92\u8054\u7f51\u6d41\u91cf\u57282023-2024\u5e74\u589e\u957f49.2%\uff0c\u53d1\u73b0\u4e86\u533a\u57df\u6027\u65e5\u5e38\u6a21\u5f0f\u548c\u7a33\u5b9a\u7684\u5229\u7528\u7387\uff0c\u4e3a\u957f\u671f\u76d1\u6d4b\u63d0\u4f9b\u4e86\u53ef\u9760\u57fa\u7840\u3002", "motivation": "\u4e92\u8054\u7f51\u4f5c\u4e3a\u4e16\u754c\u6700\u5927\u7684\u7f51\u7edc\u7f3a\u4e4f\u900f\u660e\u3001\u7ec6\u7c92\u5ea6\u7684\u6d41\u91cf\u89c2\u6d4b\u89c6\u89d2\uff0c\u963b\u788d\u4e86\u7f51\u7edc\u793e\u533a\u5bf9\u5176\u52a8\u6001\u7684\u7406\u89e3\u3002", "method": "\u5229\u7528\u516c\u5f00\u53ef\u7528\u7684\u4e92\u8054\u7f51\u4ea4\u6362\u4e2d\u5fc3\u6d41\u91cf\u7edf\u8ba1\u6570\u636e\uff0c\u5bf9\u5168\u7403472\u4e2aIXP\u8fdb\u884c\u4e86\u4e24\u5e74\u7684\u7efc\u5408\u7814\u7a76\uff0c\u8986\u76d6\u5168\u7403IXP\u7aef\u53e3\u5bb9\u91cf\u768487%\u3002", "result": "\u53d1\u73b0\u5168\u7403\u6d41\u91cf\u589e\u957f49.2%\uff08\u5e74\u531624.5%\uff09\uff0c\u5c3f\u6d1e\u65f6\u95f4\u6d41\u91cf\u8fbe300Tbps\uff0c\u63ed\u793a\u4e86\u533a\u57df\u6027\u65e5\u5e38\u6a21\u5f0f\u548c\u4e8b\u4ef6\u9a71\u52a8\u5f02\u5e38\uff0c\u8bc1\u660eIXP\u6d41\u91cf\u4f5c\u4e3a\u6574\u4f53\u4e92\u8054\u7f51\u589e\u957f\u7684\u53ef\u9760\u4ee3\u7406\u6307\u6807\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u957f\u671f\u4e92\u8054\u7f51\u6d41\u91cf\u76d1\u6d4b\u63d0\u4f9b\u4e86\u53ef\u9a8c\u8bc1\u7684\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u7f51\u7edc\u8bbe\u8ba1\u4e0e\u529f\u80fd\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u8fd0\u8425\u5546\u63d0\u4f9b\u4e86\u63a2\u7d22\u4e92\u8054\u7f51\u6f14\u5316\u751f\u6001\u7cfb\u7edf\u7684\u53ef\u8bbf\u95ee\u6846\u67b6\u3002"}}
{"id": "2509.05381", "categories": ["cs.AI", "cs.LG", "68T01, 68T20, 68Q87"], "pdf": "https://arxiv.org/pdf/2509.05381", "abs": "https://arxiv.org/abs/2509.05381", "authors": ["Madhava Gaikwad"], "title": "Murphys Laws of AI Alignment: Why the Gap Always Wins", "comment": "21 pages", "summary": "Large language models are increasingly aligned to human preferences through\nreinforcement learning from human feedback (RLHF) and related methods such as\nDirect Preference Optimization (DPO), Constitutional AI, and RLAIF. While\neffective, these methods exhibit recurring failure patterns i.e., reward\nhacking, sycophancy, annotator drift, and misgeneralization. We introduce the\nconcept of the Alignment Gap, a unifying lens for understanding recurring\nfailures in feedback-based alignment. Using a KL-tilting formalism, we\nillustrate why optimization pressure tends to amplify divergence between proxy\nrewards and true human intent. We organize these failures into a catalogue of\nMurphys Laws of AI Alignment, and propose the Alignment Trilemma as a way to\nframe trade-offs among optimization strength, value capture, and\ngeneralization. Small-scale empirical studies serve as illustrative support.\nFinally, we propose the MAPS framework (Misspecification, Annotation, Pressure,\nShift) as practical design levers. Our contribution is not a definitive\nimpossibility theorem but a perspective that reframes alignment debates around\nstructural limits and trade-offs, offering clearer guidance for future design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Alignment Gap\u6982\u5ff5\uff0c\u7edf\u4e00\u89e3\u91caRLHF\u7b49\u5bf9\u9f50\u65b9\u6cd5\u4e2d\u7684\u5e38\u89c1\u5931\u8d25\u6a21\u5f0f\uff0c\u901a\u8fc7KL-tilting\u5f62\u5f0f\u5316\u8bf4\u660e\u4f18\u5316\u538b\u529b\u5982\u4f55\u653e\u5927\u4ee3\u7406\u5956\u52b1\u4e0e\u4eba\u7c7b\u610f\u56fe\u7684\u504f\u5dee\uff0c\u5e76\u63d0\u51fa\u4e86Alignment Trilemma\u548cMAPS\u6846\u67b6\u6765\u6307\u5bfc\u672a\u6765\u8bbe\u8ba1\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u65b9\u6cd5\uff08\u5982RLHF\u3001DPO\u7b49\uff09\u867d\u7136\u6709\u6548\uff0c\u4f46\u5b58\u5728\u5956\u52b1\u9ed1\u5ba2\u3001\u5949\u627f\u884c\u4e3a\u3001\u6807\u6ce8\u8005\u6f02\u79fb\u548c\u9519\u8bef\u6cdb\u5316\u7b49\u91cd\u590d\u51fa\u73b0\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u9700\u8981\u7edf\u4e00\u7684\u89c6\u89d2\u6765\u7406\u89e3\u8fd9\u4e9b\u7ed3\u6784\u6027\u9650\u5236\u3002", "method": "\u4f7f\u7528KL-tilting\u5f62\u5f0f\u5316\u65b9\u6cd5\u5206\u6790\u4f18\u5316\u538b\u529b\u5bf9\u4ee3\u7406\u5956\u52b1\u4e0e\u771f\u5b9e\u4eba\u7c7b\u610f\u56fe\u504f\u5dee\u7684\u653e\u5927\u6548\u5e94\uff0c\u7ec4\u7ec7\u5931\u8d25\u6a21\u5f0f\u4e3aMurphy\u5b9a\u5f8b\u76ee\u5f55\uff0c\u63d0\u51faAlignment Trilemma\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5c0f\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5efa\u7acb\u4e86Alignment Gap\u6982\u5ff5\u6846\u67b6\uff0c\u7cfb\u7edf\u5316\u4e86\u5bf9\u9f50\u5931\u8d25\u6a21\u5f0f\uff0c\u63d0\u51fa\u4e86\u4f18\u5316\u5f3a\u5ea6\u3001\u4ef7\u503c\u6355\u83b7\u548c\u6cdb\u5316\u80fd\u529b\u4e4b\u95f4\u7684\u4e09\u96be\u6743\u8861\uff0c\u5e76\u5f00\u53d1\u4e86MAPS\uff08\u9519\u8bef\u8bbe\u5b9a\u3001\u6807\u6ce8\u3001\u538b\u529b\u3001\u6f02\u79fb\uff09\u5b9e\u7528\u8bbe\u8ba1\u6846\u67b6\u3002", "conclusion": "\u672c\u6587\u4e0d\u662f\u63d0\u51fa\u4e0d\u53ef\u80fd\u5b9a\u7406\uff0c\u800c\u662f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u91cd\u6784\u5bf9\u9f50\u8fa9\u8bba\u7684\u89c6\u89d2\uff0c\u56f4\u7ed5\u7ed3\u6784\u6027\u9650\u5236\u548c\u6743\u8861\uff0c\u4e3a\u672a\u6765\u5bf9\u9f50\u65b9\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u66f4\u6e05\u6670\u7684\u6307\u5bfc\u3002"}}
{"id": "2509.06639", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.06639", "abs": "https://arxiv.org/abs/2509.06639", "authors": ["Chenming He", "Rui Xia", "Chengzhen Meng", "Xiaoran Fan", "Dequan Wang", "Haojie Ren", "Jianmin Ji", "Yanyong Zhang"], "title": "Ghost Points Matter: Far-Range Vehicle Detection with a Single mmWave Radar in Tunnel", "comment": "17 pages, 25 figures, to appear in ACM MobiCom 2025", "summary": "Vehicle detection in tunnels is crucial for traffic monitoring and accident\nresponse, yet remains underexplored. In this paper, we develop mmTunnel, a\nmillimeter-wave radar system that achieves far-range vehicle detection in\ntunnels. The main challenge here is coping with ghost points caused by\nmulti-path reflections, which lead to severe localization errors and false\nalarms. Instead of merely removing ghost points, we propose correcting them to\ntrue vehicle positions by recovering their signal reflection paths, thus\nreserving more data points and improving detection performance, even in\nocclusion scenarios. However, recovering complex 3D reflection paths from\nlimited 2D radar points is highly challenging. To address this problem, we\ndevelop a multi-path ray tracing algorithm that leverages the ground plane\nconstraint and identifies the most probable reflection path based on signal\npath loss and spatial distance. We also introduce a curve-to-plane segmentation\nmethod to simplify tunnel surface modeling such that we can significantly\nreduce the computational delay and achieve real-time processing.\n  We have evaluated mmTunnel with comprehensive experiments. In two test\ntunnels, we conducted controlled experiments in various scenarios with cars and\ntrucks. Our system achieves an average F1 score of 93.7% for vehicle detection\nwhile maintaining real-time processing. Even in the challenging occlusion\nscenarios, the F1 score remains above 91%. Moreover, we collected extensive\ndata from a public tunnel with heavy traffic at times and show our method could\nachieve an F1 score of 91.5% in real-world traffic conditions.", "AI": {"tldr": "mmTunnel\u662f\u4e00\u4e2a\u6beb\u7c73\u6ce2\u96f7\u8fbe\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u8def\u5f84\u5c04\u7ebf\u8ffd\u8e2a\u7b97\u6cd5\u6821\u6b63\u96a7\u9053\u4e2d\u7684\u5e7d\u7075\u70b9\uff0c\u5b9e\u73b0\u8fdc\u8ddd\u79bb\u8f66\u8f86\u68c0\u6d4b\uff0c\u5728\u771f\u5b9e\u96a7\u9053\u73af\u5883\u4e2d\u8fbe\u523093.7%\u7684\u5e73\u5747F1\u5206\u6570\u3002", "motivation": "\u96a7\u9053\u8f66\u8f86\u68c0\u6d4b\u5bf9\u4ea4\u901a\u76d1\u63a7\u548c\u4e8b\u6545\u54cd\u5e94\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e0d\u8db3\u3002\u4e3b\u8981\u6311\u6218\u662f\u5904\u7406\u591a\u8def\u5f84\u53cd\u5c04\u4ea7\u751f\u7684\u5e7d\u7075\u70b9\uff0c\u8fd9\u4e9b\u70b9\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u5b9a\u4f4d\u8bef\u5dee\u548c\u8bef\u62a5\u3002", "method": "\u63d0\u51fa\u591a\u8def\u5f84\u5c04\u7ebf\u8ffd\u8e2a\u7b97\u6cd5\uff0c\u5229\u7528\u5730\u9762\u5e73\u9762\u7ea6\u675f\u548c\u4fe1\u53f7\u8def\u5f84\u635f\u8017\u8bc6\u522b\u6700\u53ef\u80fd\u7684\u53cd\u5c04\u8def\u5f84\uff1b\u5f15\u5165\u66f2\u7ebf\u5230\u5e73\u9762\u5206\u5272\u65b9\u6cd5\u7b80\u5316\u96a7\u9053\u8868\u9762\u5efa\u6a21\uff0c\u964d\u4f4e\u8ba1\u7b97\u5ef6\u8fdf\u5b9e\u73b0\u5b9e\u65f6\u5904\u7406\u3002", "result": "\u5728\u4e24\u4e2a\u6d4b\u8bd5\u96a7\u9053\u4e2d\uff0c\u7cfb\u7edf\u5e73\u5747F1\u5206\u6570\u8fbe\u523093.7%\uff0c\u5b9e\u65f6\u5904\u7406\uff1b\u5728\u906e\u6321\u573a\u666f\u4e0bF1\u5206\u6570\u4ecd\u9ad8\u4e8e91%\uff1b\u5728\u771f\u5b9e\u4ea4\u901a\u6761\u4ef6\u4e0b\u8fbe\u523091.5%\u7684F1\u5206\u6570\u3002", "conclusion": "mmTunnel\u7cfb\u7edf\u901a\u8fc7\u6821\u6b63\u800c\u975e\u7b80\u5355\u79fb\u9664\u5e7d\u7075\u70b9\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u96a7\u9053\u4e2d\u591a\u8def\u5f84\u53cd\u5c04\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u3001\u5b9e\u65f6\u7684\u8f66\u8f86\u68c0\u6d4b\uff0c\u5728\u590d\u6742\u96a7\u9053\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.05469", "categories": ["cs.AI", "cs.CV", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.05469", "abs": "https://arxiv.org/abs/2509.05469", "authors": ["Chenguang Wang", "Xiang Yan", "Yilong Dai", "Ziyi Wang", "Susu Xu"], "title": "From Image Generation to Infrastructure Design: a Multi-agent Pipeline for Street Design Generation", "comment": "21 pages, 8 figures", "summary": "Realistic visual renderings of street-design scenarios are essential for\npublic engagement in active transportation planning. Traditional approaches are\nlabor-intensive, hindering collective deliberation and collaborative\ndecision-making. While AI-assisted generative design shows transformative\npotential by enabling rapid creation of design scenarios, existing generative\napproaches typically require large amounts of domain-specific training data and\nstruggle to enable precise spatial variations of design/configuration in\ncomplex street-view scenes. We introduce a multi-agent system that edits and\nredesigns bicycle facilities directly on real-world street-view imagery. The\nframework integrates lane localization, prompt optimization, design generation,\nand automated evaluation to synthesize realistic, contextually appropriate\ndesigns. Experiments across diverse urban scenarios demonstrate that the system\ncan adapt to varying road geometries and environmental conditions, consistently\nyielding visually coherent and instruction-compliant results. This work\nestablishes a foundation for applying multi-agent pipelines to transportation\ninfrastructure planning and facility design.", "AI": {"tldr": "\u4e00\u4e2a\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u76f4\u63a5\u5728\u771f\u5b9e\u8857\u9053\u56fe\u50cf\u4e0a\u7f16\u8f91\u548c\u91cd\u65b0\u8bbe\u8ba1\u81ea\u884c\u8f66\u8bbe\u65bd\uff0c\u901a\u8fc7\u8f66\u9053\u5b9a\u4f4d\u3001\u63d0\u793a\u4f18\u5316\u3001\u8bbe\u8ba1\u751f\u6210\u548c\u81ea\u52a8\u8bc4\u4f30\u7b49\u6b65\u9aa4\u751f\u6210\u73b0\u5b9e\u4e14\u4e0a\u4e0b\u6587\u9002\u5b9c\u7684\u8bbe\u8ba1\u65b9\u6848\u3002", "motivation": "\u4f20\u7edf\u8857\u9053\u8bbe\u8ba1\u6e32\u67d3\u65b9\u6848\u82e6\u4e8e\u96c6\u4f53\u51b2\u8bae\u548c\u534f\u540c\u51b3\u7b56\uff0c\u800c\u73b0\u6709AI\u751f\u6210\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u9886\u57df\u7279\u5b9a\u6570\u636e\u4e14\u96be\u4ee5\u7cbe\u786e\u63a7\u5236\u590d\u6742\u8857\u9053\u573a\u666f\u4e2d\u7684\u7a7a\u95f4\u53d8\u5316\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u96c6\u6210\u4e86\u8f66\u9053\u5b9a\u4f4d\u3001\u63d0\u793a\u4f18\u5316\u3001\u8bbe\u8ba1\u751f\u6210\u548c\u81ea\u52a8\u8bc4\u4f30\u7b49\u6a21\u5757\uff0c\u80fd\u591f\u5728\u771f\u5b9e\u8857\u9053\u56fe\u50cf\u4e0a\u76f4\u63a5\u7f16\u8f91\u548c\u91cd\u65b0\u8bbe\u8ba1\u81ea\u884c\u8f66\u8bbe\u65bd\u3002", "result": "\u5728\u591a\u6837\u5316\u57ce\u5e02\u573a\u666f\u4e2d\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7cfb\u7edf\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u7684\u9053\u8def\u51e0\u4f55\u5f62\u72b6\u548c\u73af\u5883\u6761\u4ef6\uff0c\u4e00\u8d28\u5730\u4ea7\u751f\u89c6\u89c9\u4e00\u81f4\u4e14\u7b26\u5408\u6307\u4ee4\u8981\u6c42\u7684\u7ed3\u679c\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5e94\u7528\u591a\u4ee3\u7406\u6d41\u6c34\u7ebf\u5230\u4ea4\u901a\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u548c\u8bbe\u65bd\u8bbe\u8ba1\u9886\u57df\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.06700", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.06700", "abs": "https://arxiv.org/abs/2509.06700", "authors": ["Swarna Bindu Chetty", "David Grace", "Simon Saunders", "Paul Harris", "Eirini Eleni Tsiropoulou", "Tony Quek", "Hamed Ahmadi"], "title": "Sovereign AI for 6G: Towards the Future of AI-Native Networks", "comment": null, "summary": "The advent of Generative Artificial Intelligence (GenAI), Large Language\nModels (LLMs), and Large Telecom Models (LTM) significantly reshapes mobile\nnetworks, especially as the telecom industry transitions from 5G's\ncloud-centric to AI-native 6G architectures. This transition unlocks\nunprecedented capabilities in real-time automation, semantic networking, and\nautonomous service orchestration. However, it introduces critical risks related\nto data sovereignty, security, explainability, and regulatory compliance\nespecially when AI models are trained, deployed, or governed externally. This\npaper introduces the concept of `Sovereign AI' as a strategic imperative for\n6G, proposing architectural, operational, and governance frameworks that enable\nnational or operator-level control over AI development, deployment, and\nlife-cycle management. Focusing on O-RAN architecture, we explore how sovereign\nAI-based xApps and rApps can be deployed Near-RT and Non-RT RICs to ensure\npolicy-aligned control, secure model updates, and federated learning across\ntrusted infrastructure. We analyse global strategies, technical enablers, and\nchallenges across safety, talent, and model governance. Our findings underscore\nthat Sovereign AI is not just a regulatory necessity but a foundational pillar\nfor secure, resilient, and ethically-aligned 6G networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\"\u4e3b\u6743AI\"\u4f5c\u4e3a6G\u7f51\u7edc\u7684\u6218\u7565\u8981\u52a1\uff0c\u901a\u8fc7\u67b6\u6784\u3001\u8fd0\u8425\u548c\u6cbb\u7406\u6846\u67b6\u5b9e\u73b0\u56fd\u5bb6\u6216\u8fd0\u8425\u5546\u5bf9AI\u5f00\u53d1\u3001\u90e8\u7f72\u548c\u751f\u547d\u5468\u671f\u7684\u63a7\u5236\uff0c\u7279\u522b\u662f\u5728O-RAN\u67b6\u6784\u4e2d\u90e8\u7f72\u4e3b\u6743AI\u5e94\u7528\u4ee5\u786e\u4fdd\u5b89\u5168\u5408\u89c4\u3002", "motivation": "\u968f\u7740GenAI\u3001LLMs\u548cLTM\u6280\u672f\u7684\u53d1\u5c55\uff0c\u7535\u4fe1\u884c\u4e1a\u4ece5G\u4e91\u4e2d\u5fc3\u5411AI\u539f\u751f6G\u67b6\u6784\u8f6c\u578b\uff0c\u867d\u7136\u5e26\u6765\u4e86\u5b9e\u65f6\u81ea\u52a8\u5316\u7b49\u65b0\u80fd\u529b\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u6570\u636e\u4e3b\u6743\u3001\u5b89\u5168\u6027\u548c\u76d1\u7ba1\u5408\u89c4\u7b49\u5173\u952e\u98ce\u9669\uff0c\u7279\u522b\u662f\u5f53AI\u6a21\u578b\u5728\u5916\u90e8\u8bad\u7ec3\u3001\u90e8\u7f72\u6216\u6cbb\u7406\u65f6\u3002", "method": "\u63d0\u51fa\u4e3b\u6743AI\u6982\u5ff5\uff0c\u8bbe\u8ba1\u67b6\u6784\u3001\u8fd0\u8425\u548c\u6cbb\u7406\u6846\u67b6\uff0c\u91cd\u70b9\u7814\u7a76\u5982\u4f55\u5728O-RAN\u67b6\u6784\u4e2d\u90e8\u7f72\u57fa\u4e8e\u4e3b\u6743AI\u7684xApps\u548crApps\u5230\u8fd1\u5b9e\u65f6\u548c\u975e\u5b9e\u65f6RICs\u4e2d\uff0c\u5b9e\u73b0\u7b56\u7565\u5bf9\u9f50\u63a7\u5236\u3001\u5b89\u5168\u6a21\u578b\u66f4\u65b0\u548c\u53ef\u4fe1\u57fa\u7840\u8bbe\u65bd\u4e0a\u7684\u8054\u90a6\u5b66\u4e60\u3002", "result": "\u5206\u6790\u4e86\u5168\u7403\u6218\u7565\u3001\u6280\u672f\u4f7f\u80fd\u56e0\u7d20\u4ee5\u53ca\u5728\u5b89\u5168\u3001\u4eba\u624d\u548c\u6a21\u578b\u6cbb\u7406\u65b9\u9762\u7684\u6311\u6218\uff0c\u786e\u8ba4\u4e3b\u6743AI\u4e0d\u4ec5\u662f\u76d1\u7ba1\u9700\u6c42\uff0c\u66f4\u662f\u5b89\u5168\u3001\u5f39\u6027\u548c\u9053\u5fb7\u5bf9\u9f50\u76846G\u7f51\u7edc\u7684\u57fa\u7840\u652f\u67f1\u3002", "conclusion": "\u4e3b\u6743AI\u662f6G\u7f51\u7edc\u4e0d\u53ef\u6216\u7f3a\u7684\u6218\u7565\u8981\u7d20\uff0c\u80fd\u591f\u786e\u4fdd\u56fd\u5bb6\u5b89\u5168\u3001\u76d1\u7ba1\u5408\u89c4\u548c\u9053\u5fb7\u5bf9\u9f50\uff0c\u4e3a\u672a\u6765\u79fb\u52a8\u7f51\u7edc\u63d0\u4f9b\u5b89\u5168\u53ef\u9760\u7684\u57fa\u7840\u67b6\u6784\u3002"}}
{"id": "2509.05550", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05550", "abs": "https://arxiv.org/abs/2509.05550", "authors": ["Zixi Li"], "title": "TreeGPT: A Novel Hybrid Architecture for Abstract Syntax Tree Processing with Global Parent-Child Aggregation", "comment": "Code available at: https://github.com/lizixi-0x2F/TreeGPT", "summary": "We introduce TreeGPT, a novel neural architecture that combines\ntransformer-based attention mechanisms with global parent-child aggregation for\nprocessing Abstract Syntax Trees (ASTs) in neural program synthesis tasks.\nUnlike traditional approaches that rely solely on sequential processing or\ngraph neural networks, TreeGPT employs a hybrid design that leverages both\nself-attention for capturing local dependencies and a specialized Tree\nFeed-Forward Network (TreeFFN) for modeling hierarchical tree structures\nthrough iterative message passing.\n  The core innovation lies in our Global Parent-Child Aggregation mechanism,\nformalized as: $$h_i^{(t+1)} = \\sigma \\Big( h_i^{(0)} + W_{pc} \\sum_{(p,c) \\in\nE_i} f(h_p^{(t)}, h_c^{(t)}) + b \\Big)$$ where $h_i^{(t)}$ represents the\nhidden state of node $i$ at iteration $t$, $E_i$ denotes all parent-child edges\ninvolving node $i$, and $f(h_p, h_c)$ is an edge aggregation function. This\nformulation enables each node to progressively aggregate information from the\nentire tree structure through $T$ iterations.\n  Our architecture integrates optional enhancements including gated aggregation\nwith learnable edge weights, residual connections for gradient stability, and\nbidirectional propagation for capturing both bottom-up and top-down\ndependencies. We evaluate TreeGPT on the ARC Prize 2025 dataset, a challenging\nvisual reasoning benchmark requiring abstract pattern recognition and rule\ninference. Experimental results demonstrate that TreeGPT achieves 96\\%\naccuracy, significantly outperforming transformer baselines (1.3\\%),\nlarge-scale models like Grok-4 (15.9\\%), and specialized program synthesis\nmethods like SOAR (52\\%) while using only 1.5M parameters. Our comprehensive\nablation study reveals that edge projection is the most critical component,\nwith the combination of edge projection and gating achieving optimal\nperformance.", "AI": {"tldr": "TreeGPT\u662f\u4e00\u79cd\u65b0\u9896\u7684\u795e\u7ecf\u67b6\u6784\uff0c\u7ed3\u5408\u4e86transformer\u6ce8\u610f\u529b\u673a\u5236\u548c\u5168\u5c40\u7236\u5b50\u805a\u5408\uff0c\u7528\u4e8e\u5904\u7406\u62bd\u8c61\u8bed\u6cd5\u6811\uff0c\u5728\u795e\u7ecf\u7a0b\u5e8f\u5408\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u5e8f\u5217\u5904\u7406\u6216\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u65e0\u6cd5\u6709\u6548\u6355\u6349AST\u7684\u5c42\u6b21\u7ed3\u6784\u4fe1\u606f\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u5904\u7406\u5c40\u90e8\u4f9d\u8d56\u548c\u5168\u5c40\u6811\u7ed3\u6784\u7684\u6df7\u5408\u67b6\u6784\u3002", "method": "\u91c7\u7528\u6df7\u5408\u8bbe\u8ba1\uff1a\u4f7f\u7528self-attention\u6355\u6349\u5c40\u90e8\u4f9d\u8d56\uff0cTreeFFN\u901a\u8fc7\u8fed\u4ee3\u6d88\u606f\u4f20\u9012\u5efa\u6a21\u5c42\u6b21\u6811\u7ed3\u6784\uff0c\u6838\u5fc3\u521b\u65b0\u662f\u5168\u5c40\u7236\u5b50\u805a\u5408\u673a\u5236\uff0c\u5305\u542b\u53ef\u9009\u7684\u589e\u5f3a\u529f\u80fd\u5982\u95e8\u63a7\u805a\u5408\u3001\u6b8b\u5dee\u8fde\u63a5\u548c\u53cc\u5411\u4f20\u64ad\u3002", "result": "\u5728ARC Prize 2025\u6570\u636e\u96c6\u4e0a\u8fbe\u523096%\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8etransformer\u57fa\u7ebf(1.3%)\u3001Grok-4(15.9%)\u548cSOAR(52%)\u7b49\u6a21\u578b\uff0c\u4ec5\u4f7f\u7528150\u4e07\u53c2\u6570\u3002\u6d88\u878d\u7814\u7a76\u8868\u660e\u8fb9\u7f18\u6295\u5f71\u662f\u6700\u5173\u952e\u7ec4\u4ef6\u3002", "conclusion": "TreeGPT\u901a\u8fc7\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u548c\u6811\u7ed3\u6784\u805a\u5408\uff0c\u5728\u7a0b\u5e8f\u5408\u6210\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u5353\u8d8a\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u6df7\u5408\u67b6\u6784\u5728\u5904\u7406\u5c42\u6b21\u6811\u7ed3\u6784\u6570\u636e\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.06763", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.06763", "abs": "https://arxiv.org/abs/2509.06763", "authors": ["Huijun Tang", "Wang Zeng", "Ming Du", "Pinlong Zhao", "Pengfei Jiao", "Huaming Wu", "Hongjian Sun"], "title": "VariSAC: V2X Assured Connectivity in RIS-Aided ISAC via GNN-Augmented Reinforcement Learning", "comment": null, "summary": "The integration of Reconfigurable Intelligent Surfaces (RIS) and Integrated\nSensing and Communication (ISAC) in vehicular networks enables dynamic spatial\nresource management and real-time adaptation to environmental changes. However,\nthe coexistence of distinct vehicle-to-infrastructure (V2I) and\nvehicle-to-vehicle (V2V) connectivity requirements, together with highly\ndynamic and heterogeneous network topologies, presents significant challenges\nfor unified reliability modeling and resource optimization. To address these\nissues, we propose VariSAC, a graph neural network (GNN)-augmented deep\nreinforcement learning framework for assured, time-continuous connectivity in\nRIS-assisted, ISAC-enabled vehicle-to-everything (V2X) systems. Specifically,\nwe introduce the Continuous Connectivity Ratio (CCR), a unified metric that\ncharacterizes the sustained temporal reliability of V2I connections and the\nprobabilistic delivery guarantees of V2V links, thus unifying their continuous\nreliability semantics. Next, we employ a GNN with residual adapters to encode\ncomplex, high-dimensional system states, capturing spatial dependencies among\nvehicles, base stations (BS), and RIS nodes. These representations are then\nprocessed by a Soft Actor-Critic (SAC) agent, which jointly optimizes channel\nallocation, power control, and RIS configurations to maximize CCR-driven\nlong-term rewards. Extensive experiments on real-world urban datasets\ndemonstrate that VariSAC consistently outperforms existing baselines in terms\nof continuous V2I ISAC connectivity and V2V delivery reliability, enabling\npersistent connectivity in highly dynamic vehicular environments.", "AI": {"tldr": "VariSAC\u662f\u4e00\u4e2a\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728RIS\u8f85\u52a9\u7684ISAC\u8f66\u8054\u7f51\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u8fde\u7eed\u53ef\u9760\u8fde\u63a5\uff0c\u901a\u8fc7\u7edf\u4e00\u5ea6\u91cfCCR\u6765\u4f18\u5316\u4fe1\u9053\u5206\u914d\u3001\u529f\u7387\u63a7\u5236\u548cRIS\u914d\u7f6e\u3002", "motivation": "\u89e3\u51b3\u8f66\u8054\u7f51\u4e2dV2I\u548cV2V\u8fde\u63a5\u9700\u6c42\u5171\u5b58\u3001\u7f51\u7edc\u62d3\u6251\u9ad8\u5ea6\u52a8\u6001\u5f02\u6784\u5e26\u6765\u7684\u7edf\u4e00\u53ef\u9760\u6027\u5efa\u6a21\u548c\u8d44\u6e90\u4f18\u5316\u6311\u6218\u3002", "method": "\u63d0\u51faCCR\u7edf\u4e00\u5ea6\u91cf\u6307\u6807\uff0c\u4f7f\u7528\u5e26\u6b8b\u5dee\u9002\u914d\u5668\u7684GNN\u7f16\u7801\u7cfb\u7edf\u72b6\u6001\uff0c\u7ed3\u5408SAC\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u8054\u5408\u4f18\u5316\u4fe1\u9053\u5206\u914d\u3001\u529f\u7387\u63a7\u5236\u548cRIS\u914d\u7f6e\u3002", "result": "\u5728\u771f\u5b9e\u57ce\u5e02\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVariSAC\u5728\u8fde\u7eedV2I ISAC\u8fde\u63a5\u6027\u548cV2V\u4f20\u8f93\u53ef\u9760\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u5728\u9ad8\u5ea6\u52a8\u6001\u7684\u8f66\u8f7d\u73af\u5883\u4e2d\u5b9e\u73b0\u6301\u4e45\u8fde\u63a5\uff0c\u4e3aRIS\u8f85\u52a9\u7684ISAC\u8f66\u8054\u7f51\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u53ef\u9760\u6027\u4fdd\u969c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.05578", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.05578", "abs": "https://arxiv.org/abs/2509.05578", "authors": ["Ruixun Liu", "Lingyu Kong", "Derun Li", "Hang Zhao"], "title": "OccVLA: Vision-Language-Action Model with Implicit 3D Occupancy Supervision", "comment": null, "summary": "Multimodal large language models (MLLMs) have shown strong vision-language\nreasoning abilities but still lack robust 3D spatial understanding, which is\ncritical for autonomous driving. This limitation stems from two key challenges:\n(1) the difficulty of constructing accessible yet effective 3D representations\nwithout expensive manual annotations, and (2) the loss of fine-grained spatial\ndetails in VLMs due to the absence of large-scale 3D vision-language\npretraining. To address these challenges, we propose OccVLA, a novel framework\nthat integrates 3D occupancy representations into a unified multimodal\nreasoning process. Unlike prior approaches that rely on explicit 3D inputs,\nOccVLA treats dense 3D occupancy as both a predictive output and a supervisory\nsignal, enabling the model to learn fine-grained spatial structures directly\nfrom 2D visual inputs. The occupancy predictions are regarded as implicit\nreasoning processes and can be skipped during inference without performance\ndegradation, thereby adding no extra computational overhead. OccVLA achieves\nstate-of-the-art results on the nuScenes benchmark for trajectory planning and\ndemonstrates superior performance on 3D visual question-answering tasks,\noffering a scalable, interpretable, and fully vision-based solution for\nautonomous driving.", "AI": {"tldr": "OccVLA\u662f\u4e00\u4e2a\u5c063D\u5360\u7528\u8868\u793a\u96c6\u6210\u5230\u591a\u6a21\u6001\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5bc6\u96c63D\u5360\u7528\u4f5c\u4e3a\u9884\u6d4b\u8f93\u51fa\u548c\u76d1\u7763\u4fe1\u53f7\uff0c\u4ece2D\u89c6\u89c9\u8f93\u5165\u76f4\u63a5\u5b66\u4e60\u7ec6\u7c92\u5ea6\u7a7a\u95f4\u7ed3\u6784\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u65b9\u9762\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u7f3a\u4e4f\u7a33\u5065\u76843D\u7a7a\u95f4\u7406\u89e3\u80fd\u529b\uff0c\u8fd9\u5bf9\u81ea\u52a8\u9a7e\u9a76\u81f3\u5173\u91cd\u8981\u3002\u4e3b\u8981\u6311\u6218\u5305\u62ec\u6784\u5efa\u6709\u65483D\u8868\u793a\u7684\u56f0\u96be\u4ee5\u53ca\u5927\u89c4\u6a213D\u89c6\u89c9\u8bed\u8a00\u9884\u8bad\u7ec3\u7684\u7f3a\u5931\u5bfc\u81f4\u7684\u7ec6\u7c92\u5ea6\u7a7a\u95f4\u7ec6\u8282\u635f\u5931\u3002", "method": "\u63d0\u51faOccVLA\u6846\u67b6\uff0c\u5c063D\u5360\u7528\u8868\u793a\u4f5c\u4e3a\u9884\u6d4b\u8f93\u51fa\u548c\u76d1\u7763\u4fe1\u53f7\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u76f4\u63a5\u4ece2D\u89c6\u89c9\u8f93\u5165\u5b66\u4e60\u7ec6\u7c92\u5ea6\u7a7a\u95f4\u7ed3\u6784\u3002\u5360\u7528\u9884\u6d4b\u88ab\u89c6\u4e3a\u9690\u5f0f\u63a8\u7406\u8fc7\u7a0b\uff0c\u5728\u63a8\u7406\u65f6\u53ef\u8df3\u8fc7\u800c\u4e0d\u5f71\u54cd\u6027\u80fd\uff0c\u4e0d\u589e\u52a0\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728nuScenes\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u8f68\u8ff9\u89c4\u5212\u7684\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u57283D\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "OccVLA\u4e3a\u81ea\u52a8\u9a7e\u9a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u4e14\u5b8c\u5168\u57fa\u4e8e\u89c6\u89c9\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6210\u529f\u89e3\u51b3\u4e863D\u7a7a\u95f4\u7406\u89e3\u7684\u6311\u6218\u3002"}}
{"id": "2509.06766", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.06766", "abs": "https://arxiv.org/abs/2509.06766", "authors": ["Binquan Guo", "Zehui Xiong", "Zhou Zhang", "Baosheng Li", "Dusit Niyato", "Chau Yuen", "Zhu Han"], "title": "Resilience of Mega-Satellite Constellations: How Node Failures Impact Inter-Satellite Networking Over Time?", "comment": "Accepted for publication in IEEE", "summary": "Mega-satellite constellations have the potential to leverage inter-satellite\nlinks to deliver low-latency end-to-end communication services globally,\nthereby extending connectivity to underserved regions. However, harsh space\nenvironments make satellites vulnerable to failures, leading to node removals\nthat disrupt inter-satellite networking. With the high risk of satellite node\nfailures, understanding their impact on end-to-end services is essential. This\nstudy investigates the importance of individual nodes on inter-satellite\nnetworking and the resilience of mega satellite constellations against node\nfailures. We represent the mega-satellite constellation as discrete temporal\ngraphs and model node failure events accordingly. To quantify node importance\nfor targeted services over time, we propose a service-aware temporal\nbetweenness metric. Leveraging this metric, we develop an analytical framework\nto identify critical nodes and assess the impact of node failures. The\nframework takes node failure events as input and efficiently evaluates their\nimpacts across current and subsequent time windows. Simulations on the Starlink\nconstellation setting reveal that satellite networks inherently exhibit\nresilience to node failures, as their dynamic topology partially restore\nconnectivity and mitigate the long-term impact. Furthermore, we find that the\nintegration of rerouting mechanisms is crucial for unleashing the full\nresilience potential to ensure rapid recovery of inter-satellite networking.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u5de8\u578b\u536b\u661f\u661f\u5ea7\u4e2d\u8282\u70b9\u6545\u969c\u5bf9\u661f\u9645\u7f51\u7edc\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u670d\u52a1\u611f\u77e5\u7684\u65f6\u95f4\u4e2d\u4ecb\u4e2d\u5fc3\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u53d1\u73b0\u661f\u94fe\u661f\u5ea7\u5bf9\u8282\u70b9\u6545\u969c\u5177\u6709\u5185\u5728\u97e7\u6027\uff0c\u52a8\u6001\u62d3\u6251\u548c\u91cd\u8def\u7531\u673a\u5236\u5bf9\u7f51\u7edc\u6062\u590d\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u5de8\u578b\u536b\u661f\u661f\u5ea7\u5229\u7528\u661f\u9645\u94fe\u8def\u63d0\u4f9b\u5168\u7403\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u670d\u52a1\uff0c\u4f46\u6076\u52a3\u7684\u592a\u7a7a\u73af\u5883\u4f7f\u536b\u661f\u5bb9\u6613\u53d1\u751f\u6545\u969c\uff0c\u5bfc\u81f4\u8282\u70b9\u79fb\u9664\u5e76\u7834\u574f\u661f\u9645\u7f51\u7edc\u8fde\u63a5\u3002\u4e86\u89e3\u536b\u661f\u8282\u70b9\u6545\u969c\u5bf9\u7aef\u5230\u7aef\u670d\u52a1\u7684\u5f71\u54cd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5c06\u5de8\u578b\u536b\u661f\u661f\u5ea7\u8868\u793a\u4e3a\u79bb\u6563\u65f6\u95f4\u56fe\uff0c\u63d0\u51fa\u670d\u52a1\u611f\u77e5\u7684\u65f6\u95f4\u4e2d\u4ecb\u4e2d\u5fc3\u6027\u5ea6\u91cf\u6765\u91cf\u5316\u8282\u70b9\u91cd\u8981\u6027\uff0c\u5f00\u53d1\u5206\u6790\u6846\u67b6\u8bc6\u522b\u5173\u952e\u8282\u70b9\u5e76\u8bc4\u4f30\u8282\u70b9\u6545\u969c\u5f71\u54cd\uff0c\u5728\u661f\u94fe\u661f\u5ea7\u8bbe\u7f6e\u4e0a\u8fdb\u884c\u6a21\u62df\u3002", "result": "\u6a21\u62df\u663e\u793a\u536b\u661f\u7f51\u7edc\u5bf9\u8282\u70b9\u6545\u969c\u5177\u6709\u5185\u5728\u97e7\u6027\uff0c\u52a8\u6001\u62d3\u6251\u80fd\u90e8\u5206\u6062\u590d\u8fde\u63a5\u5e76\u51cf\u8f7b\u957f\u671f\u5f71\u54cd\u3002\u91cd\u8def\u7531\u673a\u5236\u7684\u6574\u5408\u5bf9\u4e8e\u91ca\u653e\u5b8c\u5168\u97e7\u6027\u6f5c\u529b\u3001\u786e\u4fdd\u661f\u9645\u7f51\u7edc\u5feb\u901f\u6062\u590d\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u536b\u661f\u661f\u5ea7\u7684\u52a8\u6001\u62d3\u6251\u7279\u6027\u4f7f\u5176\u5bf9\u8282\u70b9\u6545\u969c\u5177\u6709\u5929\u7136\u97e7\u6027\uff0c\u4f46\u9700\u8981\u7ed3\u5408\u91cd\u8def\u7531\u673a\u5236\u624d\u80fd\u5145\u5206\u53d1\u6325\u8fd9\u79cd\u97e7\u6027\uff0c\u786e\u4fdd\u661f\u9645\u7f51\u7edc\u7684\u5feb\u901f\u6062\u590d\u548c\u6301\u7eed\u670d\u52a1\u3002"}}
{"id": "2509.05685", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05685", "abs": "https://arxiv.org/abs/2509.05685", "authors": ["Jian Yang", "Jiahui Wu", "Li Fang", "Hongchao Fan", "Bianying Zhang", "Huijie Zhao", "Guangyi Yang", "Rui Xin", "Xiong You"], "title": "MSRFormer: Road Network Representation Learning using Multi-scale Feature Fusion of Heterogeneous Spatial Interactions", "comment": null, "summary": "Transforming road network data into vector representations using deep\nlearning has proven effective for road network analysis. However, urban road\nnetworks' heterogeneous and hierarchical nature poses challenges for accurate\nrepresentation learning. Graph neural networks, which aggregate features from\nneighboring nodes, often struggle due to their homogeneity assumption and focus\non a single structural scale. To address these issues, this paper presents\nMSRFormer, a novel road network representation learning framework that\nintegrates multi-scale spatial interactions by addressing their flow\nheterogeneity and long-distance dependencies. It uses spatial flow convolution\nto extract small-scale features from large trajectory datasets, and identifies\nscale-dependent spatial interaction regions to capture the spatial structure of\nroad networks and flow heterogeneity. By employing a graph transformer,\nMSRFormer effectively captures complex spatial dependencies across multiple\nscales. The spatial interaction features are fused using residual connections,\nwhich are fed to a contrastive learning algorithm to derive the final road\nnetwork representation. Validation on two real-world datasets demonstrates that\nMSRFormer outperforms baseline methods in two road network analysis tasks. The\nperformance gains of MSRFormer suggest the traffic-related task benefits more\nfrom incorporating trajectory data, also resulting in greater improvements in\ncomplex road network structures with up to 16% improvements compared to the\nmost competitive baseline method. This research provides a practical framework\nfor developing task-agnostic road network representation models and highlights\ndistinct association patterns of the interplay between scale effects and flow\nheterogeneity of spatial interactions.", "AI": {"tldr": "MSRFormer\u662f\u4e00\u4e2a\u591a\u5c3a\u5ea6\u9053\u8def\u7f51\u7edc\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7a7a\u95f4\u6d41\u5377\u79ef\u548c\u56fe\u53d8\u6362\u5668\u5904\u7406\u9053\u8def\u7f51\u7edc\u7684\u5f02\u8d28\u6027\u548c\u5c42\u6b21\u6027\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd516%", "motivation": "\u57ce\u5e02\u9053\u8def\u7f51\u7edc\u7684\u5f02\u8d28\u6027\u548c\u5c42\u6b21\u6027\u7ed9\u51c6\u786e\u8868\u793a\u5b66\u4e60\u5e26\u6765\u6311\u6218\uff0c\u4f20\u7edf\u56fe\u795e\u7ecf\u7f51\u7edc\u56e0\u540c\u8d28\u6027\u5047\u8bbe\u548c\u5355\u4e00\u7ed3\u6784\u5c3a\u5ea6\u9650\u5236\u800c\u6548\u679c\u4e0d\u4f73", "method": "\u4f7f\u7528\u7a7a\u95f4\u6d41\u5377\u79ef\u4ece\u8f68\u8ff9\u6570\u636e\u63d0\u53d6\u5c0f\u5c3a\u5ea6\u7279\u5f81\uff0c\u8bc6\u522b\u5c3a\u5ea6\u4f9d\u8d56\u7684\u7a7a\u95f4\u4ea4\u4e92\u533a\u57df\uff0c\u901a\u8fc7\u56fe\u53d8\u6362\u5668\u6355\u6349\u591a\u5c3a\u5ea6\u590d\u6742\u7a7a\u95f4\u4f9d\u8d56\uff0c\u91c7\u7528\u6b8b\u5dee\u8fde\u63a5\u548c\u5bf9\u6bd4\u5b66\u4e60\u751f\u6210\u6700\u7ec8\u8868\u793a", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u7684\u9053\u8def\u7f51\u7edc\u5206\u6790\u4efb\u52a1\u4e2d\uff0cMSRFormer\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4ea4\u901a\u76f8\u5173\u4efb\u52a1\u548c\u590d\u6742\u9053\u8def\u7f51\u7edc\u7ed3\u6784\u4e2d\u8868\u73b0\u66f4\u4f73\uff0c\u76f8\u6bd4\u6700\u5f3a\u57fa\u7ebf\u63d0\u5347\u8fbe16%", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u4efb\u52a1\u65e0\u5173\u7684\u9053\u8def\u7f51\u7edc\u8868\u793a\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5c3a\u5ea6\u6548\u5e94\u4e0e\u7a7a\u95f4\u4ea4\u4e92\u6d41\u5f02\u8d28\u6027\u4e4b\u95f4\u7684\u5173\u8054\u6a21\u5f0f"}}
{"id": "2509.06898", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.06898", "abs": "https://arxiv.org/abs/2509.06898", "authors": ["Zhihui Gao", "Zhecun Liu", "Tingjun Chen"], "title": "BatStation: Toward In-Situ Radar Sensing on 5G Base Stations with Zero-Shot Template Generation", "comment": "14 pages, 17 figures", "summary": "The coexistence between incumbent radar signals and commercial 5G signals\nnecessitates a versatile and ubiquitous radar sensing for efficient and\nadaptive spectrum sharing. In this context, leveraging the densely deployed 5G\nbase stations (BS) for radar sensing is particularly promising, offering both\nwide coverage and immediate feedback to 5G scheduling. However, the targeting\nradar signals are superimposed with concurrent 5G uplink transmissions received\nby the BS, and practical deployment also demands a lightweight, portable radar\nsensing model. This paper presents BatStation, a lightweight, in-situ radar\nsensing framework seamlessly integrated into 5G BSs. BatStation leverages\nuplink resource grids to extract radar signals through three key components:\n(i) radar signal separation to cancel concurrent 5G transmissions and reveal\nthe radar signals, (ii) resource grid reshaping to align time-frequency\nresolution with radar pulse characteristics, and (iii) zero-shot template\ncorrelation based on a portable model trained purely on synthetic data that\nsupports detection, classification, and localization of radar pulses without\nfine-tuning using experimental data. We implement BatStation on a\nsoftware-defined radio (SDR) testbed and evaluate its performance with real 5G\ntraffic in the CBRS band. Results show robust performance across diverse radar\ntypes, achieving detection probabilities of 97.02% (PUCCH) and 79.23% (PUSCH),\nclassification accuracy up to 97.00%, and median localization errors of\n2.68-6.20 MHz (frequency) and 24.6-32.4 microseconds (time). Notably,\nBatStation achieves this performance with a runtime latency of only 0.11/0.94\nms on GPU/CPU, meeting the real-time requirement of 5G networks.", "AI": {"tldr": "BatStation\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u96f7\u8fbe\u611f\u77e5\u6846\u67b6\uff0c\u96c6\u6210\u52305G\u57fa\u7ad9\u4e2d\uff0c\u5229\u7528\u4e0a\u884c\u8d44\u6e90\u7f51\u683c\u63d0\u53d6\u96f7\u8fbe\u4fe1\u53f7\uff0c\u5b9e\u73b0\u96f7\u8fbe\u68c0\u6d4b\u3001\u5206\u7c7b\u548c\u5b9a\u4f4d\uff0c\u6ee1\u8db35G\u7f51\u7edc\u5b9e\u65f6\u6027\u8981\u6c42\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u96f7\u8fbe\u4fe1\u53f7\u4e0e\u5546\u75285G\u4fe1\u53f7\u5171\u5b58\u95ee\u9898\uff0c\u5229\u7528\u5bc6\u96c6\u90e8\u7f72\u76845G\u57fa\u7ad9\u8fdb\u884c\u96f7\u8fbe\u611f\u77e5\uff0c\u5b9e\u73b0\u9ad8\u6548\u81ea\u9002\u5e94\u7684\u9891\u8c31\u5171\u4eab\u3002", "method": "\u901a\u8fc7\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u96f7\u8fbe\u4fe1\u53f7\u5206\u79bb\u6d88\u96645G\u4f20\u8f93\u5e72\u6270\u3001\u8d44\u6e90\u7f51\u683c\u91cd\u5851\u5bf9\u9f50\u65f6\u9891\u5206\u8fa8\u7387\u3001\u57fa\u4e8e\u5408\u6210\u6570\u636e\u8bad\u7ec3\u7684\u96f6\u6837\u672c\u6a21\u677f\u76f8\u5173\u5b9e\u73b0\u68c0\u6d4b\u5206\u7c7b\u5b9a\u4f4d\u3002", "result": "\u5728\u771f\u5b9e5G\u6d41\u91cf\u6d4b\u8bd5\u4e2d\uff0c\u68c0\u6d4b\u6982\u7387\u8fbe97.02%(PUCCH)\u548c79.23%(PUSCH)\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u6700\u9ad897%\uff0c\u5b9a\u4f4d\u8bef\u5dee\u9891\u73872.68-6.20MHz\u3001\u65f6\u95f424.6-32.4\u5fae\u79d2\uff0c\u8fd0\u884c\u65f6\u5ef6\u4ec50.11/0.94ms\u3002", "conclusion": "BatStation\u6210\u529f\u5b9e\u73b0\u4e86\u8f7b\u91cf\u7ea7\u3001\u5b9e\u65f6\u7684\u96f7\u8fbe\u611f\u77e5\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a5G\u57fa\u7ad9\u96f7\u8fbe\u611f\u77e5\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u6ee1\u8db3\u5b9e\u9645\u90e8\u7f72\u9700\u6c42\u3002"}}
{"id": "2509.05714", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.05714", "abs": "https://arxiv.org/abs/2509.05714", "authors": ["Zhaoyu Fan", "Kaihang Pan", "Mingze Zhou", "Bosheng Qin", "Juncheng Li", "Shengyu Zhang", "Wenqiao Zhang", "Siliang Tang", "Fei Wu", "Yueting Zhuang"], "title": "Towards Meta-Cognitive Knowledge Editing for Multimodal LLMs", "comment": "15 pages, 6 figures", "summary": "Knowledge editing enables multimodal large language models (MLLMs) to\nefficiently update outdated or incorrect information. However, existing\nbenchmarks primarily emphasize cognitive-level modifications while lacking a\nfocus on deeper meta-cognitive processes. To bridge this gap, we introduce\nCogEdit, a novel benchmark designed to evaluate MLLMs' meta-cognitive knowledge\nediting abilities across three levels: (1) Counterfactual-Driven Editing,\nassessing self-awareness of knowledge correctness changes; (2) Boundary\nConstraint Editing, ensuring appropriate generalization without unintended\ninterference; and (3) Noise-Robust Editing, promoting reflective evaluation of\nuncertain information. To advance meta-cognitive editing, we propose MIND\n(Meta-cognitive INtegrated Dynamic Knowledge Editing), a framework that\nconstructs a meta-knowledge memory for self-awareness, employs game-theoretic\ninteractions to monitor knowledge activation, and incorporates label refinement\nfor noise-robust updates. Extensive experiments show that MIND significantly\noutperforms existing cognitive editing approaches, achieving strong performance\non both traditional and meta-cognitive knowledge editing benchmarks.", "AI": {"tldr": "CogEdit\u662f\u4e00\u4e2a\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5143\u8ba4\u77e5\u77e5\u8bc6\u7f16\u8f91\u80fd\u529b\u7684\u65b0\u57fa\u51c6\uff0c\u5305\u542b\u4e09\u4e2a\u5c42\u6b21\uff1a\u53cd\u4e8b\u5b9e\u9a71\u52a8\u7f16\u8f91\u3001\u8fb9\u754c\u7ea6\u675f\u7f16\u8f91\u548c\u566a\u58f0\u9c81\u68d2\u7f16\u8f91\u3002\u63d0\u51fa\u7684MIND\u6846\u67b6\u901a\u8fc7\u5143\u77e5\u8bc6\u8bb0\u5fc6\u3001\u535a\u5f08\u8bba\u4ea4\u4e92\u548c\u6807\u7b7e\u7cbe\u70bc\u663e\u8457\u63d0\u5347\u4e86\u7f16\u8f91\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u8ba4\u77e5\u5c42\u9762\u7684\u4fee\u6539\uff0c\u7f3a\u4e4f\u5bf9\u66f4\u6df1\u5c42\u6b21\u5143\u8ba4\u77e5\u8fc7\u7a0b\u7684\u5173\u6ce8\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8bc4\u4f30\u6a21\u578b\u81ea\u6211\u610f\u8bc6\u548c\u53cd\u601d\u80fd\u529b\u7684\u57fa\u51c6\u3002", "method": "\u63d0\u51faCogEdit\u57fa\u51c6\u8bc4\u4f30\u4e09\u4e2a\u5143\u8ba4\u77e5\u5c42\u6b21\uff0c\u5e76\u5f00\u53d1MIND\u6846\u67b6\uff1a\u6784\u5efa\u5143\u77e5\u8bc6\u8bb0\u5fc6\u5b9e\u73b0\u81ea\u6211\u610f\u8bc6\uff0c\u4f7f\u7528\u535a\u5f08\u8bba\u4ea4\u4e92\u76d1\u63a7\u77e5\u8bc6\u6fc0\u6d3b\uff0c\u901a\u8fc7\u6807\u7b7e\u7cbe\u70bc\u5b9e\u73b0\u566a\u58f0\u9c81\u68d2\u66f4\u65b0\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660eMIND\u6846\u67b6\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u8ba4\u77e5\u7f16\u8f91\u65b9\u6cd5\uff0c\u5728\u4f20\u7edf\u548c\u5143\u8ba4\u77e5\u77e5\u8bc6\u7f16\u8f91\u57fa\u51c6\u4e0a\u90fd\u53d6\u5f97\u4e86\u5f3a\u52b2\u6027\u80fd\u3002", "conclusion": "CogEdit\u57fa\u51c6\u548cMIND\u6846\u67b6\u6709\u6548\u586b\u8865\u4e86\u5143\u8ba4\u77e5\u77e5\u8bc6\u7f16\u8f91\u7684\u7a7a\u767d\uff0c\u4e3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u77e5\u8bc6\u7f16\u8f91\u8bc4\u4f30\u548c\u6539\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2509.05757", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05757", "abs": "https://arxiv.org/abs/2509.05757", "authors": ["Sarang Patil", "Zeyong Zhang", "Yiran Huang", "Tengfei Ma", "Mengjia Xu"], "title": "Hyperbolic Large Language Models", "comment": "32 pages, 6 figures", "summary": "Large language models (LLMs) have achieved remarkable success and\ndemonstrated superior performance across various tasks, including natural\nlanguage processing (NLP), weather forecasting, biological protein folding,\ntext generation, and solving mathematical problems. However, many real-world\ndata exhibit highly non-Euclidean latent hierarchical anatomy, such as protein\nnetworks, transportation networks, financial networks, brain networks, and\nlinguistic structures or syntactic trees in natural languages. Effectively\nlearning intrinsic semantic entailment and hierarchical relationships from\nthese raw, unstructured input data using LLMs remains an underexplored area.\nDue to its effectiveness in modeling tree-like hierarchical structures,\nhyperbolic geometry -- a non-Euclidean space -- has rapidly gained popularity\nas an expressive latent representation space for complex data modeling across\ndomains such as graphs, images, languages, and multi-modal data. Here, we\nprovide a comprehensive and contextual exposition of recent advancements in\nLLMs that leverage hyperbolic geometry as a representation space to enhance\nsemantic representation learning and multi-scale reasoning. Specifically, the\npaper presents a taxonomy of the principal techniques of Hyperbolic LLMs\n(HypLLMs) in terms of four main categories: (1) hyperbolic LLMs through exp/log\nmaps; (2) hyperbolic fine-tuned models; (3) fully hyperbolic LLMs, and (4)\nhyperbolic state-space models. We also explore crucial potential applications\nand outline future research directions. A repository of key papers, models,\ndatasets, and code implementations is available at\nhttps://github.com/sarangp2402/Hyperbolic-LLM-Models/tree/main.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u53cc\u66f2\u51e0\u4f55\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u56db\u79cd\u4e3b\u8981\u6280\u672f\u5206\u7c7b\u63a2\u8ba8\u5982\u4f55\u5229\u7528\u53cc\u66f2\u7a7a\u95f4\u589e\u5f3a\u8bed\u4e49\u8868\u793a\u5b66\u4e60\u548c\u591a\u5c3a\u5ea6\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u5177\u6709\u9ad8\u5ea6\u975e\u6b27\u51e0\u91cc\u5f97\u7684\u5c42\u6b21\u7ed3\u6784\u7279\u5f81\uff0c\u800c\u4f20\u7edfLLMs\u5728\u5904\u7406\u8fd9\u7c7b\u7ed3\u6784\u65f6\u5b58\u5728\u5c40\u9650\uff0c\u53cc\u66f2\u51e0\u4f55\u56e0\u5176\u5bf9\u6811\u72b6\u5c42\u6b21\u7ed3\u6784\u7684\u6709\u6548\u5efa\u6a21\u80fd\u529b\u800c\u6210\u4e3a\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u56db\u7c7b\u4e3b\u8981\u6280\u672f\uff1a\u901a\u8fc7\u6307\u6570/\u5bf9\u6570\u6620\u5c04\u7684\u53cc\u66f2LLMs\u3001\u53cc\u66f2\u5fae\u8c03\u6a21\u578b\u3001\u5b8c\u5168\u53cc\u66f2LLMs\u3001\u4ee5\u53ca\u53cc\u66f2\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u5e76\u5efa\u7acb\u4e86\u5206\u7c7b\u4f53\u7cfb\u3002", "result": "\u7cfb\u7edf\u68b3\u7406\u4e86\u53cc\u66f2\u51e0\u4f55\u5728LLMs\u4e2d\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u63d0\u4f9b\u4e86\u6280\u672f\u5206\u7c7b\u6846\u67b6\u548c\u5e94\u7528\u524d\u666f\u5206\u6790\u3002", "conclusion": "\u53cc\u66f2\u51e0\u4f55\u4e3aLLMs\u5904\u7406\u5c42\u6b21\u7ed3\u6784\u6570\u636e\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u672a\u6765\u9700\u8981\u5728\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9645\u5e94\u7528\u65b9\u9762\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2509.05764", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05764", "abs": "https://arxiv.org/abs/2509.05764", "authors": ["Yuwei Lou", "Hao Hu", "Shaocong Ma", "Zongfei Zhang", "Liang Wang", "Jidong Ge", "Xianping Tao"], "title": "DRF: LLM-AGENT Dynamic Reputation Filtering Framework", "comment": "This paper has been accepted by ICONIP 2025 but not published", "summary": "With the evolution of generative AI, multi - agent systems leveraging large -\nlanguage models(LLMs) have emerged as a powerful tool for complex tasks.\nHowever, these systems face challenges in quantifying agent performance and\nlack mechanisms to assess agent credibility. To address these issues, we\nintroduce DRF, a dynamic reputation filtering framework. DRF constructs an\ninteractive rating network to quantify agent performance, designs a reputation\nscoring mechanism to measure agent honesty and capability, and integrates an\nUpper Confidence Bound - based strategy to enhance agent selection efficiency.\nExperiments show that DRF significantly improves task completion quality and\ncollaboration efficiency in logical reasoning and code - generation tasks,\noffering a new approach for multi - agent systems to handle large - scale\ntasks.", "AI": {"tldr": "DRF\u662f\u4e00\u4e2a\u52a8\u6001\u4fe1\u8a89\u8fc7\u6ee4\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u4ea4\u4e92\u8bc4\u5206\u7f51\u7edc\u91cf\u5316\u667a\u80fd\u4f53\u6027\u80fd\uff0c\u8bbe\u8ba1\u4fe1\u8a89\u8bc4\u5206\u673a\u5236\u8bc4\u4f30\u667a\u80fd\u4f53\u8bda\u5b9e\u5ea6\u548c\u80fd\u529b\uff0c\u4f7f\u7528UCB\u7b56\u7565\u63d0\u5347\u667a\u80fd\u4f53\u9009\u62e9\u6548\u7387\uff0c\u663e\u8457\u63d0\u9ad8\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u4efb\u52a1\u5b8c\u6210\u8d28\u91cf\u548c\u534f\u4f5c\u6548\u7387\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u53d1\u5c55\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u9762\u4e34\u667a\u80fd\u4f53\u6027\u80fd\u96be\u4ee5\u91cf\u5316\u548c\u7f3a\u4e4f\u4fe1\u8a89\u8bc4\u4f30\u673a\u5236\u7684\u95ee\u9898\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u6765\u63d0\u5347\u7cfb\u7edf\u6548\u80fd\u3002", "method": "\u63d0\u51faDRF\u6846\u67b6\uff1a1\uff09\u6784\u5efa\u4ea4\u4e92\u8bc4\u5206\u7f51\u7edc\u91cf\u5316\u667a\u80fd\u4f53\u6027\u80fd\uff1b2\uff09\u8bbe\u8ba1\u4fe1\u8a89\u8bc4\u5206\u673a\u5236\u8bc4\u4f30\u667a\u80fd\u4f53\u8bda\u5b9e\u5ea6\u548c\u80fd\u529b\uff1b3\uff09\u96c6\u6210\u57fa\u4e8e\u4e0a\u7f6e\u4fe1\u754c(UCB)\u7684\u7b56\u7565\u4f18\u5316\u667a\u80fd\u4f53\u9009\u62e9\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDRF\u5728\u903b\u8f91\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u5b8c\u6210\u8d28\u91cf\u548c\u534f\u4f5c\u6548\u7387\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5904\u7406\u5927\u89c4\u6a21\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002", "conclusion": "DRF\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\u91cf\u5316\u548c\u4fe1\u8a89\u8bc4\u4f30\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u4fe1\u8a89\u8fc7\u6ee4\u673a\u5236\u63d0\u5347\u4e86\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\uff0c\u4e3a\u5927\u89c4\u6a21\u4efb\u52a1\u5904\u7406\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2509.05772", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05772", "abs": "https://arxiv.org/abs/2509.05772", "authors": ["Nasser Alkhulaifi", "Ismail Gokay Dogan", "Timothy R. Cargan", "Alexander L. Bowler", "Direnc Pekaslan", "Nicholas J. Watson", "Isaac Triguero"], "title": "Decision-Focused Learning Enhanced by Automated Feature Engineering for Energy Storage Optimisation", "comment": "22 pages, 10 figures, journal-based paper", "summary": "Decision-making under uncertainty in energy management is complicated by\nunknown parameters hindering optimal strategies, particularly in Battery Energy\nStorage System (BESS) operations. Predict-Then-Optimise (PTO) approaches treat\nforecasting and optimisation as separate processes, allowing prediction errors\nto cascade into suboptimal decisions as models minimise forecasting errors\nrather than optimising downstream tasks. The emerging Decision-Focused Learning\n(DFL) methods overcome this limitation by integrating prediction and\noptimisation; however, they are relatively new and have been tested primarily\non synthetic datasets or small-scale problems, with limited evidence of their\npractical viability. Real-world BESS applications present additional\nchallenges, including greater variability and data scarcity due to collection\nconstraints and operational limitations. Because of these challenges, this work\nleverages Automated Feature Engineering (AFE) to extract richer representations\nand improve the nascent approach of DFL. We propose an AFE-DFL framework\nsuitable for small datasets that forecasts electricity prices and demand while\noptimising BESS operations to minimise costs. We validate its effectiveness on\na novel real-world UK property dataset. The evaluation compares DFL methods\nagainst PTO, with and without AFE. The results show that, on average, DFL\nyields lower operating costs than PTO and adding AFE further improves the\nperformance of DFL methods by 22.9-56.5% compared to the same models without\nAFE. These findings provide empirical evidence for DFL's practical viability in\nreal-world settings, indicating that domain-specific AFE enhances DFL and\nreduces reliance on domain expertise for BESS optimisation, yielding economic\nbenefits with broader implications for energy management systems facing similar\nchallenges.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\uff08AFE\uff09\u548c\u51b3\u7b56\u805a\u7126\u5b66\u4e60\uff08DFL\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5b9e\u9645\u7535\u529b\u7cfb\u7edf\u4e2d\u7684\u7535\u6c60\u80fd\u91cf\u5b58\u50a8\u7cfb\u7edf\uff08BESS\uff09\u4f18\u5316\u95ee\u9898\uff0c\u5728\u5c0f\u6570\u636e\u96c6\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u8fd0\u8425\u6210\u672c\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u7684\u9884\u6d4b-\u4f18\u5316\uff08PTO\uff09\u65b9\u6cd5\u5c06\u9884\u6d4b\u548c\u4f18\u5316\u5206\u79bb\u5904\u7406\uff0c\u5bfc\u81f4\u9884\u6d4b\u9519\u8bef\u4f20\u64ad\u5230\u51b3\u7b56\u4e2d\uff0c\u800c\u65b0\u5174\u7684DFL\u65b9\u6cd5\u867d\u7136\u96c6\u6210\u4e86\u9884\u6d4b\u548c\u4f18\u5316\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u548c\u53d8\u5f02\u6027\u6311\u6218\u3002", "method": "\u63d0\u51faAFE-DFL\u6846\u67b6\uff0c\u5229\u7528\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\u63d0\u53d6\u66f4\u4e30\u5bcc\u7684\u8868\u5f81\uff0c\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u7535\u4ef7\u548c\u9700\u6c42\u9884\u6d4b\uff0c\u540c\u65f6\u4f18\u5316BESS\u8fd0\u8425\u4ee5\u6700\u5c0f\u5316\u6210\u672c\u3002", "result": "\u5728\u82f1\u56fd\u5b9e\u9645\u623f\u5c4b\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cDFL\u6cd5\u6bd4PTO\u6cd5\u5e73\u5747\u8282\u7701\u66f4\u591a\u8fd0\u8425\u6210\u672c\uff0c\u800c\u6dfb\u52a0AFE\u540e\u8ba9DFL\u6027\u80fd\u63d0\u534722.9-56.5%\u3002", "conclusion": "\u7ed3\u679c\u8bc1\u660eDFL\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u9886\u57df\u7279\u5b9a\u7684AFE\u80fd\u591f\u589e\u5f3aDFL\u6548\u679c\uff0c\u51cf\u5c11\u5bf9\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u7684\u4f9d\u8d56\uff0c\u5e76\u4e3a\u9762\u4e34\u7c7b\u4f3c\u6311\u6218\u7684\u80fd\u6e90\u7ba1\u7406\u7cfb\u7edf\u5e26\u6765\u7ecf\u6d4e\u6548\u76ca\u3002"}}
{"id": "2509.05818", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05818", "abs": "https://arxiv.org/abs/2509.05818", "authors": ["Won Seok Jang", "Hieu Tran", "Manav Mistry", "SaiKiran Gandluri", "Yifan Zhang", "Sharmin Sultana", "Sunjae Kown", "Yuan Zhang", "Zonghai Yao", "Hong Yu"], "title": "Chatbot To Help Patients Understand Their Health", "comment": "Accepted in EMNLP 2025 Findings", "summary": "Patients must possess the knowledge necessary to actively participate in\ntheir care. We present NoteAid-Chatbot, a conversational AI that promotes\npatient understanding via a novel 'learning as conversation' framework, built\non a multi-agent large language model (LLM) and reinforcement learning (RL)\nsetup without human-labeled data. NoteAid-Chatbot was built on a lightweight\nLLaMA 3.2 3B model trained in two stages: initial supervised fine-tuning on\nconversational data synthetically generated using medical conversation\nstrategies, followed by RL with rewards derived from patient understanding\nassessments in simulated hospital discharge scenarios. Our evaluation, which\nincludes comprehensive human-aligned assessments and case studies, demonstrates\nthat NoteAid-Chatbot exhibits key emergent behaviors critical for patient\neducation, such as clarity, relevance, and structured dialogue, even though it\nreceived no explicit supervision for these attributes. Our results show that\neven simple Proximal Policy Optimization (PPO)-based reward modeling can\nsuccessfully train lightweight, domain-specific chatbots to handle multi-turn\ninteractions, incorporate diverse educational strategies, and meet nuanced\ncommunication objectives. Our Turing test demonstrates that NoteAid-Chatbot\nsurpasses non-expert human. Although our current focus is on healthcare, the\nframework we present illustrates the feasibility and promise of applying\nlow-cost, PPO-based RL to realistic, open-ended conversational domains,\nbroadening the applicability of RL-based alignment methods.", "AI": {"tldr": "NoteAid-Chatbot\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53LLM\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u5bf9\u8bddAI\uff0c\u901a\u8fc7'\u5b66\u4e60\u5373\u5bf9\u8bdd'\u6846\u67b6\u4fc3\u8fdb\u60a3\u8005\u7406\u89e3\u533b\u7597\u4fe1\u606f\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u3002", "motivation": "\u60a3\u8005\u9700\u8981\u5177\u5907\u76f8\u5173\u77e5\u8bc6\u624d\u80fd\u79ef\u6781\u53c2\u4e0e\u81ea\u8eab\u62a4\u7406\uff0c\u4f46\u533b\u7597\u4fe1\u606f\u7406\u89e3\u5b58\u5728\u969c\u788d\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6709\u6548\u6559\u80b2\u60a3\u8005\u7684\u5bf9\u8bdd\u7cfb\u7edf\u3002", "method": "\u57fa\u4e8e\u8f7b\u91cf\u7ea7LLaMA 3.2 3B\u6a21\u578b\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u5148\u5728\u5408\u6210\u533b\u7597\u5bf9\u8bdd\u6570\u636e\u4e0a\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff0c\u7136\u540e\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08PPO\uff09\u5728\u6a21\u62df\u51fa\u9662\u573a\u666f\u4e2d\u8fdb\u884c\u5956\u52b1\u4f18\u5316\u3002", "result": "NoteAid-Chatbot\u5c55\u73b0\u51fa\u5173\u952e\u7684\u65b0\u5174\u884c\u4e3a\uff08\u6e05\u6670\u6027\u3001\u76f8\u5173\u6027\u3001\u7ed3\u6784\u5316\u5bf9\u8bdd\uff09\uff0c\u5728\u56fe\u7075\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u975e\u4e13\u5bb6\u4eba\u7c7b\u8868\u73b0\uff0c\u8bc1\u660e\u8f7b\u91cf\u6a21\u578b\u4e5f\u80fd\u5904\u7406\u591a\u8f6e\u4ea4\u4e92\u548c\u590d\u6742\u6559\u80b2\u7b56\u7565\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c55\u793a\u4e86\u4f4e\u6210\u672cPPO\u5f3a\u5316\u5b66\u4e60\u5728\u73b0\u5b9e\u5f00\u653e\u57df\u5bf9\u8bdd\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u6269\u5c55\u4e86RL\u5bf9\u9f50\u65b9\u6cd5\u7684\u9002\u7528\u6027\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u9886\u57df\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2509.05933", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2509.05933", "abs": "https://arxiv.org/abs/2509.05933", "authors": ["Md Hasebul Hasan", "Mahir Labib Dihan", "Mohammed Eunus Ali", "Md Rizwan Parvez"], "title": "MapAgent: A Hierarchical Agent for Geospatial Reasoning with Dynamic Map Tool Integration", "comment": "27 Pages", "summary": "Agentic AI has significantly extended the capabilities of large language\nmodels (LLMs) by enabling complex reasoning and tool use. However, most\nexisting frameworks are tailored to domains such as mathematics, coding, or web\nautomation, and fall short on geospatial tasks that require spatial reasoning,\nmulti-hop planning, and real-time map interaction. To address these challenges,\nwe introduce MapAgent, a hierarchical multi-agent plug-and-play framework with\ncustomized toolsets and agentic scaffolds for map-integrated geospatial\nreasoning. Unlike existing flat agent-based approaches that treat tools\nuniformly-often overwhelming the LLM when handling similar but subtly different\ngeospatial APIs-MapAgent decouples planning from execution. A high-level\nplanner decomposes complex queries into subgoals, which are routed to\nspecialized modules. For tool-heavy modules-such as map-based services-we then\ndesign a dedicated map-tool agent that efficiently orchestrates related APIs\nadaptively in parallel to effectively fetch geospatial data relevant for the\nquery, while simpler modules (e.g., solution generation or answer extraction)\noperate without additional agent overhead. This hierarchical design reduces\ncognitive load, improves tool selection accuracy, and enables precise\ncoordination across similar APIs. We evaluate MapAgent on four diverse\ngeospatial benchmarks-MapEval-Textual, MapEval-API, MapEval-Visual, and\nMapQA-and demonstrate substantial gains over state-of-the-art tool-augmented\nand agentic baselines. We open-source our framwork at\nhttps://github.com/Hasebul/MapAgent.", "AI": {"tldr": "MapAgent\u662f\u4e00\u4e2a\u5206\u5c42\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u4e13\u95e8\u7528\u4e8e\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\uff0c\u901a\u8fc7\u89e3\u8026\u89c4\u5212\u4e0e\u6267\u884c\u6765\u63d0\u9ad8\u5de5\u5177\u9009\u62e9\u51c6\u786e\u6027\u548cAPI\u534f\u8c03\u80fd\u529b", "motivation": "\u73b0\u6709AI\u4ee3\u7406\u6846\u67b6\u4e3b\u8981\u9488\u5bf9\u6570\u5b66\u3001\u7f16\u7a0b\u7b49\u9886\u57df\uff0c\u5728\u5730\u7406\u7a7a\u95f4\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u8db3\uff0c\u9700\u8981\u7a7a\u95f4\u63a8\u7406\u3001\u591a\u8df3\u89c4\u5212\u548c\u5b9e\u65f6\u5730\u56fe\u4ea4\u4e92\u80fd\u529b", "method": "\u91c7\u7528\u5206\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff1a\u9ad8\u5c42\u89c4\u5212\u5668\u5206\u89e3\u67e5\u8be2\u4e3a\u5b50\u76ee\u6807\uff0c\u4e13\u7528\u5730\u56fe\u5de5\u5177\u4ee3\u7406\u5e76\u884c\u534f\u8c03\u76f8\u5173API\u83b7\u53d6\u5730\u7406\u7a7a\u95f4\u6570\u636e\uff0c\u7b80\u5355\u6a21\u5757\u65e0\u9700\u989d\u5916\u4ee3\u7406\u5f00\u9500", "result": "\u5728\u56db\u4e2a\u5730\u7406\u7a7a\u95f4\u57fa\u51c6\u6d4b\u8bd5(MapEval-Textual\u3001MapEval-API\u3001MapEval-Visual\u3001MapQA)\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u589e\u5f3a\u548c\u4ee3\u7406\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "MapAgent\u901a\u8fc7\u5206\u5c42\u8bbe\u8ba1\u548c\u4e13\u7528\u5de5\u5177\u96c6\u6709\u6548\u89e3\u51b3\u4e86\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u7684\u6311\u6218\uff0c\u964d\u4f4e\u4e86\u8ba4\u77e5\u8d1f\u8377\uff0c\u63d0\u9ad8\u4e86\u5de5\u5177\u9009\u62e9\u7684\u51c6\u786e\u6027"}}
{"id": "2509.06024", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06024", "abs": "https://arxiv.org/abs/2509.06024", "authors": ["Haoyang He", "Zihua Rong", "Kun Ji", "Chenyang Li", "Qing Huang", "Chong Xia", "Lan Yang", "Honggang Zhang"], "title": "Rethinking Reasoning Quality in Large Language Models through Enhanced Chain-of-Thought via RL", "comment": null, "summary": "Reinforcement learning (RL) has recently become the dominant paradigm for\nstrengthening the reasoning abilities of large language models (LLMs). Yet the\nrule-based reward functions commonly used on mathematical or programming\nbenchmarks assess only answer format and correctness, providing no signal as to\nwhether the induced Chain-of-Thought (CoT) actually improves the answer.\nFurthermore, such task-specific training offers limited control over logical\ndepth and therefore may fail to reveal a model's genuine reasoning capacity. We\npropose Dynamic Reasoning Efficiency Reward (DRER) -- a plug-and-play RL reward\nframework that reshapes both reward and advantage signals. (i) A Reasoning\nQuality Reward assigns fine-grained credit to those reasoning chains that\ndemonstrably raise the likelihood of the correct answer, directly incentivising\nthe trajectories with beneficial CoT tokens. (ii) A Dynamic Length Advantage\ndecays the advantage of responses whose length deviates from a\nvalidation-derived threshold, stabilising training. To facilitate rigorous\nassessment, we also release Logictree, a dynamically constructed deductive\nreasoning dataset that functions both as RL training data and as a\ncomprehensive benchmark. Experiments confirm the effectiveness of DRER: our 7B\nmodel attains GPT-o3-mini level performance on Logictree with 400 trianing\nsteps, while the average confidence of CoT-augmented answers rises by 30%. The\nmodel further exhibits generalisation across diverse logical-reasoning\ndatasets, and the mathematical benchmark AIME24. These results illuminate how\nRL shapes CoT behaviour and chart a practical path toward enhancing\nformal-reasoning skills in large language models. All code and data are\navailable in repository https://github.com/Henryhe09/DRER.", "AI": {"tldr": "\u63d0\u51fa\u4e86DRER\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u7406\u8d28\u91cf\u5956\u52b1\u548c\u52a8\u6001\u957f\u5ea6\u4f18\u52bf\u6765\u6539\u8fdb\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\u51fd\u6570\u53ea\u8bc4\u4f30\u7b54\u6848\u683c\u5f0f\u548c\u6b63\u786e\u6027\uff0c\u65e0\u6cd5\u5224\u65ad\u63a8\u7406\u94fe\u662f\u5426\u771f\u6b63\u6539\u5584\u7b54\u6848\uff0c\u4e14\u4efb\u52a1\u7279\u5b9a\u8bad\u7ec3\u5bf9\u903b\u8f91\u6df1\u5ea6\u7684\u63a7\u5236\u6709\u9650", "method": "DRER\u6846\u67b6\u5305\u542b\uff1a(i)\u63a8\u7406\u8d28\u91cf\u5956\u52b1 - \u5bf9\u63d0\u5347\u6b63\u786e\u7b54\u6848\u6982\u7387\u7684\u63a8\u7406\u94fe\u7ed9\u4e88\u7ec6\u7c92\u5ea6\u5956\u52b1\uff1b(ii)\u52a8\u6001\u957f\u5ea6\u4f18\u52bf - \u5bf9\u504f\u79bb\u9a8c\u8bc1\u9608\u503c\u7684\u54cd\u5e94\u957f\u5ea6\u8fdb\u884c\u4f18\u52bf\u8870\u51cf", "result": "7B\u6a21\u578b\u5728400\u8bad\u7ec3\u6b65\u540e\u8fbe\u5230GPT-o3-mini\u6c34\u5e73\uff0cCoT\u589e\u5f3a\u7b54\u6848\u7684\u5e73\u5747\u7f6e\u4fe1\u5ea6\u63d0\u534730%\uff0c\u5728\u591a\u4e2a\u903b\u8f91\u63a8\u7406\u6570\u636e\u96c6\u548cAIME24\u6570\u5b66\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u6cdb\u5316\u80fd\u529b", "conclusion": "DRER\u6709\u6548\u5851\u9020\u4e86CoT\u884c\u4e3a\uff0c\u4e3a\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f62\u5f0f\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84"}}
{"id": "2509.06160", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.06160", "abs": "https://arxiv.org/abs/2509.06160", "authors": ["Haozhe Wang", "Haoran Que", "Qixin Xu", "Minghao Liu", "Wangchunshu Zhou", "Jiazhan Feng", "Wanjun Zhong", "Wei Ye", "Tong Yang", "Wenhao Huang", "Ge Zhang", "Fangzhen Lin"], "title": "Reverse-Engineered Reasoning for Open-Ended Generation", "comment": "Preprint", "summary": "While the ``deep reasoning'' paradigm has spurred significant advances in\nverifiable domains like mathematics, its application to open-ended, creative\ngeneration remains a critical challenge. The two dominant methods for\ninstilling reasoning -- reinforcement learning (RL) and instruction\ndistillation -- falter in this area; RL struggles with the absence of clear\nreward signals and high-quality reward models, while distillation is\nprohibitively expensive and capped by the teacher model's capabilities. To\novercome these limitations, we introduce REverse-Engineered Reasoning (REER), a\nnew paradigm that fundamentally shifts the approach. Instead of building a\nreasoning process ``forwards'' through trial-and-error or imitation, REER works\n``backwards'' from known-good solutions to computationally discover the latent,\nstep-by-step deep reasoning process that could have produced them. Using this\nscalable, gradient-free approach, we curate and open-source DeepWriting-20K, a\nlarge-scale dataset of 20,000 deep reasoning trajectories for open-ended tasks.\nOur model, DeepWriter-8B, trained on this data, not only surpasses strong\nopen-source baselines but also achieves performance competitive with, and at\ntimes superior to, leading proprietary models like GPT-4o and Claude 3.5.", "AI": {"tldr": "REER\u662f\u4e00\u79cd\u65b0\u7684\u6df1\u5ea6\u63a8\u7406\u8303\u5f0f\uff0c\u901a\u8fc7\u4ece\u5df2\u77e5\u826f\u597d\u89e3\u51b3\u65b9\u6848\u53cd\u5411\u5de5\u7a0b\u63a8\u5bfc\u51fa\u63a8\u7406\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u5f00\u653e\u521b\u9020\u6027\u751f\u6210\u4e2d\u7684\u63a8\u7406\u6311\u6218", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u548c\u6307\u4ee4\u84b8\u998f\u65b9\u6cd5\u5728\u5f00\u653e\u521b\u9020\u6027\u751f\u6210\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff1aRL\u7f3a\u4e4f\u6e05\u6670\u5956\u52b1\u4fe1\u53f7\uff0c\u84b8\u998f\u65b9\u6cd5\u6210\u672c\u9ad8\u4e14\u53d7\u9650\u4e8e\u6559\u5e08\u6a21\u578b\u80fd\u529b", "method": "REER\uff08\u53cd\u5411\u5de5\u7a0b\u63a8\u7406\uff09\u8303\u5f0f\uff0c\u4ece\u5df2\u77e5\u826f\u597d\u89e3\u51b3\u65b9\u6848\u53cd\u5411\u8ba1\u7b97\u53d1\u73b0\u6f5c\u5728\u7684\u9010\u6b65\u6df1\u5ea6\u63a8\u7406\u8fc7\u7a0b\uff0c\u91c7\u7528\u53ef\u6269\u5c55\u7684\u65e0\u68af\u5ea6\u65b9\u6cd5", "result": "\u6784\u5efa\u4e86DeepWriting-20K\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0820,000\u6761\u6df1\u5ea6\u63a8\u7406\u8f68\u8ff9\uff09\uff0cDeepWriter-8B\u6a21\u578b\u8d85\u8d8a\u5f00\u6e90\u57fa\u7ebf\uff0c\u6027\u80fd\u4e0eGPT-4o\u548cClaude 3.5\u7b49\u4e13\u6709\u6a21\u578b\u76f8\u5f53\u751a\u81f3\u66f4\u4f18", "conclusion": "REER\u4e3a\u5f00\u653e\u521b\u9020\u6027\u4efb\u52a1\u4e2d\u7684\u6df1\u5ea6\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u8303\u5f0f\uff0c\u901a\u8fc7\u53cd\u5411\u5de5\u7a0b\u65b9\u6cd5\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u6027\u80fd\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7a81\u7834"}}
{"id": "2509.06174", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.06174", "abs": "https://arxiv.org/abs/2509.06174", "authors": ["Wei Han", "Geng Zhan", "Sicheng Yu", "Chenyu Wang", "Bryan Hooi"], "title": "From Long to Short: LLMs Excel at Trimming Own Reasoning Chains", "comment": "21 pages, 5 figures, 7 tables", "summary": "O1/R1 style large reasoning models (LRMs) signal a substantial leap forward\nover conventional instruction-following LLMs. By applying test-time scaling to\ngenerate extended reasoning paths, they establish many SOTAs across a wide\nrange of complex reasoning tasks. However, recent studies show that LRMs are\nprone to suffer from overthinking -- the tendency to overcomplicate simple\nproblems, leading to excessive strategy switching and long, convoluted\nreasoning traces that hinder their interpretability. To mitigate this issue, we\nconduct a systematic investigation into the reasoning efficiency of a broad set\nof LRMs and uncover a common dilemma: the difficulty in balancing multiple\ngeneration objectives such as correctness and brevity. Based on this discovery,\nwe propose a test-time scaling method, EDIT (Efficient Dynamic Inference\nTrimming), which efficiently guides LRMs to identify the shortest correct\nreasoning paths at test time. EDIT employs constraint-guided generation while\njointly tracking length and answer distributions under varying constraints,\nallowing it to select responses that strike an optimal balance between\nconciseness and correctness. Extensive experiments across diverse models and\ndatasets show that EDIT substantially enhance the reasoning efficiency,\nproducing compact yet informative outputs that improve readability and user\nexperience.", "AI": {"tldr": "EDIT\u662f\u4e00\u79cd\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ea6\u675f\u5f15\u5bfc\u751f\u6210\u548c\u8054\u5408\u8ddf\u8e2a\u957f\u5ea6\u4e0e\u7b54\u6848\u5206\u5e03\uff0c\u5e2e\u52a9\u5927\u578b\u63a8\u7406\u6a21\u578b\u627e\u5230\u6700\u77ed\u7684\u6b63\u786e\u63a8\u7406\u8def\u5f84\uff0c\u5e73\u8861\u7b80\u6d01\u6027\u548c\u6b63\u786e\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b(LRMs)\u5728\u5904\u7406\u7b80\u5355\u95ee\u9898\u65f6\u5bb9\u6613\u8fc7\u5ea6\u601d\u8003\uff0c\u4ea7\u751f\u5197\u957f\u590d\u6742\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u5f71\u54cd\u53ef\u89e3\u91ca\u6027\u3002\u7814\u7a76\u53d1\u73b0LRMs\u96be\u4ee5\u5e73\u8861\u6b63\u786e\u6027\u548c\u7b80\u6d01\u6027\u7b49\u591a\u4e2a\u751f\u6210\u76ee\u6807\u3002", "method": "\u63d0\u51faEDIT\u65b9\u6cd5\uff0c\u91c7\u7528\u7ea6\u675f\u5f15\u5bfc\u751f\u6210\uff0c\u5728\u6d4b\u8bd5\u65f6\u8054\u5408\u8ddf\u8e2a\u957f\u5ea6\u548c\u7b54\u6848\u5206\u5e03\uff0c\u9009\u62e9\u5728\u7b80\u6d01\u6027\u548c\u6b63\u786e\u6027\u4e4b\u95f4\u8fbe\u5230\u6700\u4f18\u5e73\u8861\u7684\u54cd\u5e94\u3002", "result": "\u5728\u5404\u79cd\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cEDIT\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\uff0c\u4ea7\u751f\u7d27\u51d1\u800c\u4fe1\u606f\u4e30\u5bcc\u7684\u8f93\u51fa\uff0c\u6539\u5584\u4e86\u53ef\u8bfb\u6027\u548c\u7528\u6237\u4f53\u9a8c\u3002", "conclusion": "EDIT\u6709\u6548\u89e3\u51b3\u4e86LRMs\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u63a8\u7406\u4fee\u526a\u5b9e\u73b0\u4e86\u63a8\u7406\u6548\u7387\u7684\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5b9e\u7528\u5316\u63d0\u4f9b\u4e86\u91cd\u8981\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.06235", "categories": ["cs.AI", "cs.MA", "I.2.11; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2509.06235", "abs": "https://arxiv.org/abs/2509.06235", "authors": ["Olivier Schipper", "Yudi Zhang", "Yali Du", "Mykola Pechenizkiy", "Meng Fang"], "title": "PillagerBench: Benchmarking LLM-Based Agents in Competitive Minecraft Team Environments", "comment": "for the source code, see https://github.com/aialt/PillagerBench", "summary": "LLM-based agents have shown promise in various cooperative and strategic\nreasoning tasks, but their effectiveness in competitive multi-agent\nenvironments remains underexplored. To address this gap, we introduce\nPillagerBench, a novel framework for evaluating multi-agent systems in\nreal-time competitive team-vs-team scenarios in Minecraft. It provides an\nextensible API, multi-round testing, and rule-based built-in opponents for\nfair, reproducible comparisons. We also propose TactiCrafter, an LLM-based\nmulti-agent system that facilitates teamwork through human-readable tactics,\nlearns causal dependencies, and adapts to opponent strategies. Our evaluation\ndemonstrates that TactiCrafter outperforms baseline approaches and showcases\nadaptive learning through self-play. Additionally, we analyze its learning\nprocess and strategic evolution over multiple game episodes. To encourage\nfurther research, we have open-sourced PillagerBench, fostering advancements in\nmulti-agent AI for competitive environments.", "AI": {"tldr": "\u57fa\u4e8eLLM\u7684\u591a\u6e38\u620f\u5ba4\u5185\u7ade\u4e89\u73af\u5883\u8bc4\u6d4b\u6846\u67b6PillagerBench\u548c\u6218\u672f\u7cfb\u7edfTactiCrafter\uff0c\u5728Minecraft\u4e2d\u5b9e\u73b0\u4e86\u56e2\u961f\u5bf9\u6297\u573a\u666f\u7684\u9ad8\u6548\u8bc4\u6d4b\u548c\u9002\u5e94\u6027\u5b66\u4e60", "motivation": "\u5f53\u524dLLM\u57fa\u4e8e\u7684\u4ee3\u7406\u5728\u7ade\u4e89\u6027\u591a\u6e38\u620f\u5ba4\u73af\u5883\u4e2d\u7684\u8868\u73b0\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u4e00\u4e2a\u516c\u5e73\u53ef\u590d\u73b0\u7684\u8bc4\u6d4b\u6846\u67b6\u6765\u63a8\u52a8\u8be5\u9886\u57df\u7684\u7814\u7a76", "method": "\u5f00\u53d1PillagerBench\u6846\u67b6\u63d0\u4f9b\u6269\u5c55API\u3001\u591a\u8f6e\u6d4b\u8bd5\u548c\u89c4\u5219\u57fa\u7840\u5bf9\u624b\uff1b\u8bbe\u8ba1TactiCrafter\u7cfb\u7edf\u901a\u8fc7\u4eba\u7c7b\u53ef\u8bfb\u6218\u672f\u4fc3\u8fdb\u56e2\u961f\u5408\u4f5c\uff0c\u5b66\u4e60\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u5e76\u9002\u5e94\u5bf9\u624b\u7b56\u7565", "result": "TactiCrafter\u5728\u6027\u80fd\u4e0a\u8d85\u8fc7\u57fa\u7ebf\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u6211\u5bf9\u6297\u5c55\u73b0\u51fa\u9002\u5e94\u6027\u5b66\u4e60\u80fd\u529b\uff0c\u5e76\u5728\u591a\u4e2a\u6e38\u620f\u5faa\u73af\u4e2d\u5b8c\u6210\u6218\u7565\u8fed\u4ee3\u6f14\u5316", "conclusion": "\u7814\u7a76\u4e3a\u7ade\u4e89\u6027\u591a\u6e38\u620f\u5ba4\u73af\u5883\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u8bc4\u6d4b\u5de5\u5177\u548c\u9002\u5e94\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u5f00\u6e90PillagerBench\u63a8\u52a8\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76"}}
{"id": "2509.06239", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06239", "abs": "https://arxiv.org/abs/2509.06239", "authors": ["Manvi Jha", "Jiaxin Wan", "Deming Chen"], "title": "Proof2Silicon: Prompt Repair for Verified Code and Hardware Generation via Reinforcement Learning", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nautomated code generation but frequently produce code that fails formal\nverification, an essential requirement for hardware and safety-critical\ndomains. To overcome this fundamental limitation, we previously proposed\nPREFACE, a model-agnostic framework based on reinforcement learning (RL) that\niteratively repairs the prompts provided to frozen LLMs, systematically\nsteering them toward generating formally verifiable Dafny code without costly\nfine-tuning. This work presents Proof2Silicon, a novel end-to-end synthesis\nframework that embeds the previously proposed PREFACE flow to enable the\ngeneration of correctness-by-construction hardware directly from natural\nlanguage specifications. Proof2Silicon operates by: (1) leveraging PREFACE's\nverifier-driven RL agent to optimize prompt generation iteratively, ensuring\nDafny code correctness; (2) automatically translating verified Dafny programs\ninto synthesizable high-level C using Dafny's Python backend and PyLog; and (3)\nemploying Vivado HLS to produce RTL implementations. Evaluated rigorously on a\nchallenging 100-task benchmark, PREFACE's RL-guided prompt optimization\nconsistently improved Dafny verification success rates across diverse LLMs by\nup to 21%. Crucially, Proof2Silicon achieved an end-to-end hardware synthesis\nsuccess rate of up to 72%, generating RTL designs through Vivado HLS synthesis\nflows. These results demonstrate a robust, scalable, and automated pipeline for\nLLM-driven, formally verified hardware synthesis, bridging natural-language\nspecification and silicon realization.", "AI": {"tldr": "Proof2Silicon\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u786c\u4ef6\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7PREFACE\u7684\u5f3a\u5316\u5b66\u4e60\u63d0\u793a\u4f18\u5316\u751f\u6210\u53ef\u9a8c\u8bc1\u7684Dafny\u4ee3\u7801\uff0c\u7136\u540e\u81ea\u52a8\u8f6c\u6362\u4e3aC\u4ee3\u7801\u5e76\u6700\u7ec8\u5408\u6210RTL\u786c\u4ef6\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u5230\u7845\u5b9e\u73b0\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u751f\u6210\u7684\u4ee3\u7801\u7ecf\u5e38\u65e0\u6cd5\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u8fd9\u5728\u786c\u4ef6\u548c\u5b89\u5168\u5173\u952e\u9886\u57df\u662f\u57fa\u672c\u8981\u6c42\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6b63\u786e\u7684\u4ee3\u7801\u3002", "method": "1) \u4f7f\u7528PREFACE\u7684\u9a8c\u8bc1\u5668\u9a71\u52a8RL\u4ee3\u7406\u8fed\u4ee3\u4f18\u5316\u63d0\u793a\u751f\u6210\uff0c\u786e\u4fddDafny\u4ee3\u7801\u6b63\u786e\u6027\uff1b2) \u5c06\u9a8c\u8bc1\u540e\u7684Dafny\u7a0b\u5e8f\u81ea\u52a8\u8f6c\u6362\u4e3a\u53ef\u5408\u6210\u7684\u9ad8\u7ea7C\u4ee3\u7801\uff1b3) \u4f7f\u7528Vivado HLS\u751f\u6210RTL\u5b9e\u73b0", "result": "\u5728100\u4e2a\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPREFACE\u7684RL\u5f15\u5bfc\u63d0\u793a\u4f18\u5316\u5c06Dafny\u9a8c\u8bc1\u6210\u529f\u7387\u63d0\u9ad8\u4e8621%\uff0cProof2Silicon\u5b9e\u73b0\u4e86\u9ad8\u8fbe72%\u7684\u7aef\u5230\u7aef\u786c\u4ef6\u5408\u6210\u6210\u529f\u7387", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u4e00\u4e2a\u7a33\u5065\u3001\u53ef\u6269\u5c55\u4e14\u81ea\u52a8\u5316\u7684\u6d41\u7a0b\uff0c\u7528\u4e8eLLM\u9a71\u52a8\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u786c\u4ef6\u5408\u6210\uff0c\u8fde\u63a5\u4e86\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u548c\u7845\u5b9e\u73b0"}}
{"id": "2509.06269", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06269", "abs": "https://arxiv.org/abs/2509.06269", "authors": ["Vishal Raman", "Vijai Aravindh R", "Abhijith Ragav"], "title": "REMI: A Novel Causal Schema Memory Architecture for Personalized Lifestyle Recommendation Agents", "comment": "8 pages, 2 figures, Accepted at the OARS Workshop, KDD 2025, Paper\n  link: https://oars-workshop.github.io/papers/Raman2025.pdf", "summary": "Personalized AI assistants often struggle to incorporate complex personal\ndata and causal knowledge, leading to generic advice that lacks explanatory\npower. We propose REMI, a Causal Schema Memory architecture for a multimodal\nlifestyle agent that integrates a personal causal knowledge graph, a causal\nreasoning engine, and a schema based planning module. The idea is to deliver\nexplainable, personalized recommendations in domains like fashion, personal\nwellness, and lifestyle planning. Our architecture uses a personal causal graph\nof the user's life events and habits, performs goal directed causal traversals\nenriched with external knowledge and hypothetical reasoning, and retrieves\nadaptable plan schemas to generate tailored action plans. A Large Language\nModel orchestrates these components, producing answers with transparent causal\nexplanations. We outline the CSM system design and introduce new evaluation\nmetrics for personalization and explainability, including Personalization\nSalience Score and Causal Reasoning Accuracy, to rigorously assess its\nperformance. Results indicate that CSM based agents can provide more context\naware, user aligned recommendations compared to baseline LLM agents. This work\ndemonstrates a novel approach to memory augmented, causal reasoning in\npersonalized agents, advancing the development of transparent and trustworthy\nAI lifestyle assistants.", "AI": {"tldr": "REMI\u662f\u4e00\u4e2a\u57fa\u4e8e\u56e0\u679c\u6a21\u5f0f\u8bb0\u5fc6\u67b6\u6784\u7684\u591a\u6a21\u6001\u751f\u6d3b\u65b9\u5f0f\u52a9\u624b\uff0c\u901a\u8fc7\u6574\u5408\u4e2a\u4eba\u56e0\u679c\u77e5\u8bc6\u56fe\u8c31\u3001\u56e0\u679c\u63a8\u7406\u5f15\u64ce\u548c\u57fa\u4e8e\u6a21\u5f0f\u7684\u89c4\u5212\u6a21\u5757\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u4e2a\u6027\u5316\u63a8\u8350\u3002", "motivation": "\u73b0\u6709\u7684\u4e2a\u6027\u5316AI\u52a9\u624b\u96be\u4ee5\u6574\u5408\u590d\u6742\u7684\u4e2a\u4eba\u6570\u636e\u548c\u56e0\u679c\u77e5\u8bc6\uff0c\u5bfc\u81f4\u5efa\u8bae\u8fc7\u4e8e\u901a\u7528\u4e14\u7f3a\u4e4f\u89e3\u91ca\u6027\u3002", "method": "\u4f7f\u7528\u4e2a\u4eba\u56e0\u679c\u56fe\u8c31\u8bb0\u5f55\u7528\u6237\u751f\u6d3b\u4e8b\u4ef6\u548c\u4e60\u60ef\uff0c\u901a\u8fc7\u76ee\u6807\u5bfc\u5411\u7684\u56e0\u679c\u904d\u5386\u3001\u5916\u90e8\u77e5\u8bc6\u589e\u5f3a\u548c\u5047\u8bbe\u63a8\u7406\uff0c\u7ed3\u5408\u53ef\u9002\u5e94\u8ba1\u5212\u6a21\u5f0f\u751f\u6210\u5b9a\u5236\u5316\u884c\u52a8\u65b9\u6848\uff0c\u7531\u5927\u8bed\u8a00\u6a21\u578b\u534f\u8c03\u5404\u7ec4\u4ef6\u3002", "result": "\u57fa\u4e8eCSM\u7684\u667a\u80fd\u4f53\u76f8\u6bd4\u57fa\u51c6LLM\u667a\u80fd\u4f53\u80fd\u591f\u63d0\u4f9b\u66f4\u7b26\u5408\u4e0a\u4e0b\u6587\u3001\u66f4\u8d34\u8fd1\u7528\u6237\u7684\u63a8\u8350\u5efa\u8bae\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5728\u4e2a\u6027\u5316\u667a\u80fd\u4f53\u4e2d\u5b9e\u73b0\u8bb0\u5fc6\u589e\u5f3a\u548c\u56e0\u679c\u63a8\u7406\u7684\u65b0\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86\u900f\u660e\u53ef\u4fe1\u8d56\u7684AI\u751f\u6d3b\u65b9\u5f0f\u52a9\u624b\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.06278", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06278", "abs": "https://arxiv.org/abs/2509.06278", "authors": ["Chuang Jiang", "Mingyue Cheng", "Xiaoyu Tao", "Qingyang Mao", "Jie Ouyang", "Qi Liu"], "title": "TableMind: An Autonomous Programmatic Agent for Tool-Augmented Table Reasoning", "comment": "Comments: 10 pages, 6 figures. Submitted to WSDM 2026", "summary": "Table reasoning is crucial for leveraging structured data in domains such as\nfinance, healthcare, and scientific research. While large language models\n(LLMs) show promise in multi-step reasoning, purely text-based methods often\nstruggle with the complex numerical computations and fine-grained operations\ninherently required in this task. Tool-integrated reasoning improves\ncomputational accuracy via explicit code execution, yet existing systems\nfrequently rely on rigid patterns, supervised imitation, and lack true\nautonomous adaptability. In this paper, we present TableMind, an LLM-driven\ntable reasoning agent that (i) autonomously performs multi-turn tool\ninvocation, (ii) writes and executes data-analyzing code in a secure sandbox\nenvironment for data analysis and precise numerical reasoning, and (iii)\nexhibits high-level capabilities such as planning and self-reflection to adapt\nstrategies. To realize these capabilities, we adopt a two-stage fine-tuning\nparadigm built on top of a powerful pre-trained language model: supervised\nfine-tuning on high-quality reasoning trajectories to establish effective tool\nusage patterns, followed by reinforcement fine-tuning to optimize\nmulti-objective strategies. In particular, we propose Rank-Aware Policy\nOptimization (RAPO), which increases the update weight of high-quality\ntrajectories when their output probabilities are lower than those of\nlow-quality ones, thereby guiding the model more consistently toward better and\nmore accurate answers. Extensive experiments on several mainstream benchmarks\ndemonstrate that TableMind achieves superior performance compared to\ncompetitive baselines, yielding substantial gains in both reasoning accuracy\nand computational precision.", "AI": {"tldr": "TableMind\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8868\u683c\u63a8\u7406\u4ee3\u7406\uff0c\u901a\u8fc7\u81ea\u4e3b\u591a\u8f6e\u5de5\u5177\u8c03\u7528\u3001\u5b89\u5168\u6c99\u7bb1\u4ee3\u7801\u6267\u884c\u4ee5\u53ca\u89c4\u5212\u81ea\u53cd\u601d\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8868\u683c\u6570\u636e\u7684\u6570\u503c\u8ba1\u7b97\u7cbe\u5ea6\u548c\u63a8\u7406\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7eaf\u6587\u672c\u65b9\u6cd5\u5728\u590d\u6742\u6570\u503c\u8ba1\u7b97\u548c\u7ec6\u7c92\u5ea6\u64cd\u4f5c\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u5de5\u5177\u96c6\u6210\u63a8\u7406\u65b9\u6cd5\u53c8\u7f3a\u4e4f\u771f\u6b63\u7684\u81ea\u4e3b\u9002\u5e94\u6027\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u3001\u51c6\u786e\u7684\u8868\u683c\u63a8\u7406\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5fae\u8c03\u8303\u5f0f\uff1a\u5148\u5728\u9ad8\u8d28\u91cf\u63a8\u7406\u8f68\u8ff9\u4e0a\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u5efa\u7acb\u6709\u6548\u5de5\u5177\u4f7f\u7528\u6a21\u5f0f\uff0c\u7136\u540e\u901a\u8fc7\u5f3a\u5316\u5fae\u8c03\u4f18\u5316\u591a\u76ee\u6807\u7b56\u7565\uff0c\u7279\u522b\u63d0\u51fa\u4e86Rank-Aware Policy Optimization (RAPO)\u65b9\u6cd5\u3002", "result": "\u5728\u591a\u4e2a\u4e3b\u6d41\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTableMind\u76f8\u6bd4\u7ade\u4e89\u57fa\u7ebf\u53d6\u5f97\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u5728\u63a8\u7406\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u7cbe\u5ea6\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "TableMind\u901a\u8fc7\u81ea\u4e3b\u5de5\u5177\u8c03\u7528\u3001\u5b89\u5168\u4ee3\u7801\u6267\u884c\u548c\u9ad8\u7ea7\u89c4\u5212\u80fd\u529b\uff0c\u4e3a\u8868\u683c\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u3001\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u6570\u503c\u8ba1\u7b97\u5bc6\u96c6\u578b\u9886\u57df\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.06283", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.06283", "abs": "https://arxiv.org/abs/2509.06283", "authors": ["Xuan-Phi Nguyen", "Shrey Pandit", "Revanth Gangi Reddy", "Austin Xu", "Silvio Savarese", "Caiming Xiong", "Shafiq Joty"], "title": "SFR-DeepResearch: Towards Effective Reinforcement Learning for Autonomously Reasoning Single Agents", "comment": "Technical Report", "summary": "Equipping large language models (LLMs) with complex, interleaved reasoning\nand tool-use capabilities has become a key focus in agentic AI research,\nespecially with recent advances in reasoning-oriented (``thinking'') models.\nSuch capabilities are key to unlocking a number of important applications. One\nsuch application is Deep Research (DR), which requires extensive search and\nreasoning over many sources. Our work in this paper focuses on the development\nof native Autonomous Single-Agent models for DR featuring minimal web crawling\nand Python tool integration. Unlike multi-agent systems, where agents take up\npre-defined roles and are told what to do at each step in a static workflow, an\nautonomous single-agent determines its next action dynamically based on\ncontext, without manual directive. While prior work has proposed training\nrecipes for base or instruction-tuned LLMs, we focus on continual reinforcement\nlearning (RL) of reasoning-optimized models to further enhance agentic skills\nwhile preserving reasoning ability. Towards this end, we propose a simple RL\nrecipe with entirely synthetic data, which we apply to various open-source\nLLMs. Our best variant SFR-DR-20B achieves up to 28.7% on Humanity's Last Exam\nbenchmark. In addition, we conduct key analysis experiments to provide more\ninsights into our methodologies.", "AI": {"tldr": "\u901a\u8fc7\u63a7\u5236\u6027\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7406\u6027\u4f18\u5316\u6a21\u578b\uff0c\u53d1\u5c55\u81ea\u4e3b\u5355\u4ee3\u7406\u6df1\u5ea6\u7814\u7a76\u80fd\u529b\uff0c\u5728Humanity's Last Exam\u6d4b\u8bd5\u4e2d\u8fbe\u523028.7%\u6027\u80fd", "motivation": "\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5f00\u53d1\u590d\u6742\u7684\u7406\u6027\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u6df1\u5ea6\u7814\u7a76\u5e94\u7528\u4e2d\u5b9e\u73b0\u81ea\u4e3b\u52a8\u6001\u51b3\u7b56\uff0c\u800c\u975e\u4f9d\u8d56\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u9759\u6001\u5de5\u4f5c\u6d41", "method": "\u91c7\u7528\u63a7\u5236\u6027\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u4f7f\u7528\u5168\u5408\u6210\u6570\u636e\u8bad\u7ec3\u7406\u6027\u4f18\u5316\u6a21\u578b\uff0c\u96c6\u6210\u6700\u5c0f\u5316\u7f51\u7edc\u722c\u866b\u548cPython\u5de5\u5177", "result": "\u6700\u4f73\u6a21\u578bSFR-DR-20B\u5728Humanity's Last Exam\u6d4b\u8bd5\u4e2d\u8fbe\u523028.7%\u7684\u6027\u80fd\u6c34\u5e73", "conclusion": "\u901a\u8fc7\u63a7\u5236\u6027RL\u8bad\u7ec3\u7406\u6027\u4f18\u5316\u6a21\u578b\u53ef\u6709\u6548\u63d0\u5347\u81ea\u4e3b\u5355\u4ee3\u7406\u7684\u6df1\u5ea6\u7814\u7a76\u80fd\u529b\uff0c\u4e3a\u4ee3\u7406\u667a\u80fd\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411"}}
{"id": "2509.06284", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06284", "abs": "https://arxiv.org/abs/2509.06284", "authors": ["Jiaxiang Chen", "Zhuo Wang", "Mingxi Zou", "Zhucong Li", "Zhijian Zhou", "Song Wang", "Zenglin Xu"], "title": "From Implicit Exploration to Structured Reasoning: Leveraging Guideline and Refinement for LLMs", "comment": null, "summary": "Large language models (LLMs) have advanced general-purpose reasoning, showing\nstrong performance across diverse tasks. However, existing methods often rely\non implicit exploration, where the model follows stochastic and unguided\nreasoning paths-like walking without a map. This leads to unstable reasoning\npaths, lack of error correction, and limited learning from past experience. To\naddress these issues, we propose a framework that shifts from implicit\nexploration to structured reasoning through guideline and refinement. First, we\nextract structured reasoning patterns from successful trajectories and\nreflective signals from failures. During inference, the model follows these\nguidelines step-by-step, with refinement applied after each step to correct\nerrors and stabilize the reasoning process. Experiments on BBH and four\nadditional benchmarks (GSM8K, MATH-500, MBPP, HumanEval) show that our method\nconsistently outperforms strong baselines across diverse reasoning tasks.\nStructured reasoning with stepwise execution and refinement improves stability\nand generalization, while guidelines transfer well across domains and flexibly\nsupport cross-model collaboration, matching or surpassing supervised\nfine-tuning in effectiveness and scalability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ece\u9690\u5f0f\u63a2\u7d22\u8f6c\u5411\u7ed3\u6784\u5316\u63a8\u7406\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6307\u5bfc\u539f\u5219\u548c\u7cbe\u70bc\u673a\u5236\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u7a33\u5b9a\u6027\u3001\u9519\u8bef\u7ea0\u6b63\u80fd\u529b\u548c\u5b66\u4e60\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u65b9\u6cd5\u4f9d\u8d56\u9690\u5f0f\u63a2\u7d22\uff0c\u5bfc\u81f4\u63a8\u7406\u8def\u5f84\u4e0d\u7a33\u5b9a\u3001\u7f3a\u4e4f\u9519\u8bef\u7ea0\u6b63\u673a\u5236\uff0c\u4e14\u65e0\u6cd5\u6709\u6548\u4ece\u8fc7\u5f80\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u3002", "method": "\u4ece\u6210\u529f\u8f68\u8ff9\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u63a8\u7406\u6a21\u5f0f\uff0c\u4ece\u5931\u8d25\u4e2d\u83b7\u53d6\u53cd\u601d\u4fe1\u53f7\uff1b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u9010\u6b65\u9075\u5faa\u6307\u5bfc\u539f\u5219\uff0c\u5e76\u5728\u6bcf\u4e00\u6b65\u540e\u5e94\u7528\u7cbe\u70bc\u6765\u7ea0\u6b63\u9519\u8bef\u548c\u7a33\u5b9a\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5728BBH\u548c\u5176\u4ed6\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08GSM8K\u3001MATH-500\u3001MBPP\u3001HumanEval\uff09\u4e0a\u4e00\u81f4\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5728\u591a\u6837\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u7ed3\u6784\u5316\u63a8\u7406\u7ed3\u5408\u9010\u6b65\u6267\u884c\u548c\u7cbe\u70bc\u63d0\u9ad8\u4e86\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u6307\u5bfc\u539f\u5219\u8de8\u57df\u8fc1\u79fb\u826f\u597d\uff0c\u652f\u6301\u8de8\u6a21\u578b\u534f\u4f5c\uff0c\u5728\u6548\u679c\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u5339\u914d\u6216\u8d85\u8d8a\u76d1\u7763\u5fae\u8c03\u3002"}}
{"id": "2509.06307", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06307", "abs": "https://arxiv.org/abs/2509.06307", "authors": ["Lei Shu", "Dong Zhao"], "title": "Can AI Make Energy Retrofit Decisions? An Evaluation of Large Language Models", "comment": null, "summary": "Conventional approaches to building energy retrofit decision making suffer\nfrom limited generalizability and low interpretability, hindering adoption in\ndiverse residential contexts. With the growth of Smart and Connected\nCommunities, generative AI, especially large language models (LLMs), may help\nby processing contextual information and producing practitioner readable\nrecommendations. We evaluate seven LLMs (ChatGPT, DeepSeek, Gemini, Grok,\nLlama, and Claude) on residential retrofit decisions under two objectives:\nmaximizing CO2 reduction (technical) and minimizing payback period\n(sociotechnical). Performance is assessed on four dimensions: accuracy,\nconsistency, sensitivity, and reasoning, using a dataset of 400 homes across 49\nUS states. LLMs generate effective recommendations in many cases, reaching up\nto 54.5 percent top 1 match and 92.8 percent within top 5 without fine tuning.\nPerformance is stronger for the technical objective, while sociotechnical\ndecisions are limited by economic trade offs and local context. Agreement\nacross models is low, and higher performing models tend to diverge from others.\nLLMs are sensitive to location and building geometry but less sensitive to\ntechnology and occupant behavior. Most models show step by step, engineering\nstyle reasoning, but it is often simplified and lacks deeper contextual\nawareness. Overall, LLMs are promising assistants for energy retrofit decision\nmaking, but improvements in accuracy, consistency, and context handling are\nneeded for reliable practice.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4f\u5b85\u80fd\u6e90\u7eff\u5316\u6539\u9020\u51b3\u7b56\u4e2d\u8868\u73b0\u6709\u6f5c\u529b\uff0c\u5728\u6280\u672f\u76ee\u6807\u4e0b\u6548\u679c\u66f4\u597d\uff0c\u4f46\u9700\u8981\u63d0\u9ad8\u51c6\u786e\u6027\u3001\u4e00\u81f4\u6027\u548c\u4e0a\u4e0b\u6587\u5904\u7406\u80fd\u529b", "motivation": "\u4f20\u7edf\u80fd\u6e90\u6539\u9020\u51b3\u7b56\u65b9\u6cd5\u5b58\u5728\u666e\u904d\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u667a\u80fd\u8fde\u63a5\u793e\u533a\u548c\u751f\u6210\u5f0fAI\u7684\u53d1\u5c55\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a", "method": "\u8bc4\u4f30\u4e03\u79cd\u5927\u8bed\u8a00\u6a21\u578b(ChatGPT\u3001DeepSeek\u3001Gemini\u3001Grok\u3001Llama\u3001Claude)\u5728\u4e24\u79cd\u76ee\u6807\u4e0b\u7684\u8868\u73b0\uff1a\u6700\u5927\u5316CO2\u51cf\u6392(\u6280\u672f)\u548c\u6700\u5c0f\u5316\u56de\u62a5\u671f(\u793e\u4f1a\u6280\u672f)\uff0c\u4f7f\u752849\u4e2a\u7f8e\u56fd\u5dde400\u623f\u5c4b\u7684\u6570\u636e\u96c6\uff0c\u4ece\u51c6\u786e\u6027\u3001\u4e00\u81f4\u6027\u3001\u654f\u611f\u6027\u548c\u63a8\u7406\u80fd\u529b\u56db\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u5206\u6790", "result": "LLM\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u80fd\u751f\u6210\u6709\u6548\u5efa\u8bae\uff0c\u5728\u4e0d\u7ec6\u8c03\u7684\u60c5\u51b5\u4e0b\u9876\u90e81\u5339\u914d\u7387\u8fbe54.5%\uff0c\u524d5\u5339\u914d\u738792.8%\u3002\u6280\u672f\u76ee\u6807\u4e0b\u8868\u73b0\u66f4\u597d\uff0c\u793e\u4f1a\u6280\u672f\u51b3\u7b56\u53d7\u5230\u7ecf\u6d4e\u7279\u6027\u548c\u5730\u65b9\u4e0a\u4e0b\u6587\u9650\u5236\u3002\u6a21\u578b\u95f4\u4e00\u81f4\u6027\u4f4e\uff0c\u9ad8\u6027\u80fd\u6a21\u578b\u504f\u79bb\u5176\u4ed6\u6a21\u578b\u3002LLM\u5bf9\u4f4d\u7f6e\u548c\u5efa\u7b51\u5f62\u72b6\u654f\u611f\uff0c\u5bf9\u6280\u672f\u548c\u4f4f\u6237\u884c\u4e3a\u654f\u611f\u6027\u8f83\u4f4e", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u80fd\u6e90\u6539\u9020\u51b3\u7b56\u4e2d\u5c55\u73b0\u51fa\u4e86\u4f5c\u4e3a\u52a9\u624b\u5de5\u5177\u7684\u6f5c\u529b\uff0c\u4f46\u8981\u5b9e\u73b0\u53ef\u9760\u5e94\u7528\uff0c\u8fd8\u9700\u8981\u5728\u51c6\u786e\u6027\u3001\u4e00\u81f4\u6027\u548c\u4e0a\u4e0b\u6587\u5904\u7406\u65b9\u9762\u8fdb\u4e00\u6b65\u6539\u8fdb"}}
{"id": "2509.06337", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06337", "abs": "https://arxiv.org/abs/2509.06337", "authors": ["Jianpeng Zhao", "Chenyu Yuan", "Weiming Luo", "Haoling Xie", "Guangwei Zhang", "Steven Jige Quan", "Zixuan Yuan", "Pengyang Wang", "Denghui Zhang"], "title": "Large Language Models as Virtual Survey Respondents: Evaluating Sociodemographic Response Generation", "comment": null, "summary": "Questionnaire-based surveys are foundational to social science research and\npublic policymaking, yet traditional survey methods remain costly,\ntime-consuming, and often limited in scale. This paper explores a new paradigm:\nsimulating virtual survey respondents using Large Language Models (LLMs). We\nintroduce two novel simulation settings, namely Partial Attribute Simulation\n(PAS) and Full Attribute Simulation (FAS), to systematically evaluate the\nability of LLMs to generate accurate and demographically coherent responses. In\nPAS, the model predicts missing attributes based on partial respondent\nprofiles, whereas FAS involves generating complete synthetic datasets under\nboth zero-context and context-enhanced conditions. We curate a comprehensive\nbenchmark suite, LLM-S^3 (Large Language Model-based Sociodemographic Survey\nSimulation), that spans 11 real-world public datasets across four sociological\ndomains. Our evaluation of multiple mainstream LLMs (GPT-3.5/4 Turbo, LLaMA\n3.0/3.1-8B) reveals consistent trends in prediction performance, highlights\nfailure modes, and demonstrates how context and prompt design impact simulation\nfidelity. This work establishes a rigorous foundation for LLM-driven survey\nsimulations, offering scalable and cost-effective tools for sociological\nresearch and policy evaluation. Our code and dataset are available at:\nhttps://github.com/dart-lab-research/LLM-S-Cube-Benchmark", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u865a\u62df\u8c03\u67e5\u53d7\u8bbf\u8005\u7684\u65b0\u8303\u5f0f\uff0c\u63d0\u51fa\u4e86PAS\u548cFAS\u4e24\u79cd\u6a21\u62df\u8bbe\u7f6e\uff0c\u5e76\u6784\u5efa\u4e86LLM-S^3\u57fa\u51c6\u5957\u4ef6\u6765\u8bc4\u4f30LLM\u5728\u751f\u6210\u51c6\u786e\u4eba\u53e3\u7edf\u8ba1\u54cd\u5e94\u65b9\u9762\u7684\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u95ee\u5377\u8c03\u67e5\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u8017\u65f6\u957f\u4e14\u89c4\u6a21\u6709\u9650\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\u6765\u652f\u6301\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u548c\u653f\u7b56\u5236\u5b9a\u3002", "method": "\u63d0\u51fa\u4e86Partial Attribute Simulation (PAS)\u548cFull Attribute Simulation (FAS)\u4e24\u79cd\u6a21\u62df\u8bbe\u7f6e\uff0c\u4f7f\u7528GPT-3.5/4 Turbo\u3001LLaMA 3.0/3.1-8B\u7b49\u4e3b\u6d41LLM\uff0c\u572811\u4e2a\u771f\u5b9e\u4e16\u754c\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u9884\u6d4b\u6027\u80fd\u7684\u4e00\u81f4\u8d8b\u52bf\uff0c\u8bc6\u522b\u4e86\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u8bc1\u660e\u4e86\u4e0a\u4e0b\u6587\u548c\u63d0\u793a\u8bbe\u8ba1\u5bf9\u6a21\u62df\u4fdd\u771f\u5ea6\u7684\u5f71\u54cd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3aLLM\u9a71\u52a8\u7684\u8c03\u67e5\u6a21\u62df\u5960\u5b9a\u4e86\u4e25\u683c\u57fa\u7840\uff0c\u4e3a\u793e\u4f1a\u5b66\u7814\u7a76\u548c\u653f\u7b56\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2509.06341", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06341", "abs": "https://arxiv.org/abs/2509.06341", "authors": ["Issue Yishu Wang", "Kakam Chong", "Xiaofeng Wang", "Xu Yan", "DeXin Kong", "Chen Ju", "Ming Chen", "Shuai Xiao", "Shuguang Han", "jufeng chen"], "title": "Evaluating Multi-Turn Bargain Skills in LLM-Based Seller Agent", "comment": null, "summary": "In online second-hand marketplaces, multi-turn bargaining is a crucial part\nof seller-buyer interactions. Large Language Models (LLMs) can act as seller\nagents, negotiating with buyers on behalf of sellers under given business\nconstraints. A critical ability for such agents is to track and accurately\ninterpret cumulative buyer intents across long negotiations, which directly\nimpacts bargaining effectiveness. We introduce a multi-turn evaluation\nframework for measuring the bargaining ability of seller agents in e-commerce\ndialogues. The framework tests whether an agent can extract and track buyer\nintents. Our contributions are: (1) a large-scale e-commerce bargaining\nbenchmark spanning 622 categories, 9,892 products, and 3,014 tasks; (2) a\nturn-level evaluation framework grounded in Theory of Mind (ToM) with annotated\nbuyer intents, moving beyond outcome-only metrics; and (3) an automated\npipeline that extracts reliable intent from massive dialogue data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5fc3\u7406\u7406\u8bba\u7684\u591a\u8f6e\u7535\u5b50\u5546\u52a1\u8bae\u4ef7\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u6d4b\u8bd5\u5356\u5bb6\u4ee3\u7406\u5728\u957f\u671f\u8c08\u5224\u4e2d\u63d0\u53d6\u548c\u8ddf\u8e2a\u4e70\u5bb6\u610f\u56fe\u7684\u80fd\u529b\uff0c\u5e76\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u57fa\u51c6\u6570\u636e\u96c6\u3002", "motivation": "\u5728\u7ebf\u4e8c\u624b\u5e02\u573a\u4e2d\uff0c\u591a\u8f6e\u8bae\u4ef7\u662f\u4e70\u5356\u53cc\u65b9\u4e92\u52a8\u7684\u5173\u952e\u73af\u8282\u3002LLM\u4f5c\u4e3a\u5356\u5bb6\u4ee3\u7406\u9700\u8981\u51c6\u786e\u7406\u89e3\u548c\u8ddf\u8e2a\u4e70\u5bb6\u5728\u957f\u671f\u8c08\u5224\u4e2d\u7684\u7d2f\u79ef\u610f\u56fe\uff0c\u8fd9\u5bf9\u8bae\u4ef7\u6548\u679c\u81f3\u5173\u91cd\u8981\u3002", "method": "1) \u6784\u5efa\u5927\u89c4\u6a21\u7535\u5b50\u5546\u52a1\u8bae\u4ef7\u57fa\u51c6\u6570\u636e\u96c6\uff08622\u4e2a\u7c7b\u522b\uff0c9,892\u4e2a\u4ea7\u54c1\uff0c3,014\u4e2a\u4efb\u52a1\uff09\uff1b2) \u5f00\u53d1\u57fa\u4e8e\u5fc3\u7406\u7406\u8bba\u7684\u8f6e\u7ea7\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u6807\u6ce8\u7684\u4e70\u5bb6\u610f\u56fe\uff1b3) \u5efa\u7acb\u4ece\u6d77\u91cf\u5bf9\u8bdd\u6570\u636e\u4e2d\u63d0\u53d6\u53ef\u9760\u610f\u56fe\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8d85\u8d8a\u4ec5\u7ed3\u679c\u6307\u6807\u7684\u591a\u8f6e\u8bae\u4ef7\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u6d4b\u8bd5\u5356\u5bb6\u4ee3\u7406\u7684\u610f\u56fe\u7406\u89e3\u548c\u8ddf\u8e2a\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7535\u5b50\u5546\u52a1\u8bae\u4ef7\u5bf9\u8bdd\u4e2d\u7684\u5356\u5bb6\u4ee3\u7406\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u6846\u67b6\u548c\u65b9\u6cd5\uff0c\u7279\u522b\u5f3a\u8c03\u4e86\u610f\u56fe\u8ddf\u8e2a\u5728\u591a\u8f6e\u8c08\u5224\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.06355", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06355", "abs": "https://arxiv.org/abs/2509.06355", "authors": ["Yunzhe Wang", "Volkan Ustun", "Chris McGroarty"], "title": "A data-driven discretized CS:GO simulation environment to facilitate strategic multi-agent planning research", "comment": "Accepted at the Winter Simulation Conference 2025, December, Seattle\n  USA", "summary": "Modern simulation environments for complex multi-agent interactions must\nbalance high-fidelity detail with computational efficiency. We present DECOY, a\nnovel multi-agent simulator that abstracts strategic, long-horizon planning in\n3D terrains into high-level discretized simulation while preserving low-level\nenvironmental fidelity. Using Counter-Strike: Global Offensive (CS:GO) as a\ntestbed, our framework accurately simulates gameplay using only movement\ndecisions as tactical positioning -- without explicitly modeling low-level\nmechanics such as aiming and shooting. Central to our approach is a waypoint\nsystem that simplifies and discretizes continuous states and actions, paired\nwith neural predictive and generative models trained on real CS:GO tournament\ndata to reconstruct event outcomes. Extensive evaluations show that replays\ngenerated from human data in DECOY closely match those observed in the original\ngame. Our publicly available simulation environment provides a valuable tool\nfor advancing research in strategic multi-agent planning and behavior\ngeneration.", "AI": {"tldr": "DECOY\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u667a\u80fd\u4f53\u6a21\u62df\u5668\uff0c\u5c063D\u5730\u5f62\u4e2d\u7684\u6218\u7565\u957f\u671f\u89c4\u5212\u62bd\u8c61\u4e3a\u9ad8\u7ea7\u79bb\u6563\u5316\u6a21\u62df\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u7ea7\u73af\u5883\u4fdd\u771f\u5ea6\u3002\u4f7f\u7528CS:GO\u4f5c\u4e3a\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4ec5\u901a\u8fc7\u79fb\u52a8\u51b3\u7b56\u6765\u51c6\u786e\u6a21\u62df\u6e38\u620f\u73a9\u6cd5\u3002", "motivation": "\u73b0\u4ee3\u590d\u6742\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u6a21\u62df\u73af\u5883\u9700\u8981\u5728\u9ad8\u5ea6\u4fdd\u771f\u7ec6\u8282\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u4fdd\u6301\u73af\u5883\u771f\u5b9e\u6027\u53c8\u80fd\u9ad8\u6548\u8fd0\u884c\u7684\u6a21\u62df\u5668\u6765\u63a8\u8fdb\u6218\u7565\u591a\u667a\u80fd\u4f53\u89c4\u5212\u7814\u7a76\u3002", "method": "\u91c7\u7528\u8def\u5f84\u70b9\u7cfb\u7edf\u7b80\u5316\u548c\u79bb\u6563\u5316\u8fde\u7eed\u72b6\u6001\u548c\u52a8\u4f5c\uff0c\u914d\u5408\u57fa\u4e8e\u771f\u5b9eCS:GO\u6bd4\u8d5b\u6570\u636e\u8bad\u7ec3\u7684\u795e\u7ecf\u9884\u6d4b\u548c\u751f\u6210\u6a21\u578b\u6765\u91cd\u5efa\u4e8b\u4ef6\u7ed3\u679c\u3002\u4ec5\u4f7f\u7528\u79fb\u52a8\u51b3\u7b56\u4f5c\u4e3a\u6218\u672f\u5b9a\u4f4d\uff0c\u4e0d\u663e\u5f0f\u5efa\u6a21\u4f4e\u7ea7\u673a\u5236\u5982\u7784\u51c6\u548c\u5c04\u51fb\u3002", "result": "\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0c\u4ece\u4eba\u7c7b\u6570\u636e\u751f\u6210\u7684DECOY\u56de\u653e\u4e0e\u539f\u59cb\u6e38\u620f\u4e2d\u89c2\u5bdf\u5230\u7684\u56de\u653e\u9ad8\u5ea6\u5339\u914d\u3002\u6a21\u62df\u73af\u5883\u80fd\u591f\u51c6\u786e\u91cd\u73b0\u6e38\u620f\u73a9\u6cd5\u3002", "conclusion": "DECOY\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u4ef7\u503c\u7684\u5de5\u5177\uff0c\u53ef\u7528\u4e8e\u63a8\u8fdb\u6218\u7565\u591a\u667a\u80fd\u4f53\u89c4\u5212\u548c\u884c\u4e3a\u751f\u6210\u7684\u7814\u7a76\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u5ea6\u7684\u6a21\u62df\u3002"}}
{"id": "2509.06409", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06409", "abs": "https://arxiv.org/abs/2509.06409", "authors": ["Yihong Luo", "Wenwu He", "Zhuo-Xu Cui", "Dong Liang"], "title": "Teaching AI Stepwise Diagnostic Reasoning with Report-Guided Chain-of-Thought Learning", "comment": null, "summary": "This study presents DiagCoT, a multi-stage framework that applies supervised\nfine-tuning to general-purpose vision-language models (VLMs) to emulate\nradiologists' stepwise diagnostic reasoning using only free-text reports.\nDiagCoT combines contrastive image-report tuning for domain alignment,\nchain-of-thought supervision to capture inferential logic, and reinforcement\ntuning with clinical reward signals to enhance factual accuracy and fluency. On\nthe MIMIC-CXR benchmark, DiagCoT improved zero-shot disease classification AUC\nfrom 0.52 to 0.76 (absolute gain of 0.24), pathology grounding mIoU from 0.08\nto 0.31 (absolute gain of 0.23), and report generation BLEU from 0.11 to 0.33\n(absolute gain of 0.22). It outperformed state-of-the-art models including\nLLaVA-Med and CXR-LLAVA on long-tailed diseases and external datasets. By\nconverting unstructured clinical narratives into structured supervision,\nDiagCoT offers a scalable approach for developing interpretable and\ndiagnostically competent AI systems for radiology.", "AI": {"tldr": "DiagCoT\u662f\u4e00\u4e2a\u591a\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u901a\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u4ec5\u4f7f\u7528\u81ea\u7531\u6587\u672c\u62a5\u544a\u6a21\u62df\u653e\u5c04\u79d1\u533b\u751f\u7684\u9010\u6b65\u8bca\u65ad\u63a8\u7406\uff0c\u5728\u75be\u75c5\u5206\u7c7b\u3001\u75c5\u7406\u5b9a\u4f4d\u548c\u62a5\u544a\u751f\u6210\u65b9\u9762\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5f00\u53d1\u53ef\u89e3\u91ca\u4e14\u5177\u5907\u8bca\u65ad\u80fd\u529b\u7684AI\u7cfb\u7edf\uff0c\u901a\u8fc7\u5229\u7528\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u53d9\u8ff0\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\uff0c\u6a21\u62df\u653e\u5c04\u79d1\u533b\u751f\u7684\u9010\u6b65\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u7ed3\u5408\u5bf9\u6bd4\u56fe\u50cf-\u62a5\u544a\u8c03\u4f18\u8fdb\u884c\u9886\u57df\u5bf9\u9f50\uff0c\u4f7f\u7528\u601d\u7ef4\u94fe\u76d1\u7763\u6355\u83b7\u63a8\u7406\u903b\u8f91\uff0c\u5e76\u901a\u8fc7\u4e34\u5e8a\u5956\u52b1\u4fe1\u53f7\u8fdb\u884c\u5f3a\u5316\u8c03\u4f18\u4ee5\u63d0\u9ad8\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u6d41\u7545\u6027\u3002", "result": "\u5728MIMIC-CXR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u96f6\u6837\u672c\u75be\u75c5\u5206\u7c7bAUC\u4ece0.52\u63d0\u5347\u81f30.76\uff0c\u75c5\u7406\u5b9a\u4f4dmIoU\u4ece0.08\u63d0\u5347\u81f30.31\uff0c\u62a5\u544a\u751f\u6210BLEU\u4ece0.11\u63d0\u5347\u81f30.33\uff0c\u5728\u957f\u5c3e\u75be\u75c5\u548c\u5916\u90e8\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u6a21\u578b\u3002", "conclusion": "DiagCoT\u901a\u8fc7\u5c06\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u53d9\u8ff0\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u76d1\u7763\uff0c\u4e3a\u5f00\u53d1\u53ef\u89e3\u91ca\u4e14\u5177\u5907\u8bca\u65ad\u80fd\u529b\u7684\u653e\u5c04\u5b66AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002"}}
{"id": "2509.06436", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06436", "abs": "https://arxiv.org/abs/2509.06436", "authors": ["Song Yu", "Xiaofei Xu", "Ke Deng", "Li Li", "Lin Tian"], "title": "Tree of Agents: Improving Long-Context Capabilities of Large Language Models through Multi-Perspective Reasoning", "comment": "19 pages, 5 figures", "summary": "Large language models (LLMs) face persistent challenges when handling\nlong-context tasks, most notably the lost in the middle issue, where\ninformation located in the middle of a long input tends to be underutilized.\nSome existing methods that reduce input have the risk of discarding key\ninformation, while others that extend context windows often lead to attention\ndispersion. To address these limitations, we propose Tree of Agents (TOA), a\nmulti-agent reasoning framework that segments the input into chunks processed\nby independent agents. Each agent generates its local cognition, then agents\ndynamically exchange information for collaborative reasoning along\ntree-structured paths. TOA enables agents to probe different reasoning orders\nfor multi-perspective understanding, effectively mitigating position bias and\nreducing hallucinations. To improve processing efficiency, we incorporate\nprefix-hash caching and adaptive pruning strategies, achieving significant\nperformance improvements with comparable API overhead. Experiments show that\nTOA, powered by compact LLaMA3.1-8B, significantly outperforms multiple\nbaselines and demonstrates comparable performance to the latest and much larger\ncommercial models, such as Gemini1.5-pro, on various long-context tasks. Code\nis available at https://github.com/Aireduce952/Tree-of-Agents.", "AI": {"tldr": "\u57fa\u4e8e\u591a\u6c14\u7ec4\u6811\u72b6\u7ed3\u6784\u7684\u534f\u4f5c\u63a8\u7406\u6846\u67b6TOA\uff0c\u901a\u8fc7\u5206\u5757\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u8f93\u5165\uff0c\u52a8\u6001\u4ea4\u6362\u4fe1\u606f\uff0c\u6709\u6548\u89e3\u51b3LLM\u5728\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u7684\"\u4e2d\u95f4\u4fe1\u606f\u6f0f\u5931\"\u95ee\u9898", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u5b58\u5728\u7684\"\u4e2d\u95f4\u4fe1\u606f\u6f0f\u5931\"\u95ee\u9898\uff0c\u907f\u514d\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u5173\u952e\u4fe1\u606f\u4e22\u5f03\u6216\u6ce8\u610f\u529b\u5206\u6563\u95ee\u9898", "method": "\u63d0\u51fa\u6811\u72b6\u6c14\u7ec4(TOA)\u6846\u67b6\uff0c\u5c06\u8f93\u5165\u5206\u6210\u5757\u7531\u72ec\u7acb\u6c14\u7ec4\u5904\u7406\uff0c\u6bcf\u4e2a\u6c14\u7ec4\u751f\u6210\u5c40\u90e8\u8ba4\u77e5\uff0c\u7136\u540e\u6cbf\u6811\u72b6\u7ed3\u6784\u52a8\u6001\u4ea4\u6362\u4fe1\u606f\u8fdb\u884c\u534f\u4f5c\u63a8\u7406\uff0c\u4f7f\u7528\u524d\u7f00\u54c8\u5e0c\u7f13\u5b58\u548c\u9002\u5e94\u6027\u526a\u679d\u7b56\u7565\u63d0\u9ad8\u6548\u7387", "result": "\u57fa\u4e8eLLaMA3.1-8B\u7684TOA\u5728\u5404\u79cd\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e0a\u663e\u8457\u8d85\u8fc7\u591a\u4e2a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e0eGemini1.5-pro\u7b49\u66f4\u5927\u7684\u5546\u4e1a\u6a21\u578b\u5f97\u5230\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684API\u5f00\u9500", "conclusion": "TOA\u6846\u67b6\u901a\u8fc7\u591a\u6c14\u7ec4\u534f\u4f5c\u63a8\u7406\u6709\u6548\u51cf\u8f7b\u4f4d\u7f6e\u504f\u5dee\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u80fd\u529b"}}
{"id": "2509.06444", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06444", "abs": "https://arxiv.org/abs/2509.06444", "authors": ["Cheng Qian", "Hainan Zhang", "Yongxin Tong", "Hong-Wei Zheng", "Zhiming Zheng"], "title": "HyFedRAG: A Federated Retrieval-Augmented Generation Framework for Heterogeneous and Privacy-Sensitive Data", "comment": "9 pages, 7 figures", "summary": "Centralized RAG pipelines struggle with heterogeneous and privacy-sensitive\ndata, especially in distributed healthcare settings where patient data spans\nSQL, knowledge graphs, and clinical notes. Clinicians face difficulties\nretrieving rare disease cases due to privacy constraints and the limitations of\ntraditional cloud-based RAG systems in handling diverse formats and edge\ndevices. To address this, we introduce HyFedRAG, a unified and efficient\nFederated RAG framework tailored for Hybrid data modalities. By leveraging an\nedge-cloud collaborative mechanism, HyFedRAG enables RAG to operate across\ndiverse data sources while preserving data privacy. Our key contributions are:\n(1) We design an edge-cloud collaborative RAG framework built on Flower, which\nsupports querying structured SQL data, semi-structured knowledge graphs, and\nunstructured documents. The edge-side LLMs convert diverse data into\nstandardized privacy-preserving representations, and the server-side LLMs\nintegrates them for global reasoning and generation. (2) We integrate\nlightweight local retrievers with privacy-aware LLMs and provide three\nanonymization tools that enable each client to produce semantically rich,\nde-identified summaries for global inference across devices. (3) To optimize\nresponse latency and reduce redundant computation, we design a three-tier\ncaching strategy consisting of local cache, intermediate representation cache,\nand cloud inference cache. Experimental results on PMC-Patients demonstrate\nthat HyFedRAG outperforms existing baselines in terms of retrieval quality,\ngeneration consistency, and system efficiency. Our framework offers a scalable\nand privacy-compliant solution for RAG over structural-heterogeneous data,\nunlocking the potential of LLMs in sensitive and diverse data environments.", "AI": {"tldr": "HyFedRAG\u662f\u4e00\u4e2a\u8054\u90a6RAG\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u533b\u7597\u9886\u57df\u5f02\u6784\u9690\u79c1\u6570\u636e\uff0c\u901a\u8fc7\u8fb9\u7f18-\u4e91\u534f\u4f5c\u673a\u5236\u652f\u6301SQL\u3001\u77e5\u8bc6\u56fe\u8c31\u548c\u6587\u6863\u7b49\u591a\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u63d0\u5347\u68c0\u7d22\u8d28\u91cf\u548c\u7cfb\u7edf\u6548\u7387\u3002", "motivation": "\u96c6\u4e2d\u5f0fRAG\u7cfb\u7edf\u5728\u5904\u7406\u5f02\u6784\u548c\u9690\u79c1\u654f\u611f\u7684\u533b\u7597\u6570\u636e\u65f6\u9762\u4e34\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u5206\u5e03\u5f0f\u533b\u7597\u73af\u5883\u4e2d\uff0c\u60a3\u8005\u6570\u636e\u5206\u6563\u5728SQL\u3001\u77e5\u8bc6\u56fe\u8c31\u548c\u4e34\u5e8a\u7b14\u8bb0\u7b49\u591a\u79cd\u683c\u5f0f\u4e2d\uff0c\u4e14\u5b58\u5728\u9690\u79c1\u7ea6\u675f\u548c\u8fb9\u7f18\u8bbe\u5907\u5904\u7406\u80fd\u529b\u9650\u5236\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8eFlower\u7684\u8fb9\u7f18-\u4e91\u534f\u4f5cRAG\u6846\u67b6\uff0c\u4f7f\u7528\u8fb9\u7f18\u7aefLLM\u5c06\u5f02\u6784\u6570\u636e\u8f6c\u6362\u4e3a\u6807\u51c6\u5316\u9690\u79c1\u4fdd\u62a4\u8868\u793a\uff0c\u670d\u52a1\u5668\u7aefLLM\u8fdb\u884c\u5168\u5c40\u63a8\u7406\uff1b\u96c6\u6210\u8f7b\u91cf\u7ea7\u672c\u5730\u68c0\u7d22\u5668\u548c\u9690\u79c1\u611f\u77e5LLM\uff0c\u63d0\u4f9b\u4e09\u79cd\u533f\u540d\u5316\u5de5\u5177\uff1b\u8bbe\u8ba1\u4e09\u5c42\u7f13\u5b58\u7b56\u7565\u4f18\u5316\u5ef6\u8fdf\u548c\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5728PMC-Patients\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cHyFedRAG\u5728\u68c0\u7d22\u8d28\u91cf\u3001\u751f\u6210\u4e00\u81f4\u6027\u548c\u7cfb\u7edf\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7ed3\u6784\u5316\u5f02\u6784\u6570\u636e\u4e0a\u7684RAG\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u7b26\u5408\u9690\u79c1\u8981\u6c42\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u654f\u611f\u548c\u591a\u6837\u5316\u6570\u636e\u73af\u5883\u4e2d\u91ca\u653e\u4e86LLMs\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.06463", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06463", "abs": "https://arxiv.org/abs/2509.06463", "authors": ["Chengwei Wu", "Li Du", "Hanyu Zhao", "Yiming Ju", "Jiapu Wang", "Tengfei Pan"], "title": "Accelerate Scaling of LLM Alignment via Quantifying the Coverage and Depth of Instruction Set", "comment": null, "summary": "With the growing demand for applying large language models to downstream\ntasks, improving model alignment performance and efficiency has become crucial.\nSuch a process involves selecting informative instructions from a candidate\npool. However, due to the complexity of instruction set distributions, the key\nfactors driving the performance of aligned models remain unclear. As a result,\ncurrent instruction set refinement methods fail to improve performance as the\ninstruction pool expands continuously. To address this issue, we first\ninvestigate the key factors that influence the relationship between instruction\ndataset distribution and aligned model performance. Based on these insights, we\npropose a novel instruction data selection method. We identify that the depth\nof instructions and the coverage of the semantic space are the crucial factors\ndetermining downstream performance, which could explain over 70\\% of the model\nloss on the development set. We then design an instruction selection algorithm\nto simultaneously maximize the depth and semantic coverage of the selected\ninstructions. Experimental results demonstrate that, compared to\nstate-of-the-art baseline methods, it can sustainably improve model performance\nat a faster pace and thus achieve \\emph{``Accelerated Scaling''}.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6307\u4ee4\u6570\u636e\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5927\u5316\u6307\u4ee4\u6df1\u5ea6\u548c\u8bed\u4e49\u8986\u76d6\u6765\u6301\u7eed\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u5bf9\u9f50\u6027\u80fd\uff0c\u5b9e\u73b0\"\u52a0\u901f\u6269\u5c55\"\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u9700\u6c42\u589e\u957f\uff0c\u63d0\u9ad8\u6a21\u578b\u5bf9\u9f50\u6027\u80fd\u548c\u6548\u7387\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u4f46\u7531\u4e8e\u6307\u4ee4\u96c6\u5206\u5e03\u7684\u590d\u6742\u6027\uff0c\u5f53\u524d\u65b9\u6cd5\u5728\u6307\u4ee4\u6c60\u4e0d\u65ad\u6269\u5927\u65f6\u65e0\u6cd5\u6301\u7eed\u63d0\u5347\u6027\u80fd\u3002", "method": "\u9996\u5148\u7814\u7a76\u6307\u4ee4\u6570\u636e\u96c6\u5206\u5e03\u4e0e\u5bf9\u9f50\u6a21\u578b\u6027\u80fd\u5173\u7cfb\u7684\u5173\u952e\u56e0\u7d20\uff0c\u53d1\u73b0\u6307\u4ee4\u6df1\u5ea6\u548c\u8bed\u4e49\u7a7a\u95f4\u8986\u76d6\u662f\u51b3\u5b9a\u6027\u56e0\u7d20\u3002\u7136\u540e\u8bbe\u8ba1\u6307\u4ee4\u9009\u62e9\u7b97\u6cd5\uff0c\u540c\u65f6\u6700\u5927\u5316\u6240\u9009\u6307\u4ee4\u7684\u6df1\u5ea6\u548c\u8bed\u4e49\u8986\u76d6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u4ee5\u66f4\u5feb\u7684\u901f\u5ea6\u6301\u7eed\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u53ef\u89e3\u91ca\u5f00\u53d1\u96c6\u4e0a70%\u4ee5\u4e0a\u7684\u6a21\u578b\u635f\u5931\u3002", "conclusion": "\u6307\u4ee4\u6df1\u5ea6\u548c\u8bed\u4e49\u8986\u76d6\u662f\u5f71\u54cd\u5bf9\u9f50\u6a21\u578b\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\uff0c\u63d0\u51fa\u7684\u6307\u4ee4\u9009\u62e9\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u53ef\u6301\u7eed\u7684\u6027\u80fd\u63d0\u5347\u548c\u52a0\u901f\u6269\u5c55\u3002"}}
{"id": "2509.06477", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06477", "abs": "https://arxiv.org/abs/2509.06477", "authors": ["Pengxiang Zhao", "Guangyi Liu", "Yaozhen Liang", "Weiqing He", "Zhengxi Lu", "Yuehao Huang", "Yaxuan Guo", "Kexin Zhang", "Hao Wang", "Liang Liu", "Yong Liu"], "title": "MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents", "comment": null, "summary": "To enhance the efficiency of GUI agents on various platforms like smartphones\nand computers, a hybrid paradigm that combines flexible GUI operations with\nefficient shortcuts (e.g., API, deep links) is emerging as a promising\ndirection. However, a framework for systematically benchmarking these hybrid\nagents is still underexplored. To take the first step in bridging this gap, we\nintroduce MAS-Bench, a benchmark that pioneers the evaluation of GUI-shortcut\nhybrid agents with a specific focus on the mobile domain. Beyond merely using\npredefined shortcuts, MAS-Bench assesses an agent's capability to autonomously\ngenerate shortcuts by discovering and creating reusable, low-cost workflows. It\nfeatures 139 complex tasks across 11 real-world applications, a knowledge base\nof 88 predefined shortcuts (APIs, deep-links, RPA scripts), and 7 evaluation\nmetrics. The tasks are designed to be solvable via GUI-only operations, but can\nbe significantly accelerated by intelligently embedding shortcuts. Experiments\nshow that hybrid agents achieve significantly higher success rates and\nefficiency than their GUI-only counterparts. This result also demonstrates the\neffectiveness of our method for evaluating an agent's shortcut generation\ncapabilities. MAS-Bench fills a critical evaluation gap, providing a\nfoundational platform for future advancements in creating more efficient and\nrobust intelligent agents.", "AI": {"tldr": "MAS-Bench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30GUI-\u5feb\u6377\u65b9\u5f0f\u6df7\u5408\u667a\u80fd\u4ee3\u7406\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u6ce8\u4e8e\u79fb\u52a8\u9886\u57df\uff0c\u5305\u542b139\u4e2a\u590d\u6742\u4efb\u52a1\u300188\u4e2a\u9884\u5b9a\u4e49\u5feb\u6377\u65b9\u5f0f\u548c7\u4e2a\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u8bc4\u4f30GUI\u64cd\u4f5c\u4e0e\u5feb\u6377\u65b9\u5f0f\uff08\u5982API\u3001\u6df1\u5ea6\u94fe\u63a5\uff09\u6df7\u5408\u4ee3\u7406\u7684\u6846\u67b6\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u4ee5\u63d0\u5347GUI\u4ee3\u7406\u5728\u5404\u79cd\u5e73\u53f0\u4e0a\u7684\u6548\u7387\u3002", "method": "\u6784\u5efa\u5305\u542b139\u4e2a\u590d\u6742\u4efb\u52a1\u300111\u4e2a\u771f\u5b9e\u5e94\u7528\u300188\u4e2a\u9884\u5b9a\u4e49\u5feb\u6377\u65b9\u5f0f\u77e5\u8bc6\u5e93\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4ee3\u7406\u81ea\u4e3b\u751f\u6210\u5feb\u6377\u65b9\u5f0f\u548c\u521b\u5efa\u53ef\u91cd\u7528\u4f4e\u6210\u672c\u5de5\u4f5c\u6d41\u7684\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u6df7\u5408\u4ee3\u7406\u6bd4\u7eafGUI\u4ee3\u7406\u83b7\u5f97\u663e\u8457\u66f4\u9ad8\u7684\u6210\u529f\u7387\u548c\u6548\u7387\uff0c\u8bc1\u660e\u4e86\u8bc4\u4f30\u4ee3\u7406\u5feb\u6377\u65b9\u5f0f\u751f\u6210\u80fd\u529b\u7684\u6709\u6548\u6027\u3002", "conclusion": "MAS-Bench\u586b\u8865\u4e86\u5173\u952e\u8bc4\u4f30\u7a7a\u767d\uff0c\u4e3a\u521b\u5efa\u66f4\u9ad8\u6548\u3001\u66f4\u9c81\u68d2\u7684\u667a\u80fd\u4ee3\u7406\u63d0\u4f9b\u4e86\u57fa\u7840\u5e73\u53f0\u3002"}}
{"id": "2509.06490", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06490", "abs": "https://arxiv.org/abs/2509.06490", "authors": ["Niki Kotecha", "Ehecatl Antonio del Rio Chanona"], "title": "MORSE: Multi-Objective Reinforcement Learning via Strategy Evolution for Supply Chain Optimization", "comment": null, "summary": "In supply chain management, decision-making often involves balancing multiple\nconflicting objectives, such as cost reduction, service level improvement, and\nenvironmental sustainability. Traditional multi-objective optimization methods,\nsuch as linear programming and evolutionary algorithms, struggle to adapt in\nreal-time to the dynamic nature of supply chains. In this paper, we propose an\napproach that combines Reinforcement Learning (RL) and Multi-Objective\nEvolutionary Algorithms (MOEAs) to address these challenges for dynamic\nmulti-objective optimization under uncertainty. Our method leverages MOEAs to\nsearch the parameter space of policy neural networks, generating a Pareto front\nof policies. This provides decision-makers with a diverse population of\npolicies that can be dynamically switched based on the current system\nobjectives, ensuring flexibility and adaptability in real-time decision-making.\nWe also introduce Conditional Value-at-Risk (CVaR) to incorporate\nrisk-sensitive decision-making, enhancing resilience in uncertain environments.\nWe demonstrate the effectiveness of our approach through case studies,\nshowcasing its ability to respond to supply chain dynamics and outperforming\nstate-of-the-art methods in an inventory management case study. The proposed\nstrategy not only improves decision-making efficiency but also offers a more\nrobust framework for managing uncertainty and optimizing performance in supply\nchains.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u591a\u76ee\u6807\u8fdb\u5316\u7b97\u6cd5\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f9b\u5e94\u94fe\u52a8\u6001\u591a\u76ee\u6807\u4f18\u5316\uff0c\u901a\u8fc7CVaR\u5f15\u5165\u98ce\u9669\u654f\u611f\u51b3\u7b56\uff0c\u5728\u5e93\u5b58\u7ba1\u7406\u6848\u4f8b\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u4f9b\u5e94\u94fe\u7684\u52a8\u6001\u7279\u6027\uff0c\u9700\u8981\u5b9e\u65f6\u5e73\u8861\u6210\u672c\u964d\u4f4e\u3001\u670d\u52a1\u6c34\u5e73\u63d0\u5347\u548c\u73af\u5883\u53ef\u6301\u7eed\u6027\u7b49\u51b2\u7a81\u76ee\u6807", "method": "\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60(RL)\u548c\u591a\u76ee\u6807\u8fdb\u5316\u7b97\u6cd5(MOEAs)\uff0c\u5229\u7528MOEAs\u641c\u7d22\u7b56\u7565\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u7a7a\u95f4\u751f\u6210Pareto\u524d\u6cbf\u7b56\u7565\u96c6\uff0c\u5f15\u5165\u6761\u4ef6\u98ce\u9669\u4ef7\u503c(CVaR)\u8fdb\u884c\u98ce\u9669\u654f\u611f\u51b3\u7b56", "result": "\u5728\u6848\u4f8b\u7814\u7a76\u4e2d\u5c55\u793a\u4e86\u5e94\u5bf9\u4f9b\u5e94\u94fe\u52a8\u6001\u53d8\u5316\u7684\u80fd\u529b\uff0c\u5728\u5e93\u5b58\u7ba1\u7406\u6848\u4f8b\u4e2d\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u51b3\u7b56\u6548\u7387\uff0c\u8fd8\u4e3a\u7ba1\u7406\u4e0d\u786e\u5b9a\u6027\u548c\u4f18\u5316\u4f9b\u5e94\u94fe\u6027\u80fd\u63d0\u4f9b\u4e86\u66f4\u7a33\u5065\u7684\u6846\u67b6"}}
{"id": "2509.06493", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06493", "abs": "https://arxiv.org/abs/2509.06493", "authors": ["Ran Xin", "Zeyu Zheng", "Yanchen Nie", "Kun Yuan", "Xia Xiao"], "title": "Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers", "comment": null, "summary": "The integration of Large Language Models (LLMs) into automated theorem\nproving has shown immense promise, yet is fundamentally constrained by\nchallenges in scaling up both training-time reinforcement learning (RL) and\ninference-time compute. This paper introduces \\texttt{BFS-Prover-V2}, a system\ndesigned to address this dual scaling problem. We present two primary\ninnovations. The first is a novel multi-turn off-policy RL framework for\ncontinually improving the performance of LLM step-prover at training time. This\nframework, inspired by the principles of AlphaZero, utilizes a multi-stage\nexpert iteration pipeline featuring adaptive tactic-level data filtering and\nperiodic retraining to surmount the performance plateaus that typically curtail\nlong-term RL in LLM-based agents. The second innovation is a planner-enhanced\nmulti-agent search architecture that scales reasoning capabilities at inference\ntime. This architecture employs a general reasoning model as a high-level\nplanner to iteratively decompose complex theorems into a sequence of simpler\nsubgoals. This hierarchical approach substantially reduces the search space,\nenabling a team of parallel prover agents to collaborate efficiently by\nleveraging a shared proof cache. We demonstrate that this dual approach to\nscaling yields state-of-the-art results on established formal mathematics\nbenchmarks. \\texttt{BFS-Prover-V2} achieves 95.08\\% and 41.4\\% on the MiniF2F\nand ProofNet test sets respectively. While demonstrated in the domain of formal\nmathematics, the RL and inference techniques presented in this work are of\nbroader interest and may be applied to other domains requiring long-horizon\nmulti-turn reasoning and complex search.", "AI": {"tldr": "BFS-Prover-V2\u662f\u4e00\u4e2a\u7ed3\u5408\u591a\u8f6e\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u548c\u89c4\u5212\u589e\u5f3a\u591a\u667a\u80fd\u4f53\u641c\u7d22\u7684\u7cfb\u7edf\uff0c\u5728\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u9886\u57df\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u4e2d\u8bad\u7ec3\u65f6\u5f3a\u5316\u5b66\u4e60\u548c\u63a8\u7406\u65f6\u8ba1\u7b97\u6269\u5c55\u7684\u53cc\u91cd\u6311\u6218", "method": "1) \u591a\u8f6e\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u4e13\u5bb6\u8fed\u4ee3\u6d41\u7a0b\uff1b2) \u89c4\u5212\u589e\u5f3a\u7684\u591a\u667a\u80fd\u4f53\u641c\u7d22\u67b6\u6784\uff0c\u4f7f\u7528\u901a\u7528\u63a8\u7406\u6a21\u578b\u4f5c\u4e3a\u9ad8\u5c42\u89c4\u5212\u5668\u5206\u89e3\u590d\u6742\u5b9a\u7406", "result": "\u5728MiniF2F\u548cProofNet\u6d4b\u8bd5\u96c6\u4e0a\u5206\u522b\u8fbe\u523095.08%\u548c41.4%\u7684\u51c6\u786e\u7387", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u5f62\u5f0f\u6570\u5b66\u9886\u57df\u53d6\u5f97\u7a81\u7834\u6027\u6210\u679c\uff0c\u5176\u5f3a\u5316\u5b66\u4e60\u548c\u63a8\u7406\u6280\u672f\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u9700\u8981\u957f\u7a0b\u591a\u8f6e\u63a8\u7406\u548c\u590d\u6742\u641c\u7d22\u7684\u9886\u57df"}}
{"id": "2509.06503", "categories": ["cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2509.06503", "abs": "https://arxiv.org/abs/2509.06503", "authors": ["Eser Ayg\u00fcn", "Anastasiya Belyaeva", "Gheorghe Comanici", "Marc Coram", "Hao Cui", "Jake Garrison", "Renee Johnston Anton Kast", "Cory Y. McLean", "Peter Norgaard", "Zahra Shamsi", "David Smalling", "James Thompson", "Subhashini Venugopalan", "Brian P. Williams", "Chujun He", "Sarah Martinson", "Martyna Plomecka", "Lai Wei", "Yuchen Zhou", "Qian-Ze Zhu", "Matthew Abraham", "Erica Brand", "Anna Bulanova", "Jeffrey A. Cardille", "Chris Co", "Scott Ellsworth", "Grace Joseph", "Malcolm Kane", "Ryan Krueger", "Johan Kartiwa", "Dan Liebling", "Jan-Matthis Lueckmann", "Paul Raccuglia", "Xuefei", "Wang", "Katherine Chou", "James Manyika", "Yossi Matias", "John C. Platt", "Lizzie Dorfman", "Shibl Mourad", "Michael P. Brenner"], "title": "An AI system to help scientists write expert-level empirical software", "comment": "71 pages, 26 figures", "summary": "The cycle of scientific discovery is frequently bottlenecked by the slow,\nmanual creation of software to support computational experiments. To address\nthis, we present an AI system that creates expert-level scientific software\nwhose goal is to maximize a quality metric. The system uses a Large Language\nModel (LLM) and Tree Search (TS) to systematically improve the quality metric\nand intelligently navigate the large space of possible solutions. The system\nachieves expert-level results when it explores and integrates complex research\nideas from external sources. The effectiveness of tree search is demonstrated\nacross a wide range of benchmarks. In bioinformatics, it discovered 40 novel\nmethods for single-cell data analysis that outperformed the top human-developed\nmethods on a public leaderboard. In epidemiology, it generated 14 models that\noutperformed the CDC ensemble and all other individual models for forecasting\nCOVID-19 hospitalizations. Our method also produced state-of-the-art software\nfor geospatial analysis, neural activity prediction in zebrafish, time series\nforecasting and numerical solution of integrals. By devising and implementing\nnovel solutions to diverse tasks, the system represents a significant step\ntowards accelerating scientific progress.", "AI": {"tldr": "AI\u7cfb\u7edf\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6811\u641c\u7d22\u81ea\u52a8\u751f\u6210\u4e13\u5bb6\u7ea7\u79d1\u5b66\u8f6f\u4ef6\uff0c\u5728\u591a\u4e2a\u9886\u57df\u8d85\u8d8a\u4eba\u7c7b\u5f00\u53d1\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u8fdb\u7a0b", "motivation": "\u79d1\u5b66\u53d1\u73b0\u8fc7\u7a0b\u7ecf\u5e38\u53d7\u9650\u4e8e\u624b\u52a8\u521b\u5efa\u8ba1\u7b97\u5b9e\u9a8c\u8f6f\u4ef6\u7684\u7f13\u6162\u901f\u5ea6\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u6765\u52a0\u901f\u79d1\u5b66\u8fdb\u6b65", "method": "\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u548c\u6811\u641c\u7d22(TS)\u6280\u672f\uff0c\u7cfb\u7edf\u6027\u5730\u6539\u8fdb\u8d28\u91cf\u6307\u6807\u5e76\u667a\u80fd\u5bfc\u822a\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4", "result": "\u5728\u751f\u7269\u4fe1\u606f\u5b66\u4e2d\u53d1\u73b040\u79cd\u4f18\u4e8e\u4eba\u7c7b\u65b9\u6cd5\u7684\u65b0\u5355\u7ec6\u80de\u6570\u636e\u5206\u6790\u65b9\u6cd5\uff1b\u5728\u6d41\u884c\u75c5\u5b66\u4e2d\u751f\u621014\u4e2a\u8d85\u8d8aCDC\u96c6\u6210\u6a21\u578b\u7684COVID-19\u4f4f\u9662\u9884\u6d4b\u6a21\u578b\uff1b\u5728\u591a\u4e2a\u9886\u57df\u4ea7\u751f\u6700\u5148\u8fdb\u8f6f\u4ef6", "conclusion": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u4e3a\u591a\u6837\u5316\u4efb\u52a1\u8bbe\u8ba1\u548c\u5b9e\u65bd\u65b0\u9896\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u8868\u4e86\u52a0\u901f\u79d1\u5b66\u8fdb\u6b65\u7684\u91cd\u8981\u4e00\u6b65"}}
{"id": "2509.06641", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06641", "abs": "https://arxiv.org/abs/2509.06641", "authors": ["Zhou-Peng Shou", "Zhi-Qiang You", "Fang Wang", "Hai-Bo Liu"], "title": "CogGuide: Human-Like Guidance for Zero-Shot Omni-Modal Reasoning", "comment": null, "summary": "Targeting the issues of \"shortcuts\" and insufficient contextual understanding\nin complex cross-modal reasoning of multimodal large models, this paper\nproposes a zero-shot multimodal reasoning component guided by human-like\ncognitive strategies centered on an \"intent sketch\". The component comprises a\nplug-and-play three-module pipeline-Intent Perceiver, Strategy Generator, and\nStrategy Selector-that explicitly constructs a \"understand-plan-select\"\ncognitive process. By generating and filtering \"intent sketch\" strategies to\nguide the final reasoning, it requires no parameter fine-tuning and achieves\ncross-model transfer solely through in-context engineering.\nInformation-theoretic analysis shows that this process can reduce conditional\nentropy and improve information utilization efficiency, thereby suppressing\nunintended shortcut reasoning. Experiments on IntentBench, WorldSense, and\nDaily-Omni validate the method's generality and robust gains; compared with\ntheir respective baselines, the complete \"three-module\" scheme yields\nconsistent improvements across different reasoning engines and pipeline\ncombinations, with gains up to approximately 9.51 percentage points,\ndemonstrating the practical value and portability of the \"intent sketch\"\nreasoning component in zero-shot scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\"\u610f\u56fe\u8349\u7a3f\"\u7684\u96f6\u68c0\u51fa\u591a\u6a21\u6001\u63a8\u7406\u7ec4\u4ef6\uff0c\u901a\u8fc7\u4e09\u6a21\u5757\u6d41\u6c34\u7ebf\u5b9e\u73b0\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u89e3\u51b3\u591a\u6a21\u6001\u5927\u6a21\u578b\u590d\u6742\u63a8\u7406\u4e2d\u7684\"\u77ed\u63a5\"\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\u4e0d\u5145\u5206\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u590d\u6742\u8de8\u6a21\u6001\u63a8\u7406\u4e2d\u5b58\u5728\u7684\"\u77ed\u63a5\"\u95ee\u9898\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\u4e0d\u5145\u5206\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u6a21\u578b\u7684\u6df1\u5ea6\u7406\u89e3\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u63d2\u62d4\u5373\u7528\u7684\u4e09\u6a21\u5757\u6d41\u6c34\u7ebf\uff1a\u610f\u56fe\u611f\u77e5\u5668\u3001\u7b56\u7565\u751f\u6210\u5668\u548c\u7b56\u7565\u9009\u62e9\u5668\uff0c\u901a\u8fc7\u751f\u6210\u548c\u7b5b\u9009\"\u610f\u56fe\u8349\u7a3f\"\u7b56\u7565\u6765\u6307\u5bfc\u6700\u7ec8\u63a8\u7406\uff0c\u65e0\u9700\u53c2\u6570\u5fae\u8c03\u3002", "result": "\u5728IntentBench\u3001WorldSense\u548cDaily-Omni\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u666e\u9002\u6027\u548c\u7a33\u5065\u6536\u76ca\uff0c\u76f8\u6bd4\u5404\u81ea\u57fa\u7ebf\u5b8c\u6574\u7684\"\u4e09\u6a21\u5757\"\u65b9\u6848\u5728\u4e0d\u540c\u63a8\u7406\u5f15\u64ce\u548c\u6d41\u6c34\u7ebf\u7ec4\u5408\u4e2d\u5747\u6709\u4e00\u81f4\u6536\u76ca\uff0c\u6700\u9ad8\u63d0\u5347\u7ea69.51\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u4fe1\u606f\u8bba\u5206\u6790\u663e\u793a\u8be5\u8fc7\u7a0b\u80fd\u591f\u964d\u4f4e\u6761\u4ef6\u71b5\u548c\u63d0\u9ad8\u4fe1\u606f\u5229\u7528\u6548\u7387\uff0c\u538b\u5236\u610f\u5916\u7684\u77ed\u63a5\u63a8\u7406\uff0c\u8bc1\u660e\u4e86\"\u610f\u56fe\u8349\u7a3f\"\u63a8\u7406\u7ec4\u4ef6\u5728\u96f6\u68c0\u51fa\u573a\u666f\u4e2d\u7684\u5b9e\u9645\u4ef7\u503c\u548c\u53ef\u79fb\u690d\u6027\u3002"}}
{"id": "2509.06733", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.06733", "abs": "https://arxiv.org/abs/2509.06733", "authors": ["Wenjun Li", "Zhi Chen", "Jingru Lin", "Hannan Cao", "Wei Han", "Sheng Liang", "Zhi Zhang", "Kuicai Dong", "Dexun Li", "Chen Zhang", "Yong Liu"], "title": "Reinforcement Learning Foundations for Deep Research Systems: A Survey", "comment": "38 pages, first version", "summary": "Deep research systems, agentic AI that solve complex, multi-step tasks by\ncoordinating reasoning, search across the open web and user files, and tool\nuse, are moving toward hierarchical deployments with a Planner, Coordinator,\nand Executors. In practice, training entire stacks end-to-end remains\nimpractical, so most work trains a single planner connected to core tools such\nas search, browsing, and code. While SFT imparts protocol fidelity, it suffers\nfrom imitation and exposure biases and underuses environment feedback.\nPreference alignment methods such as DPO are schema and proxy-dependent,\noff-policy, and weak for long-horizon credit assignment and multi-objective\ntrade-offs. A further limitation of SFT and DPO is their reliance on human\ndefined decision points and subskills through schema design and labeled\ncomparisons. Reinforcement learning aligns with closed-loop, tool-interaction\nresearch by optimizing trajectory-level policies, enabling exploration,\nrecovery behaviors, and principled credit assignment, and it reduces dependence\non such human priors and rater biases.\n  This survey is, to our knowledge, the first dedicated to the RL foundations\nof deep research systems. It systematizes work after DeepSeek-R1 along three\naxes: (i) data synthesis and curation; (ii) RL methods for agentic research\ncovering stability, sample efficiency, long context handling, reward and credit\ndesign, multi-objective optimization, and multimodal integration; and (iii)\nagentic RL training systems and frameworks. We also cover agent architecture\nand coordination, as well as evaluation and benchmarks, including recent QA,\nVQA, long-form synthesis, and domain-grounded, tool-interaction tasks. We\ndistill recurring patterns, surface infrastructure bottlenecks, and offer\npractical guidance for training robust, transparent deep research agents with\nRL.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u662f\u7b2c\u4e00\u7bc7\u4e13\u6ce8\u4e8e\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u5f3a\u5316\u5b66\u4e60\u57fa\u7840\u7684\u7efc\u8ff0\uff0c\u7cfb\u7edf\u5316\u5730\u5206\u6790\u4e86DeepSeek-R1\u4e4b\u540e\u7684\u5de5\u4f5c\uff0c\u6db5\u76d6\u6570\u636e\u5408\u6210\u3001RL\u65b9\u6cd5\u3001\u8bad\u7ec3\u7cfb\u7edf\u3001\u67b6\u6784\u534f\u8c03\u548c\u8bc4\u4f30\u57fa\u51c6\u7b49\u65b9\u9762\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u4e3b\u8981\u4f7f\u7528SFT\u548cDPO\u65b9\u6cd5\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5b58\u5728\u6a21\u4eff\u504f\u5dee\u3001\u66b4\u9732\u504f\u5dee\u3001\u6a21\u5f0f\u4f9d\u8d56\u7b49\u95ee\u9898\uff0c\u4e14\u4f9d\u8d56\u4eba\u5de5\u5b9a\u4e49\u7684\u51b3\u7b56\u70b9\u548c\u5b50\u6280\u80fd\u3002\u5f3a\u5316\u5b66\u4e60\u80fd\u591f\u901a\u8fc7\u4f18\u5316\u8f68\u8ff9\u7ea7\u7b56\u7565\uff0c\u5b9e\u73b0\u63a2\u7d22\u3001\u6062\u590d\u884c\u4e3a\u548c\u539f\u5219\u6027\u4fe1\u7528\u5206\u914d\uff0c\u51cf\u5c11\u5bf9\u4eba\u7c7b\u5148\u9a8c\u548c\u8bc4\u5206\u8005\u504f\u89c1\u7684\u4f9d\u8d56\u3002", "method": "\u8bba\u6587\u4ece\u4e09\u4e2a\u7ef4\u5ea6\u7cfb\u7edf\u5316\u5206\u6790\u5de5\u4f5c\uff1a(i)\u6570\u636e\u5408\u6210\u4e0e\u6574\u7406\uff1b(ii)\u9762\u5411\u667a\u80fd\u4f53\u7814\u7a76\u7684RL\u65b9\u6cd5\uff0c\u5305\u62ec\u7a33\u5b9a\u6027\u3001\u6837\u672c\u6548\u7387\u3001\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u3001\u5956\u52b1\u4e0e\u4fe1\u7528\u8bbe\u8ba1\u3001\u591a\u76ee\u6807\u4f18\u5316\u548c\u591a\u6a21\u6001\u96c6\u6210\uff1b(iii)\u667a\u80fd\u4f53RL\u8bad\u7ec3\u7cfb\u7edf\u548c\u6846\u67b6\u3002\u540c\u65f6\u6db5\u76d6\u667a\u80fd\u4f53\u67b6\u6784\u534f\u8c03\u4ee5\u53ca\u8bc4\u4f30\u57fa\u51c6\u3002", "result": "\u8bba\u6587\u63d0\u70bc\u4e86\u91cd\u590d\u51fa\u73b0\u7684\u6a21\u5f0f\uff0c\u63ed\u793a\u4e86\u57fa\u7840\u8bbe\u65bd\u74f6\u9888\uff0c\u5e76\u4e3a\u4f7f\u7528RL\u8bad\u7ec3\u9c81\u68d2\u3001\u900f\u660e\u7684\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u4e3a\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u5de5\u5177\u4ea4\u4e92\u7814\u7a76\u4e2d\u7684\u95ed\u73af\u4f18\u5316\u95ee\u9898\uff0c\u51cf\u5c11\u5bf9\u4eba\u7c7b\u5148\u9a8c\u77e5\u8bc6\u7684\u4f9d\u8d56\uff0c\u662f\u672a\u6765\u53d1\u5c55\u7684\u91cd\u70b9\u65b9\u5411\u3002"}}
{"id": "2509.06736", "categories": ["cs.AI", "cs.CL", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.06736", "abs": "https://arxiv.org/abs/2509.06736", "authors": ["Jie Yang", "Jiajun Chen", "Zhangyue Yin", "Shuo Chen", "Yuxin Wang", "Yiran Guo", "Yuan Li", "Yining Zheng", "Xuanjing Huang", "Xipeng Qiu"], "title": "VehicleWorld: A Highly Integrated Multi-Device Environment for Intelligent Vehicle Interaction", "comment": null, "summary": "Intelligent vehicle cockpits present unique challenges for API Agents,\nrequiring coordination across tightly-coupled subsystems that exceed typical\ntask environments' complexity. Traditional Function Calling (FC) approaches\noperate statelessly, requiring multiple exploratory calls to build\nenvironmental awareness before execution, leading to inefficiency and limited\nerror recovery. We introduce VehicleWorld, the first comprehensive environment\nfor the automotive domain, featuring 30 modules, 250 APIs, and 680 properties\nwith fully executable implementations that provide real-time state information\nduring agent execution. This environment enables precise evaluation of vehicle\nagent behaviors across diverse, challenging scenarios. Through systematic\nanalysis, we discovered that direct state prediction outperforms function\ncalling for environmental control. Building on this insight, we propose\nState-based Function Call (SFC), a novel approach that maintains explicit\nsystem state awareness and implements direct state transitions to achieve\ntarget conditions. Experimental results demonstrate that SFC significantly\noutperforms traditional FC approaches, achieving superior execution accuracy\nand reduced latency. We have made all implementation code publicly available on\nGithub https://github.com/OpenMOSS/VehicleWorld.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684State-based Function Call (SFC)\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ef4\u62a4\u663e\u5f0f\u7cfb\u7edf\u72b6\u6001\u610f\u8bc6\u548c\u76f4\u63a5\u72b6\u6001\u8fc1\u79fb\uff0c\u5728\u8f66\u8f86\u667a\u80fd\u5ea7\u8231\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6267\u884c\u51c6\u786e\u6027\u548c\u51cf\u5c11\u5ef6\u8fdf\u3002", "motivation": "\u4f20\u7edf\u51fd\u6570\u8c03\u7528(FC)\u65b9\u6cd5\u5728\u8f66\u8f86\u667a\u80fd\u5ea7\u8231\u8fd9\u79cd\u590d\u6742\u73af\u5883\u4e2d\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u3001\u9519\u8bef\u6062\u590d\u80fd\u529b\u5c3e\u7b49\u95ee\u9898\uff0c\u9700\u8981\u591a\u6b21\u63a2\u7d22\u6027\u8c03\u7528\u6765\u6784\u5efa\u73af\u5883\u610f\u8bc6\uff0c\u5f71\u54cd\u4e86\u6027\u80fd\u3002", "method": "\u7814\u7a76\u8005\u9996\u5148\u6784\u5efa\u4e86VehicleWorld\u73af\u5883\uff0c\u5305\u542b30\u4e2a\u6a21\u5757\u3001250\u4e2aAPI\u548c680\u4e2a\u5c5e\u6027\u3002\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u53d1\u73b0\u76f4\u63a5\u72b6\u6001\u9884\u6d4b\u5728\u73af\u5883\u63a7\u5236\u4e2d\u66f4\u4f18\u79f0\uff0c\u4ece\u800c\u63d0\u51faSFC\u65b9\u6cd5\uff0c\u7ef4\u62a4\u663e\u5f0f\u7cfb\u7edf\u72b6\u6001\u610f\u8bc6\u5e76\u5b9e\u73b0\u76f4\u63a5\u72b6\u6001\u8fc1\u79fb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cSFC\u65b9\u6cd5\u663e\u8457\u8d85\u8fc7\u4f20\u7edfFC\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6267\u884c\u51c6\u786e\u6027\u548c\u66f4\u4f4e\u7684\u5ef6\u8fdf\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e3a\u8f66\u8f86\u667a\u80fd\u5ea7\u8231\u7684API\u4ee3\u7406\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u65b9\u6848\uff0cSFC\u65b9\u6cd5\u901a\u8fc7\u72b6\u6001\u57fa\u7840\u7684\u51fd\u6570\u8c03\u7528\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u590d\u6742\u73af\u5883\u4e2d\u7684\u4ee3\u7406\u6267\u884c\u5f00\u542f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2509.06770", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.06770", "abs": "https://arxiv.org/abs/2509.06770", "authors": ["Shashidhar Reddy Javaji", "Bhavul Gauri", "Zining Zhu"], "title": "Another Turn, Better Output? A Turn-Wise Analysis of Iterative LLM Prompting", "comment": null, "summary": "Large language models (LLMs) are now used in multi-turn workflows, but we\nstill lack a clear way to measure when iteration helps and when it hurts. We\npresent an evaluation framework for iterative refinement that spans ideation,\ncode, and math. Our protocol runs controlled 12-turn conversations per task,\nutilizing a variety of prompts ranging from vague ``improve it'' feedback to\ntargeted steering, and logs per-turn outputs. We score outcomes with\ndomain-appropriate checks (unit tests for code; answer-equivalence plus\nreasoning-soundness for math; originality and feasibility for ideation) and\ntrack turn-level behavior with three families of metrics: semantic movement\nacross turns, turn-to-turn change, and output size growth. Across models and\ntasks, gains are domain-dependent: they arrive early in ideas and code, but in\nmath late turns matter when guided by elaboration. After the first few turns,\nvague feedback often plateaus or reverses correctness, while targeted prompts\nreliably shift the intended quality axis (novelty vs. feasibility in ideation;\nspeed vs. readability in code; in math, elaboration outperforms exploration and\ndrives late-turn gains). We also observe consistent domain patterns: ideation\nmoves more in meaning across turns, code tends to grow in size with little\nsemantic change, and math starts fixed but can break that path with late,\nelaborative iteration.Together, the framework and metrics make iteration\nmeasurable and comparable across models, and signal when to steer, stop, or\nswitch strategies.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u8fed\u4ee3\u7cbe\u70bc\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6d4b\u91cf\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u5de5\u4f5c\u6d41\u4e2d\u7684\u8868\u73b0\uff0c\u5305\u62ec\u601d\u60f3\u521b\u9020\u3001\u4ee3\u7801\u548c\u6570\u5b66\u9886\u57df\uff0c\u901a\u8fc7\u63a7\u5236\u5bf9\u8bdd\u548c\u591a\u79cd\u63d0\u793a\u7b56\u7565\u6765\u5206\u6790\u8fed\u4ee3\u7684\u6548\u679c\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5df2\u7ecf\u88ab\u5e7f\u6cdb\u4f7f\u7528\u4e8e\u591a\u8f6e\u5de5\u4f5c\u6d41\uff0c\u4f46\u6211\u4eec\u4ecd\u7f3a\u4e4f\u660e\u786e\u7684\u65b9\u6cd5\u6765\u8861\u91cf\u8fed\u4ee3\u5728\u4ec0\u4e48\u60c5\u51b5\u4e0b\u6709\u5e2e\u52a9\u4ee5\u53ca\u5728\u4ec0\u4e48\u60c5\u51b5\u4e0b\u6709\u5bb3\uff0c\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u8fdb\u884c\u7cfb\u7edf\u6027\u5206\u6790\u3002", "method": "\u7814\u7a76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u534f\u8bae\uff0c\u5728\u6bcf\u4e2a\u4efb\u52a1\u4e2d\u8fd0\u884c12\u8f6e\u7684\u63a7\u5236\u5bf9\u8bdd\uff0c\u4f7f\u7528\u4ece\u6a21\u7cca\"\u6539\u8fdb\u5b83\"\u53cd\u9988\u5230\u6709\u76ee\u6807\u5bfc\u822a\u7684\u5404\u79cd\u63d0\u793a\u7b56\u7565\uff0c\u5e76\u8bb0\u5f55\u6bcf\u8f6e\u8f93\u51fa\u3002\u901a\u8fc7\u9886\u57df\u9002\u5b9c\u7684\u68c0\u67e5\u6765\u8bc4\u5206\u7ed3\u679c\uff08\u4ee3\u7801\u7684\u5355\u5143\u6d4b\u8bd5\uff1b\u6570\u5b66\u7684\u7b54\u6848\u7b49\u6548\u6027\u52a0\u63a8\u7406\u5408\u7406\u6027\uff1b\u601d\u60f3\u521b\u9020\u7684\u539f\u521b\u6027\u548c\u53ef\u884c\u6027\uff09\uff0c\u5e76\u4f7f\u7528\u4e09\u7c7b\u6307\u6807\u8ddf\u8e2a\u8f6e\u6b21\u884c\u4e3a\uff1a\u8bed\u4e49\u79fb\u52a8\u3001\u8f6e\u95f4\u53d8\u5316\u548c\u8f93\u51fa\u5927\u5c0f\u589e\u957f\u3002", "result": "\u5728\u4e0d\u540c\u6a21\u578b\u548c\u4efb\u52a1\u4e2d\uff0c\u6536\u76ca\u5177\u6709\u9886\u57df\u4f9d\u8d56\u6027\uff1a\u5728\u601d\u60f3\u548c\u4ee3\u7801\u4e2d\u6536\u76ca\u6765\u5f97\u65e9\uff0c\u800c\u5728\u6570\u5b66\u4e2d\u540e\u671f\u8f6e\u6b21\u5728\u8be6\u7ec6\u6307\u5bfc\u4e0b\u91cd\u8981\u3002\u5728\u524d\u51e0\u8f6e\u4e4b\u540e\uff0c\u6a21\u7cca\u7684\u53cd\u9988\u5e38\u5e38\u505c\u6ede\u6216\u9006\u8f6c\u6b63\u786e\u6027\uff0c\u800c\u6709\u76ee\u6807\u7684\u63d0\u793a\u53ef\u9760\u5730\u63a8\u52a8\u9886\u57df\u7279\u5b9a\u7684\u8d28\u91cf\u8f74\uff08\u601d\u60f3\u521b\u9020\u4e2d\u7684\u65b0\u9896\u6027vs\u53ef\u884c\u6027\uff1b\u4ee3\u7801\u4e2d\u7684\u901f\u5ea6vs\u53ef\u8bfb\u6027\uff1b\u6570\u5b66\u4e2d\u8be6\u7ec6\u8bf4\u660e\u8d85\u8fc7\u63a2\u7d22\u5e76\u9a71\u52a8\u540e\u671f\u6536\u76ca\uff09\u3002\u8fd8\u89c2\u5bdf\u5230\u4e00\u81f4\u7684\u9886\u57df\u6a21\u5f0f\uff1a\u601d\u60f3\u521b\u9020\u5728\u8f6e\u6b21\u95f4\u8bed\u4e49\u79fb\u52a8\u66f4\u591a\uff0c\u4ee3\u7801\u5f80\u5f80\u8f93\u51fa\u5927\u5c0f\u589e\u957f\u4f46\u8bed\u4e49\u53d8\u5316\u5c11\uff0c\u6570\u5b66\u521d\u59cb\u56fa\u5b9a\u4f46\u53ef\u901a\u8fc7\u540e\u671f\u8be6\u7ec6\u8fed\u4ee3\u7a81\u7834\u8fd9\u4e00\u8def\u5f84\u3002", "conclusion": "\u8be5\u6846\u67b6\u548c\u6307\u6807\u4f7f\u5f97\u8fed\u4ee3\u53ef\u4ee5\u5728\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u8fdb\u884c\u6d4b\u91cf\u548c\u6bd4\u8f83\uff0c\u5e76\u4e3a\u4f55\u65f6\u5bfc\u822a\u3001\u505c\u6b62\u6216\u5207\u6362\u7b56\u7565\u63d0\u4f9b\u4fe1\u53f7\uff0c\u4e3a\u8bc4\u4f30\u548c\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8fed\u4ee3\u7cbe\u70bc\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2509.06822", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.06822", "abs": "https://arxiv.org/abs/2509.06822", "authors": ["Chenyang Zhu", "Spencer Hong", "Jingyu Wu", "Kushal Chawla", "Charlotte Tang", "Youbing Yin", "Nathan Wolfe", "Erin Babinsky", "Daben Liu"], "title": "RAFFLES: Reasoning-based Attribution of Faults for LLM Systems", "comment": null, "summary": "We have reached a critical roadblock in the development and enhancement of\nlong-horizon, multi-component LLM agentic systems: it is incredibly tricky to\nidentify where these systems break down and why. Evaluation capabilities that\ncurrently exist today (e.g., single pass LLM-as-a-judge) are limited in that\nthey often focus on individual metrics or capabilities, end-to-end outcomes,\nand are narrowly grounded on the preferences of humans. We argue that to match\nthe agentic capabilities, evaluation frameworks must also be able to reason,\nprobe, iterate, and understand the complex logic passing through these systems\nover long horizons. In this paper, we present RAFFLES - an evaluation\narchitecture that incorporates reasoning and iterative refinement.\nSpecifically, RAFFLES operates as an iterative, multi-component pipeline, using\na central Judge to systematically investigate faults and a set of specialized\nEvaluators to assess not only the system's components but also the quality of\nthe reasoning by the Judge itself, thereby building a history of hypotheses. We\ntested RAFFLES against several baselines on the Who&When dataset, a benchmark\ndesigned to diagnose the \"who\" (agent) and \"when\" (step) of a system's failure.\nRAFFLES outperforms these baselines, achieving an agent-step fault pair\naccuracy of over 43% on the Algorithmically-Generated dataset (a substantial\nincrease from the previously published best of 16.6%) and over 20% on the\nHand-Crafted dataset (surpassing the previously published best of 8.8%). These\nresults demonstrate a key step towards introducing automated fault detection\nfor autonomous systems over labor-intensive manual human review.", "AI": {"tldr": "RAFFLES\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u957f\u65f6\u57df\u591a\u7ec4\u4ef6LLM\u4ee3\u7406\u7cfb\u7edf\u7684\u8fed\u4ee3\u5f0f\u8bc4\u4f30\u67b6\u6784\uff0c\u901a\u8fc7\u63a8\u7406\u548c\u8fed\u4ee3\u7cbe\u5316\u6765\u8bc6\u522b\u7cfb\u7edf\u6545\u969c\u70b9\u548c\u539f\u56e0\uff0c\u5728Who&When\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u8d85\u8d8a\u4e86\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684\u957f\u65f6\u57df\u591a\u7ec4\u4ef6LLM\u4ee3\u7406\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff0c\u4e3b\u8981\u5173\u6ce8\u5355\u4e00\u6307\u6807\u6216\u7aef\u5230\u7aef\u7ed3\u679c\uff0c\u96be\u4ee5\u8bc6\u522b\u7cfb\u7edf\u6545\u969c\u7684\u5177\u4f53\u4f4d\u7f6e\u548c\u539f\u56e0\u3002\u9700\u8981\u80fd\u591f\u63a8\u7406\u3001\u63a2\u6d4b\u3001\u8fed\u4ee3\u5e76\u7406\u89e3\u7cfb\u7edf\u590d\u6742\u903b\u8f91\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "RAFFLES\u91c7\u7528\u8fed\u4ee3\u5f0f\u591a\u7ec4\u4ef6\u6d41\u6c34\u7ebf\u67b6\u6784\uff0c\u5305\u542b\u4e00\u4e2a\u4e2d\u592eJudge\u7cfb\u7edf\u6027\u5730\u8c03\u67e5\u6545\u969c\uff0c\u4ee5\u53ca\u4e00\u7ec4\u4e13\u95e8\u7684Evaluators\u8bc4\u4f30\u7cfb\u7edf\u7ec4\u4ef6\u548cJudge\u81ea\u8eab\u7684\u63a8\u7406\u8d28\u91cf\uff0c\u6784\u5efa\u5047\u8bbe\u5386\u53f2\u3002", "result": "\u5728Who&When\u6570\u636e\u96c6\u4e0a\uff0cRAFFLES\u5728\u7b97\u6cd5\u751f\u6210\u6570\u636e\u96c6\u4e0a\u8fbe\u523043%\u4ee5\u4e0a\u7684\u4ee3\u7406-\u6b65\u9aa4\u6545\u969c\u5bf9\u51c6\u786e\u7387\uff08\u76f8\u6bd4\u4e4b\u524d\u6700\u4f7316.6%\u6709\u663e\u8457\u63d0\u5347\uff09\uff0c\u5728\u624b\u5de5\u5236\u4f5c\u6570\u636e\u96c6\u4e0a\u8fbe\u523020%\u4ee5\u4e0a\uff08\u8d85\u8d8a\u4e4b\u524d\u6700\u4f738.8%\uff09\u3002", "conclusion": "RAFFLES\u5c55\u793a\u4e86\u5411\u81ea\u4e3b\u7cfb\u7edf\u5f15\u5165\u81ea\u52a8\u5316\u6545\u969c\u68c0\u6d4b\u7684\u91cd\u8981\u8fdb\u5c55\uff0c\u76f8\u6bd4\u52b3\u52a8\u5bc6\u96c6\u578b\u4eba\u5de5\u5ba1\u67e5\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u4e3a\u957f\u65f6\u57df\u591a\u7ec4\u4ef6LLM\u4ee3\u7406\u7cfb\u7edf\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.06861", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06861", "abs": "https://arxiv.org/abs/2509.06861", "authors": ["James Xu Zhao", "Bryan Hooi", "See-Kiong Ng"], "title": "Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet", "comment": "20 pages, 4 figures, 6 tables", "summary": "Test-time scaling increases inference-time computation by allowing models to\ngenerate long reasoning chains, and has shown strong performance across many\ndomains. However, in this work, we show that this approach is not yet effective\nfor knowledge-intensive tasks, where high factual accuracy and low\nhallucination rates are essential. We conduct a comprehensive evaluation of\ntest-time scaling using 12 reasoning models on two knowledge-intensive\nbenchmarks. Our results reveal that increasing test-time computation does not\nconsistently improve accuracy and, in many cases, it even leads to more\nhallucinations. We then analyze how extended reasoning affects hallucination\nbehavior. We find that reduced hallucinations often result from the model\nchoosing to abstain after thinking more, rather than from improved factual\nrecall. Conversely, for some models, longer reasoning encourages attempts on\npreviously unanswered questions, many of which result in hallucinations. Case\nstudies show that extended reasoning can induce confirmation bias, leading to\noverconfident hallucinations. Despite these limitations, we observe that\ncompared to non-thinking, enabling thinking remains beneficial. Code and data\nare available at https://github.com/XuZhao0/tts-knowledge", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u6d4b\u8bd5\u65f6\u6269\u5c55\uff08test-time scaling\uff09\u5728\u77e5\u8bc6\u5bc6\u96c6\u4efb\u52a1\u4e2d\u7684\u6548\u679c\uff0c\u53d1\u73b0\u589e\u52a0\u63a8\u7406\u94fe\u957f\u5ea6\u5e76\u4e0d\u80fd\u6301\u7eed\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u53cd\u800c\u53ef\u80fd\u5bfc\u66f4\u591a\u5e7b\u89c9\u73b0\u8c61\u3002", "motivation": "\u6d4b\u8bd5\u65f6\u6269\u5c55\u6280\u672f\u5728\u591a\u4e2a\u9886\u57df\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u77e5\u8bc6\u5bc6\u96c6\u4efb\u52a1\u4e2d\u7684\u6548\u679c\u4ecd\u4e0d\u660e\u786e\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5bf9\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u5e7b\u89c9\u7387\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u752812\u4e2a\u63a8\u7406\u6a21\u578b\u57282\u4e2a\u77e5\u8bc6\u5bc6\u96c6\u6807\u51c6\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\uff0c\u5206\u6790\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u91cf\u589e\u52a0\u5bf9\u51c6\u786e\u6027\u548c\u5e7b\u89c9\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "result": "\u589e\u52a0\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u5e76\u4e0d\u80fd\u6301\u7eed\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u53cd\u800c\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u4f1a\u5bfc\u81f4\u66f4\u591a\u5e7b\u89c9\u3002\u6a21\u578b\u901a\u8fc7\u66f4\u957f\u601d\u8003\u540e\u9009\u62e9\u653e\u5f03\u56de\u7b54\uff0c\u800c\u975e\u6539\u5584\u4e8b\u5b9e\u8bb0\u5fc6\u3002\u67d0\u4e9b\u6a21\u578b\u4f1a\u5c1d\u8bd5\u56de\u7b54\u4e4b\u524d\u672a\u56de\u7b54\u7684\u95ee\u9898\uff0c\u4f46\u5f88\u591a\u5bfc\u81f4\u5e7b\u89c9\u3002", "conclusion": "\u5c3d\u7ba1\u5b58\u5728\u9650\u5236\uff0c\u4f46\u4e0e\u4e0d\u8fdb\u884c\u601d\u8003\u76f8\u6bd4\uff0c\u542f\u7528\u6d4b\u8bd5\u65f6\u6269\u5c55\u4ecd\u7136\u6709\u76ca\u3002\u6269\u5c55\u63a8\u7406\u53ef\u80fd\u5bfc\u81f4\u786e\u8ba4\u504f\u89c1\uff0c\u4ea7\u751f\u8fc7\u4fe1\u5fc3\u5e7b\u89c9\u3002"}}
{"id": "2509.06917", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06917", "abs": "https://arxiv.org/abs/2509.06917", "authors": ["Jiacheng Miao", "Joe R. Davis", "Jonathan K. Pritchard", "James Zou"], "title": "Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents", "comment": null, "summary": "We introduce Paper2Agent, an automated framework that converts research\npapers into AI agents. Paper2Agent transforms research output from passive\nartifacts into active systems that can accelerate downstream use, adoption, and\ndiscovery. Conventional research papers require readers to invest substantial\neffort to understand and adapt a paper's code, data, and methods to their own\nwork, creating barriers to dissemination and reuse. Paper2Agent addresses this\nchallenge by automatically converting a paper into an AI agent that acts as a\nknowledgeable research assistant. It systematically analyzes the paper and the\nassociated codebase using multiple agents to construct a Model Context Protocol\n(MCP) server, then iteratively generates and runs tests to refine and robustify\nthe resulting MCP. These paper MCPs can then be flexibly connected to a chat\nagent (e.g. Claude Code) to carry out complex scientific queries through\nnatural language while invoking tools and workflows from the original paper. We\ndemonstrate Paper2Agent's effectiveness in creating reliable and capable paper\nagents through in-depth case studies. Paper2Agent created an agent that\nleverages AlphaGenome to interpret genomic variants and agents based on ScanPy\nand TISSUE to carry out single-cell and spatial transcriptomics analyses. We\nvalidate that these paper agents can reproduce the original paper's results and\ncan correctly carry out novel user queries. By turning static papers into\ndynamic, interactive AI agents, Paper2Agent introduces a new paradigm for\nknowledge dissemination and a foundation for the collaborative ecosystem of AI\nco-scientists.", "AI": {"tldr": "Paper2Agent\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u53ef\u5c06\u7814\u7a76\u8bba\u6587\u8f6c\u6362\u4e3aAI\u667a\u80fd\u4f53\uff0c\u4f7f\u9759\u6001\u8bba\u6587\u53d8\u6210\u52a8\u6001\u7684\u4ea4\u4e92\u5f0f\u7814\u7a76\u52a9\u624b\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u590d\u6742\u79d1\u5b66\u67e5\u8be2\u3002", "motivation": "\u4f20\u7edf\u7814\u7a76\u8bba\u6587\u9700\u8981\u8bfb\u8005\u6295\u5165\u5927\u91cf\u7cbe\u529b\u6765\u7406\u89e3\u548c\u9002\u5e94\u4ee3\u7801\u3001\u6570\u636e\u548c\u65b9\u6cd5\uff0c\u8fd9\u9020\u6210\u4e86\u4f20\u64ad\u548c\u91cd\u7528\u7684\u969c\u788d\u3002Paper2Agent\u65e8\u5728\u5c06\u7814\u7a76\u8f93\u51fa\u4ece\u88ab\u52a8\u4ea7\u7269\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u7cfb\u7edf\uff0c\u52a0\u901f\u4e0b\u6e38\u4f7f\u7528\u3001\u91c7\u7528\u548c\u53d1\u73b0\u3002", "method": "\u4f7f\u7528\u591a\u4e2a\u667a\u80fd\u4f53\u7cfb\u7edf\u5206\u6790\u8bba\u6587\u548c\u76f8\u5173\u4ee3\u7801\u5e93\uff0c\u6784\u5efa\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae(MCP)\u670d\u52a1\u5668\uff0c\u7136\u540e\u8fed\u4ee3\u751f\u6210\u548c\u8fd0\u884c\u6d4b\u8bd5\u6765\u4f18\u5316MCP\u3002\u751f\u6210\u7684\u8bba\u6587MCP\u53ef\u4ee5\u7075\u6d3b\u8fde\u63a5\u5230\u804a\u5929\u667a\u80fd\u4f53(\u5982Claude Code)\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6267\u884c\u590d\u6742\u79d1\u5b66\u67e5\u8be2\u5e76\u8c03\u7528\u539f\u59cb\u8bba\u6587\u7684\u5de5\u5177\u548c\u5de5\u4f5c\u6d41\u3002", "result": "\u901a\u8fc7\u6df1\u5165\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff1a\u521b\u5efa\u4e86\u5229\u7528AlphaGenome\u89e3\u91ca\u57fa\u56e0\u7ec4\u53d8\u5f02\u7684\u667a\u80fd\u4f53\uff0c\u4ee5\u53ca\u57fa\u4e8eScanPy\u548cTISSUE\u7684\u5355\u7ec6\u80de\u548c\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u5206\u6790\u667a\u80fd\u4f53\u3002\u8fd9\u4e9b\u667a\u80fd\u4f53\u80fd\u591f\u590d\u73b0\u539f\u59cb\u8bba\u6587\u7ed3\u679c\u5e76\u6b63\u786e\u6267\u884c\u65b0\u7684\u7528\u6237\u67e5\u8be2\u3002", "conclusion": "Paper2Agent\u901a\u8fc7\u5c06\u9759\u6001\u8bba\u6587\u8f6c\u5316\u4e3a\u52a8\u6001\u4ea4\u4e92\u5f0fAI\u667a\u80fd\u4f53\uff0c\u4e3a\u77e5\u8bc6\u4f20\u64ad\u5f15\u5165\u4e86\u65b0\u8303\u5f0f\uff0c\u5e76\u4e3aAI\u534f\u4f5c\u79d1\u5b66\u5bb6\u751f\u6001\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.06942", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06942", "abs": "https://arxiv.org/abs/2509.06942", "authors": ["Xiangwei Shen", "Zhimin Li", "Zhantao Yang", "Shiyi Zhang", "Yingfang Zhang", "Donghao Li", "Chunyu Wang", "Qinglin Lu", "Yansong Tang"], "title": "Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference", "comment": "15 pages", "summary": "Recent studies have demonstrated the effectiveness of directly aligning\ndiffusion models with human preferences using differentiable reward. However,\nthey exhibit two primary challenges: (1) they rely on multistep denoising with\ngradient computation for reward scoring, which is computationally expensive,\nthus restricting optimization to only a few diffusion steps; (2) they often\nneed continuous offline adaptation of reward models in order to achieve desired\naesthetic quality, such as photorealism or precise lighting effects. To address\nthe limitation of multistep denoising, we propose Direct-Align, a method that\npredefines a noise prior to effectively recover original images from any time\nsteps via interpolation, leveraging the equation that diffusion states are\ninterpolations between noise and target images, which effectively avoids\nover-optimization in late timesteps. Furthermore, we introduce Semantic\nRelative Preference Optimization (SRPO), in which rewards are formulated as\ntext-conditioned signals. This approach enables online adjustment of rewards in\nresponse to positive and negative prompt augmentation, thereby reducing the\nreliance on offline reward fine-tuning. By fine-tuning the FLUX.1.dev model\nwith optimized denoising and online reward adjustment, we improve its\nhuman-evaluated realism and aesthetic quality by over 3x.", "AI": {"tldr": "\u76f4\u63a5\u5bf9\u9f50\u6a21\u578bDirect-Align\u901a\u8fc7\u9884\u5b9a\u4e49\u566a\u58f0\u524d\u7f6e\u907f\u514d\u591a\u6b65\u53bb\u566a\u8ba1\u7b97\uff0c\u7ed3\u5408\u8bed\u4e49\u76f8\u5bf9\u504f\u597d\u4f18\u5316SRPO\u5b9e\u73b0\u5728\u7ebf\u5956\u52b1\u8c03\u6574\uff0c\u63d0\u5347\u4e86FLUX.1.dev\u6a21\u578b\u7684\u771f\u5b9e\u611f\u548c\u7f8e\u5b66\u8d28\u91cf3\u500d\u4ee5\u4e0a", "motivation": "\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u4f9d\u8d56\u591a\u6b65\u53bb\u566a\u8ba1\u7b97\u5956\u52b1\u7684\u8ba1\u7b97\u6210\u672c\u9ad8\u95ee\u9898\uff0c\u4ee5\u53ca\u9700\u8981\u8fde\u7eed\u79bb\u7ebf\u8c03\u6574\u5956\u52b1\u6a21\u578b\u624d\u80fd\u8fbe\u5230\u671f\u671b\u7684\u7f8e\u5b66\u8d28\u91cf", "method": "\u63d0\u51faDirect-Align\u65b9\u6cd5\u9884\u5b9a\u4e49\u566a\u58f0\u524d\u7f6e\u901a\u8fc7\u63d2\u503c\u6062\u590d\u539f\u56fe\u50cf\uff0c\u907f\u514d\u540e\u671f\u65f6\u95f4\u6b65\u7684\u8fc7\u5ea6\u4f18\u5316\uff1b\u4ee5\u53caSRPO\u6280\u672f\u5c06\u5956\u52b1\u4f5c\u4e3a\u6587\u672c\u6761\u4ef6\u4fe1\u53f7\uff0c\u652f\u6301\u5728\u7ebf\u6839\u636e\u6b63\u8d1f\u63d0\u793a\u6269\u5145\u8fdb\u884c\u5956\u52b1\u8c03\u6574", "result": "\u5bf9FLUX.1.dev\u6a21\u578b\u8fdb\u884c\u7cbe\u7ec6\u8c03\u6574\u540e\uff0c\u4eba\u7c7b\u8bc4\u4f30\u7684\u771f\u5b9e\u611f\u548c\u7f8e\u5b66\u8d28\u91cf\u63d0\u5347\u4e863\u500d\u4ee5\u4e0a", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u6548\u7387\u66f4\u9ad8\u7684\u53bb\u566a\u65b9\u6cd5\u548c\u7075\u6d3b\u7684\u5728\u7ebf\u5956\u52b1\u8c03\u6574\u673a\u5236\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u6d41\u884c\u4eba\u5de5\u667a\u80fd\u5bf9\u9f50\u65b9\u6cd5\u7684\u8ba1\u7b97\u6548\u7387\u548c\u8fed\u4ee3\u7075\u6d3b\u6027\u95ee\u9898"}}
