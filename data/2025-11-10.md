<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 7]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.IT](#cs.IT) [Total: 4]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [AWARE: Evaluating PriorityFresh Caching for Offline Emergency Warning Systems](https://arxiv.org/abs/2511.05022)
*Charles Melvin,N. Rich Nguyen*

Main category: cs.NI

TL;DR: PriorityFresh是一种语义优先、以可操作性为导向的缓存策略，专为离线紧急预警系统设计，在AWARE系统模拟环境中优化受限连接下的警报保留和推送。


<details>
  <summary>Details</summary>
Motivation: 为离线紧急预警系统设计一个在连接受限情况下能够优先保留和推送最具可操作性警报的缓存策略。

Method: 在AWARE系统模拟环境中实现PriorityFresh缓存策略，使用独立的Priority Forecasting模型仅用于合成真实警报序列进行受控实验。

Result: 实验表明该策略在不损害效率的前提下提高了以可操作性为导向的性能。

Conclusion: PriorityFresh是一种有效的语义优先缓存策略，能够在连接受限的紧急预警系统中优化警报管理。

Abstract: PriorityFresh is a semantic, actionability-first caching policy designed for
offline emergency warning systems. Within the AWARE system's simulation
environment, PriorityFresh optimizes which alerts to retain and surface under
constrained connectivity. Experiments indicate improved actionability-first
performance without harming efficiency. A separate Priority Forecasting model
is used only to synthesize realistic alert sequences for controlled experiments
and does not influence caching or push decisions.

</details>


### [2] [Cross-link RTS/CTS for MLO mm-Wave WLANs](https://arxiv.org/abs/2511.05027)
*Zhuoling Chen,Yi Zhong,Martin Haenggi*

Main category: cs.NI

TL;DR: 提出跨链路RTS/CTS机制解决毫米波Wi-Fi中的隐藏终端问题，建立了广义RTS/CTS硬核过程模型，分析了定向和全向RTS/CTS机制的性能权衡。


<details>
  <summary>Details</summary>
Motivation: 毫米波Wi-Fi的定向RTS/CTS机制无法完美解决隐藏终端问题，需要更有效的机制来平衡链路可靠性和网络吞吐量。

Method: 提出跨链路RTS/CTS机制，引入广义RTS/CTS硬核过程(G-HCP)建模空间收发关系，推导了强度、平均干扰、成功概率近似值和隐藏节点期望数的解析表达式。

Result: 跨链路RTS/CTS机制确保更高链路质量但降低网络吞吐量，定向RTS/CTS牺牲链路质量换取更高吞吐量，揭示了链路可靠性与网络吞吐量之间的基本权衡。

Conclusion: 研究为下一代WLAN标准中RTS/CTS机制的选择和优化提供了关键见解，需要在链路可靠性和网络吞吐量之间进行权衡。

Abstract: The directional RTS/CTS mechanism of mm-wave Wi-Fi hardly resolves the hidden
terminal problem perfectly.This paper proposes cross-link RTS/CTS under
multi-link operation (MLO) to address this problem and introduces a novel point
process, named the generalized RTS/CTS hard-core process (G-HCP), to model the
spatial transceiver relationships under the RTS/CTS mechanism, including the
directional case and the omnidirectional case.Analytical expressions are
derived for the intensity, the mean interference, an approximation of the
success probability, and the expected number of hidden nodes for the
directional RTS/CTS mechanism.Theoretical and numerical results demonstrate the
performance difference between two RTS/CTS mechanisms.The cross-link RTS/CTS
mechanism ensures higher link quality at the cost of reduced network
throughput.In contrast, the directional RTS/CTS sacrifices the link quality for
higher throughput.Our study reveals a fundamental trade-off between link
reliability and network throughput, providing critical insights into the
selection and optimization of RTS/CTS mechanisms in next-generation WLAN
standards.

</details>


### [3] [Improving Injection-Throttling Mechanisms for Congestion Control for Data-center and Supercomputer Interconnects](https://arxiv.org/abs/2511.05149)
*Cristina Olmedilla,Jesus Escudero-Sahuquillo,Pedro J. Garcia,Francisco J. Quiles,Jose Duato*

Main category: cs.NI

TL;DR: 本文重新审视DCQCN拥塞控制机制，改进其设计以实现更精确的拥塞检测、信号传递和注入节流，减少控制流量开销并避免对非拥塞流的不必要节流。


<details>
  <summary>Details</summary>
Motivation: 随着超级计算机和数据中心的发展，互连网络成为关键组件。当前应用产生大量通信操作，拥塞严重威胁网络性能。虽然DCQCN等拥塞控制技术已被广泛使用，但其核心机制在拥塞检测、通知和反应方面基本未变，无法适应当前高性能互连网络的拥塞动态。

Method: 重新审视DCQCN闭环机制，改进其设计以利用更准确的拥塞检测、信号传递和注入节流。

Result: 通过改进设计，实现了更精确的拥塞控制，减少了控制流量开销，并避免了对非拥塞流的不必要节流。

Conclusion: 对DCQCN机制的重新设计和改进能够更好地应对当前高性能互连网络中的拥塞挑战，提升网络性能。

Abstract: Over the past decade, Supercomputers and Data centers have evolved
dramatically to cope with the increasing performance requirements of
applications and services, such as scientific computing, generative AI, social
networks or cloud services. This evolution have led these systems to
incorporate high-speed networks using faster links, end nodes using multiple
and dedicated accelerators, or a advancements in memory technologies to bridge
the memory bottleneck. The interconnection network is a key element in these
systems and it must be thoroughly designed so it is not the bottleneck of the
entire system, bearing in mind the countless communication operations that
generate current applications and services. Congestion is serious threat that
spoils the interconnection network performance, and its effects are even more
dramatic when looking at the traffic dynamics and bottlenecks generated by the
communication operations mentioned above. In this vein, numerous congestion
control (CC) techniques have been developed to address congestion negative
effects. One popular example is Data Center Quantized Congestion Notification
(DCQCN), which allows congestion detection at network switch buffers, then
marking congesting packets and notifying about congestion to the sources, which
finally apply injection throttling of those packets contributing to congestion.
While DCQCN has been widely studied and improved, its main principles for
congestion detection, notification and reaction remain largely unchanged, which
is an important shortcoming considering congestion dynamics in current
high-performance interconnection networks. In this paper, we revisit the DCQCN
closed-loop mechanism and refine its design to leverage a more accurate
congestion detection, signaling, and injection throttling, reducing control
traffic overhead and avoiding unnecessary throttling of non-congesting flows.

</details>


### [4] [EPFL-REMNet: Efficient Personalized Federated Digital Twin Towards 6G Heterogeneous Radio Environme](https://arxiv.org/abs/2511.05238)
*Peide Li,Liu Cao,Lyutianyang Zhang,Dongyu Wei,Ye Hu,Qipeng Xie*

Main category: cs.NI

TL;DR: EPFL-REMNet是一个高效的个性化联邦学习框架，用于构建6G异构无线电环境的高保真数字孪生，通过共享主干+轻量个性化头的模型设计，在非独立同分布数据条件下显著提升精度和通信效率。


<details>
  <summary>Details</summary>
Motivation: 标准联邦学习在B5G/6G异构无线电环境地图构建中面临非独立同分布数据导致的性能下降和通信效率问题，需要新的解决方案。

Method: 采用"共享主干+轻量个性化头"模型架构，仅传输压缩的共享主干，个性化头在客户端本地维护，在三种不同复杂度的非独立同分布场景下进行测试。

Result: 在所有非独立同分布设置中同时实现了更高的数字孪生保真度和更低的上行开销，显著减少了数据集间的性能差异，提升了长尾客户端的本地地图精度。

Conclusion: EPFL-REMNet框架有效提升了6G异构无线电环境数字孪生的整体完整性，在非独立同分布条件下优于标准FedAvg和最先进方法。

Abstract: Radio Environment Map (REM) is transitioning from 5G homogeneous environments
to B5G/6G heterogeneous landscapes. However, standard Federated Learning (FL),
a natural fit for this distributed task, struggles with performance degradation
in accuracy and communication efficiency under the non-independent and
identically distributed (Non-IID) data conditions inherent to these new
environments. This paper proposes EPFL-REMNet, an efficient personalized
federated framework for constructing a high-fidelity digital twin of the 6G
heterogeneous radio environment. The proposed EPFL-REMNet employs a"shared
backbone + lightweight personalized head" model, where only the compressed
shared backbone is transmitted between the server and clients, while each
client's personalized head is maintained locally. We tested EPFL-REMNet by
constructing three distinct Non-IID scenarios (light, medium, and heavy) based
on radio environment complexity, with data geographically partitioned across 90
clients. Experimental results demonstrate that EPFL-REMNet simultaneously
achieves higher digital twin fidelity (accuracy) and lower uplink overhead
across all Non-IID settings compared to standard FedAvg and recent
state-of-the-art methods. Particularly, it significantly reduces performance
disparities across datasets and improves local map accuracy for long-tail
clients, enhancing the overall integrity of digital twin.

</details>


### [5] [A Formal Model for Path Set Attribute Calculation in Network Systems](https://arxiv.org/abs/2511.05334)
*Giovanni Fiaschi,Carlo Vitucci,Thomas Westerbäck,Daniel Sundmark,Thomas Nolte*

Main category: cs.NI

TL;DR: 本文提出了一种数学方法来评估路径集合的特性，强调路径特征取决于所考虑的属性，特别是在分析多路径集合时尤为重要。


<details>
  <summary>Details</summary>
Motivation: 在图论和网络应用中，路径选择问题很重要。虽然已有研究对单一路径进行了全面评估，但在考虑路径集合时缺乏同等详细的分析。路径特征强烈依赖于所考虑的特性，这在分析多路径集合时变得尤为关键。

Method: 提出了一种数学方法，定义了一个函数模型，该模型能够很好地表征路径集合的一般形式。该函数模型可以具体化特定属性。

Result: 论文展示了函数模型如何将特定属性具体化，为路径集合的特征分析提供了数学框架。

Conclusion: 通过定义函数模型，本文为路径集合的特征分析提供了通用的数学方法，能够适应不同属性的具体需求。

Abstract: In graph theory and its practical networking applications, e.g.,
telecommunications and transportation, the problem of finding paths has
particular importance. Selecting paths requires giving scores to the
alternative solutions to drive a choice. While previous studies have provided
comprehensive evaluation of single-path solutions, the same level of detail is
lacking when considering sets of paths. This paper emphasizes that the path
characterization strongly depends on the properties under consideration. While
property-based characterization is also valid for single paths, it becomes
crucial to analyse multiple path sets. From the above consideration, this paper
proposes a mathematical approach, defining a functional model that lends itself
well to characterizing the path set in its general formulation. The paper shows
how the functional model contextualizes specific attributes.

</details>


### [6] [To Squelch or not to Squelch: Enabling Improved Message Dissemination on the XRP Ledger](https://arxiv.org/abs/2511.05362)
*Lucian Trestioreanu,Flaviene Scheidt,Wazen Shbair,Jerome Francois,Damien Magoni,Radu State*

Main category: cs.NI

TL;DR: 评估XRP账本网络中Squelching机制在现实场景中的效果，并与基于命名数据网络和gossip方法的替代方案进行比较


<details>
  <summary>Details</summary>
Motivation: 随着区块链技术采用率大幅增长，底层P2P网络需要相应扩展。现有研究主要关注PoW区块链，而共识验证型区块链（如XRP账本）的通信效率问题尚未充分研究

Method: 使用真实可控测试床和XRPL生产网络评估Squelching机制，并与基于命名数据网络和gossip方法的替代方案进行对比

Result: 未在摘要中明确说明具体结果

Conclusion: 通过实际测试评估Squelching机制的有效性，为XRP账本网络扩展性提供实证依据

Abstract: With the large increase in the adoption of blockchain technologies, their
underlying peer-to-peer networks must also scale with the demand. In this
context, previous works highlighted the importance of ensuring efficient and
resilient communication for the underlying consensus and replication
mechanisms. However, they were mainly focused on mainstream,
Proof-of-Work-based Distributed Ledger Technologies like Bitcoin or Ethereum.
  In this paper, the problem is investigated in the context of
consensus-validation based blockchains, like the XRP Ledger. The latter relies
on a Federated Byzantine Agreement (FBA) consensus mechanism which is proven to
have a good scalability in regards to transaction throughput. However, it is
known that significant increases in the size of the XRP Ledger network would be
challenging to achieve. The main reason is the flooding mechanism used to
disseminate the messages related to the consensus protocol, which creates many
duplicates in the network. Squelching is a recent solution proposed for
limiting this duplication, however, it was never evaluated quantitatively in
real-life scenarios involving the XRPL production network. In this paper, our
aim is to assess this mechanism using a real-life controllable testbed and the
XRPL production network, to assess its benefit and compare it to alternative
solutions relying on Named Data Networking and on a gossip-based approach.

</details>


### [7] [Scanning the IPv6 Internet Using Subnet-Router Anycast Probing](https://arxiv.org/abs/2511.05423)
*Maynard Koch,Raphael Hiesgen,Marcin Nawrocki,Thomas C. Schmidt,Matthias Wählisch*

Main category: cs.NI

TL;DR: 本文提出使用主动子网路由器任播(SRA)探测来探索IPv6地址空间，相比随机探测能发现多10%的路由器IP地址，比直接探测路由器地址多发现80%地址，且受ICMP速率限制影响更小。


<details>
  <summary>Details</summary>
Motivation: IPv6活跃地址识别具有挑战性，现有方法包括命中列表、新探测技术和AI生成目标列表等，但子网路由器任播(SRA)探测这一常用但未被充分利用的方法值得探索。

Method: 应用主动子网路由器任播(SRA)探测技术，并与先前方法获得的活跃IPv6节点列表以及随机探测结果进行比较。

Result: SRA探测相比随机探测平均多发现10%的路由器IP地址，相比直接探测路由器地址多发现80%地址，且受ICMP速率限制影响显著更小。

Conclusion: SRA探测是IPv6测量工具箱的重要补充，可显著提高结果稳定性。同时发现某些主动扫描可能对当前IPv6部署造成有害条件，已开始与网络运营商合作修复。

Abstract: Identifying active IPv6 addresses is challenging. Various methods emerged to
master the measurement challenge in this huge address space, including
hitlists, new probing techniques, and AI-generated target lists. In this paper,
we apply active Subnet-Router anycast (SRA) probing, a commonly unused method
to explore the IPv6 address space. We compare our results with lists of active
IPv6 nodes obtained from prior methods and with random probing. Our findings
indicate that probing an SRA address reveals on average 10% more router IP
addresses than random probing and is far less affected by ICMP rate limiting.
Compared to targeting router addresses directly, SRA probing discovers 80% more
addresses. We conclude that SRA probing is an important addition to the IPv6
measurement toolbox and may improve the stability of results significantly. We
also find evidence that some active scans can cause harmful conditions in
current IPv6 deployments, which we started to fix in collaboration with network
operators.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024](https://arxiv.org/abs/2511.04685)
*Daniela Guericke,Rolf van der Hulst,Asal Karimpour,Ieke Schrader,Matthias Walter*

Main category: cs.AI

TL;DR: 团队Twente在2024年综合医疗排班竞赛中获得第三名，采用混合整数规划、约束规划和模拟退火的3阶段分解方法


<details>
  <summary>Details</summary>
Motivation: 解决医疗排班优化问题，参与2024年综合医疗排班竞赛，开发高效的排班算法

Method: 结合混合整数规划、约束规划和模拟退火的3阶段分解方法，将问题分解为子问题求解

Result: 在竞赛中获得第三名，首次提供了基准实例的最优解下界

Conclusion: 该方法有效但仍有改进空间，指出了未来可以进一步优化的开放性问题

Abstract: We report about the algorithm, implementation and results submitted to the
Integrated Healthcare Timetabling Competition 2024 by Team Twente, which scored
third in the competition. Our approach combines mixed-integer programming,
constraint programming and simulated annealing in a 3-phase solution approach
based on decomposition into subproblems. Next to describing our approach and
describing our design decisions, we share our insights and, for the first time,
lower bounds on the optimal solution values for the benchmark instances. We
finally highlight open problems for which we think that addressing them could
improve our approach even further.

</details>


### [9] [Epistemic Reject Option Prediction](https://arxiv.org/abs/2511.04855)
*Vojtech Franc,Jakub Paplham*

Main category: cs.AI

TL;DR: 本文提出了一种基于认知不确定性的拒绝选项预测器，当训练数据不足导致认知不确定性较高时，模型可以拒绝预测，以最小化期望遗憾。


<details>
  <summary>Details</summary>
Motivation: 传统拒绝选项方法只关注随机不确定性，假设训练数据充足使得认知不确定性可忽略。但在实际应用中，数据有限使得这一假设不成立，需要同时考虑认知不确定性。

Method: 基于贝叶斯学习，重新定义最优预测器为最小化期望遗憾的模型。当输入导致的遗憾超过指定拒绝成本时，模型拒绝预测。

Result: 这是第一个原则性框架，能够学习识别训练数据不足以做出可靠决策的输入。

Conclusion: 提出的认知拒绝选项预测器能够有效处理数据不足导致的认知不确定性，提高高风险应用中的预测可靠性。

Abstract: In high-stakes applications, predictive models must not only produce accurate
predictions but also quantify and communicate their uncertainty. Reject-option
prediction addresses this by allowing the model to abstain when prediction
uncertainty is high. Traditional reject-option approaches focus solely on
aleatoric uncertainty, an assumption valid only when large training data makes
the epistemic uncertainty negligible. However, in many practical scenarios,
limited data makes this assumption unrealistic. This paper introduces the
epistemic reject-option predictor, which abstains in regions of high epistemic
uncertainty caused by insufficient data. Building on Bayesian learning, we
redefine the optimal predictor as the one that minimizes expected regret -- the
performance gap between the learned model and the Bayes-optimal predictor with
full knowledge of the data distribution. The model abstains when the regret for
a given input exceeds a specified rejection cost. To our knowledge, this is the
first principled framework that enables learning predictors capable of
identifying inputs for which the training data is insufficient to make reliable
decisions.

</details>


### [10] [DMA: Online RAG Alignment with Human Feedback](https://arxiv.org/abs/2511.04880)
*Yu Bai,Yukai Miao,Dawei Wang,Li Chen,Fei Long,Rundi Zhai,Dan Li,Yanyu Ren,Tianfeng Liu,Hongtao Xie,Ce Yang,Xuhui Cai*

Main category: cs.AI

TL;DR: DMA是一个在线学习框架，通过整合多粒度人类反馈来动态调整RAG系统的检索排序，在保持基础检索能力的同时显著提升对话问答性能。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统依赖静态检索，无法适应意图演变和内容漂移，需要动态调整机制来提升交互性能。

Method: DMA将文档级、列表级和响应级信号整合到统一学习流程中：监督训练点对点和列表排序器，基于响应级偏好的策略优化，以及知识蒸馏到轻量级评分器。

Result: 在线部署显示人类参与度显著提升，离线测试在TriviaQA和HotpotQA等对话问答任务上取得明显改进，同时保持基础检索竞争力。

Conclusion: DMA为RAG系统提供了基于反馈的实时自适应方法，在不牺牲基础能力的前提下实现性能提升。

Abstract: Retrieval-augmented generation (RAG) systems often rely on static retrieval,
limiting adaptation to evolving intent and content drift. We introduce Dynamic
Memory Alignment (DMA), an online learning framework that systematically
incorporates multi-granularity human feedback to align ranking in interactive
settings. DMA organizes document-, list-, and response-level signals into a
coherent learning pipeline: supervised training for pointwise and listwise
rankers, policy optimization driven by response-level preferences, and
knowledge distillation into a lightweight scorer for low-latency serving.
Throughout this paper, memory refers to the model's working memory, which is
the entire context visible to the LLM for In-Context Learning.
  We adopt a dual-track evaluation protocol mirroring deployment: (i)
large-scale online A/B ablations to isolate the utility of each feedback
source, and (ii) few-shot offline tests on knowledge-intensive benchmarks.
Online, a multi-month industrial deployment further shows substantial
improvements in human engagement. Offline, DMA preserves competitive
foundational retrieval while yielding notable gains on conversational QA
(TriviaQA, HotpotQA). Taken together, these results position DMA as a
principled approach to feedback-driven, real-time adaptation in RAG without
sacrificing baseline capability.

</details>


### [11] [Real-Time Reasoning Agents in Evolving Environments](https://arxiv.org/abs/2511.04898)
*Yule Wen,Yixin Ye,Yanzhe Zhang,Diyi Yang,Hao Zhu*

Main category: cs.AI

TL;DR: 提出了实时推理作为动态环境中智能体的新问题框架，构建了Real-Time Reasoning Gym进行验证，并开发了AgileThinker方法同时结合反应式和规划式推理范式，在时间压力下实现更好的性能平衡。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的智能体需要在动态环境中同时做出逻辑和及时的判断，而现有语言模型推理方法未能充分考虑环境的动态特性。

Method: 研究了两种语言模型部署范式：反应式智能体（有限推理计算快速响应）和规划式智能体（扩展推理计算处理复杂问题），并提出了AgileThinker方法同时结合两种推理范式。

Result: 实验表明即使最先进的模型在单一推理范式下也难以同时满足逻辑性和及时性要求，而AgileThinker在任务难度和时间压力增加时持续优于单一范式智能体。

Conclusion: 实时推理是开发实用智能体的关键测试平台，为时间约束AI系统研究提供了基础，指明了实现实时能力智能体的路径。

Abstract: Agents in the real world must make not only logical but also timely
judgments. This requires continuous awareness of the dynamic environment:
hazards emerge, opportunities arise, and other agents act, while the agent's
reasoning is still unfolding. Despite advances in language model reasoning,
existing approaches fail to account for this dynamic nature. We introduce
real-time reasoning as a new problem formulation for agents in evolving
environments and build Real-Time Reasoning Gym to demonstrate it. We study two
paradigms for deploying language models in agents: (1) reactive agents, which
employ language models with bounded reasoning computation for rapid responses,
and (2) planning agents, which allow extended reasoning computation for complex
problems. Our experiments show that even state-of-the-art models struggle with
making logical and timely judgments in either paradigm. To address this
limitation, we propose AgileThinker, which simultaneously engages both
reasoning paradigms. AgileThinker consistently outperforms agents engaging only
one reasoning paradigm as the task difficulty and time pressure rise,
effectively balancing reasoning depth and response latency. Our work
establishes real-time reasoning as a critical testbed for developing practical
agents and provides a foundation for research in temporally constrained AI
systems, highlighting a path toward real-time capable agents.

</details>


### [12] [ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property](https://arxiv.org/abs/2511.04956)
*Maria Mahbub,Vanessa Lama,Sanjay Das,Brian Starks,Christopher Polchek,Saffell Silvers,Lauren Deck,Prasanna Balaprakash,Tirthankar Ghosal*

Main category: cs.AI

TL;DR: ORCHID是一个模块化的智能代理系统，用于美国能源部高风险财产分类，结合检索增强生成和人工监督，提高分类准确性和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 传统的高风险财产分类工作流程依赖专家，耗时长、易积压，难以跟上不断变化的法规边界。需要透明、可审计的决策系统来应对敏感的出口管制政策。

Method: 采用模块化代理架构，包括检索、描述精炼、分类器、验证器和反馈记录器等小型协作代理，通过代理间消息传递协调，使用模型上下文协议实现模型无关的本地操作。

Result: 在真实高风险财产案例的初步测试中，ORCHID相比非代理基线提高了准确性和可追溯性，同时将不确定项目转交给领域专家处理。

Conclusion: ORCHID展示了一条在敏感能源部合规工作流程中实现可信赖大语言模型辅助的实际路径，支持单项目提交、基于证据的引用、专家反馈捕获和可导出的审计工件。

Abstract: High-Risk Property (HRP) classification is critical at U.S. Department of
Energy (DOE) sites, where inventories include sensitive and often dual-use
equipment. Compliance must track evolving rules designated by various export
control policies to make transparent and auditable decisions. Traditional
expert-only workflows are time-consuming, backlog-prone, and struggle to keep
pace with shifting regulatory boundaries. We demo ORCHID, a modular agentic
system for HRP classification that pairs retrieval-augmented generation (RAG)
with human oversight to produce policy-based outputs that can be audited. Small
cooperating agents, retrieval, description refiner, classifier, validator, and
feedback logger, coordinate via agent-to-agent messaging and invoke tools
through the Model Context Protocol (MCP) for model-agnostic on-premise
operation. The interface follows an Item to Evidence to Decision loop with
step-by-step reasoning, on-policy citations, and append-only audit bundles
(run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID
improves accuracy and traceability over a non-agentic baseline while deferring
uncertain items to Subject Matter Experts (SMEs). The demonstration shows
single item submission, grounded citations, SME feedback capture, and
exportable audit artifacts, illustrating a practical path to trustworthy LLM
assistance in sensitive DOE compliance workflows.

</details>


### [13] [Autonomous generation of different courses of action in mechanized combat operations](https://arxiv.org/abs/2511.05182)
*Johan Schubert,Patrik Hansen,Pontus Hörling,Ronnie Johansson*

Main category: cs.AI

TL;DR: 提出了一种支持军事地面作战决策的方法论，通过生成和评估数千个行动方案，为机械化营提供推荐建议，并在战斗过程中动态调整方案。


<details>
  <summary>Details</summary>
Motivation: 为军事地面作战执行阶段的决策提供支持，特别是在机械化营的行动规划方面，需要系统化的方法来生成和评估各种行动方案。

Method: 从初始行动方案集开始，系统生成数千个个体行动替代方案，结合对手状态和行动进行评估，考虑部队组成、兵力比率、攻防类型和预期推进率等因素，使用野战手册评估战斗结果和推进率。

Result: 该方法能够产生具有更优结果的替代行动方案，并在战斗过程中根据条件变化动态制定修订方案，为决策者提供多样化的选择。

Conclusion: 该决策支持方法能够有效管理新行动方案的生成和评估，在顺序决策框架内为军事指挥官提供持续优化的行动建议。

Abstract: In this paper, we propose a methodology designed to support decision-making
during the execution phase of military ground combat operations, with a focus
on one's actions. This methodology generates and evaluates recommendations for
various courses of action for a mechanized battalion, commencing with an
initial set assessed by their anticipated outcomes. It systematically produces
thousands of individual action alternatives, followed by evaluations aimed at
identifying alternative courses of action with superior outcomes. These
alternatives are appraised in light of the opponent's status and actions,
considering unit composition, force ratios, types of offense and defense, and
anticipated advance rates. Field manuals evaluate battle outcomes and
advancement rates. The processes of generation and evaluation work
concurrently, yielding a variety of alternative courses of action. This
approach facilitates the management of new course generation based on
previously evaluated actions. As the combat unfolds and conditions evolve,
revised courses of action are formulated for the decision-maker within a
sequential decision-making framework.

</details>


### [14] [Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance](https://arxiv.org/abs/2511.05311)
*Valeriu Dimidov,Faisal Hawlader,Sasan Jafarnejad,Raphaël Frank*

Main category: cs.AI

TL;DR: LLM-based agents can effectively support predictive maintenance data cleaning pipelines，特别是处理维护日志中的常见错误，如拼写错误、缺失字段、近似重复条目和错误日期。


<details>
  <summary>Details</summary>
Motivation: 汽车行业预测性维护面临经济约束、数据集可用性有限和专业人才短缺等挑战，LLM的进展为克服这些障碍提供了机会。

Method: 评估LLM代理在六种不同类型噪声的清理任务中的表现，重点关注维护日志这一关键数据源。

Result: LLM在处理通用清理任务方面表现有效，为未来工业应用提供了有前景的基础。

Conclusion: 虽然领域特定错误仍具挑战性，但通过专门训练和增强代理能力，LLM在预测性维护数据清理方面具有进一步改进的潜力。

Abstract: Economic constraints, limited availability of datasets for reproducibility
and shortages of specialized expertise have long been recognized as key
challenges to the adoption and advancement of predictive maintenance (PdM) in
the automotive sector. Recent progress in large language models (LLMs) presents
an opportunity to overcome these barriers and speed up the transition of PdM
from research to industrial practice. Under these conditions, we explore the
potential of LLM-based agents to support PdM cleaning pipelines. Specifically,
we focus on maintenance logs, a critical data source for training
well-performing machine learning (ML) models, but one often affected by errors
such as typos, missing fields, near-duplicate entries, and incorrect dates. We
evaluate LLM agents on cleaning tasks involving six distinct types of noise.
Our findings show that LLMs are effective at handling generic cleaning tasks
and offer a promising foundation for future industrial applications. While
domain-specific errors remain challenging, these results highlight the
potential for further improvements through specialized training and enhanced
agentic capabilities.

</details>


### [15] [Reasoning Is All You Need for Urban Planning AI](https://arxiv.org/abs/2511.05375)
*Sijie Yang,Jiatong Li,Filip Biljecki*

Main category: cs.AI

TL;DR: 提出了一个基于推理能力的城市规划AI框架，整合认知层和逻辑组件，通过多智能体协作实现价值导向、规则约束和可解释的规划决策。


<details>
  <summary>Details</summary>
Motivation: 传统AI在城市规划分析中已很成功，但需要进一步发展AI辅助决策能力，让智能体能够推荐场地、分配资源、评估权衡，并透明地推理约束条件和利益相关者价值。

Method: 提出了Agentic Urban Planning AI框架，包含三个认知层（感知、基础、推理）和六个逻辑组件（分析、生成、验证、评估、协作、决策），通过多智能体协作框架实现。

Result: 框架展示了规划决策需要具备基于价值的推理能力、规则约束的保证和可解释的论证能力，这些是纯统计学习方法无法满足的要求。

Conclusion: 该框架表明AI智能体可以通过系统探索解决方案空间、验证法规合规性和透明地权衡利弊来增强人类规划师的能力，不是取代人类判断，而是用计算推理能力来放大它。

Abstract: AI has proven highly successful at urban planning analysis -- learning
patterns from data to predict future conditions. The next frontier is
AI-assisted decision-making: agents that recommend sites, allocate resources,
and evaluate trade-offs while reasoning transparently about constraints and
stakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,
ReAct, and multi-agent collaboration frameworks -- now make this vision
achievable.
  This position paper presents the Agentic Urban Planning AI Framework for
reasoning-capable planning agents that integrates three cognitive layers
(Perception, Foundation, Reasoning) with six logic components (Analysis,
Generation, Verification, Evaluation, Collaboration, Decision) through a
multi-agents collaboration framework. We demonstrate why planning decisions
require explicit reasoning capabilities that are value-based (applying
normative principles), rule-grounded (guaranteeing constraint satisfaction),
and explainable (generating transparent justifications) -- requirements that
statistical learning alone cannot fulfill. We compare reasoning agents with
statistical learning, present a comprehensive architecture with benchmark
evaluation metrics, and outline critical research challenges. This framework
shows how AI agents can augment human planners by systematically exploring
solution spaces, verifying regulatory compliance, and deliberating over
trade-offs transparently -- not replacing human judgment but amplifying it with
computational reasoning capabilities.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [16] [Sharing Intelligent Reflecting Surfaces in Multi-Operator Communication Systems for Sustainable 6G Networks](https://arxiv.org/abs/2511.04969)
*Hiroaki Hashida,Yuichi Kawamoto,Nei Kato*

Main category: cs.IT

TL;DR: 本研究提出了一种多运营商共享智能反射面(IRS)系统，通过协作使用公共IRS基础设施来解决6G网络中毫米波覆盖限制和高成本问题，在性能与公平性方面优于运营商专用部署方法。


<details>
  <summary>Details</summary>
Motivation: 解决6G网络中毫米波频率覆盖范围有限和当前技术基础设施成本高的两大挑战，同时避免为每个移动网络运营商单独部署IRS导致的效率低下、基础设施冗余、位置冲突和运营商间干扰问题。

Method: 提出多运营商IRS共享系统，多个移动网络运营商协作使用共同的IRS基础设施，通过数值分析验证该方法在性能和公平性方面的表现。

Result: 数值分析表明，IRS共享在多运营商场景中有效平衡了性能与公平性，优于运营商专用部署方法。

Conclusion: IRS共享具有支持可持续6G网络的潜力，有助于下一代无线通信系统的高效部署和运营。

Abstract: In this study, we investigate the use of intelligent reflecting surfaces
(IRSs) in multi-operator communication systems for 6G networks, focusing on
sustainable and efficient resource management. This research is motivated by
two critical challenges: limited coverage provided by mmWave frequencies and
high infrastructure costs associated with current technologies. IRSs can help
eliminate these issues because they can reflect electromagnetic waves to
enhance signal propagation, thereby reducing blockages and extending network
coverage. However, deploying a separate IRS for each mobile network operator
(MNO) can result in inefficiencies, redundant infrastructure, potential
conflicts over placement, and interoperator interference. To address these
challenges, in this study, an IRS sharing system is proposed in which multiple
MNOs collaborate to use a common IRS infrastructure. This approach not only
enhances network flexibility and reduces costs but also minimizes the effect of
interoperator interference. Through numerical analysis, we demonstrate that IRS
sharing effectively balances performance and fairness among MNOs, outperforming
MNO-specific deployment methods in multi-MNO scenarios. This study provides
insights into the potential of IRS sharing to support sustainable 6G networks,
thereby contributing to the efficient deployment and operation of
next-generation wireless communication systems.

</details>


### [17] [Adjoint and duality for rank-metric codes in a skew polynomial framework](https://arxiv.org/abs/2511.05084)
*José Gómez-Torrecillas,F. J. Lobillo,Gabriel Navarro,Paolo Santonastaso*

Main category: cs.IT

TL;DR: 本文系统研究了斜多项式环商中的转置和对偶运算，为Sheekey等人提出的最大秩距离码族提供了明确的斜多项式描述，并证明了这些码与已知构造的不等价性。


<details>
  <summary>Details</summary>
Motivation: 斜多项式环商在秩度量码理论中起着核心作用，最近的突破表明这些环的特定子集产生了最大的最大秩距离码族。需要系统研究这些商环中的转置和对偶运算。

Method: 开发了转置码和对偶码构造的显式斜多项式描述，计算了这些码的核参数，并证明了参数不等价性。

Result: 确定了Sheekey等人引入的MRD码族的伴随码和对偶码，证明了对于新的无限参数集，这些MRD码与文献中已知构造不等价。

Conclusion: 通过斜多项式描述成功分析了MRD码的转置和对偶结构，为秩度量码理论提供了新的不等价码族构造。

Abstract: Skew polynomial rings provide a fundamental example of noncommutative
principal ideal domains. Special quotients of these rings yield matrix algebras
that play a central role in the theory of rank-metric codes. Recent
breakthroughs have shown that specific subsets of these quotients produce the
largest known families of maximum rank distance (MRD) codes. In this work, we
present a systematic study of transposition and duality operations within
quotients of skew polynomial rings. We develop explicit skew-polynomial
descriptions of the transpose and dual code constructions, enabling us to
determine the adjoint and dual codes associated with the MRD code families
recently introduced by Sheekey et al. Building on these results, we compute the
nuclear parameters of these codes, and prove that, for a new infinite set of
parameters, many of these MRD codes are inequivalent to previously known
constructions in the literature.

</details>


### [18] [Entropy-Rank Ratio: A Novel Entropy-Based Perspective for DNA Complexity and Classification](https://arxiv.org/abs/2511.05300)
*Emmanuel Pio Pastore,Giuseppe Passarino,Peppino Sapia,Francesco De Rango*

Main category: cs.IT

TL;DR: 提出了一种新的DNA序列复杂度度量指标——熵秩比R，通过计算目标序列在相同长度所有可能序列熵值分布中的相对位置来避免香农熵的饱和问题，并将其应用于数据增强提升CNN分类性能。


<details>
  <summary>Details</summary>
Motivation: 香农熵在测量DNA序列复杂度时存在饱和效应，限制了其对长均匀片段的区分能力，需要一种分布感知的归一化度量方法。

Method: 将DNA序列划分为固定长度的子序列和非重叠n-mer组，使用组合框架推导完整的熵分布，计算目标序列在全局熵谱中的相对位置得到熵秩比R，并基于R提出比率引导的裁剪技术用于数据增强。

Result: 在两个独立数据集（病毒基因和人类基因多核苷酸扩展）上，通过R增强的模型使用极轻量架构实现了分类准确率的显著提升。

Conclusion: 熵秩比R是一种有效的DNA序列复杂度度量方法，能够避免饱和问题，并通过数据增强显著提升深度学习模型的分类性能。

Abstract: Shannon entropy is widely used to measure the complexity of DNA sequences but
suffers from saturation effects that limit its discriminative power for long
uniform segments. We introduce a novel metric, the entropy rank ratio R, which
positions a target sequence within the full distribution of all possible
sequences of the same length by computing the proportion of sequences that have
an entropy value equal to or lower than that of the target. In other words, R
expresses the relative position of a sequence within the global entropy
spectrum, assigning values close to 0 for highly ordered sequences and close to
1 for highly disordered ones. DNA sequences are partitioned into fixed-length
subsequences and non-overlapping n-mer groups; frequency vectors become ordered
integer partitions and a combinatorial framework is used to derive the complete
entropy distribution. Unlike classical measures, R is a normalized,
distribution-aware measure bounded in [0,1] at fixed (T,n), which avoids
saturation to log2 4 and makes values comparable across sequences under the
same settings. We integrate R into data augmentation for convolutional neural
networks by proposing ratio-guided cropping techniques and benchmark them
against random, entropy-based, and compression-based methods. On two
independent datasets, viral genes and human genes with polynucleotide
expansions, models augmented via R achieve substantial gains in classification
accuracy using extremely lightweight architectures.

</details>


### [19] [Shortest self-orthogonal embeddings of binary linear codes](https://arxiv.org/abs/2511.05440)
*Junmin An,Nathan Kaplan,Jon-Lark Kim,Jinquan Luo,Guodong Wang*

Main category: cs.IT

TL;DR: 本文研究二进制线性码的最短自正交嵌入问题，利用码的hull性质来确定最短自正交嵌入长度，重点关注汉明码和Reed-Muller码，并提出了从汉明码构造自对偶码的算法。


<details>
  <summary>Details</summary>
Motivation: 研究二进制线性码的最短自正交嵌入问题，因为许多这样的码是最优自正交码，且自正交嵌入在编码理论中具有重要应用价值。

Method: 使用码的hull性质来确定最短自正交嵌入长度，提出了两种从汉明码构造自对偶码的算法，并利用最短自正交嵌入构造最优自正交码。

Result: 从二进制[15,11,3]汉明码构造了自对偶[22,11,6]码（缩短Golay码），从[31,26,3]汉明码构造了自对偶[52,26,8]码，并获得了多个维度为7和8的最优自正交码，其中四个码具有新参数。

Conclusion: 通过研究码的hull性质和最短自正交嵌入，成功构造了多个自对偶码和最优自正交码，为编码理论提供了新的构造方法和参数。

Abstract: There has been recent interest in the study of shortest self-orthogonal
embeddings of binary linear codes, since many such codes are optimal
self-orthogonal codes. Several authors have studied the length of a shortest
self-orthogonal embedding of a given binary code $\mathcal C$, or equivalently,
the minimum number of columns that must be added to a generator matrix of
$\mathcal C$ to form a generator matrix of a self-orthogonal code. In this
paper, we use properties of the hull of a linear code to determine the length
of a shortest self-orthogonal embedding of any binary linear code. We focus on
the examples of Hamming codes and Reed-Muller codes. We show that a shortest
self-orthogonal embedding of a binary Hamming code is self-dual, and propose
two algorithms to construct self-dual codes from Hamming codes $\mathcal H_r$.
Using these algorithms, we construct a self-dual $[22, 11, 6]$ code, called the
shortened Golay code, from the binary $[15, 11, 3]$ Hamming code $\mathcal
H_4$, and construct a self-dual $[52, 26, 8]$ code from the binary $[31, 26,
3]$ Hamming code $\mathcal H_5$. We use shortest SO embeddings of linear codes
to obtain many inequivalent optimal self-orthogonal codes of dimension $7$ and
$8$ for several lengths. Four of the codes of dimension $8$ that we construct
are codes with new parameters such as $[91, 8, 42],\, [98, 8, 46],\,[114, 8,
54]$, and $[191, 8, 94]$.

</details>
