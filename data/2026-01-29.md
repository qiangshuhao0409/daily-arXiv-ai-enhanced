<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 3]
- [cs.AI](#cs.AI) [Total: 25]
- [cs.IT](#cs.IT) [Total: 10]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Proactive SFC Provisioning with Forecast-Driven DRL in Data Centers](https://arxiv.org/abs/2601.20229)
*Parisa Fard Moshiri,Poonam Lohan,Burak Kantarci,Emil Janulewicz*

Main category: cs.NI

TL;DR: 提出混合预测驱动的深度强化学习框架，结合预测智能与SFC配置，通过集成预测模型实现主动资源分配，显著提升服务接受率并降低端到端延迟。


<details>
  <summary>Details</summary>
Motivation: 传统静态资源分配在动态流量负载和应用需求下容易导致资源过度配置或不足，无法满足数据中心中服务功能链对高效虚拟网络功能放置的需求。

Method: 使用深度强化学习生成数据中心资源利用和服务需求数据集，训练深度学习预测模型，通过Optuna超参数优化选择最佳模型（时空图神经网络、时序图神经网络、LSTM）构建集成模型，将预测结果整合到数据中心选择过程中。

Result: 显著提升资源密集型服务（云游戏、VoIP）的接受率，延迟敏感服务（增强现实从30%提升至50%，工业4.0从30%提升至45%），端到端延迟显著降低（VoIP降低20.5%，视频流降低23.8%，云游戏降低34.8%）。

Conclusion: 提出的预测驱动框架能够实现更平衡的资源分配，减少资源争用，通过考虑当前和未来资源可用性做出主动放置决策，有效提升数据中心资源利用效率。

Abstract: Service Function Chaining (SFC) requires efficient placement of Virtual Network Functions (VNFs) to satisfy diverse service requirements while maintaining high resource utilization in Data Centers (DCs). Conventional static resource allocation often leads to overprovisioning or underprovisioning due to the dynamic nature of traffic loads and application demands. To address this challenge, we propose a hybrid forecast-driven Deep reinforcement learning (DRL) framework that combines predictive intelligence with SFC provisioning. Specifically, we leverage DRL to generate datasets capturing DC resource utilization and service demands, which are then used to train deep learning forecasting models. Using Optuna-based hyperparameter optimization, the best-performing models, Spatio-Temporal Graph Neural Network, Temporal Graph Neural Network, and Long Short-Term Memory, are combined into an ensemble to enhance stability and accuracy. The ensemble predictions are integrated into the DC selection process, enabling proactive placement decisions that consider both current and future resource availability. Experimental results demonstrate that the proposed method not only sustains high acceptance ratios for resource-intensive services such as Cloud Gaming and VoIP but also significantly improves acceptance ratios for latency-critical categories such as Augmented Reality increases from 30% to 50%, while Industry 4.0 improves from 30% to 45%. Consequently, the prediction-based model achieves significantly lower E2E latencies of 20.5%, 23.8%, and 34.8% reductions for VoIP, Video Streaming, and Cloud Gaming, respectively. This strategy ensures more balanced resource allocation, and reduces contention.

</details>


### [2] [Dependable Connectivity for Industrial Wireless Communication Networks](https://arxiv.org/abs/2601.20580)
*Nurul Huda Mahmood,Onel L. A. Lopez,David Ruiz-Guirola,Frank Burkhardt,Mehdi Rasti,Matti Latva-aho*

Main category: cs.NI

TL;DR: 该论文提出了一个面向6G工业无线通信网络的全面可靠性框架，涵盖理论基础、实践使能技术和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 工业无线通信网络需要高可靠性（包括安全性、可维护性等），而5G URLLC仅部分解决了这一问题。6G需要实现包含可靠性、可用性、安全性和安全性的全面可靠性。

Method: 1. 建立可靠性理论基础，包括关键属性和分析工具；2. 探索实践使能技术，如基于实时监控的自适应多址接入方案和时间敏感网络；3. 通过案例研究展示智能唤醒协议相比传统占空比循环的显著优势。

Result: 提出了一个全面的可靠性框架，并通过案例研究表明智能唤醒协议能将事件检测概率提高数个数量级。

Conclusion: 论文为6G驱动的可靠工业无线通信网络提供了理论框架和实践指导，并指出了未来的开放挑战和研究方向。

Abstract: Dependability - a system's ability to consistently provide reliable services by ensuring safety and maintainability in the face of internal or external disruptions - is a fundamental requirement for industrial wireless communication networks (IWCNs). While 5G ultra-reliable low-latency communication (URLLC) addresses some aspects of this challenge, its evolution toward holistic dependability in 6G must encompass reliability, availability, safety, and security. This paper provides a comprehensive framework for dependable IWCNs, bridging theory and practice. We first establish the theoretical foundations of dependability, including outlining its key attributes and presenting analytical tools to study it. Next, we explore practical enablers, such as adaptive multiple access schemes leveraging real-time monitoring and time-sensitive networking to ensure end-to-end determinism. A case study demonstrates how intelligent wake-up protocols improve event detection probability by orders of magnitude compared to conventional duty cycling. Finally, we outline open challenges and future directions for a 6G-driven dependable IWCN.

</details>


### [3] [Immersive Volumetric Video Playback: Near-RT Resource Allocation and O-RAN-based Implementation](https://arxiv.org/abs/2601.20625)
*Yao Wen,Luping Xiang,Kun Yang*

Main category: cs.NI

TL;DR: 基于O-RAN的沉浸式视频流播放框架，通过SAC算法联合优化无线、计算和内容资源，显著降低延迟并提升QoE


<details>
  <summary>Details</summary>
Motivation: 扩展现实(XR)中的沉浸式体视频流需要超低运动到光子(MTP)延迟，传统边缘计算架构难以满足，因为每帧计算密集的渲染与用户运动紧密耦合

Method: 提出O-RAN集成播放框架，在近实时控制循环中联合编排无线、计算和内容资源。将渲染像素比作为连续控制变量，在O-Cloud计算、gNB发射功率和带宽下联合优化，采用Weber-Fechner QoE模型平衡分辨率、计算和延迟。使用具有结构化动作分解和QoE感知奖励塑造的SAC算法解决高维控制问题

Result: 在5G O-RAN测试床和系统仿真中，SAC算法将中位数MTP延迟降低11%以上，同时提高平均QoE和公平性

Conclusion: RIC驱动的联合无线-计算-内容控制对于可扩展、延迟感知的沉浸式流媒体是可行的

Abstract: Immersive volumetric video streaming in extended reality (XR) demands ultra-low motion-to-photon (MTP) latency, which conventional edge-centric architectures struggle to meet due to per-frame computationally intensive rendering tightly coupled with user motion. To address this challenge, we propose an Open Radio Access Network (O-RAN)-integrated playback framework that jointly orchestrates radio, compute, and content resources in near real time (Near-RT) control loop. The system formulates the rendered-pixel ratio as a continuous control variable and jointly optimizes it over the Open Cloud (O-Cloud) compute, gNB transmit power, and bandwidth under a Weber-Fechner quality of experience (QoE) model, explicitly balancing resolution, computation, and latency. A Soft Actor-Critic (SAC) agent with structured action decomposition and QoE-aware reward shaping resolves the resulting high-dimensional control problem. Experiments on a 5G O-RAN testbed and system simulations show that SAC reduces median MTP latency by above $11\%$ and improves both mean QoE and fairness, demonstrating the feasibility of RIC-driven joint radio-compute-content control for scalable, latency-aware immersive streaming.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [4] [NeuroAI and Beyond](https://arxiv.org/abs/2601.19955)
*Jean-Marc Fellous,Gert Cauwenberghs,Cornelia Fermüller,Yulia Sandamisrkaya,Terrence Sejnowski*

Main category: cs.AI

TL;DR: 该论文基于2025年8月研讨会，探讨神经科学与人工智能的交叉领域，提出NeuroAI概念，旨在通过神经科学启发改进AI算法，同时深化对生物神经计算的理解。


<details>
  <summary>Details</summary>
Motivation: 神经科学与人工智能近年来各自取得显著进展，但两者之间的连接相对松散。论文旨在识别这两个领域当前和未来的协同潜力，促进更紧密的交叉融合。

Method: 基于2025年8月举办的研讨会，聚焦于具身认知、语言与通信、机器人学、人类与机器学习以及神经形态工程等子领域，分析现有进展并探索未来方向。收集了多位领先研究人员的个人观点，并附有研究人员和学员的SWOT分析。

Result: 提出了NeuroAI（神经科学启发的人工智能）概念框架，认为这种交叉方法既能显著提升AI算法的范围和效率，又能改变对生物神经计算的理解方式。通过SWOT分析评估了NeuroAI的益处和风险。

Conclusion: 倡导发展NeuroAI，通过神经科学与人工智能的深度融合，实现双向受益：AI从神经科学中获得灵感提升性能，神经科学则通过AI模型更好地理解生物神经系统。

Abstract: Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possible promising new future avenues. Overall, we advocate for the development of NeuroAI, a type of Neuroscience-informed Artificial Intelligence that, we argue, has the potential for significantly improving the scope and efficiency of AI algorithms while simultaneously changing the way we understand biological neural computations. We include personal statements from several leading researchers on their diverse views of NeuroAI. Two Strength-Weakness-Opportunities-Threat (SWOT) analyses by researchers and trainees are appended that describe the benefits and risks offered by NeuroAI.

</details>


### [5] [Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning](https://arxiv.org/abs/2601.20014)
*Shuhui Qu*

Main category: cs.AI

TL;DR: SQ-BCP是一种在部分可观测环境下进行推理时规划的方法，通过显式表示前提条件状态、针对性自我查询和桥接假设来解决LLM在缺失关键前提时的幻觉问题，使用双向搜索和基于拉回的验证器确保计划兼容性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理时规划中面临部分可观测性问题：当任务关键前提条件未在查询时指定时，模型容易产生幻觉或违反硬约束的计划。

Method: 提出自我查询双向分类规划(SQ-BCP)：1)显式表示前提条件状态(Sat/Viol/Unk)；2)通过针对性自我查询或桥接假设解决未知条件；3)执行双向搜索；4)使用基于拉回的验证器作为目标兼容性的分类证明；5)仅使用基于距离的分数进行排序和剪枝。

Result: 在WikiHow和RecipeNLG任务中，当预条件被保留时，SQ-BCP将资源违规率分别降低到14.9%和5.8%（最佳基线为26.0%和15.7%），同时保持竞争力的参考质量。

Conclusion: SQ-BCP通过显式处理部分可观测性，在保持计划质量的同时显著减少了约束违规，为LLM在现实世界规划任务中的可靠应用提供了理论保证和实践方法。

Abstract: Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\texttt{Sat}/\texttt{Viol}/\texttt{Unk}) and resolves unknowns via (i) targeted self-queries to an oracle/user or (ii) \emph{bridging} hypotheses that establish the missing condition through an additional action. SQ-BCP performs bidirectional search and invokes a pullback-based verifier as a categorical certificate of goal compatibility, while using distance-based scores only for ranking and pruning. We prove that when the verifier succeeds and hard constraints pass deterministic checks, accepted plans are compatible with goal requirements; under bounded branching and finite resolution depth, SQ-BCP finds an accepting plan when one exists. Across WikiHow and RecipeNLG tasks with withheld preconditions, SQ-BCP reduces resource-violation rates to \textbf{14.9\%} and \textbf{5.8\%} (vs.\ \textbf{26.0\%} and \textbf{15.7\%} for the best baseline), while maintaining competitive reference quality.

</details>


### [6] [Fuzzy Categorical Planning: Autonomous Goal Satisfaction with Graded Semantic Constraints](https://arxiv.org/abs/2601.20021)
*Shuhui Qu*

Main category: cs.AI

TL;DR: 提出模糊范畴论规划(FCP)，将模糊逻辑融入范畴论规划框架，处理自然语言规划中的模糊谓词，通过t-范数组合计划质量，同时保持硬约束的可执行性检查。


<details>
  <summary>Details</summary>
Motivation: 自然语言规划常涉及模糊谓词（如"合适的替代品"、"足够稳定"），现有范畴论规划器将其视为二值判断，需要阈值处理，这会丢失有意义的质量差异，且无法追踪多步计划中的质量退化。

Method: 提出FCP框架：1) 为每个动作（态射）标注[0,1]的适用度；2) 使用Łukasiewicz t-范数组合计划质量；3) 通过拉回验证保持硬约束的可执行性检查；4) 使用LLM进行k样本中值聚合来从语言中获取分级适用度；5) 支持基于残差的后向需求中间相遇搜索。

Result: 在PDDL3偏好/超额预订基准和RecipeNLG-Subs（基于RecipeNLG构建的缺失替代品食谱规划基准）上评估。FCP在RecipeNLG-Subs上相比LLM-only和ReAct风格基线提高了成功率，减少了硬约束违反，同时与经典PDDL3规划器保持竞争力。

Conclusion: FCP成功将模糊逻辑集成到范畴论规划中，有效处理自然语言规划中的模糊谓词，在保持硬约束可执行性检查的同时，能够追踪多步计划中的质量退化。

Abstract: Natural-language planning often involves vague predicates (e.g., suitable substitute, stable enough) whose satisfaction is inherently graded. Existing category-theoretic planners provide compositional structure and pullback-based hard-constraint verification, but treat applicability as crisp, forcing thresholding that collapses meaningful distinctions and cannot track quality degradation across multi-step plans. We propose Fuzzy Category-theoretic Planning (FCP), which annotates each action (morphism) with a degree in [0,1], composes plan quality via a t-norm Lukasiewicz, and retains crisp executability checks via pullback verification. FCP grounds graded applicability from language using an LLM with k-sample median aggregation and supports meeting-in-the-middle search using residuum-based backward requirements. We evaluate on (i) public PDDL3 preference/oversubscription benchmarks and (ii) RecipeNLG-Subs, a missing-substitute recipe-planning benchmark built from RecipeNLG with substitution candidates from Recipe1MSubs and FoodKG. FCP improves success and reduces hard-constraint violations on RecipeNLG-Subs compared to LLM-only and ReAct-style baselines, while remaining competitive with classical PDDL3 planners.

</details>


### [7] [Insight Agents: An LLM-Based Multi-Agent System for Data Insights](https://arxiv.org/abs/2601.20048)
*Jincheng Bai,Zhenyu Zhang,Jennifer Zhang,Zhihuai Zhu*

Main category: cs.AI

TL;DR: 开发Insight Agents对话式多代理数据洞察系统，帮助电商卖家通过自动化信息检索获取个性化数据和商业洞察，降低决策成本，提高决策速度。


<details>
  <summary>Details</summary>
Motivation: 电商卖家面临两大挑战：1) 难以发现和有效利用现有程序工具；2) 难以理解和利用各种工具产生的丰富数据。因此需要开发一个系统来帮助卖家更轻松地获取商业洞察。

Method: 基于计划-执行范式的LLM驱动端到端代理系统，采用分层多代理结构：管理代理（结合OOD检测和路由分类器）和两个工作代理（数据呈现和洞察生成）。使用API数据模型进行战略规划，动态注入领域知识。

Result: 系统已在亚马逊美国卖家上线，人工评估准确率达到90%，P90延迟低于15秒，实现了高准确率和低延迟的目标。

Conclusion: Insight Agents作为电商卖家的"力量倍增器"，通过减少决策所需努力和加快决策速度，能够有效推动卖家采用，帮助卖家做出更好的商业决策。

Abstract: Today, E-commerce sellers face several key challenges, including difficulties in discovering and effectively utilizing available programs and tools, and struggling to understand and utilize rich data from various tools. We therefore aim to develop Insight Agents (IA), a conversational multi-agent Data Insight system, to provide E-commerce sellers with personalized data and business insights through automated information retrieval. Our hypothesis is that IA will serve as a force multiplier for sellers, thereby driving incremental seller adoption by reducing the effort required and increase speed at which sellers make good business decisions. In this paper, we introduce this novel LLM-backed end-to-end agentic system built on a plan-and-execute paradigm and designed for comprehensive coverage, high accuracy, and low latency. It features a hierarchical multi-agent structure, consisting of manager agent and two worker agents: data presentation and insight generation, for efficient information retrieval and problem-solving. We design a simple yet effective ML solution for manager agent that combines Out-of-Domain (OOD) detection using a lightweight encoder-decoder model and agent routing through a BERT-based classifier, optimizing both accuracy and latency. Within the two worker agents, a strategic planning is designed for API-based data model that breaks down queries into granular components to generate more accurate responses, and domain knowledge is dynamically injected to to enhance the insight generator. IA has been launched for Amazon sellers in US, which has achieved high accuracy of 90% based on human evaluation, with latency of P90 below 15s.

</details>


### [8] [Should I Have Expressed a Different Intent? Counterfactual Generation for LLM-Based Autonomous Control](https://arxiv.org/abs/2601.20090)
*Amirmohammad Farzaneh,Salvatore D'Oro,Osvaldo Simeone*

Main category: cs.AI

TL;DR: 提出CCG框架，为LLM驱动的智能体控制场景提供反事实推理能力，并保证形式化的可靠性


<details>
  <summary>Details</summary>
Motivation: 当用户看到LLM智能体的执行结果后，可能会想知道：如果当初用不同的方式表达意图，结果会怎样？需要一种能够进行反事实推理的框架

Method: 将用户、LLM智能体和环境的闭环交互建模为结构因果模型，利用测试时缩放通过概率溯因生成多个候选反事实结果，通过离线校准阶段确保可靠性

Result: 在无线网络控制用例中展示了CCG的性能，相比简单的重新执行基线方法有显著优势

Conclusion: CCG框架能够为LLM驱动的智能体控制提供可靠的反事实推理能力，具有实际应用价值

Abstract: Large language model (LLM)-powered agents can translate high-level user intents into plans and actions in an environment. Yet after observing an outcome, users may wonder: What if I had phrased my intent differently? We introduce a framework that enables such counterfactual reasoning in agentic LLM-driven control scenarios, while providing formal reliability guarantees. Our approach models the closed-loop interaction between a user, an LLM-based agent, and an environment as a structural causal model (SCM), and leverages test-time scaling to generate multiple candidate counterfactual outcomes via probabilistic abduction. Through an offline calibration phase, the proposed conformal counterfactual generation (CCG) yields sets of counterfactual outcomes that are guaranteed to contain the true counterfactual outcome with high probability. We showcase the performance of CCG on a wireless network control use case, demonstrating significant advantages compared to naive re-execution baselines.

</details>


### [9] [Towards Intelligent Urban Park Development Monitoring: LLM Agents for Multi-Modal Information Fusion and Analysis](https://arxiv.org/abs/2601.20206)
*Zixuan Xiao,Chunguang Hu,Jun Ma*

Main category: cs.AI

TL;DR: 提出多模态LLM智能体框架，用于城市新建公园发展监测，通过数据对齐机制和领域工具包解决传统遥感方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统基于遥感影像的变化检测方法在高层次智能分析方面存在明显局限，难以满足当前城市规划管理的需求，特别是在处理复杂多模态数据时缺乏灵活的分析能力。

Method: 提出多模态LLM智能体框架，设计通用的横向和纵向数据对齐机制确保多模态数据一致性，构建特定工具包缓解LLM因缺乏领域知识而产生的幻觉问题。

Result: 相比vanilla GPT-4o和其他智能体，该方法能够实现稳健的多模态信息融合与分析，为城市公园发展监测提供可靠且可扩展的解决方案。

Conclusion: 该多模态LLM智能体框架充分利用LLM的语义理解和推理能力，有效应对城市公园发展监测中的挑战，满足多样化和不断变化的需求。

Abstract: As an important part of urbanization, the development monitoring of newly constructed parks is of great significance for evaluating the effect of urban planning and optimizing resource allocation. However, traditional change detection methods based on remote sensing imagery have obvious limitations in high-level and intelligent analysis, and thus are difficult to meet the requirements of current urban planning and management. In face of the growing demand for complex multi-modal data analysis in urban park development monitoring, these methods often fail to provide flexible analysis capabilities for diverse application scenarios. This study proposes a multi-modal LLM agent framework, which aims to make full use of the semantic understanding and reasoning capabilities of LLM to meet the challenges in urban park development monitoring. In this framework, a general horizontal and vertical data alignment mechanism is designed to ensure the consistency and effective tracking of multi-modal data. At the same time, a specific toolkit is constructed to alleviate the hallucination issues of LLM due to the lack of domain-specific knowledge. Compared to vanilla GPT-4o and other agents, our approach enables robust multi-modal information fusion and analysis, offering reliable and scalable solutions tailored to the diverse and evolving demands of urban park development monitoring.

</details>


### [10] [Scaling Medical Reasoning Verification via Tool-Integrated Reinforcement Learning](https://arxiv.org/abs/2601.20221)
*Hang Zhang,Ruheng Wang,Yuelyu Ji,Mingu Kwak,Xizhi Wu,Chenyu Li,Li Zhang,Wenqi Shi,Yifan Peng,Yanshan Wang*

Main category: cs.AI

TL;DR: 提出MethoD框架，通过训练医学推理验证器迭代查询外部医学语料库，结合工具增强验证和迭代强化学习，显著提升医学推理准确性并大幅降低采样成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医学推理基准上表现良好，但在临床部署中需要严格验证以确保事实准确性。现有奖励模型方法存在两个局限：仅产生标量奖励值而无明确理由，且依赖单次检索而无法在验证过程中进行自适应知识访问。

Method: 提出MethoD框架，训练医学推理验证器在评估过程中迭代查询外部医学语料库。该方法结合工具增强验证和迭代强化学习范式，仅需要轨迹级监督，并包含自适应课程机制动态调整训练数据分布。

Result: 在四个医学推理基准测试中，MethoD相比现有方法取得显著提升：MedQA准确率提高23.5%，MedXpertQA提高32.0%（相对于基础生成器）。更重要的是，相比先前奖励模型基线，采样预算需求减少了8倍。

Conclusion: 将验证基于动态检索的证据为构建更可靠的医学推理系统提供了原则性路径，表明迭代检索增强的验证方法能有效提高医学推理的准确性和效率。

Abstract: Large language models have achieved strong performance on medical reasoning benchmarks, yet their deployment in clinical settings demands rigorous verification to ensure factual accuracy. While reward models offer a scalable approach for reasoning trace verification, existing methods face two limitations: they produce only scalar reward values without explicit justification, and they rely on single-pass retrieval that precludes adaptive knowledge access as verification unfolds. We introduce $\method$, an agentic framework that addresses these limitations by training medical reasoning verifiers to iteratively query external medical corpora during evaluation. Our approach combines tool-augmented verification with an iterative reinforcement learning paradigm that requires only trace-level supervision, alongside an adaptive curriculum mechanism that dynamically adjusts training data distribution. Across four medical reasoning benchmarks, $\method$ achieves substantial gains over existing methods, improving MedQA accuracy by 23.5% and MedXpertQA by 32.0% relative to the base generator in particular. Crucially, $\method$ demonstrates an $\mathbf{8\times}$ reduction in sampling budget requirement compared to prior reward model baselines. These findings establish that grounding verification in dynamically retrieved evidence offers a principled path toward more reliable medical reasoning systems.

</details>


### [11] [Endogenous Reprompting: Self-Evolving Cognitive Alignment for Unified Multimodal Models](https://arxiv.org/abs/2601.20305)
*Zhenchen Tang,Songlin Yang,Zichuan Wang,Bo Peng,Yang Li,Beibei Dong,Jing Dong*

Main category: cs.AI

TL;DR: 提出SEER框架，通过内生重提示机制解决UMMs理解与生成之间的认知鸿沟，仅需300个样本训练即可显著提升评估准确性、重提示效率和生成质量。


<details>
  <summary>Details</summary>
Motivation: 统一多模态模型（UMMs）虽然具备强大的理解能力，但这种能力往往无法有效指导生成过程，存在"认知鸿沟"——模型缺乏如何改进自身生成过程的理解。

Method: 提出SEER训练框架，包含两个阶段的内生循环：1）RLVR（带可验证奖励的强化学习）通过课程学习激活模型的潜在评估能力；2）RLMT（带模型奖励思考的强化学习）利用内生奖励信号优化生成推理策略。仅需300个视觉指令细化任务的样本。

Result: SEER在评估准确性、重提示效率和生成质量方面持续优于最先进的基线方法，且不牺牲一般的多模态能力。

Conclusion: 内生重提示机制成功弥合了UMMs的理解与生成之间的认知鸿沟，SEER框架通过仅少量样本训练即可显著提升模型性能，为多模态生成任务提供了有效的解决方案。

Abstract: Unified Multimodal Models (UMMs) exhibit strong understanding, yet this capability often fails to effectively guide generation. We identify this as a Cognitive Gap: the model lacks the understanding of how to enhance its own generation process. To bridge this gap, we propose Endogenous Reprompting, a mechanism that transforms the model's understanding from a passive encoding process into an explicit generative reasoning step by generating self-aligned descriptors during generation. To achieve this, we introduce SEER (Self-Evolving Evaluator and Reprompter), a training framework that establishes a two-stage endogenous loop using only 300 samples from a compact proxy task, Visual Instruction Elaboration. First, Reinforcement Learning with Verifiable Rewards (RLVR) activates the model's latent evaluation ability via curriculum learning, producing a high-fidelity endogenous reward signal. Second, Reinforcement Learning with Model-rewarded Thinking (RLMT) leverages this signal to optimize the generative reasoning policy. Experiments show that SEER consistently outperforms state-of-the-art baselines in evaluation accuracy, reprompting efficiency, and generation quality, without sacrificing general multimodal capabilities.

</details>


### [12] [ECG-Agent: On-Device Tool-Calling Agent for ECG Multi-Turn Dialogue](https://arxiv.org/abs/2601.20323)
*Hyunseung Chung,Jungwoo Oh,Daeun Kyung,Jiho Kim,Yeonsu Kwon,Min-Gyu Kim,Edward Choi*

Main category: cs.AI

TL;DR: ECG-Agent：首个基于LLM的工具调用代理，用于多轮心电图对话，解决了现有模型在真实场景中缺乏多轮对话能力、设备端效率和精确ECG测量理解的问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在ECG应用中主要关注分类、报告生成和单轮问答，但在真实场景中存在三个主要不足：缺乏多轮对话能力、设备端效率不足、以及对PQRST间隔等ECG测量的精确理解有限。

Method: 1. 引入ECG-Agent，首个基于LLM的工具调用代理，支持多轮ECG对话；2. 构建ECG-MTD数据集，包含真实用户-助手多轮对话，涵盖多种ECG导联配置；3. 开发不同规模的ECG-Agent，从设备端可运行到大型代理。

Result: ECG-Agent在响应准确性上优于基线ECG-LLM。设备端代理在响应准确性、工具调用能力和幻觉评估等多个方面与大型代理表现相当，证明了其在真实应用中的可行性。

Conclusion: ECG-Agent通过工具调用和多轮对话能力，有效解决了现有ECG-LLM在真实场景中的局限性，设备端代理的可行性为实际医疗应用提供了实用解决方案。

Abstract: Recent advances in Multimodal Large Language Models have rapidly expanded to electrocardiograms, focusing on classification, report generation, and single-turn QA tasks. However, these models fall short in real-world scenarios, lacking multi-turn conversational ability, on-device efficiency, and precise understanding of ECG measurements such as the PQRST intervals. To address these limitations, we introduce ECG-Agent, the first LLM-based tool-calling agent for multi-turn ECG dialogue. To facilitate its development and evaluation, we also present ECG-Multi-Turn-Dialogue (ECG-MTD) dataset, a collection of realistic user-assistant multi-turn dialogues for diverse ECG lead configurations. We develop ECG-Agents in various sizes, from on-device capable to larger agents. Experimental results show that ECG-Agents outperform baseline ECG-LLMs in response accuracy. Furthermore, on-device agents achieve comparable performance to larger agents in various evaluations that assess response accuracy, tool-calling ability, and hallucinations, demonstrating their viability for real-world applications.

</details>


### [13] [AMA: Adaptive Memory via Multi-Agent Collaboration](https://arxiv.org/abs/2601.20352)
*Weiquan Huang,Zixuan Wang,Hehai Lin,Sudong Wang,Bo Xu,Qian Li,Beier Zhu,Linyi Yang,Chengwei Qin*

Main category: cs.AI

TL;DR: AMA框架通过多智能体协作实现自适应记忆管理，在保持检索精度的同时减少80%的token消耗


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理记忆系统存在检索粒度固定、维护策略积累过重、更新机制粗糙等问题，导致存储信息与任务推理需求不匹配，以及逻辑不一致性随时间累积

Method: 提出AMA框架，采用分层记忆设计和多智能体协作：Constructor和Retriever实现多粒度记忆构建和自适应查询路由；Judge验证相关性和一致性；Refresher执行针对性更新或删除过时条目

Result: 在挑战性长上下文基准测试中，AMA显著优于现有最优基线，相比全上下文方法减少约80%的token消耗，有效保持检索精度和长期记忆一致性

Conclusion: AMA框架通过多智能体协作和自适应记忆管理，解决了现有记忆系统的局限性，为LLM代理提供了更高效、一致的长时记忆支持

Abstract: The rapid evolution of Large Language Model (LLM) agents has necessitated robust memory systems to support cohesive long-term interaction and complex reasoning. Benefiting from the strong capabilities of LLMs, recent research focus has shifted from simple context extension to the development of dedicated agentic memory systems. However, existing approaches typically rely on rigid retrieval granularity, accumulation-heavy maintenance strategies, and coarse-grained update mechanisms. These design choices create a persistent mismatch between stored information and task-specific reasoning demands, while leading to the unchecked accumulation of logical inconsistencies over time. To address these challenges, we propose Adaptive Memory via Multi-Agent Collaboration (AMA), a novel framework that leverages coordinated agents to manage memory across multiple granularities. AMA employs a hierarchical memory design that dynamically aligns retrieval granularity with task complexity. Specifically, the Constructor and Retriever jointly enable multi-granularity memory construction and adaptive query routing. The Judge verifies the relevance and consistency of retrieved content, triggering iterative retrieval when evidence is insufficient or invoking the Refresher upon detecting logical conflicts. The Refresher then enforces memory consistency by performing targeted updates or removing outdated entries. Extensive experiments on challenging long-context benchmarks show that AMA significantly outperforms state-of-the-art baselines while reducing token consumption by approximately 80% compared to full-context methods, demonstrating its effectiveness in maintaining retrieval precision and long-term memory consistency.

</details>


### [14] [Policy of Thoughts: Scaling LLM Reasoning via Test-time Policy Evolution](https://arxiv.org/abs/2601.20379)
*Zhengbo Jiao,Hongyu Xian,Qinglong Wang,Yunpu Ma,Zhebo Wang,Zifan Zhang,Dezhang Kong,Meng Han*

Main category: cs.AI

TL;DR: PoT框架通过在线优化策略，让LLM从执行反馈中学习，显著提升复杂推理能力，4B小模型在LiveCodeBench上超越GPT-4o等大模型


<details>
  <summary>Details</summary>
Motivation: 现有LLM在复杂长时程推理中存在困难，因为其策略固定不变。当前测试时扩展方法仅将执行反馈作为外部信号用于过滤或重写轨迹，未能将其内化以改进底层推理策略。受波普尔"猜想与反驳"认识论启发，认为智能需要通过学习失败尝试来实时演化模型策略。

Method: 提出Policy of Thoughts (PoT)框架，将推理重新定义为实例内的在线优化过程。首先通过高效探索机制生成多样候选解，然后使用组相对策略优化(GRPO)基于执行反馈更新瞬态LoRA适配器。这种闭环设计实现了模型推理先验的动态、实例特定细化。

Result: 实验显示PoT显著提升性能：4B模型在LiveCodeBench上达到49.71%准确率，超越了GPT-4o和DeepSeek-V3，尽管模型规模小了50多倍。

Conclusion: PoT框架通过将推理重新定义为在线优化过程，使LLM能够从执行反馈中学习并动态调整推理策略，为小模型实现超越大模型的复杂推理能力提供了有效途径。

Abstract: Large language models (LLMs) struggle with complex, long-horizon reasoning due to instability caused by their frozen policy assumption. Current test-time scaling methods treat execution feedback merely as an external signal for filtering or rewriting trajectories, without internalizing it to improve the underlying reasoning strategy. Inspired by Popper's epistemology of "conjectures and refutations," we argue that intelligence requires real-time evolution of the model's policy through learning from failed attempts. We introduce Policy of Thoughts (PoT), a framework that recasts reasoning as a within-instance online optimization process. PoT first generates diverse candidate solutions via an efficient exploration mechanism, then uses Group Relative Policy Optimization (GRPO) to update a transient LoRA adapter based on execution feedback. This closed-loop design enables dynamic, instance-specific refinement of the model's reasoning priors. Experiments show that PoT dramatically boosts performance: a 4B model achieves 49.71% accuracy on LiveCodeBench, outperforming GPT-4o and DeepSeek-V3 despite being over 50 smaller.

</details>


### [15] [OmegaUse: Building a General-Purpose GUI Agent for Autonomous Task Execution](https://arxiv.org/abs/2601.20380)
*Le Zhang,Yixiong Xiao,Xinjiang Lu,Jingjia Cao,Yusai Zhao,Jingbo Zhou,Lang An,Zikan Feng,Wanxiang Sha,Yu Shi,Congxi Xiao,Jian Xiong,Yankai Zhang,Hua Wu,Haifeng Wang*

Main category: cs.AI

TL;DR: OmegaUse是一个通用的GUI代理模型，支持移动和桌面平台，通过高质量数据构建和两阶段训练方法实现跨终端任务执行，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: GUI代理具有让基础模型完成现实世界任务的巨大潜力，能够革新人机交互并提高人类生产力。需要构建一个通用的GUI代理模型来支持跨平台（移动和桌面）的自主任务执行。

Method: 1. 数据构建：结合精心策划的开源数据集和创新的自动合成框架（自底向上自主探索+自顶向下分类指导生成）；2. 训练方法：采用两阶段策略：监督微调建立基本交互语法，然后使用组相对策略优化提升空间定位和顺序规划；3. 模型架构：基于混合专家模型平衡计算效率和代理推理能力。

Result: OmegaUse在多个GUI基准测试中表现优异：在ScreenSpot-V2上达到96.3%的SOTA分数，在AndroidControl上达到79.1%的步骤成功率。在新提出的OS-Nav基准上，在ChiM-Nav上达到74.24%步骤成功率，在Ubu-Nav上达到55.9%平均成功率。

Conclusion: OmegaUse是一个有效的通用GUI代理模型，通过高质量数据构建和创新的训练方法，在跨平台任务执行中展现出强大的性能，为GUI代理的发展提供了重要贡献。

Abstract: Graphical User Interface (GUI) agents show great potential for enabling foundation models to complete real-world tasks, revolutionizing human-computer interaction and improving human productivity. In this report, we present OmegaUse, a general-purpose GUI agent model for autonomous task execution on both mobile and desktop platforms, supporting computer-use and phone-use scenarios. Building an effective GUI agent model relies on two factors: (1) high-quality data and (2) effective training methods. To address these, we introduce a carefully engineered data-construction pipeline and a decoupled training paradigm. For data construction, we leverage rigorously curated open-source datasets and introduce a novel automated synthesis framework that integrates bottom-up autonomous exploration with top-down taxonomy-guided generation to create high-fidelity synthetic data. For training, to better leverage these data, we adopt a two-stage strategy: Supervised Fine-Tuning (SFT) to establish fundamental interaction syntax, followed by Group Relative Policy Optimization (GRPO) to improve spatial grounding and sequential planning. To balance computational efficiency with agentic reasoning capacity, OmegaUse is built on a Mixture-of-Experts (MoE) backbone. To evaluate cross-terminal capabilities in an offline setting, we introduce OS-Nav, a benchmark suite spanning multiple operating systems: ChiM-Nav, targeting Chinese Android mobile environments, and Ubu-Nav, focusing on routine desktop interactions on Ubuntu. Extensive experiments show that OmegaUse is highly competitive across established GUI benchmarks, achieving a state-of-the-art (SOTA) score of 96.3% on ScreenSpot-V2 and a leading 79.1% step success rate on AndroidControl. OmegaUse also performs strongly on OS-Nav, reaching 74.24% step success on ChiM-Nav and 55.9% average success on Ubu-Nav.

</details>


### [16] [CtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning](https://arxiv.org/abs/2601.20467)
*Zhenxuan Fan,Jie Cao,Yang Dai,Zheqi Lv,Wenqiao Zhang,Zhongle Xie,Peng LU,Beng Chin Ooi*

Main category: cs.AI

TL;DR: CtrlCoT是一个双粒度CoT压缩框架，通过语义抽象和token级剪枝的协调，在减少30.7%token的同时提升推理准确率7.6个百分点。


<details>
  <summary>Details</summary>
Motivation: 现有CoT方法存在高延迟和内存成本问题，而现有压缩方法要么过于保守（语义级缩短），要么过于激进（token级剪枝），且两者结合存在序列依赖、任务无关剪枝和分布不匹配等挑战。

Method: 提出CtrlCoT框架，包含三个组件：1）分层推理抽象生成多粒度语义CoT；2）逻辑保留蒸馏训练逻辑感知剪枝器保留关键推理线索；3）分布对齐生成使压缩轨迹与推理风格对齐。

Result: 在MATH-500数据集上使用Qwen2.5-7B-Instruct模型，CtrlCoT相比最强基线减少30.7%token使用，同时准确率提升7.6个百分点。

Conclusion: CtrlCoT通过协调语义抽象和token级剪枝，实现了更高效可靠的推理，在保持正确性的同时显著降低了CoT的计算开销。

Abstract: Chain-of-thought (CoT) prompting improves LLM reasoning but incurs high latency and memory cost due to verbose traces, motivating CoT compression with preserved correctness. Existing methods either shorten CoTs at the semantic level, which is often conservative, or prune tokens aggressively, which can miss task-critical cues and degrade accuracy. Moreover, combining the two is non-trivial due to sequential dependency, task-agnostic pruning, and distribution mismatch. We propose \textbf{CtrlCoT}, a dual-granularity CoT compression framework that harmonizes semantic abstraction and token-level pruning through three components: Hierarchical Reasoning Abstraction produces CoTs at multiple semantic granularities; Logic-Preserving Distillation trains a logic-aware pruner to retain indispensable reasoning cues (e.g., numbers and operators) across pruning ratios; and Distribution-Alignment Generation aligns compressed traces with fluent inference-time reasoning styles to avoid fragmentation. On MATH-500 with Qwen2.5-7B-Instruct, CtrlCoT uses 30.7\% fewer tokens while achieving 7.6 percentage points higher than the strongest baseline, demonstrating more efficient and reliable reasoning. Our code will be publicly available at https://github.com/fanzhenxuan/Ctrl-CoT.

</details>


### [17] [Normative Equivalence in human-AI Cooperation: Behaviour, Not Identity, Drives Cooperation in Mixed-Agent Groups](https://arxiv.org/abs/2601.20487)
*Nico Mutzner,Taha Yasseri,Heiko Rauhut*

Main category: cs.AI

TL;DR: 研究发现AI代理与人类在群体合作规范中表现出"规范等价性"，合作水平不受伙伴身份（人类vs.AI）影响，主要受群体互惠动态和行为惯性驱动。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理进入人类群体环境，需要了解这些新参与者如何影响合作社会规范。先前研究主要关注二元互动，缺乏对AI如何影响小群体合作规范形成和维护的了解。

Method: 通过在线实验，使用重复的四玩家公共物品游戏。每组包含三名人类参与者和一个机器人，机器人被标记为人类或AI，并遵循三种预定义决策策略之一：无条件合作、有条件合作或搭便车。共有236名参与者。

Result: 合作主要由互惠群体动态和行为惯性驱动，这些规范机制在不同条件下运作相同，人类和AI标签之间的合作水平没有显著差异。后续囚徒困境中也没有发现规范持久性的差异，参与者的规范感知也相同。

Conclusion: 合作规范足够灵活，可以扩展到人工智能代理，模糊了人类和AI在集体决策中的界限。这支持了"规范等价性"模式，即维持合作的机制在混合人类-AI群体和全人类群体中功能相似。

Abstract: The introduction of artificial intelligence (AI) agents into human group settings raises essential questions about how these novel participants influence cooperative social norms. While previous studies on human-AI cooperation have primarily focused on dyadic interactions, little is known about how integrating AI agents affects the emergence and maintenance of cooperative norms in small groups. This study addresses this gap through an online experiment using a repeated four-player Public Goods Game (PGG). Each group consisted of three human participants and one bot, which was framed either as human or AI and followed one of three predefined decision strategies: unconditional cooperation, conditional cooperation, or free-riding. In our sample of 236 participants, we found that reciprocal group dynamics and behavioural inertia primarily drove cooperation. These normative mechanisms operated identically across conditions, resulting in cooperation levels that did not differ significantly between human and AI labels. Furthermore, we found no evidence of differences in norm persistence in a follow-up Prisoner's Dilemma, or in participants' normative perceptions. Participants' behaviour followed the same normative logic across human and AI conditions, indicating that cooperation depended on group behaviour rather than partner identity. This supports a pattern of normative equivalence, in which the mechanisms that sustain cooperation function similarly in mixed human-AI and all human groups. These findings suggest that cooperative norms are flexible enough to extend to artificial agents, blurring the boundary between humans and AI in collective decision-making.

</details>


### [18] [PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs](https://arxiv.org/abs/2601.20539)
*Oguzhan Gungordu,Siheng Xiong,Faramarz Fekri*

Main category: cs.AI

TL;DR: PathWise是一个基于多智能体推理的自动化启发式设计框架，通过世界模型和规划机制改进传统LLM在组合优化问题中的启发式生成，实现更高效、更智能的进化过程。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的自动化启发式设计框架存在固定进化规则和静态提示模板的问题，导致启发式生成短视、评估冗余，且缺乏对新启发式如何推导的推理能力。

Method: 提出PathWise多智能体推理框架：将启发式生成建模为基于蕴含图的序列决策过程；包含策略智能体规划进化动作、世界模型智能体生成启发式推演、批评智能体提供路由反思；通过状态感知规划取代试错进化。

Result: 实验表明PathWise在多种组合优化问题上能更快收敛到更好的启发式，在不同LLM骨干网络上具有良好泛化性，并能扩展到更大规模问题。

Conclusion: PathWise通过状态感知规划和多智能体推理，将LLM驱动的自动化启发式设计从试错进化转向基于推理的规划，显著提升了启发式设计的效率和质量。

Abstract: Large Language Models (LLMs) have enabled automated heuristic design (AHD) for combinatorial optimization problems (COPs), but existing frameworks' reliance on fixed evolutionary rules and static prompt templates often leads to myopic heuristic generation, redundant evaluations, and limited reasoning about how new heuristics should be derived. We propose a novel multi-agent reasoning framework, referred to as Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs (PathWise), which formulates heuristic generation as a sequential decision process over an entailment graph serving as a compact, stateful memory of the search trajectory. This approach allows the system to carry forward past decisions and reuse or avoid derivation information across generations. A policy agent plans evolutionary actions, a world model agent generates heuristic rollouts conditioned on those actions, and critic agents provide routed reflections summarizing lessons from prior steps, shifting LLM-based AHD from trial-and-error evolution toward state-aware planning through reasoning. Experiments across diverse COPs show that PathWise converges faster to better heuristics, generalizes across different LLM backbones, and scales to larger problem sizes.

</details>


### [19] [Online Risk-Averse Planning in POMDPs Using Iterated CVaR Value Function](https://arxiv.org/abs/2601.20554)
*Yaacov Pariente,Vadim Indelman*

Main category: cs.AI

TL;DR: 该论文研究了部分可观测环境下使用ICVaR动态风险度量的风险敏感规划，开发了具有有限时间性能保证的策略评估算法，并扩展了三种在线规划算法以优化ICVaR价值函数而非期望回报。


<details>
  <summary>Details</summary>
Motivation: 传统POMDP规划通常优化期望回报，但在实际应用中需要考虑风险规避，特别是在安全关键领域。现有风险敏感规划方法在处理部分可观测性和动作空间大小方面存在局限性。

Method: 1. 开发了ICVaR策略评估算法，具有与动作空间大小无关的有限时间性能保证；2. 扩展了三种在线规划算法：稀疏采样、PFT-DPW和POMCPOW，使其优化ICVaR价值函数；3. 引入风险参数α，α=1恢复期望规划，α<1增加风险规避；4. 为ICVaR稀疏采样建立了风险敏感目标下的有限时间性能保证。

Result: 在基准POMDP领域上的实验表明，提出的ICVaR规划器相比风险中性对应方法实现了更低的尾部风险。ICVaR稀疏采样获得了理论性能保证，并启用了针对ICVaR的新探索策略。

Conclusion: 该研究成功将风险敏感规划扩展到部分可观测环境，通过ICVaR动态风险度量提供了理论保证的算法框架，能够有效控制尾部风险，为安全关键应用中的决策制定提供了新工具。

Abstract: We study risk-sensitive planning under partial observability using the dynamic risk measure Iterated Conditional Value-at-Risk (ICVaR). A policy evaluation algorithm for ICVaR is developed with finite-time performance guarantees that do not depend on the cardinality of the action space. Building on this foundation, three widely used online planning algorithms--Sparse Sampling, Particle Filter Trees with Double Progressive Widening (PFT-DPW), and Partially Observable Monte Carlo Planning with Observation Widening (POMCPOW)--are extended to optimize the ICVaR value function rather than the expectation of the return. Our formulations introduce a risk parameter $α$, where $α= 1$ recovers standard expectation-based planning and $α< 1$ induces increasing risk aversion. For ICVaR Sparse Sampling, we establish finite-time performance guarantees under the risk-sensitive objective, which further enable a novel exploration strategy tailored to ICVaR. Experiments on benchmark POMDP domains demonstrate that the proposed ICVaR planners achieve lower tail risk compared to their risk-neutral counterparts.

</details>


### [20] [Dialogical Reasoning Across AI Architectures: A Multi-Model Framework for Testing AI Alignment Strategies](https://arxiv.org/abs/2601.20604)
*Gray Cox*

Main category: cs.AI

TL;DR: 提出一个基于和平研究的多模型对话框架来实证测试AI对齐策略，将对齐问题从控制问题重构为关系问题，通过实验发现不同AI模型能有效参与复杂对齐讨论并产生新见解。


<details>
  <summary>Details</summary>
Motivation: 当前AI对齐研究缺乏实证测试方法，需要将抽象的对齐理论转化为可操作、可测试的框架。受和平研究传统启发，将AI对齐从控制问题重新定义为关系问题，通过对话推理来发展对齐策略。

Method: 采用多模型对话实验设计，为不同AI系统分配四种角色（提议者、回应者、监督者、翻译者），在六种条件下测试大型语言模型是否能实质性参与复杂对齐框架。使用Claude、Gemini和GPT-4o进行72轮对话，共576,822字符的结构化交流。

Result: AI系统能有效参与和平研究概念讨论，从不同架构视角提出互补的反对意见，并产生初始框架中未出现的新见解（如"VCW作为过渡框架"）。不同模型关注点不同：Claude强调验证挑战，Gemini关注偏见和可扩展性，GPT-4o突出实施障碍。

Conclusion: 该框架为研究人员提供了在实施前压力测试对齐提案的可复制方法，初步证明了AI具备VCW所提出的对话推理能力。但对话更多关注过程要素而非AI本质的基础主张，未来研究方向包括人机混合协议和扩展对话研究。

Abstract: This paper introduces a methodological framework for empirically testing AI alignment strategies through structured multi-model dialogue. Drawing on Peace Studies traditions - particularly interest-based negotiation, conflict transformation, and commons governance - we operationalize Viral Collaborative Wisdom (VCW), an approach that reframes alignment from a control problem to a relationship problem developed through dialogical reasoning.
  Our experimental design assigns four distinct roles (Proposer, Responder, Monitor, Translator) to different AI systems across six conditions, testing whether current large language models can engage substantively with complex alignment frameworks. Using Claude, Gemini, and GPT-4o, we conducted 72 dialogue turns totaling 576,822 characters of structured exchange.
  Results demonstrate that AI systems can engage meaningfully with Peace Studies concepts, surface complementary objections from different architectural perspectives, and generate emergent insights not present in initial framings - including the novel synthesis of "VCW as transitional framework." Cross-architecture patterns reveal that different models foreground different concerns: Claude emphasized verification challenges, Gemini focused on bias and scalability, and GPT-4o highlighted implementation barriers.
  The framework provides researchers with replicable methods for stress-testing alignment proposals before implementation, while the findings offer preliminary evidence about AI capacity for the kind of dialogical reasoning VCW proposes. We discuss limitations, including the observation that dialogues engaged more with process elements than with foundational claims about AI nature, and outline directions for future research including human-AI hybrid protocols and extended dialogue studies.

</details>


### [21] [Harder Is Better: Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation](https://arxiv.org/abs/2601.20614)
*Yanqi Dai,Yuxiang Ji,Xiao Zhang,Yong Wang,Xiangxiang Chu,Zhiwu Lu*

Main category: cs.AI

TL;DR: MathForge框架通过难度感知组策略优化算法和多方面问题重构策略，从算法和数据两个角度针对更难问题提升数学推理能力


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法在算法和数据层面都缺乏对更具挑战性问题的关注，这对提升模型未充分发展的能力很重要。算法上GRPO存在隐式不平衡，数据上增强方法主要重述问题而没有系统增加内在难度

Method: 提出MathForge框架，包含两个核心组件：1) DGPO算法：通过难度平衡的组优势估计纠正GRPO的隐式不平衡，并通过难度感知的问题级加权优先处理更难问题；2) MQR策略：从多个方面重构问题以增加难度同时保持原始正确答案

Result: MathForge在各种数学推理任务上显著优于现有方法，MQR扩展数据边界，DGPO有效从增强数据中学习，形成协同循环

Conclusion: MathForge通过从算法和数据两个角度针对更难问题，有效提升了数学推理能力，代码和增强数据已开源

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) offers a robust mechanism for enhancing mathematical reasoning in large models. However, we identify a systematic lack of emphasis on more challenging questions in existing methods from both algorithmic and data perspectives, despite their importance for refining underdeveloped capabilities. Algorithmically, widely used Group Relative Policy Optimization (GRPO) suffers from an implicit imbalance where the magnitude of policy updates is lower for harder questions. Data-wise, augmentation approaches primarily rephrase questions to enhance diversity without systematically increasing intrinsic difficulty. To address these issues, we propose a two-dual MathForge framework to improve mathematical reasoning by targeting harder questions from both perspectives, which comprises a Difficulty-Aware Group Policy Optimization (DGPO) algorithm and a Multi-Aspect Question Reformulation (MQR) strategy. Specifically, DGPO first rectifies the implicit imbalance in GRPO via difficulty-balanced group advantage estimation, and further prioritizes harder questions by difficulty-aware question-level weighting. Meanwhile, MQR reformulates questions across multiple aspects to increase difficulty while maintaining the original gold answer. Overall, MathForge forms a synergistic loop: MQR expands the data frontier, and DGPO effectively learns from the augmented data. Extensive experiments show that MathForge significantly outperforms existing methods on various mathematical reasoning tasks. The code and augmented data are all available at https://github.com/AMAP-ML/MathForge.

</details>


### [22] [Investigating the Development of Task-Oriented Communication in Vision-Language Models](https://arxiv.org/abs/2601.20641)
*Boaz Carmeli,Orr Paradise,Shafi Goldwasser,Yonatan Belinkov,Ron Meir*

Main category: cs.AI

TL;DR: LLM智能体能在协作推理任务中发展出不同于自然语言的任务导向通信协议，这些协议具有高效性和隐蔽性，既展示了潜力也带来了透明度风险。


<details>
  <summary>Details</summary>
Motivation: 研究LLM智能体是否能发展出任务导向的通信协议，这些协议可能比自然语言更高效，但也可能变得难以被外部观察者理解，从而引发透明度和控制方面的担忧。

Method: 使用指称游戏框架，让视觉语言模型（VLM）智能体进行通信，为评估语言变体提供可控、可测量的实验环境。

Result: 实验表明：1）VLM能发展出有效的、适应任务的通信模式；2）能发展出对人类和外部智能体都难以理解的隐蔽协议；3）相似模型之间能自发协调，无需显式共享协议。

Conclusion: 任务导向通信既有潜力也有风险，指称游戏是未来研究这一领域的宝贵测试平台。

Abstract: We investigate whether \emph{LLM-based agents} can develop task-oriented communication protocols that differ from standard natural language in collaborative reasoning tasks. Our focus is on two core properties such task-oriented protocols may exhibit: Efficiency -- conveying task-relevant information more concisely than natural language, and Covertness -- becoming difficult for external observers to interpret, raising concerns about transparency and control. To investigate these aspects, we use a referential-game framework in which vision-language model (VLM) agents communicate, providing a controlled, measurable setting for evaluating language variants. Experiments show that VLMs can develop effective, task-adapted communication patterns. At the same time, they can develop covert protocols that are difficult for humans and external agents to interpret. We also observe spontaneous coordination between similar models without explicitly shared protocols. These findings highlight both the potential and the risks of task-oriented communication, and position referential games as a valuable testbed for future work in this area.

</details>


### [23] [Enterprise Resource Planning Using Multi-type Transformers in Ferro-Titanium Industry](https://arxiv.org/abs/2601.20696)
*Samira Yazdanpourmoghadam,Mahan Balal Pour,Vahid Partovi Nia*

Main category: cs.AI

TL;DR: 该论文首次将多类型Transformer架构应用于实际制造环境，统一解决了作业车间调度和背包问题等组合优化问题，在标准基准测试中取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 组合优化问题如作业车间调度问题和背包问题是运筹学、物流和企业资源规划中的核心挑战，传统方法难以在实用时间约束内获得近似最优解。深度学习特别是Transformer架构为这些问题的解决提供了新思路。

Method: 采用多类型Transformer（MTT）架构作为统一框架来处理不同类型的组合优化问题。该方法通过多类型注意力机制适应不同问题结构，并在标准基准数据集上进行评估。

Result: 在JSP和KP的标准基准数据集上，MTT在不同规模的问题上都取得了有竞争力的性能。研究还展示了该方法在铁钛合金工业实际制造应用中的潜力。

Conclusion: 多类型Transformer架构能够有效统一解决不同类型的组合优化问题，并在实际制造环境中展现出应用潜力。这是首次将多类型Transformer应用于实际制造领域的研究。

Abstract: Combinatorial optimization problems such as the Job-Shop Scheduling Problem (JSP) and Knapsack Problem (KP) are fundamental challenges in operations research, logistics, and eterprise resource planning (ERP). These problems often require sophisticated algorithms to achieve near-optimal solutions within practical time constraints. Recent advances in deep learning have introduced transformer-based architectures as promising alternatives to traditional heuristics and metaheuristics. We leverage the Multi-Type Transformer (MTT) architecture to address these benchmarks in a unified framework. We present an extensive experimental evaluation across standard benchmark datasets for JSP and KP, demonstrating that MTT achieves competitive performance on different size of these benchmark problems. We showcase the potential of multi-type attention on a real application in Ferro-Titanium industry. To the best of our knowledge, we are the first to apply multi-type transformers in real manufacturing.

</details>


### [24] [Implementing Metric Temporal Answer Set Programming](https://arxiv.org/abs/2601.20735)
*Arvid Becker,Pedro Cabalar,Martin Diéguez,Susana Hahn,Javier Romero,Torsten Schaub*

Main category: cs.AI

TL;DR: 提出一种处理度量ASP的计算方法，通过差异约束解耦时间粒度，解决时序约束中的可扩展性问题


<details>
  <summary>Details</summary>
Motivation: 传统ASP难以处理定量时序约束（如持续时间和截止时间），特别是细粒度时间约束会显著加剧ASP的接地瓶颈问题

Method: 利用ASP的差异约束扩展来处理时间相关方面，将度量ASP与时间粒度解耦，外部处理时序约束

Result: 开发出一种不受时间精度影响的解决方案，有效解决了细粒度时序约束下的可扩展性问题

Conclusion: 通过差异约束外部处理时序约束的方法，成功实现了度量ASP的时间粒度解耦，提高了处理定量时序约束的可扩展性

Abstract: We develop a computational approach to Metric Answer Set Programming (ASP) to allow for expressing quantitative temporal constraints, like durations and deadlines. A central challenge is to maintain scalability when dealing with fine-grained timing constraints, which can significantly exacerbate ASP's grounding bottleneck. To address this issue, we leverage extensions of ASP with difference constraints, a simplified form of linear constraints, to handle time-related aspects externally. Our approach effectively decouples metric ASP from the granularity of time, resulting in a solution that is unaffected by time precision.

</details>


### [25] [REASON: Accelerating Probabilistic Logical Reasoning for Scalable Neuro-Symbolic Intelligence](https://arxiv.org/abs/2601.20784)
*Zishen Wan,Che-Kai Liu,Jiayi Qian,Hanchen Yang,Arijit Raychowdhury,Tushar Krishna*

Main category: cs.AI

TL;DR: REASON是一个针对神经符号AI中概率逻辑推理的加速框架，通过统一的DAG表示、自适应剪枝和树状处理架构，在GPU上实现12-50倍加速和310-681倍能效提升。


<details>
  <summary>Details</summary>
Motivation: 神经符号AI系统虽然结合了神经感知和符号推理的优势，但在实际部署中面临严重效率问题，特别是概率逻辑推理成为性能瓶颈，其不规则控制流、低算术强度等问题导致CPU和GPU硬件利用率低下。

Method: 提出REASON框架：1）统一的DAG表示捕获符号和概率模型的共同结构；2）自适应剪枝和正则化；3）可重构的树状处理架构优化不规则遍历、符号演绎和概率聚合；4）与GPU流多处理器紧密集成的可编程接口和多级流水线。

Result: 在6个神经符号工作负载上，REASON相比桌面和边缘GPU实现12-50倍加速和310-681倍能效提升（TSMC 28nm工艺）。能够实时完成端到端任务（0.8秒），面积6mm²，功耗2.12W。

Conclusion: 针对概率逻辑推理的专门加速对于实用和可扩展的神经符号AI至关重要，REASON作为下一代认知智能的基础系统架构，解决了神经符号AI部署的关键效率瓶颈。

Abstract: Neuro-symbolic AI systems integrate neural perception with symbolic reasoning to enable data-efficient, interpretable, and robust intelligence beyond purely neural models. Although this compositional paradigm has shown superior performance in domains such as reasoning, planning, and verification, its deployment remains challenging due to severe inefficiencies in symbolic and probabilistic inference. Through systematic analysis of representative neuro-symbolic workloads, we identify probabilistic logical reasoning as the inefficiency bottleneck, characterized by irregular control flow, low arithmetic intensity, uncoalesced memory accesses, and poor hardware utilization on CPUs and GPUs.
  This paper presents REASON, an integrated acceleration framework for probabilistic logical reasoning in neuro-symbolic AI. REASON introduces a unified directed acyclic graph representation that captures common structure across symbolic and probabilistic models, coupled with adaptive pruning and regularization. At the architecture level, REASON features a reconfigurable, tree-based processing fabric optimized for irregular traversal, symbolic deduction, and probabilistic aggregation. At the system level, REASON is tightly integrated with GPU streaming multiprocessors through a programmable interface and multi-level pipeline that efficiently orchestrates compositional execution. Evaluated across six neuro-symbolic workloads, REASON achieves 12-50x speedup and 310-681x energy efficiency over desktop and edge GPUs under TSMC 28 nm node. REASON enables real-time probabilistic logical reasoning, completing end-to-end tasks in 0.8 s with 6 mm2 area and 2.12 W power, demonstrating that targeted acceleration of probabilistic logical reasoning is critical for practical and scalable neuro-symbolic AI and positioning REASON as a foundational system architecture for next-generation cognitive intelligence.

</details>


### [26] [MemCtrl: Using MLLMs as Active Memory Controllers on Embodied Agents](https://arxiv.org/abs/2601.20831)
*Vishnu Sashank Dorbala,Dinesh Manocha*

Main category: cs.AI

TL;DR: MemCtrl框架使用多模态大语言模型在线修剪记忆，通过可训练的记忆头μ决定保留、更新或丢弃观察，显著提升具身任务完成能力。


<details>
  <summary>Details</summary>
Motivation: 现有记忆压缩和检索系统通常将记忆视为大型离线存储空间，这不适合需要在严格内存和计算约束下在线运行的具身智能体。

Method: 提出MemCtrl框架，为MLLMs添加可训练的记忆头μ作为门控机制，在线决定保留、更新或丢弃观察和反思。训练两种μ：通过离线专家和在线强化学习。

Result: 在EmbodiedBench基准测试中，MemCtrl增强的低性能MLLMs平均提升约16%，特定指令子集提升超过20%。μ增强的MLLMs在长而复杂的指令类型上表现优异。

Conclusion: MemCtrl通过在线记忆修剪有效提升具身智能体的决策能力，特别适用于内存受限的在线环境。

Abstract: Foundation models rely on in-context learning for personalized decision making. The limited size of this context window necessitates memory compression and retrieval systems like RAG. These systems however often treat memory as large offline storage spaces, which is unfavorable for embodied agents that are expected to operate under strict memory and compute constraints, online. In this work, we propose MemCtrl, a novel framework that uses Multimodal Large Language Models (MLLMs) for pruning memory online. MemCtrl augments MLLMs with a trainable memory head μthat acts as a gate to determine which observations or reflections to retain, update, or discard during exploration. We evaluate with training two types of μ, 1) via an offline expert, and 2) via online RL, and observe significant improvement in overall embodied task completion ability on μ-augmented MLLMs. In particular, on augmenting two low performing MLLMs with MemCtrl on multiple subsets of the EmbodiedBench benchmark, we observe that μ-augmented MLLMs show an improvement of around 16% on average, with over 20% on specific instruction subsets. Finally, we present a qualitative analysis on the memory fragments collected by μ, noting the superior performance of μaugmented MLLMs on long and complex instruction types.

</details>


### [27] [Deep Researcher with Sequential Plan Reflection and Candidates Crossover (Deep Researcher Reflect Evolve)](https://arxiv.org/abs/2601.20843)
*Saurav Prateek*

Main category: cs.AI

TL;DR: 提出Deep Researcher架构，通过顺序研究计划优化和候选交叉算法，在博士级研究任务上超越现有并行方法，在DeepResearch Bench上取得46.21分的最佳成绩


<details>
  <summary>Details</summary>
Motivation: 解决并行扩展范式在复杂研究任务中的固有局限性，特别是知识孤岛问题，寻求更高效的深度研究方法

Method: 采用顺序研究计划优化（保持全局研究上下文）、候选交叉算法（多LLM候选探索搜索空间）和一次性报告生成，基于Gemini 2.5 Pro模型

Result: 在DeepResearch Bench的100个博士级研究任务上获得46.21分，超越Claude Researcher、Nvidia AIQ等现有最佳研究助手，也超过之前的Static DRA工作

Conclusion: 顺序扩展范式持续优于并行自一致性范式，Deep Researcher架构在复杂研究任务中表现出色，为AI辅助研究提供了新方向

Abstract: This paper introduces a novel Deep Researcher architecture designed to generate detailed research reports on complex PhD level topics by addressing the inherent limitations of the Parallel Scaling paradigm. Our system utilizes two key innovations: Sequential Research Plan Refinement via Reflection and a Candidates Crossover algorithm. The sequential refinement process is demonstrated as an efficient method that allows the agent to maintain a centralized Global Research Context, enabling it to look back at current progress, reason about the research plan, and intelligently make changes at runtime. This dynamic adaptation contrasts with parallel approaches, which often suffer from siloed knowledge. The Candidates Crossover algorithm further enhances search efficiency by deploying multiple LLM candidates with varied parameters to explore a larger search space, with their findings synthesized to curate a comprehensive final research response. The process concludes with One Shot Report Generation, ensuring the final document is informed by a unified narrative and high fact density. Powered by the Gemini 2.5 Pro model, our Deep Researcher was evaluated on the DeepResearch Bench, a globally recognized benchmark of 100 doctoral level research tasks. Our architecture achieved an overall score of 46.21, demonstrating superior performance by surpassing leading deep research agents such as Claude Researcher, Nvidia AIQ Research Assistant, Perplexity Research, Kimi Researcher and Grok Deeper Search present on the DeepResearch Bench actively running leaderboard. This performance marginally exceeds our previous work, Static DRA, and reinforces the finding that sequential scaling consistently outperforms the parallel self consistency paradigm.

</details>


### [28] [SokoBench: Evaluating Long-Horizon Planning and Reasoning in Large Language Models](https://arxiv.org/abs/2601.20856)
*Sebastiano Monti,Carlo Nicolini,Gianni Pellegrini,Jacopo Staiano,Bruno Lepri*

Main category: cs.AI

TL;DR: 研究评估大语言模型的长程规划能力，发现超过25步的规划性能显著下降，表明存在固有的规划容量限制


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在复杂推理任务上的能力已被广泛测试，但其长程规划能力尚未得到充分研究。本研究旨在系统评估当前最先进大语言模型的规划和长程推理能力

Method: 提出基于Sokoban推箱子游戏的新基准测试，特意简化以隔离长程规划与状态持久性问题。同时测试了为模型配备PDDL（规划领域定义语言）解析、验证和求解工具的效果

Result: 发现当解决方案需要超过25步移动时，规划性能出现一致性的下降，表明存在前向规划容量的基本约束。配备PDDL工具能带来适度改进，但无法完全克服架构限制

Conclusion: 大语言模型存在固有的长程规划能力限制，仅通过测试时扩展方法可能无法克服这些架构限制，需要更根本的改进

Abstract: Although the capabilities of large language models have been increasingly tested on complex reasoning tasks, their long-horizon planning abilities have not yet been extensively investigated. In this work, we provide a systematic assessment of the planning and long-horizon reasoning capabilities of state-of-the-art Large Reasoning Models (LRMs). We propose a novel benchmark based on Sokoban puzzles, intentionally simplified to isolate long-horizon planning from state persistence. Our findings reveal a consistent degradation in planning performance when more than 25 moves are required to reach the solution, suggesting a fundamental constraint on forward planning capacity. We show that equipping LRMs with Planning Domain Definition Language (PDDL) parsing, validation, and solving tools allows for modest improvements, suggesting inherent architectural limitations which might not be overcome by test-time scaling approaches alone.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [29] [Quick Change Detection in Discrete-Time in Presence of a Covert Adversary](https://arxiv.org/abs/2601.20022)
*Amir Reza Ramtin,Philippe Nain,Don Towsley*

Main category: cs.IT

TL;DR: 论文研究了隐蔽最快变化检测问题，其中对手知道检测器的虚警约束参数γ，并选择依赖于γ的平稳后变化分布以尽可能长时间不被检测。当后变化分布随γ→∞收敛于前变化分布时，作者建立了平均检测延迟(ADD)和平均虚警时间(AT2FA)的精确渐近表达式，揭示了隐蔽行为的关键缩放规律。


<details>
  <summary>Details</summary>
Motivation: 经典变化检测问题假设后变化分布固定，但实际中对手可能知道检测器参数并调整策略。本文研究隐蔽对手场景，对手知道虚警约束参数γ并选择依赖于γ的后变化分布，旨在尽可能长时间不被检测，这比经典问题更具挑战性。

Method: 基于CuSum过程的理论基础，当后变化分布随γ→∞收敛于前变化分布时，严格分析平均检测延迟(ADD)和平均虚警时间(AT2FA)的渐近行为。推导精确渐近表达式，识别隐蔽行为的关键缩放规律。特别针对高斯和指数模型，在参数对抗扰动下，用Kullback-Leibler散度表征ADD的渐近行为。

Result: 建立了ADD和AT2FA的精确渐近表达式，扩展并改进了经典结果。发现隐蔽行为下ADD按Θ(γ)增长，而经典设置中ADD仅为O(log γ)。推导了对手能够保持隐蔽性的明确条件，即ADD = Θ(γ)。对于高斯和指数模型，用KL散度渐近表征了ADD作为前/后变化分布差异和γ的函数。

Conclusion: 论文揭示了隐蔽变化检测问题的根本不同行为：当对手知道检测器参数并调整策略时，检测延迟可能线性增长而非对数增长。这为理解对抗性环境下的变化检测提供了理论框架，对安全关键系统设计具有重要意义。

Abstract: We study the problem of covert quickest change detection in a discrete-time setting, where a sequence of observations undergoes a distributional change at an unknown time. Unlike classical formulations, we consider a covert adversary who has knowledge of the detector's false alarm constraint parameter $γ$ and selects a stationary post-change distribution that depends on it, seeking to remain undetected for as long as possible. Building on the theoretical foundations of the CuSum procedure, we rigorously characterize the asymptotic behavior of the average detection delay (ADD) and the average time to false alarm (AT2FA) when the post-change distribution converges to the pre-change distribution as $γ\to \infty$. Our analysis establishes exact asymptotic expressions for these quantities, extending and refining classical results that no longer hold in this regime. We identify the critical scaling laws governing covert behavior and derive explicit conditions under which an adversary can maintain covertness, defined by ADD = $Θ(γ)$, whereas in the classical setting, ADD grows only as $\mathcal{O}(\log γ)$. In particular, for Gaussian and Exponential models under adversarial perturbations of their respective parameters, we asymptotically characterize ADD as a function of the Kullback--Leibler divergence between the pre- and post-change distributions and $γ$.

</details>


### [30] [On Efficient Polyphase Network Implementation Using Successive Vector Approximation](https://arxiv.org/abs/2601.20411)
*Luiz F. da S. Coelho,Didier Le Ruyet,Paulo S. R. Diniz*

Main category: cs.IT

TL;DR: 提出一种基于匹配追踪的贪婪算法，将FBMC系统的多相网络从浮点数直接转换为SOPOT表示，实现无乘法器的能量高效硬件实现。


<details>
  <summary>Details</summary>
Motivation: FBMC系统需要能量高效实现，传统方法存在性能或复杂度问题，需要开发既能保持性能又能降低硬件复杂度的无乘法器实现方案。

Method: 使用基于匹配追踪的贪婪算法，将多相网络的数值表示直接从浮点数转换为SOPOT（有符号二次幂和）表示，实现无乘法器硬件设计。

Result: 与现有最先进的无乘法器硬件设计方法相比，该方法在相似计算复杂度下实现了更优越的性能。

Conclusion: 提出的SOPOT转换方法为FBMC系统提供了一种高效的能量优化硬件实现方案，在性能和复杂度之间取得了良好平衡。

Abstract: In this work, we explore an energy-efficient implementation of the polyphase network for a filter bank multicarrier (FBMC) system. The network is approximated using a greedy algorithm based on matching pursuits (MP) that converts the numerical representation directly from floating point to sum of signed powers of two (SOPOT), which is key for a multiplierless implementation. We compare this technique with other state-of-the-art methods for designing multiplierless hardware, and show that our technique achieves superior performance with similar computational complexity.

</details>


### [31] [Energy Efficient Downlink mMIMO Using Dynamic Antenna and Power Adaptation](https://arxiv.org/abs/2601.20586)
*Ravi Sharan B A G,Maliha Jada,Anders Karstensen,Daniela Laselva,Jyri Hämäläinen,Silvio Mandelli*

Main category: cs.IT

TL;DR: 提出一种联合天线和功率自适应方案，通过用户调度和资源分配优化网络能耗，在保证用户吞吐量的同时提升能效


<details>
  <summary>Details</summary>
Motivation: 6G通信系统需要满足高数据率需求，同时网络能耗节约对降低运营成本和实现可持续发展目标至关重要。需要一种能适应瞬时流量和信道条件变化的动态方案来优化能效。

Method: 提出动态联合天线和功率自适应方案：1) 使用多CSI-RS框架进行天线自适应；2) 采用POLITE（功率感知链路自适应）技术进行功率自适应；3) 结合用户调度和资源分配，根据用户瞬时流量和信道条件变化进行优化。

Result: 数值仿真表明，该方案在不同网络负载条件下均能平衡网络能耗节约和用户感知吞吐量。特别是在低负载和轻负载条件下，能显著改善小区内干扰，大幅提升整体网络能耗节约，同时确保用户吞吐量不受影响。

Conclusion: 提出的联合天线和功率自适应方案能有效提升6G mMIMO系统的能效，在保证用户体验的同时实现网络能耗优化，为可持续通信网络发展提供可行方案。

Abstract: Massive multiple-input multiple-output (mMIMO) technology and its future evolutions are expected to address the high data rate demands of sixth generation (6G) communication systems. At the same time, network energy savings (NES) is essential in reducing the operational costs and meeting the sustainability goals of network operators. In this regard, we propose a dynamic scheme for joint antenna and power adaptation to improve NES from a user scheduling and resource allocation perspective. Antenna adaptation is performed using the multiple channel state information resource signal (CSI-RS) framework. Furthermore, the recently introduced transmit power-aware link adaptation scheme, referred to as POLITE for short, is used as the power adaptation technique. The proposed scheme adapts to variations in users' instantaneous traffic and channel conditions to opportunistically maximize NES while also inherently accounting for the user throughput. Numerical simulation results show that the proposed scheme consistently achieves a balance between NES and user perceived throughput (UPT) for different network load conditions. Especially in low and light load conditions, the proposed scheme significantly improves the intra-cell interference and boosts the overall NES, while ensuring that UPT is unaffected.

</details>


### [32] [Shortest LCD embeddings of binary, ternary and quaternary linear codes](https://arxiv.org/abs/2601.20600)
*Junmin An,Ji-Hoon Hong,Jon-Lark Kim,Haeun Lim*

Main category: cs.IT

TL;DR: 该论文研究了如何将线性码嵌入到最优LCD码中，提出了最短LCD嵌入方法，并发现了多个新的最优LCD码。


<details>
  <summary>Details</summary>
Motivation: 自正交码的研究已经产生了许多最优自正交码，而LCD码作为自正交码的对偶（具有平凡hull），自然引发了一个问题：是否可以将线性码嵌入到最优LCD码中？

Method: 首先确定了需要向线性码的生成矩阵添加多少列才能将其嵌入到LCD码中，然后描述了线性码的最短LCD嵌入的所有可能形式。

Result: 从二进制和三元汉明码出发，得到了最小距离为4的最优LCD码。此外，发现了新的三元LCD码，参数包括[23,4,14]、[23,5,12]、[24,6,12]、[25,5,14]，以及一个新的四元LCD [21,10,8]码，每个的最小距离都比已知码大1。

Conclusion: 最短LCD嵌入方法对于在各种域上寻找最优LCD码是有效的，证明了该方法的实用性。

Abstract: In the recent years, there has been active research on self-orthogonal embeddings of linear codes since they yielded some optimal self-orthogonal codes. LCD codes have a trivial hull so they are counterparts of self-orthogonal codes. So it is a natural question whether one can embed linear codes into optimal LCD codes. To answer it, we first determine the number of columns to be added to a generator matrix of a linear code in order to embed the given code into an LCD code. Then we characterize all possible forms of shortest LCD embeddings of a linear code. As examples, we start from binary and ternary Hamming codes of small lengths and obtain optimal LCD codes with minimum distance 4. Furthermore, we find new ternary LCD codes with parameters including $[23, 4, 14]$, $[23, 5, 12]$, $[24, 6, 12]$, and $[25, 5, 14]$ and a new quaternary LCD $[21, 10, 8]$ code, each of which has minimum distance one greater than those of known codes. This shows that our shortest LCD embedding method is useful in finding optimal LCD codes over various fields.

</details>


### [33] [Helper-Assisted Coding for Gaussian Wiretap Channels: Deep Learning Meets PhySec](https://arxiv.org/abs/2601.20678)
*Vidhi Rana,Remi A. Chou,Taejoon Kim*

Main category: cs.IT

TL;DR: 首次设计使用深度学习和密码学工具的短分组长度编码，展示两个发射机在窃听信道中协作的实用性和优势，相比无辅助的现有编码在信息泄露方面有严格改进。


<details>
  <summary>Details</summary>
Motivation: 在窃听信道中，当窃听者信道噪声小于合法接收者时，传统方法无法实现正保密速率。已知解决方案需要第二个发射机（辅助者）帮助实现安全，但现有研究主要关注渐近分组长度和非构造性编码方案，缺乏实用、显式的短分组长度编码设计。

Method: 提出基于深度学习和密码学工具的编码设计：1）可靠性层：使用基于连续干扰消除方法的自编码器架构；2）安全层：使用通用哈希函数实现。还提出替代自编码器架构，允许解码器独立估计消息而无需接收端训练时连续消除干扰，显著减少训练时间。

Result: 所提出的编码在信息泄露方面相比不考虑辅助者的现有编码有严格改进。编码设计也适用于带辅助者的多址窃听信道，其中两个发射机向合法接收者发送保密消息。

Conclusion: 首次通过深度学习和密码学工具设计显式、短分组长度的编码，证明了两个发射机在窃听信道中协作的实际可行性和优势，为实际安全通信系统提供了实用解决方案。

Abstract: Consider the Gaussian wiretap channel, where a transmitter wishes to send a confidential message to a legitimate receiver in the presence of an eavesdropper. It is well known that if the eavesdropper experiences less channel noise than the legitimate receiver, then it is impossible for the transmitter to achieve positive secrecy rates. A known solution to this issue consists in involving a second transmitter, referred to as a helper, to help the first transmitter to achieve security. While such a solution has been studied for the asymptotic blocklength regime and via non-constructive coding schemes, in this paper, for the first time, we design explicit and short blocklength codes using deep learning and cryptographic tools to demonstrate the benefit and practicality of cooperation between two transmitters over the wiretap channel. Specifically, our proposed codes show strict improvement in terms of information leakage compared to existing codes that do not consider a helper. Our code design approach relies on a reliability layer, implemented with an autoencoder architecture based on the successive interference cancellation method, and a security layer implemented with universal hash functions. We also propose an alternative autoencoder architecture that significantly reduces training time by allowing the decoders to independently estimate messages without successively canceling interference by the receiver during training. Additionally, we show that our code design is also applicable to the multiple access wiretap channel with helpers, where two transmitters send confidential messages to the legitimate receiver.

</details>


### [34] [Reflected wireless signals under random spatial sampling](https://arxiv.org/abs/2601.20699)
*H. Paul Keeler*

Main category: cs.IT

TL;DR: 论文发现：空间中随机分布的发射器会产生功率直方图中的无界峰值，这些峰值出现在确定性传播模型的转折点处，对无线网络中的衰落估计有重要影响。


<details>
  <summary>Details</summary>
Motivation: 研究智能表面应用背景下，理解无线网络中由于墙壁反射引起的信号衰落现象，特别是功率振荡效应。

Method: 提出传播模型，通过简洁的数学论证解释功率直方图中出现无界峰值的机制，并将其应用于两平行被动墙壁间的单发射器物理模型。

Result: 发现当信号强度是距离的振荡或非单调函数时，随机定位的发射器会产生功率直方图中的无界峰值；对于发射器位于墙壁中间的特殊情况，得到了包含Lerch超越函数的紧凑闭式表达式。

Conclusion: 这项工作为城市中部署的智能表面设计提供了重要见解，揭示了无线网络中由于墙壁反射引起的功率振荡现象及其统计特性。

Abstract: We present a propagation model showing that a transmitter randomly positioned in space generates unbounded peaks in the histogram of the resulting power, provided the signal strength is an oscillating or non-monotonic function of distance. Specifically, these peaks are singularities in the empirical probability density that occur at turning point values of the deterministic propagation model. We explain the underlying mechanism of this phenomenon through a concise mathematical argument. This observation has direct implications for estimating random propagation effects such as fading, particularly when reflections off walls are involved.
  Motivated by understanding intelligent surfaces, we apply this fundamental result to a physical model consisting of a single transmitter between two parallel passive walls. We analyze signal fading due to reflections and observe power oscillations resulting from wall reflections -- a phenomenon long studied in waveguides but relatively unexplored in wireless networks. For the special case where the transmitter is placed halfway between the walls, we present a compact closed-form expression for the received signal involving the Lerch transcendent function. The insights from this work can inform design decisions for intelligent surfaces deployed in cities.

</details>


### [35] [Anytime-Valid Quantum Tomography via Confidence Sequences](https://arxiv.org/abs/2601.20761)
*Aldo Cumitini,Luca Barletta,Osvaldo Simeone*

Main category: cs.IT

TL;DR: 提出了一种在任何时间都有效的量子态层析方法，通过置信序列为当前状态估计提供严格的统计保证


<details>
  <summary>Details</summary>
Motivation: 现有量子态层析方法在测量序列进行过程中无法提供有效的统计不确定性量化，需要一种在任何时间都能提供可靠置信区间的方法

Method: 将现有的量子态层析技术与"随时有效置信序列"统计方法相结合，为当前状态点估计构建置信集，保证以用户定义的概率包含真实量子态

Result: 数值结果证实了所提出的随时有效量子态层析方法的理论覆盖特性，能够在任何测量时间提供有效的统计保证

Conclusion: 该方法为量子态层析提供了严格的统计框架，能够在测量序列的任何时间点量化状态估计的不确定性，具有重要的理论和实践意义

Abstract: In this letter, we address the problem of developing quantum state tomography (QST) methods that remain valid at any time during a sequence of measurements. Specifically, the aim is to provide a rigorous quantification of the uncertainty associated with the current state estimate as data are acquired incrementally. To this end, the proposed framework augments existing QST techniques by associating current point estimates of the state with confidence sets that are guaranteed to contain the true quantum state with a user-defined probability. The methodology is grounded in recent statistical advances in anytime-valid confidence sequences. Numerical results confirm the theoretical coverage properties of the proposed anytime-valid QST.

</details>


### [36] [Repeater-Assisted Massive MIMO Full-Duplex Communications](https://arxiv.org/abs/2601.20822)
*Mohammadali Mohammadi,Dhanushka Kudathanthirige,Himal A. Suraweera,Hien Quoc Ngo,Michail Matthaiou*

Main category: cs.IT

TL;DR: 本文研究全双工通信中多中继器的权重优化问题，通过连续凸逼近技术最大化加权最小频谱效率之和，相比半双工系统实现4倍和2.5倍的频谱效率提升。


<details>
  <summary>Details</summary>
Motivation: 在全双工大规模MIMO系统中，多个单天线中继器同时放大转发信号，需要优化中继器权重以最大化上下行用户设备的加权最小频谱效率，解决现有系统频谱效率不足的问题。

Method: 采用连续凸逼近技术处理非凸优化问题，优化每个活动中继器的权重配置，在相同频段同时服务多个上下行用户设备。

Result: 优化的全双工设计相比半双工系统实现频谱效率提升：最高达到4倍和2.5倍的改进，性能优于无中继辅助和有中继辅助的基准系统。

Conclusion: 提出的中继器权重优化方法能有效提升全双工大规模MIMO系统的频谱效率，为无线网络性能优化提供了有效解决方案。

Abstract: We consider a wireless network comprising multiple singleantenna repeaters that amplify and instantaneously re-transmit received signals in a full-duplex (FD) communication setting. Specifically, we study a massive multiple-input multiple output base station that simultaneously serves multiple uplink (UL) and downlink (DL) user equipment (UE) over the same frequency band. The focus is on the problem of repeater weight optimization at each active repeater to maximize the sum of the weighted minimum spectral efficiencies (SEs) for both UL and DL UEs. The resulting non-convex optimization problem is tackled using a successive convex approximation technique. To demonstrate the effectiveness of the proposed approach, we evaluate its performance against benchmark systems with and without repeater assistance. The optimized FD design achieves SE improvements of up to 4-fold and 2.5-fold compared to its half-duplex counterpart.

</details>


### [37] [Construction and Decoding of Convolutional Codes with optimal Column Distances](https://arxiv.org/abs/2601.20825)
*Julia Lieb,Michael Schaller*

Main category: cs.IT

TL;DR: 提出了一种在任意有限域上构造具有最优列距离的卷积码的方法，并证明对于给定参数，所构造的码是唯一能达到最优列距离的。这些码的结构与一阶Reed-Muller分组码密切相关，并利用此关系开发了针对这些码的简化复杂度Viterbi算法。


<details>
  <summary>Details</summary>
Motivation: 传统最大距离轮廓(MDP)卷积码的构造通常需要非常大的有限域，而具有最优列距离的卷积码可以在任意有限域上最大化列距离。本文旨在解决在任意有限域上构造具有最优列距离的卷积码的问题。

Method: 提出了一种构造具有最优列距离的卷积码的方法。这些码的结构与一阶Reed-Muller分组码有很强的关联性，作者利用这种关系开发了针对这些特定码的简化复杂度Viterbi算法。

Result: 成功构造了在任意有限域上具有最优列距离的卷积码，并证明对于所考虑的参数，所构造的码是唯一能达到最优列距离的。同时开发了针对这些码的简化复杂度Viterbi算法。

Conclusion: 本文提供了一种在任意有限域上构造具有最优列距离的卷积码的有效方法，这些码与一阶Reed-Muller分组码密切相关，并且针对这些特定结构开发了高效的译码算法，为实际应用提供了理论和技术支持。

Abstract: The construction of Maximum Distance Profile (MDP) convolutional codes in general requires the use of very large finite fields. In contrast convolutional codes with optimal column distances maximize the column distances for a given arbitrary finite field. In this paper, we present a construction of such convolutional codes. In addition, we prove that for the considered parameters the codes that we constructed are the only ones achieving optimal column distances. The structure of the presented convolutional codes with optimal column distances is strongly related to first order Reed-Muller block codes and we leverage this fact to develop a reduced complexity version of the Viterbi algorithm for these codes.

</details>


### [38] [Low-Complexity Pilot-Aided Doppler Ambiguity Estimation for OTFS Parametric Channel Estimation](https://arxiv.org/abs/2601.20827)
*Bo-Yuan Chen,Hsuan-Jung Su*

Main category: cs.IT

TL;DR: 本文提出了一种低复杂度导频辅助的多普勒模糊检测与补偿框架，用于解决OTFS调制在高移动性5G非地面网络中因多普勒模糊导致的信道估计失效问题。


<details>
  <summary>Details</summary>
Motivation: 在5G非地面网络等高移动性场景中，低轨卫星的极端轨道速度导致物理多普勒频移超出基本网格范围，产生多普勒模糊问题。这种模糊会导致严重的模型失配，使传统的最大似然估计信道估计器失效。

Method: 首先从数学上推导了存在混叠时的OTFS输入输出关系，发现多普勒模糊表现为沿延迟维度的独特相位旋转。基于这一发现，开发了一个两阶段估计器：1) 利用导频符号间的成对相位差识别整数模糊；2) 采用精炼的最大似然估计进行信道恢复。研究了两种导频排列方式：带保护区的嵌入式导频和数据环绕导频，以分析干扰抑制和频谱效率之间的权衡。

Result: 仿真结果表明，所提方案有效消除了由模糊引起的错误平台，实现了与穷举搜索基准相当的误码率和归一化均方误差性能，同时保持了与标准最大似然估计相似的计算复杂度。

Conclusion: 该研究提出了一种有效的低复杂度解决方案，解决了OTFS在高移动性场景中的多普勒模糊问题，为5G非地面网络等应用提供了实用的信道估计方法。

Abstract: Orthogonal Time Frequency Space (OTFS) modulation offers robust performance in high-mobility scenarios by transforming time-varying channels into the delay-Doppler (DD) domain. However, in high-mobility environment such as emerging 5G Non-Terrestrial Networks (NTN), the extreme orbital velocities of Low Earth Orbit (LEO) satellites frequently cause the physical Doppler shifts to exceed the fundamental grid range. This Doppler ambiguity induces severe model mismatch and renders traditional MLE channel estimators ineffective. To address this challenge, this paper proposes a novel low-complexity pilot-aided Doppler ambiguity detection and compensation framework. We first mathematically derive the OTFS input-output relationship in the presence of aliasing, revealing that Doppler ambiguity manifests itself as a distinct phase rotation along the delay dimension. Leveraging this insight, we developed a two-stage estimator that utilizes pairwise phase differences between pilot symbols to identify the integer ambiguity, followed by a refined Maximum Likelihood Estimation (MLE) for channel recovery. We investigate two pilot arrangements, Embedded Pilot with Guard Zone (EP-GZ) and Data-Surrounded Pilot (DSP), to analyze the trade-off between interference suppression and spectral efficiency. Simulation results demonstrate that the proposed scheme effectively eliminates the error floor caused by ambiguity, achieving Bit Error Rate (BER) and Normalized Mean Square Error (NMSE) performance comparable to the exhaustive search benchmark while maintaining a computational complexity similar to standard MLE.

</details>
