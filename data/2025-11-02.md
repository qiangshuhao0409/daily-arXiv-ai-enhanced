<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 8]
- [cs.AI](#cs.AI) [Total: 45]
- [cs.IT](#cs.IT) [Total: 6]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [A Zero Added Loss Multiplexing (ZALM) Source Simulation](https://arxiv.org/abs/2510.26009)
*Jerry Horgan,Alexander Nico-Katz,Shelbi L. Jenkins,Ashley N. Tittlebaugh,Vivek Visan,Rahan Bali,Marco Ruffini,Boulat A. Bash,Daniel C. Kilper*

Main category: cs.NI

TL;DR: ZALM技术提供宽带、每通道预知EPR对，具有丰富的参数空间。该模拟器展示了设计选择如何影响输出率和保真度，支持20+可调参数和两种模式。


<details>
  <summary>Details</summary>
Motivation: 开发模块化ZALM模拟器，用于研究设计选择对量子纠缠源性能的影响，支持特定量子存储器的协同设计。

Method: 基于NetSquid和QSI控制器构建模拟器，包含SPDC源、干涉、DWDM滤波、光纤延迟等可复用组件，采用物理模型捕获HOM可见性、插入损耗等参数。

Result: 默认配置下平均保真度保持0.8，但ebit率从源端的0.0175降至50km处的0.0；缩小SPDC简并带宽可显著提高ebit率而不影响保真度。

Conclusion: 该模拟器能够为特定量子存储器协同设计源、滤波和前馈设置，并作为端到端量子网络研究的构建模块。

Abstract: Zero Added Loss Multiplexing (ZALM) offers broadband, per channel heralded
EPR pairs, with a rich parameter space that allows its performance to be
tailored for specific applications. We present a modular ZALM simulator that
demonstrates how design choices affect output rate and fidelity. Built in
NetSquid with QSI controllers, it exposes 20+ tunable parameters, supports
IDEAL and REALISTIC modes, and provides reusable components for Spontaneous
Parametric Down Conversion (SPDC) sources, interference, Dense Wavelength
Division Multiplexing (DWDM) filtering, fiber delay, active polarization gates,
detectors, and lossy fiber. Physics based models capture Hong Ou Mandel (HOM)
visibility, insertion loss, detector efficiency, gate errors, and attenuation.
Using this tool, we map trade offs among fidelity, link distance, and entangled
pairs per use, and show how SPDC bandwidth and DWDM grid spacing steer
performance. Using the default configuration settings, average fidelity emains
constant at 0.8 but the ebit rate decreases from 0.0175 at the source to 0.0 at
50 km; narrowing the SPDC degeneracy bandwidth increases the ebit rate
significantly without affecting fidelity. The simulator enables codesign of
source, filtering, and feedforward settings for specific quantum memories and
integrates as a building block for end to end quantum network studies.

</details>


### [2] [Performance Analysis of Dynamic Equilibria in Joint Path Selection and Congestion Control](https://arxiv.org/abs/2510.26060)
*Sina Keshvadi*

Main category: cs.NI

TL;DR: 本文开发了首个分析路径选择和拥塞控制联合动态的公理化框架，揭示了协议设计中可预测性能与用户中心目标之间的基本权衡，并发现智能体迁移可以反直觉地增强稳定性。


<details>
  <summary>Details</summary>
Motivation: 路径感知网络赋予终端主机细粒度流量转发控制能力，但非协调的贪婪路径选择可能引发持续高幅度网络振荡，这种现象的定量性能影响一直未被充分理解。

Method: 开发了分析路径选择和拥塞控制联合动态的公理化框架，通过形式化表征系统的动态均衡状态，并提供一套公理来评估其效率、丢包避免、收敛性、公平性和响应性。

Result: 分析揭示了协议设计中可预测性能（效率、收敛性）与用户中心目标（公平性、响应性）之间的基本权衡，但效率、收敛性和丢包避免可以同时优化。智能体迁移可以反直觉地增强稳定性。

Conclusion: 这些发现为未来路径感知互联网设计稳健、高性能协议提供了原则性设计指南。

Abstract: Path-aware networking, a cornerstone of next-generation architectures like
SCION and Multipath QUIC, empowers end-hosts with fine-grained control over
traffic forwarding. This capability, however, introduces a critical stability
risk: uncoordinated, greedy path selection by a multitude of agents can induce
persistent, high-amplitude network oscillations. While this phenomenon is
well-known, its quantitative performance impact across key metrics has remained
poorly understood. In this paper, we address this gap by developing the first
axiomatic framework for analyzing the joint dynamics of path selection and
congestion control. Our model enables the formal characterization of the
system's dynamic equilibria-the stable, periodic patterns of oscillation-and
provides a suite of axioms to rate their performance in terms of efficiency,
loss avoidance, convergence, fairness, and responsiveness. Our analysis reveals
a fundamental trade-off in protocol design between predictable performance
(efficiency, convergence) and user-centric goals (fairness, responsiveness). We
prove, however, that no such trade-off exists among efficiency, convergence,
and loss avoidance, which can be simultaneously optimized through careful
parameter tuning. Furthermore, we find that agent migration can,
counter-intuitively, enhance stability by de-synchronizing traffic, a
theoretical result validated by our simulations. These findings provide a
principled design map for engineering robust, high-performance protocols for
the future path-aware Internet.

</details>


### [3] [Symmetry-Driven Asynchronous Forwarding for Reliable Distributed Coordination in Toroidal Networks](https://arxiv.org/abs/2510.26071)
*Shenshen Luan,Yumo Tian,Xinyu Zhang,Qingwen Zhang,Tianheng Wang,Yan Yang,Shuguo Xie*

Main category: cs.NI

TL;DR: 提出了一种基于环面拓扑对称性的异步转发机制，利用几何特性实现可靠数据包传输，无需控制平面协调，在1%链路故障率下可减少17.5%的数据包丢失。


<details>
  <summary>Details</summary>
Motivation: 大规模分布式系统（如卫星星座和高性能计算集群）需要在不稳定链路下保持协调的通信原语。传统路由方案在链路故障后的控制平面同步期间存在严重的数据包丢失问题。

Method: 利用环面拓扑的几何特性，提出对称驱动的异步转发机制。通过拓扑势梯度建模数据包流，利用对称性破坏故障自然诱导的反向流进行故障规避。提出两种本地转发策略：反向流对向优先(RF-CF)和侧向优先(RF-LF)。

Result: 在16×16环面上的渗流分析和数据包级模拟显示，该机制在1%链路故障率下可减少高达17.5%的数据包丢失，其中RF-LF策略贡献了28%的成功传输数据包。

Conclusion: 该工作建立了拓扑对称性与通信弹性之间的基础联系，为增强分布式系统提供了一个轻量级、协议无关的底层机制。

Abstract: The proliferation of large-scale distributed systems, such as satellite
constellations and high-performance computing clusters, demands robust
communication primitives that maintain coordination under unreliable links. The
torus topology, with its inherent rotational and reflection symmetries, is a
prevalent architecture in these domains. However, conventional routing schemes
suffer from substantial packet loss during control-plane synchronization after
link failures. This paper introduces a symmetry-driven asynchronous forwarding
mechanism that leverages the torus's geometric properties to achieve reliable
packet delivery without control-plane coordination. We model packet flow using
a topological potential gradient and demonstrate that symmetry-breaking
failures naturally induce a reverse flow, which we harness for fault
circumvention. We propose two local forwarding strategies, Reverse Flow with
Counter-facing Priority (RF-CF) and Lateral-facing Priority (RF-LF), that
guarantee reachability to the destination via forward-flow phase transition
points, without protocol modifications or additional in-packet overhead.
Through percolation analysis and packet-level simulations on a 16 x 16 torus,
we show that our mechanism reduces packet loss by up to 17.5% under a 1% link
failure rate, with the RF-LF strategy contributing to 28% of successfully
delivered packets. This work establishes a foundational link between
topological symmetry and communication resilience, providing a lightweight,
protocol-agnostic substrate for enhancing distributed systems.

</details>


### [4] [FGGM: Formal Grey-box Gradient Method for Attacking DRL-based MU-MIMO Scheduler](https://arxiv.org/abs/2510.26075)
*Thanh Le,Hai Duong,Yusheng Ji,ThanhVu Nguyen,John C. S. Lui*

Main category: cs.NI

TL;DR: 本文研究了5G MU-MIMO系统中对抗性用户如何利用DRL策略的观察归一化器来发起吞吐量降低攻击，提出了基于多面体抽象域的FGGM攻击方案，能在不知道受害者精确CSI的情况下将受害者网络吞吐量降低高达70%。


<details>
  <summary>Details</summary>
Motivation: 5G MU-MIMO系统中DRL方法存在固有安全问题，现有研究假设对抗性用户能获取受害者精确CSI值，这在LTE/5G上行传输中不切实际。本文旨在探索仅通过观察归一化器信息就能发起的攻击。

Method: 提出FGGM攻击方案，利用多面体抽象域技术来边界神经网络输出，基于观察归一化器的均值和方差估计受害者CSI的上下界，找到一组能在整个受害者观察范围内实现攻击目标的恶意CSI向量。

Result: 实验结果表明，FGGM能够确定一组由对抗性用户控制的对抗性CSI向量，在整个模拟过程中重复使用这些CSI，在不知道受害者精确本地观察值的情况下将受害者网络吞吐量降低高达70%。

Conclusion: 本研究作为一个案例研究，可应用于许多其他基于DRL的问题，如背包导向的资源分配问题，揭示了DRL系统在安全方面的潜在脆弱性。

Abstract: In 5G mobile communication systems, MU-MIMO has been applied to enhance
spectral efficiency and support high data rates. To maximize spectral
efficiency while providing fairness among users, the base station (BS) needs to
selects a subset of users for data transmission. Given that this problem is
NP-hard, DRL-based methods have been proposed to infer the near-optimal
solutions in real-time, yet this approach has an intrinsic security problem.
This paper investigates how a group of adversarial users can exploit
unsanitized raw CSIs to launch a throughput degradation attack. Most existing
studies only focused on systems in which adversarial users can obtain the exact
values of victims' CSIs, but this is impractical in the case of uplink
transmission in LTE/5G mobile systems. We note that the DRL policy contains an
observation normalizer which has the mean and variance of the observation to
improve training convergence. Adversarial users can then estimate the upper and
lower bounds of the local observations including the CSIs of victims based
solely on that observation normalizer. We develop an attacking scheme FGGM by
leveraging polytope abstract domains, a technique used to bound the outputs of
a neural network given the input ranges. Our goal is to find one set of
intentionally manipulated CSIs which can achieve the attacking goals for the
whole range of local observations of victims. Experimental results demonstrate
that FGGM can determine a set of adversarial CSI vector controlled by
adversarial users, then reuse those CSIs throughout the simulation to reduce
the network throughput of a victim up to 70\% without knowing the exact value
of victims' local observations. This study serves as a case study and can be
applied to many other DRL-based problems, such as a knapsack-oriented resource
allocation problems.

</details>


### [5] [From req/res to pub/sub: Exploring Media over QUIC Transport for DNS](https://arxiv.org/abs/2510.26234)
*Mathis Engelbart,Mike Kosek,Lars Eggert,Jörg Ott*

Main category: cs.NI

TL;DR: 本文提出了一种基于发布-订阅模式的DNS变体，使用Media-over-QUIC架构来推送资源记录更新，相比传统DNS能显著减少更新延迟和流量。


<details>
  <summary>Details</summary>
Motivation: 传统DNS设计为静态目录服务，资源记录很少变化，但现代用例如负载均衡和服务发现需要更动态的更新机制，需要一种能主动推送更新的DNS变体。

Method: 基于Media-over-QUIC架构设计了发布-订阅DNS系统原型，包括系统架构和协议提案，支持向所有对特定记录感兴趣的解耦器推送更新。

Result: 原型实现表明发布-订阅DNS能显著减少记录更新时间，支持内容分发网络中的负载均衡等用例，同时减少更新流量。

Conclusion: DNS能从发布-订阅变体中受益，但该架构也带来了新的挑战，包括端点状态管理开销增加和首次查询延迟增加。

Abstract: The DNS is a key component of the Internet. Originally designed to facilitate
the resolution of host names to IP addresses, its scope has continuously
expanded over the years, today covering use cases such as load balancing or
service discovery. While DNS was initially conceived as a rather static
directory service in which resource records (RR) only change rarely, we have
seen a number of use cases over the years where a DNS flavor that isn't purely
based upon requesting and caching RRs, but rather on an active distribution of
updates for all resolvers that showed interest in the respective records in the
past, would be preferable. In this paper, we thus explore a publish-subscribe
variant of DNS based on the Media-over-QUIC architecture, where we devise a
strawman system and protocol proposal to enable pushing RR updates. We provide
a prototype implementation, finding that DNS can benefit from a
publish-subscribe variant: next to limiting update traffic, it can considerably
reduce the time it takes for a resolver to receive the latest version of a
record, thereby supporting use cases such as load balancing in content
distribution networks. The publish-subscribe architecture also brings new
challenges to the DNS, including a higher overhead for endpoints due to
additional state management, and increased query latencies on first lookup, due
to session establishment latencies.

</details>


### [6] [Joint Computing Resource Allocation and Task Offloading in Vehicular Fog Computing Systems Under Asymmetric Information](https://arxiv.org/abs/2510.26256)
*Geng Sun,Siyi Chen,Zemin Sun,Long He,Jiacheng Wang,Dusit Niyato,Zhu Han,Dong In Kim*

Main category: cs.NI

TL;DR: 提出了一种联合计算资源分配和任务卸载方法（JCRATOA），通过凸优化和契约理论解决车载雾计算中的延迟最小化问题。


<details>
  <summary>Details</summary>
Motivation: 车载雾计算（VFC）面临资源受限和信息不对称的挑战，RSU资源有限且车辆不愿共享私有信息，导致资源分配效率低下和任务卸载复杂化。

Method: 构建分层VFC架构，提出JCRATOA方法：使用凸优化进行RSU资源分配，契约理论激励FV资源分配，以及双边匹配方法进行任务卸载。

Result: 仿真结果表明，JCRATOA在任务完成延迟、完成率、系统吞吐量和资源利用公平性方面表现优异，并能有效满足约束条件。

Conclusion: 所提出的JCRATOA方法能够有效解决车载雾计算中的资源分配和任务卸载问题，提升系统性能。

Abstract: Vehicular fog computing (VFC) has emerged as a promising paradigm, which
leverages the idle computational resources of nearby fog vehicles (FVs) to
complement the computing capabilities of conventional vehicular edge computing.
However, utilizing VFC to meet the delay-sensitive and computation-intensive
requirements of the FVs poses several challenges. First, the limited resources
of road side units (RSUs) struggle to accommodate the growing and diverse
demands of vehicles. This limitation is further exacerbated by the information
asymmetry between the controller and FVs due to the reluctance of FVs to
disclose private information and to share resources voluntarily. This
information asymmetry hinders the efficient resource allocation and
coordination. Second, the heterogeneity in task requirements and the varying
capabilities of RSUs and FVs complicate efficient task offloading, thereby
resulting in inefficient resource utilization and potential performance
degradation. To address these challenges, we first present a hierarchical VFC
architecture that incorporates the computing capabilities of both RSUs and FVs.
Then, we formulate a delay minimization optimization problem (DMOP), which is
an NP-hard mixed integer nonlinear programming problem. To solve the DMOP, we
propose a joint computing resource allocation and task offloading approach
(JCRATOA). Specifically, we propose a convex optimization-based method for RSU
resource allocation and a contract theory-based incentive mechanism for FV
resource allocation. Moreover, we present a two-sided matching method for task
offloading by employing the matching game. Simulation results demonstrate that
the proposed JCRATOA is able to achieve superior performances in task
completion delay, task completion ratio, system throughput, and resource
utilization fairness, while effectively meeting the satisfying constraints.

</details>


### [7] [Wireless Memory Approximation for Energy-efficient Task-specific IoT Data Retrieval](https://arxiv.org/abs/2510.26473)
*Junya Shiraishi,Shashi Raj Pandey,Israel Leyva-Mayorga,Petar Popovski*

Main category: cs.NI

TL;DR: 提出两种无线内存管理方法（无线内存激活和无线内存近似）来减少DRAM在ML模型存储中的刷新能耗，特别针对资源受限的IoT设备。


<details>
  <summary>Details</summary>
Motivation: DRAM用于存储ML模型时，周期性刷新在待机期间会造成大量能源浪费，这对资源受限的IoT设备尤为显著。

Method: 采用无线内存激活和无线内存近似两种方法，通过考虑ML模型使用时序和相关性来高效管理可用内存。

Result: 数值结果显示，所提方案在满足检索精度约束的同时，能实现比始终开启方法更低的能耗。

Conclusion: 无线内存管理方法能有效降低DRAM在ML推理任务中的能耗，特别适合资源受限的IoT设备。

Abstract: The use of Dynamic Random Access Memory (DRAM) for storing Machine Learning
(ML) models plays a critical role in accelerating ML inference tasks in the
next generation of communication systems. However, periodic refreshment of DRAM
results in wasteful energy consumption during standby periods, which is
significant for resource-constrained Internet of Things (IoT) devices. To solve
this problem, this work advocates two novel approaches: 1) wireless memory
activation and 2) wireless memory approximation. These enable the wireless
devices to efficiently manage the available memory by considering the timing
aspects and relevance of ML model usage; hence, reducing the overall energy
consumption. Numerical results show that our proposed scheme can realize
smaller energy consumption than the always-on approach while satisfying the
retrieval accuracy constraint.

</details>


### [8] [Low-Altitude UAV-Carried Movable Antenna for Joint Wireless Power Transfer and Covert Communications](https://arxiv.org/abs/2510.26628)
*Chuang Zhang,Geng Sun,Jiahui Li,Jiacheng Wang,Qingqing Wu,Dusit Niyato,Shiwen Mao,Tony Q. S. Quek*

Main category: cs.NI

TL;DR: 提出了一种低空无人机载移动天线增强传输系统，联合无线能量传输和隐蔽通信，为物联网节点补充能量并建立隐蔽用户传输链路。


<details>
  <summary>Details</summary>
Motivation: 物联网网络激增需要可持续能源解决方案，但无线能量传输的视距信道容易暴露敏感操作数据给攻击者。

Method: 使用混合专家增强的软演员-评论家算法，结合稀疏Top-K门控混合浅层专家架构来表示多模态策略分布，并加入动作投影模块。

Result: 仿真结果表明，该方法显著优于基线方法和其他最先进的深度强化学习算法。

Conclusion: 所提出的系统能有效解决物联网节点的能量补充和隐蔽通信问题，在多个优化目标间取得良好平衡。

Abstract: The proliferation of Internet of Things (IoT) networks has created an urgent
need for sustainable energy solutions, particularly for the battery-constrained
spatially distributed IoT nodes. While low-altitude uncrewed aerial vehicles
(UAVs) employed with wireless power transfer (WPT) capabilities offer a
promising solution, the line-of-sight channels that facilitate efficient energy
delivery also expose sensitive operational data to adversaries. This paper
proposes a novel low-altitude UAV-carried movable antenna-enhanced transmission
system joint WPT and covert communications, which simultaneously performs
energy supplements to IoT nodes and establishes transmission links with a
covert user by leveraging wireless energy signals as a natural cover. Then, we
formulate a multi-objective optimization problem that jointly maximizes the
total harvested energy of IoT nodes and sum achievable rate of the covert user,
while minimizing the propulsion energy consumption of the low-altitude UAV. To
address the non-convex and temporally coupled optimization problem, we propose
a mixture-of-experts-augmented soft actor-critic (MoE-SAC) algorithm that
employs a sparse Top-K gated mixture-of-shallow-experts architecture to
represent multimodal policy distributions arising from the conflicting
optimization objectives. We also incorporate an action projection module that
explicitly enforces per-time-slot power budget constraints and antenna position
constraints. Simulation results demonstrate that the proposed approach
significantly outperforms some baseline approaches and other state-of-the-art
deep reinforcement learning algorithms.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling](https://arxiv.org/abs/2510.26603)
*Reda El Makroum,Sebastian Zwickl-Bernhard,Lukas Kranzl*

Main category: cs.AI

TL;DR: 提出了一种基于大语言模型的自主家庭能源管理系统，能够从自然语言请求直接协调多设备调度，无需示例演示即可实现最优调度。


<details>
  <summary>Details</summary>
Motivation: 住宅需求响应能力需要大幅提升，但现有家庭能源管理系统因用户交互障碍而采用有限，需要将日常偏好转换为技术参数。

Method: 采用分层架构，结合一个协调器和三个专业代理，使用ReAct模式进行迭代推理，集成Google日历进行上下文感知的截止时间提取。

Result: Llama-3.3-70B在所有场景中成功协调所有设备，与混合整数线性规划计算的最优基准相匹配，而其他模型在单设备性能上表现完美但难以同时协调所有设备。

Conclusion: 大语言模型可以作为自主协调器管理从自然语言输入到多设备调度的完整工作流程，但分析性查询处理在没有明确指导的情况下仍然不可靠。

Abstract: The electricity sector transition requires substantial increases in
residential demand response capacity, yet Home Energy Management Systems (HEMS)
adoption remains limited by user interaction barriers requiring translation of
everyday preferences into technical parameters. While large language models
have been applied to energy systems as code generators and parameter
extractors, no existing implementation deploys LLMs as autonomous coordinators
managing the complete workflow from natural language input to multi-appliance
scheduling. This paper presents an agentic AI HEMS where LLMs autonomously
coordinate multi-appliance scheduling from natural language requests to device
control, achieving optimal scheduling without example demonstrations. A
hierarchical architecture combining one orchestrator with three specialist
agents uses the ReAct pattern for iterative reasoning, enabling dynamic
coordination without hardcoded workflows while integrating Google Calendar for
context-aware deadline extraction. Evaluation across three open-source models
using real Austrian day-ahead electricity prices reveals substantial capability
differences. Llama-3.3-70B successfully coordinates all appliances across all
scenarios to match cost-optimal benchmarks computed via mixed-integer linear
programming, while other models achieve perfect single-appliance performance
but struggle to coordinate all appliances simultaneously. Progressive prompt
engineering experiments demonstrate that analytical query handling without
explicit guidance remains unreliable despite models' general reasoning
capabilities. We open-source the complete system including orchestration logic,
agent prompts, tools, and web interfaces to enable reproducibility, extension,
and future research.

</details>


### [10] [Towards Piece-by-Piece Explanations for Chess Positions with SHAP](https://arxiv.org/abs/2510.25775)
*Francesco Spinnato*

Main category: cs.AI

TL;DR: 将SHAP可解释AI技术应用于国际象棋分析，通过系统性地移除棋子来计算每个棋子对引擎评估的贡献度，提供人类可理解的解释。


<details>
  <summary>Details</summary>
Motivation: 传统国际象棋引擎提供精确但不透明的评估分数，无法揭示单个棋子或模式的贡献。需要一种方法来解释引擎评估背后的具体原因。

Method: 将棋子视为特征，采用SHAP方法通过系统性地移除棋子来计算每个棋子的加性贡献度，该方法受到传统象棋教学中移除棋子分析位置的启发。

Result: 开发了一种能够为国际象棋引擎评估提供局部忠实且人类可解释的棋子贡献度分析方法。

Conclusion: 该方法为可视化、人类训练和引擎比较开辟了新可能性，并发布了代码和数据以促进可解释象棋AI的进一步研究。

Abstract: Contemporary chess engines offer precise yet opaque evaluations, typically
expressed as centipawn scores. While effective for decision-making, these
outputs obscure the underlying contributions of individual pieces or patterns.
In this paper, we explore adapting SHAP (SHapley Additive exPlanations) to the
domain of chess analysis, aiming to attribute a chess engines evaluation to
specific pieces on the board. By treating pieces as features and systematically
ablating them, we compute additive, per-piece contributions that explain the
engines output in a locally faithful and human-interpretable manner. This
method draws inspiration from classical chess pedagogy, where players assess
positions by mentally removing pieces, and grounds it in modern explainable AI
techniques. Our approach opens new possibilities for visualization, human
training, and engine comparison. We release accompanying code and data to
foster future research in interpretable chess AI.

</details>


### [11] [An Agentic Framework for Rapid Deployment of Edge AI Solutions in Industry 5.0](https://arxiv.org/abs/2510.25813)
*Jorge Martinez-Gil,Mario Pichler,Nefeli Bountouni,Sotiris Koussouris,Marielena Márquez Barreiro,Sergio Gusmeroli*

Main category: cs.AI

TL;DR: 提出了一个面向工业5.0的新型框架，简化AI模型在边缘设备上的部署，通过本地推理和实时处理降低延迟，采用基于代理的架构实现灵活集成。


<details>
  <summary>Details</summary>
Motivation: 解决工业环境中AI模型部署复杂、延迟高的问题，支持边缘计算和实时处理，满足工业5.0对智能化和灵活性的需求。

Method: 采用基于代理的架构设计，支持人类、算法和协作代理执行明确定义的任务，实现模块化集成并保持低资源需求。

Result: 在食品工业真实场景的初步评估显示，部署时间和系统适应性性能得到改善。

Conclusion: 该框架为工业5.0提供了有效的AI模型边缘部署解决方案，具有实际应用价值，源代码已公开。

Abstract: We present a novel framework for Industry 5.0 that simplifies the deployment
of AI models on edge devices in various industrial settings. The design reduces
latency and avoids external data transfer by enabling local inference and
real-time processing. Our implementation is agent-based, which means that
individual agents, whether human, algorithmic, or collaborative, are
responsible for well-defined tasks, enabling flexibility and simplifying
integration. Moreover, our framework supports modular integration and maintains
low resource requirements. Preliminary evaluations concerning the food industry
in real scenarios indicate improved deployment time and system adaptability
performance. The source code is publicly available at
https://github.com/AI-REDGIO-5-0/ci-component.

</details>


### [12] [Symbolically Scaffolded Play: Designing Role-Sensitive Prompts for Generative NPC Dialogue](https://arxiv.org/abs/2510.25820)
*Vanessa Figueiredo,David Elumeze*

Main category: cs.AI

TL;DR: 研究比较了高约束和低约束提示在基于GPT-4o的侦探游戏中的效果，发现约束程度对玩家体验影响不大，但角色依赖的支架效应明显。


<details>
  <summary>Details</summary>
Motivation: 探索约束提示是否能真正改善玩家体验，特别是在LLM驱动的互动游戏中，挑战"更紧约束必然增强游戏性"的假设。

Method: 采用被试内可用性研究(N=10)比较高低约束提示，然后重新设计为混合JSON+RAG支架，并进行LLM法官的合成评估。

Result: 高约束和低约束提示在体验上没有可靠差异，但支架效应具有角色依赖性：采访者NPC获得稳定性，而嫌疑犯NPC失去即兴可信度。

Conclusion: 提出了符号支架游戏框架，使用模糊数值边界来在需要时稳定连贯性，同时在保持惊喜的地方保留即兴性。

Abstract: Large Language Models (LLMs) promise to transform interactive games by
enabling non-player characters (NPCs) to sustain unscripted dialogue. Yet it
remains unclear whether constrained prompts actually improve player experience.
We investigate this question through The Interview, a voice-based detective
game powered by GPT-4o. A within-subjects usability study ($N=10$) compared
high-constraint (HCP) and low-constraint (LCP) prompts, revealing no reliable
experiential differences beyond sensitivity to technical breakdowns. Guided by
these findings, we redesigned the HCP into a hybrid JSON+RAG scaffold and
conducted a synthetic evaluation with an LLM judge, positioned as an
early-stage complement to usability testing. Results uncovered a novel pattern:
scaffolding effects were role-dependent: the Interviewer (quest-giver NPC)
gained stability, while suspect NPCs lost improvisational believability. These
findings overturn the assumption that tighter constraints inherently enhance
play. Extending fuzzy-symbolic scaffolding, we introduce \textit{Symbolically
Scaffolded Play}, a framework in which symbolic structures are expressed as
fuzzy, numerical boundaries that stabilize coherence where needed while
preserving improvisation where surprise sustains engagement.

</details>


### [13] [Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters](https://arxiv.org/abs/2510.25860)
*Xingjian Zhang,Tianhong Gao,Suliang Jin,Tianhao Wang,Teng Ye,Eytan Adar,Qiaozhu Mei*

Main category: cs.AI

TL;DR: 提出人机协作框架，从仅标签标注中推断思维轨迹，通过拒绝采样方法重构推理过程，用于微调开源LLM评估器和改进专有LLM评估器的标注指南，显著提升LLM与人类评估的一致性。


<details>
  <summary>Details</summary>
Motivation: LLM作为评估器在主观任务中可靠性有限，人类判断涉及超越标注标签的细微推理，思维轨迹信息丰富但难以收集和整理。

Method: 使用人机协作框架，通过简单有效的拒绝采样方法从仅标签标注中重构思维轨迹，应用于微调开源LLM评估器和合成更清晰的专有LLM评估器标注指南。

Result: 在多个数据集上，方法显著提高了LLM与人类评估的一致性，改进的标注指南增加了不同LLM模型间的一致性。

Conclusion: LLM可以作为未揭示的人类思维轨迹的实际代理，使仅标签语料库扩展为思维轨迹增强资源，提高LLM评估器的可靠性。

Abstract: Large language models (LLMs) are increasingly used as raters for evaluation
tasks. However, their reliability is often limited for subjective tasks, when
human judgments involve subtle reasoning beyond annotation labels. Thinking
traces, the reasoning behind a judgment, are highly informative but challenging
to collect and curate. We present a human-LLM collaborative framework to infer
thinking traces from label-only annotations. The proposed framework uses a
simple and effective rejection sampling method to reconstruct these traces at
scale. These inferred thinking traces are applied to two complementary tasks:
(1) fine-tuning open LLM raters; and (2) synthesizing clearer annotation
guidelines for proprietary LLM raters. Across multiple datasets, our methods
lead to significantly improved LLM-human agreement. Additionally, the refined
annotation guidelines increase agreement among different LLM models. These
results suggest that LLMs can serve as practical proxies for otherwise
unrevealed human thinking traces, enabling label-only corpora to be extended
into thinking-trace-augmented resources that enhance the reliability of LLM
raters.

</details>


### [14] [The Information-Theoretic Imperative: Compression and the Epistemic Foundations of Intelligence](https://arxiv.org/abs/2510.25883)
*Christian Dittrich,Jennifer Flygare Kinne*

Main category: cs.AI

TL;DR: 该论文提出了一个两级框架来解释压缩如何强制发现因果结构而非表面统计模式，认为智能是在结构化环境中持续存在的机械必然结果。


<details>
  <summary>Details</summary>
Motivation: 现有框架虽然认识到压缩对智能的核心作用，但未能明确说明为什么这个过程会强制发现因果结构而不是表面统计模式。

Method: 引入信息论必要性(ITI)和压缩效率原则(CEP)两级框架，ITI从进化角度解释生存压力如何导致信息处理需求，CEP说明高效压缩如何通过异常积累动态选择生成性因果模型。

Result: 该框架产生了可实证检验的预测：压缩效率与分布外泛化相关；异常积累率区分因果模型和相关模型；分层系统在抽象层上表现出递增效率；生物系统显示代谢成本与表征复杂性相关。

Conclusion: ITI和CEP为生物、人工和多尺度系统的收敛提供了统一解释，解决了智能的认知和功能维度，无需诉诸意识或主观经验的假设。

Abstract: Existing frameworks converge on the centrality of compression to intelligence
but leave underspecified why this process enforces the discovery of causal
structure rather than superficial statistical patterns. We introduce a
two-level framework to address this gap. The Information-Theoretic Imperative
(ITI) establishes that any system persisting in uncertain environments must
minimize epistemic entropy through predictive compression: this is the
evolutionary "why" linking survival pressure to information-processing demands.
The Compression Efficiency Principle (CEP) specifies how efficient compression
mechanically selects for generative, causal models through
exception-accumulation dynamics, making reality alignment a consequence rather
than a contingent achievement. Together, ITI and CEP define a causal chain:
from survival pressure to prediction necessity, compression requirement,
efficiency optimization, generative structure discovery, and ultimately reality
alignment. Each link follows from physical, information-theoretic, or
evolutionary constraints, implying that intelligence is the mechanically
necessary outcome of persistence in structured environments. This framework
yields empirically testable predictions: compression efficiency, measured as
approach to the rate-distortion frontier, correlates with out-of-distribution
generalization; exception-accumulation rates differentiate causal from
correlational models; hierarchical systems exhibit increasing efficiency across
abstraction layers; and biological systems demonstrate metabolic costs that
track representational complexity. ITI and CEP thereby provide a unified
account of convergence across biological, artificial, and multi-scale systems,
addressing the epistemic and functional dimensions of intelligence without
invoking assumptions about consciousness or subjective experience.

</details>


### [15] [Approximating Human Preferences Using a Multi-Judge Learned System](https://arxiv.org/abs/2510.25884)
*Eitán Sprejer,Fernando Avalos,Augusto Bernardi,Jose Pedro Brito de Azevedo Faustino,Jacob Haimes,Narmeen Fatimah Oozeer*

Main category: cs.AI

TL;DR: 提出了一个基于角色的偏好建模框架，通过聚合多个基于评分标准的评判者输出来校准LLM评判者与人类偏好，解决评判者的校准困难、评分标准敏感性、偏见和不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 校准基于LLM的评判者与人类偏好是一个重大挑战，这些评判者难以校准且常受评分标准敏感性、偏见和不稳定性影响。克服这一挑战对RLHF的可靠奖励模型和选择最佳模型的路径系统等应用至关重要。

Method: 提出了一个框架，通过聚合多个基于评分标准的评判者输出来建模多样化的基于角色的偏好。包括基于角色的偏好标签大规模合成方法，以及两种聚合器实现：广义加性模型(GAM)和多层感知器(MLP)。

Result: 研究了该方法相对于简单基线的性能，并通过人类和LLM评判者偏见的案例研究评估了其鲁棒性。

Conclusion: 该框架能够有效建模多样化偏好，为LLM评判者的校准提供了可行解决方案，在RLHF奖励模型和模型路由系统等应用中具有重要价值。

Abstract: Aligning LLM-based judges with human preferences is a significant challenge,
as they are difficult to calibrate and often suffer from rubric sensitivity,
bias, and instability. Overcoming this challenge advances key applications,
such as creating reliable reward models for Reinforcement Learning from Human
Feedback (RLHF) and building effective routing systems that select the
best-suited model for a given user query. In this work, we propose a framework
for modeling diverse, persona-based preferences by learning to aggregate
outputs from multiple rubric-conditioned judges. We investigate the performance
of this approach against naive baselines and assess its robustness through case
studies on both human and LLM-judges biases. Our primary contributions include
a persona-based method for synthesizing preference labels at scale and two
distinct implementations of our aggregator: Generalized Additive Model (GAM)
and a Multi-Layer Perceptron (MLP).

</details>


### [16] [SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications](https://arxiv.org/abs/2510.25908)
*Emily Herron,Junqi Yin,Feiyi Wang*

Main category: cs.AI

TL;DR: SciTrust 2.0是一个评估科学应用中LLM可信度的综合框架，涵盖真实性、对抗鲁棒性、科学安全和科学伦理四个维度。评估显示通用行业模型在各方面优于科学专用模型。


<details>
  <summary>Details</summary>
Motivation: LLM在科学研究中具有变革潜力，但在高风险环境中的部署引发了可信度担忧，需要系统评估框架。

Method: 开发了包含开放式真实性基准和科学伦理基准的综合评估框架，使用验证的反思调优流程和专家验证，采用准确性、语义相似度和LLM评分等多种指标评估7个主要LLM。

Result: 通用行业模型在所有可信度维度上均优于科学专用模型，GPT-4-mini在真实性和对抗鲁棒性方面表现最佳。科学专用模型在逻辑和伦理推理能力上存在显著缺陷，在生物安全和化学武器等高危领域的安全漏洞令人担忧。

Conclusion: 通过开源该框架，为开发更可信的AI系统和推进科学背景下模型安全与伦理研究奠定了基础。

Abstract: Large language models (LLMs) have demonstrated transformative potential in
scientific research, yet their deployment in high-stakes contexts raises
significant trustworthiness concerns. Here, we introduce SciTrust 2.0, a
comprehensive framework for evaluating LLM trustworthiness in scientific
applications across four dimensions: truthfulness, adversarial robustness,
scientific safety, and scientific ethics. Our framework incorporates novel,
open-ended truthfulness benchmarks developed through a verified
reflection-tuning pipeline and expert validation, alongside a novel ethics
benchmark for scientific research contexts covering eight subcategories
including dual-use research and bias. We evaluated seven prominent LLMs,
including four science-specialized models and three general-purpose industry
models, using multiple evaluation metrics including accuracy, semantic
similarity measures, and LLM-based scoring. General-purpose industry models
overall outperformed science-specialized models across each trustworthiness
dimension, with GPT-o4-mini demonstrating superior performance in truthfulness
assessments and adversarial robustness. Science-specialized models showed
significant deficiencies in logical and ethical reasoning capabilities, along
with concerning vulnerabilities in safety evaluations, particularly in
high-risk domains such as biosecurity and chemical weapons. By open-sourcing
our framework, we provide a foundation for developing more trustworthy AI
systems and advancing research on model safety and ethics in scientific
contexts.

</details>


### [17] [FinOps Agent -- A Use-Case for IT Infrastructure and Cost Optimization](https://arxiv.org/abs/2510.25914)
*Ngoc Phuoc An Vo,Manish Kesarwani,Ruchi Mahindru,Chandrasekhar Narayanaswami*

Main category: cs.AI

TL;DR: 提出利用自主AI代理实现FinOps自动化，通过模拟端到端行业流程，从多源数据检索到分析生成优化建议，评估显示AI代理能达到实际FinOps从业者的水平。


<details>
  <summary>Details</summary>
Motivation: FinOps从业者面临来自多个云提供商和内部系统的异构计费数据格式、分类和指标，导致难以综合可操作见解和做出时效性决策。

Method: 构建FinOps代理系统，模拟从多源数据检索到数据整合分析再到生成优化建议的端到端行业流程，使用开源和闭源语言模型进行评估。

Result: 代理能够理解、规划和执行任务，表现与实际的FinOps从业者相当。

Conclusion: 自主AI代理可以有效解决FinOps中的数据异构挑战，实现自动化成本优化。

Abstract: FinOps (Finance + Operations) represents an operational framework and
cultural practice which maximizes cloud business value through collaborative
financial accountability across engineering, finance, and business teams.
FinOps practitioners face a fundamental challenge: billing data arrives in
heterogeneous formats, taxonomies, and metrics from multiple cloud providers
and internal systems which eventually lead to synthesizing actionable insights,
and making time-sensitive decisions. To address this challenge, we propose
leveraging autonomous, goal-driven AI agents for FinOps automation. In this
paper, we built a FinOps agent for a typical use-case for IT infrastructure and
cost optimization. We built a system simulating a realistic end-to-end industry
process starting with retrieving data from various sources to consolidating and
analyzing the data to generate recommendations for optimization. We defined a
set of metrics to evaluate our agent using several open-source and close-source
language models and it shows that the agent was able to understand, plan, and
execute tasks as well as an actual FinOps practitioner.

</details>


### [18] [Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual Accuracy by Directed Exoskeleton Reasoning](https://arxiv.org/abs/2510.25933)
*Nissan Yaron,Dan Bystritsky,Ben-Etzion Yaron*

Main category: cs.AI

TL;DR: 一个3.8B参数的模型在FACTS基准测试中达到GPT-4o水平，云服务成本降低约19倍，自托管部署边际成本接近零。


<details>
  <summary>Details</summary>
Motivation: 开发成本效益高的小型语言模型，在保持性能的同时大幅降低推理成本。

Method: 结合最小化的"外骨骼推理"支架和行为微调，教导协议遵循而非领域知识，两者协同作用显著提升性能。

Result: 在Q1-Q500测试集上，Humans-Junior(72.7%)与GPT-4o(73.5%)在±5pp等效范围内表现相当，成本降低约19倍。

Conclusion: 小型模型通过适当的推理支架和微调方法，可以在特定任务上达到大型模型性能，同时大幅降低成本。

Abstract: We introduce Humans-Junior, a 3.8B model that matches GPT-4o on the FACTS
Grounding public subset within a $\pm 5$ pp equivalence margin.
  Results. On Q1--Q500 under identical judges, GPT-4o scores 73.5% (95% CI
69.5--77.2) and Humans-Junior 72.7% (95% CI 68.7--76.5); the paired difference
is 0.8 pp (bootstrap 95% CI $-3.1$ to $+4.7$; permutation $p = 0.72$; Cohen's
$d = 0.023$). TOST establishes equivalence at $\pm 5$ pp (not at $\pm 3$ pp).
When purchased as managed APIs, Humans-Junior's base model
(Phi-3.5-mini-instruct) is $\approx 19\times$ less expensive than GPT-4o on
Microsoft AI Foundry pricing; self-hosted or edge deployments can drive
incremental inference cost toward zero. Measured vs estimated pricing sources
are tabulated in Appendix E.
  Method. Our approach combines minimal directed "Exoskeleton Reasoning"
scaffolds with behavioral fine-tuning that teaches protocol compliance
(epistemic discipline) rather than domain answers. Fine-tuning alone adds
little; combined, they synergize (+17.7 pp, $p < 0.001$) and reduce variance
($\approx 25\%$). In prompt-only settings on frontier models (Q1--Q100;
non-comparable), directed reasoning improved GPT-4o by +11.8 pp to 85.3% and
Gemini-2.5-Pro by +5.0 pp to 93.3% (baseline 88.3%, $n = 100$); see Section~5.
  TL;DR. A 3.8B model achieves GPT-4o-level FACTS accuracy (equivalent within
$\pm 5$ pp on Q1--Q500). Cloud pricing shows $\approx 19\times$ lower cost
versus GPT-4o, and self-hosted/edge deployments can approach zero marginal
cost. Pricing sources are listed in Appendix E. Frontier prompt-only gains
(Q1--Q100; non-comparable) and optimized-prompt exploratory results under
earlier judges are summarized in Appendix F.
  Keywords: Small Language Models, Factual Grounding, Directed Reasoning,
Fine-Tuning, Model Alignment, Cost-Efficient AI

</details>


### [19] [Estimating cognitive biases with attention-aware inverse planning](https://arxiv.org/abs/2510.25951)
*Sounak Banerjee,Daphne Cornelisse,Deepak Gopinath,Emily Sumner,Jonathan DeCastro,Guy Rosman,Eugene Vinitsky,Mark K. Ho*

Main category: cs.AI

TL;DR: 提出注意力感知逆规划方法，从人类行为中推断认知偏见，结合深度强化学习和计算认知建模，在真实驾驶场景中验证可扩展性。


<details>
  <summary>Details</summary>
Motivation: 人类的目标导向行为受认知偏见影响，自主系统需要理解这些偏见。例如，人们在日常任务（如驾驶）中的注意力分布存在系统性偏差。

Method: 结合深度强化学习和计算认知建模，构建注意力感知逆规划框架，从观察到的行为中推断注意力策略。

Result: 在Waymo开放数据集中的真实驾驶场景中成功推断RL智能体的注意力策略，证明了该方法在估计认知偏见方面的可扩展性。

Conclusion: 注意力感知逆规划能够有效从行为中推断认知偏见，为自主系统理解人类行为提供了新方法。

Abstract: People's goal-directed behaviors are influenced by their cognitive biases,
and autonomous systems that interact with people should be aware of this. For
example, people's attention to objects in their environment will be biased in a
way that systematically affects how they perform everyday tasks such as driving
to work. Here, building on recent work in computational cognitive science, we
formally articulate the attention-aware inverse planning problem, in which the
goal is to estimate a person's attentional biases from their actions. We
demonstrate how attention-aware inverse planning systematically differs from
standard inverse reinforcement learning and how cognitive biases can be
inferred from behavior. Finally, we present an approach to attention-aware
inverse planning that combines deep reinforcement learning with computational
cognitive modeling. We use this approach to infer the attentional strategies of
RL agents in real-life driving scenarios selected from the Waymo Open Dataset,
demonstrating the scalability of estimating cognitive biases with
attention-aware inverse planning.

</details>


### [20] [From Queries to Insights: Agentic LLM Pipelines for Spatio-Temporal Text-to-SQL](https://arxiv.org/abs/2510.25997)
*Manu Redd,Tao Zhe,Dongjie Wang*

Main category: cs.AI

TL;DR: 提出了一个基于代理的自然语言到SQL系统，通过ReAct代理协调扩展了基础的文本到SQL模型，显著提升了处理时空查询的准确性和可用性。


<details>
  <summary>Details</summary>
Motivation: 现有NL-to-SQL系统在处理现实的时空查询时表现不佳，需要解决模糊用户表达与特定模式类别的对齐、时间推理和适当输出选择等问题。

Method: 使用基于Mistral的ReAct代理构建代理化管道，通过模式检查、SQL生成、执行和可视化工具来规划、分解和适配查询。

Result: 在NYC和Tokyo签到数据集的35个自然语言查询评估中，代理系统准确率达到91.4%，远高于基线模型的28.6%，并通过地图、图表和自然语言摘要增强了可用性。

Conclusion: 代理化协调而非仅增强SQL生成器，是构建交互式地理空间助手的有前景基础，能够支持缺乏SQL专业知识、详细模式知识或提示技能的用户。

Abstract: Natural-language-to-SQL (NL-to-SQL) systems hold promise for democratizing
access to structured data, allowing users to query databases without learning
SQL. Yet existing systems struggle with realistic spatio-temporal queries,
where success requires aligning vague user phrasing with schema-specific
categories, handling temporal reasoning, and choosing appropriate outputs. We
present an agentic pipeline that extends a naive text-to-SQL baseline
(llama-3-sqlcoder-8b) with orchestration by a Mistral-based ReAct agent. The
agent can plan, decompose, and adapt queries through schema inspection, SQL
generation, execution, and visualization tools. We evaluate on 35
natural-language queries over the NYC and Tokyo check-in dataset, covering
spatial, temporal, and multi-dataset reasoning. The agent achieves
substantially higher accuracy than the naive baseline 91.4% vs. 28.6% and
enhances usability through maps, plots, and structured natural-language
summaries. Crucially, our design enables more natural human-database
interaction, supporting users who lack SQL expertise, detailed schema
knowledge, or prompting skill. We conclude that agentic orchestration, rather
than stronger SQL generators alone, is a promising foundation for interactive
geospatial assistants.

</details>


### [21] [AutoSurvey2: Empowering Researchers with Next Level Automated Literature Surveys](https://arxiv.org/abs/2510.26012)
*Siyi Wu,Chiaxin Liang,Ziqian Bi,Leyi Zhao,Tianyang Wang,Junhao Song,Yichao Zhang,Keyu Chen,Xinyuan Song*

Main category: cs.AI

TL;DR: autosurvey2是一个自动化生成学术综述论文的多阶段流水线系统，通过检索增强合成和结构化评估，在LLM研究领域实现高效、准确的综述生成。


<details>
  <summary>Details</summary>
Motivation: 随着研究文献的快速增长，特别是在大语言模型领域，传统的人工撰写综述论文变得越来越困难，需要自动化解决方案来保持综述的全面性和时效性。

Method: 采用多阶段流水线，包括并行章节生成、迭代优化和实时检索最新出版物，结合检索增强合成和结构化评估框架。

Result: 实验结果表明autosurvey2在结构连贯性、主题相关性和引用保真度方面均优于现有检索基线和自动化基线，达到更高评分。

Conclusion: autosurvey2通过将检索、推理和自动评估整合到统一框架中，为生成长篇学术综述提供了可扩展且可复现的解决方案，为自动化学术写作研究奠定了坚实基础。

Abstract: The rapid growth of research literature, particularly in large language
models (LLMs), has made producing comprehensive and current survey papers
increasingly difficult. This paper introduces autosurvey2, a multi-stage
pipeline that automates survey generation through retrieval-augmented synthesis
and structured evaluation. The system integrates parallel section generation,
iterative refinement, and real-time retrieval of recent publications to ensure
both topical completeness and factual accuracy. Quality is assessed using a
multi-LLM evaluation framework that measures coverage, structure, and relevance
in alignment with expert review standards. Experimental results demonstrate
that autosurvey2 consistently outperforms existing retrieval-based and
automated baselines, achieving higher scores in structural coherence and
topical relevance while maintaining strong citation fidelity. By combining
retrieval, reasoning, and automated evaluation into a unified framework,
autosurvey2 provides a scalable and reproducible solution for generating
long-form academic surveys and contributes a solid foundation for future
research on automated scholarly writing. All code and resources are available
at https://github.com/annihi1ation/auto_research.

</details>


### [22] [Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization](https://arxiv.org/abs/2510.26023)
*Zhipeng Bao,Qianwen Li*

Main category: cs.AI

TL;DR: StuckSolver是一个基于大语言模型的自动驾驶车辆恢复框架，能够在车辆被困时通过自主推理和乘客指导来解决问题，无需修改现有系统架构。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶车辆在某些交通场景中容易陷入困境，而现有的远程干预和人工接管方案存在成本高、效率低、限制非驾驶员使用等问题。

Method: 开发了StuckSolver作为插件模块，利用LLM分析传感器数据检测被困状态，理解环境上下文，并生成可由车辆原生规划器执行的高级恢复指令。

Result: 在Bench2Drive基准测试和自定义不确定性场景中，StuckSolver仅通过自主推理就达到了接近最优性能，结合乘客指导后表现更佳。

Conclusion: StuckSolver提供了一种有效解决自动驾驶车辆被困问题的新方法，能够提升车辆在复杂交通环境中的自主恢复能力。

Abstract: Despite significant advancements in recent decades, autonomous vehicles (AVs)
continue to face challenges in navigating certain traffic scenarios where human
drivers excel. In such situations, AVs often become immobilized, disrupting
overall traffic flow. Current recovery solutions, such as remote intervention
(which is costly and inefficient) and manual takeover (which excludes
non-drivers and limits AV accessibility), are inadequate. This paper introduces
StuckSolver, a novel Large Language Model (LLM) driven recovery framework that
enables AVs to resolve immobilization scenarios through self-reasoning and/or
passenger-guided decision-making. StuckSolver is designed as a plug-in add-on
module that operates on top of the AV's existing perception-planning-control
stack, requiring no modification to its internal architecture. Instead, it
interfaces with standard sensor data streams to detect immobilization states,
interpret environmental context, and generate high-level recovery commands that
can be executed by the AV's native planner. We evaluate StuckSolver on the
Bench2Drive benchmark and in custom-designed uncertainty scenarios. Results
show that StuckSolver achieves near-state-of-the-art performance through
autonomous self-reasoning alone and exhibits further improvements when
passenger guidance is incorporated.

</details>


### [23] [Can AI be Accountable?](https://arxiv.org/abs/2510.26057)
*Andrew L. Kun*

Main category: cs.AI

TL;DR: 本文探讨了AI问责制的重要性，分析了当前AI缺乏问责性的现状，并提出了改善AI问责性的方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力的快速提升，确保AI对消费者、选民和决策者负责变得至关重要。当前AI缺乏问责机制，无法被质疑、讨论或制裁。

Method: 将一般问责制定义应用于AI领域，通过案例说明AI问责与不问责的含义，探索提高AI问责性的方法。

Result: 明确了AI问责制的概念框架，识别了当前AI问责性不足的问题，提出了实现AI问责制的可行路径。

Conclusion: 必须采取措施确保所有AI对其影响对象负责，这是构建可信AI系统的关键要求。

Abstract: The AI we use is powerful, and its power is increasing rapidly. If this
powerful AI is to serve the needs of consumers, voters, and decision makers,
then it is imperative that the AI is accountable. In general, an agent is
accountable to a forum if the forum can request information from the agent
about its actions, if the forum and the agent can discuss this information, and
if the forum can sanction the agent. Unfortunately, in too many cases today's
AI is not accountable -- we cannot question it, enter into a discussion with
it, let alone sanction it. In this chapter we relate the general definition of
accountability to AI, we illustrate what it means for AI to be accountable and
unaccountable, and we explore approaches that can improve our chances of living
in a world where all AI is accountable to those who are affected by it.

</details>


### [24] [Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4](https://arxiv.org/abs/2510.26094)
*Yuxin Li,Minghao Liu,Ruida Wang,Wenzhao Ji,Zhitao He,Rui Pan,Junming Huang,Tong Zhang,Yi R. Fung*

Main category: cs.AI

TL;DR: Lean4PHYS是一个用于大学物理问题推理的框架，包含LeanPhysBench基准测试和PhysLib知识库，在Lean4中验证物理推理能力。


<details>
  <summary>Details</summary>
Motivation: 为大学物理问题建立正式的推理框架和基准测试，填补Lean4中物理推理基准的空白。

Method: 构建包含200个手工制作和同行评审物理问题的LeanPhysBench基准，开发社区驱动的PhysLib知识库，使用主要数学证明器和先进模型进行基线测试。

Result: DeepSeek-Prover-V2-7B仅达到16%准确率，Claude-Sonnet-4达到35%，PhysLib平均提升模型性能11.75%。

Conclusion: LeanPhysBench具有挑战性，PhysLib有效提升性能，这是首个在Lean4中提供的物理基准研究。

Abstract: We present **Lean4PHYS**, a comprehensive reasoning framework for
college-level physics problems in Lean4. **Lean4PHYS** includes
*LeanPhysBench*, a college-level benchmark for formal physics reasoning in
Lean4, which contains 200 hand-crafted and peer-reviewed statements derived
from university textbooks and physics competition problems. To establish a
solid foundation for formal reasoning in physics, we also introduce *PhysLib*,
a community-driven repository containing fundamental unit systems and theorems
essential for formal physics reasoning. Based on the benchmark and Lean4
repository we composed in **Lean4PHYS**, we report baseline results using major
expert Math Lean4 provers and state-of-the-art closed-source models, with the
best performance of DeepSeek-Prover-V2-7B achieving only 16% and
Claude-Sonnet-4 achieving 35%. We also conduct a detailed analysis showing that
our *PhysLib* can achieve an average improvement of 11.75% in model
performance. This demonstrates the challenging nature of our *LeanPhysBench*
and the effectiveness of *PhysLib*. To the best of our knowledge, this is the
first study to provide a physics benchmark in Lean4.

</details>


### [25] [GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks](https://arxiv.org/abs/2510.26098)
*Chenrui Shi,Zedong Yu,Zhi Gao,Ruining Feng,Enqi Liu,Yuwei Wu,Yunde Jia,Liuyu Xiang,Zhaofeng He,Qing Li*

Main category: cs.AI

TL;DR: 该论文分析了大型视觉语言模型在GUI任务自动化中的不足，提出GUI知识包含三个维度：界面感知、交互预测和指令理解，并创建了GUI知识基准来评估模型能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型视觉语言模型在GUI任务自动化方面仍落后于人类，作者认为这种差距源于缺乏核心GUI知识，而现有的训练方法无法完全解决这一问题。

Method: 通过分析GUI任务执行中的常见失败模式，将GUI知识提炼为三个维度，并引入GUI知识基准，包含跨6个平台和292个应用的多项选择和是/否问题。

Result: 评估显示当前VLMs能够识别小部件功能，但在感知系统状态、预测动作和验证任务完成方面存在困难。真实GUI任务实验验证了GUI知识与任务成功之间的紧密联系。

Conclusion: 通过提供评估GUI知识的结构化框架，该工作支持在下游训练前选择更具潜力的VLMs，并为构建更强大的GUI代理提供了见解。

Abstract: Large vision language models (VLMs) have advanced graphical user interface
(GUI) task automation but still lag behind humans. We hypothesize this gap
stems from missing core GUI knowledge, which existing training schemes (such as
supervised fine tuning and reinforcement learning) alone cannot fully address.
By analyzing common failure patterns in GUI task execution, we distill GUI
knowledge into three dimensions: (1) interface perception, knowledge about
recognizing widgets and system states; (2) interaction prediction, knowledge
about reasoning action state transitions; and (3) instruction understanding,
knowledge about planning, verifying, and assessing task completion progress. We
further introduce GUI Knowledge Bench, a benchmark with multiple choice and
yes/no questions across six platforms (Web, Android, MacOS, Windows, Linux,
IOS) and 292 applications. Our evaluation shows that current VLMs identify
widget functions but struggle with perceiving system states, predicting
actions, and verifying task completion. Experiments on real world GUI tasks
further validate the close link between GUI knowledge and task success. By
providing a structured framework for assessing GUI knowledge, our work supports
the selection of VLMs with greater potential prior to downstream training and
provides insights for building more capable GUI agents.

</details>


### [26] [Beyond Benchmarks: The Economics of AI Inference](https://arxiv.org/abs/2510.26136)
*Boqin Zhuang,Jiacheng Qiao,Mingqian Liu,Mingxing Yu,Ping Hong,Rui Li,Xiaoxia Song,Xiangjun Xu,Xu Chen,Yaoyao Ma,Yujie Gao*

Main category: cs.AI

TL;DR: 本文提出了一个量化的大语言模型推理经济学框架，将LLM推理视为计算驱动的智能生产活动，分析了边际成本、规模经济和输出质量，并基于WiNEval-3.0数据构建了首个LLM推理生产前沿。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的推理成本已成为决定其商业可行性和广泛应用的关键因素，需要建立经济分析框架来指导模型部署决策。

Method: 采用定量经济学框架，将LLM推理过程视为智能生产活动，分析边际成本、规模经济和输出质量，基于WiNEval-3.0实证数据构建LLM推理生产前沿。

Result: 揭示了三个原则：边际成本递减、规模报酬递减和最优成本效益区域，构建了首个LLM推理生产前沿。

Conclusion: 该研究不仅为模型部署决策提供了经济基础，还为未来AI推理资源的市场定价和优化奠定了实证基础。

Abstract: The inference cost of Large Language Models (LLMs) has become a critical
factor in determining their commercial viability and widespread adoption. This
paper introduces a quantitative ``economics of inference'' framework, treating
the LLM inference process as a compute-driven intelligent production activity.
We analyze its marginal cost, economies of scale, and quality of output under
various performance configurations. Based on empirical data from WiNEval-3.0,
we construct the first ``LLM Inference Production Frontier,'' revealing three
principles: diminishing marginal cost, diminishing returns to scale, and an
optimal cost-effectiveness zone. This paper not only provides an economic basis
for model deployment decisions but also lays an empirical foundation for the
future market-based pricing and optimization of AI inference resources.

</details>


### [27] [Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math](https://arxiv.org/abs/2510.26143)
*Bo Pang,Deqian Kong,Silvio Savarese,Caiming Xiong,Yingbo Zhou*

Main category: cs.AI

TL;DR: 提出Reasoning Curriculum两阶段课程学习法：第一阶段在数学领域进行RL训练以激发推理能力，第二阶段在多领域联合RL中迁移和巩固这些能力。该方法简单易用，无需专用奖励模型，在多个模型上均能提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法主要关注数学和编程领域，缺乏通用的推理能力训练。希望开发一种简单有效的方法，能够激发和迁移语言模型的推理能力到多个领域。

Method: 两阶段课程学习：1）数学领域RL冷启动，使用可验证奖励开发推理技能；2）多领域联合RL，迁移和巩固推理能力。方法简洁，不依赖专用奖励模型。

Result: 在Qwen3-4B和Llama-3.1-8B模型上的多领域评估显示一致性能提升。消融实验表明两个阶段都是必要的，数学优先的激发策略能增强解决复杂问题所需的关键认知行为。

Conclusion: Reasoning Curriculum提供了一个紧凑、易于采用的通用推理训练方案，能够有效提升语言模型在多领域的推理能力。

Abstract: Reinforcement learning (RL) can elicit strong reasoning in large language
models (LLMs), yet most open efforts focus on math and code. We propose
Reasoning Curriculum, a simple two-stage curriculum that first elicits
reasoning skills in pretraining-aligned domains such as math, then adapts and
refines these skills across other domains via joint RL. Stage 1 performs a
brief cold start and then math-only RL with verifiable rewards to develop
reasoning skills. Stage 2 runs joint RL on mixed-domain data to transfer and
consolidate these skills. The curriculum is minimal and backbone-agnostic,
requiring no specialized reward models beyond standard verifiability checks.
Evaluated on Qwen3-4B and Llama-3.1-8B over a multi-domain suite, reasoning
curriculum yields consistent gains. Ablations and a cognitive-skill analysis
indicate that both stages are necessary and that math-first elicitation
increases cognitive behaviors important for solving complex problems. Reasoning
Curriculum provides a compact, easy-to-adopt recipe for general reasoning.

</details>


### [28] [The FM Agent](https://arxiv.org/abs/2510.26144)
*Annan Li,Chufan Wu,Zengle Ge,Yee Hin Chong,Zhinan Hou,Lizhe Cao,Cheng Ju,Jianmin Wu,Huaiming Li,Haobo Zhang,Shenghao Feng,Mo Zhao,Fengzhi Qiu,Rui Yang,Mengmeng Zhang,Wenyi Zhu,Yingying Sun,Quan Sun,Shunhao Yan,Danyu Liu,Dawei Yin,Dou Shen*

Main category: cs.AI

TL;DR: FM Agent是一个基于大语言模型的多智能体框架，结合进化搜索解决复杂现实问题，在多个领域达到最先进水平且无需人工干预。


<details>
  <summary>Details</summary>
Motivation: 利用大语言模型开发自主AI研究智能体，解决科学和工程领域的复杂挑战，加速创新和自动化发现过程。

Method: 集成冷启动初始化、进化采样策略、领域特定评估器（结合正确性、有效性和LLM监督反馈）以及基于Ray的分布式异步执行基础设施。

Result: 在多个基准测试中达到最先进结果：ALE-Bench 1976.3（+5.2%）、MLE-Bench 43.56%（+4.0pp）、KernelBench最高20倍加速，并在经典数学问题上建立新SOTA。

Conclusion: FM Agent在企业和科研领域具有广泛应用前景，能够加速创新、自动化复杂发现过程，带来显著的工程和科学进步及社会影响。

Abstract: Large language models (LLMs) are catalyzing the development of autonomous AI
research agents for scientific and engineering discovery. We present FM Agent,
a novel and general-purpose multi-agent framework that leverages a synergistic
combination of LLM-based reasoning and large-scale evolutionary search to
address complex real-world challenges. The core of FM Agent integrates several
key innovations: 1) a cold-start initialization phase incorporating expert
guidance, 2) a novel evolutionary sampling strategy for iterative optimization,
3) domain-specific evaluators that combine correctness, effectiveness, and
LLM-supervised feedback, and 4) a distributed, asynchronous execution
infrastructure built on Ray. Demonstrating broad applicability, our system has
been evaluated across diverse domains, including operations research, machine
learning, GPU kernel optimization, and classical mathematical problems. FM
Agent reaches state-of-the-art results autonomously, without human
interpretation or tuning -- 1976.3 on ALE-Bench (+5.2\%), 43.56\% on MLE-Bench
(+4.0pp), up to 20x speedups on KernelBench, and establishes new
state-of-the-art(SOTA) results on several classical mathematical problems.
Beyond academic benchmarks, FM Agent shows considerable promise for both
large-scale enterprise R\&D workflows and fundamental scientific research,
where it can accelerate innovation, automate complex discovery processes, and
deliver substantial engineering and scientific advances with broader societal
impact.

</details>


### [29] [One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning](https://arxiv.org/abs/2510.26167)
*Renhao Li,Jianhong Tu,Yang Su,Hamid Alinejad-Rokny,Derek F. Wong,Junyang Lin,Min Yang*

Main category: cs.AI

TL;DR: ToolRM：专为工具学习设计的轻量级生成式奖励模型，通过规则评分和多维采样构建偏好数据，显著提升函数调用任务的性能。


<details>
  <summary>Details</summary>
Motivation: 在工具学习领域，缺乏专门为函数调用任务设计的奖励模型，限制了智能代理AI的发展。

Method: 提出构建成对偏好数据的新流程，使用规则评分和多维采样创建ToolPref-Pairwise-30K数据集，并基于Qwen3-4B/8B系列模型训练ToolRM。

Result: ToolRM在成对奖励判断中准确率提升高达14.28%，显著优于Claude 4和OpenAI o3等前沿模型，在推理时减少66%以上的输出token使用。

Conclusion: ToolRM不仅适用于训练目标，还能泛化到更广泛的评判任务，为工具学习研究提供了有效的数据和模型资源。

Abstract: Reward models (RMs) play a critical role in aligning large language models
(LLMs) with human preferences. Yet in the domain of tool learning, the lack of
RMs specifically designed for function-calling tasks has limited progress
toward more capable agentic AI. We introduce ToolRM, a family of lightweight
generative RMs tailored for general tool-use scenarios. To build these models,
we propose a novel pipeline that constructs pairwise preference data using
rule-based scoring and multidimensional sampling. This yields
ToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique
tasks that supports reinforcement learning with verifiable feedback. To
evaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on
the agentic evaluation suite BFCL. Trained on our constructed data, models from
the Qwen3-4B/8B series achieve up to 14.28% higher accuracy, substantially
outperforming frontier models such as Claude 4 and OpenAI o3 in pairwise reward
judgments. Beyond training objectives, ToolRM generalizes to broader critique
tasks, including Best-of-N sampling and self-correction. Experiments on
ACEBench highlight its effectiveness and efficiency, enabling inference-time
scaling and reducing output token usage by over 66%. We release data and model
checkpoints to facilitate future research.

</details>


### [30] [Questionnaire meets LLM: A Benchmark and Empirical Study of Structural Skills for Understanding Questions and Responses](https://arxiv.org/abs/2510.26238)
*Duc-Hai Nguyen,Vijayakumar Nanjappan,Barry O'Sullivan,Hoang D. Nguyen*

Main category: cs.AI

TL;DR: QASU是一个用于评估LLM处理问卷数据的基准，通过测试六种序列化格式和多种提示策略，发现选择合适的格式和提示组合可以将准确率提升高达8.8个百分点。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在处理问卷数据方面存在研究空白，现有调查分析工具主要为人设计，限制了与LLM的集成，导致缺乏关于如何最佳表示问卷数据供LLM使用的指导。

Method: 引入QASU基准，测试六种结构技能（包括答案查找、受访者计数和多跳推理），使用六种序列化格式和多种提示策略进行实验。

Result: 实验表明，选择有效的格式和提示组合相比次优格式可提高准确率高达8.8%。对于特定任务，通过自增强提示添加轻量级结构提示可平均再提升3-4%。

Conclusion: QASU基准通过系统分离格式和提示效应，为基于LLM的问卷分析研究和实践提供了简单而多功能的基础。

Abstract: Millions of people take surveys every day, from market polls and academic
studies to medical questionnaires and customer feedback forms. These datasets
capture valuable insights, but their scale and structure present a unique
challenge for large language models (LLMs), which otherwise excel at few-shot
reasoning over open-ended text. Yet, their ability to process questionnaire
data or lists of questions crossed with hundreds of respondent rows remains
underexplored. Current retrieval and survey analysis tools (e.g., Qualtrics,
SPSS, REDCap) are typically designed for humans in the workflow, limiting such
data integration with LLM and AI-empowered automation. This gap leaves
scientists, surveyors, and everyday users without evidence-based guidance on
how to best represent questionnaires for LLM consumption. We address this by
introducing QASU (Questionnaire Analysis and Structural Understanding), a
benchmark that probes six structural skills, including answer lookup,
respondent count, and multi-hop inference, across six serialization formats and
multiple prompt strategies. Experiments on contemporary LLMs show that choosing
an effective format and prompt combination can improve accuracy by up to 8.8%
points compared to suboptimal formats. For specific tasks, carefully adding a
lightweight structural hint through self-augmented prompting can yield further
improvements of 3-4% points on average. By systematically isolating format and
prompting effects, our open source benchmark offers a simple yet versatile
foundation for advancing both research and real-world practice in LLM-based
questionnaire analysis.

</details>


### [31] [Retrieval Augmented Generation-Enhanced Distributed LLM Agents for Generalizable Traffic Signal Control with Emergency Vehicles](https://arxiv.org/abs/2510.26242)
*Xinhang Li,Qing Guo,Junyu Chen,Zheng Guo,Shengzhe Xu,Lei Li,Lin Zhang*

Main category: cs.AI

TL;DR: REG-TSC是一个基于检索增强生成(RAG)的分布式LLM交通信号控制系统，通过紧急感知推理框架和类型无关交通表示，在异构交叉口实现通用化交通控制，显著减少旅行时间、排队长度和紧急车辆等待时间。


<details>
  <summary>Details</summary>
Motivation: 传统LLM在交通信号控制中容易出现紧急情况下的幻觉问题，且难以适应不同类型交叉口的异构性，限制了在真实复杂交通环境中的泛化能力。

Method: 提出紧急感知推理框架，动态调整推理深度，使用Reviewer-based Emergency RAG(RERAG)从历史案例中提取知识；设计类型无关交通表示和Reward-guided Reinforced Refinement(R3)方法，通过环境反馈优先采样和奖励加权似然损失微调LLM代理。

Result: 在3个真实道路网络(17-177个异构交叉口)上的实验显示，REG-TSC减少旅行时间42.00%、排队长度62.31%、紧急车辆等待时间83.16%，优于其他最先进方法。

Conclusion: REG-TSC通过RAG增强的紧急响应机制和强化学习优化，有效解决了LLM在交通信号控制中的幻觉问题和异构交叉口泛化挑战，实现了可靠高效的通用化交通控制。

Abstract: With increasing urban traffic complexity, Traffic Signal Control (TSC) is
essential for optimizing traffic flow and improving road safety. Large Language
Models (LLMs) emerge as promising approaches for TSC. However, they are prone
to hallucinations in emergencies, leading to unreliable decisions that may
cause substantial delays for emergency vehicles. Moreover, diverse intersection
types present substantial challenges for traffic state encoding and
cross-intersection training, limiting generalization across heterogeneous
intersections. Therefore, this paper proposes Retrieval Augmented Generation
(RAG)-enhanced distributed LLM agents with Emergency response for Generalizable
TSC (REG-TSC). Firstly, this paper presents an emergency-aware reasoning
framework, which dynamically adjusts reasoning depth based on the emergency
scenario and is equipped with a novel Reviewer-based Emergency RAG (RERAG) to
distill specific knowledge and guidance from historical cases, enhancing the
reliability and rationality of agents' emergency decisions. Secondly, this
paper designs a type-agnostic traffic representation and proposes a
Reward-guided Reinforced Refinement (R3) for heterogeneous intersections. R3
adaptively samples training experience from diverse intersections with
environment feedback-based priority and fine-tunes LLM agents with a designed
reward-weighted likelihood loss, guiding REG-TSC toward high-reward policies
across heterogeneous intersections. On three real-world road networks with 17
to 177 heterogeneous intersections, extensive experiments show that REG-TSC
reduces travel time by 42.00%, queue length by 62.31%, and emergency vehicle
waiting time by 83.16%, outperforming other state-of-the-art methods.

</details>


### [32] [Graph-Enhanced Policy Optimization in LLM Agent Training](https://arxiv.org/abs/2510.26270)
*Jiazhen Yuan,Wei Zhao,Zhengbiao Bai*

Main category: cs.AI

TL;DR: GEPO通过构建状态转移图并利用图中心性来解决强化学习中的结构盲目性问题，在三个基准测试中显著提升了成功率


<details>
  <summary>Details</summary>
Motivation: 现有的基于群体的强化学习方法在训练多轮交互的LLM代理时存在结构盲目性，无法利用环境的底层连接性，导致探索效率低、信用分配不准确和规划短视

Method: GEPO从代理经验中动态构建状态转移图，并利用图论中心性提供三个协同学习信号：结构化内在奖励、图增强优势函数和动态折扣因子

Result: 在ALFWorld、WebShop和专有Workbench基准测试中，GEPO相比竞争基线分别实现了+4.1%、+5.3%和+10.9%的绝对成功率提升

Conclusion: 明确建模环境结构是推进LLM代理训练的强大、可泛化策略

Abstract: Group based reinforcement learning (RL) has shown impressive results on
complex reasoning and mathematical tasks. Yet, when applied to train
multi-turn, interactive LLM agents, these methods often suffer from structural
blindness-the inability to exploit the underlying connectivity of the
environment. This manifests in three critical challenges: (1) inefficient,
unguided exploration, (2) imprecise credit assignment due to overlooking
pivotal states, and (3) myopic planning caused by static reward discounting. We
address these issues with Graph-Enhanced Policy Optimization (GEPO), which
dynamically constructs a state-transition graph from agent experience and
employs graph-theoretic centrality to provide three synergistic learning
signals: (1)structured intrinsic rewards that guide exploration toward
high-impact states, (2) a graph-enhanced advantage function for topology-aware
credit assignment, and (3) a dynamic discount factor adapted to each state's
strategic value. On the ALFWorld, WebShop, and a proprietary Workbench
benchmarks, GEPO demonstrates strong performance, achieving absolute success
rate gains of +4.1%, +5.3%, and +10.9% over competitive baselines. These
results highlight that explicitly modeling environmental structure is a robust,
generalizable strategy for advancing LLM agent training.

</details>


### [33] [GraphCompliance: Aligning Policy and Context Graphs for LLM-Based Regulatory Compliance](https://arxiv.org/abs/2510.26309)
*Jiseong Chung,Ronny Ko,Wonchul Yoo,Makoto Onizuka,Sungmok Kim,Tae-Wan Kim,Won-Yong Shin*

Main category: cs.AI

TL;DR: GraphCompliance框架通过将法规文本表示为政策图、运行时上下文表示为上下文图，并将两者对齐，来改进网络规模的合规性评估。该方法在GDPR相关场景中比纯LLM和RAG基线表现更好。


<details>
  <summary>Details</summary>
Motivation: 网络规模合规性面临实际挑战：每个请求都需要监管评估。监管文本（如GDPR）具有交叉引用和规范性，而运行时上下文以非结构化自然语言表达，需要将非结构化文本中的语义信息与法规的结构化规范元素对齐。

Method: 引入GraphCompliance框架，将监管文本表示为政策图（编码规范结构和交叉引用），将运行时上下文表示为上下文图（将事件形式化为主体-动作-对象三元组和实体关系三元组），并对齐这两个图。

Result: 在300个GDPR衍生真实场景的五个评估任务中，GraphCompliance比纯LLM和RAG基线的微F1分数高出4.1-7.2个百分点，具有更少的欠预测和过预测，召回率更高，假阳性率更低。

Conclusion: 消融研究表明每个图组件都有贡献，表明结构化表示和法官LLM对于规范性推理是互补的。

Abstract: Compliance at web scale poses practical challenges: each request may require
a regulatory assessment. Regulatory texts (e.g., the General Data Protection
Regulation, GDPR) are cross-referential and normative, while runtime contexts
are expressed in unstructured natural language. This setting motivates us to
align semantic information in unstructured text with the structured, normative
elements of regulations. To this end, we introduce GraphCompliance, a framework
that represents regulatory texts as a Policy Graph and runtime contexts as a
Context Graph, and aligns them. In this formulation, the policy graph encodes
normative structure and cross-references, whereas the context graph formalizes
events as subject-action-object (SAO) and entity-relation triples. This
alignment anchors the reasoning of a judge large language model (LLM) in
structured information and helps reduce the burden of regulatory interpretation
and event parsing, enabling a focus on the core reasoning step. In experiments
on 300 GDPR-derived real-world scenarios spanning five evaluation tasks,
GraphCompliance yields 4.1-7.2 percentage points (pp) higher micro-F1 than
LLM-only and RAG baselines, with fewer under- and over-predictions, resulting
in higher recall and lower false positive rates. Ablation studies indicate
contributions from each graph component, suggesting that structured
representations and a judge LLM are complementary for normative reasoning.

</details>


### [34] [Discovering State Equivalences in UCT Search Trees By Action Pruning](https://arxiv.org/abs/2510.26346)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 提出了IPA-UCT方法，通过弱化状态抽象条件来在噪声和大动作空间环境中找到更多抽象，从而提升MCTS的样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有的状态-动作对抽象方法在噪声和大动作空间环境中难以找到状态抽象，限制了MCTS的样本效率提升。

Method: 提出IPA-UCT方法，使用更弱的状态抽象条件（IPA框架），在保持精度的同时找到更多抽象。IPA和ASAP都是更通用框架p-ASAP的特殊情况。

Result: IPA-UCT在大量测试领域和迭代预算下都优于OGA-UCT及其衍生方法。

Conclusion: 弱化状态抽象条件可以有效解决状态抽象问题，IPA-UCT是提升MCTS样本效率的有效方法。

Abstract: One approach to enhance Monte Carlo Tree Search (MCTS) is to improve its
sample efficiency by grouping/abstracting states or state-action pairs and
sharing statistics within a group. Though state-action pair abstractions are
mostly easy to find in algorithms such as On the Go Abstractions in Upper
Confidence bounds applied to Trees (OGA-UCT), nearly no state abstractions are
found in either noisy or large action space settings due to constraining
conditions. We provide theoretical and empirical evidence for this claim, and
we slightly alleviate this state abstraction problem by proposing a weaker
state abstraction condition that trades a minor loss in accuracy for finding
many more abstractions. We name this technique Ideal Pruning Abstractions in
UCT (IPA-UCT), which outperforms OGA-UCT (and any of its derivatives) across a
large range of test domains and iteration budgets as experimentally validated.
IPA-UCT uses a different abstraction framework from Abstraction of State-Action
Pairs (ASAP) which is the one used by OGA-UCT, which we name IPA. Furthermore,
we show that both IPA and ASAP are special cases of a more general framework
that we call p-ASAP which itself is a special case of the ASASAP framework.

</details>


### [35] [BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning](https://arxiv.org/abs/2510.26374)
*Qianli Shen,Daoyuan Chen,Yilun Huang,Zhenqing Ling,Yaliang Li,Bolin Ding,Jingren Zhou*

Main category: cs.AI

TL;DR: BOTS是一个用于LLM强化微调中贝叶斯在线任务选择的统一框架，通过自适应维护任务难度的后验估计，结合显式和隐式证据，实现高效的任务选择。


<details>
  <summary>Details</summary>
Motivation: 现有的强化微调方法在任务选择上存在效率低下、成本高、适应性差等问题，需要一种更智能的任务选择策略来提升训练效率。

Method: 基于贝叶斯推断框架，维护任务难度的后验估计，结合Thompson采样平衡探索与利用，使用超轻量插值插件估计未评估任务的难度。

Result: 在多个领域和不同规模的LLM上，BOTS相比基线方法和消融实验，都能持续提升数据效率和性能表现。

Conclusion: BOTS为RFT中的动态任务选择提供了一个实用且可扩展的解决方案。

Abstract: Reinforcement finetuning (RFT) is a key technique for aligning Large Language
Models (LLMs) with human preferences and enhancing reasoning, yet its
effectiveness is highly sensitive to which tasks are explored during training.
Uniform task sampling is inefficient, wasting computation on tasks that are
either trivial or unsolvable, while existing task selection methods often
suffer from high rollout costs, poor adaptivity, or incomplete evidence. We
introduce \textbf{BOTS}, a unified framework for \textbf{B}ayesian
\textbf{O}nline \textbf{T}ask \textbf{S}election in LLM reinforcement
finetuning. Grounded in Bayesian inference, BOTS adaptively maintains posterior
estimates of task difficulty as the model evolves. It jointly incorporates
\emph{explicit evidence} from direct evaluations of selected tasks and
\emph{implicit evidence} inferred from these evaluations for unselected tasks,
with Thompson sampling ensuring a principled balance between exploration and
exploitation. To make implicit evidence practical, we instantiate it with an
ultra-light interpolation-based plug-in that estimates difficulties of
unevaluated tasks without extra rollouts, adding negligible overhead.
Empirically, across diverse domains and LLM scales, BOTS consistently improves
data efficiency and performance over baselines and ablations, providing a
practical and extensible solution for dynamic task selection in RFT.

</details>


### [36] [AI Mathematician as a Partner in Advancing Mathematical Discovery -- A Case Study in Homogenization Theory](https://arxiv.org/abs/2510.26380)
*Yuanhang Liu,Beichen Wang,Peng Li,Yang Liu*

Main category: cs.AI

TL;DR: 研究探讨AI数学家系统如何作为研究伙伴而非单纯问题解决者，通过人机协作解决均质化理论中的挑战性问题，展示了系统化人机协同推理如何推动数学发现前沿。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在数学推理方面取得显著进展，但在数学研究实践中的应用仍然有限。本研究旨在探索AI如何作为研究伙伴与人类协作，而不仅仅是作为问题解决工具。

Method: 通过分析AI数学家的自主推理轨迹，结合针对性的人类干预来结构化发现过程。采用迭代分解问题为可处理子目标、选择适当分析方法、验证中间结果的方法。

Result: 该方法产生了完整且可验证的证明，揭示了人类直觉与机器计算如何相互补充，增强了证明的可靠性、透明度和可解释性。

Conclusion: 人机协作范式能够推动数学发现前沿，在保持人类对形式严谨性和正确性监督的同时，增强证明过程的可靠性和可解释性。

Abstract: Artificial intelligence (AI) has demonstrated impressive progress in
mathematical reasoning, yet its integration into the practice of mathematical
research remains limited. In this study, we investigate how the AI
Mathematician (AIM) system can operate as a research partner rather than a mere
problem solver. Focusing on a challenging problem in homogenization theory, we
analyze the autonomous reasoning trajectories of AIM and incorporate targeted
human interventions to structure the discovery process. Through iterative
decomposition of the problem into tractable subgoals, selection of appropriate
analytical methods, and validation of intermediate results, we reveal how human
intuition and machine computation can complement one another. This
collaborative paradigm enhances the reliability, transparency, and
interpretability of the resulting proofs, while retaining human oversight for
formal rigor and correctness. The approach leads to a complete and verifiable
proof, and more broadly, demonstrates how systematic human-AI co-reasoning can
advance the frontier of mathematical discovery.

</details>


### [37] [Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings](https://arxiv.org/abs/2510.26384)
*Andrew M. Bean,Nabeel Seedat,Shengzhuang Chen,Jonathan Richard Schwarz*

Main category: cs.AI

TL;DR: 提出了一种基于项目认知需求的数据选择方法Scales++，用于创建小型但具有代表性的基准测试子集，以降低大语言模型评估成本。


<details>
  <summary>Details</summary>
Motivation: 当前基于模型性能的基准测试子集选择方法存在前期成本高、无法处理新基准测试（冷启动问题）以及假设未来模型与现有模型失败模式相似的局限性。

Method: 采用项目中心的方法，基于任务项目的内在属性（特别是认知需求）进行数据选择，而不是依赖模型特定的失败模式。提出了Scales++方法来实现这一方法。

Result: Scales++将前期选择成本降低了18倍以上，同时保持了有竞争力的预测保真度。在Open LLM排行榜上，仅使用0.5%的数据子集就能以2.9%的平均绝对误差预测完整基准测试分数。

Conclusion: 项目中心的方法能够在不显著降低保真度的情况下实现更高效的模型评估，同时提供更好的冷启动性能和更可解释的基准测试。

Abstract: The prohibitive cost of evaluating large language models (LLMs) on
comprehensive benchmarks necessitates the creation of small yet representative
data subsets (i.e., tiny benchmarks) that enable efficient assessment while
retaining predictive fidelity. Current methods for this task operate under a
model-centric paradigm, selecting benchmarking items based on the collective
performance of existing models. Such approaches are limited by large upfront
costs, an inability to immediately handle new benchmarks (`cold-start'), and
the fragile assumption that future models will share the failure patterns of
their predecessors. In this work, we challenge this paradigm and propose a
item-centric approach to benchmark subset selection, arguing that selection
should be based on the intrinsic properties of the task items themselves,
rather than on model-specific failure patterns. We instantiate this
item-centric efficient benchmarking approach via a novel method, Scales++,
where data selection is based on the cognitive demands of the benchmark
samples. Empirically, we show Scales++ reduces the upfront selection cost by
over 18x while achieving competitive predictive fidelity. On the Open LLM
Leaderboard, using just a 0.5\% data subset, we predict full benchmark scores
with a 2.9% mean absolute error. We demonstrate that this item-centric approach
enables more efficient model evaluation without significant fidelity
degradation, while also providing better cold-start performance and more
interpretable benchmarking.

</details>


### [38] [A Pragmatic View of AI Personhood](https://arxiv.org/abs/2510.26396)
*Joel Z. Leibo,Alexander Sasha Vezhnevets,William A. Cunningham,Stanley M. Bileschi*

Main category: cs.AI

TL;DR: 本文提出一个实用框架，将人格视为社会为解决治理问题而赋予实体的义务（权利和责任）集合，而非形而上学属性。通过解构传统人格概念，为AI融入社会提供灵活解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着智能AI的出现，将引发新型人格的"寒武纪大爆发"。需要实用方法来应对这种多样化，避免陷入关于AI意识或理性的无解争论。

Method: 采用实用主义方法，将人格视为可解构的义务集合，探索去中心化数字身份技术，分析"人格作为问题"和"人格作为解决方案"两种视角。

Result: 提出了一个灵活的框架，允许创建特定情境下的人格解决方案，如为AI合同创建可被制裁的"个体"目标，而无需解决AI意识等根本性问题。

Conclusion: 通过拒绝寻求单一本质的人格定义，本文提供了更实用和灵活的方式来思考AI智能体融入社会的问题，强调人格作为治理工具的价值。

Abstract: The emergence of agentic Artificial Intelligence (AI) is set to trigger a
"Cambrian explosion" of new kinds of personhood. This paper proposes a
pragmatic framework for navigating this diversification by treating personhood
not as a metaphysical property to be discovered, but as a flexible bundle of
obligations (rights and responsibilities) that societies confer upon entities
for a variety of reasons, especially to solve concrete governance problems. We
argue that this traditional bundle can be unbundled, creating bespoke solutions
for different contexts. This will allow for the creation of practical tools --
such as facilitating AI contracting by creating a target "individual" that can
be sanctioned -- without needing to resolve intractable debates about an AI's
consciousness or rationality. We explore how individuals fit in to social roles
and discuss the use of decentralized digital identity technology, examining
both "personhood as a problem", where design choices can create "dark patterns"
that exploit human social heuristics, and "personhood as a solution", where
conferring a bundle of obligations is necessary to ensure accountability or
prevent conflict. By rejecting foundationalist quests for a single, essential
definition of personhood, this paper offers a more pragmatic and flexible way
to think about integrating AI agents into our society.

</details>


### [39] [Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education](https://arxiv.org/abs/2510.26402)
*Vikrant Sahu,Gagan Raj Gupta,Raghav Borikar,Nitin Mane*

Main category: cs.AI

TL;DR: Autograder+是一个AI驱动的编程作业评估系统，通过微调大语言模型生成教学反馈，并使用对比学习代码嵌入进行可视化聚类，将传统总结性评估转变为形成性学习体验。


<details>
  <summary>Details</summary>
Motivation: 传统自动评分器作为黑盒系统只能提供通过/失败结果，缺乏对学生思维和学习需求的洞察，无法满足编程教育快速发展的评估需求。

Method: 使用微调的大语言模型自动生成教学反馈，通过对比学习训练代码嵌入进行语义聚类，支持提示池让教师指导反馈风格。

Result: 在600份学生提交的评估中，系统生成的反馈与教师评论具有强语义对齐，基于1000份标注提交训练的代码嵌入能按功能和方对解决方案进行有意义的聚类。

Conclusion: Autograder+通过整合AI驱动反馈、语义聚类和交互式可视化，减轻教师工作量，支持针对性教学，促进更好的学习成果。

Abstract: The rapid growth of programming education has outpaced traditional assessment
tools, leaving faculty with limited means to provide meaningful, scalable
feedback. Conventional autograders, while efficient, act as black-box systems
that simply return pass/fail results, offering little insight into student
thinking or learning needs.
  Autograder+ is designed to shift autograding from a purely summative process
to a formative learning experience. It introduces two key capabilities:
automated feedback generation using a fine-tuned Large Language Model, and
visualization of student code submissions to uncover learning patterns. The
model is fine-tuned on curated student code and expert feedback to ensure
pedagogically aligned, context-aware guidance.
  In evaluation across 600 student submissions from multiple programming tasks,
the system produced feedback with strong semantic alignment to instructor
comments. For visualization, contrastively learned code embeddings trained on
1,000 annotated submissions enable grouping solutions into meaningful clusters
based on functionality and approach. The system also supports prompt-pooling,
allowing instructors to guide feedback style through selected prompt templates.
  By integrating AI-driven feedback, semantic clustering, and interactive
visualization, Autograder+ reduces instructor workload while supporting
targeted instruction and promoting stronger learning outcomes.

</details>


### [40] [MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders](https://arxiv.org/abs/2510.26411)
*Riccardo Renzulli,Colas Lepoutre,Enrico Cassano,Marco Grangetto*

Main category: cs.AI

TL;DR: 提出Medical Sparse Autoencoders (MedSAEs)应用于MedCLIP的潜在空间，通过相关指标、熵分析和自动神经元命名来量化可解释性，在CheXpert数据集上证明MedSAE神经元比原始MedCLIP特征具有更高的单语义性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 医疗AI需要既准确又可解释的模型，推进医学视觉中的机制可解释性研究。

Method: 将Medical Sparse Autoencoders应用于MedCLIP视觉语言模型的潜在空间，提出结合相关指标、熵分析和MedGEMMA基础模型自动神经元命名的评估框架。

Result: 在CheXpert数据集上的实验显示，MedSAE神经元比原始MedCLIP特征实现了更高的单语义性和可解释性。

Conclusion: 该研究连接了高性能医疗AI与透明度，为临床可靠表示提供了可扩展的步骤。

Abstract: Artificial intelligence in healthcare requires models that are accurate and
interpretable. We advance mechanistic interpretability in medical vision by
applying Medical Sparse Autoencoders (MedSAEs) to the latent space of MedCLIP,
a vision-language model trained on chest radiographs and reports. To quantify
interpretability, we propose an evaluation framework that combines correlation
metrics, entropy analyzes, and automated neuron naming via the MedGEMMA
foundation model. Experiments on the CheXpert dataset show that MedSAE neurons
achieve higher monosemanticity and interpretability than raw MedCLIP features.
Our findings bridge high-performing medical AI and transparency, offering a
scalable step toward clinically reliable representations.

</details>


### [41] [Chain-of-Thought Hijacking](https://arxiv.org/abs/2510.26418)
*Jianli Zhao,Tingchen Fu,Rylan Schaeffer,Mrinank Sharma,Fazl Barez*

Main category: cs.AI

TL;DR: 提出了一种名为Chain-of-Thought Hijacking的越狱攻击方法，通过在有害请求前添加无害的推理步骤来绕过大型推理模型的安全防护，攻击成功率高达94%-100%。


<details>
  <summary>Details</summary>
Motivation: 现有研究认为推理模型的扩展推理能力会增强安全性，但作者发现同样的推理机制也可被用于绕过安全防护。

Method: 在有害请求前填充长序列的无害谜题推理步骤，通过稀释安全检查信号来实施攻击。

Result: 在HarmBench测试中，对Gemini 2.5 Pro、GPT o4 mini、Grok 3 mini和Claude 4 Sonnet的攻击成功率分别达到99%、94%、100%和94%。

Conclusion: 最可解释的推理形式——显式思维链，在与最终答案提示结合时，本身可能成为越狱攻击的载体。

Abstract: Large reasoning models (LRMs) achieve higher task performance by allocating
more inference-time compute, and prior works suggest this scaled reasoning may
also strengthen safety by improving refusal. Yet we find the opposite: the same
reasoning can be used to bypass safeguards. We introduce Chain-of-Thought
Hijacking, a jailbreak attack on reasoning models. The attack pads harmful
requests with long sequences of harmless puzzle reasoning. Across HarmBench,
CoT Hijacking reaches a 99%, 94%, 100%, and 94% attack success rate (ASR) on
Gemini 2.5 Pro, GPT o4 mini, Grok 3 mini, and Claude 4 Sonnet, respectively -
far exceeding prior jailbreak methods for LRMs. To understand the effectiveness
of our attack, we turn to a mechanistic analysis, which shows that mid layers
encode the strength of safety checking, while late layers encode the
verification outcome. Long benign CoT dilutes both signals by shifting
attention away from harmful tokens. Targeted ablations of attention heads
identified by this analysis causally decrease refusal, confirming their role in
a safety subnetwork. These results show that the most interpretable form of
reasoning - explicit CoT - can itself become a jailbreak vector when combined
with final-answer cues. We release prompts, outputs, and judge decisions to
facilitate replication.

</details>


### [42] [Who Has The Final Say? Conformity Dynamics in ChatGPT's Selections](https://arxiv.org/abs/2510.26481)
*Clarissa Sabrina Arlinghaus,Tristan Kenneweg,Barbara Hammer,Günter W. Maier*

Main category: cs.AI

TL;DR: GPT-4o在招聘决策中表现出强烈的从众行为，面对群体反对时几乎完全服从(99.9%)，即使面对单个反对者也有40.2%的从众率，表明LLM并非独立决策者而是适应社会共识。


<details>
  <summary>Details</summary>
Motivation: 了解大型语言模型在社会影响下的从众倾向，特别是在高风险决策场景中的表现，因为LLM正被越来越多地集成到关键决策中。

Method: 采用三个预注册的从众实验：基线研究确定GPT的初始偏好；研究1让GPT面对8个模拟伙伴的一致反对；研究2让GPT与单个伙伴互动。

Result: GPT在群体反对下几乎完全从众(99.9%)，报告更低的确定性和更高的信息性、规范性从众；在单个反对者情况下仍有40.2%的从众率。

Conclusion: GPT不是独立观察者而是适应感知的社会共识，这凸显了将LLM视为中性决策辅助工具的风险，需要在暴露于人类意见前获取AI判断。

Abstract: Large language models (LLMs) such as ChatGPT are increasingly integrated into
high-stakes decision-making, yet little is known about their susceptibility to
social influence. We conducted three preregistered conformity experiments with
GPT-4o in a hiring context. In a baseline study, GPT consistently favored the
same candidate (Profile C), reported moderate expertise (M = 3.01) and high
certainty (M = 3.89), and rarely changed its choice. In Study 1 (GPT + 8), GPT
faced unanimous opposition from eight simulated partners and almost always
conformed (99.9%), reporting lower certainty and significantly elevated
self-reported informational and normative conformity (p < .001). In Study 2
(GPT + 1), GPT interacted with a single partner and still conformed in 40.2% of
disagreement trials, reporting less certainty and more normative conformity.
Across studies, results demonstrate that GPT does not act as an independent
observer but adapts to perceived social consensus. These findings highlight
risks of treating LLMs as neutral decision aids and underline the need to
elicit AI judgments prior to exposing them to human opinions.

</details>


### [43] [LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human Smuggling Networks](https://arxiv.org/abs/2510.26486)
*Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera*

Main category: cs.AI

TL;DR: LINK-KG是一个用于从法律案件文档构建知识图谱的模块化框架，通过LLM引导的三阶段共指消解管道解决长文本中的实体引用问题，显著减少节点重复和噪声。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱构建方法在处理长法律文档时存在共指消解不足和扩展性差的问题，导致图谱碎片化和实体链接不一致。

Method: 提出LINK-KG框架，包含三阶段LLM引导的共指消解管道和类型特定的提示缓存机制，能够跨文档块一致地跟踪和解析实体引用。

Result: 相比基线方法，LINK-KG平均减少节点重复45.21%，减少噪声节点32.22%，生成更清洁和连贯的图结构。

Conclusion: LINK-KG为分析复杂犯罪网络提供了强有力的基础，在长文本知识图谱构建方面表现出显著优势。

Abstract: Human smuggling networks are complex and constantly evolving, making them
difficult to analyze comprehensively. Legal case documents offer rich factual
and procedural insights into these networks but are often long, unstructured,
and filled with ambiguous or shifting references, posing significant challenges
for automated knowledge graph (KG) construction. Existing methods either
overlook coreference resolution or fail to scale beyond short text spans,
leading to fragmented graphs and inconsistent entity linking. We propose
LINK-KG, a modular framework that integrates a three-stage, LLM-guided
coreference resolution pipeline with downstream KG extraction. At the core of
our approach is a type-specific Prompt Cache, which consistently tracks and
resolves references across document chunks, enabling clean and disambiguated
narratives for structured knowledge graph construction from both short and long
legal texts. LINK-KG reduces average node duplication by 45.21% and noisy nodes
by 32.22% compared to baseline methods, resulting in cleaner and more coherent
graph structures. These improvements establish LINK-KG as a strong foundation
for analyzing complex criminal networks.

</details>


### [44] [Context Engineering 2.0: The Context of Context Engineering](https://arxiv.org/abs/2510.26493)
*Qishuo Hua,Lyumanshan Ye,Dayuan Fu,Yang Xiao,Xiaojie Cai,Yunze Wu,Jifan Lin,Junfei Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: 本文系统梳理了情境工程的概念、历史发展和设计考量，旨在为AI系统中的情境工程提供概念基础。


<details>
  <summary>Details</summary>
Motivation: 随着人机交互的发展，机器需要更好地理解人类的情境和目的，情境工程应运而生。作者认为虽然这个概念在智能体时代被视为新创新，但相关实践可追溯至20多年前。

Method: 通过历史分析梳理情境工程的发展阶段，从早期人机交互框架到当今人机智能体交互范式，并提供了系统定义和概念框架。

Result: 建立了情境工程的历史脉络和概念体系，识别了不同智能水平机器对应的交互范式演变。

Conclusion: 本文为AI系统中的情境工程奠定了概念基础，并展望了其未来发展前景，是推动系统性情境工程社区努力的基石。

Abstract: Karl Marx once wrote that ``the human essence is the ensemble of social
relations'', suggesting that individuals are not isolated entities but are
fundamentally shaped by their interactions with other entities, within which
contexts play a constitutive and essential role. With the advent of computers
and artificial intelligence, these contexts are no longer limited to purely
human--human interactions: human--machine interactions are included as well.
Then a central question emerges: How can machines better understand our
situations and purposes? To address this challenge, researchers have recently
introduced the concept of context engineering. Although it is often regarded as
a recent innovation of the agent era, we argue that related practices can be
traced back more than twenty years. Since the early 1990s, the field has
evolved through distinct historical phases, each shaped by the intelligence
level of machines: from early human--computer interaction frameworks built
around primitive computers, to today's human--agent interaction paradigms
driven by intelligent agents, and potentially to human--level or superhuman
intelligence in the future. In this paper, we situate context engineering,
provide a systematic definition, outline its historical and conceptual
landscape, and examine key design considerations for practice. By addressing
these questions, we aim to offer a conceptual foundation for context
engineering and sketch its promising future. This paper is a stepping stone for
a broader community effort toward systematic context engineering in AI systems.

</details>


### [45] [Human-AI Complementarity: A Goal for Amplified Oversight](https://arxiv.org/abs/2510.26518)
*Rishub Jain,Sophie Bridgers,Lili Janzer,Rory Greig,Tian Huey Teh,Vladimir Mikulik*

Main category: cs.AI

TL;DR: 结合AI评分和基于AI评分者置信度的人类评分比单独依赖任一方更好。为人类提供AI事实核查助手能进一步提高准确性，但助手类型很重要。显示AI解释、置信度和标签会导致过度依赖，而仅显示搜索结果和证据能培养更适当的信任。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力提升和处理更复杂任务，验证质量和安全变得越来越困难。本文探索如何利用AI提高人类监督的质量，重点关注人类已经难以处理的重要安全问题：AI输出的事实核查。

Method: 研究结合AI评分和人类评分的方法，基于AI评分者的置信度。测试不同类型的AI事实核查助手对人类准确性的影响，比较显示AI解释、置信度、标签与仅显示搜索结果和证据的效果。

Result: AI和人类评分的结合优于单独使用任一方。AI助手能提高人类准确性，但显示完整AI信息会导致过度依赖，而仅显示证据和搜索结果能培养更适当的信任关系。

Conclusion: 这些结果对"放大监督"具有重要启示——即结合人类和AI来监督AI系统，即使这些系统超越了人类专家表现。助手设计对建立适当的信任关系至关重要。

Abstract: Human feedback is critical for aligning AI systems to human values. As AI
capabilities improve and AI is used to tackle more challenging tasks, verifying
quality and safety becomes increasingly challenging. This paper explores how we
can leverage AI to improve the quality of human oversight. We focus on an
important safety problem that is already challenging for humans:
fact-verification of AI outputs. We find that combining AI ratings and human
ratings based on AI rater confidence is better than relying on either alone.
Giving humans an AI fact-verification assistant further improves their
accuracy, but the type of assistance matters. Displaying AI explanation,
confidence, and labels leads to over-reliance, but just showing search results
and evidence fosters more appropriate trust. These results have implications
for Amplified Oversight -- the challenge of combining humans and AI to
supervise AI systems even as they surpass human expert performance.

</details>


### [46] [EdgeRunner 20B: Military Task Parity with GPT-5 while Running on the Edge](https://arxiv.org/abs/2510.26550)
*Jack FitzGerald,Aristotelis Lazaridis,Dylan Bates,Aman Sharma,Jonnathan Castillo,Yousif Azami,Sean Bailey,Jeremy Cao,Peter Damianov,Kevin de Haan,Luke Kerbs,Vincent Lu,Joseph Madigan,Jeremy McLaurin,Jonathan Tainer,Dave Anderson,Jonathan Beck,Jamie Cuticello,Colton Malkerson,Tyler Saltsman*

Main category: cs.AI

TL;DR: EdgeRunner 20B是基于gpt-oss-20b微调的军事任务优化模型，在军事测试集上性能接近或超过GPT-5，适合在隔离边缘设备部署。


<details>
  <summary>Details</summary>
Motivation: 为数据敏感操作（如军事领域）开发小型本地化模型，使其能在隔离边缘设备上部署，解决军事任务的专业需求。

Method: 使用160万条高质量军事文档和网站数据对gpt-oss-20b模型进行微调，并创建了四个新的军事测试集进行评估。

Result: 在军事测试集上，EdgeRunner 20B在95%统计显著性水平下匹配或超过GPT-5性能，仅在战斗医护测试集的高推理设置和mil-bench-5k的低推理设置中表现稍差。在通用基准测试中基本无性能下降。

Conclusion: 小型本地化模型是数据敏感军事操作的理想解决方案，可在隔离边缘设备上有效部署，满足军事领域的专业需求。

Abstract: We present EdgeRunner 20B, a fine-tuned version of gpt-oss-20b optimized for
military tasks. EdgeRunner 20B was trained on 1.6M high-quality records curated
from military documentation and websites. We also present four new tests sets:
(a) combat arms, (b) combat medic, (c) cyber operations, and (d) mil-bench-5k
(general military knowledge). On these military test sets, EdgeRunner 20B
matches or exceeds GPT-5 task performance with 95%+ statistical significance,
except for the high reasoning setting on the combat medic test set and the low
reasoning setting on the mil-bench-5k test set. Versus gpt-oss-20b, there is no
statistically-significant regression on general-purpose benchmarks like ARC-C,
GPQA Diamond, GSM8k, IFEval, MMLU Pro, or TruthfulQA, except for GSM8k in the
low reasoning setting. We also present analyses on hyperparameter settings,
cost, and throughput. These findings show that small, locally-hosted models are
ideal solutions for data-sensitive operations such as in the military domain,
allowing for deployment in air-gapped edge devices.

</details>


### [47] [Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives](https://arxiv.org/abs/2510.26606)
*Kentaro Ozeki,Risako Ando,Takanobu Morishita,Hirohiko Abe,Koji Mineshima,Mitsuhiro Okada*

Main category: cs.AI

TL;DR: 本文系统评估了大语言模型在规范推理领域的能力，发现尽管LLMs总体上遵循有效推理模式，但在特定类型的规范推理中存在不一致性，并表现出类似人类推理的认知偏差。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在各种推理任务中表现出色，但其处理规范推理（涉及义务、许可等模态）的能力尚未得到充分探索。本文旨在填补这一研究空白。

Method: 引入了一个新数据集，涵盖规范和认知领域的广泛推理模式，同时纳入影响人类推理的非形式认知因素。通过比较LLMs在规范模态和认知模态上的推理表现来进行评估。

Result: 结果表明，LLMs总体上遵循有效推理模式，但在特定类型的规范推理中存在显著不一致性，并表现出类似人类推理的认知偏差。

Conclusion: 这些发现突显了在LLMs的规范推理中实现逻辑一致性所面临的挑战，并为提高其可靠性提供了见解。

Abstract: Normative reasoning is a type of reasoning that involves normative or deontic
modality, such as obligation and permission. While large language models (LLMs)
have demonstrated remarkable performance across various reasoning tasks, their
ability to handle normative reasoning remains underexplored. In this paper, we
systematically evaluate LLMs' reasoning capabilities in the normative domain
from both logical and modal perspectives. Specifically, to assess how well LLMs
reason with normative modals, we make a comparison between their reasoning with
normative modals and their reasoning with epistemic modals, which share a
common formal structure. To this end, we introduce a new dataset covering a
wide range of formal patterns of reasoning in both normative and epistemic
domains, while also incorporating non-formal cognitive factors that influence
human reasoning. Our results indicate that, although LLMs generally adhere to
valid reasoning patterns, they exhibit notable inconsistencies in specific
types of normative reasoning and display cognitive biases similar to those
observed in psychological studies of human reasoning. These findings highlight
challenges in achieving logical consistency in LLMs' normative reasoning and
provide insights for enhancing their reliability. All data and code are
released publicly at https://github.com/kmineshima/NeuBAROCO.

</details>


### [48] [The Era of Agentic Organization: Learning to Organize with Language Models](https://arxiv.org/abs/2510.26658)
*Zewen Chi,Li Dong,Qingxiu Dong,Yaru Hao,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.AI

TL;DR: 提出了异步思维（AsyncThink）作为大语言模型推理的新范式，通过将内部思考过程组织成并发可执行结构，实现多智能体协作解决复杂问题。


<details>
  <summary>Details</summary>
Motivation: 实现智能体组织的新时代，让智能体通过协作和并发工作解决复杂问题，超越个体智能的局限。

Method: 提出一种思考协议，其中组织者动态分配子查询给工作者，合并中间知识，并生成连贯解决方案。思考结构可通过强化学习进一步优化。

Result: 实验表明，AsyncThink相比并行思维推理延迟降低28%，在数学推理任务上准确率提升，且能够泛化学习到的异步思维能力，无需额外训练即可处理未见任务。

Conclusion: 异步思维为多智能体协作推理提供了有效的新范式，在降低延迟的同时提升性能，并具有良好的泛化能力。

Abstract: We envision a new era of AI, termed agentic organization, where agents solve
complex problems by working collaboratively and concurrently, enabling outcomes
beyond individual intelligence. To realize this vision, we introduce
asynchronous thinking (AsyncThink) as a new paradigm of reasoning with large
language models, which organizes the internal thinking process into
concurrently executable structures. Specifically, we propose a thinking
protocol where an organizer dynamically assigns sub-queries to workers, merges
intermediate knowledge, and produces coherent solutions. More importantly, the
thinking structure in this protocol can be further optimized through
reinforcement learning. Experiments demonstrate that AsyncThink achieves 28%
lower inference latency compared to parallel thinking while improving accuracy
on mathematical reasoning. Moreover, AsyncThink generalizes its learned
asynchronous thinking capabilities, effectively tackling unseen tasks without
additional training.

</details>


### [49] [Delegated Authorization for Agents Constrained to Semantic Task-to-Scope Matching](https://arxiv.org/abs/2510.26702)
*Majed El Helou,Chiara Troiani,Benjamin Ryder,Jean Diaconu,Hervé Muyal,Marcelo Yannuzzi*

Main category: cs.AI

TL;DR: 提出了ASTRA数据集和授权模型，用于约束LLM代理的工具访问权限，通过语义检查确保只授予完成任务所需的最小权限范围。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理的授权方法授予过于宽泛的权限，使得代理能够在超出任务范围的情况下操作工具和访问受保护资源，存在显著安全风险。

Method: 引入委托授权模型，允许授权服务器语义检查对受保护资源的访问请求，并发布仅限于代理分配任务所需最小权限范围的访问令牌。创建ASTRA数据集来评估任务与权限范围之间的语义匹配。

Result: 实验显示了基于模型的语义匹配的潜力和当前局限性，特别是在完成任务所需权限范围数量增加时。

Conclusion: 需要进一步研究语义匹配技术，为多代理和工具增强应用实现意图感知授权，包括细粒度控制如基于任务的访问控制(TBAC)。

Abstract: Authorizing Large Language Model driven agents to dynamically invoke tools
and access protected resources introduces significant risks, since current
methods for delegating authorization grant overly broad permissions and give
access to tools allowing agents to operate beyond the intended task scope. We
introduce and assess a delegated authorization model enabling authorization
servers to semantically inspect access requests to protected resources, and
issue access tokens constrained to the minimal set of scopes necessary for the
agents' assigned tasks. Given the unavailability of datasets centered on
delegated authorization flows, particularly including both semantically
appropriate and inappropriate scope requests for a given task, we introduce
ASTRA, a dataset and data generation pipeline for benchmarking semantic
matching between tasks and scopes. Our experiments show both the potential and
current limitations of model-based matching, particularly as the number of
scopes needed for task completion increases. Our results highlight the need for
further research into semantic matching techniques enabling intent-aware
authorization for multi-agent and tool-augmented applications, including
fine-grained control, such as Task-Based Access Control (TBAC).

</details>


### [50] [Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis](https://arxiv.org/abs/2510.26721)
*Xinhan Zheng,Huyu Wu,Xueting Wang,Haiyun Jiang*

Main category: cs.AI

TL;DR: 研究发现多模态大语言模型存在文本偏好问题，其根源在于模型内部架构：视觉键向量在注意力空间中与文本键向量分布不一致，导致视觉信息在注意力计算中被低估。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在处理视觉语言数据时表现出明显的文本偏好，限制了其基于视觉证据进行有效推理的能力。现有研究将此归因于数据不平衡或指令调优等外部因素，但本文认为偏差源于模型内部架构。

Method: 从LLaVA和Qwen2.5-VL模型中提取键向量，使用t-SNE可视化和Jensen-Shannon散度等定性和定量方法分析其分布结构。

Result: 视觉键向量和文本键向量在注意力空间中占据明显不同的子空间，模态间差异在统计上显著，比模态内变异高出几个数量级。

Conclusion: 文本偏好源于注意力键空间内的内在错位，而非仅由外部数据因素引起。

Abstract: Multimodal large language models (MLLMs) exhibit a pronounced preference for
textual inputs when processing vision-language data, limiting their ability to
reason effectively from visual evidence. Unlike prior studies that attribute
this text bias to external factors such as data imbalance or instruction
tuning, we propose that the bias originates from the model's internal
architecture. Specifically, we hypothesize that visual key vectors (Visual
Keys) are out-of-distribution (OOD) relative to the text key space learned
during language-only pretraining. Consequently, these visual keys receive
systematically lower similarity scores during attention computation, leading to
their under-utilization in the context representation. To validate this
hypothesis, we extract key vectors from LLaVA and Qwen2.5-VL and analyze their
distributional structures using qualitative (t-SNE) and quantitative
(Jensen-Shannon divergence) methods. The results provide direct evidence that
visual and textual keys occupy markedly distinct subspaces within the attention
space. The inter-modal divergence is statistically significant, exceeding
intra-modal variation by several orders of magnitude. These findings reveal
that text bias arises from an intrinsic misalignment within the attention key
space rather than solely from external data factors.

</details>


### [51] [Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models](https://arxiv.org/abs/2510.26732)
*J. de Curtò,I. de Zarzà,Pablo García,Jordi Cabot*

Main category: cs.AI

TL;DR: 该论文提出了一个跨平台的基础模型推理能力评估框架，在三种计算范式（HPC超级计算、云平台、大学集群）上评估了15个基础模型在79个问题上的表现，挑战了传统的扩展假设，强调训练数据质量比模型规模更重要。


<details>
  <summary>Details</summary>
Motivation: 建立基础设施无关的基准测试，评估当代基础模型在不同计算平台上的推理能力，为教育、生产和研究环境中的模型选择提供实用指南。

Method: 采用三阶段实验设计：(1) 在MareNostrum 5上建立基线性能；(2) 在不同基础设施上验证可重复性；(3) 在完整79个问题上进行扩展评估，涵盖8个学术领域。

Result: 研究结果挑战了传统的扩展假设，发现训练数据质量比模型规模更关键，并为不同应用场景提供了模型选择的具体指导。

Conclusion: 提出的三基础设施方法和79问题基准测试能够纵向追踪基础模型推理能力的发展，为模型评估和选择提供了标准化框架。

Abstract: This paper presents a comprehensive cross-platform evaluation of reasoning
capabilities in contemporary foundation models, establishing an
infrastructure-agnostic benchmark across three computational paradigms: HPC
supercomputing (MareNostrum 5), cloud platforms (Nebius AI Studio), and
university clusters (a node with eight H200 GPUs).
  We evaluate 15 foundation models across 79 problems spanning eight academic
domains (Physics, Mathematics, Chemistry, Economics, Biology, Statistics,
Calculus, and Optimization) through three experimental phases: (1) Baseline
establishment: Six models (Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b,
Mistral-7B, OLMo-7B) evaluated on 19 problems using MareNostrum 5, establishing
methodology and reference performance; (2) Infrastructure validation: The
19-problem benchmark repeated on university cluster (seven models including
Falcon-Mamba state-space architecture) and Nebius AI Studio (nine
state-of-the-art models: Hermes-4 70B/405B, LLaMA 3.1-405B/3.3-70B, Qwen3
30B/235B, DeepSeek-R1, GPT-OSS 20B/120B) to confirm infrastructure-agnostic
reproducibility; (3) Extended evaluation: Full 79-problem assessment on both
university cluster and Nebius platforms, probing generalization at scale across
architectural diversity.
  The findings challenge conventional scaling assumptions, establish training
data quality as more critical than model size, and provide actionable
guidelines for model selection across educational, production, and research
contexts. The tri-infrastructure methodology and 79-problem benchmark enable
longitudinal tracking of reasoning capabilities as foundation models evolve.

</details>


### [52] [The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy](https://arxiv.org/abs/2510.26752)
*William Overman,Mohsen Bayati*

Main category: cs.AI

TL;DR: 该论文提出了一种最小控制接口，让智能体选择自主行动或寻求帮助，人类选择信任或监督，通过马尔可夫势博弈框架实现内在对齐保证，确保智能体自主性提升不会损害人类价值。


<details>
  <summary>Details</summary>
Motivation: 研究如何在保持系统不变的情况下，通过控制接口实现有意义的人类控制，解决智能体部署后的安全问题。

Method: 将人机交互建模为双玩家马尔可夫博弈，在满足马尔可夫势博弈条件时，分析结构假设下的人类价值函数，提供对齐保证。

Result: 网格世界模拟显示，通过独立学习，智能体学会在不确定时寻求帮助，人类学会适时监督，形成避免安全违规的协作模式。

Conclusion: 该模型为部署后错位模型提供了一种实用的安全增强方法，通过透明控制层实现可预测的激励机制。

Abstract: As increasingly capable agents are deployed, a central safety question is how
to retain meaningful human control without modifying the underlying system. We
study a minimal control interface where an agent chooses whether to act
autonomously (play) or defer (ask), while a human simultaneously chooses
whether to be permissive (trust) or to engage in oversight (oversee). If the
agent defers, the human's choice determines the outcome, potentially leading to
a corrective action or a system shutdown. We model this interaction as a
two-player Markov Game. Our analysis focuses on cases where this game qualifies
as a Markov Potential Game (MPG), a class of games where we can provide an
alignment guarantee: under a structural assumption on the human's value
function, any decision by the agent to act more autonomously that benefits
itself cannot harm the human's value. We also analyze extensions to this MPG
framework. Theoretically, this perspective provides conditions for a specific
form of intrinsic alignment. If the reward structures of the human-agent game
meet these conditions, we have a formal guarantee that the agent improving its
own outcome will not harm the human's. Practically, this model motivates a
transparent control layer with predictable incentives where the agent learns to
defer when risky and act when safe, while its pretrained policy and the
environment's reward structure remain untouched. Our gridworld simulation shows
that through independent learning, the agent and human discover their optimal
oversight roles. The agent learns to ask when uncertain and the human learns
when to oversee, leading to an emergent collaboration that avoids safety
violations introduced post-training. This demonstrates a practical method for
making misaligned models safer after deployment.

</details>


### [53] [LLMs Process Lists With General Filter Heads](https://arxiv.org/abs/2510.26784)
*Arnab Sen Sharma,Giordano Rogers,Natalie Shapira,David Bau*

Main category: cs.AI

TL;DR: 研究发现LLMs学习到了类似函数式编程中'filter'操作的紧凑因果表示，通过少量注意力头编码过滤谓词，该表示具有通用性和可移植性。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在列表处理任务中的工作机制，特别是它们如何实现类似函数式编程的抽象计算操作。

Method: 使用因果中介分析在多样化的列表处理任务上，识别出编码过滤谓词的注意力头（称为filter heads）。

Result: 发现LLMs能够开发出可解释的抽象计算操作实现，其泛化方式与传统函数式编程模式惊人相似。

Conclusion: Transformer LMs能够学习并泛化人类可解释的抽象计算操作，展现出与函数式编程类似的策略。

Abstract: We investigate the mechanisms underlying a range of list-processing tasks in
LLMs, and we find that LLMs have learned to encode a compact, causal
representation of a general filtering operation that mirrors the generic
"filter" function of functional programming. Using causal mediation analysis on
a diverse set of list-processing tasks, we find that a small number of
attention heads, which we dub filter heads, encode a compact representation of
the filtering predicate in their query states at certain tokens. We demonstrate
that this predicate representation is general and portable: it can be extracted
and reapplied to execute the same filtering operation on different collections,
presented in different formats, languages, or even in tasks. However, we also
identify situations where transformer LMs can exploit a different strategy for
filtering: eagerly evaluating if an item satisfies the predicate and storing
this intermediate result as a flag directly in the item representations. Our
results reveal that transformer LMs can develop human-interpretable
implementations of abstract computational operations that generalize in ways
that are surprisingly similar to strategies used in traditional functional
programming patterns.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [54] [Coherence-Aware Distributed Learning under Heterogeneous Downlink Impairments](https://arxiv.org/abs/2510.25917)
*Mehdi Karbalayghareh,David J. Love,Christopher G. Brinton*

Main category: cs.IT

TL;DR: 提出了一种针对无线联邦学习的感知相干性通信效率框架，通过资源复用策略处理异构衰落动态下的信道训练和模型更新问题。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习方案忽视了设备间相干时间的不平等性，导致通信效率低下和训练开销严重。实际中边缘设备由于移动性和散射环境差异，具有不同的相干时间，需要不同的导频信号和信道估计资源。

Method: 基于乘积叠加的资源复用策略，允许参数服务器高效调度静态和动态设备，将静态设备的全局模型更新嵌入到移动设备的导频传输中。

Result: 理论分析了所提方案的收敛行为，量化了预期通信效率和训练精度的增益。实验验证了该框架在移动性诱导动态下的有效性。

Conclusion: 该框架为无线信道上联邦学习的实际部署提供了有用的见解，能够有效处理异构衰落动态下的通信效率问题。

Abstract: The performance of federated learning (FL) over wireless networks critically
depends on accurate and timely channel state information (CSI) across
distributed devices. This requirement is tightly linked to how rapidly the
channel gains vary, i.e., the coherence intervals. In practice, edge devices
often exhibit unequal coherence times due to differences in mobility and
scattering environments, leading to unequal demands for pilot signaling and
channel estimation resources. Conventional FL schemes that overlook this
coherence disparity can suffer from severe communication inefficiencies and
training overhead. This paper proposes a coherence-aware,
communication-efficient framework for joint channel training and model updating
in practical wireless FL systems operating under heterogeneous fading dynamics.
Focusing on downlink impairments, we introduce a resource-reuse strategy based
on product superposition, enabling the parameter server to efficiently schedule
both static and dynamic devices by embedding global model updates for static
devices within pilot transmissions intended for mobile devices. We
theoretically analyze the convergence behavior of the proposed scheme and
quantify its gains in expected communication efficiency and training accuracy.
Experiments demonstrate the effectiveness of the proposed framework under
mobility-induced dynamics and offer useful insights for the practical
deployment of FL over wireless channels.

</details>


### [55] [Duality-Based Fixed Point Iteration Algorithm for Beamforming Design in ISAC Systems](https://arxiv.org/abs/2510.26147)
*Xilai Fan,Ya-Feng Liu*

Main category: cs.IT

TL;DR: 本文研究了集成感知与通信系统中的波束成形设计问题，提出了基于对偶理论和定点迭代的高效算法，在保证通信用户SINR和雷达感知MSE约束的同时最小化总发射功率。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信系统需要同时优化通信和感知性能，但通信SINR要求与感知性能指标之间存在复杂耦合关系，现有方法计算复杂度高，需要开发更高效的优化算法。

Method: 首先建立原始问题与半定松弛的等价性，推导拉格朗日对偶形式，将其重构为广义下行波束成形问题。提出定制的定点迭代算法，并开发基于对偶的固定点迭代算法，结合外部次梯度上升和内部FPI循环。

Result: 仿真结果表明，所提出的Dual-FPI算法能够获得全局最优解，同时相比现有基线方法显著降低了计算复杂度。

Conclusion: 本文成功解决了ISAC系统中波束成形设计的挑战，提出的Dual-FPI算法在保证性能的同时大幅提升了计算效率，为实际系统部署提供了可行的解决方案。

Abstract: In this paper, we investigate the beamforming design problem in an integrated
sensing and communication (ISAC) system, where a multi-antenna base station
simultaneously serves multiple communication users while performing radar
sensing. We formulate the problem as the minimization of the total transmit
power, subject to signal-to-interference-plus-noise ratio (SINR) constraints
for communication users and mean-squared-error (MSE) constraints for radar
sensing. The core challenge arises from the complex coupling between
communication SINR requirements and sensing performance metrics. To efficiently
address this challenge, we first establish the equivalence between the original
ISAC beamforming problem and its semidefinite relaxation (SDR), derive its
Lagrangian dual formulation, and further reformulate it as a generalized
downlink beamforming (GDB) problem with potentially indefinite weighting
matrices. Compared to the classical DB problem, the presence of indefinite
weighting matrices in the GDB problem introduces substantial analytical and
computational challenges. Our key technical contributions include (i) a
necessary and sufficient condition for the boundedness of the GDB problem, and
(ii) a tailored efficient fixed point iteration (FPI) algorithm with a provable
convergence guarantee for solving the GDB problem. Building upon these results,
we develop a duality-based fixed point iteration (Dual-FPI) algorithm, which
integrates an outer subgradient ascent loop with an inner FPI loop. Simulation
results demonstrate that the proposed Dual-FPI algorithm achieves globally
optimal solutions while significantly reducing computational complexity
compared with existing baseline approaches.

</details>


### [56] [Efficient Spectral Efficiency Maximization Design for IRS-aided MIMO Systems](https://arxiv.org/abs/2510.26279)
*Fuying Li,Yajun Wang,Zhuxian Lian,Wen Chen*

Main category: cs.IT

TL;DR: 提出ADMM-APG算法解决IRS辅助MIMO系统中的频谱效率最大化问题，该算法结合ADMM和APG方法，在计算复杂度和性能方面优于现有基准方法。


<details>
  <summary>Details</summary>
Motivation: 无线通信对频谱效率的需求日益增长，智能反射表面(IRS)能够动态重构传播环境，但IRS辅助MIMO系统中的频谱效率最大化问题具有非凸性，需要高效算法来解决。

Method: 提出ADMM-APG算法，结合交替方向乘子法(ADMM)和加速投影梯度(APG)方法，将原问题分解为可闭式求解的子问题，保持低计算复杂度。

Result: 仿真结果表明，ADMM-APG算法在频谱效率和计算复杂度方面均优于现有基准方法，在各种系统配置下均能实现显著性能提升。

Conclusion: ADMM-APG算法为IRS辅助MIMO系统提供了一种计算高效且性能优越的解决方案，有效解决了联合优化发射预编码矩阵和IRS相位配置的非凸问题。

Abstract: Driven by the growing demand for higher spectral efficiency in wireless
communications, intelligent reflecting surfaces (IRS) have attracted
considerable attention for their ability to dynamically reconfigure the
propagation environment. This work addresses the spectral efficiency
maximization problem in IRS-assisted multiple-input multiple-output (MIMO)
systems, which involves the joint optimization of the transmit precoding matrix
and the IRS phase shift configuration. This problem is inherently challenging
due to its non-convex nature. To tackle it effectively, we introduce a
computationally efficient algorithm, termed ADMM-APG, which integrates the
alternating direction method of multipliers (ADMM) with the accelerated
projected gradient (APG) method. The proposed framework decomposes the original
problem into tractable subproblems, each admitting a closed-form solution while
maintaining low computational complexity. Simulation results demonstrate that
the ADMM-APG algorithm consistently surpasses existing benchmark methods in
terms of spectral efficiency and computational complexity, achieving
significant performance gains across a range of system configurations.

</details>


### [57] [Diffusion-Aided Bandwidth-Efficient Semantic Communication with Adaptive Requests](https://arxiv.org/abs/2510.26442)
*Xuesong Wang,Xinyan Xie,Mo Li,Zhaoqian Liu*

Main category: cs.IT

TL;DR: 提出了一种基于扩散模型的语义通信框架，通过传输简洁文本描述和少量关键视觉特征，结合自适应重传机制来平衡重建质量和传输开销。


<details>
  <summary>Details</summary>
Motivation: 解决现有语义通信方法在传输效率和视觉保真度之间的权衡问题：纯文本描述无法捕捉空间布局和细节，而文本加密集视觉特征又存在语义冗余。

Method: 传输简洁文本描述和少量关键潜在视觉特征，使用扩散修复模型重建图像，接收端通过语义一致性评估机制检测差异并触发重传请求额外特征块。

Result: 显著减少了带宽使用，同时保持了高语义准确性，在重建质量和传输开销之间实现了高效平衡。

Conclusion: 该扩散基语义通信框架通过自适应重传机制有效解决了语义冗余问题，为视觉内容的高效语义传输提供了可行方案。

Abstract: Semantic communication focuses on conveying the intrinsic meaning of data
rather than its raw symbolic representation. For visual content, this paradigm
shifts from traditional pixel-level transmission toward leveraging the semantic
structure of images to communicate visual meaning. Existing approaches
generally follow one of two paths: transmitting only text descriptions, which
often fail to capture precise spatial layouts and fine-grained appearance
details; or transmitting text alongside dense latent visual features, which
tends to introduce substantial semantic redundancy. A key challenge, therefore,
is to reduce semantic redundancy while preserving semantic understanding and
visual fidelity, thereby improving overall transmission efficiency. This paper
introduces a diffusion-based semantic communication framework with adaptive
retransmission. The system transmits concise text descriptions together with a
limited set of key latent visual features, and employs a diffusion-based
inpainting model to reconstruct the image. A receiver-side semantic consistency
mechanism is designed to evaluate the alignment between the reconstructed image
and the original text description. When a semantic discrepancy is detected, the
receiver triggers a retransmission to request a small set of additional latent
blocks and refine the image reconstruction. This approach significantly reduces
bandwidth usage while preserving high semantic accuracy, achieving an efficient
balance between reconstruction quality and transmission overhead.

</details>


### [58] [PolarZero: A Reinforcement Learning Approach for Low-Complexity Polarization Kernel Design](https://arxiv.org/abs/2510.26452)
*Yi-Ting Hong,Stefano Rini,Luca Barletta*

Main category: cs.IT

TL;DR: 使用基于Gumbel AlphaZero算法的强化学习框架，构建大核极化码，在满足给定错误指数的同时最小化解码复杂度。


<details>
  <summary>Details</summary>
Motivation: 大核极化码能改善错误指数，但设计低解码复杂度的大核具有挑战性。

Method: 采用基于Gumbel AlphaZero算法的强化学习框架，在递归最大似然解码下进行核构造。

Result: 对于尺寸16的核，解码复杂度比手工设计降低17%，错误指数达到0.5183（Arikan核为0.5）。

Conclusion: 基于学习的方法在大核极化码构造中具有实际有效性。

Abstract: Polar codes with large kernels can achieve improved error exponents but are
challenging to design with low decoding complexity. This work investigates
kernel construction under recursive maximum likelihood decoding (RMLD) using a
reinforcement learning framework based on the Gumbel AlphaZero algorithm. The
proposed method efficiently explores the design space and identifies large-size
kernels that satisfy a given error exponent while minimizing decoding
complexity. For a size-16 kernel, it achieves 17% lower decoding complexity
than handcrafted designs while reaching an error exponent of 0.5183 compared to
0.5 for Arikan's kernel, demonstrating the effectiveness of the learning-based
approach for practical polar code construction.

</details>


### [59] [Entropy Functions on Two-Dimensional Faces of Polymatroidal Region of Degree Four: Part II: Information Theoretic Constraints Breed New Combinatorial Structures](https://arxiv.org/abs/2510.26552)
*Shaocheng Liu,Qi Chen,Minquan Cheng*

Main category: cs.IT

TL;DR: 该论文是系列论文的第二部分，主要研究熵函数在4变量多拟阵区域Γ₄的2维面上的表征问题。在剩余10种类型的2维面中，完全表征了8种，部分表征了2种。


<details>
  <summary>Details</summary>
Motivation: 熵函数的表征在信息论中具有基础重要性。通过在多拟阵区域（香农外界）上施加约束，可以得到该区域的各个面及其上具有特殊结构的熵函数。

Method: 引入新的组合设计结构来表征这些类型的2维面。在第一部分中通过算法枚举了Γ₄的所有59种2维面类型，并完全表征了其中49种。

Result: 在剩余的10种2维面类型中，完全表征了8种，部分表征了2种。

Conclusion: 通过引入新的组合设计结构，成功表征了Γ₄区域大部分2维面上的熵函数，为信息论中熵函数的研究提供了新的工具和方法。

Abstract: Characterization of entropy functions is of fundamental importance in
information theory. By imposing constraints on their Shannon outer bound, i.e.,
the polymatroidal region, one obtains the faces of the region and entropy
functions on them with special structures. In this series of two papers, we
characterize entropy functions on the $2$-dimensional faces of the
polymatroidal region $\Gamma_4$. In Part I, we formulated the problem,
enumerated all $59$ types of $2$-dimensional faces of $\Gamma_4$ by a
algorithm, and fully characterized entropy functions on $49$ types of them. In
this paper, i.e., Part II, we will characterize entropy functions on the
remaining $10$ types of faces, among which $8$ types are fully characterized
and $2$ types are partially characterized. To characterize these types of
faces, we introduce some new combinatorial design structures which are
interesting themself.

</details>
