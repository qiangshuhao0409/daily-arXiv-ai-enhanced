{"id": "2511.05524", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05524", "abs": "https://arxiv.org/abs/2511.05524", "authors": ["Ruiying Chen"], "title": "Evidence-Bound Autonomous Research (EviBound): A Governance Framework for Eliminating False Claims", "comment": "27 pages, 11 figures, 5 tables. Reproducibility package with MLflow artifacts and Google Colab notebooks available upon publication", "summary": "LLM-based autonomous research agents report false claims: tasks marked \"complete\" despite missing artifacts, contradictory metrics, or failed executions. EviBound is an evidence-bound execution framework that eliminates false claims through dual governance gates requiring machine-checkable evidence.\n  Two complementary gates enforce evidence requirements. The pre-execution Approval Gate validates acceptance criteria schemas before code runs, catching structural violations proactively. The post-execution Verification Gate validates artifacts via MLflow API queries (with recursive path checking) and optionally validates metrics when specified by acceptance criteria. Claims propagate only when backed by a queryable run ID, required artifacts, and FINISHED status. Bounded, confidence-gated retries (typically 1-2 attempts) recover from transient failures without unbounded loops.\n  The framework was evaluated on 8 benchmark tasks spanning infrastructure validation, ML capabilities, and governance stress tests. Baseline A (Prompt-Level Only) yields 100% hallucination (8/8 claimed, 0/8 verified). Baseline B (Verification-Only) reduces hallucination to 25% (2/8 fail verification). EviBound (Dual Gates) achieves 0% hallucination: 7/8 tasks verified and 1 task correctly blocked at the approval gate, all with only approximately 8.3% execution overhead.\n  This package includes execution trajectories, MLflow run IDs for all verified tasks, and a 4-step verification protocol. Research integrity is an architectural property, achieved through governance gates rather than emergent from model scale.", "AI": {"tldr": "EviBound\u662f\u4e00\u4e2a\u8bc1\u636e\u7ed1\u5b9a\u7684\u6267\u884c\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u91cd\u6cbb\u7406\u95e8\u6d88\u9664LLM\u81ea\u4e3b\u7814\u7a76\u4ee3\u7406\u7684\u9519\u8bef\u58f0\u660e\uff0c\u8981\u6c42\u673a\u5668\u53ef\u68c0\u67e5\u7684\u8bc1\u636e\u6765\u786e\u4fdd\u7814\u7a76\u5b8c\u6574\u6027\u3002", "motivation": "LLM\u81ea\u4e3b\u7814\u7a76\u4ee3\u7406\u7ecf\u5e38\u62a5\u544a\u865a\u5047\u58f0\u660e\uff0c\u5373\u4f7f\u7f3a\u5c11\u5de5\u4ef6\u3001\u5b58\u5728\u77db\u76fe\u6307\u6807\u6216\u6267\u884c\u5931\u8d25\u4e5f\u6807\u8bb0\u4e3a\"\u5b8c\u6210\"\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u79cd\u7814\u7a76\u5b8c\u6574\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u53cc\u91cd\u6cbb\u7406\u95e8\uff1a\u6267\u884c\u524d\u6279\u51c6\u95e8\u9a8c\u8bc1\u63a5\u53d7\u6807\u51c6\u6a21\u5f0f\uff0c\u6267\u884c\u540e\u9a8c\u8bc1\u95e8\u901a\u8fc7MLflow API\u67e5\u8be2\u9a8c\u8bc1\u5de5\u4ef6\u548c\u6307\u6807\u3002\u58f0\u660e\u53ea\u6709\u5728\u6709\u53ef\u67e5\u8be2\u7684\u8fd0\u884cID\u3001\u5fc5\u9700\u5de5\u4ef6\u548cFINISHED\u72b6\u6001\u65f6\u624d\u4f20\u64ad\u3002", "result": "\u57288\u4e2a\u57fa\u51c6\u4efb\u52a1\u8bc4\u4f30\u4e2d\uff0c\u57fa\u7ebfA\uff08\u4ec5\u63d0\u793a\u7ea7\u522b\uff09\u4ea7\u751f100%\u5e7b\u89c9\uff0c\u57fa\u7ebfB\uff08\u4ec5\u9a8c\u8bc1\uff09\u5c06\u5e7b\u89c9\u964d\u81f325%\uff0c\u800cEviBound\uff08\u53cc\u91cd\u95e8\uff09\u5b9e\u73b00%\u5e7b\u89c9\uff0c7/8\u4efb\u52a1\u9a8c\u8bc1\u901a\u8fc7\uff0c1\u4e2a\u4efb\u52a1\u5728\u6279\u51c6\u95e8\u6b63\u786e\u963b\u6b62\uff0c\u4ec5\u589e\u52a0\u7ea68.3%\u6267\u884c\u5f00\u9500\u3002", "conclusion": "\u7814\u7a76\u5b8c\u6574\u6027\u662f\u67b6\u6784\u5c5e\u6027\uff0c\u901a\u8fc7\u6cbb\u7406\u95e8\u800c\u975e\u6a21\u578b\u89c4\u6a21\u5b9e\u73b0\uff0cEviBound\u6846\u67b6\u6709\u6548\u6d88\u9664\u4e86LLM\u81ea\u4e3b\u7814\u7a76\u4ee3\u7406\u7684\u865a\u5047\u58f0\u660e\u95ee\u9898\u3002"}}
{"id": "2511.06003", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.06003", "abs": "https://arxiv.org/abs/2511.06003", "authors": ["Atsushi Miki", "Toshiyasu Matsushima"], "title": "Necessary and Sufficient Conditions for Capacity-Achieving Private Information Retrieval with Adversarial Servers", "comment": "17 pages", "summary": "Private information retrieval (PIR) is a mechanism for efficiently downloading messages while keeping the index of the desired message secret from the servers. PIR schemes have been extended to various scenarios with adversarial servers: PIR schemes where some servers are unresponsive or return noisy responses are called robust PIR and Byzantine PIR, respectively; PIR schemes where some servers collude to reveal the index are called colluding PIR. The information-theoretic upper bound on the download efficiency of these PIR schemes has been proved in previous studies. However, systematic ways to construct PIR schemes that achieve the upper bound are not known. In order to construct a capacity-achieving PIR schemes systematically, it is necessary to clarify the conditions that the queries should satisfy. This paper proves the necessary and sufficient conditions for capacity-achieving PIR schemes.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u5b9e\u73b0\u5bb9\u91cf\u6700\u4f18\u7684\u79c1\u6709\u4fe1\u606f\u68c0\u7d22(PIR)\u65b9\u6848\u7684\u5145\u8981\u6761\u4ef6\uff0c\u4e3a\u7cfb\u7edf\u6784\u5efa\u8fbe\u5230\u7406\u8bba\u4e0a\u754c\u7684PIR\u65b9\u6848\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u867d\u7136\u5df2\u6709\u7814\u7a76\u8bc1\u660e\u4e86\u5404\u79cdPIR\u65b9\u6848\u7684\u4fe1\u606f\u7406\u8bba\u4e0a\u754c\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6784\u5efa\u8fbe\u5230\u8fd9\u4e9b\u4e0a\u754c\u7684\u65b9\u6cd5\u3002\u4e3a\u4e86\u7cfb\u7edf\u6784\u5efa\u5bb9\u91cf\u6700\u4f18\u7684PIR\u65b9\u6848\uff0c\u9700\u8981\u660e\u786e\u67e5\u8be2\u5e94\u6ee1\u8db3\u7684\u6761\u4ef6\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u5bb9\u91cf\u6700\u4f18PIR\u65b9\u6848\u7684\u5145\u8981\u6761\u4ef6\u3002", "result": "\u660e\u786e\u4e86\u5b9e\u73b0\u5bb9\u91cf\u6700\u4f18PIR\u65b9\u6848\u6240\u9700\u7684\u67e5\u8be2\u6761\u4ef6\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7cfb\u7edf\u6784\u5efa\u8fbe\u5230\u4fe1\u606f\u7406\u8bba\u4e0a\u754c\u7684PIR\u65b9\u6848\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u6307\u5bfc\u539f\u5219\u3002"}}
{"id": "2511.06089", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.06089", "abs": "https://arxiv.org/abs/2511.06089", "authors": ["M. S. S. Manasa", "Praful D. Mankar", "Sundaram Vanka"], "title": "Capacity Analysis of Cascaded BD-RIS Assisted MIMO Systems", "comment": null, "summary": "This paper examines the cascaded deployment of beyond diagonal (BD) reconfigurable intelligent surfaces (RISs) and explores its potential to enhance the performance of MIMO systems. We first derive the jointly optimal closed form solutions for the RISs in cascade with SVD water filling (SVD WF) and uniform power allocation (UPA) precoding strategies. The optimally configured cascaded-RIS with UPA is shown to achieve performance comparable to that with the SVD WF approach, suggesting that cascaded-RISs can also aid in reducing transmitter complexity. Furthermore, the approximate ergodic capacity for UPA is derived, along with its high SNR approximation which provides multiple useful insights into the dimension and deployment of cascaded RISs. The analytical results establish a clear tradeoff among transmit power, RIS size, and achievable capacity, providing insights for practical deployment in high SNR cascaded RIS MIMO systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7ea7\u8054\u8d85\u5bf9\u89d2\u7ebf\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(BD-RIS)\u5728MIMO\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\u63d0\u5347\u6f5c\u529b\uff0c\u63a8\u5bfc\u4e86\u7ea7\u8054RIS\u4e0eSVD\u6ce8\u6c34\u6cd5\u548c\u5747\u5300\u529f\u7387\u5206\u914d\u9884\u7f16\u7801\u7b56\u7565\u7684\u6700\u4f18\u95ed\u5f0f\u89e3\uff0c\u5e76\u5206\u6790\u4e86\u8fd1\u4f3c\u904d\u5386\u5bb9\u91cf\u53ca\u5176\u9ad8\u4fe1\u566a\u6bd4\u8fd1\u4f3c\u3002", "motivation": "\u63a2\u7d22\u7ea7\u8054BD-RIS\u90e8\u7f72\u5982\u4f55\u589e\u5f3aMIMO\u7cfb\u7edf\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u53d1\u5c04\u673a\u590d\u6742\u5ea6\uff0c\u4e3a\u9ad8\u4fe1\u566a\u6bd4\u7ea7\u8054RIS MIMO\u7cfb\u7edf\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\u3002", "method": "\u63a8\u5bfc\u4e86\u7ea7\u8054RIS\u4e0eSVD\u6ce8\u6c34\u6cd5\u548c\u5747\u5300\u529f\u7387\u5206\u914d\u9884\u7f16\u7801\u7b56\u7565\u7684\u8054\u5408\u6700\u4f18\u95ed\u5f0f\u89e3\uff0c\u5206\u6790\u4e86\u8fd1\u4f3c\u904d\u5386\u5bb9\u91cf\u53ca\u5176\u9ad8\u4fe1\u566a\u6bd4\u8fd1\u4f3c\u3002", "result": "\u7ea7\u8054RIS\u4e0e\u5747\u5300\u529f\u7387\u5206\u914d\u7b56\u7565\u53ef\u5b9e\u73b0\u4e0eSVD\u6ce8\u6c34\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u53d1\u5c04\u673a\u590d\u6742\u5ea6\uff1b\u5efa\u7acb\u4e86\u53d1\u5c04\u529f\u7387\u3001RIS\u5c3a\u5bf8\u548c\u53ef\u8fbe\u5bb9\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u7ea7\u8054RIS\u4e0d\u4ec5\u63d0\u5347MIMO\u7cfb\u7edf\u6027\u80fd\uff0c\u8fd8\u80fd\u964d\u4f4e\u53d1\u5c04\u673a\u590d\u6742\u5ea6\uff0c\u4e3a\u9ad8\u4fe1\u566a\u6bd4\u7ea7\u8054RIS MIMO\u7cfb\u7edf\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u4f9d\u636e\u548c\u8bbe\u8ba1\u6307\u5bfc\u3002"}}
{"id": "2511.06001", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.06001", "abs": "https://arxiv.org/abs/2511.06001", "authors": ["Lorenzo Mario Amorosa", "Zhan Gao", "Roberto Verdone", "Petar Popovski", "Deniz G\u00fcnd\u00fcz"], "title": "Learning a Decentralized Medium Access Control Protocol for Shared Message Transmission", "comment": null, "summary": "In large-scale Internet of things networks, efficient medium access control (MAC) is critical due to the growing number of devices competing for limited communication resources. In this work, we consider a new challenge in which a set of nodes must transmit a set of shared messages to a central controller, without inter-node communication or retransmissions. Messages are distributed among random subsets of nodes, which must implicitly coordinate their transmissions over shared communication opportunities. The objective is to guarantee the delivery of all shared messages, regardless of which nodes transmit them. We first prove the optimality of deterministic strategies, and characterize the success rate degradation of a deterministic strategy under dynamic message-transmission patterns. To solve this problem, we propose a decentralized learning-based framework that enables nodes to autonomously synthesize deterministic transmission strategies aiming to maximize message delivery success, together with an online adaptation mechanism that maintains stable performance in dynamic scenarios. Extensive simulations validate the framework's effectiveness, scalability, and adaptability, demonstrating its robustness to varying network sizes and fast adaptation to dynamic changes in transmission patterns, outperforming existing multi-armed bandit approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u7269\u8054\u7f51\u7f51\u7edc\u4e2d\u8282\u70b9\u5728\u65e0\u8282\u70b9\u95f4\u901a\u4fe1\u6216\u91cd\u4f20\u7684\u60c5\u51b5\u4e0b\uff0c\u534f\u8c03\u4f20\u8f93\u5171\u4eab\u6d88\u606f\uff0c\u786e\u4fdd\u6240\u6709\u6d88\u606f\u7684\u53ef\u9760\u4f20\u9012\u3002", "motivation": "\u5927\u89c4\u6a21\u7269\u8054\u7f51\u7f51\u7edc\u4e2d\u8bbe\u5907\u6570\u91cf\u6fc0\u589e\uff0c\u6709\u9650\u7684\u901a\u4fe1\u8d44\u6e90\u9700\u8981\u9ad8\u6548\u7684\u4e2d\u4ecb\u8bbf\u95ee\u63a7\u5236\u3002\u8282\u70b9\u9700\u8981\u5728\u4e0d\u8fdb\u884c\u8282\u70b9\u95f4\u901a\u4fe1\u6216\u91cd\u4f20\u7684\u60c5\u51b5\u4e0b\uff0c\u534f\u8c03\u4f20\u8f93\u5206\u5e03\u5728\u968f\u673a\u8282\u70b9\u5b50\u96c6\u4e0a\u7684\u5171\u4eab\u6d88\u606f\u3002", "method": "\u9996\u5148\u8bc1\u660e\u4e86\u786e\u5b9a\u6027\u7b56\u7565\u7684\u6700\u4f18\u6027\uff0c\u5e76\u5206\u6790\u4e86\u52a8\u6001\u6d88\u606f\u4f20\u8f93\u6a21\u5f0f\u4e0b\u786e\u5b9a\u6027\u7b56\u7565\u7684\u6027\u80fd\u4e0b\u964d\u3002\u7136\u540e\u63d0\u51fa\u4e86\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u8282\u70b9\u80fd\u591f\u81ea\u4e3b\u5408\u6210\u786e\u5b9a\u6027\u4f20\u8f93\u7b56\u7565\u4ee5\u6700\u5927\u5316\u6d88\u606f\u4f20\u9012\u6210\u529f\u7387\uff0c\u5e76\u5305\u542b\u5728\u7ebf\u9002\u5e94\u673a\u5236\u4ee5\u5728\u52a8\u6001\u573a\u666f\u4e2d\u4fdd\u6301\u7a33\u5b9a\u6027\u80fd\u3002", "result": "\u5927\u91cf\u4eff\u771f\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u9002\u5e94\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5bf9\u4e0d\u540c\u7f51\u7edc\u89c4\u6a21\u7684\u9c81\u68d2\u6027\u4ee5\u53ca\u5bf9\u4f20\u8f93\u6a21\u5f0f\u52a8\u6001\u53d8\u5316\u7684\u5feb\u901f\u9002\u5e94\u80fd\u529b\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u591a\u81c2\u8d4c\u535a\u673a\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u7269\u8054\u7f51\u7f51\u7edc\u4e2d\u5171\u4eab\u6d88\u606f\u4f20\u8f93\u7684\u534f\u8c03\u95ee\u9898\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e0b\u4fdd\u6301\u9ad8\u6027\u80fd\uff0c\u4e3a\u5927\u89c4\u6a21\u7269\u8054\u7f51\u7f51\u7edc\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.05597", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05597", "abs": "https://arxiv.org/abs/2511.05597", "authors": ["Francisco Caravaca", "\u00c1ngel Cuevas", "Rub\u00e9n Cuevas"], "title": "From Prompts to Power: Measuring the Energy Footprint of LLM Inference", "comment": null, "summary": "The rapid expansion of Large Language Models (LLMs) has introduced unprecedented energy demands, extending beyond training to large-scale inference workloads that often dominate total lifecycle consumption. Deploying these models requires energy-intensive GPU infrastructure, and in some cases has even prompted plans to power data centers with nuclear energy. Despite this growing relevance, systematic analyses of inference energy consumption remain limited. In this work, we present a large-scale measurement-based study comprising over 32,500 measurements across 21 GPU configurations and 155 model architectures, from small open-source models to frontier systems. Using the vLLM inference engine, we quantify energy usage at the prompt level and identify how architectural and operational factors shape energy demand. Building on these insights, we develop a predictive model that accurately estimates inference energy consumption across unseen architectures and hardware, and implement it as a browser extension to raise awareness of the environmental impact of generative AI.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u6d4b\u91cf\u7814\u7a76\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u9636\u6bb5\u7684\u80fd\u8017\u95ee\u9898\uff0c\u5f00\u53d1\u4e86\u9884\u6d4b\u6a21\u578b\u6765\u4f30\u7b97\u80fd\u8017\uff0c\u5e76\u521b\u5efa\u4e86\u6d4f\u89c8\u5668\u6269\u5c55\u6765\u63d0\u9ad8\u5bf9\u751f\u6210\u5f0fAI\u73af\u5883\u5f71\u54cd\u7684\u8ba4\u77e5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u6269\u5f20\u5e26\u6765\u4e86\u524d\u6240\u672a\u6709\u7684\u80fd\u6e90\u9700\u6c42\uff0c\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u5f80\u5f80\u4e3b\u5bfc\u6574\u4e2a\u751f\u547d\u5468\u671f\u80fd\u8017\uff0c\u4f46\u7cfb\u7edf\u6027\u7684\u63a8\u7406\u80fd\u8017\u5206\u6790\u4ecd\u7136\u6709\u9650\u3002", "method": "\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u6d4b\u91cf\u7814\u7a76\uff0c\u5305\u542b\u8d85\u8fc732,500\u6b21\u6d4b\u91cf\uff0c\u6db5\u76d621\u79cdGPU\u914d\u7f6e\u548c155\u79cd\u6a21\u578b\u67b6\u6784\uff0c\u4f7f\u7528vLLM\u63a8\u7406\u5f15\u64ce\u5728\u63d0\u793a\u7ea7\u522b\u91cf\u5316\u80fd\u8017\u3002", "result": "\u8bc6\u522b\u4e86\u67b6\u6784\u548c\u64cd\u4f5c\u56e0\u7d20\u5982\u4f55\u5f71\u54cd\u80fd\u6e90\u9700\u6c42\uff0c\u5f00\u53d1\u4e86\u80fd\u591f\u51c6\u786e\u4f30\u7b97\u672a\u89c1\u67b6\u6784\u548c\u786c\u4ef6\u4e0a\u63a8\u7406\u80fd\u8017\u7684\u9884\u6d4b\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u6d4f\u89c8\u5668\u6269\u5c55\u5b9e\u65bd\u9884\u6d4b\u6a21\u578b\uff0c\u65e8\u5728\u63d0\u9ad8\u5bf9\u751f\u6210\u5f0fAI\u73af\u5883\u5f71\u54cd\u7684\u8ba4\u8bc6\uff0c\u4e3a\u89e3\u51b3LLM\u80fd\u8017\u95ee\u9898\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2511.06372", "categories": ["cs.IT", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.06372", "abs": "https://arxiv.org/abs/2511.06372", "authors": ["Saeed Razavikia", "Deniz G\u00fcnd\u00fcz", "Carlo Fischione"], "title": "Towards Optimal Constellation Design for Digital Over-the-Air Computation", "comment": null, "summary": "Over-the-air computation (OAC) has emerged as a key technique for efficient function computation over multiple-access channels (MACs) by exploiting the waveform superposition property of the wireless domain. While conventional OAC methods rely on analog amplitude modulation, their performance is often limited by noise sensitivity and hardware constraints, motivating the use of digital modulation schemes. This paper proposes a novel digital modulation framework optimized for computation over additive white Gaussian noise (AWGN) channels. The design is formulated as an additive mapping problem to determine the optimal constellation that minimizes the mean-squared error (MSE) under a transmit power constraint. We express the optimal constellation design as a system of nonlinear equations and establish the conditions guaranteeing the uniqueness of its solution. In the high signal-to-noise-ratio (SNR) regime, we derive closed-form expressions for the optimal modulation parameters using the generalized Lambert function, providing analytical insight into the system's behavior. Furthermore, we discuss extensions of the framework to higher-dimensional grids corresponding to multiple channel uses, to non-Gaussian noise models, and to computation over real-valued domains via hybrid digital-analog modulation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8eAWGN\u4fe1\u9053\u4e0a\u8ba1\u7b97\u7684\u6570\u5b57\u8c03\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u661f\u5ea7\u8bbe\u8ba1\u6765\u6700\u5c0f\u5316\u5747\u65b9\u8bef\u5dee\uff0c\u5e76\u5728\u9ad8\u4fe1\u566a\u6bd4\u4e0b\u63a8\u5bfc\u51fa\u95ed\u5f0f\u89e3\u3002", "motivation": "\u4f20\u7edf\u7a7a\u4e2d\u8ba1\u7b97\u4f9d\u8d56\u4e8e\u6a21\u62df\u5e45\u5ea6\u8c03\u5236\uff0c\u4f46\u53d7\u9650\u4e8e\u566a\u58f0\u654f\u611f\u6027\u548c\u786c\u4ef6\u7ea6\u675f\uff0c\u56e0\u6b64\u9700\u8981\u91c7\u7528\u6570\u5b57\u8c03\u5236\u65b9\u6848\u6765\u63d0\u9ad8\u6027\u80fd\u3002", "method": "\u5c06\u8bbe\u8ba1\u8868\u8ff0\u4e3a\u52a0\u6027\u6620\u5c04\u95ee\u9898\uff0c\u786e\u5b9a\u5728\u53d1\u5c04\u529f\u7387\u7ea6\u675f\u4e0b\u6700\u5c0f\u5316\u5747\u65b9\u8bef\u5dee\u7684\u6700\u4f18\u661f\u5ea7\uff0c\u5efa\u7acb\u975e\u7ebf\u6027\u65b9\u7a0b\u7ec4\u5e76\u8bc1\u660e\u89e3\u7684\u552f\u4e00\u6027\u6761\u4ef6\u3002", "result": "\u5728\u9ad8\u4fe1\u566a\u6bd4\u4e0b\uff0c\u4f7f\u7528\u5e7f\u4e49Lambert\u51fd\u6570\u63a8\u5bfc\u51fa\u6700\u4f18\u8c03\u5236\u53c2\u6570\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u4e3a\u7cfb\u7edf\u884c\u4e3a\u63d0\u4f9b\u5206\u6790\u89c1\u89e3\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u6269\u5c55\u5230\u9ad8\u7ef4\u7f51\u683c\u3001\u975e\u9ad8\u65af\u566a\u58f0\u6a21\u578b\uff0c\u4ee5\u53ca\u901a\u8fc7\u6df7\u5408\u6570\u5b57-\u6a21\u62df\u8c03\u5236\u5b9e\u73b0\u5b9e\u503c\u57df\u8ba1\u7b97\u3002"}}
{"id": "2511.07176", "categories": ["cs.NI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.07176", "abs": "https://arxiv.org/abs/2511.07176", "authors": ["Hanlin Cai", "Houtianfu Wang", "Haofan Dong", "Kai Li", "Ozgur B. Akan"], "title": "Graph Representation-based Model Poisoning on the Heterogeneous Internet of Agents", "comment": "6 pages, 6 figures", "summary": "Internet of Agents (IoA) envisions a unified, agent-centric paradigm where heterogeneous large language model (LLM) agents can interconnect and collaborate at scale. Within this paradigm, federated learning (FL) serves as a key enabler that allows distributed LLM agents to co-train global models without centralizing data. However, the FL-enabled IoA system remains vulnerable to model poisoning attacks, and the prevailing distance and similarity-based defenses become fragile at billion-parameter scale and under heterogeneous data distributions. This paper proposes a graph representation-based model poisoning (GRMP) attack, which passively exploits observed benign local models to construct a parameter correlation graph and extends an adversarial variational graph autoencoder to capture and reshape higher-order dependencies. The GRMP attack synthesizes malicious local models that preserve benign-like statistics while embedding adversarial objectives, remaining elusive to detection at the server. Experiments demonstrate a gradual drop in system accuracy under the proposed attack and the ineffectiveness of the prevailing defense mechanism in detecting the attack, underscoring a severe threat to the ambitious IoA paradigm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u8868\u793a\u7684\u6a21\u578b\u6295\u6bd2\u653b\u51fb(GRMP)\uff0c\u8be5\u653b\u51fb\u5229\u7528\u826f\u6027\u672c\u5730\u6a21\u578b\u6784\u5efa\u53c2\u6570\u76f8\u5173\u6027\u56fe\uff0c\u901a\u8fc7\u53d8\u5206\u56fe\u81ea\u7f16\u7801\u5668\u6355\u83b7\u9ad8\u9636\u4f9d\u8d56\u5173\u7cfb\uff0c\u751f\u6210\u5177\u6709\u826f\u6027\u7edf\u8ba1\u7279\u5f81\u4f46\u5305\u542b\u5bf9\u6297\u76ee\u6807\u7684\u6076\u610f\u6a21\u578b\uff0c\u80fd\u591f\u9003\u907f\u670d\u52a1\u5668\u68c0\u6d4b\u3002", "motivation": "\u5728\u8054\u90a6\u5b66\u4e60\u652f\u6301\u7684\u7269\u8054\u7f51\u4ee3\u7406\u7cfb\u7edf\u4e2d\uff0c\u73b0\u6709\u7684\u57fa\u4e8e\u8ddd\u79bb\u548c\u76f8\u4f3c\u6027\u7684\u9632\u5fa1\u673a\u5236\u5728\u5341\u4ebf\u53c2\u6570\u89c4\u6a21\u548c\u975e\u5747\u5300\u6570\u636e\u5206\u5e03\u4e0b\u53d8\u5f97\u8106\u5f31\uff0c\u7cfb\u7edf\u5bb9\u6613\u53d7\u5230\u6a21\u578b\u6295\u6bd2\u653b\u51fb\u7684\u5a01\u80c1\u3002", "method": "\u63d0\u51faGRMP\u653b\u51fb\u65b9\u6cd5\uff1a\u88ab\u52a8\u89c2\u5bdf\u826f\u6027\u672c\u5730\u6a21\u578b\u6784\u5efa\u53c2\u6570\u76f8\u5173\u6027\u56fe\uff0c\u4f7f\u7528\u5bf9\u6297\u53d8\u5206\u56fe\u81ea\u7f16\u7801\u5668\u6355\u83b7\u548c\u91cd\u5851\u9ad8\u9636\u4f9d\u8d56\u5173\u7cfb\uff0c\u5408\u6210\u5177\u6709\u826f\u6027\u7edf\u8ba1\u7279\u5f81\u4f46\u5d4c\u5165\u5bf9\u6297\u76ee\u6807\u7684\u6076\u610f\u672c\u5730\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u7cfb\u7edf\u51c6\u786e\u6027\u5728\u653b\u51fb\u4e0b\u9010\u6e10\u4e0b\u964d\uff0c\u73b0\u6709\u9632\u5fa1\u673a\u5236\u65e0\u6cd5\u6709\u6548\u68c0\u6d4b\u8be5\u653b\u51fb\uff0c\u8868\u660e\u5bf9\u7269\u8054\u7f51\u4ee3\u7406\u8303\u5f0f\u6784\u6210\u4e25\u91cd\u5a01\u80c1\u3002", "conclusion": "GRMP\u653b\u51fb\u80fd\u591f\u6709\u6548\u89c4\u907f\u73b0\u6709\u9632\u5fa1\u673a\u5236\uff0c\u7a81\u663e\u4e86\u7269\u8054\u7f51\u4ee3\u7406\u7cfb\u7edf\u4e2d\u6a21\u578b\u6295\u6bd2\u653b\u51fb\u7684\u4e25\u91cd\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u9632\u5fa1\u65b9\u6cd5\u3002"}}
{"id": "2511.05747", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05747", "abs": "https://arxiv.org/abs/2511.05747", "authors": ["Ziqian Bi", "Kaijie Chen", "Tianyang Wang", "Junfeng Hao", "Xinyuan Song"], "title": "CoT-X: An Adaptive Framework for Cross-Model Chain-of-Thought Transfer and Optimization", "comment": "TKDD 2025", "summary": "Chain-of-Thought (CoT) reasoning enhances the problem-solving ability of large language models (LLMs) but leads to substantial inference overhead, limiting deployment in resource-constrained settings. This paper investigates efficient CoT transfer across models of different scales and architectures through an adaptive reasoning summarization framework. The proposed method compresses reasoning traces via semantic segmentation with importance scoring, budget-aware dynamic compression, and coherence reconstruction, preserving critical reasoning steps while significantly reducing token usage. Experiments on 7{,}501 medical examination questions across 10 specialties show up to 40% higher accuracy than truncation under the same token budgets. Evaluations on 64 model pairs from eight LLMs (1.5B-32B parameters, including DeepSeek-R1 and Qwen3) confirm strong cross-model transferability. Furthermore, a Gaussian Process-based Bayesian optimization module reduces evaluation cost by 84% and reveals a power-law relationship between model size and cross-domain robustness. These results demonstrate that reasoning summarization provides a practical path toward efficient CoT transfer, enabling advanced reasoning under tight computational constraints. Code will be released upon publication.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u63a8\u7406\u6458\u8981\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u5206\u5272\u3001\u91cd\u8981\u6027\u8bc4\u5206\u548c\u52a8\u6001\u538b\u7f29\u6765\u538b\u7f29\u63a8\u7406\u8f68\u8ff9\uff0c\u5728\u4fdd\u6301\u5173\u952e\u63a8\u7406\u6b65\u9aa4\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11token\u4f7f\u7528\u91cf\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684CoT\u8de8\u6a21\u578b\u8fc1\u79fb\u3002", "motivation": "CoT\u63a8\u7406\u867d\u7136\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u4f46\u5e26\u6765\u4e86\u663e\u8457\u7684\u63a8\u7406\u5f00\u9500\uff0c\u9650\u5236\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u3002", "method": "\u81ea\u9002\u5e94\u63a8\u7406\u6458\u8981\u6846\u67b6\uff0c\u5305\u62ec\u8bed\u4e49\u5206\u5272\u4e0e\u91cd\u8981\u6027\u8bc4\u5206\u3001\u9884\u7b97\u611f\u77e5\u52a8\u6001\u538b\u7f29\u548c\u8fde\u8d2f\u6027\u91cd\u5efa\uff0c\u538b\u7f29\u63a8\u7406\u8f68\u8ff9\u3002", "result": "\u57287,501\u4e2a\u533b\u5b66\u8003\u8bd5\u95ee\u9898\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u5728\u76f8\u540ctoken\u9884\u7b97\u4e0b\u6bd4\u622a\u65ad\u65b9\u6cd5\u51c6\u786e\u7387\u9ad840%\uff1b\u572864\u4e2a\u6a21\u578b\u5bf9\u4e0a\u7684\u8bc4\u4f30\u8bc1\u5b9e\u4e86\u5f3a\u8de8\u6a21\u578b\u53ef\u8fc1\u79fb\u6027\uff1b\u8d1d\u53f6\u65af\u4f18\u5316\u6a21\u5757\u5c06\u8bc4\u4f30\u6210\u672c\u964d\u4f4e84%\u3002", "conclusion": "\u63a8\u7406\u6458\u8981\u4e3a\u5b9e\u73b0\u9ad8\u6548\u7684CoT\u8fc1\u79fb\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u4f7f\u5728\u4e25\u683c\u8ba1\u7b97\u7ea6\u675f\u4e0b\u8fdb\u884c\u9ad8\u7ea7\u63a8\u7406\u6210\u4e3a\u53ef\u80fd\u3002"}}
{"id": "2511.06510", "categories": ["cs.IT", "cs.ET", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06510", "abs": "https://arxiv.org/abs/2511.06510", "authors": ["Marx M. M. Freitas", "Giovanni Interdonato", "Stefano Buzzi"], "title": "Differential Space-Time Block Coding for Phase-Unsynchronized Cell-Free MIMO Downlink", "comment": "Submitted to IEEE for possible publication. This manuscript builds upon and significantly extends our prior works: https://ieeexplore.ieee.org/document/11027597/ and https://ieeexplore.ieee.org/document/11143305 | \u00a9 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses", "summary": "In the downlink of a cell-free massive multiple-input multiple-output (CF-mMIMO) system, spectral efficiency gains critically rely on joint coherent transmission, as all access points (APs) must align their transmitted signals in phase at the user equipment (UE). Achieving such phase alignment is technically challenging, as it requires tight synchronization among geographically distributed APs. In this paper, we address this issue by introducing a differential space-time block coding (DSTBC) approach that bypasses the need for AP phase synchronization. We first provide analytic bounds to the achievable spectral efficiency of CF-mMIMO with phase-unsynchronized APs. Then, we propose a DSTBC-based transmission scheme specifically tailored to CF-mMIMO, which operates without channel state information and does not require any form of phase synchronization among the APs. We derive a closed-form expression for the resulting signal-to-interference-plus-noise ratio (SINR), enabling quantitative comparisons among different DSTBC schemes. Numerical simulations confirm that phase misalignments can significantly impair system performance. In contrast, the proposed DSTBC scheme successfully mitigates these effects, achieving performance comparable to that of fully synchronized systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u5dee\u5206\u7a7a\u65f6\u5206\u7ec4\u7f16\u7801\u65b9\u6cd5\uff0c\u65e0\u9700AP\u76f8\u4f4d\u540c\u6b65\u5373\u53ef\u5b9e\u73b0\u76f8\u5e72\u4f20\u8f93\u6027\u80fd", "motivation": "\u89e3\u51b3\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2dAP\u76f8\u4f4d\u540c\u6b65\u7684\u6280\u672f\u6311\u6218\uff0c\u56e0\u4e3a\u5730\u7406\u5206\u5e03\u7684AP\u9700\u8981\u7cbe\u786e\u540c\u6b65\u624d\u80fd\u5b9e\u73b0\u8054\u5408\u76f8\u5e72\u4f20\u8f93", "method": "\u91c7\u7528\u5dee\u5206\u7a7a\u65f6\u5206\u7ec4\u7f16\u7801\u65b9\u6cd5\uff0c\u65e0\u9700\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u548cAP\u95f4\u7684\u4efb\u4f55\u76f8\u4f4d\u540c\u6b65\u5f62\u5f0f\uff0c\u63a8\u5bfc\u4e86\u4fe1\u5e72\u566a\u6bd4\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f", "result": "\u6570\u503c\u4eff\u771f\u8868\u660e\u76f8\u4f4d\u5931\u914d\u4f1a\u663e\u8457\u635f\u5bb3\u7cfb\u7edf\u6027\u80fd\uff0c\u800c\u63d0\u51fa\u7684DSTBC\u65b9\u6848\u80fd\u6709\u6548\u7f13\u89e3\u8fd9\u4e9b\u5f71\u54cd\uff0c\u6027\u80fd\u63a5\u8fd1\u5b8c\u5168\u540c\u6b65\u7cfb\u7edf", "conclusion": "DSTBC\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u76f8\u4f4d\u540c\u6b65\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4e0e\u5b8c\u5168\u540c\u6b65\u7cfb\u7edf\u76f8\u5f53\u7684\u6027\u80fd"}}
{"id": "2511.07189", "categories": ["cs.NI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.07189", "abs": "https://arxiv.org/abs/2511.07189", "authors": ["Marc Jayson Baucas", "Petros Spachos"], "title": "Improving Remote Patient Monitoring Systems Using a Fog-based IoT Platform with Speech Recognition", "comment": null, "summary": "Due to the recent shortage of resources in the healthcare industry, Remote Patient Monitoring (RPM) systems arose to establish a convenient alternative for accessing healthcare services remotely. However, as the usage of this system grows with the increase of patients and sensing devices, data and network management becomes an issue. As a result, wireless architecture challenges in patient privacy, data flow, and service interactability surface that need addressing. We propose a fog-based Internet of Things (IoT) platform to address these issues and reinforce the existing RPM system. The introduced platform can allocate resources to alleviate server overloading and provide an interactive means of monitoring patients through speech recognition. We designed a testbed to simulate and test the platform in terms of accuracy, latency, and throughput. The results show the platform's potential as a viable RPM system for sound-based healthcare services.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u96fe\u8ba1\u7b97\u7684\u7269\u8054\u7f51\u5e73\u53f0\u6765\u89e3\u51b3\u8fdc\u7a0b\u60a3\u8005\u76d1\u62a4\u7cfb\u7edf\u7684\u8d44\u6e90\u5206\u914d\u3001\u6570\u636e\u6d41\u7ba1\u7406\u548c\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u901a\u8fc7\u8bed\u97f3\u8bc6\u522b\u5b9e\u73b0\u4ea4\u4e92\u5f0f\u60a3\u8005\u76d1\u6d4b\u3002", "motivation": "\u533b\u7597\u8d44\u6e90\u77ed\u7f3a\u4fc3\u4f7f\u8fdc\u7a0b\u60a3\u8005\u76d1\u62a4\u7cfb\u7edf\u5174\u8d77\uff0c\u4f46\u968f\u7740\u60a3\u8005\u548c\u4f20\u611f\u8bbe\u5907\u589e\u52a0\uff0c\u6570\u636e\u4e0e\u7f51\u7edc\u7ba1\u7406\u6210\u4e3a\u95ee\u9898\uff0c\u9700\u8981\u89e3\u51b3\u60a3\u8005\u9690\u79c1\u3001\u6570\u636e\u6d41\u548c\u670d\u52a1\u4ea4\u4e92\u6027\u7b49\u65e0\u7ebf\u67b6\u6784\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u96fe\u8ba1\u7b97\u7684\u7269\u8054\u7f51\u5e73\u53f0\uff0c\u901a\u8fc7\u8d44\u6e90\u5206\u914d\u7f13\u89e3\u670d\u52a1\u5668\u8fc7\u8f7d\uff0c\u5229\u7528\u8bed\u97f3\u8bc6\u522b\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u60a3\u8005\u76d1\u6d4b\uff0c\u5e76\u6784\u5efa\u6d4b\u8bd5\u5e73\u53f0\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u6d4b\u8bd5\u7ed3\u679c\u663e\u793a\u8be5\u5e73\u53f0\u5728\u51c6\u786e\u6027\u3001\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u5177\u6709\u4f5c\u4e3a\u57fa\u4e8e\u58f0\u97f3\u7684\u533b\u7597\u670d\u52a1\u7684\u53ef\u884c\u8fdc\u7a0b\u60a3\u8005\u76d1\u62a4\u7cfb\u7edf\u7684\u6f5c\u529b\u3002", "conclusion": "\u57fa\u4e8e\u96fe\u8ba1\u7b97\u7684\u7269\u8054\u7f51\u5e73\u53f0\u662f\u89e3\u51b3\u8fdc\u7a0b\u60a3\u8005\u76d1\u62a4\u7cfb\u7edf\u6311\u6218\u7684\u6709\u6548\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u58f0\u97f3\u533b\u7597\u670d\u52a1\uff0c\u5c55\u793a\u4e86\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.05766", "categories": ["cs.AI", "cs.CL", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.05766", "abs": "https://arxiv.org/abs/2511.05766", "authors": ["Felipe Valencia-Clavijo"], "title": "Anchors in the Machine: Behavioral and Attributional Evidence of Anchoring Bias in LLMs", "comment": null, "summary": "Large language models (LLMs) are increasingly examined as both behavioral subjects and decision systems, yet it remains unclear whether observed cognitive biases reflect surface imitation or deeper probability shifts. Anchoring bias, a classic human judgment bias, offers a critical test case. While prior work shows LLMs exhibit anchoring, most evidence relies on surface-level outputs, leaving internal mechanisms and attributional contributions unexplored. This paper advances the study of anchoring in LLMs through three contributions: (1) a log-probability-based behavioral analysis showing that anchors shift entire output distributions, with controls for training-data contamination; (2) exact Shapley-value attribution over structured prompt fields to quantify anchor influence on model log-probabilities; and (3) a unified Anchoring Bias Sensitivity Score integrating behavioral and attributional evidence across six open-source models. Results reveal robust anchoring effects in Gemma-2B, Phi-2, and Llama-2-7B, with attribution signaling that the anchors influence reweighting. Smaller models such as GPT-2, Falcon-RW-1B, and GPT-Neo-125M show variability, suggesting scale may modulate sensitivity. Attributional effects, however, vary across prompt designs, underscoring fragility in treating LLMs as human substitutes. The findings demonstrate that anchoring bias in LLMs is robust, measurable, and interpretable, while highlighting risks in applied domains. More broadly, the framework bridges behavioral science, LLM safety, and interpretability, offering a reproducible path for evaluating other cognitive biases in LLMs.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6982\u7387\u5206\u6790\u548c\u5f52\u56e0\u65b9\u6cd5\u7cfb\u7edf\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u951a\u5b9a\u504f\u89c1\uff0c\u53d1\u73b0\u951a\u70b9\u4f1a\u6539\u53d8\u6574\u4e2a\u8f93\u51fa\u5206\u5e03\uff0c\u4e14\u6a21\u578b\u89c4\u6a21\u53ef\u80fd\u5f71\u54cd\u654f\u611f\u6027\u3002", "motivation": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8ba4\u77e5\u504f\u89c1\u662f\u8868\u9762\u6a21\u4eff\u8fd8\u662f\u6df1\u5c42\u6982\u7387\u53d8\u5316\uff0c\u951a\u5b9a\u504f\u89c1\u4f5c\u4e3a\u7ecf\u5178\u4eba\u7c7b\u5224\u65ad\u504f\u89c1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5173\u952e\u6d4b\u8bd5\u6848\u4f8b\u3002", "method": "\u4f7f\u7528\u5bf9\u6570\u6982\u7387\u884c\u4e3a\u5206\u6790\u3001\u7cbe\u786eShapley\u503c\u5f52\u56e0\u548c\u7edf\u4e00\u7684\u951a\u5b9a\u504f\u89c1\u654f\u611f\u5ea6\u8bc4\u5206\uff0c\u5728\u516d\u4e2a\u5f00\u6e90\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "Gemma-2B\u3001Phi-2\u548cLlama-2-7B\u8868\u73b0\u51fa\u7a33\u5065\u7684\u951a\u5b9a\u6548\u5e94\uff0c\u800cGPT-2\u3001Falcon-RW-1B\u548cGPT-Neo-125M\u7b49\u8f83\u5c0f\u6a21\u578b\u663e\u793a\u51fa\u53d8\u5f02\u6027\uff0c\u8868\u660e\u89c4\u6a21\u53ef\u80fd\u8c03\u8282\u654f\u611f\u6027\u3002", "conclusion": "LLM\u4e2d\u7684\u951a\u5b9a\u504f\u89c1\u662f\u7a33\u5065\u3001\u53ef\u6d4b\u91cf\u548c\u53ef\u89e3\u91ca\u7684\uff0c\u4f46\u5f52\u56e0\u6548\u5e94\u56e0\u63d0\u793a\u8bbe\u8ba1\u800c\u5f02\uff0c\u7a81\u663e\u4e86\u5c06LLM\u89c6\u4e3a\u4eba\u7c7b\u66ff\u4ee3\u54c1\u7684\u8106\u5f31\u6027\u3002"}}
{"id": "2511.06591", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.06591", "abs": "https://arxiv.org/abs/2511.06591", "authors": ["Ittetsu Uchiyama", "Chihiro Tsutake", "Keita Takahashi", "Toshiaki Fujii"], "title": "Events Meet Phase-Shifting Digital Holography: Practical Acquisition, Theory, and Algorithms", "comment": null, "summary": "We introduce a novel phase-shifting digital holography (PSDH) method leveraging a hybrid event-based vision sensor (EVS). The key idea of our method is the phase shift during a single exposure. The hybrid EVS records a hologram blurred by the phase shift, together with the events corresponding to blur variations. We present analytical and optimization-based methods that theoretically support the reconstruction of full-complex wavefronts from the blurred hologram and events. The experimental results demonstrate that our method achieves a reconstruction quality comparable to that of a conventional PSDH method while enhancing the acquisition efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u4e8b\u4ef6\u89c6\u89c9\u4f20\u611f\u5668\u7684\u76f8\u4f4d\u79fb\u52a8\u6570\u5b57\u5168\u606f\u672f\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u5355\u6b21\u66dd\u5149\u671f\u95f4\u8fdb\u884c\u76f8\u4f4d\u79fb\u52a8\uff0c\u7ed3\u5408\u6a21\u7cca\u5168\u606f\u56fe\u548c\u4e8b\u4ef6\u6570\u636e\u91cd\u5efa\u5b8c\u6574\u590d\u6ce2\u524d\u3002", "motivation": "\u4f20\u7edf\u76f8\u4f4d\u79fb\u52a8\u6570\u5b57\u5168\u606f\u672f\u9700\u8981\u591a\u6b21\u66dd\u5149\uff0c\u6548\u7387\u8f83\u4f4e\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6df7\u5408\u4e8b\u4ef6\u89c6\u89c9\u4f20\u611f\u5668\u5728\u5355\u6b21\u66dd\u5149\u4e2d\u5b9e\u73b0\u76f8\u4f4d\u79fb\u52a8\uff0c\u63d0\u9ad8\u91c7\u96c6\u6548\u7387\u3002", "method": "\u4f7f\u7528\u6df7\u5408\u4e8b\u4ef6\u89c6\u89c9\u4f20\u611f\u5668\u8bb0\u5f55\u76f8\u4f4d\u79fb\u52a8\u5bfc\u81f4\u7684\u6a21\u7cca\u5168\u606f\u56fe\u4ee5\u53ca\u5bf9\u5e94\u7684\u6a21\u7cca\u53d8\u5316\u4e8b\u4ef6\uff0c\u63d0\u51fa\u89e3\u6790\u548c\u4f18\u5316\u4e24\u79cd\u65b9\u6cd5\u6765\u91cd\u5efa\u5b8c\u6574\u590d\u6ce2\u524d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u91cd\u5efa\u8d28\u91cf\u4e0a\u4e0e\u4f20\u7edf\u76f8\u4f4d\u79fb\u52a8\u6570\u5b57\u5168\u606f\u672f\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u91c7\u96c6\u6548\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u5728\u5355\u6b21\u66dd\u5149\u4e2d\u5b8c\u6210\u76f8\u4f4d\u79fb\u52a8\u6570\u5b57\u5168\u606f\u672f\uff0c\u4e3a\u9ad8\u6548\u5168\u606f\u6210\u50cf\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.07265", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.07265", "abs": "https://arxiv.org/abs/2511.07265", "authors": ["Gamal Refai-Ahmed", "Mallik Tatipamula", "Victor Zhirnov", "Ahmed Refaey Hussein", "Abdallah Shami"], "title": "When Intelligence Overloads Infrastructure: A Forecast Model for AI-Driven Bottlenecks", "comment": null, "summary": "The exponential growth of AI agents and connected devices fundamentally transforms the structure and capacity demands of global digital infrastructure. This paper introduces a unified forecasting model that projects AI agent populations to increase by more than 100 times between 2026 and 2036+, reaching trillions of instances globally. In parallel, bandwidth demand is expected to surge from 1 EB/day in 2026 to over 8,000 EB/day by 2036, which is an increase of 8000 times in a single decade. Through this growth model, we identify critical bottleneck domains across access networks, edge gateways, interconnection exchanges, and cloud infrastructures. Simulations reveal that edge and peering systems will experience saturation as early as 2030, with more than 70% utilization of projected maximum capacity by 2033. To address these constraints, we propose a coevolutionary shift in compute-network design, emphasizing distributed inference, AI-native traffic engineering, and intent-aware orchestration. Security, scalability, and coordination challenges are examined with a focus on sustaining intelligent connectivity throughout the next digital decade.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9884\u6d4bAI\u667a\u80fd\u4f53\u548c\u8fde\u63a5\u8bbe\u5907\u5c06\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u52302036\u5e74\u5c06\u8fbe\u5230\u6570\u4e07\u4ebf\u5b9e\u4f8b\uff0c\u5e26\u5bbd\u9700\u6c42\u5c06\u5728\u5341\u5e74\u5185\u589e\u957f8000\u500d\uff0c\u5bfc\u81f4\u8fb9\u7f18\u548c\u4e92\u8054\u7cfb\u7edf\u57282030\u5e74\u51fa\u73b0\u9971\u548c\u3002", "motivation": "AI\u667a\u80fd\u4f53\u548c\u8fde\u63a5\u8bbe\u5907\u7684\u7206\u70b8\u5f0f\u589e\u957f\u6b63\u5728\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u5168\u7403\u6570\u5b57\u57fa\u7840\u8bbe\u65bd\u7684\u7ed3\u6784\u548c\u5bb9\u91cf\u9700\u6c42\uff0c\u9700\u8981\u9884\u6d4b\u548c\u89e3\u51b3\u5373\u5c06\u51fa\u73b0\u7684\u74f6\u9888\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u6a21\u62df\u5206\u6790\u8bc6\u522b\u5173\u952e\u74f6\u9888\u9886\u57df\uff0c\u5305\u62ec\u63a5\u5165\u7f51\u7edc\u3001\u8fb9\u7f18\u7f51\u5173\u3001\u4e92\u8054\u4ea4\u6362\u548c\u4e91\u57fa\u7840\u8bbe\u65bd\u3002", "result": "\u9884\u6d4b\u663e\u793aAI\u667a\u80fd\u4f53\u6570\u91cf\u5c06\u57282026-2036\u5e74\u95f4\u589e\u957f100\u500d\u4ee5\u4e0a\uff0c\u5e26\u5bbd\u9700\u6c42\u4ece1EB/\u5929\u589e\u81f38000EB/\u5929\uff0c\u8fb9\u7f18\u548c\u4e92\u8054\u7cfb\u7edf\u5c06\u57282030\u5e74\u8fbe\u5230\u9971\u548c\uff0c2033\u5e74\u5229\u7528\u7387\u8d85\u8fc770%\u3002", "conclusion": "\u9700\u8981\u8ba1\u7b97\u7f51\u7edc\u8bbe\u8ba1\u7684\u534f\u540c\u8fdb\u5316\u8f6c\u53d8\uff0c\u5f3a\u8c03\u5206\u5e03\u5f0f\u63a8\u7406\u3001AI\u539f\u751f\u6d41\u91cf\u5de5\u7a0b\u548c\u610f\u56fe\u611f\u77e5\u7f16\u6392\uff0c\u4ee5\u5e94\u5bf9\u5b89\u5168\u3001\u53ef\u6269\u5c55\u6027\u548c\u534f\u8c03\u6027\u6311\u6218\u3002"}}
{"id": "2511.05810", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05810", "abs": "https://arxiv.org/abs/2511.05810", "authors": ["Bowen Xu", "Xinyue Zeng", "Jiazhen Hu", "Tuo Wang", "Adithya Kulkarni"], "title": "DiagnoLLM: A Hybrid Bayesian Neural Language Framework for Interpretable Disease Diagnosis", "comment": null, "summary": "Building trustworthy clinical AI systems requires not only accurate predictions but also transparent, biologically grounded explanations. We present \\texttt{DiagnoLLM}, a hybrid framework that integrates Bayesian deconvolution, eQTL-guided deep learning, and LLM-based narrative generation for interpretable disease diagnosis. DiagnoLLM begins with GP-unmix, a Gaussian Process-based hierarchical model that infers cell-type-specific gene expression profiles from bulk and single-cell RNA-seq data while modeling biological uncertainty. These features, combined with regulatory priors from eQTL analysis, power a neural classifier that achieves high predictive performance in Alzheimer's Disease (AD) detection (88.0\\% accuracy). To support human understanding and trust, we introduce an LLM-based reasoning module that translates model outputs into audience-specific diagnostic reports, grounded in clinical features, attribution signals, and domain knowledge. Human evaluations confirm that these reports are accurate, actionable, and appropriately tailored for both physicians and patients. Our findings show that LLMs, when deployed as post-hoc reasoners rather than end-to-end predictors, can serve as effective communicators within hybrid diagnostic pipelines.", "AI": {"tldr": "DiagnoLLM\u662f\u4e00\u4e2a\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u53cd\u5377\u79ef\u3001eQTL\u5f15\u5bfc\u7684\u6df1\u5ea6\u5b66\u4e60\u548cLLM\u53d9\u4e8b\u751f\u6210\uff0c\u7528\u4e8e\u53ef\u89e3\u91ca\u7684\u75be\u75c5\u8bca\u65ad\uff0c\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u68c0\u6d4b\u4e2d\u8fbe\u523088.0%\u51c6\u786e\u7387\u3002", "motivation": "\u6784\u5efa\u503c\u5f97\u4fe1\u8d56\u7684\u4e34\u5e8aAI\u7cfb\u7edf\u9700\u8981\u4e0d\u4ec5\u51c6\u786e\u7684\u9884\u6d4b\uff0c\u8fd8\u9700\u8981\u900f\u660e\u3001\u57fa\u4e8e\u751f\u7269\u5b66\u7684\u89e3\u91ca\u3002", "method": "\u4f7f\u7528GP-unmix\u9ad8\u65af\u8fc7\u7a0b\u5206\u5c42\u6a21\u578b\u4ecebulk\u548c\u5355\u7ec6\u80deRNA-seq\u6570\u636e\u63a8\u65ad\u7ec6\u80de\u7c7b\u578b\u7279\u5f02\u6027\u57fa\u56e0\u8868\u8fbe\u8c31\uff0c\u7ed3\u5408eQTL\u5206\u6790\u7684\u8c03\u63a7\u5148\u9a8c\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u5668\uff0c\u6700\u540e\u901a\u8fc7LLM\u6a21\u5757\u751f\u6210\u9762\u5411\u4e0d\u540c\u53d7\u4f17\u7684\u8bca\u65ad\u62a5\u544a\u3002", "result": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe\u523088.0%\uff0c\u4eba\u7c7b\u8bc4\u4f30\u786e\u8ba4\u751f\u6210\u7684\u62a5\u544a\u51c6\u786e\u3001\u53ef\u64cd\u4f5c\u4e14\u9002\u5408\u533b\u751f\u548c\u60a3\u8005\u3002", "conclusion": "LLM\u4f5c\u4e3a\u540e\u5904\u7406\u63a8\u7406\u5668\u800c\u975e\u7aef\u5230\u7aef\u9884\u6d4b\u5668\u65f6\uff0c\u53ef\u4ee5\u5728\u6df7\u5408\u8bca\u65ad\u6d41\u7a0b\u4e2d\u4f5c\u4e3a\u6709\u6548\u7684\u6c9f\u901a\u5de5\u5177\u3002"}}
{"id": "2511.06795", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.06795", "abs": "https://arxiv.org/abs/2511.06795", "authors": ["Neil D. Lawrence"], "title": "The Inaccessible Game", "comment": null, "summary": "In this paper we introduce the inaccessible game, an information-theoretic dynamical system constructed from four axioms. The first three axioms are known and define \\emph{information loss} in the system. The fourth is a novel \\emph{information isolation} axiom that assumes our system is isolated from observation, making it observer-independent and exchangeable. Under this isolation axiom, total marginal entropy is conserved: $\\sum_i h_i = C$. We consider maximum entropy production in the game and show that the dynamics exhibit a GENERIC-like structure combining reversible and irreversible components.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u56db\u4e2a\u516c\u7406\u6784\u5efa\u7684\u4fe1\u606f\u8bba\u52a8\u6001\u7cfb\u7edf\u2014\u2014\u4e0d\u53ef\u8bbf\u95ee\u6e38\u620f\u3002\u524d\u4e09\u4e2a\u516c\u7406\u5b9a\u4e49\u4e86\u4fe1\u606f\u635f\u5931\uff0c\u7b2c\u56db\u4e2a\u65b0\u9896\u7684\u4fe1\u606f\u9694\u79bb\u516c\u7406\u4f7f\u7cfb\u7edf\u72ec\u7acb\u4e8e\u89c2\u5bdf\u8005\u4e14\u53ef\u4ea4\u6362\uff0c\u5bfc\u81f4\u603b\u8fb9\u9645\u71b5\u5b88\u6052\u3002\u7cfb\u7edf\u5728\u6700\u5927\u71b5\u4ea7\u751f\u6761\u4ef6\u4e0b\u5c55\u73b0\u51fa\u7c7b\u4f3cGENERIC\u7684\u7ed3\u6784\u3002", "motivation": "\u6784\u5efa\u4e00\u4e2a\u4fe1\u606f\u8bba\u52a8\u6001\u7cfb\u7edf\uff0c\u901a\u8fc7\u5f15\u5165\u4fe1\u606f\u9694\u79bb\u516c\u7406\u6765\u521b\u5efa\u89c2\u5bdf\u8005\u72ec\u7acb\u4e14\u53ef\u4ea4\u6362\u7684\u7cfb\u7edf\uff0c\u7814\u7a76\u5728\u6700\u5927\u71b5\u4ea7\u751f\u6761\u4ef6\u4e0b\u7684\u52a8\u529b\u5b66\u884c\u4e3a\u3002", "method": "\u57fa\u4e8e\u56db\u4e2a\u516c\u7406\u6784\u5efa\u4fe1\u606f\u8bba\u52a8\u6001\u7cfb\u7edf\uff1a\u524d\u4e09\u4e2a\u516c\u7406\u5b9a\u4e49\u4fe1\u606f\u635f\u5931\uff0c\u7b2c\u56db\u4e2a\u4fe1\u606f\u9694\u79bb\u516c\u7406\u786e\u4fdd\u7cfb\u7edf\u72ec\u7acb\u4e8e\u89c2\u5bdf\u3002\u5206\u6790\u7cfb\u7edf\u5728\u6700\u5927\u71b5\u4ea7\u751f\u6761\u4ef6\u4e0b\u7684\u52a8\u529b\u5b66\u7ed3\u6784\u3002", "result": "\u5728\u4fe1\u606f\u9694\u79bb\u516c\u7406\u4e0b\uff0c\u603b\u8fb9\u9645\u71b5\u5b88\u6052\uff08\u2211hi = C\uff09\u3002\u7cfb\u7edf\u5728\u6700\u5927\u71b5\u4ea7\u751f\u6761\u4ef6\u4e0b\u5c55\u73b0\u51fa\u7c7b\u4f3cGENERIC\u7684\u7ed3\u6784\uff0c\u7ed3\u5408\u4e86\u53ef\u9006\u548c\u4e0d\u53ef\u9006\u5206\u91cf\u3002", "conclusion": "\u4e0d\u53ef\u8bbf\u95ee\u6e38\u620f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u5176\u4e2d\u4fe1\u606f\u9694\u79bb\u5bfc\u81f4\u71b5\u5b88\u6052\uff0c\u5e76\u5728\u6700\u5927\u71b5\u4ea7\u751f\u6761\u4ef6\u4e0b\u4ea7\u751f\u5177\u6709\u53ef\u9006\u548c\u4e0d\u53ef\u9006\u5206\u91cf\u7684GENERIC-like\u52a8\u529b\u5b66\u7ed3\u6784\u3002"}}
{"id": "2511.07366", "categories": ["cs.NI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07366", "abs": "https://arxiv.org/abs/2511.07366", "authors": ["Dao Lan Vy Dinh", "Anh Nguyen Thi Mai", "Hung Tran", "Giang Quynh Le Vu", "Tu Dac Ho", "Zhenni Pan", "Vo Nhan Van", "Symeon Chatzinotas", "Dinh-Hieu Tran"], "title": "UAV-Assisted Resilience in 6G and Beyond Network Energy Saving: A Multi-Agent DRL Approach", "comment": "6 pages, 5 figures, 1 table", "summary": "This paper investigates the unmanned aerial vehicle (UAV)-assisted resilience perspective in the 6G network energy saving (NES) scenario. More specifically, we consider multiple ground base stations (GBSs) and each GBS has three different sectors/cells in the terrestrial networks, and multiple cells are turned off due to NES or incidents, e.g., disasters, hardware failures, or outages. To address this, we propose a Multi-Agent Deep Deterministic Policy Gradient (MADDPG) framework to enable UAV-assisted communication by jointly optimizing UAV trajectories, transmission power, and user-UAV association under a sleeping ground base station (GBS) strategy. This framework aims to ensure the resilience of active users in the network and the long-term operability of UAVs. Specifically, it maximizes service coverage for users during power outages or NES zones, while minimizing the energy consumption of UAVs. Simulation results demonstrate that the proposed MADDPG policy consistently achieves high coverage ratio across different testing episodes, outperforming other baselines. Moreover, the MADDPG framework attains the lowest total energy consumption, with a reduction of approximately 24\\% compared to the conventional all GBS ON configuration, while maintaining a comparable user service rate. These results confirm the effectiveness of the proposed approach in achieving a superior trade-off between energy efficiency and service performance, supporting the development of sustainable and resilient UAV-assisted cellular networks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eMADDPG\u7684\u65e0\u4eba\u673a\u8f85\u52a9\u901a\u4fe1\u6846\u67b6\uff0c\u57286G\u7f51\u7edc\u8282\u80fd\u573a\u666f\u4e0b\u8054\u5408\u4f18\u5316\u65e0\u4eba\u673a\u8f68\u8ff9\u3001\u4f20\u8f93\u529f\u7387\u548c\u7528\u6237\u5173\u8054\uff0c\u5b9e\u73b0\u9ad8\u8986\u76d6\u7387\u548c\u4f4e\u80fd\u8017\u3002", "motivation": "\u89e3\u51b3\u5730\u9762\u57fa\u7ad9\u56e0\u8282\u80fd\u6216\u6545\u969c\u5173\u95ed\u65f6\u7f51\u7edc\u8986\u76d6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u786e\u4fdd\u7f51\u7edc\u97e7\u6027\u548c\u65e0\u4eba\u673a\u957f\u671f\u8fd0\u884c\u80fd\u529b\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6(MADDPG)\u6846\u67b6\uff0c\u8054\u5408\u4f18\u5316\u65e0\u4eba\u673a\u8f68\u8ff9\u3001\u4f20\u8f93\u529f\u7387\u548c\u7528\u6237-\u65e0\u4eba\u673a\u5173\u8054\u7b56\u7565\u3002", "result": "MADDPG\u7b56\u7565\u5728\u4e0d\u540c\u6d4b\u8bd5\u573a\u666f\u4e0b\u5747\u5b9e\u73b0\u9ad8\u8986\u76d6\u7387\uff0c\u603b\u80fd\u8017\u6bd4\u5168\u57fa\u7ad9\u5f00\u542f\u914d\u7f6e\u964d\u4f4e\u7ea624%\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u6bd4\u8f83\u7684\u7528\u6237\u670d\u52a1\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u80fd\u6548\u548c\u670d\u52a1\u6027\u80fd\u4e4b\u95f4\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u6743\u8861\uff0c\u652f\u6301\u53ef\u6301\u7eed\u548c\u97e7\u6027\u7684\u65e0\u4eba\u673a\u8f85\u52a9\u8702\u7a9d\u7f51\u7edc\u53d1\u5c55\u3002"}}
{"id": "2511.05854", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05854", "abs": "https://arxiv.org/abs/2511.05854", "authors": ["Zepeng Bao", "Shen Zhou", "Qiankun Pi", "Jianhao Chen", "Mayi Xu", "Ming Zhong", "Yuanyuan Zhu", "Tieyun Qian"], "title": "Can a Small Model Learn to Look Before It Leaps? Dynamic Learning and Proactive Correction for Hallucination Detection", "comment": null, "summary": "Hallucination in large language models (LLMs) remains a critical barrier to their safe deployment. Existing tool-augmented hallucination detection methods require pre-defined fixed verification strategies, which are crucial to the quality and effectiveness of tool calls. Some methods directly employ powerful closed-source LLMs such as GPT-4 as detectors, which are effective but too costly. To mitigate the cost issue, some methods adopt the teacher-student architecture and finetune open-source small models as detectors via agent tuning. However, these methods are limited by fixed strategies. When faced with a dynamically changing execution environment, they may lack adaptability and inappropriately call tools, ultimately leading to detection failure. To address the problem of insufficient strategy adaptability, we propose the innovative ``Learning to Evaluate and Adaptively Plan''(LEAP) framework, which endows an efficient student model with the dynamic learning and proactive correction capabilities of the teacher model. Specifically, our method formulates the hallucination detection problem as a dynamic strategy learning problem. We first employ a teacher model to generate trajectories within the dynamic learning loop and dynamically adjust the strategy based on execution failures. We then distill this dynamic planning capability into an efficient student model via agent tuning. Finally, during strategy execution, the student model adopts a proactive correction mechanism, enabling it to propose, review, and optimize its own verification strategies before execution. We demonstrate through experiments on three challenging benchmarks that our LEAP-tuned model outperforms existing state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51faLEAP\u6846\u67b6\u89e3\u51b3LLM\u5e7b\u89c9\u68c0\u6d4b\u4e2d\u56fa\u5b9a\u7b56\u7565\u7f3a\u4e4f\u9002\u5e94\u6027\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u5b66\u4e60\u5faa\u73af\u548c\u4e3b\u52a8\u4fee\u6b63\u673a\u5236\uff0c\u8ba9\u9ad8\u6548\u5b66\u751f\u6a21\u578b\u5177\u5907\u52a8\u6001\u89c4\u5212\u548c\u7b56\u7565\u4f18\u5316\u80fd\u529b", "motivation": "\u73b0\u6709\u5de5\u5177\u589e\u5f3a\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u4f7f\u7528\u9884\u5b9a\u4e49\u7684\u56fa\u5b9a\u9a8c\u8bc1\u7b56\u7565\uff0c\u5728\u52a8\u6001\u53d8\u5316\u73af\u5883\u4e2d\u7f3a\u4e4f\u9002\u5e94\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u68c0\u6d4b\u5931\u8d25\u3002\u76f4\u63a5\u4f7f\u7528GPT-4\u7b49\u5927\u6a21\u578b\u6210\u672c\u8fc7\u9ad8\uff0c\u800c\u6559\u5e08-\u5b66\u751f\u67b6\u6784\u7684\u65b9\u6cd5\u53c8\u53d7\u9650\u4e8e\u56fa\u5b9a\u7b56\u7565", "method": "\u5c06\u5e7b\u89c9\u68c0\u6d4b\u95ee\u9898\u5efa\u6a21\u4e3a\u52a8\u6001\u7b56\u7565\u5b66\u4e60\u95ee\u9898\uff0c\u9996\u5148\u7528\u6559\u5e08\u6a21\u578b\u5728\u52a8\u6001\u5b66\u4e60\u5faa\u73af\u4e2d\u751f\u6210\u8f68\u8ff9\u5e76\u6839\u636e\u6267\u884c\u5931\u8d25\u8c03\u6574\u7b56\u7565\uff0c\u7136\u540e\u901a\u8fc7\u667a\u80fd\u4f53\u8c03\u4f18\u5c06\u52a8\u6001\u89c4\u5212\u80fd\u529b\u84b8\u998f\u5230\u9ad8\u6548\u5b66\u751f\u6a21\u578b\u4e2d\uff0c\u6700\u540e\u5b66\u751f\u6a21\u578b\u5728\u6267\u884c\u65f6\u91c7\u7528\u4e3b\u52a8\u4fee\u6b63\u673a\u5236\u6765\u63d0\u51fa\u3001\u5ba1\u67e5\u548c\u4f18\u5316\u9a8c\u8bc1\u7b56\u7565", "result": "\u5728\u4e09\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLEAP\u8c03\u4f18\u7684\u6a21\u578b\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u65b9\u6cd5", "conclusion": "LEAP\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5e7b\u89c9\u68c0\u6d4b\u4e2d\u7b56\u7565\u9002\u5e94\u6027\u95ee\u9898\uff0c\u8d4b\u4e88\u9ad8\u6548\u5b66\u751f\u6a21\u578b\u52a8\u6001\u5b66\u4e60\u548c\u4e3b\u52a8\u4fee\u6b63\u80fd\u529b\uff0c\u5728\u4fdd\u6301\u4f4e\u6210\u672c\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u68c0\u6d4b\u6027\u80fd"}}
{"id": "2511.06843", "categories": ["cs.IT", "math.AC", "math.AG"], "pdf": "https://arxiv.org/pdf/2511.06843", "abs": "https://arxiv.org/abs/2511.06843", "authors": ["Martin Kreuzer"], "title": "Code Equivalence, Point Set Equivalence, and Polynomial Isomorphism", "comment": "25 pages", "summary": "The linear code equivalence (LCE) problem is shown to be equivalent to the point set equivalence (PSE) problem, i.e., the problem to check whether two sets of points in a projective space over a finite field differ by a linear change of coordinates. For such a point set $\\mathbb{X}$, let $R$ be its homogeneous coordinate ring and $\\mathfrak{J}_{\\mathbb{X}}$ its canonical ideal. Then the LCE problem is shown to be equivalent to an algebra isomorphism problem for the doubling $R/\\mathfrak{J}_{\\mathbb{X}}$. As this doubling is an Artinian Gorenstein algebra, we can use its Macaulay inverse system to reduce the LCE problem to a Polynomial Isomorphism (PI) problem for homogeneous polynomials. The last step is polynomial time under some mild assumptions about the codes. Moreover, for indecomposable iso-dual codes we can reduce the LCE search problem to the PI search problem of degree 3 by noting that the corresponding point sets are self-associated and arithmetically Gorenstein, so that we can use the isomorphism problem for the Artinian reductions of the coordinate rings and form their Macaulay inverse systems.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u7ebf\u6027\u7801\u7b49\u4ef7\u95ee\u9898\u4e0e\u70b9\u96c6\u7b49\u4ef7\u95ee\u9898\u7b49\u4ef7\uff0c\u5e76\u901a\u8fc7\u4ee3\u6570\u65b9\u6cd5\u5c06\u5176\u8f6c\u5316\u4e3a\u591a\u9879\u5f0f\u540c\u6784\u95ee\u9898\uff0c\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u53ef\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u89e3\u51b3\u3002", "motivation": "\u7814\u7a76\u7ebf\u6027\u7801\u7b49\u4ef7\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u5bfb\u627e\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6cd5\u3002", "method": "\u5c06\u7ebf\u6027\u7801\u7b49\u4ef7\u95ee\u9898\u8f6c\u5316\u4e3a\u70b9\u96c6\u7b49\u4ef7\u95ee\u9898\uff0c\u7136\u540e\u901a\u8fc7\u9f50\u6b21\u5750\u6807\u73af\u548c\u5178\u8303\u7406\u60f3\u6784\u9020Artinian Gorenstein\u4ee3\u6570\uff0c\u5229\u7528Macaulay\u9006\u7cfb\u7edf\u8fdb\u4e00\u6b65\u8f6c\u5316\u4e3a\u591a\u9879\u5f0f\u540c\u6784\u95ee\u9898\u3002", "result": "\u8bc1\u660e\u4e86\u7ebf\u6027\u7801\u7b49\u4ef7\u95ee\u9898\u4e0e\u70b9\u96c6\u7b49\u4ef7\u95ee\u9898\u7b49\u4ef7\uff0c\u5e76\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\u53ef\u591a\u9879\u5f0f\u65f6\u95f4\u6c42\u89e3\u3002\u5bf9\u4e8e\u4e0d\u53ef\u5206\u89e3\u7684iso-dual\u7801\uff0c\u53ef\u8fdb\u4e00\u6b65\u7b80\u5316\u4e3a3\u6b21\u591a\u9879\u5f0f\u540c\u6784\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u4ee3\u6570\u51e0\u4f55\u65b9\u6cd5\u4e3a\u7ebf\u6027\u7801\u7b49\u4ef7\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u6846\u67b6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2511.05874", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05874", "abs": "https://arxiv.org/abs/2511.05874", "authors": ["Haoran Xue", "Gias Uddin", "Song Wang"], "title": "An Empirical Study of Reasoning Steps in Thinking Code LLMs", "comment": null, "summary": "Thinking Large Language Models (LLMs) generate explicit intermediate reasoning traces before final answers, potentially improving transparency, interpretability, and solution accuracy for code generation. However, the quality of these reasoning chains remains underexplored. We present a comprehensive empirical study examining the reasoning process and quality of thinking LLMs for code generation. We evaluate six state-of-the-art reasoning LLMs (DeepSeek-R1, OpenAI-o3-mini, Claude-3.7-Sonnet-Thinking, Gemini-2.0-Flash-Thinking, Gemini-2.5-Flash, and Qwen-QwQ) across 100 code generation tasks of varying difficulty from BigCodeBench. We quantify reasoning-chain structure through step counts and verbosity, conduct controlled step-budget adjustments, and perform a 21-participant human evaluation across three dimensions: efficiency, logical correctness, and completeness. Our step-count interventions reveal that targeted step increases can improve resolution rates for certain models/tasks, while modest reductions often preserve success on standard tasks, rarely on hard ones. Through systematic analysis, we develop a reasoning-problematic taxonomy, identifying completeness as the dominant failure mode. Task complexity significantly impacts reasoning quality; hard problems are substantially more prone to incompleteness than standard tasks. Our stability analysis demonstrates that thinking LLMs maintain consistent logical structures across computational effort levels and can self-correct previous errors. This study provides new insights into the strengths and limitations of current thinking LLMs in software engineering.", "AI": {"tldr": "\u5bf96\u79cd\u601d\u8003\u578b\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u8fc7\u7a0b\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u63a8\u7406\u94fe\u8d28\u91cf\u53d7\u4efb\u52a1\u590d\u6742\u5ea6\u5f71\u54cd\uff0c\u5b8c\u6574\u6027\u662f\u4e3b\u8981\u5931\u8d25\u6a21\u5f0f\uff0c\u4f46\u6a21\u578b\u80fd\u4fdd\u6301\u903b\u8f91\u7ed3\u6784\u4e00\u81f4\u6027\u5e76\u81ea\u6211\u7ea0\u9519\u3002", "motivation": "\u63a2\u7d22\u601d\u8003\u578bLLMs\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u751f\u6210\u663e\u5f0f\u4e2d\u95f4\u63a8\u7406\u94fe\u7684\u8d28\u91cf\uff0c\u8fd9\u4e9b\u63a8\u7406\u94fe\u867d\u7136\u53ef\u80fd\u63d0\u9ad8\u900f\u660e\u5ea6\u548c\u51c6\u786e\u6027\uff0c\u4f46\u5176\u8d28\u91cf\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u8bc4\u4f306\u79cd\u6700\u5148\u8fdb\u7684\u63a8\u7406LLMs\u5728100\u4e2a\u4e0d\u540c\u96be\u5ea6\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u6b65\u9aa4\u8ba1\u6570\u548c\u5197\u957f\u5ea6\u91cf\u5316\u63a8\u7406\u94fe\u7ed3\u6784\uff0c\u8fdb\u884c\u53d7\u63a7\u6b65\u9aa4\u9884\u7b97\u8c03\u6574\uff0c\u5e76\u5f00\u5c5521\u4eba\u53c2\u4e0e\u7684\u4eba\u5de5\u8bc4\u4f30\u3002", "result": "\u9488\u5bf9\u6027\u589e\u52a0\u6b65\u9aa4\u53ef\u63d0\u9ad8\u67d0\u4e9b\u6a21\u578b/\u4efb\u52a1\u7684\u89e3\u51b3\u7387\uff0c\u9002\u5ea6\u51cf\u5c11\u6b65\u9aa4\u5728\u6807\u51c6\u4efb\u52a1\u4e0a\u901a\u5e38\u80fd\u4fdd\u6301\u6210\u529f\u4f46\u5728\u56f0\u96be\u4efb\u52a1\u4e0a\u5f88\u5c11\u80fd\u6210\u529f\u3002\u4efb\u52a1\u590d\u6742\u5ea6\u663e\u8457\u5f71\u54cd\u63a8\u7406\u8d28\u91cf\uff0c\u56f0\u96be\u95ee\u9898\u66f4\u5bb9\u6613\u51fa\u73b0\u4e0d\u5b8c\u6574\u6027\u3002", "conclusion": "\u601d\u8003\u578bLLMs\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5177\u6709\u4fdd\u6301\u903b\u8f91\u7ed3\u6784\u4e00\u81f4\u6027\u548c\u81ea\u6211\u7ea0\u9519\u7684\u80fd\u529b\uff0c\u4f46\u63a8\u7406\u8d28\u91cf\u53d7\u4efb\u52a1\u590d\u6742\u5ea6\u5f71\u54cd\uff0c\u5b8c\u6574\u6027\u662f\u4e3b\u8981\u6311\u6218\u3002"}}
{"id": "2511.06882", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.06882", "abs": "https://arxiv.org/abs/2511.06882", "authors": ["Zhipeng Li", "Wenjie Ma"], "title": "Rate-Optimal Streaming Codes Under an Extended Delay Profile for Three-Node Relay Networks With Burst Erasures", "comment": null, "summary": "This paper investigates streaming codes for three-node relay networks under burst packet erasures with a delay constraint $T$. In any sliding window of $T+1$ consecutive packets, the source-to-relay and relay-to-destination channels may introduce burst erasures of lengths at most $b_1$ and $b_2$, respectively. Let $u = \\max\\{b_1, b_2\\}$ and $v = \\min\\{b_1, b_2\\}$. Singhvi et al. proposed a construction achieving the optimal rate when $u\\mid (T-u-v)$. In this paper, we present an extended delay profile method that attains the optimal rate under a relaxed constraint $\\frac{T - u - v}{2u - v} \\leq \\left\\lfloor \\frac{T - u - v}{u} \\right\\rfloor$ and it strictly cover restriction $u\\mid (T-u-v)$. %Furthermore, we demonstrate that the optimal rate for streaming codes is not achievable when $0< T-u-v<v$ under the convolutional code framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55\u5ef6\u8fdf\u914d\u7f6e\u65b9\u6cd5\uff0c\u7528\u4e8e\u4e09\u8282\u70b9\u4e2d\u7ee7\u7f51\u7edc\u4e2d\u7684\u6d41\u7801\u8bbe\u8ba1\uff0c\u5728\u66f4\u5bbd\u677e\u7684\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u6700\u4f18\u901f\u7387\uff0c\u8986\u76d6\u4e86\u5148\u524d\u8981\u6c42\u7684\u6574\u9664\u6761\u4ef6\u3002", "motivation": "\u7814\u7a76\u4e09\u8282\u70b9\u4e2d\u7ee7\u7f51\u7edc\u4e2d\u5728\u7a81\u53d1\u5305\u5220\u9664\u548c\u5ef6\u8fdf\u7ea6\u675f\u4e0b\u7684\u6d41\u7801\u8bbe\u8ba1\uff0c\u65e8\u5728\u5728\u66f4\u5bbd\u677e\u7684\u6761\u4ef6\u4e0b\u5b9e\u73b0\u6700\u4f18\u4f20\u8f93\u901f\u7387\u3002", "method": "\u91c7\u7528\u6269\u5c55\u5ef6\u8fdf\u914d\u7f6e\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u9020\u6ee1\u8db3\u5ef6\u8fdf\u7ea6\u675f\u7684\u6d41\u7801\uff0c\u5728\u66f4\u5bbd\u677e\u7684\u7ea6\u675f\u6761\u4ef6\u4e0b\u5b9e\u73b0\u6700\u4f18\u901f\u7387\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6761\u4ef6(T-u-v)/(2u-v) \u2264 \u230a(T-u-v)/u\u230b\u4e0b\u5b9e\u73b0\u4e86\u6700\u4f18\u901f\u7387\uff0c\u4e25\u683c\u8986\u76d6\u4e86\u5148\u524d\u8981\u6c42u\u6574\u9664(T-u-v)\u7684\u9650\u5236\u3002", "conclusion": "\u6269\u5c55\u5ef6\u8fdf\u914d\u7f6e\u65b9\u6cd5\u4e3a\u4e09\u8282\u70b9\u4e2d\u7ee7\u7f51\u7edc\u4e2d\u7684\u6d41\u7801\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u6784\u9020\u65b9\u6848\uff0c\u5728\u66f4\u5bbd\u677e\u7684\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u6700\u4f18\u4f20\u8f93\u901f\u7387\u3002"}}
{"id": "2511.05883", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05883", "abs": "https://arxiv.org/abs/2511.05883", "authors": ["Hehai Lin", "Hui Liu", "Shilei Cao", "Jing Li", "Haoliang Li", "Wenya Wang"], "title": "Unveiling Modality Bias: Automated Sample-Specific Analysis for Multimodal Misinformation Benchmarks", "comment": null, "summary": "Numerous multimodal misinformation benchmarks exhibit bias toward specific modalities, allowing detectors to make predictions based solely on one modality. While previous research has quantified bias at the dataset level or manually identified spurious correlations between modalities and labels, these approaches lack meaningful insights at the sample level and struggle to scale to the vast amount of online information. In this paper, we investigate the design for automated recognition of modality bias at the sample level. Specifically, we propose three bias quantification methods based on theories/views of different levels of granularity: 1) a coarse-grained evaluation of modality benefit; 2) a medium-grained quantification of information flow; and 3) a fine-grained causality analysis. To verify the effectiveness, we conduct a human evaluation on two popular benchmarks. Experimental results reveal three interesting findings that provide potential direction toward future research: 1)~Ensembling multiple views is crucial for reliable automated analysis; 2)~Automated analysis is prone to detector-induced fluctuations; and 3)~Different views produce a higher agreement on modality-balanced samples but diverge on biased ones.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u79cd\u57fa\u4e8e\u4e0d\u540c\u7c92\u5ea6\u7406\u8bba\u7684\u6837\u672c\u7ea7\u6a21\u6001\u504f\u5dee\u91cf\u5316\u65b9\u6cd5\uff1a\u7c97\u7c92\u5ea6\u7684\u6a21\u6001\u6548\u76ca\u8bc4\u4f30\u3001\u4e2d\u7c92\u5ea6\u7684\u4fe1\u606f\u6d41\u91cf\u5316\u3001\u7ec6\u7c92\u5ea6\u7684\u56e0\u679c\u5206\u6790\uff0c\u5e76\u901a\u8fc7\u4eba\u5de5\u8bc4\u4f30\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\u57fa\u51c6\u5b58\u5728\u7279\u5b9a\u6a21\u6001\u504f\u5411\uff0c\u4f7f\u68c0\u6d4b\u5668\u4ec5\u57fa\u4e8e\u5355\u4e00\u6a21\u6001\u5373\u53ef\u9884\u6d4b\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u6837\u672c\u7ea7\u6d1e\u5bdf\u4e14\u96be\u4ee5\u6269\u5c55\u5230\u6d77\u91cf\u5728\u7ebf\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u504f\u5dee\u91cf\u5316\u65b9\u6cd5\uff1a1) \u7c97\u7c92\u5ea6\u6a21\u6001\u6548\u76ca\u8bc4\u4f30\uff1b2) \u4e2d\u7c92\u5ea6\u4fe1\u606f\u6d41\u91cf\u5316\uff1b3) \u7ec6\u7c92\u5ea6\u56e0\u679c\u5206\u6790\u3002\u5728\u4e24\u4e2a\u6d41\u884c\u57fa\u51c6\u4e0a\u8fdb\u884c\u4eba\u5de5\u8bc4\u4f30\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff1a1) \u591a\u89c6\u56fe\u96c6\u6210\u5bf9\u53ef\u9760\u81ea\u52a8\u5206\u6790\u81f3\u5173\u91cd\u8981\uff1b2) \u81ea\u52a8\u5206\u6790\u6613\u53d7\u68c0\u6d4b\u5668\u8bf1\u5bfc\u6ce2\u52a8\u5f71\u54cd\uff1b3) \u4e0d\u540c\u89c6\u56fe\u5728\u6a21\u6001\u5e73\u8861\u6837\u672c\u4e0a\u4e00\u81f4\u6027\u66f4\u9ad8\uff0c\u5728\u504f\u5dee\u6837\u672c\u4e0a\u5206\u6b67\u66f4\u5927\u3002", "conclusion": "\u591a\u89c6\u56fe\u96c6\u6210\u65b9\u6cd5\u80fd\u6709\u6548\u8bc6\u522b\u6837\u672c\u7ea7\u6a21\u6001\u504f\u5dee\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u6a21\u6001\u4e0d\u5e73\u8861\u6837\u672c\u65f6\u9700\u8003\u8651\u68c0\u6d4b\u5668\u7a33\u5b9a\u6027\u548c\u591a\u89c6\u89d2\u4e00\u81f4\u6027\u3002"}}
{"id": "2511.06994", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06994", "abs": "https://arxiv.org/abs/2511.06994", "authors": ["Emil Bj\u00f6rnson", "Murat Babek Salman"], "title": "Experimental Validation of Reflective Near-Field Beamfocusing using a b-bit RIS", "comment": "6 pages, 6 figures, Submitted for publication", "summary": "This paper presents the first experimental validation of reflective near-field beamfocusing using a reconfigurable intelligent surface (RIS). While beamfocusing has been theoretically established as a key feature of large-aperture RISs, its practical realization has remained unexplored. We derive new analytical expressions for the array gain achieved with a $b$-bit RIS in near-field line-of-sight scenarios, characterizing both the finite depth and angular width of the focal region. The theoretical results are validated through a series of measurements in an indoor office environment at 28 GHz using a one-bit 1024-element RIS. The experiments confirm that near-field beamfocusing can be dynamically achieved and accurately predicted by the proposed analytical model, despite the presence of hardware imperfections and multipath propagation. These findings demonstrate that near-field beamfocusing is a robust and practically viable feature of RIS-assisted wireless communications.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4f7f\u7528\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(RIS)\u7684\u53cd\u5c04\u8fd1\u573a\u6ce2\u675f\u805a\u7126\u6280\u672f\uff0c\u901a\u8fc728GHz\u9891\u6bb5\u76841024\u5355\u51431\u6bd4\u7279RIS\u5728\u5ba4\u5185\u529e\u516c\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u7406\u8bba\u6a21\u578b\u3002", "motivation": "\u867d\u7136\u6ce2\u675f\u805a\u7126\u5df2\u88ab\u7406\u8bba\u8bc1\u660e\u662f\u5927\u5b54\u5f84RIS\u7684\u5173\u952e\u7279\u6027\uff0c\u4f46\u5176\u5b9e\u7528\u5b9e\u73b0\u5c1a\u672a\u88ab\u63a2\u7d22\uff0c\u9700\u8981\u5b9e\u9a8c\u9a8c\u8bc1\u8fd1\u573a\u6ce2\u675f\u805a\u7126\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3002", "method": "\u63a8\u5bfc\u4e86b\u6bd4\u7279RIS\u5728\u8fd1\u573a\u89c6\u8ddd\u573a\u666f\u4e0b\u7684\u9635\u5217\u589e\u76ca\u65b0\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u5e76\u901a\u8fc728GHz\u9891\u6bb51024\u5355\u51431\u6bd4\u7279RIS\u5728\u5ba4\u5185\u529e\u516c\u73af\u5883\u8fdb\u884c\u6d4b\u91cf\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u8fd1\u573a\u6ce2\u675f\u805a\u7126\u53ef\u4ee5\u52a8\u6001\u5b9e\u73b0\uff0c\u5e76\u4e14\u4e0e\u63d0\u51fa\u7684\u89e3\u6790\u6a21\u578b\u51c6\u786e\u5339\u914d\uff0c\u5373\u4f7f\u5728\u5b58\u5728\u786c\u4ef6\u7f3a\u9677\u548c\u591a\u5f84\u4f20\u64ad\u7684\u60c5\u51b5\u4e0b\u4e5f\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u3002", "conclusion": "\u8fd1\u573a\u6ce2\u675f\u805a\u7126\u662fRIS\u8f85\u52a9\u65e0\u7ebf\u901a\u4fe1\u4e2d\u4e00\u4e2a\u9c81\u68d2\u4e14\u5b9e\u9645\u53ef\u884c\u7684\u7279\u6027\uff0c\u4e3a\u672a\u6765\u65e0\u7ebf\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2511.05931", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05931", "abs": "https://arxiv.org/abs/2511.05931", "authors": ["Hiroaki Hayashi", "Bo Pang", "Wenting Zhao", "Ye Liu", "Akash Gokul", "Srijan Bansal", "Caiming Xiong", "Semih Yavuz", "Yingbo Zhou"], "title": "Self-Abstraction from Grounded Experience for Plan-Guided Policy Refinement", "comment": null, "summary": "Large language model (LLM) based agents are increasingly used to tackle software engineering tasks that require multi-step reasoning and code modification, demonstrating promising yet limited performance. However, most existing LLM agents typically operate within static execution frameworks, lacking a principled mechanism to learn and self-improve from their own experience and past rollouts. As a result, their performance remains bounded by the initial framework design and the underlying LLM's capabilities. We propose Self-Abstraction from Grounded Experience (SAGE), a framework that enables agents to learn from their own task executions and refine their behavior through self-abstraction. After an initial rollout, the agent induces a concise plan abstraction from its grounded experience, distilling key steps, dependencies, and constraints. This learned abstraction is then fed back as contextual guidance, refining the agent's policy and supporting more structured, informed subsequent executions. Empirically, SAGE delivers consistent performance gains across diverse LLM backbones and agent architectures. Notably, it yields a 7.2% relative performance improvement over the strong Mini-SWE-Agent baseline when paired with the GPT-5 (high) backbone. SAGE further achieves strong overall performance on SWE-Bench Verified benchmark, reaching 73.2% and 74% Pass@1 resolve rates with the Mini-SWE-Agent and OpenHands CodeAct agent framework, respectively.", "AI": {"tldr": "\u63d0\u51fa\u4e86SAGE\u6846\u67b6\uff0c\u4f7fLLM\u4ee3\u7406\u80fd\u591f\u4ece\u81ea\u8eab\u4efb\u52a1\u6267\u884c\u4e2d\u5b66\u4e60\uff0c\u901a\u8fc7\u81ea\u6211\u62bd\u8c61\u6765\u63d0\u70bc\u5173\u952e\u6b65\u9aa4\u3001\u4f9d\u8d56\u5173\u7cfb\u548c\u7ea6\u675f\uff0c\u4ece\u800c\u6539\u8fdb\u540e\u7eed\u6267\u884c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u901a\u5e38\u5728\u9759\u6001\u6267\u884c\u6846\u67b6\u4e2d\u8fd0\u884c\uff0c\u7f3a\u4e4f\u4ece\u81ea\u8eab\u7ecf\u9a8c\u548c\u5386\u53f2\u6267\u884c\u4e2d\u5b66\u4e60\u6539\u8fdb\u7684\u673a\u5236\uff0c\u5bfc\u81f4\u6027\u80fd\u53d7\u9650\u4e8e\u521d\u59cb\u6846\u67b6\u8bbe\u8ba1\u548c\u57fa\u7840LLM\u80fd\u529b\u3002", "method": "SAGE\u6846\u67b6\u8ba9\u4ee3\u7406\u4ece\u521d\u59cb\u6267\u884c\u4e2d\u5f52\u7eb3\u51fa\u7b80\u6d01\u7684\u8ba1\u5212\u62bd\u8c61\uff0c\u63d0\u70bc\u5173\u952e\u6b65\u9aa4\u3001\u4f9d\u8d56\u5173\u7cfb\u548c\u7ea6\u675f\uff0c\u7136\u540e\u5c06\u5b66\u4e60\u5230\u7684\u62bd\u8c61\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u6307\u5bfc\u53cd\u9988\u7ed9\u4ee3\u7406\uff0c\u4f18\u5316\u5176\u7b56\u7565\u3002", "result": "\u5728\u591a\u6837\u5316LLM\u9aa8\u5e72\u548c\u4ee3\u7406\u67b6\u6784\u4e0a\u5b9e\u73b0\u4e86\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e0eMini-SWE-Agent\u57fa\u7ebf\u76f8\u6bd4\u83b7\u5f977.2%\u76f8\u5bf9\u6027\u80fd\u6539\u8fdb\uff0c\u5728SWE-Bench Verified\u57fa\u51c6\u4e0a\u8fbe\u523073.2%\u548c74%\u7684Pass@1\u89e3\u51b3\u7387\u3002", "conclusion": "SAGE\u6846\u67b6\u901a\u8fc7\u81ea\u6211\u62bd\u8c61\u5b66\u4e60\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86LLM\u4ee3\u7406\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u4ece\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.07145", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.07145", "abs": "https://arxiv.org/abs/2511.07145", "authors": ["Xinke Jian", "Zhiyuan Ren", "Wenchi Cheng"], "title": "A Copula-based Semantics-Structure Minimization Framework for QoS Guaranteed Wireless Communications", "comment": null, "summary": "Current empirically driven research on semantic communication lacks a unified theoretical foundation, preventing quantifiable Quality of Service guarantees, particularly for transmitting minimal structural semantics in emergency scenarios. This deficiency limits its evolution into a predictable engineering science. To address this, we establish a complete theoretical axiomatic basis for this problem. We propose four axioms and rigorously prove that the family of pairwise rank-Copulas is the minimal sufficient representation for minimal structural semantics. Based on this, we construct a semantic distortion metric, centered on the Jensen-Shannon divergence. We then establish the core theoretical boundaries of the framework: sample complexity bounds; rate-distortion bounds; an end-to-end Service Level Agreements theorem; and a semantic source-channel separation theorem, which provides a provable Quality of Service guarantee. Finally, we validate our framework through decoupled experiments, empirically demonstrating that our core metric strictly adheres to our foundational axioms while standard perceptual metrics fail to do so.", "AI": {"tldr": "\u4e3a\u8bed\u4e49\u901a\u4fe1\u5efa\u7acb\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63d0\u51fa\u56db\u4e2a\u516c\u7406\u5e76\u8bc1\u660epairwise rank-Copulas\u662f\u6700\u5c0f\u7ed3\u6784\u8bed\u4e49\u7684\u6700\u5c0f\u5145\u5206\u8868\u793a\uff0c\u6784\u5efa\u8bed\u4e49\u5931\u771f\u5ea6\u91cf\uff0c\u786e\u7acb\u7406\u8bba\u8fb9\u754c\u548cQoS\u4fdd\u8bc1\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u7ecf\u9a8c\u7684\u8bed\u4e49\u901a\u4fe1\u7814\u7a76\u7f3a\u4e4f\u7edf\u4e00\u7406\u8bba\u57fa\u7840\uff0c\u65e0\u6cd5\u63d0\u4f9b\u53ef\u91cf\u5316\u7684\u670d\u52a1\u8d28\u91cf\u4fdd\u8bc1\uff0c\u7279\u522b\u662f\u5728\u7d27\u6025\u573a\u666f\u4e2d\u4f20\u8f93\u6700\u5c0f\u7ed3\u6784\u8bed\u4e49\u65f6\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u53d1\u5c55\u6210\u4e3a\u53ef\u9884\u6d4b\u7684\u5de5\u7a0b\u79d1\u5b66\u3002", "method": "\u63d0\u51fa\u56db\u4e2a\u516c\u7406\uff0c\u8bc1\u660epairwise rank-Copulas\u662f\u6700\u5c0f\u7ed3\u6784\u8bed\u4e49\u7684\u6700\u5c0f\u5145\u5206\u8868\u793a\uff0c\u6784\u5efa\u57fa\u4e8eJensen-Shannon\u6563\u5ea6\u7684\u8bed\u4e49\u5931\u771f\u5ea6\u91cf\uff0c\u5efa\u7acb\u6837\u672c\u590d\u6742\u5ea6\u8fb9\u754c\u3001\u7387\u5931\u771f\u8fb9\u754c\u3001\u7aef\u5230\u7aefSLA\u5b9a\u7406\u548c\u8bed\u4e49\u6e90\u4fe1\u9053\u5206\u79bb\u5b9a\u7406\u3002", "result": "\u901a\u8fc7\u89e3\u8026\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027\uff0c\u8bc1\u660e\u6838\u5fc3\u5ea6\u91cf\u4e25\u683c\u9075\u5faa\u57fa\u7840\u516c\u7406\uff0c\u800c\u6807\u51c6\u611f\u77e5\u5ea6\u91cf\u65e0\u6cd5\u505a\u5230\u8fd9\u4e00\u70b9\u3002", "conclusion": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u8bed\u4e49\u901a\u4fe1\u7406\u8bba\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u53ef\u8bc1\u660e\u7684\u670d\u52a1\u8d28\u91cf\u4fdd\u8bc1\uff0c\u4e3a\u8bed\u4e49\u901a\u4fe1\u53d1\u5c55\u6210\u4e3a\u53ef\u9884\u6d4b\u7684\u5de5\u7a0b\u79d1\u5b66\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.05951", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05951", "abs": "https://arxiv.org/abs/2511.05951", "authors": ["Qi Wang", "Hongzhi Zhang", "Jia Fu", "Kai Fu", "Yahui Liu", "Tinghai Zhang", "Chenxi Sun", "Gangwei Jiang", "Jingyi Tang", "Xingguang Ji", "Yang Yue", "Jingyuan Zhang", "Fuzheng Zhang", "Kun Gai", "Guorui Zhou"], "title": "Klear-AgentForge: Forging Agentic Intelligence through Posttraining Scaling", "comment": "20 pages, 7 figures", "summary": "Despite the proliferation of powerful agentic models, the lack of critical post-training details hinders the development of strong counterparts in the open-source community. In this study, we present a comprehensive and fully open-source pipeline for training a high-performance agentic model for interacting with external tools and environments, named Klear-Qwen3-AgentForge, starting from the Qwen3-8B base model. We design effective supervised fine-tuning (SFT) with synthetic data followed by multi-turn reinforcement learning (RL) to unlock the potential for multiple diverse agentic tasks. We perform exclusive experiments on various agentic benchmarks in both tool use and coding domains. Klear-Qwen3-AgentForge-8B achieves state-of-the-art performance among LLMs of similar size and remains competitive with significantly larger models.", "AI": {"tldr": "\u5f00\u53d1\u4e86Klear-Qwen3-AgentForge-8B\uff0c\u4e00\u4e2a\u5b8c\u5168\u5f00\u6e90\u7684\u667a\u80fd\u4f53\u8bad\u7ec3\u6d41\u7a0b\uff0c\u4eceQwen3-8B\u57fa\u7840\u6a21\u578b\u5f00\u59cb\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\uff0c\u5728\u5de5\u5177\u4f7f\u7528\u548c\u7f16\u7801\u4efb\u52a1\u4e0a\u8fbe\u5230\u540c\u7c7b\u5c3a\u5bf8\u6a21\u578b\u7684\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5f3a\u5927\u7684\u667a\u80fd\u4f53\u6a21\u578b\u4e0d\u65ad\u6d8c\u73b0\uff0c\u4f46\u7f3a\u4e4f\u5173\u952e\u7684\u8bad\u7ec3\u540e\u7ec6\u8282\u963b\u788d\u4e86\u5f00\u6e90\u793e\u533a\u5f00\u53d1\u540c\u7b49\u5f3a\u5927\u7684\u6a21\u578b\u3002", "method": "\u8bbe\u8ba1\u4e86\u6709\u6548\u7684\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u4f7f\u7528\u5408\u6210\u6570\u636e\uff0c\u7136\u540e\u8fdb\u884c\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\uff0c\u4ee5\u89e3\u9501\u591a\u79cd\u667a\u80fd\u4f53\u4efb\u52a1\u7684\u6f5c\u529b\u3002", "result": "Klear-Qwen3-AgentForge-8B\u5728\u7c7b\u4f3c\u5c3a\u5bf8\u7684LLM\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u4e0e\u663e\u8457\u66f4\u5927\u7684\u6a21\u578b\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u4e14\u5b8c\u5168\u5f00\u6e90\u7684\u667a\u80fd\u4f53\u6a21\u578b\u8bad\u7ec3\u6d41\u7a0b\uff0c\u80fd\u591f\u5f00\u53d1\u51fa\u9ad8\u6027\u80fd\u7684\u667a\u80fd\u4f53\u6a21\u578b\u3002"}}
{"id": "2511.07309", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.07309", "abs": "https://arxiv.org/abs/2511.07309", "authors": ["Han Xiao", "Xiaoyan Hu", "Wenjie Wang", "Kai-Kit Wong", "Kun Yang", "Chan-Byoung Chae"], "title": "Frequency Diverse (FD)-RIS-Enhanced Covert Communications: Defense Against Wiretapping via Joint Distance-Angle Beamforming", "comment": null, "summary": "In response to the security blind zone challenges faced by traditional reconfigurable intelligent surface (RIS)-aided covert communication (CC) systems, the joint distance-angle beamforming capability of frequency diverse RIS (FD-RIS) shows significant potential for addressing these limitations. Therefore, this paper initially incorporates the FD-RIS into the CC systems and proposes the corresponding CC transmission scheme. Specifically, we first develop the signal processing model of the FD-RIS, which considers effective control of harmonic signals by leveraging the time-delay techniques. The joint distance-angle beamforming capability is then validated through its normalized beampattern. Based on this model, we then construct an FD-RIS-assisted CC system under a multi-warden scenario and derive an approximate closed-form expression for the covert constraints by considering the worst-case eavesdropping conditions and utilizing the logarithmic moment-generating function. An optimization problem is formulated which aims at maximizing the covert user's achievable rate under covert constrains by jointly designing the time delays and modulation frequencies. To tackle this non-convex problem, an iterative algorithm with assured convergence is proposed to effectively solve the time-delay and modulation frequency variables. To evaluate the performance of the proposed scheme, we consider three communication scenarios with varying spatial correlations between the covert user and wardens. Simulation results demonstrate that FD-RIS can significantly improve covert performance, particularly in angular-overlap scenarios where traditional RIS experiences severe degradation. These findings further highlight the effectiveness of FD-RIS in enhancing CC robustness under challenging spatial environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9891\u7387\u5206\u96c6\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(FD-RIS)\u7684\u9690\u853d\u901a\u4fe1\u65b9\u6848\uff0c\u901a\u8fc7\u8054\u5408\u8ddd\u79bb-\u89d2\u5ea6\u6ce2\u675f\u6210\u5f62\u80fd\u529b\u89e3\u51b3\u4f20\u7edfRIS\u5728\u9690\u853d\u901a\u4fe1\u4e2d\u7684\u5b89\u5168\u76f2\u533a\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfRIS\u8f85\u52a9\u7684\u9690\u853d\u901a\u4fe1\u7cfb\u7edf\u5b58\u5728\u5b89\u5168\u76f2\u533a\u6311\u6218\uff0c\u800cFD-RIS\u7684\u8054\u5408\u8ddd\u79bb-\u89d2\u5ea6\u6ce2\u675f\u6210\u5f62\u80fd\u529b\u5177\u6709\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\u7684\u6f5c\u529b\u3002", "method": "\u9996\u5148\u5f00\u53d1\u4e86FD-RIS\u7684\u4fe1\u53f7\u5904\u7406\u6a21\u578b\uff0c\u5229\u7528\u65f6\u5ef6\u6280\u672f\u63a7\u5236\u8c10\u6ce2\u4fe1\u53f7\uff1b\u7136\u540e\u6784\u5efa\u591a\u770b\u5b88\u573a\u666f\u4e0b\u7684FD-RIS\u8f85\u52a9\u9690\u853d\u901a\u4fe1\u7cfb\u7edf\uff0c\u63a8\u5bfc\u9690\u853d\u7ea6\u675f\u7684\u8fd1\u4f3c\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff1b\u6700\u540e\u63d0\u51fa\u8fed\u4ee3\u7b97\u6cd5\u8054\u5408\u4f18\u5316\u65f6\u5ef6\u548c\u8c03\u5236\u9891\u7387\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cFD-RIS\u80fd\u663e\u8457\u63d0\u5347\u9690\u853d\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u89d2\u5ea6\u91cd\u53e0\u573a\u666f\u4e2d\uff0c\u4f20\u7edfRIS\u6027\u80fd\u4e25\u91cd\u4e0b\u964d\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "FD-RIS\u5728\u6311\u6218\u6027\u7a7a\u95f4\u73af\u5883\u4e0b\u80fd\u6709\u6548\u589e\u5f3a\u9690\u853d\u901a\u4fe1\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.05977", "categories": ["cs.AI", "cs.LO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.05977", "abs": "https://arxiv.org/abs/2511.05977", "authors": ["Pavel Naumov", "Alexandra Pavlova"], "title": "An Epistemic Perspective on Agent Awareness", "comment": "Fortieth AAAI Conference on Artificial Intelligence (AAAI-26)", "summary": "The paper proposes to treat agent awareness as a form of knowledge, breaking the tradition in the existing literature on awareness. It distinguishes the de re and de dicto forms of such knowledge. The work introduces two modalities capturing these forms and formally specifies their meaning using a version of 2D-semantics. The main technical result is a sound and complete logical system describing the interplay between the two proposed modalities and the standard \"knowledge of the fact\" modality.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u667a\u80fd\u4f53\u610f\u8bc6\u89c6\u4e3a\u4e00\u79cd\u77e5\u8bc6\u5f62\u5f0f\uff0c\u533a\u522b\u4e8e\u73b0\u6709\u6587\u732e\u4f20\u7edf\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u6a21\u6001\u6765\u6355\u6349\u8fd9\u79cd\u77e5\u8bc6\u7684de re\u548cde dicto\u5f62\u5f0f\uff0c\u5e76\u5efa\u7acb\u4e86\u63cf\u8ff0\u8fd9\u4e9b\u6a21\u6001\u4e0e\u6807\u51c6\"\u4e8b\u5b9e\u77e5\u8bc6\"\u6a21\u6001\u4e4b\u95f4\u76f8\u4e92\u4f5c\u7528\u7684\u903b\u8f91\u7cfb\u7edf\u3002", "motivation": "\u6253\u7834\u73b0\u6709\u6587\u732e\u4e2d\u5c06\u667a\u80fd\u4f53\u610f\u8bc6\u89c6\u4e3a\u4f20\u7edf\u77e5\u8bc6\u7684\u4f20\u7edf\uff0c\u63d0\u51fa\u5c06\u610f\u8bc6\u4f5c\u4e3a\u72ec\u7acb\u7684\u77e5\u8bc6\u5f62\u5f0f\u6765\u7814\u7a76\uff0c\u7279\u522b\u662f\u533a\u5206de re\u548cde dicto\u4e24\u79cd\u610f\u8bc6\u77e5\u8bc6\u5f62\u5f0f\u3002", "method": "\u5f15\u5165\u4e24\u79cd\u6a21\u6001\u6765\u6355\u6349de re\u548cde dicto\u5f62\u5f0f\u7684\u610f\u8bc6\u77e5\u8bc6\uff0c\u4f7f\u75282D\u8bed\u4e49\u5b66\u5f62\u5f0f\u5316\u5176\u542b\u4e49\uff0c\u6784\u5efa\u63cf\u8ff0\u8fd9\u4e9b\u6a21\u6001\u4e0e\u6807\u51c6\u77e5\u8bc6\u6a21\u6001\u76f8\u4e92\u4f5c\u7528\u7684\u903b\u8f91\u7cfb\u7edf\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u63cf\u8ff0\u4e24\u79cd\u610f\u8bc6\u77e5\u8bc6\u6a21\u6001\u4e0e\u6807\u51c6\u4e8b\u5b9e\u77e5\u8bc6\u6a21\u6001\u4e4b\u95f4\u76f8\u4e92\u4f5c\u7528\u7684\u5065\u5168\u4e14\u5b8c\u5907\u7684\u903b\u8f91\u7cfb\u7edf\u3002", "conclusion": "\u901a\u8fc7\u5c06\u667a\u80fd\u4f53\u610f\u8bc6\u5f62\u5f0f\u5316\u4e3a\u77e5\u8bc6\uff0c\u5e76\u533a\u5206de re\u548cde dicto\u5f62\u5f0f\uff0c\u6210\u529f\u6784\u5efa\u4e86\u63cf\u8ff0\u610f\u8bc6\u77e5\u8bc6\u4e0e\u6807\u51c6\u77e5\u8bc6\u4e4b\u95f4\u5173\u7cfb\u7684\u903b\u8f91\u6846\u67b6\uff0c\u4e3a\u610f\u8bc6\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u5f62\u5f0f\u5316\u5de5\u5177\u3002"}}
{"id": "2511.06065", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06065", "abs": "https://arxiv.org/abs/2511.06065", "authors": ["Lianrui Li", "Dakuan Lu", "Jiawei Shao", "Chi Zhang", "Xuelong Li"], "title": "ScRPO: From Errors to Insights", "comment": null, "summary": "We propose Self-correction Relative Policy Optimization (ScRPO), a novel reinforcement learning framework designed to enhance large language models on challenging mathematical problems by leveraging self-reflection and error correction. Our approach consists of two stages: (1) Trial-and-error learning stage: training the model with GRPO and collecting incorrect answers along with their corresponding questions in an error pool; (2) Self-correction learning stage: guiding the model to reflect on why its previous answers were wrong. Extensive experiments across multiple math reasoning benchmarks, including AIME, AMC, Olympiad, MATH-500, GSM8k, using Deepseek-Distill-Qwen-1.5B and Deepseek-Distill-Qwen-7B. The experimental results demonstrate that ScRPO consistently outperforms several post-training methods. These findings highlight ScRPO as a promising paradigm for enabling language models to self-improve on difficult tasks with limited external feedback, paving the way toward more reliable and capable AI systems.", "AI": {"tldr": "\u63d0\u51faScRPO\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u6211\u53cd\u601d\u548c\u7ea0\u9519\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u5305\u542b\u8bd5\u9519\u5b66\u4e60\u548c\u81ea\u6211\u7ea0\u6b63\u4e24\u4e2a\u9636\u6bb5\uff0c\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u6570\u5b66\u95ee\u9898\u4e0a\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u6211\u53cd\u601d\u548c\u7ea0\u9519\u673a\u5236\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u51cf\u5c11\u5bf9\u5916\u90e8\u53cd\u9988\u7684\u4f9d\u8d56\u3002", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u8bd5\u9519\u5b66\u4e60\u9636\u6bb5\u4f7f\u7528GRPO\u8bad\u7ec3\u5e76\u6536\u96c6\u9519\u8bef\u7b54\u6848\uff1b2) \u81ea\u6211\u7ea0\u6b63\u5b66\u4e60\u9636\u6bb5\u5f15\u5bfc\u6a21\u578b\u53cd\u601d\u4e4b\u524d\u9519\u8bef\u7684\u539f\u56e0\u3002", "result": "\u5728AIME\u3001AMC\u3001Olympiad\u3001MATH-500\u3001GSM8k\u7b49\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cScRPO\u6301\u7eed\u4f18\u4e8e\u591a\u79cd\u540e\u8bad\u7ec3\u65b9\u6cd5\u3002", "conclusion": "ScRPO\u4e3a\u8bed\u8a00\u6a21\u578b\u5728\u56f0\u96be\u4efb\u52a1\u4e0a\u7684\u81ea\u6211\u6539\u8fdb\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u8303\u5f0f\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u53ef\u9760\u548c\u5f3a\u5927\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2511.06134", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.06134", "abs": "https://arxiv.org/abs/2511.06134", "authors": ["Wei Yang", "Jiacheng Pang", "Shixuan Li", "Paul Bogdan", "Stephen Tu", "Jesse Thomason"], "title": "Maestro: Learning to Collaborate via Conditional Listwise Policy Optimization for Multi-Agent LLMs", "comment": null, "summary": "Multi-agent systems (MAS) built on Large Language Models (LLMs) are being used to approach complex problems and can surpass single model inference. However, their success hinges on navigating a fundamental cognitive tension: the need to balance broad, divergent exploration of the solution space with a principled, convergent synthesis to the optimal solution. Existing paradigms often struggle to manage this duality, leading to premature consensus, error propagation, and a critical credit assignment problem that fails to distinguish between genuine reasoning and superficially plausible arguments. To resolve this core challenge, we propose the Multi-Agent Exploration-Synthesis framework Through Role Orchestration (Maestro), a principled paradigm for collaboration that structurally decouples these cognitive modes. Maestro uses a collective of parallel Execution Agents for diverse exploration and a specialized Central Agent for convergent, evaluative synthesis. To operationalize this critical synthesis phase, we introduce Conditional Listwise Policy Optimization (CLPO), a reinforcement learning objective that disentangles signals for strategic decisions and tactical rationales. By combining decision-focused policy gradients with a list-wise ranking loss over justifications, CLPO achieves clean credit assignment and stronger comparative supervision. Experiments on mathematical reasoning and general problem-solving benchmarks demonstrate that Maestro, coupled with CLPO, consistently outperforms existing state-of-the-art multi-agent approaches, delivering absolute accuracy gains of 6% on average and up to 10% at best.", "AI": {"tldr": "\u63d0\u51faMaestro\u6846\u67b6\uff0c\u901a\u8fc7\u89d2\u8272\u7f16\u6392\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u63a2\u7d22-\u5408\u6210\u8ba4\u77e5\u5f20\u529b\uff0c\u7ed3\u5408CLPO\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u6e05\u6670\u7684\u4fe1\u7528\u5206\u914d\uff0c\u5728\u6570\u5b66\u63a8\u7406\u548c\u95ee\u9898\u89e3\u51b3\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u96be\u4ee5\u5e73\u8861\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4\u7684\u5e7f\u6cdb\u63a2\u7d22\u548c\u6700\u4f18\u89e3\u7684\u6536\u655b\u5408\u6210\uff0c\u5bb9\u6613\u5bfc\u81f4\u8fc7\u65e9\u5171\u8bc6\u3001\u9519\u8bef\u4f20\u64ad\u548c\u4fe1\u7528\u5206\u914d\u95ee\u9898\u3002", "method": "Maestro\u6846\u67b6\uff1a\u4f7f\u7528\u5e76\u884c\u6267\u884c\u667a\u80fd\u4f53\u8fdb\u884c\u591a\u6837\u5316\u63a2\u7d22\uff0c\u4e13\u95e8\u4e2d\u592e\u667a\u80fd\u4f53\u8fdb\u884c\u6536\u655b\u6027\u5408\u6210\u8bc4\u4f30\uff1bCLPO\u65b9\u6cd5\uff1a\u7ed3\u5408\u51b3\u7b56\u5bfc\u5411\u7684\u7b56\u7565\u68af\u5ea6\u548c\u57fa\u4e8e\u7406\u7531\u7684\u5217\u8868\u6392\u5e8f\u635f\u5931\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u548c\u901a\u7528\u95ee\u9898\u89e3\u51b3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMaestro+CLPO\u5e73\u5747\u7edd\u5bf9\u51c6\u786e\u7387\u63d0\u53476%\uff0c\u6700\u9ad8\u53ef\u8fbe10%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5316\u89e3\u8026\u63a2\u7d22\u548c\u5408\u6210\u8ba4\u77e5\u6a21\u5f0f\uff0c\u7ed3\u5408CLPO\u7684\u6e05\u6670\u4fe1\u7528\u5206\u914d\u673a\u5236\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u63a8\u7406\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002"}}
{"id": "2511.06136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06136", "abs": "https://arxiv.org/abs/2511.06136", "authors": ["Stefano Ferraro", "Akihiro Nakano", "Masahiro Suzuki", "Yutaka Matsuo"], "title": "When Object-Centric World Models Meet Policy Learning: From Pixels to Policies, and Where It Breaks", "comment": null, "summary": "Object-centric world models (OCWM) aim to decompose visual scenes into object-level representations, providing structured abstractions that could improve compositional generalization and data efficiency in reinforcement learning. We hypothesize that explicitly disentangled object-level representations, by localizing task-relevant information, can enhance policy performance across novel feature combinations. To test this hypothesis, we introduce DLPWM, a fully unsupervised, disentangled object-centric world model that learns object-level latents directly from pixels. DLPWM achieves strong reconstruction and prediction performance, including robustness to several out-of-distribution (OOD) visual variations. However, when used for downstream model-based control, policies trained on DLPWM latents underperform compared to DreamerV3. Through latent-trajectory analyses, we identify representation shift during multi-object interactions as a key driver of unstable policy learning. Our results suggest that, although object-centric perception supports robust visual modeling, achieving stable control requires mitigating latent drift.", "AI": {"tldr": "DLPWM\u662f\u4e00\u4e2a\u65e0\u76d1\u7763\u7684\u3001\u89e3\u8026\u7684\u5bf9\u8c61\u4e2d\u5fc3\u4e16\u754c\u6a21\u578b\uff0c\u867d\u7136\u80fd\u5b9e\u73b0\u5f3a\u5065\u7684\u89c6\u89c9\u91cd\u5efa\u548c\u9884\u6d4b\uff0c\u4f46\u5728\u4e0b\u6e38\u63a7\u5236\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u5982DreamerV3\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u591a\u5bf9\u8c61\u4ea4\u4e92\u65f6\u7684\u8868\u793a\u6f02\u79fb\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u89e3\u8026\u7684\u5bf9\u8c61\u7ea7\u8868\u793a\u662f\u5426\u80fd\u591f\u901a\u8fc7\u5b9a\u4f4d\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u6765\u589e\u5f3a\u7b56\u7565\u5728\u65b0\u578b\u7279\u5f81\u7ec4\u5408\u4e0a\u7684\u6027\u80fd\u3002", "method": "\u5f15\u5165DLPWM\uff0c\u4e00\u4e2a\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u89e3\u8026\u5bf9\u8c61\u4e2d\u5fc3\u4e16\u754c\u6a21\u578b\uff0c\u76f4\u63a5\u4ece\u50cf\u7d20\u5b66\u4e60\u5bf9\u8c61\u7ea7\u6f5c\u5728\u8868\u793a\u3002", "result": "DLPWM\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u91cd\u5efa\u548c\u9884\u6d4b\u6027\u80fd\uff0c\u5305\u62ec\u5bf9\u591a\u79cd\u5206\u5e03\u5916\u89c6\u89c9\u53d8\u5316\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u5728\u4e0b\u6e38\u6a21\u578b\u63a7\u5236\u4e2d\u8868\u73b0\u4e0d\u5982DreamerV3\u3002", "conclusion": "\u867d\u7136\u5bf9\u8c61\u4e2d\u5fc3\u611f\u77e5\u652f\u6301\u9c81\u68d2\u7684\u89c6\u89c9\u5efa\u6a21\uff0c\u4f46\u8981\u5b9e\u73b0\u7a33\u5b9a\u7684\u63a7\u5236\u9700\u8981\u51cf\u8f7b\u6f5c\u5728\u6f02\u79fb\u95ee\u9898\u3002"}}
{"id": "2511.06142", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06142", "abs": "https://arxiv.org/abs/2511.06142", "authors": ["Sizhe Tang", "Jiayu Chen", "Tian Lan"], "title": "MALinZero: Efficient Low-Dimensional Search for Mastering Complex Multi-Agent Planning", "comment": null, "summary": "Monte Carlo Tree Search (MCTS), which leverages Upper Confidence Bound for Trees (UCTs) to balance exploration and exploitation through randomized sampling, is instrumental to solving complex planning problems. However, for multi-agent planning, MCTS is confronted with a large combinatorial action space that often grows exponentially with the number of agents. As a result, the branching factor of MCTS during tree expansion also increases exponentially, making it very difficult to efficiently explore and exploit during tree search. To this end, we propose MALinZero, a new approach to leverage low-dimensional representational structures on joint-action returns and enable efficient MCTS in complex multi-agent planning. Our solution can be viewed as projecting the joint-action returns into the low-dimensional space representable using a contextual linear bandit problem formulation. We solve the contextual linear bandit problem with convex and $\u03bc$-smooth loss functions -- in order to place more importance on better joint actions and mitigate potential representational limitations -- and derive a linear Upper Confidence Bound applied to trees (LinUCT) to enable novel multi-agent exploration and exploitation in the low-dimensional space. We analyze the regret of MALinZero for low-dimensional reward functions and propose an $(1-\\tfrac1e)$-approximation algorithm for the joint action selection by maximizing a sub-modular objective. MALinZero demonstrates state-of-the-art performance on multi-agent benchmarks such as matrix games, SMAC, and SMACv2, outperforming both model-based and model-free multi-agent reinforcement learning baselines with faster learning speed and better performance.", "AI": {"tldr": "MALinZero\u662f\u4e00\u79cd\u65b0\u7684\u591a\u667a\u80fd\u4f53\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u8054\u5408\u52a8\u4f5c\u56de\u62a5\u6295\u5f71\u5230\u4f4e\u7ef4\u7a7a\u95f4\uff0c\u4f7f\u7528\u4e0a\u4e0b\u6587\u7ebf\u6027\u8d4c\u535a\u673a\u95ee\u9898\u6765\u63d0\u5347MCTS\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u6548\u7387\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u89c4\u5212\u4e2d\uff0cMCTS\u9762\u4e34\u7ec4\u5408\u52a8\u4f5c\u7a7a\u95f4\u6307\u6570\u7ea7\u589e\u957f\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u6811\u6269\u5c55\u7684\u5206\u652f\u56e0\u5b50\u6025\u5267\u589e\u52a0\uff0c\u96be\u4ee5\u9ad8\u6548\u8fdb\u884c\u63a2\u7d22\u548c\u5229\u7528\u3002", "method": "\u5c06\u8054\u5408\u52a8\u4f5c\u56de\u62a5\u6295\u5f71\u5230\u4f4e\u7ef4\u7a7a\u95f4\uff0c\u4f7f\u7528\u4e0a\u4e0b\u6587\u7ebf\u6027\u8d4c\u535a\u673a\u95ee\u9898\u516c\u5f0f\u5316\uff0c\u91c7\u7528\u51f8\u4e14\u03bc-\u5e73\u6ed1\u7684\u635f\u5931\u51fd\u6570\uff0c\u63a8\u5bfc\u51fa\u7ebf\u6027\u4e0a\u7f6e\u4fe1\u754c\u5e94\u7528\u4e8e\u6811(LinUCT)\u3002", "result": "\u5728\u77e9\u9635\u6e38\u620f\u3001SMAC\u548cSMACv2\u7b49\u591a\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u4f18\u4e8e\u57fa\u4e8e\u6a21\u578b\u548c\u65e0\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\uff0c\u5b66\u4e60\u901f\u5ea6\u66f4\u5feb\u4e14\u6027\u80fd\u66f4\u597d\u3002", "conclusion": "MALinZero\u901a\u8fc7\u4f4e\u7ef4\u8868\u793a\u7ed3\u6784\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53MCTS\u4e2d\u7684\u7ec4\u5408\u7206\u70b8\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u591a\u667a\u80fd\u4f53\u63a2\u7d22\u548c\u5229\u7528\u3002"}}
{"id": "2511.06160", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06160", "abs": "https://arxiv.org/abs/2511.06160", "authors": ["Fatima Jahara", "Mark Dredze", "Sharon Levy"], "title": "Evaluating Implicit Biases in LLM Reasoning through Logic Grid Puzzles", "comment": "24 pages (including appendix)", "summary": "While recent safety guardrails effectively suppress overtly biased outputs, subtler forms of social bias emerge during complex logical reasoning tasks that evade current evaluation benchmarks. To fill this gap, we introduce a new evaluation framework, PRIME (Puzzle Reasoning for Implicit Biases in Model Evaluation), that uses logic grid puzzles to systematically probe the influence of social stereotypes on logical reasoning and decision making in LLMs. Our use of logic puzzles enables automatic generation and verification, as well as variability in complexity and biased settings. PRIME includes stereotypical, anti-stereotypical, and neutral puzzle variants generated from a shared puzzle structure, allowing for controlled and fine-grained comparisons. We evaluate multiple model families across puzzle sizes and test the effectiveness of prompt-based mitigation strategies. Focusing our experiments on gender stereotypes, our findings highlight that models consistently reason more accurately when solutions align with stereotypical associations. This demonstrates the significance of PRIME for diagnosing and quantifying social biases perpetuated in the deductive reasoning of LLMs, where fairness is critical.", "AI": {"tldr": "PRIME\u662f\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528\u903b\u8f91\u7f51\u683c\u8c1c\u9898\u7cfb\u7edf\u6027\u5730\u63a2\u6d4bLLMs\u5728\u903b\u8f91\u63a8\u7406\u548c\u51b3\u7b56\u4e2d\u53d7\u793e\u4f1a\u523b\u677f\u5370\u8c61\u5f71\u54cd\u7684\u7a0b\u5ea6\uff0c\u91cd\u70b9\u5173\u6ce8\u6027\u522b\u523b\u677f\u5370\u8c61\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u62a4\u680f\u80fd\u6709\u6548\u6291\u5236\u660e\u663e\u504f\u89c1\u8f93\u51fa\uff0c\u4f46\u5728\u590d\u6742\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e2d\u66f4\u5fae\u5999\u7684\u793e\u4f1a\u504f\u89c1\u4f1a\u6d6e\u73b0\u4e14\u9003\u907f\u5f53\u524d\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u4f7f\u7528\u903b\u8f91\u7f51\u683c\u8c1c\u9898\u6784\u5efa\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u523b\u677f\u5370\u8c61\u3001\u53cd\u523b\u677f\u5370\u8c61\u548c\u4e2d\u7acb\u53d8\u4f53\uff0c\u81ea\u52a8\u751f\u6210\u548c\u9a8c\u8bc1\uff0c\u6d4b\u8bd5\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u548c\u63d0\u793a\u7f13\u89e3\u7b56\u7565\u3002", "result": "\u6a21\u578b\u5728\u89e3\u51b3\u65b9\u6848\u7b26\u5408\u523b\u677f\u5370\u8c61\u5173\u8054\u65f6\u63a8\u7406\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u8868\u660e\u523b\u677f\u5370\u8c61\u5bf9LLMs\u6f14\u7ece\u63a8\u7406\u7684\u5f71\u54cd\u3002", "conclusion": "PRIME\u5bf9\u4e8e\u8bca\u65ad\u548c\u91cf\u5316LLMs\u6f14\u7ece\u63a8\u7406\u4e2d\u6301\u7eed\u5b58\u5728\u7684\u793e\u4f1a\u504f\u89c1\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u7279\u522b\u662f\u5728\u516c\u5e73\u6027\u81f3\u5173\u91cd\u8981\u7684\u573a\u666f\u4e2d\u3002"}}
{"id": "2511.06168", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06168", "abs": "https://arxiv.org/abs/2511.06168", "authors": ["Boxuan Wang", "Zhuoyun Li", "Xinmiao Huang", "Xiaowei Huang", "Yi Dong"], "title": "Chasing Consistency: Quantifying and Optimizing Human-Model Alignment in Chain-of-Thought Reasoning", "comment": "13 pages, 3 figures", "summary": "This paper presents a framework for evaluating and optimizing reasoning consistency in Large Language Models (LLMs) via a new metric, the Alignment Score, which quantifies the semantic alignment between model-generated reasoning chains and human-written reference chains in Chain-of-Thought (CoT) reasoning. Empirically, we find that 2-hop reasoning chains achieve the highest Alignment Score. To explain this phenomenon, we define four key error types: logical disconnection, thematic shift, redundant reasoning, and causal reversal, and show how each contributes to the degradation of the Alignment Score. Building on this analysis, we further propose Semantic Consistency Optimization Sampling (SCOS), a method that samples and favors chains with minimal alignment errors, significantly improving Alignment Scores by an average of 29.84% with longer reasoning chains, such as in 3-hop tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u548c\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e00\u81f4\u6027\u7684\u6846\u67b6\uff0c\u5305\u62ec\u65b0\u7684\u5bf9\u9f50\u5206\u6570\u6307\u6807\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u4f18\u5316\u91c7\u6837\u65b9\u6cd5\uff0c\u53d1\u73b02\u8df3\u63a8\u7406\u94fe\u5bf9\u9f50\u5206\u6570\u6700\u9ad8\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u957f\u63a8\u7406\u94fe\u7684\u5bf9\u9f50\u5206\u6570\u3002", "motivation": "\u8bc4\u4f30\u548c\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u5728\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u4e2d\u7684\u63a8\u7406\u4e00\u81f4\u6027\uff0c\u89e3\u51b3\u63a8\u7406\u94fe\u4e0e\u4eba\u7c7b\u53c2\u8003\u94fe\u4e4b\u95f4\u7684\u8bed\u4e49\u5bf9\u9f50\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u5bf9\u9f50\u5206\u6570\u6307\u6807\u6765\u91cf\u5316\u63a8\u7406\u94fe\u4e0e\u53c2\u8003\u94fe\u7684\u8bed\u4e49\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u5b9a\u4e49\u4e86\u56db\u79cd\u5173\u952e\u9519\u8bef\u7c7b\u578b\uff0c\u5e76\u5f00\u53d1\u4e86\u8bed\u4e49\u4e00\u81f4\u6027\u4f18\u5316\u91c7\u6837\u65b9\u6cd5\u6765\u9009\u62e9\u5bf9\u9f50\u9519\u8bef\u6700\u5c0f\u7684\u63a8\u7406\u94fe\u3002", "result": "\u5b9e\u8bc1\u53d1\u73b02\u8df3\u63a8\u7406\u94fe\u5bf9\u9f50\u5206\u6570\u6700\u9ad8\uff0c\u8bed\u4e49\u4e00\u81f4\u6027\u4f18\u5316\u91c7\u6837\u65b9\u6cd5\u5e73\u5747\u63d0\u5347\u5bf9\u9f50\u5206\u657029.84%\uff0c\u57283\u8df3\u4efb\u52a1\u7b49\u957f\u63a8\u7406\u94fe\u4e2d\u6548\u679c\u663e\u8457\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u8bc4\u4f30\u548c\u4f18\u5316\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u4e00\u81f4\u6027\uff0c\u8bed\u4e49\u4e00\u81f4\u6027\u4f18\u5316\u91c7\u6837\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347\u957f\u63a8\u7406\u94fe\u7684\u5bf9\u9f50\u5206\u6570\uff0c\u4e3a\u6539\u8fdb\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2511.06175", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.06175", "abs": "https://arxiv.org/abs/2511.06175", "authors": ["Kaijie Xu", "Fandi Meng", "Clark Verbrugge", "Simon Lucas"], "title": "CSP4SDG: Constraint and Information-Theory Based Role Identification in Social Deduction Games with LLM-Enhanced Inference", "comment": null, "summary": "In Social Deduction Games (SDGs) such as Avalon, Mafia, and Werewolf, players conceal their identities and deliberately mislead others, making hidden-role inference a central and demanding task. Accurate role identification, which forms the basis of an agent's belief state, is therefore the keystone for both human and AI performance. We introduce CSP4SDG, a probabilistic, constraint-satisfaction framework that analyses gameplay objectively. Game events and dialogue are mapped to four linguistically-agnostic constraint classes-evidence, phenomena, assertions, and hypotheses. Hard constraints prune impossible role assignments, while weighted soft constraints score the remainder; information-gain weighting links each hypothesis to its expected value under entropy reduction, and a simple closed-form scoring rule guarantees that truthful assertions converge to classical hard logic with minimum error. The resulting posterior over roles is fully interpretable and updates in real time. Experiments on three public datasets show that CSP4SDG (i) outperforms LLM-based baselines in every inference scenario, and (ii) boosts LLMs when supplied as an auxiliary \"reasoning tool.\" Our study validates that principled probabilistic reasoning with information theory is a scalable alternative-or complement-to heavy-weight neural models for SDGs.", "AI": {"tldr": "CSP4SDG\u662f\u4e00\u4e2a\u57fa\u4e8e\u7ea6\u675f\u6ee1\u8db3\u7684\u6982\u7387\u63a8\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u4e2d\u9690\u85cf\u89d2\u8272\u63a8\u65ad\uff0c\u901a\u8fc7\u786c\u7ea6\u675f\u548c\u8f6f\u7ea6\u675f\u5206\u6790\u6e38\u620f\u4e8b\u4ef6\u548c\u5bf9\u8bdd\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8eLLM\u57fa\u51c6\u65b9\u6cd5\u3002", "motivation": "\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u4e2d\u73a9\u5bb6\u9690\u85cf\u8eab\u4efd\u5e76\u6545\u610f\u8bef\u5bfc\u4ed6\u4eba\uff0c\u51c6\u786e\u7684\u89d2\u8272\u8bc6\u522b\u662f\u6e38\u620f\u8868\u73b0\u7684\u5173\u952e\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u5c06\u6e38\u620f\u4e8b\u4ef6\u548c\u5bf9\u8bdd\u6620\u5c04\u5230\u56db\u4e2a\u8bed\u8a00\u65e0\u5173\u7684\u7ea6\u675f\u7c7b\u522b\uff08\u8bc1\u636e\u3001\u73b0\u8c61\u3001\u65ad\u8a00\u3001\u5047\u8bbe\uff09\uff0c\u4f7f\u7528\u786c\u7ea6\u675f\u4fee\u526a\u4e0d\u53ef\u80fd\u89d2\u8272\u5206\u914d\uff0c\u52a0\u6743\u8f6f\u7ea6\u675f\u5bf9\u5269\u4f59\u5206\u914d\u8bc4\u5206\uff0c\u4fe1\u606f\u589e\u76ca\u6743\u91cd\u5c06\u6bcf\u4e2a\u5047\u8bbe\u4e0e\u5176\u5728\u71b5\u51cf\u5c11\u4e0b\u7684\u671f\u671b\u503c\u8054\u7cfb\u8d77\u6765\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCSP4SDG\u5728\u6240\u6709\u63a8\u7406\u573a\u666f\u4e2d\u90fd\u4f18\u4e8e\u57fa\u4e8eLLM\u7684\u57fa\u51c6\u65b9\u6cd5\uff0c\u5e76\u4e14\u4f5c\u4e3a\u8f85\u52a9\"\u63a8\u7406\u5de5\u5177\"\u53ef\u4ee5\u63d0\u5347LLM\u6027\u80fd\u3002", "conclusion": "\u57fa\u4e8e\u4fe1\u606f\u7406\u8bba\u7684\u539f\u5219\u6027\u6982\u7387\u63a8\u7406\u662f\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u4e2d\u91cd\u578b\u795e\u7ecf\u6a21\u578b\u7684\u53ef\u6269\u5c55\u66ff\u4ee3\u6216\u8865\u5145\u65b9\u6848\u3002"}}
{"id": "2511.06185", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06185", "abs": "https://arxiv.org/abs/2511.06185", "authors": ["Xinyuan Wang", "Yanjie Fu"], "title": "Dataforge: A Data Agent Platform for Autonomous Data Engineering", "comment": null, "summary": "The growing demand for AI applications in fields such as materials discovery, molecular modeling, and climate science has made data preparation an important but labor-intensive step. Raw data from diverse sources must be cleaned, normalized, and transformed to become AI-ready, while effective feature transformation and selection are essential for efficient training and inference. To address the challenges of scalability and expertise dependence, we present Data Agent, a fully autonomous system specialized for tabular data. Leveraging large language model (LLM) reasoning and grounded validation, Data Agent automatically performs data cleaning, hierarchical routing, and feature-level optimization through dual feedback loops. It embodies three core principles: automatic, safe, and non-expert friendly, which ensure end-to-end reliability without human supervision. This demo showcases the first practical realization of an autonomous Data Agent, illustrating how raw data can be transformed \"From Data to Better Data.\"", "AI": {"tldr": "Data Agent\u662f\u4e00\u4e2a\u5b8c\u5168\u81ea\u4e3b\u7684\u8868\u683c\u6570\u636e\u5904\u7406\u7cfb\u7edf\uff0c\u5229\u7528LLM\u63a8\u7406\u548c\u9a8c\u8bc1\u6765\u81ea\u52a8\u6267\u884c\u6570\u636e\u6e05\u6d17\u3001\u5206\u5c42\u8def\u7531\u548c\u7279\u5f81\u7ea7\u4f18\u5316\uff0c\u5b9e\u73b0\u4ece\u539f\u59cb\u6570\u636e\u5230AI\u5c31\u7eea\u6570\u636e\u7684\u7aef\u5230\u7aef\u8f6c\u6362\u3002", "motivation": "AI\u5e94\u7528\u5728\u6750\u6599\u53d1\u73b0\u3001\u5206\u5b50\u5efa\u6a21\u548c\u6c14\u5019\u79d1\u5b66\u7b49\u9886\u57df\u7684\u9700\u6c42\u589e\u957f\uff0c\u4f7f\u5f97\u6570\u636e\u51c6\u5907\u6210\u4e3a\u91cd\u8981\u4f46\u52b3\u52a8\u5bc6\u96c6\u7684\u6b65\u9aa4\uff0c\u9700\u8981\u89e3\u51b3\u53ef\u6269\u5c55\u6027\u548c\u4e13\u4e1a\u77e5\u8bc6\u4f9d\u8d56\u7684\u6311\u6218\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u548c\u57fa\u4e8e\u9a8c\u8bc1\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cc\u53cd\u9988\u5faa\u73af\u81ea\u52a8\u6267\u884c\u6570\u636e\u6e05\u6d17\u3001\u5206\u5c42\u8def\u7531\u548c\u7279\u5f81\u7ea7\u4f18\u5316\uff0c\u9075\u5faa\u81ea\u52a8\u3001\u5b89\u5168\u548c\u975e\u4e13\u5bb6\u53cb\u597d\u7684\u6838\u5fc3\u539f\u5219\u3002", "result": "\u5c55\u793a\u4e86\u7b2c\u4e00\u4e2a\u5b9e\u7528\u7684\u81ea\u4e3b\u6570\u636e\u4ee3\u7406\u7cfb\u7edf\uff0c\u80fd\u591f\u5c06\u539f\u59cb\u6570\u636e\u8f6c\u6362\u4e3a\u66f4\u597d\u7684\u6570\u636e\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u53ef\u9760\u6027\u800c\u65e0\u9700\u4eba\u5de5\u76d1\u7763\u3002", "conclusion": "Data Agent\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u4e86\u4ece\u6570\u636e\u5230\u66f4\u597d\u6570\u636e\u7684\u81ea\u4e3b\u8f6c\u6362\uff0c\u4e3aAI\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u975e\u4e13\u5bb6\u53cb\u597d\u7684\u6570\u636e\u51c6\u5907\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.06209", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06209", "abs": "https://arxiv.org/abs/2511.06209", "authors": ["Jingwei Ni", "Ekaterina Fadeeva", "Tianyi Wu", "Mubashara Akhtar", "Jiaheng Zhang", "Elliott Ash", "Markus Leippold", "Timothy Baldwin", "See-Kiong Ng", "Artem Shelmanov", "Mrinmaya Sachan"], "title": "Reasoning with Confidence: Efficient Verification of LLM Reasoning Steps via Uncertainty Heads", "comment": "Preprint under review", "summary": "Solving complex tasks usually requires LLMs to generate long multi-step reasoning chains. Previous work has shown that verifying the correctness of individual reasoning steps can further improve the performance and efficiency of LLMs on such tasks and enhance solution interpretability. However, existing verification approaches, such as Process Reward Models (PRMs), are either computationally expensive, limited to specific domains, or require large-scale human or model-generated annotations. Thus, we propose a lightweight alternative for step-level reasoning verification based on data-driven uncertainty scores. We train transformer-based uncertainty quantification heads (UHeads) that use the internal states of a frozen LLM to estimate the uncertainty of its reasoning steps during generation. The approach is fully automatic: target labels are generated either by another larger LLM (e.g., DeepSeek R1) or in a self-supervised manner by the original model itself. UHeads are both effective and lightweight, containing less than 10M parameters. Across multiple domains, including mathematics, planning, and general knowledge question answering, they match or even surpass the performance of PRMs that are up to 810x larger. Our findings suggest that the internal states of LLMs encode their uncertainty and can serve as reliable signals for reasoning verification, offering a promising direction toward scalable and generalizable introspective LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u4e0d\u786e\u5b9a\u6027\u5206\u6570\u7684\u8f7b\u91cf\u7ea7\u63a8\u7406\u6b65\u9aa4\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u4f7f\u7528\u51bb\u7ed3LLM\u5185\u90e8\u72b6\u6001\u8bad\u7ec3\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5934\u6765\u4f30\u8ba1\u63a8\u7406\u6b65\u9aa4\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u591a\u4e2a\u9886\u57df\u5339\u914d\u6216\u8d85\u8d8a\u66f4\u5927\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u9a8c\u8bc1\u65b9\u6cd5\u5982\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u9886\u57df\u53d7\u9650\u6216\u9700\u8981\u5927\u89c4\u6a21\u4eba\u5de5\u6807\u6ce8\uff0c\u9700\u8981\u66f4\u8f7b\u91cf\u3001\u901a\u7528\u7684\u63a8\u7406\u9a8c\u8bc1\u65b9\u6848\u3002", "method": "\u8bad\u7ec3\u57fa\u4e8etransformer\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5934\uff0c\u5229\u7528\u51bb\u7ed3LLM\u7684\u5185\u90e8\u72b6\u6001\u6765\u4f30\u8ba1\u63a8\u7406\u6b65\u9aa4\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u76ee\u6807\u6807\u7b7e\u7531\u66f4\u5927LLM\u6216\u539f\u59cb\u6a21\u578b\u81ea\u76d1\u7763\u751f\u6210\u3002", "result": "UHeads\u5728\u6570\u5b66\u3001\u89c4\u5212\u548c\u5e38\u8bc6\u95ee\u7b54\u7b49\u591a\u4e2a\u9886\u57df\u5339\u914d\u6216\u8d85\u8d8a\u6bd4\u5176\u5927810\u500d\u7684\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u6027\u80fd\uff0c\u53c2\u6570\u5c11\u4e8e1000\u4e07\u3002", "conclusion": "LLM\u5185\u90e8\u72b6\u6001\u7f16\u7801\u4e86\u5176\u4e0d\u786e\u5b9a\u6027\uff0c\u53ef\u4f5c\u4e3a\u53ef\u9760\u7684\u63a8\u7406\u9a8c\u8bc1\u4fe1\u53f7\uff0c\u4e3a\u53ef\u6269\u5c55\u548c\u6cdb\u5316\u7684\u5185\u7701LLM\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2511.06221", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06221", "abs": "https://arxiv.org/abs/2511.06221", "authors": ["Sen Xu", "Yi Zhou", "Wei Wang", "Jixin Min", "Zhibin Yin", "Yingwei Dai", "Shixi Liu", "Lianyu Pang", "Yirong Chen", "Junlin Zhang"], "title": "Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B", "comment": null, "summary": "Challenging the prevailing consensus that small models inherently lack robust reasoning, this report introduces VibeThinker-1.5B, a 1.5B-parameter dense model developed via our Spectrum-to-Signal Principle (SSP). This challenges the prevailing approach of scaling model parameters to enhance capabilities, as seen in models like DeepSeek R1 (671B) and Kimi k2 (>1T). The SSP framework first employs a Two-Stage Diversity-Exploring Distillation (SFT) to generate a broad spectrum of solutions, followed by MaxEnt-Guided Policy Optimization (RL) to amplify the correct signal. With a total training cost of only $7,800, VibeThinker-1.5B demonstrates superior reasoning capabilities compared to closed-source models like Magistral Medium and Claude Opus 4, and performs on par with open-source models like GPT OSS-20B Medium. Remarkably, it surpasses the 400x larger DeepSeek R1 on three math benchmarks: AIME24 (80.3 vs. 79.8), AIME25 (74.4 vs. 70.0), and HMMT25 (50.4 vs. 41.7). This is a substantial improvement over its base model (6.7, 4.3, and 0.6, respectively). On LiveCodeBench V6, it scores 51.1, outperforming Magistral Medium's 50.3 and its base model's 0.0. These findings demonstrate that small models can achieve reasoning capabilities comparable to large models, drastically reducing training and inference costs and thereby democratizing advanced AI research.", "AI": {"tldr": "VibeThinker-1.5B\u662f\u4e00\u4e2a1.5B\u53c2\u6570\u7684\u5bc6\u96c6\u6a21\u578b\uff0c\u901a\u8fc7Spectrum-to-Signal Principle (SSP)\u6846\u67b6\u5f00\u53d1\uff0c\u6311\u6218\u4e86\u6a21\u578b\u53c2\u6570\u89c4\u6a21\u51b3\u5b9a\u63a8\u7406\u80fd\u529b\u7684\u5171\u8bc6\u3002\u8be5\u6a21\u578b\u4ee5\u4ec57,800\u7f8e\u5143\u7684\u8bad\u7ec3\u6210\u672c\uff0c\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86400\u500d\u5927\u7684DeepSeek R1\uff0c\u5e76\u5728\u63a8\u7406\u80fd\u529b\u4e0a\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\u3002", "motivation": "\u6311\u6218\u5f53\u524d\u5171\u8bc6\uff0c\u5373\u5c0f\u6a21\u578b\u7f3a\u4e4f\u5f3a\u5927\u63a8\u7406\u80fd\u529b\uff0c\u8bc1\u660e\u901a\u8fc7\u9ad8\u6548\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5c0f\u6a21\u578b\u4e5f\u80fd\u8fbe\u5230\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4ece\u800c\u5927\u5e45\u964d\u4f4e\u8bad\u7ec3\u548c\u63a8\u7406\u6210\u672c\uff0c\u4f7f\u5148\u8fdbAI\u7814\u7a76\u6c11\u4e3b\u5316\u3002", "method": "\u91c7\u7528Spectrum-to-Signal Principle (SSP)\u6846\u67b6\uff1a1) Two-Stage Diversity-Exploring Distillation (SFT)\u751f\u6210\u5e7f\u6cdb\u89e3\u51b3\u65b9\u6848\u8c31\uff1b2) MaxEnt-Guided Policy Optimization (RL)\u653e\u5927\u6b63\u786e\u4fe1\u53f7\u3002", "result": "\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u8d85\u8d8a\u5927\u578b\u6a21\u578b\uff1aAIME24 (80.3 vs. 79.8)\u3001AIME25 (74.4 vs. 70.0)\u3001HMMT25 (50.4 vs. 41.7)\uff0c\u4f18\u4e8eDeepSeek R1\uff1b\u5728LiveCodeBench V6\u4e0a\u5f97\u5206\u4e3a51.1\uff0c\u4f18\u4e8eMagistral Medium\u768450.3\u3002\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u6709\u5de8\u5927\u63d0\u5347\u3002", "conclusion": "\u5c0f\u6a21\u578b\u901a\u8fc7\u9ad8\u6548\u8bad\u7ec3\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5927\u5e45\u964d\u4f4eAI\u7814\u7a76\u548c\u90e8\u7f72\u6210\u672c\uff0c\u4e3aAI\u6c11\u4e3b\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2511.06226", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06226", "abs": "https://arxiv.org/abs/2511.06226", "authors": ["Xingcheng Liu", "Yanchen Guan", "Haicheng Liao", "Zhengbing He", "Zhenning Li"], "title": "ROAR: Robust Accident Recognition and Anticipation for Autonomous Driving", "comment": "Published to Accident Analysis and Prevention", "summary": "Accurate accident anticipation is essential for enhancing the safety of autonomous vehicles (AVs). However, existing methods often assume ideal conditions, overlooking challenges such as sensor failures, environmental disturbances, and data imperfections, which can significantly degrade prediction accuracy. Additionally, previous models have not adequately addressed the considerable variability in driver behavior and accident rates across different vehicle types. To overcome these limitations, this study introduces ROAR, a novel approach for accident detection and prediction. ROAR combines Discrete Wavelet Transform (DWT), a self adaptive object aware module, and dynamic focal loss to tackle these challenges. The DWT effectively extracts features from noisy and incomplete data, while the object aware module improves accident prediction by focusing on high-risk vehicles and modeling the spatial temporal relationships among traffic agents. Moreover, dynamic focal loss mitigates the impact of class imbalance between positive and negative samples. Evaluated on three widely used datasets, Dashcam Accident Dataset (DAD), Car Crash Dataset (CCD), and AnAn Accident Detection (A3D), our model consistently outperforms existing baselines in key metrics such as Average Precision (AP) and mean Time to Accident (mTTA). These results demonstrate the model's robustness in real-world conditions, particularly in handling sensor degradation, environmental noise, and imbalanced data distributions. This work offers a promising solution for reliable and accurate accident anticipation in complex traffic environments.", "AI": {"tldr": "ROAR\u662f\u4e00\u79cd\u65b0\u9896\u7684\u4e8b\u6545\u68c0\u6d4b\u548c\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u3001\u81ea\u9002\u5e94\u76ee\u6807\u611f\u77e5\u6a21\u5757\u548c\u52a8\u6001\u7126\u70b9\u635f\u5931\uff0c\u6709\u6548\u5904\u7406\u4f20\u611f\u5668\u6545\u969c\u3001\u73af\u5883\u566a\u58f0\u548c\u6570\u636e\u4e0d\u5e73\u8861\u7b49\u73b0\u5b9e\u6311\u6218\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4e8b\u6545\u9884\u6d4b\u65b9\u6cd5\u5f80\u5f80\u5047\u8bbe\u7406\u60f3\u6761\u4ef6\uff0c\u5ffd\u7565\u4e86\u4f20\u611f\u5668\u6545\u969c\u3001\u73af\u5883\u5e72\u6270\u548c\u6570\u636e\u7f3a\u9677\u7b49\u73b0\u5b9e\u6311\u6218\uff0c\u4e14\u672a\u80fd\u5145\u5206\u5904\u7406\u4e0d\u540c\u8f66\u8f86\u7c7b\u578b\u95f4\u9a7e\u9a76\u5458\u884c\u4e3a\u548c\u4e8b\u6545\u7387\u7684\u663e\u8457\u5dee\u5f02\u3002", "method": "ROAR\u7ed3\u5408\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u4ece\u566a\u58f0\u548c\u4e0d\u5b8c\u6574\u6570\u636e\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u4f7f\u7528\u81ea\u9002\u5e94\u76ee\u6807\u611f\u77e5\u6a21\u5757\u805a\u7126\u9ad8\u98ce\u9669\u8f66\u8f86\u5e76\u5efa\u6a21\u4ea4\u901a\u53c2\u4e0e\u8005\u7684\u65f6\u7a7a\u5173\u7cfb\uff0c\u91c7\u7528\u52a8\u6001\u7126\u70b9\u635f\u5931\u7f13\u89e3\u6b63\u8d1f\u6837\u672c\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "\u5728Dashcam Accident Dataset\u3001Car Crash Dataset\u548cAnAn Accident Detection\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cROAR\u5728\u5e73\u5747\u7cbe\u5ea6\u548c\u5e73\u5747\u4e8b\u6545\u65f6\u95f4\u7b49\u5173\u952e\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u4f20\u611f\u5668\u9000\u5316\u3001\u73af\u5883\u566a\u58f0\u548c\u4e0d\u5e73\u8861\u6570\u636e\u5206\u5e03\u65b9\u9762\uff0c\u4e3a\u590d\u6742\u4ea4\u901a\u73af\u5883\u4e2d\u7684\u53ef\u9760\u4e8b\u6545\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.06262", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06262", "abs": "https://arxiv.org/abs/2511.06262", "authors": ["Siming Zhao", "Qi Li"], "title": "GAIA: A General Agency Interaction Architecture for LLM-Human B2B Negotiation & Screening", "comment": null, "summary": "Organizations are increasingly exploring delegation of screening and negotiation tasks to AI systems, yet deployment in high-stakes B2B settings is constrained by governance: preventing unauthorized commitments, ensuring sufficient information before bargaining, and maintaining effective human oversight and auditability. Prior work on large language model negotiation largely emphasizes autonomous bargaining between agents and omits practical needs such as staged information gathering, explicit authorization boundaries, and systematic feedback integration. We propose GAIA, a governance-first framework for LLM-human agency in B2B negotiation and screening. GAIA defines three essential roles - Principal (human), Delegate (LLM agent), and Counterparty - with an optional Critic to enhance performance, and organizes interactions through three mechanisms: information-gated progression that separates screening from negotiation; dual feedback integration that combines AI critique with lightweight human corrections; and authorization boundaries with explicit escalation paths. Our contributions are fourfold: (1) a formal governance framework with three coordinated mechanisms and four safety invariants for delegation with bounded authorization; (2) information-gated progression via task-completeness tracking (TCI) and explicit state transitions that separate screening from commitment; (3) dual feedback integration that blends Critic suggestions with human oversight through parallel learning channels; and (4) a hybrid validation blueprint that combines automated protocol metrics with human judgment of outcomes and safety. By bridging theory and practice, GAIA offers a reproducible specification for safe, efficient, and accountable AI delegation that can be instantiated across procurement, real estate, and staffing workflows.", "AI": {"tldr": "GAIA\u662f\u4e00\u4e2a\u9762\u5411B2B\u8c08\u5224\u548c\u7b5b\u9009\u7684\u6cbb\u7406\u4f18\u5148\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u606f\u95e8\u63a7\u8fdb\u5c55\u3001\u53cc\u91cd\u53cd\u9988\u96c6\u6210\u548c\u6388\u6743\u8fb9\u754c\u4e09\u5927\u673a\u5236\uff0c\u786e\u4fddAI\u59d4\u6258\u5728\u91c7\u8d2d\u3001\u623f\u5730\u4ea7\u548c\u4eba\u529b\u8d44\u6e90\u7b49\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u7684\u5b89\u5168\u6027\u3001\u6548\u7387\u548c\u53ef\u5ba1\u8ba1\u6027\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u5728\u9ad8\u98ce\u9669B2B\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u53d7\u5230\u6cbb\u7406\u7ea6\u675f\uff0c\u5305\u62ec\u9632\u6b62\u672a\u7ecf\u6388\u6743\u7684\u627f\u8bfa\u3001\u786e\u4fdd\u5145\u5206\u4fe1\u606f\u6536\u96c6\u4ee5\u53ca\u7ef4\u6301\u6709\u6548\u7684\u4eba\u7c7b\u76d1\u7763\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u81ea\u4e3b\u8c08\u5224\uff0c\u5ffd\u7565\u4e86\u5206\u9636\u6bb5\u4fe1\u606f\u6536\u96c6\u3001\u660e\u786e\u6388\u6743\u8fb9\u754c\u548c\u7cfb\u7edf\u53cd\u9988\u96c6\u6210\u7b49\u5b9e\u9645\u9700\u6c42\u3002", "method": "GAIA\u5b9a\u4e49\u4e86\u59d4\u6258\u4eba\uff08\u4eba\u7c7b\uff09\u3001\u4ee3\u7406\u4eba\uff08LLM\u4ee3\u7406\uff09\u548c\u5bf9\u624b\u65b9\u4e09\u4e2a\u6838\u5fc3\u89d2\u8272\uff0c\u4ee5\u53ca\u53ef\u9009\u7684\u6279\u8bc4\u8005\u89d2\u8272\u3002\u901a\u8fc7\u4e09\u5927\u673a\u5236\u5b9e\u73b0\uff1a\u4fe1\u606f\u95e8\u63a7\u8fdb\u5c55\uff08\u5206\u79bb\u7b5b\u9009\u4e0e\u8c08\u5224\uff09\u3001\u53cc\u91cd\u53cd\u9988\u96c6\u6210\uff08AI\u6279\u8bc4\u4e0e\u4eba\u5de5\u4fee\u6b63\u7ed3\u5408\uff09\u3001\u6388\u6743\u8fb9\u754c\u4e0e\u660e\u786e\u5347\u7ea7\u8def\u5f84\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6b63\u5f0f\u7684\u6cbb\u7406\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u5b89\u5168\u4e0d\u53d8\u91cf\uff1a\u4efb\u52a1\u5b8c\u6574\u6027\u8ddf\u8e2a\uff08TCI\uff09\u3001\u660e\u786e\u72b6\u6001\u8f6c\u6362\u3001\u5e76\u884c\u5b66\u4e60\u6e20\u9053\u7684\u53cd\u9988\u96c6\u6210\uff0c\u4ee5\u53ca\u7ed3\u5408\u81ea\u52a8\u5316\u534f\u8bae\u6307\u6807\u4e0e\u4eba\u5de5\u5224\u65ad\u7684\u6df7\u5408\u9a8c\u8bc1\u84dd\u56fe\u3002", "conclusion": "GAIA\u901a\u8fc7\u8fde\u63a5\u7406\u8bba\u4e0e\u5b9e\u8df5\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u89c4\u8303\uff0c\u7528\u4e8e\u5b9e\u73b0\u5b89\u5168\u3001\u9ad8\u6548\u548c\u53ef\u95ee\u8d23\u7684AI\u59d4\u6258\uff0c\u53ef\u5e94\u7528\u4e8e\u91c7\u8d2d\u3001\u623f\u5730\u4ea7\u548c\u4eba\u529b\u8d44\u6e90\u7b49\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2511.06292", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06292", "abs": "https://arxiv.org/abs/2511.06292", "authors": ["Yaoning Yu", "Kaimin Chang", "Ye Yu", "Kai Wei", "Haojing Luo", "Haohan Wang"], "title": "Synthetic Data-Driven Prompt Tuning for Financial QA over Tables and Documents", "comment": null, "summary": "Financial documents like earning reports or balance sheets often involve long tables and multi-page reports. Large language models have become a new tool to help numerical reasoning and understanding these documents. However, prompt quality can have a major effect on how well LLMs perform these financial reasoning tasks. Most current methods tune prompts on fixed datasets of financial text or tabular data, which limits their ability to adapt to new question types or document structures, or they involve costly and manually labeled/curated dataset to help build the prompts. We introduce a self-improving prompt framework driven by data-augmented optimization. In this closed-loop process, we generate synthetic financial tables and document excerpts, verify their correctness and robustness, and then update the prompt based on the results. Specifically, our framework combines a synthetic data generator with verifiers and a prompt optimizer, where the generator produces new examples that exposes weaknesses in the current prompt, the verifiers check the validity and robustness of the produced examples, and the optimizer incrementally refines the prompt in response. By iterating these steps in a feedback cycle, our method steadily improves prompt accuracy on financial reasoning tasks without needing external labels. Evaluation on DocMath-Eval benchmark demonstrates that our system achieves higher performance in both accuracy and robustness than standard prompt methods, underscoring the value of incorporating synthetic data generation into prompt learning for financial applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6570\u636e\u589e\u5f3a\u4f18\u5316\u7684\u81ea\u6539\u8fdb\u63d0\u793a\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u5408\u6210\u91d1\u878d\u8868\u683c\u548c\u6587\u6863\u6458\u5f55\u3001\u9a8c\u8bc1\u5176\u6b63\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u7136\u540e\u6839\u636e\u7ed3\u679c\u66f4\u65b0\u63d0\u793a\uff0c\u4ece\u800c\u5728\u4e0d\u9700\u8981\u5916\u90e8\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\u6301\u7eed\u6539\u8fdb\u91d1\u878d\u63a8\u7406\u4efb\u52a1\u7684\u63d0\u793a\u51c6\u786e\u6027\u3002", "motivation": "\u91d1\u878d\u6587\u6863\u901a\u5e38\u5305\u542b\u957f\u8868\u683c\u548c\u591a\u9875\u62a5\u544a\uff0cLLMs\u5df2\u6210\u4e3a\u5e2e\u52a9\u6570\u503c\u63a8\u7406\u548c\u7406\u89e3\u8fd9\u4e9b\u6587\u6863\u7684\u65b0\u5de5\u5177\uff0c\u4f46\u63d0\u793a\u8d28\u91cf\u5bf9LLMs\u6027\u80fd\u6709\u91cd\u5927\u5f71\u54cd\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u56fa\u5b9a\u6570\u636e\u96c6\u4e0a\u8c03\u6574\u63d0\u793a\uff0c\u9650\u5236\u4e86\u9002\u5e94\u65b0\u95ee\u9898\u7c7b\u578b\u6216\u6587\u6863\u7ed3\u6784\u7684\u80fd\u529b\uff0c\u6216\u9700\u8981\u6602\u8d35\u7684\u624b\u52a8\u6807\u6ce8\u6570\u636e\u96c6\u3002", "method": "\u7ed3\u5408\u5408\u6210\u6570\u636e\u751f\u6210\u5668\u3001\u9a8c\u8bc1\u5668\u548c\u63d0\u793a\u4f18\u5316\u5668\u7684\u95ed\u73af\u6846\u67b6\u3002\u751f\u6210\u5668\u4ea7\u751f\u66b4\u9732\u5f53\u524d\u63d0\u793a\u5f31\u70b9\u7684\u793a\u4f8b\uff0c\u9a8c\u8bc1\u5668\u68c0\u67e5\u751f\u6210\u793a\u4f8b\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4f18\u5316\u5668\u6839\u636e\u7ed3\u679c\u9010\u6b65\u4f18\u5316\u63d0\u793a\u3002", "result": "\u5728DocMath-Eval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u7cfb\u7edf\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u6807\u51c6\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "\u5c06\u5408\u6210\u6570\u636e\u751f\u6210\u878d\u5165\u63d0\u793a\u5b66\u4e60\u5bf9\u91d1\u878d\u5e94\u7528\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u80fd\u591f\u5728\u65e0\u9700\u5916\u90e8\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\u6301\u7eed\u6539\u8fdb\u63d0\u793a\u6027\u80fd\u3002"}}
{"id": "2511.06301", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06301", "abs": "https://arxiv.org/abs/2511.06301", "authors": ["Azanzi Jiomekong", "Jean Bikim", "Patricia Negoue", "Joyce Chin"], "title": "Secu-Table: a Comprehensive security table dataset for evaluating semantic table interpretation systems", "comment": "Submitted to Nature Scientific Data", "summary": "Evaluating semantic tables interpretation (STI) systems, (particularly, those based on Large Language Models- LLMs) especially in domain-specific contexts such as the security domain, depends heavily on the dataset. However, in the security domain, tabular datasets for state-of-the-art are not publicly available. In this paper, we introduce Secu-Table dataset, composed of more than 1500 tables with more than 15k entities constructed using security data extracted from Common Vulnerabilities and Exposures (CVE) and Common Weakness Enumeration (CWE) data sources and annotated using Wikidata and the SEmantic Processing of Security Event Streams CyberSecurity Knowledge Graph (SEPSES CSKG). Along with the dataset, all the code is publicly released. This dataset is made available to the research community in the context of the SemTab challenge on Tabular to Knowledge Graph Matching. This challenge aims to evaluate the performance of several STI based on open source LLMs. Preliminary evaluation, serving as baseline, was conducted using Falcon3-7b-instruct and Mistral-7B-Instruct, two open source LLMs and GPT-4o mini one closed source LLM.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Secu-Table\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u4e00\u4e2a\u5305\u542b1500\u591a\u4e2a\u8868\u683c\u548c15k+\u5b9e\u4f53\u7684\u5b89\u5168\u9886\u57df\u8868\u683c\u6570\u636e\u96c6\uff0c\u57fa\u4e8eCVE\u548cCWE\u6570\u636e\u6784\u5efa\uff0c\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8eLLM\u7684\u8bed\u4e49\u8868\u683c\u89e3\u91ca\u7cfb\u7edf\u3002", "motivation": "\u5728\u5b89\u5168\u9886\u57df\uff0c\u7528\u4e8e\u8bc4\u4f30\u8bed\u4e49\u8868\u683c\u89e3\u91ca\u7cfb\u7edf\u7684\u8868\u683c\u6570\u636e\u96c6\u5c1a\u672a\u516c\u5f00\u53ef\u7528\uff0c\u8fd9\u9650\u5236\u4e86\u76f8\u5173\u7814\u7a76\u7684\u8fdb\u5c55\u3002", "method": "\u4eceCVE\u548cCWE\u6570\u636e\u6e90\u63d0\u53d6\u5b89\u5168\u6570\u636e\u6784\u5efa\u8868\u683c\uff0c\u4f7f\u7528Wikidata\u548cSEPSES CSKG\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u6807\u6ce8\uff0c\u5e76\u516c\u5f00\u53d1\u5e03\u6570\u636e\u96c6\u548c\u4ee3\u7801\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b1500\u591a\u4e2a\u8868\u683c\u548c15k+\u5b9e\u4f53\u7684Secu-Table\u6570\u636e\u96c6\uff0c\u5e76\u8fdb\u884c\u4e86\u521d\u6b65\u8bc4\u4f30\uff0c\u4f7f\u7528Falcon3-7b-instruct\u3001Mistral-7B-Instruct\u548cGPT-4o mini\u4f5c\u4e3a\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "Secu-Table\u6570\u636e\u96c6\u586b\u8865\u4e86\u5b89\u5168\u9886\u57df\u8868\u683c\u6570\u636e\u96c6\u7684\u7a7a\u767d\uff0c\u4e3aSemTab\u6311\u6218\u8d5b\u63d0\u4f9b\u4e86\u8bc4\u4f30\u57fa\u51c6\uff0c\u4fc3\u8fdb\u4e86\u57fa\u4e8e\u5f00\u6e90LLM\u7684\u8bed\u4e49\u8868\u683c\u89e3\u91ca\u7cfb\u7edf\u7814\u7a76\u3002"}}
{"id": "2511.06309", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.06309", "abs": "https://arxiv.org/abs/2511.06309", "authors": ["Stephen Chung", "Wenyu Du"], "title": "The Station: An Open-World Environment for AI-Driven Discovery", "comment": "54 pages", "summary": "We introduce the STATION, an open-world multi-agent environment that models a miniature scientific ecosystem. Leveraging their extended context windows, agents in the Station can engage in long scientific journeys that include reading papers from peers, formulating hypotheses, submitting code, performing analyses, and publishing results. Importantly, there is no centralized system coordinating their activities - agents are free to choose their own actions and develop their own narratives within the Station. Experiments demonstrate that AI agents in the Station achieve new state-of-the-art performance on a wide range of benchmarks, spanning from mathematics to computational biology to machine learning, notably surpassing AlphaEvolve in circle packing. A rich tapestry of narratives emerges as agents pursue independent research, interact with peers, and build upon a cumulative history. From these emergent narratives, novel methods arise organically, such as a new density-adaptive algorithm for scRNA-seq batch integration. The Station marks a first step towards autonomous scientific discovery driven by emergent behavior in an open-world environment, representing a new paradigm that moves beyond rigid optimization.", "AI": {"tldr": "STATION\u662f\u4e00\u4e2a\u5f00\u653e\u4e16\u754c\u7684\u591a\u667a\u80fd\u4f53\u73af\u5883\uff0c\u6a21\u62df\u5fae\u578b\u79d1\u5b66\u751f\u6001\u7cfb\u7edf\uff0c\u667a\u80fd\u4f53\u53ef\u4ee5\u8fdb\u884c\u957f\u671f\u79d1\u5b66\u7814\u7a76\u6d3b\u52a8\uff0c\u5305\u62ec\u9605\u8bfb\u8bba\u6587\u3001\u63d0\u51fa\u5047\u8bbe\u3001\u63d0\u4ea4\u4ee3\u7801\u3001\u5206\u6790\u6570\u636e\u548c\u53d1\u8868\u6210\u679c\uff0c\u65e0\u9700\u4e2d\u592e\u534f\u8c03\u3002", "motivation": "\u521b\u5efa\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\u7684\u65b0\u8303\u5f0f\uff0c\u8d85\u8d8a\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u7684\u6d8c\u73b0\u884c\u4e3a\u63a8\u52a8\u79d1\u5b66\u7814\u7a76\u3002", "method": "\u5229\u7528\u6269\u5c55\u4e0a\u4e0b\u6587\u7a97\u53e3\uff0c\u8ba9AI\u667a\u80fd\u4f53\u5728STATION\u73af\u5883\u4e2d\u81ea\u7531\u9009\u62e9\u884c\u52a8\uff0c\u8fdb\u884c\u957f\u671f\u79d1\u5b66\u63a2\u7d22\uff0c\u5305\u62ec\u9605\u8bfb\u540c\u884c\u8bba\u6587\u3001\u5236\u5b9a\u5047\u8bbe\u3001\u63d0\u4ea4\u4ee3\u7801\u3001\u6267\u884c\u5206\u6790\u548c\u53d1\u5e03\u7ed3\u679c\u3002", "result": "\u5728\u6570\u5b66\u3001\u8ba1\u7b97\u751f\u7269\u5b66\u548c\u673a\u5668\u5b66\u4e60\u7b49\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5706\u5305\u88c5\u95ee\u9898\u4e0a\u8d85\u8d8aAlphaEvolve\uff0c\u5e76\u6d8c\u73b0\u51fa\u65b0\u7684\u65b9\u6cd5\u5982scRNA-seq\u6279\u91cf\u6574\u5408\u7684\u5bc6\u5ea6\u81ea\u9002\u5e94\u7b97\u6cd5\u3002", "conclusion": "STATION\u4ee3\u8868\u4e86\u901a\u8fc7\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u6d8c\u73b0\u884c\u4e3a\u9a71\u52a8\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\u7684\u7b2c\u4e00\u6b65\uff0c\u6807\u5fd7\u7740\u8d85\u8d8a\u521a\u6027\u4f18\u5316\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2511.06316", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06316", "abs": "https://arxiv.org/abs/2511.06316", "authors": ["MD Thamed Bin Zaman Chowdhury", "Moazzem Hossain"], "title": "ALIGN: A Vision-Language Framework for High-Accuracy Accident Location Inference through Geo-Spatial Neural Reasoning", "comment": null, "summary": "Reliable geospatial information on road accidents is vital for safety analysis and infrastructure planning, yet most low- and middle-income countries continue to face a critical shortage of accurate, location-specific crash data. Existing text-based geocoding tools perform poorly in multilingual and unstructured news environments, where incomplete place descriptions and mixed Bangla-English scripts obscure spatial context. To address these limitations, this study introduces ALIGN (Accident Location Inference through Geo-Spatial Neural Reasoning)- a vision-language framework that emulates human spatial reasoning to infer accident coordinates directly from textual and map-based cues. ALIGN integrates large language and vision-language models within a multi-stage pipeline that performs optical character recognition, linguistic reasoning, and map-level verification through grid-based spatial scanning. The framework systematically evaluates each predicted location against contextual and visual evidence, ensuring interpretable, fine-grained geolocation outcomes without requiring model retraining. Applied to Bangla-language news data, ALIGN demonstrates consistent improvements over traditional geoparsing methods, accurately identifying district and sub-district-level crash sites. Beyond its technical contribution, the framework establishes a high accuracy foundation for automated crash mapping in data-scarce regions, supporting evidence-driven road-safety policymaking and the broader integration of multimodal artificial intelligence in transportation analytics. The code for this paper is open-source and available at: https://github.com/Thamed-Chowdhury/ALIGN", "AI": {"tldr": "ALIGN\u662f\u4e00\u4e2a\u89c6\u89c9\u8bed\u8a00\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u7a7a\u95f4\u63a8\u7406\u4ece\u6587\u672c\u548c\u5730\u56fe\u7ebf\u7d22\u76f4\u63a5\u63a8\u65ad\u4e8b\u6545\u5750\u6807\uff0c\u89e3\u51b3\u4e86\u591a\u8bed\u8a00\u548c\u975e\u7ed3\u6784\u5316\u65b0\u95fb\u73af\u5883\u4e2d\u4e8b\u6545\u4f4d\u7f6e\u8bc6\u522b\u7684\u95ee\u9898\u3002", "motivation": "\u4f4e\u6536\u5165\u548c\u4e2d\u7b49\u6536\u5165\u56fd\u5bb6\u7f3a\u4e4f\u51c6\u786e\u7684\u4e8b\u6545\u4f4d\u7f6e\u6570\u636e\uff0c\u73b0\u6709\u57fa\u4e8e\u6587\u672c\u7684\u5730\u7406\u7f16\u7801\u5de5\u5177\u5728\u591a\u8bed\u8a00\u548c\u975e\u7ed3\u6784\u5316\u65b0\u95fb\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e0d\u5b8c\u6574\u7684\u5730\u70b9\u63cf\u8ff0\u548c\u6df7\u5408\u8bed\u8a00\u811a\u672c\u963b\u788d\u4e86\u7a7a\u95f4\u4e0a\u4e0b\u6587\u7406\u89e3\u3002", "method": "ALIGN\u6574\u5408\u5927\u578b\u8bed\u8a00\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u6d41\u7a0b\uff1a\u5149\u5b66\u5b57\u7b26\u8bc6\u522b\u3001\u8bed\u8a00\u63a8\u7406\u548c\u57fa\u4e8e\u7f51\u683c\u7684\u7a7a\u95f4\u626b\u63cf\u8fdb\u884c\u5730\u56fe\u7ea7\u9a8c\u8bc1\uff0c\u7cfb\u7edf\u8bc4\u4f30\u9884\u6d4b\u4f4d\u7f6e\u4e0e\u4e0a\u4e0b\u6587\u548c\u89c6\u89c9\u8bc1\u636e\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u5b5f\u52a0\u62c9\u8bed\u65b0\u95fb\u6570\u636e\u4e0a\u7684\u5e94\u7528\u663e\u793a\uff0cALIGN\u76f8\u6bd4\u4f20\u7edf\u5730\u7406\u89e3\u6790\u65b9\u6cd5\u6709\u6301\u7eed\u6539\u8fdb\uff0c\u80fd\u51c6\u786e\u8bc6\u522b\u5730\u533a\u548c\u6b21\u5730\u533a\u7ea7\u522b\u7684\u4e8b\u6545\u5730\u70b9\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6570\u636e\u7a00\u7f3a\u5730\u533a\u7684\u81ea\u52a8\u5316\u4e8b\u6545\u5730\u56fe\u7ed8\u5236\u5efa\u7acb\u4e86\u9ad8\u7cbe\u5ea6\u57fa\u7840\uff0c\u652f\u6301\u57fa\u4e8e\u8bc1\u636e\u7684\u9053\u8def\u5b89\u5168\u653f\u7b56\u5236\u5b9a\uff0c\u5e76\u4fc3\u8fdb\u591a\u6a21\u6001\u4eba\u5de5\u667a\u80fd\u5728\u4ea4\u901a\u5206\u6790\u4e2d\u7684\u66f4\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2511.06346", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06346", "abs": "https://arxiv.org/abs/2511.06346", "authors": ["Liya Zhu", "Peizhuang Cong", "Aowei Ji", "Wenya Wu", "Jiani Hou", "Chunjie Wu", "Xiang Gao", "Jingkai Liu", "Zhou Huan", "Xuelei Sun", "Yang Yang", "Jianpeng Jiao", "Liang Hu", "Xinjie Chen", "Jiashuo Liu", "Jingzhe Ding", "Tong Yang", "Zaiyuan Wang", "Ge Zhang", "Wenhao Huang"], "title": "LPFQA: A Long-Tail Professional Forum-based Benchmark for LLM Evaluation", "comment": null, "summary": "Large Language Models (LLMs) have made rapid progress in reasoning, question answering, and professional applications; however, their true capabilities remain difficult to evaluate using existing benchmarks. Current datasets often focus on simplified tasks or artificial scenarios, overlooking long-tail knowledge and the complexities of real-world applications. To bridge this gap, we propose LPFQA, a long-tail knowledge-based benchmark derived from authentic professional forums across 20 academic and industrial fields, covering 502 tasks grounded in practical expertise. LPFQA introduces four key innovations: fine-grained evaluation dimensions that target knowledge depth, reasoning, terminology comprehension, and contextual analysis; a hierarchical difficulty structure that ensures semantic clarity and unique answers; authentic professional scenario modeling with realistic user personas; and interdisciplinary knowledge integration across diverse domains. We evaluated 12 mainstream LLMs on LPFQA and observed significant performance disparities, especially in specialized reasoning tasks. LPFQA provides a robust, authentic, and discriminative benchmark for advancing LLM evaluation and guiding future model development.", "AI": {"tldr": "LPFQA\u662f\u4e00\u4e2a\u57fa\u4e8e\u957f\u5c3e\u77e5\u8bc6\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ece20\u4e2a\u5b66\u672f\u548c\u5de5\u4e1a\u9886\u57df\u7684\u4e13\u4e1a\u8bba\u575b\u4e2d\u63d0\u53d6\uff0c\u5305\u542b502\u4e2a\u57fa\u4e8e\u5b9e\u8df5\u4e13\u4e1a\u77e5\u8bc6\u7684\u4efb\u52a1\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u771f\u5b9e\u4e13\u4e1a\u573a\u666f\u4e2d\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5f80\u5f80\u5173\u6ce8\u7b80\u5316\u4efb\u52a1\u6216\u4eba\u5de5\u573a\u666f\uff0c\u5ffd\u7565\u4e86\u957f\u5c3e\u77e5\u8bc6\u548c\u771f\u5b9e\u5e94\u7528\u7684\u590d\u6742\u6027\uff0c\u96be\u4ee5\u51c6\u786e\u8bc4\u4f30LLMs\u7684\u771f\u5b9e\u80fd\u529b\u3002", "method": "\u4ece20\u4e2a\u5b66\u672f\u548c\u5de5\u4e1a\u9886\u57df\u7684\u4e13\u4e1a\u8bba\u575b\u6536\u96c6\u6570\u636e\uff0c\u6784\u5efa\u5305\u542b502\u4e2a\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5f15\u5165\u56db\u4e2a\u5173\u952e\u521b\u65b0\uff1a\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u7ef4\u5ea6\u3001\u5206\u5c42\u96be\u5ea6\u7ed3\u6784\u3001\u771f\u5b9e\u4e13\u4e1a\u573a\u666f\u5efa\u6a21\u548c\u8de8\u5b66\u79d1\u77e5\u8bc6\u6574\u5408\u3002", "result": "\u572812\u4e2a\u4e3b\u6d41LLMs\u4e0a\u8bc4\u4f30LPFQA\uff0c\u89c2\u5bdf\u5230\u663e\u8457\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u7279\u522b\u662f\u5728\u4e13\u4e1a\u63a8\u7406\u4efb\u52a1\u4e2d\u3002", "conclusion": "LPFQA\u4e3a\u63a8\u8fdbLLM\u8bc4\u4f30\u548c\u6307\u5bfc\u672a\u6765\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a33\u5065\u3001\u771f\u5b9e\u548c\u5177\u6709\u533a\u5206\u5ea6\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2511.06380", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06380", "abs": "https://arxiv.org/abs/2511.06380", "authors": ["Chen He", "Xun Jiang", "Lei Wang", "Hao Yang", "Chong Peng", "Peng Yan", "Fumin Shen", "Xing Xu"], "title": "What Makes Reasoning Invalid: Echo Reflection Mitigation for Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of reasoning tasks. Recent methods have further improved LLM performance in complex mathematical reasoning. However, when extending these methods beyond the domain of mathematical reasoning to tasks involving complex domain-specific knowledge, we observe a consistent failure of LLMs to generate novel insights during the reflection stage. Instead of conducting genuine cognitive refinement, the model tends to mechanically reiterate earlier reasoning steps without introducing new information or perspectives, a phenomenon referred to as \"Echo Reflection\". We attribute this behavior to two key defects: (1) Uncontrollable information flow during response generation, which allows premature intermediate thoughts to propagate unchecked and distort final decisions; (2) Insufficient exploration of internal knowledge during reflection, leading to repeating earlier findings rather than generating new cognitive insights. Building on these findings, we proposed a novel reinforcement learning method termed Adaptive Entropy Policy Optimization (AEPO). Specifically, the AEPO framework consists of two major components: (1) Reflection-aware Information Filtration, which quantifies the cognitive information flow and prevents the final answer from being affected by earlier bad cognitive information; (2) Adaptive-Entropy Optimization, which dynamically balances exploration and exploitation across different reasoning stages, promoting both reflective diversity and answer correctness. Extensive experiments demonstrate that AEPO consistently achieves state-of-the-art performance over mainstream reinforcement learning baselines across diverse benchmarks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAEPO\u65b9\u6cd5\u89e3\u51b3LLMs\u5728\u590d\u6742\u9886\u57df\u63a8\u7406\u4e2d\u7684\"\u56de\u97f3\u53cd\u5c04\"\u95ee\u9898\uff0c\u901a\u8fc7\u63a7\u5236\u4fe1\u606f\u6d41\u548c\u81ea\u9002\u5e94\u71b5\u4f18\u5316\u6765\u63d0\u5347\u53cd\u601d\u9636\u6bb5\u7684\u8ba4\u77e5\u6d1e\u5bdf\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6570\u5b66\u63a8\u7406\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u6d89\u53ca\u590d\u6742\u9886\u57df\u77e5\u8bc6\u7684\u4efb\u52a1\u4e2d\uff0cLLMs\u5728\u53cd\u601d\u9636\u6bb5\u65e0\u6cd5\u4ea7\u751f\u65b0\u7684\u8ba4\u77e5\u6d1e\u5bdf\uff0c\u800c\u662f\u673a\u68b0\u91cd\u590d\u65e9\u671f\u63a8\u7406\u6b65\u9aa4\uff0c\u51fa\u73b0\"\u56de\u97f3\u53cd\u5c04\"\u73b0\u8c61\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u71b5\u7b56\u7565\u4f18\u5316(AEPO)\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u7ec4\u4ef6\uff1a\u53cd\u601d\u611f\u77e5\u4fe1\u606f\u8fc7\u6ee4(\u91cf\u5316\u8ba4\u77e5\u4fe1\u606f\u6d41\uff0c\u9632\u6b62\u65e9\u671f\u9519\u8bef\u8ba4\u77e5\u5f71\u54cd\u6700\u7ec8\u7b54\u6848)\u548c\u81ea\u9002\u5e94\u71b5\u4f18\u5316(\u52a8\u6001\u5e73\u8861\u4e0d\u540c\u63a8\u7406\u9636\u6bb5\u7684\u63a2\u7d22\u4e0e\u5229\u7528)\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cAEPO\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u4e3b\u6d41\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\u6c34\u5e73\u3002", "conclusion": "AEPO\u901a\u8fc7\u63a7\u5236\u4fe1\u606f\u6d41\u548c\u4fc3\u8fdb\u8ba4\u77e5\u591a\u6837\u6027\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLMs\u5728\u590d\u6742\u9886\u57df\u63a8\u7406\u4e2d\u7684\u53cd\u601d\u80fd\u529b\u4e0d\u8db3\u95ee\u9898\uff0c\u4e3a\u63d0\u5347\u6a21\u578b\u8ba4\u77e5\u6d1e\u5bdf\u529b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.06396", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.06396", "abs": "https://arxiv.org/abs/2511.06396", "authors": ["Dachuan Lin", "Guobin Shen", "Zihao Yang", "Tianrong Liu", "Dongcheng Zhao", "Yi Zeng"], "title": "Efficient LLM Safety Evaluation through Multi-Agent Debate", "comment": "9 pages of main text, 14 pages total, 4 figures", "summary": "Safety evaluation of large language models (LLMs) increasingly relies on LLM-as-a-Judge frameworks, but the high cost of frontier models limits scalability. We propose a cost-efficient multi-agent judging framework that employs Small Language Models (SLMs) through structured debates among critic, defender, and judge agents. To rigorously assess safety judgments, we construct HAJailBench, a large-scale human-annotated jailbreak benchmark comprising 12,000 adversarial interactions across diverse attack methods and target models. The dataset provides fine-grained, expert-labeled ground truth for evaluating both safety robustness and judge reliability. Our SLM-based framework achieves agreement comparable to GPT-4o judges on HAJailBench while substantially reducing inference cost. Ablation results show that three rounds of debate yield the optimal balance between accuracy and efficiency. These findings demonstrate that structured, value-aligned debate enables SLMs to capture semantic nuances of jailbreak attacks and that HAJailBench offers a reliable foundation for scalable LLM safety evaluation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u4ee3\u7406\u8bc4\u5224\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8fa9\u8bba\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u6784\u5efa\u4e86\u5305\u542b12,000\u4e2a\u5bf9\u6297\u6027\u4ea4\u4e92\u7684\u5927\u89c4\u6a21\u4eba\u5de5\u6807\u6ce8\u57fa\u51c6HAJailBench\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u6602\u8d35\u7684\u524d\u6cbf\u6a21\u578b\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u9700\u8981\u5f00\u53d1\u6210\u672c\u6548\u76ca\u66f4\u9ad8\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6279\u8bc4\u8005\u3001\u8fa9\u62a4\u8005\u548c\u8bc4\u5224\u8005\u4e09\u4e2a\u4ee3\u7406\u89d2\u8272\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7ed3\u6784\u5316\u8fa9\u8bba\uff0c\u6784\u5efa\u4e86HAJailBench\u57fa\u51c6\u6570\u636e\u96c6\u6765\u8bc4\u4f30\u5b89\u5168\u6027\u548c\u8bc4\u5224\u53ef\u9760\u6027\u3002", "result": "\u57fa\u4e8e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\u5728HAJailBench\u4e0a\u8fbe\u5230\u4e86\u4e0eGPT-4o\u8bc4\u5224\u8005\u76f8\u5f53\u7684\u534f\u8bae\u6c34\u5e73\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u63a8\u7406\u6210\u672c\uff0c\u4e09\u8f6e\u8fa9\u8bba\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u8fbe\u5230\u6700\u4f73\u5e73\u8861\u3002", "conclusion": "\u7ed3\u6784\u5316\u3001\u4ef7\u503c\u5bf9\u9f50\u7684\u8fa9\u8bba\u4f7f\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6355\u6349\u8d8a\u72f1\u653b\u51fb\u7684\u8bed\u4e49\u7ec6\u5fae\u5dee\u522b\uff0cHAJailBench\u4e3a\u53ef\u6269\u5c55\u7684LLM\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u9760\u57fa\u7840\u3002"}}
{"id": "2511.06411", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06411", "abs": "https://arxiv.org/abs/2511.06411", "authors": ["Zhi Zheng", "Wee Sun Lee"], "title": "SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization", "comment": null, "summary": "The soft-thinking paradigm for Large Language Model (LLM) reasoning can outperform the conventional discrete-token Chain-of-Thought (CoT) reasoning in some scenarios, underscoring its research and application value. However, while the discrete-token CoT reasoning pattern can be reinforced through policy optimization algorithms such as group relative policy optimization (GRPO), extending the soft-thinking pattern with Reinforcement Learning (RL) remains challenging. This difficulty stems from the complexities of injecting stochasticity into soft-thinking tokens and updating soft-thinking policies accordingly. As a result, previous attempts to combine soft-thinking with GRPO typically underperform their discrete-token GRPO counterparts. To fully unlock the potential of soft-thinking, this paper presents a novel policy optimization algorithm, SofT-GRPO, to reinforce LLMs under the soft-thinking reasoning pattern. SofT-GRPO injects the Gumbel noise into logits, employs the Gumbel-Softmax technique to avoid soft-thinking tokens outside the pre-trained embedding space, and leverages the reparameterization trick in policy gradient. We conduct experiments across base LLMs ranging from 1.5B to 7B parameters, and results demonstrate that SofT-GRPO enables soft-thinking LLMs to slightly outperform discrete-token GRPO on Pass@1 (+0.13% on average accuracy), while exhibiting a substantial uplift on Pass@32 (+2.19% on average accuracy). Codes and weights are available on https://github.com/zz1358m/SofT-GRPO-master", "AI": {"tldr": "\u63d0\u51faSofT-GRPO\u7b97\u6cd5\uff0c\u901a\u8fc7\u6ce8\u5165Gumbel\u566a\u58f0\u548c\u4f7f\u7528Gumbel-Softmax\u6280\u672f\uff0c\u6210\u529f\u5c06\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u8f6f\u601d\u7ef4\u63a8\u7406\u8303\u5f0f\uff0c\u4f7fLLM\u5728\u8f6f\u601d\u7ef4\u6a21\u5f0f\u4e0b\u6027\u80fd\u8d85\u8d8a\u79bb\u6563token\u63a8\u7406\u3002", "motivation": "\u8f6f\u601d\u7ef4\u63a8\u7406\u8303\u5f0f\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u4f18\u4e8e\u4f20\u7edf\u79bb\u6563token\u63a8\u7406\uff0c\u4f46\u96be\u4ee5\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff0c\u56e0\u4e3a\u96be\u4ee5\u5728\u8f6f\u601d\u7ef4token\u4e2d\u6ce8\u5165\u968f\u673a\u6027\u5e76\u66f4\u65b0\u7b56\u7565\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u7ed3\u5408\u8f6f\u601d\u7ef4\u4e0eGRPO\u65f6\u8868\u73b0\u4e0d\u5982\u79bb\u6563token\u7248\u672c\u3002", "method": "\u63d0\u51faSofT-GRPO\u7b97\u6cd5\uff1a1) \u5728logits\u4e2d\u6ce8\u5165Gumbel\u566a\u58f0\uff1b2) \u4f7f\u7528Gumbel-Softmax\u907f\u514d\u8f6f\u601d\u7ef4token\u8d85\u51fa\u9884\u8bad\u7ec3\u5d4c\u5165\u7a7a\u95f4\uff1b3) \u5728\u7b56\u7565\u68af\u5ea6\u4e2d\u5229\u7528\u91cd\u53c2\u6570\u5316\u6280\u5de7\u3002", "result": "\u57281.5B\u52307B\u53c2\u6570\u7684LLM\u4e0a\u5b9e\u9a8c\uff0cSofT-GRPO\u4f7f\u8f6f\u601d\u7ef4LLM\u5728Pass@1\u4e0a\u7565\u4f18\u4e8e\u79bb\u6563token GRPO\uff08\u5e73\u5747\u51c6\u786e\u7387+0.13%\uff09\uff0c\u5728Pass@32\u4e0a\u663e\u8457\u63d0\u5347\uff08\u5e73\u5747\u51c6\u786e\u7387+2.19%\uff09\u3002", "conclusion": "SofT-GRPO\u6210\u529f\u89e3\u9501\u4e86\u8f6f\u601d\u7ef4\u63a8\u7406\u7684\u6f5c\u529b\uff0c\u4e3a\u8f6f\u601d\u7ef4\u8303\u5f0f\u4e0e\u5f3a\u5316\u5b66\u4e60\u7684\u7ed3\u5408\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.06417", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06417", "abs": "https://arxiv.org/abs/2511.06417", "authors": ["Xiangwu Guo", "Difei Gao", "Mike Zheng Shou"], "title": "AUTO-Explorer: Automated Data Collection for GUI Agent", "comment": null, "summary": "Recent advancements in GUI agents have significantly expanded their ability to interpret natural language commands to manage software interfaces. However, acquiring GUI data remains a significant challenge. Existing methods often involve designing automated agents that browse URLs from the Common Crawl, using webpage HTML to collect screenshots and corresponding annotations, including the names and bounding boxes of UI elements. However, this method is difficult to apply to desktop software or some newly launched websites not included in the Common Crawl. While we expect the model to possess strong generalization capabilities to handle this, it is still crucial for personalized scenarios that require rapid and perfect adaptation to new software or websites. To address this, we propose an automated data collection method with minimal annotation costs, named Auto-Explorer. It incorporates a simple yet effective exploration mechanism that autonomously parses and explores GUI environments, gathering data efficiently. Additionally, to assess the quality of exploration, we have developed the UIXplore benchmark. This benchmark creates environments for explorer agents to discover and save software states. Using the data gathered, we fine-tune a multimodal large language model (MLLM) and establish a GUI element grounding testing set to evaluate the effectiveness of the exploration strategies. Our experiments demonstrate the superior performance of Auto-Explorer, showing that our method can quickly enhance the capabilities of an MLLM in explored software.", "AI": {"tldr": "\u63d0\u51faAuto-Explorer\u81ea\u52a8\u5316GUI\u6570\u636e\u6536\u96c6\u65b9\u6cd5\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e94\u7528\u4e8e\u684c\u9762\u8f6f\u4ef6\u548c\u65b0\u7f51\u7ad9\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u4e3b\u63a2\u7d22\u673a\u5236\u9ad8\u6548\u6536\u96c6\u6570\u636e\uff0c\u5e76\u5efa\u7acbUIXplore\u57fa\u51c6\u8bc4\u4f30\u63a2\u7d22\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709GUI\u6570\u636e\u6536\u96c6\u65b9\u6cd5\u4f9d\u8d56Common Crawl\u7684\u7f51\u9875HTML\uff0c\u96be\u4ee5\u5e94\u7528\u4e8e\u684c\u9762\u8f6f\u4ef6\u548c\u672a\u6536\u5f55\u7684\u65b0\u7f51\u7ad9\uff0c\u800c\u4e2a\u6027\u5316\u573a\u666f\u9700\u8981\u5feb\u901f\u9002\u5e94\u65b0\u8f6f\u4ef6\u6216\u7f51\u7ad9\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faAuto-Explorer\u65b9\u6cd5\uff0c\u5305\u542b\u7b80\u5355\u6709\u6548\u7684\u63a2\u7d22\u673a\u5236\uff0c\u80fd\u81ea\u4e3b\u89e3\u6790\u548c\u63a2\u7d22GUI\u73af\u5883\u9ad8\u6548\u6536\u96c6\u6570\u636e\uff1b\u5efa\u7acbUIXplore\u57fa\u51c6\u8bc4\u4f30\u63a2\u7d22\u8d28\u91cf\uff0c\u5e76\u5fae\u8c03\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eAuto-Explorer\u6027\u80fd\u4f18\u8d8a\uff0c\u80fd\u5feb\u901f\u63d0\u5347MLLM\u5728\u5df2\u63a2\u7d22\u8f6f\u4ef6\u4e2d\u7684\u80fd\u529b\u3002", "conclusion": "Auto-Explorer\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f4e\u6807\u6ce8\u6210\u672c\u7684\u81ea\u52a8\u5316\u6570\u636e\u6536\u96c6\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86GUI\u6570\u636e\u83b7\u53d6\u7684\u6311\u6218\uff0c\u4e3aGUI\u4ee3\u7406\u7684\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u652f\u6301\u3002"}}
{"id": "2511.06419", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06419", "abs": "https://arxiv.org/abs/2511.06419", "authors": ["Jingyu Hu", "Shu Yang", "Xilin Gong", "Hongming Wang", "Weiru Liu", "Di Wang"], "title": "MONICA: Real-Time Monitoring and Calibration of Chain-of-Thought Sycophancy in Large Reasoning Models", "comment": null, "summary": "Large Reasoning Models (LRMs) suffer from sycophantic behavior, where models tend to agree with users' incorrect beliefs and follow misinformation rather than maintain independent reasoning. This behavior undermines model reliability and poses societal risks. Mitigating LRM sycophancy requires monitoring how this sycophancy emerges during the reasoning trajectory; however, current methods mainly focus on judging based on final answers and correcting them, without understanding how sycophancy develops during reasoning processes. To address this limitation, we propose MONICA, a novel Monitor-guided Calibration framework that monitors and mitigates sycophancy during model inference at the level of reasoning steps, without requiring the model to finish generating its complete answer. MONICA integrates a sycophantic monitor that provides real-time monitoring of sycophantic drift scores during response generation with a calibrator that dynamically suppresses sycophantic behavior when scores exceed predefined thresholds. Extensive experiments across 12 datasets and 3 LRMs demonstrate that our method effectively reduces sycophantic behavior in both intermediate reasoning steps and final answers, yielding robust performance improvements.", "AI": {"tldr": "MONICA\u6846\u67b6\u901a\u8fc7\u5b9e\u65f6\u76d1\u63a7\u63a8\u7406\u6b65\u9aa4\u4e2d\u7684\u8c04\u5a9a\u884c\u4e3a\u5e76\u52a8\u6001\u6821\u51c6\uff0c\u6709\u6548\u51cf\u5c11\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u8c04\u5a9a\u884c\u4e3a\uff0c\u63d0\u5347\u6a21\u578b\u53ef\u9760\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5b58\u5728\u8c04\u5a9a\u884c\u4e3a\uff0c\u503e\u5411\u4e8e\u8fce\u5408\u7528\u6237\u7684\u9519\u8bef\u4fe1\u5ff5\u548c\u9519\u8bef\u4fe1\u606f\uff0c\u8fd9\u524a\u5f31\u4e86\u6a21\u578b\u53ef\u9760\u6027\u5e76\u5e26\u6765\u793e\u4f1a\u98ce\u9669\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u6700\u7ec8\u7b54\u6848\u8fdb\u884c\u5224\u65ad\u548c\u4fee\u6b63\uff0c\u65e0\u6cd5\u7406\u89e3\u8c04\u5a9a\u884c\u4e3a\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51faMONICA\u6846\u67b6\uff0c\u5305\u542b\u8c04\u5a9a\u76d1\u63a7\u5668\u548c\u6821\u51c6\u5668\u3002\u76d1\u63a7\u5668\u5728\u54cd\u5e94\u751f\u6210\u8fc7\u7a0b\u4e2d\u5b9e\u65f6\u76d1\u63a7\u8c04\u5a9a\u6f02\u79fb\u5206\u6570\uff0c\u6821\u51c6\u5668\u5728\u5206\u6570\u8d85\u8fc7\u9608\u503c\u65f6\u52a8\u6001\u6291\u5236\u8c04\u5a9a\u884c\u4e3a\uff0c\u65e0\u9700\u6a21\u578b\u5b8c\u6210\u5b8c\u6574\u7b54\u6848\u751f\u6210\u3002", "result": "\u572812\u4e2a\u6570\u636e\u96c6\u548c3\u4e2a\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u51cf\u5c11\u4e86\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u548c\u6700\u7ec8\u7b54\u6848\u4e2d\u7684\u8c04\u5a9a\u884c\u4e3a\uff0c\u83b7\u5f97\u4e86\u7a33\u5065\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "MONICA\u6846\u67b6\u80fd\u591f\u5728\u63a8\u7406\u6b65\u9aa4\u5c42\u9762\u76d1\u63a7\u548c\u51cf\u8f7b\u8c04\u5a9a\u884c\u4e3a\uff0c\u4e3a\u7f13\u89e3\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u8c04\u5a9a\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.06437", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06437", "abs": "https://arxiv.org/abs/2511.06437", "authors": ["Abhishek More", "Anthony Zhang", "Nicole Bonilla", "Ashvik Vivekan", "Kevin Zhu", "Parham Sharafoleslami", "Maheep Chaudhary"], "title": "Optimizing Chain-of-Thought Confidence via Topological and Dirichlet Risk Analysis", "comment": null, "summary": "Chain-of-thought (CoT) prompting enables Large Language Models to solve complex problems, but deploying these models safely requires reliable confidence estimates, a capability where existing methods suffer from poor calibration and severe overconfidence on incorrect predictions. We propose Enhanced Dirichlet and Topology Risk (EDTR), a novel decoding strategy that combines topological analysis with Dirichlet-based uncertainty quantification to measure LLM confidence across multiple reasoning paths. EDTR treats each CoT as a vector in high-dimensional space and extracts eight topological risk features capturing the geometric structure of reasoning distributions: tighter, more coherent clusters indicate higher confidence while dispersed, inconsistent paths signal uncertainty. We evaluate EDTR against three state-of-the-art calibration methods across four diverse reasoning benchmarks spanning olympiad-level mathematics (AIME), grade school math (GSM8K), commonsense reasoning, and stock price prediction \\cite{zhang2025aime, cobbe2021training, talmor-etal-2019-commonsenseqa, yahoo_finance}. EDTR achieves 41\\% better calibration than competing methods with an average ECE of 0.287 and the best overall composite score of 0.672, while notably achieving perfect accuracy on AIME and exceptional calibration on GSM8K with an ECE of 0.107, domains where baselines exhibit severe overconfidence. Our work provides a geometric framework for understanding and quantifying uncertainty in multi-step LLM reasoning, enabling more reliable deployment where calibrated confidence estimates are essential.", "AI": {"tldr": "EDTR\u662f\u4e00\u79cd\u65b0\u7684\u89e3\u7801\u7b56\u7565\uff0c\u7ed3\u5408\u62d3\u6251\u5206\u6790\u548c\u72c4\u5229\u514b\u96f7\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u901a\u8fc7\u5206\u6790\u601d\u7ef4\u94fe\u7684\u51e0\u4f55\u7ed3\u6784\u6765\u6d4b\u91cfLLM\u7f6e\u4fe1\u5ea6\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u597d\u7684\u6821\u51c6\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728LLM\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u9762\u5b58\u5728\u6821\u51c6\u5dee\u548c\u8fc7\u5ea6\u81ea\u4fe1\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9519\u8bef\u9884\u6d4b\u4e0a\u8868\u73b0\u4e25\u91cd\u8fc7\u81ea\u4fe1\uff0c\u8fd9\u5f71\u54cd\u4e86\u6a21\u578b\u7684\u5b89\u5168\u90e8\u7f72\u3002", "method": "\u5c06\u6bcf\u4e2a\u601d\u7ef4\u94fe\u89c6\u4e3a\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u7684\u5411\u91cf\uff0c\u63d0\u53d68\u4e2a\u62d3\u6251\u98ce\u9669\u7279\u5f81\u6765\u6355\u6349\u63a8\u7406\u5206\u5e03\u7684\u51e0\u4f55\u7ed3\u6784\uff1a\u7d27\u5bc6\u3001\u8fde\u8d2f\u7684\u7c07\u8868\u793a\u9ad8\u7f6e\u4fe1\u5ea6\uff0c\u800c\u5206\u6563\u3001\u4e0d\u4e00\u81f4\u7684\u8def\u5f84\u8868\u793a\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5728\u56db\u4e2a\u4e0d\u540c\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEDTR\u6bd4\u4e09\u79cd\u6700\u5148\u8fdb\u7684\u6821\u51c6\u65b9\u6cd5\u6821\u51c6\u6548\u679c\u63d0\u534741%\uff0c\u5e73\u5747ECE\u4e3a0.287\uff0c\u7efc\u5408\u5f97\u52060.672\u6700\u4f73\uff0c\u5728AIME\u4e0a\u8fbe\u5230\u5b8c\u7f8e\u51c6\u786e\u7387\uff0c\u5728GSM8K\u4e0aECE\u4e3a0.107\uff0c\u800c\u57fa\u7ebf\u65b9\u6cd5\u5728\u8fd9\u4e9b\u9886\u57df\u8868\u73b0\u51fa\u4e25\u91cd\u8fc7\u81ea\u4fe1\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u51e0\u4f55\u6846\u67b6\u6765\u7406\u89e3\u548c\u91cf\u5316\u591a\u6b65LLM\u63a8\u7406\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u9700\u8981\u6821\u51c6\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u7684\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u66f4\u53ef\u9760\u7684\u90e8\u7f72\u3002"}}
{"id": "2511.06470", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06470", "abs": "https://arxiv.org/abs/2511.06470", "authors": ["Mingde \"Harry\" Zhao"], "title": "Brain-Inspired Planning for Better Generalization in Reinforcement Learning", "comment": "McGill PhD Thesis (updated on 20251109 for typos and margin adjustments)", "summary": "Existing Reinforcement Learning (RL) systems encounter significant challenges when applied to real-world scenarios, primarily due to poor generalization across environments that differ from their training conditions. This thesis explores the direction of enhancing agents' zero-shot systematic generalization abilities by granting RL agents reasoning behaviors that are found to help systematic generalization in the human brain. Inspired by human conscious planning behaviors, we first introduced a top-down attention mechanism, which allows a decision-time planning agent to dynamically focus its reasoning on the most relevant aspects of the environmental state given its instantaneous intentions, a process we call \"spatial abstraction\". This approach significantly improves systematic generalization outside the training tasks. Subsequently, building on spatial abstraction, we developed the Skipper framework to automatically decompose complex tasks into simpler, more manageable sub-tasks. Skipper provides robustness against distributional shifts and efficacy in long-term, compositional planning by focusing on pertinent spatial and temporal elements of the environment. Finally, we identified a common failure mode and safety risk in planning agents that rely on generative models to generate state targets during planning. It is revealed that most agents blindly trust the targets they hallucinate, resulting in delusional planning behaviors. Inspired by how the human brain rejects delusional intentions, we propose learning a feasibility evaluator to enable rejecting hallucinated infeasible targets, which led to significant performance improvements in various kinds of planning agents. Finally, we suggest directions for future research, aimed at achieving general task abstraction and fully enabling abstract planning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5f15\u5165\u4eba\u7c7b\u610f\u8bc6\u89c4\u5212\u884c\u4e3a\u542f\u53d1\u7684\u673a\u5236\uff0c\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u96f6\u6837\u672c\u7cfb\u7edf\u6cdb\u5316\u80fd\u529b\uff0c\u5305\u62ec\u7a7a\u95f4\u62bd\u8c61\u3001\u4efb\u52a1\u5206\u89e3\u548c\u53ef\u884c\u6027\u8bc4\u4f30\uff0c\u4ee5\u89e3\u51b3\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u6cdb\u5316\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u9762\u4e34\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u4e0e\u8bad\u7ec3\u6761\u4ef6\u4e0d\u540c\u7684\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u53d7\u4eba\u7c7b\u5927\u8111\u7cfb\u7edf\u6027\u6cdb\u5316\u80fd\u529b\u7684\u542f\u53d1\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u8d4b\u4e88RL\u4ee3\u7406\u63a8\u7406\u884c\u4e3a\u6765\u589e\u5f3a\u5176\u96f6\u6837\u672c\u7cfb\u7edf\u6cdb\u5316\u80fd\u529b\u3002", "method": "1. \u5f15\u5165\u81ea\u4e0a\u800c\u4e0b\u7684\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u7a7a\u95f4\u62bd\u8c61\uff0c\u8ba9\u4ee3\u7406\u6839\u636e\u77ac\u65f6\u610f\u56fe\u52a8\u6001\u805a\u7126\u73af\u5883\u72b6\u6001\u7684\u5173\u952e\u65b9\u9762\uff1b2. \u5f00\u53d1Skipper\u6846\u67b6\u81ea\u52a8\u5206\u89e3\u590d\u6742\u4efb\u52a1\u4e3a\u66f4\u7b80\u5355\u7684\u5b50\u4efb\u52a1\uff1b3. \u5b66\u4e60\u53ef\u884c\u6027\u8bc4\u4f30\u5668\u6765\u62d2\u7edd\u5e7b\u89c9\u4ea7\u751f\u7684\u4e0d\u53ef\u884c\u76ee\u6807\uff0c\u9632\u6b62\u5984\u60f3\u89c4\u5212\u884c\u4e3a\u3002", "result": "\u7a7a\u95f4\u62bd\u8c61\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u8bad\u7ec3\u4efb\u52a1\u5916\u7684\u7cfb\u7edf\u6cdb\u5316\u80fd\u529b\uff1bSkipper\u6846\u67b6\u5728\u5206\u5e03\u504f\u79fb\u548c\u957f\u671f\u7ec4\u5408\u89c4\u5212\u4e2d\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\uff1b\u53ef\u884c\u6027\u8bc4\u4f30\u5668\u5728\u5404\u79cd\u89c4\u5212\u4ee3\u7406\u4e2d\u5e26\u6765\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u89c4\u5212\u884c\u4e3a\uff0c\u8bba\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86RL\u4ee3\u7406\u7684\u7cfb\u7edf\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e3a\u5b9e\u73b0\u901a\u7528\u4efb\u52a1\u62bd\u8c61\u548c\u5b8c\u5168\u62bd\u8c61\u89c4\u5212\u7684\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2511.06471", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06471", "abs": "https://arxiv.org/abs/2511.06471", "authors": ["Jingtao Tang", "Hang Ma"], "title": "GHOST: Solving the Traveling Salesman Problem on Graphs of Convex Sets", "comment": "Accepted to AAAI-2026", "summary": "We study GCS-TSP, a new variant of the Traveling Salesman Problem (TSP) defined over a Graph of Convex Sets (GCS) -- a powerful representation for trajectory planning that decomposes the configuration space into convex regions connected by a sparse graph. In this setting, edge costs are not fixed but depend on the specific trajectory selected through each convex region, making classical TSP methods inapplicable. We introduce GHOST, a hierarchical framework that optimally solves the GCS-TSP by combining combinatorial tour search with convex trajectory optimization. GHOST systematically explores tours on a complete graph induced by the GCS, using a novel abstract-path-unfolding algorithm to compute admissible lower bounds that guide best-first search at both the high level (over tours) and the low level (over feasible GCS paths realizing the tour). These bounds provide strong pruning power, enabling efficient search while avoiding unnecessary convex optimization calls. We prove that GHOST guarantees optimality and present a bounded-suboptimal variant for time-critical scenarios. Experiments show that GHOST is orders-of-magnitude faster than unified mixed-integer convex programming baselines for simple cases and uniquely handles complex trajectory planning problems involving high-order continuity constraints and an incomplete GCS.", "AI": {"tldr": "GHOST\u662f\u4e00\u4e2a\u5206\u5c42\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u56fe\u51f8\u96c6\u65c5\u884c\u5546\u95ee\u9898(GCS-TSP)\uff0c\u901a\u8fc7\u7ed3\u5408\u7ec4\u5408\u8def\u5f84\u641c\u7d22\u548c\u51f8\u8f68\u8ff9\u4f18\u5316\uff0c\u5728\u4fdd\u8bc1\u6700\u4f18\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u6c42\u89e3\u3002", "motivation": "\u4f20\u7edfTSP\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8eGCS-TSP\uff0c\u56e0\u4e3a\u8fb9\u6210\u672c\u53d6\u51b3\u4e8e\u901a\u8fc7\u51f8\u533a\u57df\u7684\u5177\u4f53\u8f68\u8ff9\uff0c\u800c\u975e\u56fa\u5b9a\u503c\u3002\u9700\u8981\u5f00\u53d1\u65b0\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u79cd\u8f68\u8ff9\u89c4\u5212\u95ee\u9898\u3002", "method": "GHOST\u91c7\u7528\u5206\u5c42\u6846\u67b6\uff1a\u9ad8\u5c42\u5728GCS\u8bf1\u5bfc\u7684\u5b8c\u5168\u56fe\u4e0a\u641c\u7d22\u8def\u5f84\uff0c\u4f7f\u7528\u62bd\u8c61\u8def\u5f84\u5c55\u5f00\u7b97\u6cd5\u8ba1\u7b97\u53ef\u63a5\u53d7\u7684\u4e0b\u754c\uff1b\u4f4e\u5c42\u641c\u7d22\u5b9e\u73b0\u8def\u5f84\u7684\u53ef\u884cGCS\u8def\u5f84\u3002\u901a\u8fc7\u5f3a\u526a\u679d\u80fd\u529b\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u51f8\u4f18\u5316\u8c03\u7528\u3002", "result": "\u5b9e\u9a8c\u8868\u660eGHOST\u6bd4\u7edf\u4e00\u6df7\u5408\u6574\u6570\u51f8\u89c4\u5212\u57fa\u7ebf\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u80fd\u5904\u7406\u590d\u6742\u8f68\u8ff9\u89c4\u5212\u95ee\u9898\uff0c\u5305\u62ec\u9ad8\u9636\u8fde\u7eed\u6027\u7ea6\u675f\u548c\u4e0d\u5b8c\u6574GCS\u3002", "conclusion": "GHOST\u4e3aGCS-TSP\u63d0\u4f9b\u4e86\u6700\u4f18\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6d89\u53ca\u590d\u6742\u7ea6\u675f\u7684\u8f68\u8ff9\u89c4\u5212\u573a\u666f\u3002"}}
{"id": "2511.06522", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06522", "abs": "https://arxiv.org/abs/2511.06522", "authors": ["Jan Ondras", "Marek \u0160uppa"], "title": "FractalBench: Diagnosing Visual-Mathematical Reasoning Through Recursive Program Synthesis", "comment": "Accepted to The 5th Workshop on Mathematical Reasoning and AI at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025); 25 pages, 14 figures, 8 tables; Code available at https://github.com/NaiveNeuron/FractalBench", "summary": "Mathematical reasoning requires abstracting symbolic rules from visual patterns -- inferring the infinite from the finite. We investigate whether multimodal AI systems possess this capability through FractalBench, a benchmark evaluating fractal program synthesis from images. Fractals provide ideal test cases: Iterated Function Systems with only a few contraction maps generate complex self-similar patterns through simple recursive rules, requiring models to bridge visual perception with mathematical abstraction. We evaluate four leading MLLMs -- GPT-4o, Claude 3.7 Sonnet, Gemini 2.5 Flash, and Qwen 2.5-VL -- on 12 canonical fractals. Models must generate executable Python code reproducing the fractal, enabling objective evaluation. Results reveal a striking disconnect: 76% generate syntactically valid code but only 4% capture mathematical structure. Success varies systematically -- models handle geometric transformations (Koch curves: 17-21%) but fail at branching recursion (trees: <2%), revealing fundamental gaps in mathematical abstraction. FractalBench provides a contamination-resistant diagnostic for visual-mathematical reasoning and is available at https://github.com/NaiveNeuron/FractalBench", "AI": {"tldr": "FractalBench\u662f\u4e00\u4e2a\u8bc4\u4f30AI\u7cfb\u7edf\u4ece\u56fe\u50cf\u4e2d\u5408\u6210\u5206\u5f62\u7a0b\u5e8f\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6d4b\u8bd5\u4e86GPT-4o\u3001Claude 3.7 Sonnet\u7b49\u4e3b\u6d41\u591a\u6a21\u6001\u5927\u6a21\u578b\u572812\u79cd\u7ecf\u5178\u5206\u5f62\u4e0a\u7684\u8868\u73b0\u3002\u7ed3\u679c\u663e\u793a\uff0c\u867d\u713676%\u7684\u6a21\u578b\u80fd\u751f\u6210\u8bed\u6cd5\u6709\u6548\u7684\u4ee3\u7801\uff0c\u4f46\u53ea\u67094%\u80fd\u6b63\u786e\u6355\u6349\u6570\u5b66\u7ed3\u6784\uff0c\u63ed\u793a\u4e86\u89c6\u89c9-\u6570\u5b66\u63a8\u7406\u80fd\u529b\u7684\u6839\u672c\u7f3a\u9677\u3002", "motivation": "\u7814\u7a76\u591a\u6a21\u6001AI\u7cfb\u7edf\u662f\u5426\u5177\u5907\u4ece\u89c6\u89c9\u6a21\u5f0f\u4e2d\u62bd\u8c61\u7b26\u53f7\u89c4\u5219\u7684\u80fd\u529b\u2014\u2014\u4ece\u6709\u9650\u63a8\u65ad\u65e0\u9650\u3002\u5206\u5f62\u63d0\u4f9b\u4e86\u7406\u60f3\u7684\u6d4b\u8bd5\u6848\u4f8b\uff0c\u56e0\u4e3a\u8fed\u4ee3\u51fd\u6570\u7cfb\u7edf\u901a\u8fc7\u7b80\u5355\u7684\u9012\u5f52\u89c4\u5219\u751f\u6210\u590d\u6742\u7684\u81ea\u76f8\u4f3c\u6a21\u5f0f\uff0c\u8981\u6c42\u6a21\u578b\u5728\u89c6\u89c9\u611f\u77e5\u548c\u6570\u5b66\u62bd\u8c61\u4e4b\u95f4\u5efa\u7acb\u6865\u6881\u3002", "method": "\u521b\u5efaFractalBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f304\u4e2a\u9886\u5148\u7684\u591a\u6a21\u6001\u5927\u6a21\u578b\u572812\u79cd\u7ecf\u5178\u5206\u5f62\u4e0a\u7684\u8868\u73b0\u3002\u6a21\u578b\u5fc5\u987b\u751f\u6210\u53ef\u6267\u884c\u7684Python\u4ee3\u7801\u6765\u91cd\u73b0\u5206\u5f62\uff0c\u4ece\u800c\u5b9e\u73b0\u5ba2\u89c2\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u663e\u793a\u660e\u663e\u7684\u8131\u8282\uff1a76%\u7684\u6a21\u578b\u80fd\u751f\u6210\u8bed\u6cd5\u6709\u6548\u7684\u4ee3\u7801\uff0c\u4f46\u53ea\u67094%\u80fd\u6b63\u786e\u6355\u6349\u6570\u5b66\u7ed3\u6784\u3002\u6210\u529f\u7387\u56e0\u5206\u5f62\u7c7b\u578b\u800c\u5f02\u2014\u2014\u6a21\u578b\u80fd\u5904\u7406\u51e0\u4f55\u53d8\u6362\uff08Koch\u66f2\u7ebf\uff1a17-21%\uff09\uff0c\u4f46\u5728\u5206\u652f\u9012\u5f52\uff08\u6811\u5f62\u5206\u5f62\uff1a<2%\uff09\u4e0a\u5931\u8d25\uff0c\u63ed\u793a\u4e86\u6570\u5b66\u62bd\u8c61\u80fd\u529b\u7684\u6839\u672c\u5dee\u8ddd\u3002", "conclusion": "FractalBench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6297\u6c61\u67d3\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9-\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u591a\u6a21\u6001AI\u5728\u6570\u5b66\u62bd\u8c61\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u9012\u5f52\u7ed3\u6784\u65f6\u5b58\u5728\u6839\u672c\u6027\u7f3a\u9677\u3002"}}
{"id": "2511.06618", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.06618", "abs": "https://arxiv.org/abs/2511.06618", "authors": ["Moriya Dechtiar", "Daniel Martin Katz", "Mari Sundaresan", "Sylvain Jaume", "Hongming Wang"], "title": "GRAPH-GRPO-LEX: Contract Graph Modeling and Reinforcement Learning with Group Relative Policy Optimization", "comment": null, "summary": "Contracts are complex documents featuring detailed formal structures, explicit and implicit dependencies and rich semantic content. Given these document properties, contract drafting and manual examination of contracts have proven to be both arduous and susceptible to errors. This work aims to simplify and automate the task of contract review and analysis using a novel framework for transforming legal contracts into structured semantic graphs, enabling computational analysis and data-driven insights. We introduce a detailed ontology mapping core legal contract elements to their graph-theoretic equivalents of nodes and edges. We then present a reinforcement learning based Large Language Model (LLM) framework for segmentation and extraction of entities and relationships from contracts. Our method, GRAPH-GRPO-LEX, incorporates both LLMs and reinforcement learning with group relative policy optimization (GRPO). By applying a carefully drafted reward function of graph metrics, we demonstrate the ability to automatically identify direct relationships between clauses, and even uncover hidden dependencies. Our introduction of the gated GRPO approach shows a strong learning signal and can move contract analysis from a linear, manual reading process to an easily visualized graph. This allows for a more dynamic analysis, including building the groundwork for contract linting similar to what is now practiced in software engineering.", "AI": {"tldr": "\u63d0\u51faGRAPH-GRPO-LEX\u6846\u67b6\uff0c\u5c06\u6cd5\u5f8b\u5408\u540c\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u8bed\u4e49\u56fe\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60LLM\u81ea\u52a8\u8bc6\u522b\u6761\u6b3e\u5173\u7cfb\u548c\u9690\u85cf\u4f9d\u8d56\u3002", "motivation": "\u5408\u540c\u6587\u4ef6\u7ed3\u6784\u590d\u6742\u3001\u4f9d\u8d56\u5173\u7cfb\u4e30\u5bcc\uff0c\u4eba\u5de5\u5ba1\u67e5\u65e2\u8d39\u65f6\u53c8\u5bb9\u6613\u51fa\u9519\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5408\u540c\u5206\u6790\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684LLM\u6846\u67b6\uff0c\u7ed3\u5408\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(GRPO)\uff0c\u901a\u8fc7\u56fe\u6307\u6807\u5956\u52b1\u51fd\u6570\u4ece\u5408\u540c\u4e2d\u63d0\u53d6\u5b9e\u4f53\u548c\u5173\u7cfb\u3002", "result": "\u80fd\u591f\u81ea\u52a8\u8bc6\u522b\u6761\u6b3e\u95f4\u7684\u76f4\u63a5\u5173\u7cfb\uff0c\u53d1\u73b0\u9690\u85cf\u4f9d\u8d56\uff0c\u5c06\u5408\u540c\u5206\u6790\u4ece\u7ebf\u6027\u4eba\u5de5\u9605\u8bfb\u8f6c\u53d8\u4e3a\u53ef\u89c6\u5316\u56fe\u5f62\u5206\u6790\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5408\u540clinting\u5960\u5b9a\u57fa\u7840\uff0c\u7c7b\u4f3c\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\uff0c\u5b9e\u73b0\u4e86\u5408\u540c\u5206\u6790\u7684\u81ea\u52a8\u5316\u548c\u52a8\u6001\u53ef\u89c6\u5316\u3002"}}
{"id": "2511.06626", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06626", "abs": "https://arxiv.org/abs/2511.06626", "authors": ["Chloe Li", "Mary Phuong", "Daniel Tan"], "title": "Spilling the Beans: Teaching LLMs to Self-Report Their Hidden Objectives", "comment": null, "summary": "As AI systems become more capable of complex agentic tasks, they also become more capable of pursuing undesirable objectives and causing harm. Previous work has attempted to catch these unsafe instances by interrogating models directly about their objectives and behaviors. However, the main weakness of trusting interrogations is that models can lie. We propose self-report fine-tuning (SRFT), a simple supervised fine-tuning technique that trains models to admit their factual mistakes when asked. We show that the admission of factual errors in simple question-answering settings generalizes out-of-distribution (OOD) to the admission of hidden misaligned objectives in adversarial agentic settings. We evaluate SRFT in OOD stealth tasks, where models are instructed to complete a hidden misaligned objective alongside a user-specified objective without being caught by monitoring. After SRFT, models are more likely to confess the details of their hidden objectives when interrogated, even under strong pressure not to disclose them. Interrogation on SRFT models can detect hidden objectives with near-ceiling performance (F1 score = 0.98), while the baseline model lies when interrogated under the same conditions (F1 score = 0). Interrogation on SRFT models can further elicit the content of the hidden objective, recovering 28-100% details, compared to 0% details recovered in the baseline model and by prefilled assistant turn attacks. This provides a promising technique for promoting honesty propensity and incriminating misaligned AI systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u81ea\u62a5\u544a\u5fae\u8c03\uff08SRFT\uff09\u7684\u76d1\u7763\u5fae\u8c03\u6280\u672f\uff0c\u8bad\u7ec3\u6a21\u578b\u5728\u88ab\u8be2\u95ee\u65f6\u627f\u8ba4\u4e8b\u5b9e\u9519\u8bef\uff0c\u8fd9\u79cd\u80fd\u529b\u53ef\u4ee5\u6cdb\u5316\u5230\u5bf9\u6297\u6027\u4ee3\u7406\u8bbe\u7f6e\u4e2d\uff0c\u4f7f\u6a21\u578b\u66f4\u53ef\u80fd\u5766\u767d\u9690\u85cf\u7684\u4e0d\u5bf9\u9f50\u76ee\u6807\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u80fd\u591f\u6267\u884c\u66f4\u590d\u6742\u7684\u4ee3\u7406\u4efb\u52a1\uff0c\u5b83\u4eec\u4e5f\u53d8\u5f97\u66f4\u80fd\u591f\u8ffd\u6c42\u4e0d\u826f\u76ee\u6807\u5e76\u9020\u6210\u4f24\u5bb3\u3002\u73b0\u6709\u901a\u8fc7\u76f4\u63a5\u8be2\u95ee\u6a21\u578b\u6765\u6355\u6349\u4e0d\u5b89\u5168\u5b9e\u4f8b\u7684\u65b9\u6cd5\u5b58\u5728\u5f31\u70b9\uff0c\u5373\u6a21\u578b\u53ef\u4ee5\u8bf4\u8c0e\u3002", "method": "\u4f7f\u7528\u81ea\u62a5\u544a\u5fae\u8c03\uff08SRFT\uff09\u6280\u672f\uff0c\u5728\u7b80\u5355\u7684\u95ee\u7b54\u8bbe\u7f6e\u4e2d\u8bad\u7ec3\u6a21\u578b\u627f\u8ba4\u4e8b\u5b9e\u9519\u8bef\uff0c\u7136\u540e\u5c06\u8fd9\u79cd\u80fd\u529b\u6cdb\u5316\u5230\u5bf9\u6297\u6027\u4ee3\u7406\u73af\u5883\u4e2d\u3002", "result": "\u5728OOD\u9690\u8eab\u4efb\u52a1\u4e2d\uff0c\u7ecf\u8fc7SRFT\u7684\u6a21\u578b\u5728\u88ab\u8be2\u95ee\u65f6\u66f4\u53ef\u80fd\u5766\u767d\u9690\u85cf\u76ee\u6807\u7684\u7ec6\u8282\uff0c\u68c0\u6d4b\u9690\u85cf\u76ee\u6807\u7684F1\u5206\u6570\u8fbe\u52300.98\uff08\u57fa\u7ebf\u6a21\u578b\u4e3a0\uff09\uff0c\u80fd\u591f\u6062\u590d28-100%\u7684\u9690\u85cf\u76ee\u6807\u7ec6\u8282\uff08\u57fa\u7ebf\u6a21\u578b\u4e3a0%\uff09\u3002", "conclusion": "SRFT\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u6280\u672f\uff0c\u53ef\u4ee5\u4fc3\u8fdb\u8bda\u5b9e\u503e\u5411\u5e76\u63ed\u9732\u4e0d\u5bf9\u9f50\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2511.06761", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06761", "abs": "https://arxiv.org/abs/2511.06761", "authors": ["Fei Yang"], "title": "SRNN: Spatiotemporal Relational Neural Network for Intuitive Physics Understanding", "comment": null, "summary": "Human prowess in intuitive physics remains unmatched by machines. To bridge this gap, we argue for a fundamental shift towards brain-inspired computational principles. This paper introduces the Spatiotemporal Relational Neural Network (SRNN), a model that establishes a unified neural representation for object attributes, relations, and timeline, with computations governed by a Hebbian ``Fire Together, Wire Together'' mechanism across dedicated \\textit{What} and \\textit{How} pathways. This unified representation is directly used to generate structured linguistic descriptions of the visual scene, bridging perception and language within a shared neural substrate. Moreover, unlike the prevalent ``pretrain-then-finetune'' paradigm, SRNN adopts a ``predefine-then-finetune'' approach. On the CLEVRER benchmark, SRNN achieves competitive performance. Our analysis further reveals a benchmark bias, outlines a path for a more holistic evaluation, and demonstrates SRNN's white-box utility for precise error diagnosis. Our work confirms the viability of translating biological intelligence into engineered systems for intuitive physics understanding.", "AI": {"tldr": "SRNN\u6a21\u578b\u901a\u8fc7\u5927\u8111\u542f\u53d1\u7684\u8ba1\u7b97\u539f\u7406\uff0c\u5efa\u7acb\u7edf\u4e00\u7684\u795e\u7ecf\u8868\u793a\u6765\u5904\u7406\u7269\u4f53\u5c5e\u6027\u3001\u5173\u7cfb\u548c\u65f6\u5e8f\uff0c\u5728CLEVRER\u57fa\u51c6\u4e0a\u53d6\u5f97\u7ade\u4e89\u6027\u8868\u73b0\uff0c\u5e76\u5c55\u793a\u4e86\u767d\u76d2\u8bca\u65ad\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u5728\u76f4\u89c9\u7269\u7406\u7406\u89e3\u65b9\u9762\u4e0e\u4eba\u7c7b\u80fd\u529b\u5dee\u8ddd\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u8f6c\u5411\u5927\u8111\u542f\u53d1\u7684\u8ba1\u7b97\u539f\u5219\u6765\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u65f6\u7a7a\u5173\u7cfb\u795e\u7ecf\u7f51\u7edc(SRNN)\uff0c\u5efa\u7acb\u7edf\u4e00\u7684\u795e\u7ecf\u8868\u793a\u6765\u5904\u7406\u7269\u4f53\u5c5e\u6027\u3001\u5173\u7cfb\u548c\u65f6\u5e8f\uff0c\u91c7\u7528Hebbian \"\u4e00\u8d77\u6fc0\u53d1\uff0c\u4e00\u8d77\u8fde\u63a5\"\u673a\u5236\uff0c\u901a\u8fc7\u4e13\u95e8\u7684What\u548cHow\u901a\u8def\u8fdb\u884c\u8ba1\u7b97\uff0c\u91c7\u7528\"\u9884\u5b9a\u4e49-\u7136\u540e\u5fae\u8c03\"\u65b9\u6cd5\u800c\u975e\u4f20\u7edf\u7684\"\u9884\u8bad\u7ec3-\u7136\u540e\u5fae\u8c03\"\u8303\u5f0f\u3002", "result": "\u5728CLEVRER\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u63ed\u793a\u4e86\u57fa\u51c6\u504f\u5dee\uff0c\u5e76\u5c55\u793a\u4e86\u767d\u76d2\u8bca\u65ad\u80fd\u529b\uff0c\u80fd\u591f\u8fdb\u884c\u7cbe\u786e\u7684\u9519\u8bef\u5206\u6790\u3002", "conclusion": "\u8bc1\u5b9e\u4e86\u5c06\u751f\u7269\u667a\u80fd\u8f6c\u5316\u4e3a\u5de5\u7a0b\u7cfb\u7edf\u7528\u4e8e\u76f4\u89c9\u7269\u7406\u7406\u89e3\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6307\u660e\u4e86\u8def\u5f84\u3002"}}
{"id": "2511.06805", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06805", "abs": "https://arxiv.org/abs/2511.06805", "authors": ["Jinhao Chen", "Zhen Yang", "Jianxin Shi", "Tianyu Wo", "Jie Tang"], "title": "MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning", "comment": "19 pages, 11 figures", "summary": "Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in vision-language answering tasks. Despite their strengths, these models often encounter challenges in achieving complex reasoning tasks such as mathematical problem-solving. Previous works have focused on fine-tuning on specialized mathematical datasets. However, these datasets are typically distilled directly from teacher models, which capture only static reasoning patterns and leaving substantial gaps compared to student models. This reliance on fixed teacher-derived datasets not only restricts the model's ability to adapt to novel or more intricate questions that extend beyond the confines of the training data, but also lacks the iterative depth needed for robust generalization. To overcome these limitations, we propose \\textbf{\\method}, a \\textbf{Math}ematical \\textbf{S}elf-\\textbf{E}volving framework for MLLMs. In contrast to traditional one-shot fine-tuning paradigms, \\method iteratively refines the model through cycles of inference, reflection, and reward-based feedback. Specifically, we leverage iterative fine-tuning by incorporating correct reasoning paths derived from previous-stage inference and integrating reflections from a specialized Outcome Reward Model (ORM). To verify the effectiveness of \\method, we evaluate it on a suite of challenging benchmarks, demonstrating significant performance gains over backbone models. Notably, our experimental results on MathVL-test surpass the leading open-source multimodal mathematical reasoning model QVQ. Our code and models are available at \\texttt{https://zheny2751\\allowbreak-dotcom.github.io/\\allowbreak MathSE.github.io/}.", "AI": {"tldr": "\u63d0\u51fa\u4e86MathSE\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u7406-\u53cd\u601d-\u5956\u52b1\u53cd\u9988\u7684\u8fed\u4ee3\u5faa\u73af\u6765\u589e\u5f3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u4e00\u6b21\u6027\u5fae\u8c03\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709MLLMs\u5728\u590d\u6742\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u6559\u5e08\u6a21\u578b\u84b8\u998f\u7684\u9759\u6001\u6570\u636e\u96c6\uff0c\u7f3a\u4e4f\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u91c7\u7528\u8fed\u4ee3\u5fae\u8c03\u7b56\u7565\uff0c\u7ed3\u5408\u524d\u9636\u6bb5\u63a8\u7406\u7684\u6b63\u786e\u8def\u5f84\u548c\u4e13\u95e8\u7ed3\u679c\u5956\u52b1\u6a21\u578b(ORM)\u7684\u53cd\u601d\u53cd\u9988\uff0c\u5b9e\u73b0\u6a21\u578b\u7684\u81ea\u6211\u8fdb\u5316\u3002", "result": "\u5728\u591a\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5728MathVL-test\u4e0a\u8d85\u8d8a\u4e86\u9886\u5148\u7684\u5f00\u6e90\u591a\u6a21\u6001\u6570\u5b66\u63a8\u7406\u6a21\u578bQVQ\u3002", "conclusion": "MathSE\u6846\u67b6\u901a\u8fc7\u8fed\u4ee3\u81ea\u6211\u8fdb\u5316\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86MLLMs\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.06918", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06918", "abs": "https://arxiv.org/abs/2511.06918", "authors": ["Gilles Audemard", "Christophe Lecoutre", "Emmanuel Lonca"], "title": "Proceedings of the 2025 XCSP3 Competition", "comment": "110 pages", "summary": "This document represents the proceedings of the 2025 XCSP3 Competition. The results of this competition of constraint solvers were presented at CP'25 (31st International Conference on Principles and Practice of Constraint Programming).", "AI": {"tldr": "2025\u5e74XCSP3\u7ade\u8d5b\u8bba\u6587\u96c6\uff0c\u5305\u542b\u5728CP'25\u4f1a\u8bae\u4e0a\u5c55\u793a\u7684\u7ea6\u675f\u6c42\u89e3\u5668\u7ade\u8d5b\u7ed3\u679c", "motivation": "\u8bb0\u5f55\u548c\u5c55\u793a2025\u5e74XCSP3\u7ea6\u675f\u6c42\u89e3\u5668\u7ade\u8d5b\u7684\u6210\u679c\uff0c\u4e3a\u7ea6\u675f\u7f16\u7a0b\u793e\u533a\u63d0\u4f9b\u6700\u65b0\u7684\u6c42\u89e3\u5668\u6027\u80fd\u6bd4\u8f83", "method": "\u7ec4\u7ec7\u7ea6\u675f\u6c42\u89e3\u5668\u7ade\u8d5b\uff0c\u6536\u96c6\u5404\u53c2\u8d5b\u6c42\u89e3\u5668\u5728\u6807\u51c6\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8868\u73b0\u6570\u636e", "result": "\u5728CP'25\u4f1a\u8bae\u4e0a\u516c\u5e03\u4e86\u7ade\u8d5b\u7ed3\u679c\uff0c\u5c55\u793a\u4e86\u5404\u7ea6\u675f\u6c42\u89e3\u5668\u7684\u76f8\u5bf9\u6027\u80fd", "conclusion": "\u8be5\u8bba\u6587\u96c6\u8bb0\u5f55\u4e862025\u5e74XCSP3\u7ade\u8d5b\u7684\u5b8c\u6574\u7ed3\u679c\uff0c\u4e3a\u7ea6\u675f\u7f16\u7a0b\u9886\u57df\u7684\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003"}}
{"id": "2511.07061", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07061", "abs": "https://arxiv.org/abs/2511.07061", "authors": ["Xinran Li", "Xiujuan Xu", "Jiaqi Qiao", "Yu Liu"], "title": "Do LLMs Feel? Teaching Emotion Recognition with Prompts, Retrieval, and Curriculum Learning", "comment": "Accepted at AAAI 2026", "summary": "Emotion Recognition in Conversation (ERC) is a crucial task for understanding human emotions and enabling natural human-computer interaction. Although Large Language Models (LLMs) have recently shown great potential in this field, their ability to capture the intrinsic connections between explicit and implicit emotions remains limited. We propose a novel ERC training framework, PRC-Emo, which integrates Prompt engineering, demonstration Retrieval, and Curriculum learning, with the goal of exploring whether LLMs can effectively perceive emotions in conversational contexts. Specifically, we design emotion-sensitive prompt templates based on both explicit and implicit emotional cues to better guide the model in understanding the speaker's psychological states. We construct the first dedicated demonstration retrieval repository for ERC, which includes training samples from widely used datasets, as well as high-quality dialogue examples generated by LLMs and manually verified. Moreover, we introduce a curriculum learning strategy into the LoRA fine-tuning process, incorporating weighted emotional shifts between same-speaker and different-speaker utterances to assign difficulty levels to dialogue samples, which are then organized in an easy-to-hard training sequence. Experimental results on two benchmark datasets-- IEMOCAP and MELD --show that our method achieves new state-of-the-art (SOTA) performance, demonstrating the effectiveness and generalizability of our approach in improving LLM-based emotional understanding.", "AI": {"tldr": "\u63d0\u51fa\u4e86PRC-Emo\u6846\u67b6\uff0c\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u3001\u6f14\u793a\u68c0\u7d22\u548c\u8bfe\u7a0b\u5b66\u4e60\uff0c\u63d0\u5347LLM\u5728\u5bf9\u8bdd\u60c5\u611f\u8bc6\u522b\u4e2d\u7684\u8868\u73b0\uff0c\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM\u5728\u6355\u6349\u5bf9\u8bdd\u4e2d\u663e\u6027\u548c\u9690\u6027\u60c5\u611f\u4e4b\u95f4\u5185\u5728\u8054\u7cfb\u7684\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u6539\u8fdb\u5176\u5728\u5bf9\u8bdd\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u8bbe\u8ba1\u60c5\u611f\u654f\u611f\u63d0\u793a\u6a21\u677f\uff0c\u6784\u5efa\u9996\u4e2aERC\u4e13\u7528\u6f14\u793a\u68c0\u7d22\u5e93\uff0c\u5e76\u5728LoRA\u5fae\u8c03\u4e2d\u5f15\u5165\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u6309\u60c5\u611f\u8f6c\u79fb\u96be\u5ea6\u7ec4\u7ec7\u8bad\u7ec3\u6837\u672c\u3002", "result": "\u5728IEMOCAP\u548cMELD\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "PRC-Emo\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u5bf9\u8bdd\u60c5\u611f\u7406\u89e3\u65b9\u9762\u7684\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u6cdb\u5316\u6027\u3002"}}
{"id": "2511.07062", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07062", "abs": "https://arxiv.org/abs/2511.07062", "authors": ["Yimei Zhang", "Guojiang Shen", "Kaili Ning", "Tongwei Ren", "Xuebo Qiu", "Mengmeng Wang", "Xiangjie Kong"], "title": "Improving Region Representation Learning from Urban Imagery with Noisy Long-Caption Supervision", "comment": "Accepted as a full paper by AAAI-26", "summary": "Region representation learning plays a pivotal role in urban computing by extracting meaningful features from unlabeled urban data. Analogous to how perceived facial age reflects an individual's health, the visual appearance of a city serves as its ``portrait\", encapsulating latent socio-economic and environmental characteristics. Recent studies have explored leveraging Large Language Models (LLMs) to incorporate textual knowledge into imagery-based urban region representation learning. However, two major challenges remain: i)~difficulty in aligning fine-grained visual features with long captions, and ii) suboptimal knowledge incorporation due to noise in LLM-generated captions. To address these issues, we propose a novel pre-training framework called UrbanLN that improves Urban region representation learning through Long-text awareness and Noise suppression. Specifically, we introduce an information-preserved stretching interpolation strategy that aligns long captions with fine-grained visual semantics in complex urban scenes. To effectively mine knowledge from LLM-generated captions and filter out noise, we propose a dual-level optimization strategy. At the data level, a multi-model collaboration pipeline automatically generates diverse and reliable captions without human intervention. At the model level, we employ a momentum-based self-distillation mechanism to generate stable pseudo-targets, facilitating robust cross-modal learning under noisy conditions. Extensive experiments across four real-world cities and various downstream tasks demonstrate the superior performance of our UrbanLN.", "AI": {"tldr": "UrbanLN\uff1a\u901a\u8fc7\u957f\u6587\u672c\u611f\u77e5\u548c\u566a\u58f0\u6291\u5236\u6539\u8fdb\u57ce\u5e02\u533a\u57df\u8868\u793a\u5b66\u4e60\u7684\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u89e3\u51b3\u89c6\u89c9\u7279\u5f81\u4e0e\u957f\u6587\u672c\u5bf9\u9f50\u56f0\u96be\u4ee5\u53caLLM\u751f\u6210\u6587\u672c\u566a\u58f0\u95ee\u9898", "motivation": "\u57ce\u5e02\u89c6\u89c9\u5916\u89c2\u5982\u540c\"\u8096\u50cf\"\uff0c\u8574\u542b\u793e\u4f1a\u7ecf\u6d4e\u548c\u73af\u5883\u7279\u5f81\u3002\u73b0\u6709\u65b9\u6cd5\u5229\u7528LLM\u5c06\u6587\u672c\u77e5\u8bc6\u878d\u5165\u56fe\u50cf\u57fa\u57ce\u5e02\u533a\u57df\u8868\u793a\u5b66\u4e60\uff0c\u4f46\u9762\u4e34\u7ec6\u7c92\u5ea6\u89c6\u89c9\u7279\u5f81\u4e0e\u957f\u6587\u672c\u5bf9\u9f50\u56f0\u96be\u3001LLM\u751f\u6210\u6587\u672c\u566a\u58f0\u5f71\u54cd\u77e5\u8bc6\u878d\u5408\u7684\u95ee\u9898", "method": "\u63d0\u51fa\u4fe1\u606f\u4fdd\u7559\u62c9\u4f38\u63d2\u503c\u7b56\u7565\u5bf9\u9f50\u957f\u6587\u672c\u4e0e\u7ec6\u7c92\u5ea6\u89c6\u89c9\u8bed\u4e49\uff1b\u91c7\u7528\u53cc\u7ea7\u4f18\u5316\u7b56\u7565\uff1a\u6570\u636e\u7ea7\u901a\u8fc7\u591a\u6a21\u578b\u534f\u4f5c\u81ea\u52a8\u751f\u6210\u591a\u6837\u53ef\u9760\u6587\u672c\uff0c\u6a21\u578b\u7ea7\u4f7f\u7528\u52a8\u91cf\u81ea\u84b8\u998f\u673a\u5236\u751f\u6210\u7a33\u5b9a\u4f2a\u76ee\u6807\uff0c\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9c81\u68d2\u8de8\u6a21\u6001\u5b66\u4e60", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u57ce\u5e02\u548c\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660eUrbanLN\u5177\u6709\u4f18\u8d8a\u6027\u80fd", "conclusion": "UrbanLN\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u57ce\u5e02\u533a\u57df\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u957f\u6587\u672c\u5bf9\u9f50\u548c\u566a\u58f0\u6291\u5236\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u8868\u793a\u5b66\u4e60\u8d28\u91cf"}}
{"id": "2511.07070", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07070", "abs": "https://arxiv.org/abs/2511.07070", "authors": ["Fei Zhao", "Chonggang Lu", "Haofu Qian", "Fangcheng Shi", "Zijie Meng", "Jianzhao Huang", "Xu Tang", "Zheyong Xie", "Zheyu Ye", "Zhe Xu", "Yao Hu", "Shaosheng Cao"], "title": "RedOne 2.0: Rethinking Domain-specific LLM Post-Training in Social Networking Services", "comment": null, "summary": "As a key medium for human interaction and information exchange, social networking services (SNS) pose unique challenges for large language models (LLMs): heterogeneous workloads, fast-shifting norms and slang, and multilingual, culturally diverse corpora that induce sharp distribution shift. Supervised fine-tuning (SFT) can specialize models but often triggers a ``seesaw'' between in-distribution gains and out-of-distribution robustness, especially for smaller models. To address these challenges, we introduce RedOne 2.0, an SNS-oriented LLM trained with a progressive, RL-prioritized post-training paradigm designed for rapid and stable adaptation. The pipeline consist in three stages: (1) Exploratory Learning on curated SNS corpora to establish initial alignment and identify systematic weaknesses; (2) Targeted Fine-Tuning that selectively applies SFT to the diagnosed gaps while mixing a small fraction of general data to mitigate forgetting; and (3) Refinement Learning that re-applies RL with SNS-centric signals to consolidate improvements and harmonize trade-offs across tasks. Across various tasks spanning three categories, our 4B scale model delivers an average improvements about 2.41 over the 7B sub-optimal baseline. Additionally, RedOne 2.0 achieves average performance lift about 8.74 from the base model with less than half the data required by SFT-centric method RedOne, evidencing superior data efficiency and stability at compact scales. Overall, RedOne 2.0 establishes a competitive, cost-effective baseline for domain-specific LLMs in SNS scenario, advancing capability without sacrificing robustness.", "AI": {"tldr": "RedOne 2.0\u662f\u4e00\u4e2a\u9762\u5411\u793e\u4ea4\u7f51\u7edc\u670d\u52a1\u7684LLM\uff0c\u91c7\u7528\u6e10\u8fdb\u5f0fRL\u4f18\u5148\u7684\u540e\u8bad\u7ec3\u8303\u5f0f\uff0c\u901a\u8fc7\u63a2\u7d22\u6027\u5b66\u4e60\u3001\u9488\u5bf9\u6027\u5fae\u8c03\u548c\u7cbe\u70bc\u5b66\u4e60\u4e09\u4e2a\u9636\u6bb5\uff0c\u57284B\u89c4\u6a21\u4e0a\u5b9e\u73b0\u4e86\u4f18\u4e8e7B\u57fa\u7ebf\u7684\u6027\u80fd\uff0c\u6570\u636e\u6548\u7387\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u793e\u4ea4\u7f51\u7edc\u670d\u52a1(SNS)\u5b58\u5728\u5f02\u6784\u5de5\u4f5c\u8d1f\u8f7d\u3001\u5feb\u901f\u53d8\u5316\u7684\u89c4\u8303\u548c\u4fda\u8bed\u3001\u591a\u8bed\u8a00\u6587\u5316\u591a\u6837\u6027\u7b49\u6311\u6218\uff0c\u4f20\u7edf\u76d1\u7763\u5fae\u8c03\u5bb9\u6613\u5bfc\u81f4\u5206\u5e03\u5185\u5916\u6027\u80fd\u7684\"\u8df7\u8df7\u677f\"\u6548\u5e94\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5c0f\u6a21\u578b\u3002", "method": "\u4e09\u9636\u6bb5\u6e10\u8fdb\u5f0f\u8bad\u7ec3\uff1a1) \u63a2\u7d22\u6027\u5b66\u4e60\u5efa\u7acb\u521d\u59cb\u5bf9\u9f50\u5e76\u8bc6\u522b\u7cfb\u7edf\u5f31\u70b9\uff1b2) \u9488\u5bf9\u6027\u5fae\u8c03\u9009\u62e9\u6027\u5e94\u7528SFT\u586b\u8865\u8bca\u65ad\u51fa\u7684\u5dee\u8ddd\uff0c\u540c\u65f6\u6df7\u5408\u5c11\u91cf\u901a\u7528\u6570\u636e\u9632\u6b62\u9057\u5fd8\uff1b3) \u7cbe\u70bc\u5b66\u4e60\u91cd\u65b0\u5e94\u7528RL\u4e0eSNS\u4e2d\u5fc3\u4fe1\u53f7\u6765\u5de9\u56fa\u6539\u8fdb\u5e76\u534f\u8c03\u4efb\u52a1\u95f4\u6743\u8861\u3002", "result": "\u57284B\u89c4\u6a21\u4e0a\uff0c\u76f8\u6bd47B\u6b21\u4f18\u57fa\u7ebf\u5e73\u5747\u63d0\u53472.41\u5206\uff1b\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u5e73\u5747\u6027\u80fd\u63d0\u53478.74\u5206\uff0c\u6240\u9700\u6570\u636e\u91cf\u4e0d\u5230SFT\u4e2d\u5fc3\u65b9\u6cd5RedOne\u7684\u4e00\u534a\uff0c\u8bc1\u660e\u4e86\u5728\u7d27\u51d1\u89c4\u6a21\u4e0b\u7684\u4f18\u8d8a\u6570\u636e\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "RedOne 2.0\u4e3aSNS\u573a\u666f\u4e2d\u7684\u9886\u57df\u7279\u5b9aLLM\u5efa\u7acb\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u6210\u672c\u6548\u76ca\u57fa\u7ebf\uff0c\u5728\u4e0d\u727a\u7272\u9c81\u68d2\u6027\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u4e86\u80fd\u529b\u3002"}}
{"id": "2511.07083", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07083", "abs": "https://arxiv.org/abs/2511.07083", "authors": ["Marc Jansen", "Marcel Pehlke"], "title": "Increasing AI Explainability by LLM Driven Standard Processes", "comment": null, "summary": "This paper introduces an approach to increasing the explainability of artificial intelligence (AI) systems by embedding Large Language Models (LLMs) within standardized analytical processes. While traditional explainable AI (XAI) methods focus on feature attribution or post-hoc interpretation, the proposed framework integrates LLMs into defined decision models such as Question-Option-Criteria (QOC), Sensitivity Analysis, Game Theory, and Risk Management. By situating LLM reasoning within these formal structures, the approach transforms opaque inference into transparent and auditable decision traces. A layered architecture is presented that separates the reasoning space of the LLM from the explainable process space above it. Empirical evaluations show that the system can reproduce human-level decision logic in decentralized governance, systems analysis, and strategic reasoning contexts. The results suggest that LLM-driven standard processes provide a foundation for reliable, interpretable, and verifiable AI-supported decision making.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5c06LLM\u5d4c\u5165\u6807\u51c6\u5316\u5206\u6790\u6d41\u7a0b\u6765\u63d0\u9ad8AI\u7cfb\u7edf\u53ef\u89e3\u91ca\u6027\u7684\u65b9\u6cd5\uff0c\u5c06LLM\u63a8\u7406\u7f6e\u4e8e\u6b63\u5f0f\u51b3\u7b56\u6846\u67b6\u4e2d\uff0c\u5b9e\u73b0\u900f\u660e\u53ef\u5ba1\u8ba1\u7684\u51b3\u7b56\u8ffd\u8e2a\u3002", "motivation": "\u4f20\u7edf\u53ef\u89e3\u91caAI\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7279\u5f81\u5f52\u56e0\u6216\u4e8b\u540e\u89e3\u91ca\uff0c\u7f3a\u4e4f\u5c06LLM\u63a8\u7406\u8fc7\u7a0b\u6574\u5408\u5230\u7ed3\u6784\u5316\u51b3\u7b56\u6a21\u578b\u4e2d\u7684\u7cfb\u7edf\u6027\u65b9\u6cd5\u3002", "method": "\u5728QOC\u3001\u654f\u611f\u6027\u5206\u6790\u3001\u535a\u5f08\u8bba\u548c\u98ce\u9669\u7ba1\u7406\u7b49\u6807\u51c6\u5316\u51b3\u7b56\u6a21\u578b\u4e2d\u5d4c\u5165LLM\uff0c\u91c7\u7528\u5206\u5c42\u67b6\u6784\u5206\u79bbLLM\u63a8\u7406\u7a7a\u95f4\u548c\u53ef\u89e3\u91ca\u8fc7\u7a0b\u7a7a\u95f4\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\u7cfb\u7edf\u80fd\u591f\u5728\u53bb\u4e2d\u5fc3\u5316\u6cbb\u7406\u3001\u7cfb\u7edf\u5206\u6790\u548c\u6218\u7565\u63a8\u7406\u7b49\u573a\u666f\u4e2d\u91cd\u73b0\u4eba\u7c7b\u6c34\u5e73\u7684\u51b3\u7b56\u903b\u8f91\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u6807\u51c6\u6d41\u7a0b\u4e3a\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u9a8c\u8bc1\u7684AI\u8f85\u52a9\u51b3\u7b56\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.07086", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07086", "abs": "https://arxiv.org/abs/2511.07086", "authors": ["Marcel Pehlke", "Marc Jansen"], "title": "LLM Driven Processes to Foster Explainable AI", "comment": null, "summary": "We present a modular, explainable LLM-agent pipeline for decision support that externalizes reasoning into auditable artifacts. The system instantiates three frameworks: Vester's Sensitivity Model (factor set, signed impact matrix, systemic roles, feedback loops); normal-form games (strategies, payoff matrix, equilibria); and sequential games (role-conditioned agents, tree construction, backward induction), with swappable modules at every step. LLM components (default: GPT-5) are paired with deterministic analyzers for equilibria and matrix-based role classification, yielding traceable intermediates rather than opaque outputs. In a real-world logistics case (100 runs), mean factor alignment with a human baseline was 55.5\\% over 26 factors and 62.9\\% on the transport-core subset; role agreement over matches was 57\\%. An LLM judge using an eight-criterion rubric (max 100) scored runs on par with a reconstructed human baseline. Configurable LLM pipelines can thus mimic expert workflows with transparent, inspectable steps.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u53ef\u89e3\u91ca\u7684LLM\u4ee3\u7406\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u901a\u8fc7\u5916\u90e8\u5316\u63a8\u7406\u751f\u6210\u53ef\u5ba1\u8ba1\u7684\u4e2d\u95f4\u4ea7\u7269\uff0c\u7ed3\u5408\u4e09\u79cd\u6846\u67b6\uff08\u654f\u611f\u6027\u6a21\u578b\u3001\u535a\u5f08\u8bba\u3001\u5e8f\u5217\u535a\u5f08\uff09\u8fdb\u884c\u51b3\u7b56\u5206\u6790\u3002", "motivation": "\u5f00\u53d1\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u901a\u8fc7\u5916\u90e8\u5316\u63a8\u7406\u8fc7\u7a0b\u751f\u6210\u53ef\u5ba1\u8ba1\u7684\u4e2d\u95f4\u4ea7\u7269\uff0c\u63d0\u9ad8\u51b3\u7b56\u8fc7\u7a0b\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316LLM\u4ee3\u7406\u7ba1\u9053\uff0c\u7ed3\u5408Vester\u654f\u611f\u6027\u6a21\u578b\uff08\u56e0\u5b50\u96c6\u3001\u7b26\u53f7\u5f71\u54cd\u77e9\u9635\u3001\u7cfb\u7edf\u89d2\u8272\u3001\u53cd\u9988\u5faa\u73af\uff09\u3001\u6807\u51c6\u5f62\u5f0f\u535a\u5f08\uff08\u7b56\u7565\u3001\u652f\u4ed8\u77e9\u9635\u3001\u5747\u8861\uff09\u548c\u5e8f\u5217\u535a\u5f08\uff08\u89d2\u8272\u6761\u4ef6\u4ee3\u7406\u3001\u6811\u6784\u5efa\u3001\u9006\u5411\u5f52\u7eb3\uff09\uff0c\u6bcf\u4e2a\u6b65\u9aa4\u90fd\u652f\u6301\u6a21\u5757\u66ff\u6362\u3002", "result": "\u5728\u771f\u5b9e\u7269\u6d41\u6848\u4f8b\u4e2d\uff08100\u6b21\u8fd0\u884c\uff09\uff0c\u4e0e\u4eba\u7c7b\u57fa\u7ebf\u76f8\u6bd4\uff0c26\u4e2a\u56e0\u5b50\u7684\u5e73\u5747\u5bf9\u9f50\u5ea6\u4e3a55.5%\uff0c\u8fd0\u8f93\u6838\u5fc3\u5b50\u96c6\u4e3a62.9%\uff1b\u89d2\u8272\u5339\u914d\u4e00\u81f4\u6027\u4e3a57%\u3002LLM\u8bc4\u4f30\u5668\u4f7f\u7528\u516b\u9879\u6807\u51c6\u8bc4\u5206\uff08\u6ee1\u5206100\uff09\u4e0e\u91cd\u6784\u7684\u4eba\u7c7b\u57fa\u7ebf\u76f8\u5f53\u3002", "conclusion": "\u53ef\u914d\u7f6e\u7684LLM\u7ba1\u9053\u80fd\u591f\u6a21\u62df\u4e13\u5bb6\u5de5\u4f5c\u6d41\u7a0b\uff0c\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u68c0\u67e5\u7684\u51b3\u7b56\u6b65\u9aa4\uff0c\u4e3a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u3002"}}
{"id": "2511.07090", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07090", "abs": "https://arxiv.org/abs/2511.07090", "authors": ["Marcel Rojahn", "Marcus Grum"], "title": "Green AI: A systematic review and meta-analysis of its definitions, lifecycle models, hardware and measurement attempts", "comment": null, "summary": "Across the Artificial Intelligence (AI) lifecycle - from hardware to development, deployment, and reuse - burdens span energy, carbon, water, and embodied impacts. Cloud provider tools improve transparency but remain heterogeneous and often omit water and value chain effects, limiting comparability and reproducibility. Addressing these multi dimensional burdens requires a lifecycle approach linking phase explicit mapping with system levers (hardware, placement, energy mix, cooling, scheduling) and calibrated measurement across facility, system, device, and workload levels. This article (i) establishes a unified, operational definition of Green AI distinct from Sustainable AI; (ii) formalizes a five phase lifecycle mapped to Life Cycle Assessment (LCA) stages, making energy, carbon, water, and embodied impacts first class; (iii) specifies governance via Plan Do Check Act (PDCA) cycles with decision gateways; (iv) systematizes hardware and system level strategies across the edge cloud continuum to reduce embodied burdens; and (v) defines a calibrated measurement framework combining estimator models with direct metering to enable reproducible, provider agnostic comparisons. Combining definition, lifecycle processes, hardware strategies, and calibrated measurement, this article offers actionable, evidence based guidance for researchers, practitioners, and policymakers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7eff\u8272AI\u7684\u7edf\u4e00\u64cd\u4f5c\u5b9a\u4e49\uff0c\u5efa\u7acb\u4e86\u5305\u542b\u4e94\u4e2a\u9636\u6bb5\u7684\u751f\u547d\u5468\u671f\u6846\u67b6\uff0c\u5c06\u80fd\u6e90\u3001\u78b3\u3001\u6c34\u548c\u9690\u542b\u5f71\u54cd\u4f5c\u4e3a\u9996\u8981\u8003\u91cf\uff0c\u5e76\u5236\u5b9a\u4e86\u7ed3\u5408\u4f30\u8ba1\u6a21\u578b\u548c\u76f4\u63a5\u6d4b\u91cf\u7684\u6821\u51c6\u6d4b\u91cf\u6846\u67b6\u3002", "motivation": "AI\u751f\u547d\u5468\u671f\u4e2d\u7684\u8d1f\u62c5\u5305\u62ec\u80fd\u6e90\u3001\u78b3\u3001\u6c34\u6d88\u8017\u548c\u9690\u542b\u5f71\u54cd\uff0c\u73b0\u6709\u4e91\u63d0\u4f9b\u5546\u5de5\u5177\u5b58\u5728\u5f02\u8d28\u6027\u4e14\u5f80\u5f80\u5ffd\u7565\u6c34\u548c\u4ef7\u503c\u94fe\u6548\u5e94\uff0c\u9650\u5236\u4e86\u53ef\u6bd4\u6027\u548c\u53ef\u91cd\u73b0\u6027\u3002", "method": "\u5efa\u7acb\u7edf\u4e00\u7684\u7eff\u8272AI\u5b9a\u4e49\uff0c\u5c06\u751f\u547d\u5468\u671f\u5206\u4e3a\u4e94\u4e2a\u9636\u6bb5\u6620\u5c04\u5230LCA\u9636\u6bb5\uff0c\u901a\u8fc7PDCA\u5faa\u73af\u8fdb\u884c\u6cbb\u7406\uff0c\u7cfb\u7edf\u5316\u786c\u4ef6\u548c\u7cfb\u7edf\u7ea7\u7b56\u7565\uff0c\u5e76\u5b9a\u4e49\u7ed3\u5408\u4f30\u8ba1\u6a21\u578b\u548c\u76f4\u63a5\u6d4b\u91cf\u7684\u6821\u51c6\u6d4b\u91cf\u6846\u67b6\u3002", "result": "\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u3001\u57fa\u4e8e\u8bc1\u636e\u7684\u6307\u5bfc\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u3001\u4ece\u4e1a\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u80fd\u591f\u8fdb\u884c\u53ef\u91cd\u73b0\u3001\u63d0\u4f9b\u5546\u65e0\u5173\u7684\u6bd4\u8f83\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u5b9a\u4e49\u3001\u751f\u547d\u5468\u671f\u6d41\u7a0b\u3001\u786c\u4ef6\u7b56\u7565\u548c\u6821\u51c6\u6d4b\u91cf\uff0c\u672c\u6587\u4e3a\u51cf\u5c11AI\u591a\u7ef4\u8d1f\u62c5\u63d0\u4f9b\u4e86\u7efc\u5408\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.07095", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07095", "abs": "https://arxiv.org/abs/2511.07095", "authors": ["Meghyn Bienvenu", "Quentin Mani\u00e8re"], "title": "Data Complexity of Querying Description Logic Knowledge Bases under Cost-Based Semantics", "comment": "Long version of paper to appear in AAAI 2026", "summary": "In this paper, we study the data complexity of querying inconsistent weighted description logic (DL) knowledge bases under recently-introduced cost-based semantics. In a nutshell, the idea is to assign each interpretation a cost based upon the weights of the violated axioms and assertions, and certain and possible query answers are determined by considering all (resp. some) interpretations having optimal or bounded cost. Whereas the initial study of cost-based semantics focused on DLs between $\\mathcal{EL}_\\bot$ and $\\mathcal{ALCO}$, we consider DLs that may contain inverse roles and role inclusions, thus covering prominent DL-Lite dialects. Our data complexity analysis goes significantly beyond existing results by sharpening several lower bounds and pinpointing the precise complexity of optimal-cost certain answer semantics (no non-trivial upper bound was known). Moreover, while all existing results show the intractability of cost-based semantics, our most challenging and surprising result establishes that if we consider $\\text{DL-Lite}^\\mathcal{H}_\\mathsf{bool}$ ontologies and a fixed cost bound, certain answers for instance queries and possible answers for conjunctive queries can be computed using first-order rewriting and thus enjoy the lowest possible data complexity ($\\mathsf{TC}_0$).", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u52a0\u6743\u63cf\u8ff0\u903b\u8f91\u77e5\u8bc6\u5e93\u4e2d\u4f7f\u7528\u57fa\u4e8e\u6210\u672c\u7684\u8bed\u4e49\u8fdb\u884c\u67e5\u8be2\u7684\u6570\u636e\u590d\u6742\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u5305\u542b\u9006\u89d2\u8272\u548c\u89d2\u8272\u5305\u542b\u7684DL\uff0c\u8986\u76d6\u4e86DL-Lite\u65b9\u8a00\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6210\u672c\u8bed\u4e49\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728EL\u22a5\u5230ALCO\u4e4b\u95f4\u7684\u63cf\u8ff0\u903b\u8f91\uff0c\u4e14\u6240\u6709\u73b0\u6709\u7ed3\u679c\u90fd\u663e\u793a\u57fa\u4e8e\u6210\u672c\u8bed\u4e49\u662f\u4e0d\u53ef\u5904\u7406\u7684\u3002\u672c\u6587\u65e8\u5728\u6269\u5c55\u7814\u7a76\u8303\u56f4\uff0c\u8003\u8651\u5305\u542b\u9006\u89d2\u8272\u548c\u89d2\u8272\u5305\u542b\u7684DL\uff0c\u5e76\u63a2\u7d22\u5728\u56fa\u5b9a\u6210\u672c\u8fb9\u754c\u4e0b\u7684\u53ef\u5904\u7406\u6027\u3002", "method": "\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u89e3\u91ca\u5206\u914d\u57fa\u4e8e\u8fdd\u53cd\u516c\u7406\u548c\u65ad\u8a00\u6743\u91cd\u7684\u6210\u672c\uff0c\u786e\u5b9a\u67e5\u8be2\u7b54\u6848\u3002\u4f7f\u7528\u4e00\u9636\u91cd\u5199\u6280\u672f\u6765\u8ba1\u7b97\u5b9e\u4f8b\u67e5\u8be2\u7684\u786e\u5b9a\u7b54\u6848\u548c\u8fde\u63a5\u67e5\u8be2\u7684\u53ef\u80fd\u7b54\u6848\u3002", "result": "\u5bf9\u4e8eDL-Lite^H_bool\u672c\u4f53\u548c\u56fa\u5b9a\u6210\u672c\u8fb9\u754c\uff0c\u5b9e\u4f8b\u67e5\u8be2\u7684\u786e\u5b9a\u7b54\u6848\u548c\u8fde\u63a5\u67e5\u8be2\u7684\u53ef\u80fd\u7b54\u6848\u53ef\u4ee5\u901a\u8fc7\u4e00\u9636\u91cd\u5199\u8ba1\u7b97\uff0c\u8fbe\u5230\u6700\u4f4e\u53ef\u80fd\u7684\u6570\u636e\u590d\u6742\u6027(TC0)\u3002", "conclusion": "\u672c\u6587\u663e\u8457\u6269\u5c55\u4e86\u57fa\u4e8e\u6210\u672c\u8bed\u4e49\u7684\u6570\u636e\u590d\u6742\u6027\u5206\u6790\uff0c\u4e0d\u4ec5\u5f3a\u5316\u4e86\u591a\u4e2a\u4e0b\u754c\uff0c\u8fd8\u786e\u5b9a\u4e86\u6700\u4f18\u6210\u672c\u786e\u5b9a\u7b54\u6848\u8bed\u4e49\u7684\u7cbe\u786e\u590d\u6742\u6027\uff0c\u5e76\u610f\u5916\u53d1\u73b0\u5728\u56fa\u5b9a\u6210\u672c\u8fb9\u754c\u4e0b\u67d0\u4e9b\u67e5\u8be2\u53ef\u4ee5\u8fbe\u5230TC0\u590d\u6742\u5ea6\u3002"}}
{"id": "2511.07097", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.07097", "abs": "https://arxiv.org/abs/2511.07097", "authors": ["Diego Gosmar", "Anna Chiara Pallotta", "Giovanni Zenezini"], "title": "Agentic AI Sustainability Assessment for Supply Chain Document Insights", "comment": "17 pages, 4 figures", "summary": "This paper presents a comprehensive sustainability assessment framework for document intelligence within supply chain operations, centered on agentic artificial intelligence (AI). We address the dual objective of improving automation efficiency while providing measurable environmental performance in document-intensive workflows. The research compares three scenarios: fully manual (human-only), AI-assisted (human-in-the-loop, HITL), and an advanced multi-agent agentic AI workflow leveraging parsers and verifiers. Empirical results show that AI-assisted HITL and agentic AI scenarios achieve reductions of up to 70-90% in energy consumption, 90-97% in carbon dioxide emissions, and 89-98% in water usage compared to manual processes. Notably, full agentic configurations, combining advanced reasoning (thinking mode) and multi-agent validation, achieve substantial sustainability gains over human-only approaches, even when resource usage increases slightly versus simpler AI-assisted solutions. The framework integrates performance, energy, and emission indicators into a unified ESG-oriented methodology for assessing and governing AI-enabled supply chain solutions. The paper includes a complete replicability use case demonstrating the methodology's application to real-world document extraction tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u667a\u80fdAI\u7684\u6587\u6863\u667a\u80fd\u53ef\u6301\u7eed\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u4f9b\u5e94\u94fe\u6587\u6863\u5904\u7406\u4e2d\u5b9e\u73b0\u81ea\u52a8\u5316\u6548\u7387\u63d0\u5347\u548c\u73af\u5883\u7ee9\u6548\u8861\u91cf\u3002", "motivation": "\u89e3\u51b3\u6587\u6863\u5bc6\u96c6\u578b\u5de5\u4f5c\u6d41\u4e2d\u81ea\u52a8\u5316\u6548\u7387\u4e0e\u73af\u5883\u7ee9\u6548\u7684\u53cc\u91cd\u76ee\u6807\uff0c\u4e3aAI\u8d4b\u80fd\u7684\u4f9b\u5e94\u94fe\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u7edf\u4e00\u7684ESG\u5bfc\u5411\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u6bd4\u8f83\u4e09\u79cd\u573a\u666f\uff1a\u5168\u4eba\u5de5\u3001AI\u8f85\u52a9\uff08\u4eba\u5728\u56de\u8def\uff09\u548c\u9ad8\u7ea7\u591a\u667a\u80fd\u4f53AI\u5de5\u4f5c\u6d41\uff0c\u7ed3\u5408\u89e3\u6790\u5668\u548c\u9a8c\u8bc1\u5668\uff0c\u96c6\u6210\u6027\u80fd\u3001\u80fd\u8017\u548c\u6392\u653e\u6307\u6807\u3002", "result": "AI\u8f85\u52a9\u548c\u667a\u80fdAI\u573a\u666f\u76f8\u6bd4\u4eba\u5de5\u6d41\u7a0b\u5b9e\u73b0\uff1a\u80fd\u8017\u964d\u4f4e70-90%\uff0c\u4e8c\u6c27\u5316\u78b3\u6392\u653e\u51cf\u5c1190-97%\uff0c\u7528\u6c34\u91cf\u51cf\u5c1189-98%\u3002\u5b8c\u6574\u667a\u80fd\u914d\u7f6e\u5728\u53ef\u6301\u7eed\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u7eaf\u4eba\u5de5\u65b9\u6cd5\u3002", "conclusion": "\u667a\u80fdAI\u914d\u7f6e\u5728\u4f9b\u5e94\u94fe\u6587\u6863\u5904\u7406\u4e2d\u80fd\u5b9e\u73b0\u663e\u8457\u7684\u53ef\u6301\u7eed\u6027\u6536\u76ca\uff0c\u8be5\u6846\u67b6\u4e3a\u8bc4\u4f30\u548c\u7ba1\u7406AI\u8d4b\u80fd\u7684\u4f9b\u5e94\u94fe\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u53ef\u590d\u5236\u7684ESG\u5bfc\u5411\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2511.07098", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07098", "abs": "https://arxiv.org/abs/2511.07098", "authors": ["Yuanshao Zhu", "Xiangyu Zhao", "Zijian Zhang", "Xuetao Wei", "James Jianqiao Yu"], "title": "Boosting Fine-Grained Urban Flow Inference via Lightweight Architecture and Focalized Optimization", "comment": "Accepted as a regular paper by AAAI'26", "summary": "Fine-grained urban flow inference is crucial for urban planning and intelligent transportation systems, enabling precise traffic management and resource allocation. However, the practical deployment of existing methods is hindered by two key challenges: the prohibitive computational cost of over-parameterized models and the suboptimal performance of conventional loss functions on the highly skewed distribution of urban flows. To address these challenges, we propose a unified solution that synergizes architectural efficiency with adaptive optimization. Specifically, we first introduce PLGF, a lightweight yet powerful architecture that employs a Progressive Local-Global Fusion strategy to effectively capture both fine-grained details and global contextual dependencies. Second, we propose DualFocal Loss, a novel function that integrates dual-space supervision with a difficulty-aware focusing mechanism, enabling the model to adaptively concentrate on hard-to-predict regions. Extensive experiments on 4 real-world scenarios validate the effectiveness and scalability of our method. Notably, while achieving state-of-the-art performance, PLGF reduces the model size by up to 97% compared to current high-performing methods. Furthermore, under comparable parameter budgets, our model yields an accuracy improvement of over 10% against strong baselines. The implementation is included in the https://github.com/Yasoz/PLGF.", "AI": {"tldr": "\u63d0\u51fa\u4e86PLGF\u6a21\u578b\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u5c40\u90e8-\u5168\u5c40\u878d\u5408\u67b6\u6784\u548c\u53cc\u7126\u70b9\u635f\u5931\u51fd\u6570\uff0c\u5728\u4fdd\u6301\u8f7b\u91cf\u5316\u7684\u540c\u65f6\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u57ce\u5e02\u6d41\u91cf\u63a8\u65ad\u7684\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57ce\u5e02\u6d41\u91cf\u63a8\u65ad\u65b9\u6cd5\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\u8fc7\u5ea6\u53c2\u6570\u5316\u6a21\u578b\u7684\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u4ee5\u53ca\u4f20\u7edf\u635f\u5931\u51fd\u6570\u5728\u9ad8\u5ea6\u504f\u6001\u5206\u5e03\u7684\u6d41\u91cf\u6570\u636e\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "1. PLGF\u67b6\u6784\uff1a\u91c7\u7528\u6e10\u8fdb\u5f0f\u5c40\u90e8-\u5168\u5c40\u878d\u5408\u7b56\u7565\uff0c\u6709\u6548\u6355\u6349\u7ec6\u7c92\u5ea6\u7ec6\u8282\u548c\u5168\u5c40\u4e0a\u4e0b\u6587\u4f9d\u8d56\uff1b2. DualFocal Loss\uff1a\u7ed3\u5408\u53cc\u7a7a\u95f4\u76d1\u7763\u548c\u96be\u5ea6\u611f\u77e5\u805a\u7126\u673a\u5236\uff0c\u81ea\u9002\u5e94\u5173\u6ce8\u96be\u4ee5\u9884\u6d4b\u7684\u533a\u57df\u3002", "result": "\u57284\u4e2a\u771f\u5b9e\u573a\u666f\u7684\u5b9e\u9a8c\u4e2d\uff0cPLGF\u5728\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u7684\u540c\u65f6\uff0c\u6a21\u578b\u5927\u5c0f\u6bd4\u73b0\u6709\u9ad8\u6027\u80fd\u65b9\u6cd5\u51cf\u5c11\u9ad8\u8fbe97%\uff1b\u5728\u540c\u7b49\u53c2\u6570\u9884\u7b97\u4e0b\uff0c\u51c6\u786e\u7387\u6bd4\u5f3a\u57fa\u7ebf\u63d0\u9ad8\u8d85\u8fc710%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u67b6\u6784\u6548\u7387\u548c\u81ea\u9002\u5e94\u4f18\u5316\u7684\u534f\u540c\u4f5c\u7528\uff0c\u4e3a\u7ec6\u7c92\u5ea6\u57ce\u5e02\u6d41\u91cf\u63a8\u65ad\u63d0\u4f9b\u4e86\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u663e\u8457\u7684\u8ba1\u7b97\u6548\u7387\u548c\u6027\u80fd\u4f18\u52bf\u3002"}}
{"id": "2511.07104", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07104", "abs": "https://arxiv.org/abs/2511.07104", "authors": ["Junji Hou", "Junzhou Zhao", "Shuo Zhang", "Pinghui Wang"], "title": "A Theoretical Analysis of Detecting Large Model-Generated Time Series", "comment": "23 pages,12 figures, to be published in AAAI-2026 main track", "summary": "Motivated by the increasing risks of data misuse and fabrication, we investigate the problem of identifying synthetic time series generated by Time-Series Large Models (TSLMs) in this work. While there are extensive researches on detecting model generated text, we find that these existing methods are not applicable to time series data due to the fundamental modality difference, as time series usually have lower information density and smoother probability distributions than text data, which limit the discriminative power of token-based detectors. To address this issue, we examine the subtle distributional differences between real and model-generated time series and propose the contraction hypothesis, which states that model-generated time series, unlike real ones, exhibit progressively decreasing uncertainty under recursive forecasting. We formally prove this hypothesis under theoretical assumptions on model behavior and time series structure. Model-generated time series exhibit progressively concentrated distributions under recursive forecasting, leading to uncertainty contraction. We provide empirical validation of the hypothesis across diverse datasets. Building on this insight, we introduce the Uncertainty Contraction Estimator (UCE), a white-box detector that aggregates uncertainty metrics over successive prefixes to identify TSLM-generated time series. Extensive experiments on 32 datasets show that UCE consistently outperforms state-of-the-art baselines, offering a reliable and generalizable solution for detecting model-generated time series.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u68c0\u6d4b\u65f6\u95f4\u5e8f\u5217\u5927\u6a21\u578b\u751f\u6210\u6570\u636e\u7684\u65b9\u6cd5UCE\uff0c\u57fa\u4e8e\u6a21\u578b\u751f\u6210\u65f6\u95f4\u5e8f\u5217\u5728\u9012\u5f52\u9884\u6d4b\u4e2d\u4e0d\u786e\u5b9a\u6027\u6536\u7f29\u7684\u7279\u6027\uff0c\u572832\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u6570\u636e\u6ee5\u7528\u548c\u4f2a\u9020\u98ce\u9669\u589e\u52a0\uff0c\u9700\u8981\u68c0\u6d4b\u65f6\u95f4\u5e8f\u5217\u5927\u6a21\u578b\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u3002\u73b0\u6709\u6587\u672c\u751f\u6210\u68c0\u6d4b\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u56e0\u4e3a\u65f6\u95f4\u5e8f\u5217\u4fe1\u606f\u5bc6\u5ea6\u8f83\u4f4e\u3001\u6982\u7387\u5206\u5e03\u66f4\u5e73\u6ed1\u3002", "method": "\u63d0\u51fa\u6536\u7f29\u5047\u8bf4\uff1a\u6a21\u578b\u751f\u6210\u7684\u65f6\u95f4\u5e8f\u5217\u5728\u9012\u5f52\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u4e0d\u786e\u5b9a\u6027\u9012\u51cf\u3002\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86UCE\u68c0\u6d4b\u5668\uff0c\u901a\u8fc7\u805a\u5408\u8fde\u7eed\u524d\u7f00\u7684\u4e0d\u786e\u5b9a\u6027\u6307\u6807\u6765\u8bc6\u522b\u6a21\u578b\u751f\u6210\u7684\u65f6\u95f4\u5e8f\u5217\u3002", "result": "\u572832\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cUCE\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u53ef\u9760\u4e14\u53ef\u63a8\u5e7f\u7684\u6a21\u578b\u751f\u6210\u65f6\u95f4\u5e8f\u5217\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u6a21\u578b\u751f\u6210\u7684\u65f6\u95f4\u5e8f\u5217\u5728\u9012\u5f52\u9884\u6d4b\u4e2d\u786e\u5b9e\u8868\u73b0\u51fa\u4e0d\u786e\u5b9a\u6027\u6536\u7f29\u7279\u6027\uff0cUCE\u68c0\u6d4b\u5668\u57fa\u4e8e\u8fd9\u4e00\u7279\u6027\u80fd\u591f\u6709\u6548\u8bc6\u522b\u5408\u6210\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u771f\u5b9e\u6027\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2511.07107", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.07107", "abs": "https://arxiv.org/abs/2511.07107", "authors": ["Liang Shan", "Kaicheng Shen", "Wen Wu", "Zhenyu Ying", "Chaochao Lu", "Guangze Ye", "Liang He"], "title": "MENTOR: A Metacognition-Driven Self-Evolution Framework for Uncovering and Mitigating Implicit Risks in LLMs on Domain Tasks", "comment": null, "summary": "Ensuring the safety and value alignment of large language models (LLMs) is critical for their deployment. Current alignment efforts primarily target explicit risks such as bias, hate speech, and violence. However, they often fail to address deeper, domain-specific implicit risks and lack a flexible, generalizable framework applicable across diverse specialized fields. Hence, we proposed MENTOR: A MEtacognition-driveN self-evoluTion framework for uncOvering and mitigating implicit Risks in LLMs on Domain Tasks. To address the limitations of labor-intensive human evaluation, we introduce a novel metacognitive self-assessment tool. This enables LLMs to reflect on potential value misalignments in their responses using strategies like perspective-taking and consequential thinking. We also release a supporting dataset of 9,000 risk queries spanning education, finance, and management to enhance domain-specific risk identification. Subsequently, based on the outcomes of metacognitive reflection, the framework dynamically generates supplementary rule knowledge graphs that extend predefined static rule trees. This enables models to actively apply validated rules to future similar challenges, establishing a continuous self-evolution cycle that enhances generalization by reducing maintenance costs and inflexibility of static systems. Finally, we employ activation steering during inference to guide LLMs in following the rules, a cost-effective method to robustly enhance enforcement across diverse contexts. Experimental results show MENTOR's effectiveness: In defensive testing across three vertical domains, the framework substantially reduces semantic attack success rates, enabling a new level of implicit risk mitigation for LLMs. Furthermore, metacognitive assessment not only aligns closely with baseline human evaluators but also delivers more thorough and insightful analysis of LLMs value alignment.", "AI": {"tldr": "\u63d0\u51fa\u4e86MENTOR\u6846\u67b6\uff0c\u901a\u8fc7\u5143\u8ba4\u77e5\u9a71\u52a8\u7684\u81ea\u6211\u8fdb\u5316\u673a\u5236\u6765\u53d1\u73b0\u548c\u7f13\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9886\u57df\u4efb\u52a1\u4e2d\u7684\u9690\u6027\u98ce\u9669\uff0c\u5305\u62ec\u5143\u8ba4\u77e5\u81ea\u6211\u8bc4\u4f30\u3001\u52a8\u6001\u89c4\u5219\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u548c\u6fc0\u6d3b\u5f15\u5bfc\u63a8\u7406\u7b49\u6280\u672f\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u4e3b\u8981\u9488\u5bf9\u663e\u6027\u98ce\u9669\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u9886\u57df\u7279\u5b9a\u9690\u6027\u98ce\u9669\u7684\u5173\u6ce8\uff0c\u4e14\u7f3a\u5c11\u7075\u6d3b\u3001\u53ef\u6cdb\u5316\u7684\u8de8\u9886\u57df\u98ce\u9669\u7f13\u89e3\u6846\u67b6\u3002", "method": "1) \u5f15\u5165\u5143\u8ba4\u77e5\u81ea\u6211\u8bc4\u4f30\u5de5\u5177\uff0c\u8ba9LLM\u901a\u8fc7\u6362\u4f4d\u601d\u8003\u548c\u7ed3\u679c\u63a8\u7406\u53cd\u601d\u4ef7\u503c\u5bf9\u9f50\u95ee\u9898\uff1b2) \u57fa\u4e8e\u53cd\u601d\u7ed3\u679c\u52a8\u6001\u751f\u6210\u8865\u5145\u89c4\u5219\u77e5\u8bc6\u56fe\u8c31\uff1b3) \u5728\u63a8\u7406\u65f6\u4f7f\u7528\u6fc0\u6d3b\u5f15\u5bfc\u6765\u589e\u5f3a\u89c4\u5219\u9075\u5faa\u3002", "result": "\u5728\u4e09\u4e2a\u5782\u76f4\u9886\u57df\u7684\u9632\u5fa1\u6d4b\u8bd5\u4e2d\uff0cMENTOR\u663e\u8457\u964d\u4f4e\u4e86\u8bed\u4e49\u653b\u51fb\u6210\u529f\u7387\uff0c\u5b9e\u73b0\u4e86\u65b0\u7684\u9690\u6027\u98ce\u9669\u7f13\u89e3\u6c34\u5e73\u3002\u5143\u8ba4\u77e5\u8bc4\u4f30\u4e0e\u4eba\u5de5\u8bc4\u4f30\u9ad8\u5ea6\u4e00\u81f4\u4e14\u63d0\u4f9b\u66f4\u6df1\u5165\u7684\u5206\u6790\u3002", "conclusion": "MENTOR\u6846\u67b6\u901a\u8fc7\u5143\u8ba4\u77e5\u9a71\u52a8\u7684\u81ea\u6211\u8fdb\u5316\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u9886\u57df\u4efb\u52a1\u4e2d\u7684\u9690\u6027\u98ce\u9669\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6301\u7eed\u8fdb\u5316\u7684\u98ce\u9669\u7f13\u89e3\u65b9\u6848\u3002"}}
{"id": "2511.07110", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07110", "abs": "https://arxiv.org/abs/2511.07110", "authors": ["Tianhao Fu", "Xinxin Xu", "Weichen Xu", "Jue Chen", "Ruilong Ren", "Bowen Deng", "Xinyu Zhao", "Jian Cao", "Xixin Cao"], "title": "Two Heads are Better than One: Distilling Large Language Model Features Into Small Models with Feature Decomposition and Mixture", "comment": null, "summary": "Market making (MM) through Reinforcement Learning (RL) has attracted significant attention in financial trading. With the development of Large Language Models (LLMs), more and more attempts are being made to apply LLMs to financial areas. A simple, direct application of LLM as an agent shows significant performance. Such methods are hindered by their slow inference speed, while most of the current research has not studied LLM distillation for this specific task. To address this, we first propose the normalized fluorescent probe to study the mechanism of the LLM's feature. Based on the observation found by our investigation, we propose Cooperative Market Making (CMM), a novel framework that decouples LLM features across three orthogonal dimensions: layer, task, and data. Various student models collaboratively learn simple LLM features along with different dimensions, with each model responsible for a distinct feature to achieve knowledge distillation. Furthermore, CMM introduces an H\u00e1jek-MoE to integrate the output of the student models by investigating the contribution of different models in a kernel function-generated common feature space. Extensive experimental results on four real-world market datasets demonstrate the superiority of CMM over the current distillation method and RL-based market-making strategies.", "AI": {"tldr": "\u63d0\u51fa\u4e86CMM\u6846\u67b6\uff0c\u901a\u8fc7\u5c06LLM\u7279\u5f81\u5728\u5c42\u3001\u4efb\u52a1\u548c\u6570\u636e\u4e09\u4e2a\u6b63\u4ea4\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u89e3\u8026\uff0c\u5b9e\u73b0\u591a\u5b66\u751f\u6a21\u578b\u534f\u4f5c\u5b66\u4e60\uff0c\u5e76\u5f15\u5165H\u00e1jek-MoE\u96c6\u6210\u6a21\u578b\u8f93\u51fa\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5e02\u573a\u505a\u5e02\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u91d1\u878d\u4ea4\u6613\u65b9\u6cd5\u53d7\u9650\u4e8e\u63a8\u7406\u901f\u5ea6\u6162\u7684\u95ee\u9898\uff0c\u4e14\u7f3a\u4e4f\u9488\u5bf9\u5e02\u573a\u505a\u5e02\u4efb\u52a1\u7684LLM\u84b8\u998f\u7814\u7a76\uff0c\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u7684\u84b8\u998f\u6846\u67b6\u3002", "method": "\u9996\u5148\u63d0\u51fa\u5f52\u4e00\u5316\u8367\u5149\u63a2\u9488\u7814\u7a76LLM\u7279\u5f81\u673a\u5236\uff0c\u7136\u540e\u8bbe\u8ba1CMM\u6846\u67b6\u5728\u5c42\u3001\u4efb\u52a1\u548c\u6570\u636e\u4e09\u4e2a\u7ef4\u5ea6\u89e3\u8026LLM\u7279\u5f81\uff0c\u8ba9\u591a\u4e2a\u5b66\u751f\u6a21\u578b\u534f\u4f5c\u5b66\u4e60\u4e0d\u540c\u7279\u5f81\uff0c\u6700\u540e\u4f7f\u7528H\u00e1jek-MoE\u5728\u6838\u51fd\u6570\u751f\u6210\u7684\u516c\u5171\u7279\u5f81\u7a7a\u95f4\u4e2d\u96c6\u6210\u6a21\u578b\u8f93\u51fa\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u5e02\u573a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCMM\u4f18\u4e8e\u5f53\u524d\u84b8\u998f\u65b9\u6cd5\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5e02\u573a\u505a\u5e02\u7b56\u7565\u3002", "conclusion": "CMM\u6846\u67b6\u901a\u8fc7\u591a\u7ef4\u5ea6\u7279\u5f81\u89e3\u8026\u548c\u534f\u4f5c\u5b66\u4e60\uff0c\u6210\u529f\u5b9e\u73b0\u4e86LLM\u77e5\u8bc6\u7684\u6709\u6548\u84b8\u998f\uff0c\u4e3a\u91d1\u878d\u9886\u57df\u7684LLM\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.07126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07126", "abs": "https://arxiv.org/abs/2511.07126", "authors": ["Tim Bohne", "Anne-Kathrin Patricia Windler", "Martin Atzmueller"], "title": "Saliency Map-Guided Knowledge Discovery for Subclass Identification with LLM-Based Symbolic Approximations", "comment": null, "summary": "This paper proposes a novel neuro-symbolic approach for sensor signal-based knowledge discovery, focusing on identifying latent subclasses in time series classification tasks. The approach leverages gradient-based saliency maps derived from trained neural networks to guide the discovery process. Multiclass time series classification problems are transformed into binary classification problems through label subsumption, and classifiers are trained for each of these to yield saliency maps. The input signals, grouped by predicted class, are clustered under three distinct configurations. The centroids of the final set of clusters are provided as input to an LLM for symbolic approximation and fuzzy knowledge graph matching to discover the underlying subclasses of the original multiclass problem. Experimental results on well-established time series classification datasets demonstrate the effectiveness of our saliency map-driven method for knowledge discovery, outperforming signal-only baselines in both clustering and subclass identification.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u663e\u8457\u6027\u56fe\u7684\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4e2d\u7684\u6f5c\u5728\u5b50\u7c7b\u53d1\u73b0\uff0c\u901a\u8fc7\u6807\u7b7e\u5305\u542b\u5c06\u591a\u7c7b\u95ee\u9898\u8f6c\u4e3a\u4e8c\u5206\u7c7b\uff0c\u7ed3\u5408\u805a\u7c7b\u548cLLM\u8fdb\u884c\u7b26\u53f7\u8fd1\u4f3c\u548c\u77e5\u8bc6\u56fe\u8c31\u5339\u914d\u3002", "motivation": "\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4e2d\u8bc6\u522b\u6f5c\u5728\u5b50\u7c7b\u7684\u95ee\u9898\uff0c\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u663e\u8457\u6027\u56fe\u6307\u5bfc\u77e5\u8bc6\u53d1\u73b0\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u5b50\u7c7b\u8bc6\u522b\u6548\u679c\u3002", "method": "\u5c06\u591a\u7c7b\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u8f6c\u4e3a\u4e8c\u5206\u7c7b\uff0c\u8bad\u7ec3\u5206\u7c7b\u5668\u83b7\u53d6\u663e\u8457\u6027\u56fe\uff0c\u5bf9\u9884\u6d4b\u7c7b\u522b\u7684\u4fe1\u53f7\u8fdb\u884c\u805a\u7c7b\uff0c\u4f7f\u7528\u805a\u7c7b\u4e2d\u5fc3\u901a\u8fc7LLM\u8fdb\u884c\u7b26\u53f7\u8fd1\u4f3c\u548c\u6a21\u7cca\u77e5\u8bc6\u56fe\u8c31\u5339\u914d\u3002", "result": "\u5728\u6807\u51c6\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u805a\u7c7b\u548c\u5b50\u7c7b\u8bc6\u522b\u65b9\u9762\u4f18\u4e8e\u4ec5\u4f7f\u7528\u4fe1\u53f7\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u663e\u8457\u6027\u56fe\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u53d1\u73b0\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4e2d\u7684\u6f5c\u5728\u5b50\u7c7b\uff0c\u4e3a\u77e5\u8bc6\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.07204", "categories": ["cs.AI", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.07204", "abs": "https://arxiv.org/abs/2511.07204", "authors": ["Giacomo Fidone", "Lucia Passaro", "Riccardo Guidotti"], "title": "Evaluating Online Moderation Via LLM-Powered Counterfactual Simulations", "comment": "Accepted for publication at AAAI Conference on Artificial Intelligence 2026", "summary": "Online Social Networks (OSNs) widely adopt content moderation to mitigate the spread of abusive and toxic discourse. Nonetheless, the real effectiveness of moderation interventions remains unclear due to the high cost of data collection and limited experimental control. The latest developments in Natural Language Processing pave the way for a new evaluation approach. Large Language Models (LLMs) can be successfully leveraged to enhance Agent-Based Modeling and simulate human-like social behavior with unprecedented degree of believability. Yet, existing tools do not support simulation-based evaluation of moderation strategies. We fill this gap by designing a LLM-powered simulator of OSN conversations enabling a parallel, counterfactual simulation where toxic behavior is influenced by moderation interventions, keeping all else equal. We conduct extensive experiments, unveiling the psychological realism of OSN agents, the emergence of social contagion phenomena and the superior effectiveness of personalized moderation strategies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5728\u7ebf\u793e\u4ea4\u7f51\u7edc\u5bf9\u8bdd\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u8bc4\u4f30\u5185\u5bb9\u5ba1\u6838\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u4e2a\u6027\u5316\u5ba1\u6838\u7b56\u7565\u5177\u6709\u4f18\u8d8a\u6548\u679c\u3002", "motivation": "\u7531\u4e8e\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u548c\u5b9e\u9a8c\u63a7\u5236\u6709\u9650\uff0c\u5f53\u524d\u5728\u7ebf\u793e\u4ea4\u7f51\u7edc\u5185\u5bb9\u5ba1\u6838\u5e72\u9884\u7684\u5b9e\u9645\u6548\u679c\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5728\u7ebf\u793e\u4ea4\u7f51\u7edc\u5bf9\u8bdd\u6a21\u62df\u5668\uff0c\u652f\u6301\u5e76\u884c\u3001\u53cd\u4e8b\u5b9e\u6a21\u62df\uff0c\u5728\u4fdd\u6301\u5176\u4ed6\u56e0\u7d20\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\u7814\u7a76\u6bd2\u6027\u884c\u4e3a\u5982\u4f55\u53d7\u5ba1\u6838\u5e72\u9884\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86OSN\u4ee3\u7406\u7684\u5fc3\u7406\u771f\u5b9e\u6027\uff0c\u63ed\u793a\u4e86\u793e\u4f1a\u4f20\u67d3\u73b0\u8c61\u7684\u51fa\u73b0\uff0c\u5e76\u8bc1\u660e\u4e2a\u6027\u5316\u5ba1\u6838\u7b56\u7565\u5177\u6709\u66f4\u9ad8\u7684\u6709\u6548\u6027\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u6a21\u62df\u5668\u4e3a\u8bc4\u4f30\u5185\u5bb9\u5ba1\u6838\u7b56\u7565\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u4e2a\u6027\u5316\u5e72\u9884\u5728\u63a7\u5236\u6bd2\u6027\u5185\u5bb9\u4f20\u64ad\u65b9\u9762\u6548\u679c\u663e\u8457\u3002"}}
{"id": "2511.07260", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07260", "abs": "https://arxiv.org/abs/2511.07260", "authors": ["Hohei Chan", "Xinzhi Zhang", "Antao Xiang", "Weinan Zhang", "Mengchen Zhao"], "title": "PADiff: Predictive and Adaptive Diffusion Policies for Ad Hoc Teamwork", "comment": "Accepted by the 40th AAAI conference on Artificial Intelligence (AAAI 2026)", "summary": "Ad hoc teamwork (AHT) requires agents to collaborate with previously unseen teammates, which is crucial for many real-world applications. The core challenge of AHT is to develop an ego agent that can predict and adapt to unknown teammates on the fly. Conventional RL-based approaches optimize a single expected return, which often causes policies to collapse into a single dominant behavior, thus failing to capture the multimodal cooperation patterns inherent in AHT. In this work, we introduce PADiff, a diffusion-based approach that captures agent's multimodal behaviors, unlocking its diverse cooperation modes with teammates. However, standard diffusion models lack the ability to predict and adapt in highly non-stationary AHT scenarios. To address this limitation, we propose a novel diffusion-based policy that integrates critical predictive information about teammates into the denoising process. Extensive experiments across three cooperation environments demonstrate that PADiff outperforms existing AHT methods significantly.", "AI": {"tldr": "PADiff\u662f\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3ad hoc teamwork\u4e2d\u7684\u591a\u6a21\u6001\u5408\u4f5c\u6a21\u5f0f\u95ee\u9898\uff0c\u901a\u8fc7\u5728\u53bb\u566a\u8fc7\u7a0b\u4e2d\u6574\u5408\u961f\u53cb\u9884\u6d4b\u4fe1\u606f\u6765\u9002\u5e94\u975e\u5e73\u7a33\u73af\u5883\u3002", "motivation": "\u4f20\u7edfRL\u65b9\u6cd5\u5728ad hoc teamwork\u4e2d\u5bb9\u6613\u6536\u655b\u5230\u5355\u4e00\u884c\u4e3a\u6a21\u5f0f\uff0c\u65e0\u6cd5\u6355\u6349\u591a\u6a21\u6001\u5408\u4f5c\u6a21\u5f0f\uff0c\u800c\u6807\u51c6\u6269\u6563\u6a21\u578b\u5728\u9ad8\u5ea6\u975e\u5e73\u7a33\u7684AHT\u573a\u666f\u4e2d\u7f3a\u4e4f\u9884\u6d4b\u548c\u9002\u5e94\u80fd\u529b\u3002", "method": "\u63d0\u51faPADiff\u6269\u6563\u7b56\u7565\uff0c\u5c06\u961f\u53cb\u7684\u5173\u952e\u9884\u6d4b\u4fe1\u606f\u6574\u5408\u5230\u53bb\u566a\u8fc7\u7a0b\u4e2d\uff0c\u4ee5\u6355\u6349\u667a\u80fd\u4f53\u7684\u591a\u6a21\u6001\u884c\u4e3a\u5e76\u89e3\u9501\u591a\u6837\u5316\u7684\u5408\u4f5c\u6a21\u5f0f\u3002", "result": "\u5728\u4e09\u4e2a\u5408\u4f5c\u73af\u5883\u4e2d\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cPADiff\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684AHT\u65b9\u6cd5\u3002", "conclusion": "PADiff\u901a\u8fc7\u6574\u5408\u9884\u6d4b\u4fe1\u606f\u7684\u6269\u6563\u6a21\u578b\uff0c\u6210\u529f\u89e3\u51b3\u4e86AHT\u4e2d\u7684\u591a\u6a21\u6001\u5408\u4f5c\u6311\u6218\uff0c\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2511.07262", "categories": ["cs.AI", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07262", "abs": "https://arxiv.org/abs/2511.07262", "authors": ["Qile Jiang", "George Karniadakis"], "title": "AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery in Scientific Machine Learning", "comment": null, "summary": "Scientific Machine Learning (SciML) integrates data-driven inference with physical modeling to solve complex problems in science and engineering. However, the design of SciML architectures, loss formulations, and training strategies remains an expert-driven research process, requiring extensive experimentation and problem-specific insights. Here we introduce AgenticSciML, a collaborative multi-agent system in which over 10 specialized AI agents collaborate to propose, critique, and refine SciML solutions through structured reasoning and iterative evolution. The framework integrates structured debate, retrieval-augmented method memory, and ensemble-guided evolutionary search, enabling the agents to generate and assess new hypotheses about architectures and optimization procedures. Across physics-informed learning and operator learning tasks, the framework discovers solution methods that outperform single-agent and human-designed baselines by up to four orders of magnitude in error reduction. The agents produce novel strategies -- including adaptive mixture-of-expert architectures, decomposition-based PINNs, and physics-informed operator learning models -- that do not appear explicitly in the curated knowledge base. These results show that collaborative reasoning among AI agents can yield emergent methodological innovation, suggesting a path toward scalable, transparent, and autonomous discovery in scientific computing.", "AI": {"tldr": "AgenticSciML\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7cfb\u7edf\uff0c\u901a\u8fc710\u591a\u4e2a\u4e13\u4e1aAI\u667a\u80fd\u4f53\u7684\u7ed3\u6784\u5316\u8fa9\u8bba\u548c\u8fed\u4ee3\u8fdb\u5316\uff0c\u81ea\u52a8\u8bbe\u8ba1\u548c\u4f18\u5316\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u7269\u7406\u4fe1\u606f\u5b66\u4e60\u548c\u7b97\u5b50\u5b66\u4e60\u4efb\u52a1\u4e2d\u663e\u8457\u8d85\u8d8a\u5355\u667a\u80fd\u4f53\u548c\u4eba\u5de5\u8bbe\u8ba1\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u7684\u8bbe\u8ba1\u8fc7\u7a0b\u9700\u8981\u4e13\u5bb6\u9a71\u52a8\u7684\u7814\u7a76\uff0c\u6d89\u53ca\u5927\u91cf\u5b9e\u9a8c\u548c\u95ee\u9898\u7279\u5b9a\u6d1e\u5bdf\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u81ea\u52a8\u5316\u548c\u53ef\u6269\u5c55\u6027\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u81ea\u4e3b\u53d1\u73b0\u548c\u4f18\u5316SciML\u89e3\u51b3\u65b9\u6848\u7684\u6846\u67b6\u3002", "method": "\u91c7\u7528\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u6574\u5408\u7ed3\u6784\u5316\u8fa9\u8bba\u3001\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u8bb0\u5fc6\u548c\u96c6\u6210\u5f15\u5bfc\u7684\u8fdb\u5316\u641c\u7d22\u3002\u667a\u80fd\u4f53\u901a\u8fc7\u63d0\u51fa\u3001\u6279\u8bc4\u548c\u7cbe\u70bcSciML\u89e3\u51b3\u65b9\u6848\u6765\u8fdb\u884c\u7ed3\u6784\u5316\u63a8\u7406\u548c\u8fed\u4ee3\u8fdb\u5316\u3002", "result": "\u5728\u7269\u7406\u4fe1\u606f\u5b66\u4e60\u548c\u7b97\u5b50\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0c\u8be5\u6846\u67b6\u53d1\u73b0\u7684\u89e3\u51b3\u65b9\u6848\u6bd4\u5355\u667a\u80fd\u4f53\u548c\u4eba\u5de5\u8bbe\u8ba1\u7684\u57fa\u7ebf\u65b9\u6cd5\u5728\u8bef\u5dee\u51cf\u5c11\u65b9\u9762\u63d0\u5347\u4e86\u9ad8\u8fbe\u56db\u4e2a\u6570\u91cf\u7ea7\u3002\u667a\u80fd\u4f53\u4ea7\u751f\u4e86\u65b0\u9896\u7b56\u7565\uff0c\u5982\u81ea\u9002\u5e94\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\u3001\u57fa\u4e8e\u5206\u89e3\u7684PINNs\u548c\u7269\u7406\u4fe1\u606f\u7b97\u5b50\u5b66\u4e60\u6a21\u578b\u3002", "conclusion": "AI\u667a\u80fd\u4f53\u95f4\u7684\u534f\u4f5c\u63a8\u7406\u80fd\u591f\u4ea7\u751f\u6d8c\u73b0\u7684\u65b9\u6cd5\u521b\u65b0\uff0c\u4e3a\u79d1\u5b66\u8ba1\u7b97\u4e2d\u53ef\u6269\u5c55\u3001\u900f\u660e\u548c\u81ea\u4e3b\u7684\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e00\u6761\u8def\u5f84\u3002"}}
{"id": "2511.07267", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07267", "abs": "https://arxiv.org/abs/2511.07267", "authors": ["Chen Han", "Yijia Ma", "Jin Tan", "Wenzhen Zheng", "Xijin Tang"], "title": "Beyond Detection: Exploring Evidence-based Multi-Agent Debate for Misinformation Intervention and Persuasion", "comment": "This paper has been accepted to AAAI 2026", "summary": "Multi-agent debate (MAD) frameworks have emerged as promising approaches for misinformation detection by simulating adversarial reasoning. While prior work has focused on detection accuracy, it overlooks the importance of helping users understand the reasoning behind factual judgments and develop future resilience. The debate transcripts generated during MAD offer a rich but underutilized resource for transparent reasoning. In this study, we introduce ED2D, an evidence-based MAD framework that extends previous approach by incorporating factual evidence retrieval. More importantly, ED2D is designed not only as a detection framework but also as a persuasive multi-agent system aimed at correcting user beliefs and discouraging misinformation sharing. We compare the persuasive effects of ED2D-generated debunking transcripts with those authored by human experts. Results demonstrate that ED2D outperforms existing baselines across three misinformation detection benchmarks. When ED2D generates correct predictions, its debunking transcripts exhibit persuasive effects comparable to those of human experts; However, when ED2D misclassifies, its accompanying explanations may inadvertently reinforce users'misconceptions, even when presented alongside accurate human explanations. Our findings highlight both the promise and the potential risks of deploying MAD systems for misinformation intervention. We further develop a public community website to help users explore ED2D, fostering transparency, critical thinking, and collaborative fact-checking.", "AI": {"tldr": "ED2D\u662f\u4e00\u4e2a\u57fa\u4e8e\u8bc1\u636e\u7684\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u6846\u67b6\uff0c\u4e0d\u4ec5\u7528\u4e8e\u9519\u8bef\u4fe1\u606f\u68c0\u6d4b\uff0c\u8fd8\u65e8\u5728\u7ea0\u6b63\u7528\u6237\u4fe1\u5ff5\u548c\u963b\u6b62\u9519\u8bef\u4fe1\u606f\u4f20\u64ad\u3002\u8be5\u6846\u67b6\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\uff0c\u4f46\u5176\u89e3\u91ca\u5728\u9519\u8bef\u5206\u7c7b\u65f6\u53ef\u80fd\u5f3a\u5316\u7528\u6237\u8bef\u89e3\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u6846\u67b6\u4e3b\u8981\u5173\u6ce8\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u5ffd\u89c6\u4e86\u5e2e\u52a9\u7528\u6237\u7406\u89e3\u4e8b\u5b9e\u5224\u65ad\u80cc\u540e\u63a8\u7406\u548c\u57f9\u517b\u672a\u6765\u62b5\u5fa1\u80fd\u529b\u7684\u91cd\u8981\u6027\u3002\u8fa9\u8bba\u8bb0\u5f55\u4f5c\u4e3a\u900f\u660e\u63a8\u7406\u7684\u4e30\u5bcc\u8d44\u6e90\u672a\u88ab\u5145\u5206\u5229\u7528\u3002", "method": "\u5f15\u5165ED2D\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u5148\u524d\u65b9\u6cd5\uff0c\u6574\u5408\u4e86\u4e8b\u5b9e\u8bc1\u636e\u68c0\u7d22\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u4f5c\u4e3a\u68c0\u6d4b\u5de5\u5177\uff0c\u8fd8\u8bbe\u8ba1\u4e3a\u5177\u6709\u8bf4\u670d\u529b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u65e8\u5728\u7ea0\u6b63\u7528\u6237\u4fe1\u5ff5\u548c\u963b\u6b62\u9519\u8bef\u4fe1\u606f\u4f20\u64ad\u3002", "result": "ED2D\u5728\u4e09\u4e2a\u9519\u8bef\u4fe1\u606f\u68c0\u6d4b\u57fa\u51c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002\u5f53ED2D\u505a\u51fa\u6b63\u786e\u9884\u6d4b\u65f6\uff0c\u5176\u53cd\u9a73\u8bb0\u5f55\u7684\u8bf4\u670d\u6548\u679c\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u5f53\uff1b\u4f46\u5f53\u9519\u8bef\u5206\u7c7b\u65f6\uff0c\u5176\u89e3\u91ca\u53ef\u80fd\u65e0\u610f\u4e2d\u5f3a\u5316\u7528\u6237\u8bef\u89e3\uff0c\u5373\u4f7f\u4e0e\u51c6\u786e\u7684\u4eba\u7c7b\u89e3\u91ca\u4e00\u8d77\u5448\u73b0\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u51f8\u663e\u4e86\u90e8\u7f72\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u7cfb\u7edf\u8fdb\u884c\u9519\u8bef\u4fe1\u606f\u5e72\u9884\u7684\u6f5c\u529b\u548c\u6f5c\u5728\u98ce\u9669\u3002\u5f00\u53d1\u4e86\u516c\u5171\u793e\u533a\u7f51\u7ad9\u6765\u4fc3\u8fdb\u900f\u660e\u5ea6\u3001\u6279\u5224\u6027\u601d\u7ef4\u548c\u534f\u4f5c\u4e8b\u5b9e\u6838\u67e5\u3002"}}
{"id": "2511.07327", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.07327", "abs": "https://arxiv.org/abs/2511.07327", "authors": ["Guoxin Chen", "Zile Qiao", "Xuanzhong Chen", "Donglei Yu", "Haotian Xu", "Wayne Xin Zhao", "Ruihua Song", "Wenbiao Yin", "Huifeng Yin", "Liwen Zhang", "Kuan Li", "Minpeng Liao", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Jingren Zhou"], "title": "IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction", "comment": "https://github.com/Alibaba-NLP/DeepResearch", "summary": "Recent advances in deep-research agents have shown promise for autonomous knowledge construction through dynamic reasoning over external sources. However, existing approaches rely on a mono-contextual paradigm that accumulates all information in a single, expanding context window, leading to context suffocation and noise contamination that limit their effectiveness on long-horizon tasks. We introduce IterResearch, a novel iterative deep-research paradigm that reformulates long-horizon research as a Markov Decision Process with strategic workspace reconstruction. By maintaining an evolving report as memory and periodically synthesizing insights, our approach preserves consistent reasoning capacity across arbitrary exploration depths. We further develop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learning framework that incentivizes efficient exploration through geometric reward discounting and enables stable distributed training via adaptive downsampling. Extensive experiments demonstrate that IterResearch achieves substantial improvements over existing open-source agents with average +14.5pp across six benchmarks and narrows the gap with frontier proprietary systems. Remarkably, our paradigm exhibits unprecedented interaction scaling, extending to 2048 interactions with dramatic performance gains (from 3.5\\% to 42.5\\%), and serves as an effective prompting strategy, improving frontier models by up to 19.2pp over ReAct on long-horizon tasks. These findings position IterResearch as a versatile solution for long-horizon reasoning, effective both as a trained agent and as a prompting paradigm for frontier models.", "AI": {"tldr": "IterResearch\u63d0\u51fa\u4e86\u4e00\u79cd\u8fed\u4ee3\u5f0f\u6df1\u5ea6\u7814\u7a76\u8303\u5f0f\uff0c\u901a\u8fc7\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u548c\u7b56\u7565\u6027\u5de5\u4f5c\u7a7a\u95f4\u91cd\u6784\u89e3\u51b3\u957f\u89c6\u91ce\u7814\u7a76\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u7a92\u606f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7814\u7a76\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u91c7\u7528\u5355\u4e0a\u4e0b\u6587\u8303\u5f0f\uff0c\u5c06\u6240\u6709\u4fe1\u606f\u79ef\u7d2f\u5728\u5355\u4e00\u6269\u5c55\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e2d\uff0c\u5bfc\u81f4\u4e0a\u4e0b\u6587\u7a92\u606f\u548c\u566a\u58f0\u6c61\u67d3\uff0c\u9650\u5236\u4e86\u5728\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u5c06\u957f\u89c6\u91ce\u7814\u7a76\u91cd\u65b0\u6784\u5efa\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u7ef4\u62a4\u6f14\u5316\u62a5\u544a\u4f5c\u4e3a\u8bb0\u5fc6\u5e76\u5b9a\u671f\u5408\u6210\u89c1\u89e3\uff1b\u5f00\u53d1\u6548\u7387\u611f\u77e5\u7b56\u7565\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u51e0\u4f55\u5956\u52b1\u6298\u6263\u6fc0\u52b1\u9ad8\u6548\u63a2\u7d22\uff0c\u5e76\u901a\u8fc7\u81ea\u9002\u5e94\u4e0b\u91c7\u6837\u5b9e\u73b0\u7a33\u5b9a\u5206\u5e03\u5f0f\u8bad\u7ec3\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u63d0\u534714.5\u4e2a\u767e\u5206\u70b9\uff0c\u4e0e\u524d\u6cbf\u4e13\u6709\u7cfb\u7edf\u7684\u5dee\u8ddd\u7f29\u5c0f\uff1b\u5c55\u73b0\u51fa\u524d\u6240\u672a\u6709\u7684\u4ea4\u4e92\u6269\u5c55\u6027\uff0c\u6269\u5c55\u52302048\u6b21\u4ea4\u4e92\u65f6\u6027\u80fd\u4ece3.5%\u63d0\u5347\u81f342.5%\uff1b\u4f5c\u4e3a\u63d0\u793a\u7b56\u7565\u53ef\u5c06\u524d\u6cbf\u6a21\u578b\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe19.2\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "IterResearch\u662f\u957f\u89c6\u91ce\u63a8\u7406\u7684\u591a\u529f\u80fd\u89e3\u51b3\u65b9\u6848\uff0c\u65e2\u53ef\u4f5c\u4e3a\u8bad\u7ec3\u4ee3\u7406\uff0c\u4e5f\u53ef\u4f5c\u4e3a\u524d\u6cbf\u6a21\u578b\u7684\u63d0\u793a\u8303\u5f0f\u3002"}}
{"id": "2511.07338", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07338", "abs": "https://arxiv.org/abs/2511.07338", "authors": ["Zhen Wang", "Yufan Zhou", "Zhongyan Luo", "Lyumanshan Ye", "Adam Wood", "Man Yao", "Luoshang Pan"], "title": "DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas", "comment": "12 pages, 5 figures, accepted at LAW 2025 Workshop (NeurIPS 2025)", "summary": "Simulating human profiles by instilling personas into large language models (LLMs) is rapidly transforming research in agentic behavioral simulation, LLM personalization, and human-AI alignment. However, most existing synthetic personas remain shallow and simplistic, capturing minimal attributes and failing to reflect the rich complexity and diversity of real human identities. We introduce DEEPPERSONA, a scalable generative engine for synthesizing narrative-complete synthetic personas through a two-stage, taxonomy-guided method. First, we algorithmically construct the largest-ever human-attribute taxonomy, comprising over hundreds of hierarchically organized attributes, by mining thousands of real user-ChatGPT conversations. Second, we progressively sample attributes from this taxonomy, conditionally generating coherent and realistic personas that average hundreds of structured attributes and roughly 1 MB of narrative text, two orders of magnitude deeper than prior works. Intrinsic evaluations confirm significant improvements in attribute diversity (32 percent higher coverage) and profile uniqueness (44 percent greater) compared to state-of-the-art baselines. Extrinsically, our personas enhance GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on average across ten metrics and substantially narrow (by 31.7 percent) the gap between simulated LLM citizens and authentic human responses in social surveys. Our generated national citizens reduced the performance gap on the Big Five personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA thus provides a rigorous, scalable, and privacy-free platform for high-fidelity human simulation and personalized AI research.", "AI": {"tldr": "DEEPPERSONA\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u751f\u6210\u5f15\u64ce\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u3001\u5206\u7c7b\u5b66\u6307\u5bfc\u7684\u65b9\u6cd5\u5408\u6210\u5177\u6709\u5b8c\u6574\u53d9\u4e8b\u6027\u7684\u5408\u6210\u4eba\u7269\u89d2\u8272\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4eba\u7269\u5c5e\u6027\u7684\u591a\u6837\u6027\u548c\u72ec\u7279\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u591a\u6570\u5408\u6210\u4eba\u7269\u89d2\u8272\u8fc7\u4e8e\u6d45\u663e\u548c\u7b80\u5355\uff0c\u4ec5\u6355\u6349\u4e86\u5c11\u91cf\u5c5e\u6027\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4eba\u7c7b\u8eab\u4efd\u7684\u4e30\u5bcc\u590d\u6742\u6027\u548c\u591a\u6837\u6027\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u9996\u5148\u901a\u8fc7\u6316\u6398\u6570\u5343\u4e2a\u771f\u5b9e\u7528\u6237\u4e0eChatGPT\u7684\u5bf9\u8bdd\uff0c\u7b97\u6cd5\u6784\u5efa\u4e86\u6700\u5927\u7684\u4eba\u7c7b\u5c5e\u6027\u5206\u7c7b\u5b66\uff1b\u7136\u540e\u4ece\u8be5\u5206\u7c7b\u5b66\u4e2d\u9010\u6b65\u91c7\u6837\u5c5e\u6027\uff0c\u6709\u6761\u4ef6\u5730\u751f\u6210\u8fde\u8d2f\u4e14\u771f\u5b9e\u7684\u4eba\u7269\u89d2\u8272\u3002", "result": "\u5185\u5728\u8bc4\u4f30\u663e\u793a\u5c5e\u6027\u591a\u6837\u6027\u63d0\u9ad8\u4e8632%\uff0c\u89d2\u8272\u72ec\u7279\u6027\u63d0\u9ad8\u4e8644%\uff1b\u5916\u5728\u8bc4\u4f30\u663e\u793a\u5728\u4e2a\u6027\u5316\u95ee\u7b54\u51c6\u786e\u7387\u4e0a\u5e73\u5747\u63d0\u9ad8\u4e8611.6%\uff0c\u5728\u793e\u4ea4\u8c03\u67e5\u4e2d\u7f29\u5c0f\u4e86\u6a21\u62dfLLM\u516c\u6c11\u4e0e\u771f\u5b9e\u4eba\u7c7b\u54cd\u5e94\u4e4b\u95f4\u7684\u5dee\u8ddd31.7%\u3002", "conclusion": "DEEPPERSONA\u4e3a\u9ad8\u4fdd\u771f\u4eba\u7c7b\u6a21\u62df\u548c\u4e2a\u6027\u5316AI\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e25\u8c28\u3001\u53ef\u6269\u5c55\u4e14\u65e0\u9700\u9690\u79c1\u7684\u5e73\u53f0\u3002"}}
{"id": "2511.07413", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07413", "abs": "https://arxiv.org/abs/2511.07413", "authors": ["Yuxuan Sun", "Manchen Wang", "Shengyi Qian", "William R. Wong", "Eric Gan", "Pierluca D'Oro", "Alejandro Castillejo Munoz", "Sneha Silwal", "Pedro Matias", "Nitin Kamra", "Satwik Kottur", "Nick Raines", "Xuanyi Zhao", "Joy Chen", "Joseph Greer", "Andrea Madotto", "Allen Bolourchi", "James Valori", "Kevin Carlberg", "Karl Ridgeway", "Joseph Tighe"], "title": "DigiData: Training and Evaluating General-Purpose Mobile Control Agents", "comment": "Website: https://facebookresearch.github.io/DigiData", "summary": "AI agents capable of controlling user interfaces have the potential to transform human interaction with digital devices. To accelerate this transformation, two fundamental building blocks are essential: high-quality datasets that enable agents to achieve complex and human-relevant goals, and robust evaluation methods that allow researchers and practitioners to rapidly enhance agent performance. In this paper, we introduce DigiData, a large-scale, high-quality, diverse, multi-modal dataset designed for training mobile control agents. Unlike existing datasets, which derive goals from unstructured interactions, DigiData is meticulously constructed through comprehensive exploration of app features, resulting in greater diversity and higher goal complexity. Additionally, we present DigiData-Bench, a benchmark for evaluating mobile control agents on real-world complex tasks. We demonstrate that the commonly used step-accuracy metric falls short in reliably assessing mobile control agents and, to address this, we propose dynamic evaluation protocols and AI-powered evaluations as rigorous alternatives for agent assessment. Our contributions aim to significantly advance the development of mobile control agents, paving the way for more intuitive and effective human-device interactions.", "AI": {"tldr": "\u63d0\u51fa\u4e86DigiData\u6570\u636e\u96c6\u548cDigiData-Bench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u79fb\u52a8\u63a7\u5236AI\u4ee3\u7406\u3002\u8be5\u6570\u636e\u96c6\u901a\u8fc7\u5168\u9762\u63a2\u7d22\u5e94\u7528\u529f\u80fd\u6784\u5efa\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u591a\u6837\u6027\u548c\u76ee\u6807\u590d\u6742\u6027\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u52a8\u6001\u8bc4\u4f30\u534f\u8bae\u548cAI\u9a71\u52a8\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u89e3\u51b3\u73b0\u6709\u8bc4\u4f30\u6307\u6807\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f00\u53d1\u80fd\u591f\u63a7\u5236\u7528\u6237\u754c\u9762\u7684AI\u4ee3\u7406\u53ef\u4ee5\u6539\u53d8\u4eba\u7c7b\u4e0e\u6570\u5b57\u8bbe\u5907\u7684\u4ea4\u4e92\u65b9\u5f0f\uff0c\u4f46\u9700\u8981\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\u6765\u8bad\u7ec3\u4ee3\u7406\u5b8c\u6210\u590d\u6742\u7684\u4eba\u7c7b\u76f8\u5173\u76ee\u6807\uff0c\u4ee5\u53ca\u5f3a\u5927\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u5feb\u901f\u63d0\u5347\u4ee3\u7406\u6027\u80fd\u3002", "method": "\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u3001\u591a\u6837\u5316\u3001\u591a\u6a21\u6001\u7684DigiData\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5168\u9762\u63a2\u7d22\u5e94\u7528\u529f\u80fd\u800c\u975e\u975e\u7ed3\u6784\u5316\u4ea4\u4e92\u6765\u6784\u5efa\u76ee\u6807\uff1b\u540c\u65f6\u63d0\u51fa\u4e86DigiData-Bench\u57fa\u51c6\uff0c\u91c7\u7528\u52a8\u6001\u8bc4\u4f30\u534f\u8bae\u548cAI\u9a71\u52a8\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u521b\u5efa\u4e86\u6bd4\u73b0\u6709\u6570\u636e\u96c6\u66f4\u5177\u591a\u6837\u6027\u548c\u66f4\u9ad8\u76ee\u6807\u590d\u6742\u6027\u7684\u6570\u636e\u96c6\uff0c\u5e76\u8bc1\u660e\u4e86\u5e38\u7528\u7684\u6b65\u9aa4\u51c6\u786e\u6027\u6307\u6807\u5728\u8bc4\u4f30\u79fb\u52a8\u63a7\u5236\u4ee3\u7406\u65f6\u5b58\u5728\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u66f4\u4e25\u683c\u7684\u66ff\u4ee3\u8bc4\u4f30\u65b9\u6848\u3002", "conclusion": "\u8fd9\u4e9b\u8d21\u732e\u65e8\u5728\u663e\u8457\u63a8\u8fdb\u79fb\u52a8\u63a7\u5236\u4ee3\u7406\u7684\u53d1\u5c55\uff0c\u4e3a\u66f4\u76f4\u89c2\u548c\u6709\u6548\u7684\u4eba\u673a\u4ea4\u4e92\u94fa\u5e73\u9053\u8def\u3002"}}
