<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 8]
- [cs.AI](#cs.AI) [Total: 48]
- [cs.IT](#cs.IT) [Total: 9]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [LIFY: IoT System for Monitoring Vital Signs of Elderly People](https://arxiv.org/abs/2509.18411)
*Sara Gonzalez,Martin Vasquez,Wilder Castellanos*

Main category: cs.NI

TL;DR: 本文描述了一个技术解决方案，旨在改善老年护理机构中老年人生理信号的记录。系统包括配备体温、心率和血氧水平传感器的智能设备，通过互联网将数据传输到云平台存储，并创建了可视化实时数据的仪表板，具有用户管理和个性化警报功能。


<details>
  <summary>Details</summary>
Motivation: 改善老年护理机构中老年人生理信号的监测和记录，提高护理质量和效率。

Method: 开发配备传感器的智能设备，建立互联网连接传输数据到云平台，创建可视化仪表板，集成Telegram即时通讯系统进行警报通知。

Result: 成功实现了生理信号的实时监测、数据存储和可视化，以及通过Telegram发送个性化警报的功能。

Conclusion: 该技术解决方案有效改善了老年护理机构中生理信号的记录和监测，为老年人护理提供了实用的技术支持。

Abstract: This article describes the implementation of a technological solution aimed
at improving the recording of physiological signals in the elderly population
residing in geriatric facilities. The developed system consists of a smart
device equipped with sensors for body temperature, heart rate, and blood oxygen
levels. This device establishes an Internet connection to transmit data to a
cloud-based platform for storage. Within this platform, a dashboard has been
created to visualize real-time values captured by the sensors, along with
additional functionalities such as user management and the configuration of
personalized alerts, which are transmitted to the solution's users through the
instant messaging system called Telegram.

</details>


### [2] [5GC-Bench: A Framework for Stress-Testing and Benchmarking 5G Core VNFs](https://arxiv.org/abs/2509.18443)
*Ioannis Panitsas,Tolga O. Atalay,Dragoslav Stojadinovic,Angelos Stavrou,Leandros Tassiulas*

Main category: cs.NI

TL;DR: 5GC-Bench是一个模块化框架，用于在真实工作负载下对5G核心网进行压力测试，能够联合模拟信令和服务流量，支持VNF性能分析和端到端服务链分析。


<details>
  <summary>Details</summary>
Motivation: 5G核心网的云原生设计带来了灵活性和可扩展性，但也引入了复杂挑战。现有工具往往孤立地测试各个维度，依赖合成工作负载，或缺乏细粒度资源使用可见性。

Method: 开发了5GC-Bench框架，集成了OpenAirInterface 5GC，并在真实5G测试平台上部署，通过模拟真实工作负载来识别资源瓶颈和跨VNF依赖关系。

Result: 5GC-Bench能够发现资源约束并暴露跨VNF依赖关系，在模拟实际5G部署场景下提供了可操作的容量规划和性能优化见解。

Conclusion: 该框架为5G核心网性能测试提供了有效工具，所有相关组件已公开发布以促进可重复性和进一步研究。

Abstract: The disaggregated, cloud-native design of the 5G Core (5GC) enables
flexibility and scalability but introduces significant challenges.
Control-plane procedures involve complex interactions across multiple Virtual
Network Functions (VNFs), while the user plane must sustain diverse and
resource-intensive traffic. Existing tools often benchmark these dimensions in
isolation, rely on synthetic workloads, or lack visibility into fine-grained
resource usage. This paper presents 5GC-Bench, a modular framework for
stress-testing the 5GC under realistic workloads. 5GC-Bench jointly emulates
signaling and service traffic, supporting both VNF profiling and end-to-end
service-chain analysis. By characterizing bottlenecks and resource demands, it
provides actionable insights for capacity planning and performance
optimization. We integrated 5GC-Bench with the OpenAirInterface (OAI) 5GC and
deployed it on a real 5G testbed, demonstrating its ability to uncover resource
constraints and expose cross-VNF dependencies under scenarios that mirror
operational 5G deployments. To foster reproducibility and further research, we
release publicly all the artifacts.

</details>


### [3] [Using Age of Information for Throughput Optimal Spectrum Sharing](https://arxiv.org/abs/2509.18465)
*Hongjae Nam,Vishrant Tripathi,David J. Love*

Main category: cs.NI

TL;DR: 该论文研究了频谱共享问题，提出了一种基于Whittle指数和信息年龄(AoI)的次用户调度策略，以最大化吞吐量同时最小化与主用户的碰撞。


<details>
  <summary>Details</summary>
Motivation: 解决多信道频谱共享中次用户需要在满足频谱接入约束的同时最大化自身吞吐量的问题，特别是处理主用户占用状态的动态变化和信息新鲜度的影响。

Method: 将多信道问题解耦为单信道问题，证明最优阈值策略的存在性，分析策略结构建立索引性，推导基于Whittle指数和信息年龄的调度策略，并扩展到相关信道模型和未知马尔可夫参数的学习。

Result: 通过详细数值仿真验证了所提方法的性能优势，表明基于信息年龄的调度策略能有效提升次用户吞吐量并减少碰撞。

Conclusion: 提出的Whittle指数调度策略为动态频谱接入提供了有效的解决方案，特别是在处理信息新鲜度和信道相关性方面表现出色，具有实际应用价值。

Abstract: We consider a spectrum sharing problem where two users attempt to communicate
over N channels. The Primary User (PU) has prioritized transmissions and its
occupancy on each channel over time can be modeled as a Markov chain. The
Secondary User (SU) needs to determine which channels are free at each
time-slot and attempt opportunistic transmissions. The goal of the SU is to
maximize its own throughput, while simultaneously minimizing collisions with
the PU, and satisfying spectrum access constraints. To solve this problem, we
first decouple the multiple-channel problem into N single-channel problems. For
each decoupled problem, we prove that there exists an optimal threshold policy
that depends on the last observed PU occupancy and the freshness of this
occupancy information. Second, we establish the indexability of the decoupled
problems by analyzing the structure of the optimal threshold policy. Using this
structure, we derive a Whittle index-based scheduling policy that allocates SU
transmissions using the Age of Information (AoI) of accessed channels. We also
extend our insights to PU occupancy models that are correlated across channels
and incorporate learning of unknown Markov transition matrices into our
policies. Finally, we provide detailed numerical simulations that demonstrate
the performance gains of our approach.

</details>


### [4] [Whack-a-Mole: Deterministic Packet Spraying Across Multiple Network Paths](https://arxiv.org/abs/2509.18519)
*Michael Luby,John Byers*

Main category: cs.NI

TL;DR: Whack-a-Mole是一种确定性数据包分发算法，用于在多路径网络中分发数据包，具有可证明的紧致差异界限。该算法针对大规模分布式AI/ML训练和推理工作负载设计，通过位反转计数器选择路径，并对拥塞反馈做出快速响应。


<details>
  <summary>Details</summary>
Motivation: 大规模分布式AI/ML训练和推理工作负载对尾部延迟和传输不平衡高度敏感，集体完成时间（CCT）和有效训练时间比（ETTR）需要优化的多路径传输协议。

Method: 将路径配置文件表示为n条路径上m个选择单元的离散分配，使用位反转计数器为每个数据包选择路径。算法通过减少降级路径的分配并将负载重新分配到更健康的路径来快速响应拥塞反馈。

Result: 证明在任何连续数据包序列中，每条路径的预期与实际数据包计数之间的差异界限为O(log m)。该算法具有确定性分布、低每包开销和与擦除编码传输兼容的特点。

Conclusion: Whack-a-Mole是构建多路径传输协议的有效基础模块，旨在最小化CCT和最大化GPU利用率，特别适用于AI/ML工作负载的传输需求。

Abstract: We present Whack-a-Mole, a deterministic packet spraying algorithm for
distributing packets across multiple network paths with provably tight
discrepancy bounds. The algorithm is motivated by large-scale distributed AI/ML
training and inference workloads, where collective completion time (CCT) and
effective training time ratio (ETTR) are highly sensitive to tail latency and
transport imbalance. Whack-a-Mole represents the path profile as a discrete
allocation of $m$ selection units across $n$ paths and uses a bit-reversal
counter to choose a path for each packet. We prove that the discrepancy between
expected and actual packet counts per path is bounded by $O(\log m)$ over any
contiguous packet sequence. The algorithm responds quickly to congestion
feedback by reducing allocations to degraded paths and redistributing load to
healthier ones. This combination of deterministic distribution, low per-packet
overhead, and compatibility with erasure-coded transport makes Whack-a-Mole an
effective building block for multipath transport protocols that aim to minimize
CCT and maximize GPU utilization.

</details>


### [5] [Accelerating Network Slice Placement with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2509.18545)
*Ioannis Panitsas,Tolga O. Atalay,Dragoslav Stojadinovic,Angelos Stavrou,Leandros Tassiulas*

Main category: cs.NI

TL;DR: 本文提出了一种基于多智能体强化学习（MARL）的模块化框架，用于在多云环境中实现自主且接近最优的VNF放置，以解决5G网络切片部署中的资源分配挑战。


<details>
  <summary>Details</summary>
Motivation: 随着5G网络采用云原生基础设施，网络切片在异构多云环境中的部署面临新的挑战，包括可变资源能力和切片特定需求，需要高效的VNF放置方案。

Method: 采用模块化框架，结合真实流量配置文件估计切片资源需求，并使用基于MARL的调度器来最小化部署成本同时满足QoS约束。

Result: 在多云测试平台上的实验评估显示，相比组合优化方法实现了19倍的加速，部署成本在最优解的7.8%以内，但在高负载下会产生最多2.42倍的QoS违规。

Conclusion: MARL方法在异构基础设施中为实时网络切片放置提供了可扩展且成本效益高的解决方案，在决策速度和计算复杂度方面具有显著优势。

Abstract: Cellular networks are increasingly realized through software-based entities,
with core functions deployed as Virtual Network Functions (VNFs) on
Commercial-off-the-Shelf (COTS) hardware. Network slicing has emerged as a key
enabler of 5G by providing logically isolated Quality of Service (QoS)
guarantees for diverse applications. With the adoption of cloud-native
infrastructures, the placement of network slices across heterogeneous
multi-cloud environments poses new challenges due to variable resource
capabilities and slice-specific requirements. This paper introduces a modular
framework for autonomous and near-optimal VNF placement based on a
disaggregated Multi-Agent Reinforcement Learning (MARL) approach. The framework
incorporates real traffic profiles to estimate slice resource demands and
employs a MARL-based scheduler to minimize deployment cost while meeting QoS
constraints. Experimental evaluation on a multi-cloud testbed shows a 19x
speed-up compared to combinatorial optimization, with deployment costs within
7.8% of the optimal. While the method incurs up to 2.42x more QoS violations
under high load, the trade-off provides significantly faster decision-making
and reduced computational complexity. These results suggest that MARL-based
approaches offer a scalable and cost-efficient solution for real-time network
slice placement in heterogeneous infrastructures.

</details>


### [6] [Online Learning for Optimizing AoI-Energy Tradeoff under Unknown Channel Statistics](https://arxiv.org/abs/2509.18654)
*Mohamed A. Abd-Elmagid,Ming Shi,Eylem Ekici,Ness B. Shroff*

Main category: cs.NI

TL;DR: 本文研究了一个实时监控系统中，源节点在未知信道统计信息的情况下，通过在线学习算法优化能量消耗与信息新鲜度（AoI）之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究在已知信道统计信息的假设下优化了能量消耗与AoI性能的权衡，但实际场景中信道统计信息通常是未知的，需要开发在线学习算法来解决这一实际问题。

Method: 首先证明了在已知信道统计信息时，最优调度策略具有基于AoI值的阈值结构（即当AoI低于某个阈值时丢弃更新）。利用这一关键洞察，开发了在线学习算法，这些算法在时间范围长度上实现了阶数最优的遗憾（O(1)）。

Result: 提出的学习算法在未知信道统计信息的实际场景中，能够优化能量消耗与AoI性能的权衡，并且达到了阶数最优的遗憾性能。

Conclusion: 本文成功开发了具有有限时间保证的在线学习算法，解决了实际监控系统中在未知信道统计信息情况下的调度优化问题，证明了阈值结构策略的最优性，并实现了优异的性能保证。

Abstract: We consider a real-time monitoring system where a source node (with energy
limitations) aims to keep the information status at a destination node as fresh
as possible by scheduling status update transmissions over a set of channels.
The freshness of information at the destination node is measured in terms of
the Age of Information (AoI) metric. In this setting, a natural tradeoff exists
between the transmission cost (or equivalently, energy consumption) of the
source and the achievable AoI performance at the destination. This tradeoff has
been optimized in the existing literature under the assumption of having a
complete knowledge of the channel statistics. In this work, we develop online
learning-based algorithms with finite-time guarantees that optimize this
tradeoff in the practical scenario where the channel statistics are unknown to
the scheduler. In particular, when the channel statistics are known, the
optimal scheduling policy is first proven to have a threshold-based structure
with respect to the value of AoI (i.e., it is optimal to drop updates when the
AoI value is below some threshold). This key insight was then utilized to
develop the proposed learning algorithms that surprisingly achieve an
order-optimal regret (i.e., $O(1)$) with respect to the time horizon length.

</details>


### [7] [Accurate and Efficient Prediction of Wi-Fi Link Quality Based on Machine Learning](https://arxiv.org/abs/2509.18933)
*Gabriele Formis,Gianluca Cena,Lukasz Wisniewski,Stefano Scanzio*

Main category: cs.NI

TL;DR: 本文分析了基于机器学习技术的Wi-Fi链路质量预测模型，特别关注低复杂度实现的数据驱动模型，评估了其在真实Wi-Fi测试环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 无线通信的不确定性给通信质量一致性带来挑战，需要开发准确高效的预测模型来提升Wi-Fi在工业环境中的可靠性。

Method: 采用基于指数移动平均线性组合的数据驱动模型，设计用于低复杂度实现，适合处理资源有限的硬件平台。使用真实Wi-Fi测试床的实验数据评估模型准确性，考虑信道相关和信道无关的训练数据。

Result: 信道无关模型表现出竞争力，允许设备制造商进行通用化训练。

Conclusion: 该研究为在工业环境中实际部署基于机器学习的预测模型以增强Wi-Fi可靠性提供了见解。

Abstract: Wireless communications are characterized by their unpredictability, posing
challenges for maintaining consistent communication quality. This paper
presents a comprehensive analysis of various prediction models, with a focus on
achieving accurate and efficient Wi-Fi link quality forecasts using machine
learning techniques. Specifically, the paper evaluates the performance of
data-driven models based on the linear combination of exponential moving
averages, which are designed for low-complexity implementations and are then
suitable for hardware platforms with limited processing resources. Accuracy of
the proposed approaches was assessed using experimental data from a real-world
Wi-Fi testbed, considering both channel-dependent and channel-independent
training data. Remarkably, channel-independent models, which allow for
generalized training by equipment manufacturers, demonstrated competitive
performance. Overall, this study provides insights into the practical
deployment of machine learning-based prediction models for enhancing Wi-Fi
dependability in industrial environments.

</details>


### [8] [Poster: The Internet Quality Barometer Framework](https://arxiv.org/abs/2509.19034)
*Lai Yi Ohlsen,Pavlos Sermpezis,Melissa Newcomb*

Main category: cs.NI

TL;DR: IQB框架重新定义互联网质量，通过用户中心的方法考虑流行用例，将网络需求映射到用例，利用公开数据集计算反映互联网体验质量的综合指标。


<details>
  <summary>Details</summary>
Motivation: 传统互联网质量评估过于关注"速度"，需要更全面的用户中心质量评估框架。

Method: 定义用户中心的质量标准，建立用例与网络需求的映射关系，使用权重和质量阈值，利用公开性能数据集计算IQB综合得分。

Result: 开发出IQB评分系统，能够更全面地反映互联网体验质量。

Conclusion: IQB框架为互联网质量评估提供了更全面、用户中心的新方法，超越了单纯的速度指标。

Abstract: In this paper, we introduce the Internet Quality Barometer (IQB), a framework
aiming to redefine Internet quality beyond ``speed''. IQB (i) defines Internet
quality in a user-centric way by considering popular use cases, (ii) maps
network requirements to use cases through a set of weights and quality
thresholds, and (iii) leverages publicly available Internet performance
datasets, to calculate the IQB score, a composite metric that reflects the
quality of Internet experience.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [A Cost-Benefit Analysis of On-Premise Large Language Model Deployment: Breaking Even with Commercial LLM Services](https://arxiv.org/abs/2509.18101)
*Guanzhong Pan,Haibo Wang*

Main category: cs.AI

TL;DR: 本文提出了一个成本效益分析框架，帮助组织确定何时本地部署开源LLM比商业订阅服务更具经济可行性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，组织面临选择商业LLM服务还是本地部署的决策。虽然云服务提供便捷访问和扩展性，但数据隐私、供应商锁定和长期运营成本等问题推动了本地开源模型部署的需求。

Method: 通过分析最新开源模型（如Qwen、Llama、Mistral等）的硬件需求、运营费用和性能基准，并与主要云服务提供商的订阅费用进行对比。

Result: 研究提供了基于使用水平和性能需求的盈亏平衡点估计。

Conclusion: 这些结果为组织规划LLM战略提供了实用框架。

Abstract: Large language models (LLMs) are becoming increasingly widespread.
Organizations that want to use AI for productivity now face an important
decision. They can subscribe to commercial LLM services or deploy models on
their own infrastructure. Cloud services from providers such as OpenAI,
Anthropic, and Google are attractive because they provide easy access to
state-of-the-art models and are easy to scale. However, concerns about data
privacy, the difficulty of switching service providers, and long-term operating
costs have driven interest in local deployment of open-source models. This
paper presents a cost-benefit analysis framework to help organizations
determine when on-premise LLM deployment becomes economically viable compared
to commercial subscription services. We consider the hardware requirements,
operational expenses, and performance benchmarks of the latest open-source
models, including Qwen, Llama, Mistral, and etc. Then we compare the total cost
of deploying these models locally with the major cloud providers subscription
fee. Our findings provide an estimated breakeven point based on usage levels
and performance needs. These results give organizations a practical framework
for planning their LLM strategies.

</details>


### [10] [SPADE: A Large Language Model Framework for Soil Moisture Pattern Recognition and Anomaly Detection in Precision Agriculture](https://arxiv.org/abs/2509.18123)
*Yeonju Lee,Rui Qi Chen,Joseph Oboamah,Po Nien Su,Wei-zhen Liang,Yeyin Shi,Lu Gan,Yongsheng Chen,Xin Qiao,Jing Li*

Main category: cs.AI

TL;DR: SPADE是一个利用大语言模型分析土壤湿度时间序列数据的框架，能够检测灌溉模式和异常，无需特定任务标注或微调。


<details>
  <summary>Details</summary>
Motivation: 现有土壤湿度分析方法依赖阈值规则或数据密集型模型，适应性和可解释性有限。

Method: 使用ChatGPT-4.1，将时间序列数据转换为文本表示，设计领域知识提示模板，进行零样本分析。

Result: SPADE在异常检测方面优于现有方法，召回率和F1分数更高，灌溉事件检测精度和召回率也很高。

Conclusion: LLMs可作为精准农业的可扩展、适应性工具，整合定性知识和数据驱动推理，提供可操作的土壤湿度监测和灌溉调度见解。

Abstract: Accurate interpretation of soil moisture patterns is critical for irrigation
scheduling and crop management, yet existing approaches for soil moisture
time-series analysis either rely on threshold-based rules or data-hungry
machine learning or deep learning models that are limited in adaptability and
interpretability. In this study, we introduce SPADE (Soil moisture Pattern and
Anomaly DEtection), an integrated framework that leverages large language
models (LLMs) to jointly detect irrigation patterns and anomalies in soil
moisture time-series data. SPADE utilizes ChatGPT-4.1 for its advanced
reasoning and instruction-following capabilities, enabling zero-shot analysis
without requiring task-specific annotation or fine-tuning. By converting
time-series data into a textual representation and designing domain-informed
prompt templates, SPADE identifies irrigation events, estimates net irrigation
gains, detects, classifies anomalies, and produces structured, interpretable
reports. Experiments were conducted on real-world soil moisture sensor data
from commercial and experimental farms cultivating multiple crops across the
United States. Results demonstrate that SPADE outperforms the existing method
in anomaly detection, achieving higher recall and F1 scores and accurately
classifying anomaly types. Furthermore, SPADE achieved high precision and
recall in detecting irrigation events, indicating its strong capability to
capture irrigation patterns accurately. SPADE's reports provide
interpretability and usability of soil moisture analytics. This study
highlights the potential of LLMs as scalable, adaptable tools for precision
agriculture, which is capable of integrating qualitative knowledge and
data-driven reasoning to produce actionable insights for accurate soil moisture
monitoring and improved irrigation scheduling from soil moisture time-series
data.

</details>


### [11] [Position Paper: Integrating Explainability and Uncertainty Estimation in Medical AI](https://arxiv.org/abs/2509.18132)
*Xiuyi Fan*

Main category: cs.AI

TL;DR: 本文提出可解释不确定性估计（XUE），将可解释性与不确定性量化相结合，以增强医疗AI的可信度和可用性。


<details>
  <summary>Details</summary>
Motivation: 当前医疗AI系统未能以符合临床推理的方式明确量化或传达不确定性，现有可解释AI（XAI）工作缺乏对预测置信度的捕捉，而不确定性估计（UE）技术又缺乏直观解释，这种脱节限制了AI在医学中的应用。

Method: 系统地将医学不确定性映射到AI不确定性概念，识别XUE实施的关键挑战，提出技术方向包括多模态不确定性量化、模型无关可视化技术和不确定性感知决策支持系统。

Result: 分析了XUE的实现需求，提出了确保有效XUE实现的指导原则。

Conclusion: 这项工作通过桥接可解释性和不确定性，为开发可信赖的医疗AI做出贡献，为符合现实世界临床复杂性的AI系统铺平道路。

Abstract: Uncertainty is a fundamental challenge in medical practice, but current
medical AI systems fail to explicitly quantify or communicate uncertainty in a
way that aligns with clinical reasoning. Existing XAI works focus on
interpreting model predictions but do not capture the confidence or reliability
of these predictions. Conversely, uncertainty estimation (UE) techniques
provide confidence measures but lack intuitive explanations. The disconnect
between these two areas limits AI adoption in medicine. To address this gap, we
propose Explainable Uncertainty Estimation (XUE) that integrates explainability
with uncertainty quantification to enhance trust and usability in medical AI.
We systematically map medical uncertainty to AI uncertainty concepts and
identify key challenges in implementing XUE. We outline technical directions
for advancing XUE, including multimodal uncertainty quantification,
model-agnostic visualization techniques, and uncertainty-aware decision support
systems. Lastly, we propose guiding principles to ensure effective XUE
realisation. Our analysis highlights the need for AI systems that not only
generate reliable predictions but also articulate confidence levels in a
clinically meaningful way. This work contributes to the development of
trustworthy medical AI by bridging explainability and uncertainty, paving the
way for AI systems that are aligned with real-world clinical complexities.

</details>


### [12] [HSGM: Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics](https://arxiv.org/abs/2509.18168)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: HSGM框架通过分层段图内存技术解决长文档语义解析中的二次复杂度问题，将输入分解为有意义的段，构建局部语义图，并通过摘要节点形成全局图内存，实现增量更新和分层查询处理。


<details>
  <summary>Details</summary>
Motivation: 长文档语义解析面临二次复杂度增长和内存需求高的挑战，需要一种能够高效处理超长文本的语义建模方法。

Method: HSGM框架将输入分解为M个有意义的段，在每个段上构建局部语义图，提取紧凑的摘要节点形成全局图内存，支持增量更新和分层查询处理。

Result: 在三个基准测试中，HSGM实现了2-4倍的推理加速，峰值内存减少超过60%，同时保持基线准确率的95%以上。

Conclusion: HSGM方法为超长文本的可扩展、准确语义建模提供了解决方案，支持实时和资源受限的NLP应用。

Abstract: Semantic parsing of long documents remains challenging due to quadratic
growth in pairwise composition and memory requirements. We introduce
\textbf{Hierarchical Segment-Graph Memory (HSGM)}, a novel framework that
decomposes an input of length $N$ into $M$ meaningful segments, constructs
\emph{Local Semantic Graphs} on each segment, and extracts compact
\emph{summary nodes} to form a \emph{Global Graph Memory}. HSGM supports
\emph{incremental updates} -- only newly arrived segments incur local graph
construction and summary-node integration -- while \emph{Hierarchical Query
Processing} locates relevant segments via top-$K$ retrieval over summary nodes
and then performs fine-grained reasoning within their local graphs.
  Theoretically, HSGM reduces worst-case complexity from $O(N^2)$ to
$O\!\left(N\,k + (N/k)^2\right)$, with segment size $k \ll N$, and we derive
Frobenius-norm bounds on the approximation error introduced by node
summarization and sparsification thresholds. Empirically, on three benchmarks
-- long-document AMR parsing, segment-level semantic role labeling (OntoNotes),
and legal event extraction -- HSGM achieves \emph{2--4$\times$ inference
speedup}, \emph{$>60\%$ reduction} in peak memory, and \emph{$\ge 95\%$} of
baseline accuracy. Our approach unlocks scalable, accurate semantic modeling
for ultra-long texts, enabling real-time and resource-constrained NLP
applications.

</details>


### [13] [Foam-Agent: An End-to-End Composable Multi-Agent Framework for Automating CFD Simulation in OpenFOAM](https://arxiv.org/abs/2509.18178)
*Ling Yue,Nithin Somasekharan,Tingwen Zhang,Yadi Cao,Shaowu Pan*

Main category: cs.AI

TL;DR: Foam-Agent是一个多智能体框架，通过单一自然语言提示自动化整个OpenFOAM工作流程，显著降低了CFD仿真的技术门槛。


<details>
  <summary>Details</summary>
Motivation: 计算流体动力学(CFD)仿真的学习曲线陡峭且设置复杂，现有系统存在自动化程度不足的问题。

Method: 采用多智能体框架，包含网格生成代理、HPC脚本自动生成和可视化功能；使用模型上下文协议(MCP)实现可组合服务架构；通过分层多索引RAG实现高保真配置生成。

Result: 在110个仿真任务基准测试中，Foam-Agent成功率达到88.2%，显著优于MetaOpenFOAM的55.5%。

Conclusion: Foam-Agent显著降低了CFD的专业门槛，展示了专用多智能体系统如何民主化复杂科学计算。

Abstract: Computational Fluid Dynamics (CFD) is an essential simulation tool in
engineering, yet its steep learning curve and complex manual setup create
significant barriers. To address these challenges, we introduce Foam-Agent, a
multi-agent framework that automates the entire end-to-end OpenFOAM workflow
from a single natural language prompt. Our key innovations address critical
gaps in existing systems: 1. An Comprehensive End-to-End Simulation Automation:
Foam-Agent is the first system to manage the full simulation pipeline,
including advanced pre-processing with a versatile Meshing Agent capable of
handling external mesh files and generating new geometries via Gmsh, automatic
generation of HPC submission scripts, and post-simulation visualization via
ParaView. 2. Composable Service Architecture: Going beyond a monolithic agent,
the framework uses Model Context Protocol (MCP) to expose its core functions as
discrete, callable tools. This allows for flexible integration and use by other
agentic systems, such as Claude-code, for more exploratory workflows. 3.
High-Fidelity Configuration Generation: We achieve superior accuracy through a
Hierarchical Multi-Index RAG for precise context retrieval and a
dependency-aware generation process that ensures configuration consistency.
Evaluated on a benchmark of 110 simulation tasks, Foam-Agent achieves an 88.2%
success rate with Claude 3.5 Sonnet, significantly outperforming existing
frameworks (55.5% for MetaOpenFOAM). Foam-Agent dramatically lowers the
expertise barrier for CFD, demonstrating how specialized multi-agent systems
can democratize complex scientific computing. The code is public at
https://github.com/csml-rpi/Foam-Agent.

</details>


### [14] [Large Language Models and Operations Research: A Structured Survey](https://arxiv.org/abs/2509.18180)
*Yang Wang,Kai Li*

Main category: cs.AI

TL;DR: 本文综述了将大语言模型（LLMs）集成到运筹学（OR）中的最新进展，主要关注自动建模、辅助优化和直接求解三个方向，并讨论了评估基准、应用领域及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统运筹学方法依赖专家建模和手动参数调整，难以处理大规模、动态和多约束问题。LLMs通过语义理解、结构化生成和推理控制，有望解决这些限制。

Method: 将LLMs在OR中的应用方法分为三类：自动建模（将自然语言描述转换为数学模型或代码）、辅助优化（生成启发式算法和演化算法）和直接求解（直接处理优化任务）。

Result: LLMs在OR中显示出潜力，但存在语义到结构映射不稳定、研究进展碎片化、泛化能力有限和评估体系不足等关键问题。

Conclusion: 本文概述了推动LLMs在OR中作用的可能研究途径，包括改进语义映射、整合研究进展、提升泛化能力和完善评估系统。

Abstract: Operations research (OR) provides fundamental methodologies for complex
system decision-making, with established applications in transportation, supply
chain management, and production scheduling. Traditional approaches, which
depend on expert-based modeling and manual parameter adjustment, often face
challenges in handling large-scale, dynamic, and multi-constraint problems.
Recently, large language models (LLMs) have shown potential to address these
limitations through semantic understanding, structured generation, and
reasoning control. LLMs can translate natural language descriptions into
mathematical models or executable code, generate heuristics, evolve algorithms,
and directly tackle optimization tasks. This paper surveys recent progress on
the integration of LLMs into OR, organizing methods into three main directions:
automatic modeling, auxiliary optimization, and direct solving. It further
reviews evaluation benchmarks and domain-specific applications, and summarizes
key open issues such as unstable semantic-to-structure mapping, fragmented
research progress, limited generalization, and insufficient evaluation systems.
Finally, the survey outlines possible research avenues for advancing the role
of LLMs in OR.

</details>


### [15] [Synthesizing Attitudes, Predicting Actions (SAPA): Behavioral Theory-Guided LLMs for Ridesourcing Mode Choice Modeling](https://arxiv.org/abs/2509.18181)
*Mustafa Sameen,Xiaojian Zhang,Xilei Zhao*

Main category: cs.AI

TL;DR: 该论文提出了SAPA框架，使用大型语言模型合成理论驱动的潜在态度来预测网约车选择模式，显著提升了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有网约车模式选择模型预测精度有限，无法捕捉关键心理因素，且面临严重的类别不平衡问题（网约车出行仅占日常出行的一小部分）。

Method: SAPA框架采用分层方法：1）使用LLM从原始旅行调查数据生成定性旅行者画像；2）基于人口统计和行为特征训练倾向得分模型；3）LLM为理论驱动的潜在变量分配定量分数；4）最终分类器整合倾向得分、潜在变量分数和可观察的行程属性来预测网约车选择。

Result: 在大规模多年旅行调查上的实验表明，SAPA显著优于最先进的基线方法，在测试集上的PR-AUC指标上提升了高达75.9%。

Conclusion: 该研究为准确预测网约车模式选择提供了强大工具，其方法学可轻松迁移到各种应用中。

Abstract: Accurate modeling of ridesourcing mode choices is essential for designing and
implementing effective traffic management policies for reducing congestion,
improving mobility, and allocating resources more efficiently. Existing models
for predicting ridesourcing mode choices often suffer from limited predictive
accuracy due to their inability to capture key psychological factors, and are
further challenged by severe class imbalance, as ridesourcing trips comprise
only a small fraction of individuals' daily travel. To address these
limitations, this paper introduces the Synthesizing Attitudes, Predicting
Actions (SAPA) framework, a hierarchical approach that uses Large Language
Models (LLMs) to synthesize theory-grounded latent attitudes to predict
ridesourcing choices. SAPA first uses an LLM to generate qualitative traveler
personas from raw travel survey data and then trains a propensity-score model
on demographic and behavioral features, enriched by those personas, to produce
an individual-level score. Next, the LLM assigns quantitative scores to
theory-driven latent variables (e.g., time and cost sensitivity), and a final
classifier integrates the propensity score, latent-variable scores (with their
interaction terms), and observable trip attributes to predict ridesourcing mode
choice. Experiments on a large-scale, multi-year travel survey show that SAPA
significantly outperforms state-of-the-art baselines, improving ridesourcing
choice predictions by up to 75.9% in terms of PR-AUC on a held-out test set.
This study provides a powerful tool for accurately predicting ridesourcing mode
choices, and provides a methodology that is readily transferable to various
applications.

</details>


### [16] [An Outcome-Based Educational Recommender System](https://arxiv.org/abs/2509.18186)
*Nursultan Askarbekuly,Timur Fayzrakhmanov,Sladjan Babarogić,Ivan Luković*

Main category: cs.AI

TL;DR: OBER是一个基于学习成果的教育推荐系统，通过将学习成果和评估项目直接嵌入数据模式，使任何推荐算法都能根据其促进的学习掌握程度进行评估。


<details>
  <summary>Details</summary>
Motivation: 大多数教育推荐系统仅基于点击或评分相关性进行调优和评估，缺乏对其真实教学影响的清晰衡量。

Method: OBER采用极简实体关系模型、基于日志的掌握度公式和插件架构，在非正式学习领域的电子学习系统中进行了为期两周的随机分组测试，比较了固定专家轨迹、协同过滤和基于知识的过滤三种方法。

Result: 协同过滤方法最大化用户留存率，但固定路径方法实现了最高的学习掌握度。

Conclusion: OBER框架允许从业者在没有额外测试开销的情况下权衡相关性、参与度和学习成果掌握度，该框架与具体方法无关，可轻松扩展到未来的自适应或情境感知推荐系统。

Abstract: Most educational recommender systems are tuned and judged on click- or
rating-based relevance, leaving their true pedagogical impact unclear. We
introduce OBER-an Outcome-Based Educational Recommender that embeds learning
outcomes and assessment items directly into the data schema, so any algorithm
can be evaluated on the mastery it fosters. OBER uses a minimalist
entity-relation model, a log-driven mastery formula, and a plug-in
architecture. Integrated into an e-learning system in non-formal domain, it was
evaluated trough a two-week randomized split test with over 5 700 learners
across three methods: fixed expert trajectory, collaborative filtering (CF),
and knowledge-based (KB) filtering. CF maximized retention, but the fixed path
achieved the highest mastery. Because OBER derives business, relevance, and
learning metrics from the same logs, it lets practitioners weigh relevance and
engagement against outcome mastery with no extra testing overhead. The
framework is method-agnostic and readily extensible to future adaptive or
context-aware recommenders.

</details>


### [17] [MMCD: Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation](https://arxiv.org/abs/2509.18198)
*Rui Liu,Zikang Wang,Peng Gao,Yu Shen,Pratap Tokekar,Ming Lin*

Main category: cs.AI

TL;DR: 提出MMCD框架，通过多模态协作决策和跨模态知识蒸馏解决自动驾驶中传感器故障或连接车辆缺失的问题，提升驾驶安全性


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶系统在传感器故障或连接车辆缺失情况下的鲁棒决策问题，现有方法假设训练和测试时所有数据模态都可用，这不切实际

Method: 提出MMCD框架，融合自车和协作车辆的多模态观测数据，采用基于教师-学生模型的跨模态知识蒸馏方法，教师模型使用多模态数据训练，学生模型设计为在模态减少时仍能有效运行

Result: 在连接自动驾驶和空地车辆协作实验中，方法将驾驶安全性提升高达20.7%，在潜在事故检测和安全驾驶决策方面超越现有最佳基线

Conclusion: MMCD框架通过多模态协作和知识蒸馏有效提升了自动驾驶系统在挑战性条件下的鲁棒性和安全性

Abstract: Autonomous systems have advanced significantly, but challenges persist in
accident-prone environments where robust decision-making is crucial. A single
vehicle's limited sensor range and obstructed views increase the likelihood of
accidents. Multi-vehicle connected systems and multi-modal approaches,
leveraging RGB images and LiDAR point clouds, have emerged as promising
solutions. However, existing methods often assume the availability of all data
modalities and connected vehicles during both training and testing, which is
impractical due to potential sensor failures or missing connected vehicles. To
address these challenges, we introduce a novel framework MMCD (Multi-Modal
Collaborative Decision-making) for connected autonomy. Our framework fuses
multi-modal observations from ego and collaborative vehicles to enhance
decision-making under challenging conditions. To ensure robust performance when
certain data modalities are unavailable during testing, we propose an approach
based on cross-modal knowledge distillation with a teacher-student model
structure. The teacher model is trained with multiple data modalities, while
the student model is designed to operate effectively with reduced modalities.
In experiments on $\textit{connected autonomous driving with ground vehicles}$
and $\textit{aerial-ground vehicles collaboration}$, our method improves
driving safety by up to ${\it 20.7}\%$, surpassing the best-existing baseline
in detecting potential accidents and making safe driving decisions. More
information can be found on our website https://ruiiu.github.io/mmcd.

</details>


### [18] [Change in Quantitative Bipolar Argumentation: Sufficient, Necessary, and Counterfactual Explanations](https://arxiv.org/abs/2509.18215)
*Timotheus Kampik,Kristijonas Čyras,José Ruiz Alarcón*

Main category: cs.AI

TL;DR: 本文提出了一种形式化方法来解释定量双极论证框架（QBAF）中推理变化的原因，通过追踪论证强度不一致性及其解释机制


<details>
  <summary>Details</summary>
Motivation: 在QBAF中进行推理并更新框架时，需要解释论证强度排序变化的原因，帮助理解推理过程的变化

Method: 定义强度不一致性概念，识别充分、必要和反事实解释，开发基于启发式的解释搜索方法并提供实现

Result: 证明了强度不一致性解释存在的充要条件，并提供了有效的解释搜索实现

Conclusion: 该方法能够有效追踪和解释QBAF更新过程中论证强度排序的变化，为推理变化提供形式化解释机制

Abstract: This paper presents a formal approach to explaining change of inference in
Quantitative Bipolar Argumentation Frameworks (QBAFs). When drawing conclusions
from a QBAF and updating the QBAF to then again draw conclusions (and so on),
our approach traces changes -- which we call strength inconsistencies -- in the
partial order over argument strengths that a semantics establishes on some
arguments of interest, called topic arguments. We trace the causes of strength
inconsistencies to specific arguments, which then serve as explanations. We
identify sufficient, necessary, and counterfactual explanations for strength
inconsistencies and show that strength inconsistency explanations exist if and
only if an update leads to strength inconsistency. We define a heuristic-based
approach to facilitate the search for strength inconsistency explanations, for
which we also provide an implementation.

</details>


### [19] [nDNA -- the Semantic Helix of Artificial Cognition](https://arxiv.org/abs/2509.18216)
*Amitava Das*

Main category: cs.AI

TL;DR: 本文提出Neural DNA（nDNA）作为语义基因型表示，通过潜在几何结构捕捉AI基础模型的内部认知身份，包括谱曲率、热力学长度和信念向量场三个维度。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试仅衡量模型行为，但模型的本质在于其潜在几何结构。nDNA旨在揭示模型的内在认知身份，包括微调痕迹、文化印记和架构漂移等。

Method: nDNA从三个几何维度合成：谱曲率（揭示跨层的概念流曲率）、热力学长度（量化语义转换所需努力）和信念向量场（描述引导模型信念方向的语义扭转场）。

Result: nDNA产生稳定的、坐标无关的神经DNA指纹，可用于追踪预训练、微调、对齐等过程中的谱系，测量检查点间的继承关系，检测数据或目标变化下的特征漂移。

Conclusion: 这项工作开启了神经基因组学新领域，将模型视为具有可追溯内部认知的数字语义有机体，为比较模型、诊断风险和治理认知演化提供了新方法。

Abstract: As AI foundation models grow in capability, a deeper question emerges: What
shapes their internal cognitive identity -- beyond fluency and output?
Benchmarks measure behavior, but the soul of a model resides in its latent
geometry. In this work, we propose Neural DNA (nDNA) as a semantic-genotypic
representation that captures this latent identity through the intrinsic
geometry of belief. At its core, nDNA is synthesized from three principled and
indispensable dimensions of latent geometry: spectral curvature, which reveals
the curvature of conceptual flow across layers; thermodynamic length, which
quantifies the semantic effort required to traverse representational
transitions through layers; and belief vector field, which delineates the
semantic torsion fields that guide a model's belief directional orientations.
Like biological DNA, it encodes ancestry, mutation, and semantic inheritance,
found in finetuning and alignment scars, cultural imprints, and architectural
drift. In naming it, we open a new field: Neural Genomics, where models are not
just tools, but digital semantic organisms with traceable inner cognition.
  Modeling statement. We read AI foundation models as semantic fluid--dynamics:
meaning is transported through layers like fluid in a shaped conduit; nDNA is
the physics-grade readout of that flow -- a geometry-first measure of how
meaning is bent, paid for, and pushed -- yielding a stable, coordinate-free
neural DNA fingerprint tied to on-input behavior; with this fingerprint we
cross into biology: tracing lineages across pretraining, fine-tuning,
alignment, pruning, distillation, and merges; measuring inheritance between
checkpoints; detecting drift as traits shift under new data or objectives; and,
ultimately, studying the evolution of artificial cognition to compare models,
diagnose risks, and govern change over time.

</details>


### [20] [Similarity Field Theory: A Mathematical Framework for Intelligence](https://arxiv.org/abs/2509.18218)
*Kei-Sing Ng*

Main category: cs.AI

TL;DR: 本文提出了相似性场理论，这是一个数学框架，用于形式化实体间相似性关系及其演化的原则。该理论定义了相似性场、系统演化、概念纤维和生成算子，并基于此形式化地定义了智能的概念。


<details>
  <summary>Details</summary>
Motivation: 作者认为持久化和转换相似性关系是任何可理解动态系统的结构基础。需要建立一个数学框架来形式化相似性值及其演化的原则，为表征、比较和构建智能系统提供基础语言。

Method: 定义了相似性场S: U×U→[0,1]，满足自反性但允许不对称性和非传递性；系统演化序列Zp=(Xp,S(p))；概念K诱导纤维Fα(K)；生成算子G。基于此形式化智能定义：若G能生成属于概念K纤维的新实体，则G相对于K是智能的。

Result: 证明了两个定理：(i)不对称性阻止相互包含；(ii)稳定性需要锚定坐标或最终限制在f的水平集内。这些结果确保了相似性场演化的约束性和可解释性。

Conclusion: 相似性场理论为智能系统提供了基础框架，可用于解释大语言模型并将其作为社会认知的实验探针。该框架确保了系统演化的约束性和可解释性。

Abstract: We posit that persisting and transforming similarity relations form the
structural basis of any comprehensible dynamic system. This paper introduces
Similarity Field Theory, a mathematical framework that formalizes the
principles governing similarity values among entities and their evolution. We
define: (1) a similarity field $S: U \times U \to [0,1]$ over a universe of
entities $U$, satisfying reflexivity $S(E,E)=1$ and treated as a directed
relational field (asymmetry and non-transitivity are allowed); (2) the
evolution of a system through a sequence $Z_p = (X_p, S^{(p)})$ indexed by
$p=0,1,2,\ldots$; (3) concepts $K$ as entities that induce fibers
$F_{\alpha}(K) = { E \in U \mid S(E,K) \ge \alpha }$, i.e., superlevel sets of
the unary map $S_K(E) := S(E,K)$; and (4) a generative operator $G$ that
produces new entities. Within this framework, we formalize a generative
definition of intelligence: an operator $G$ is intelligent with respect to a
concept $K$ if, given a system containing entities belonging to the fiber of
$K$, it generates new entities that also belong to that fiber. Similarity Field
Theory thus offers a foundational language for characterizing, comparing, and
constructing intelligent systems. We prove two theorems: (i) asymmetry blocks
mutual inclusion; and (ii) stability requires either an anchor coordinate or
eventual confinement within a level set of $f$. These results ensure that the
evolution of similarity fields is both constrained and interpretable,
culminating in an exploration of how the framework allows us to interpret large
language models and use them as experimental probes into societal cognition.

</details>


### [21] [Multimodal Health Risk Prediction System for Chronic Diseases via Vision-Language Fusion and Large Language Models](https://arxiv.org/abs/2509.18221)
*Dingxin Lu,Shurui Wu,Xinyi Huang*

Main category: cs.AI

TL;DR: VL-RiskFormer是一个用于预测个体健康风险的多模态AI框架，结合视觉和语言数据，在MIMIC-IV数据集上取得了0.90的AUROC。


<details>
  <summary>Details</summary>
Motivation: 随着慢性疾病负担增加和多模态临床数据的涌现，需要统一的多模态AI框架来主动预测个体健康风险。

Method: 提出分层堆叠的视觉-语言多模态Transformer，包含四个关键创新：跨模态预训练、时间融合块、疾病本体图适配器和LLM推理头。

Result: 在MIMIC-IV纵向队列中，平均AUROC达到0.90，预期校准误差为2.7%。

Conclusion: VL-RiskFormer展示了在多模态临床数据上进行健康风险预测的有效性，为个性化医疗提供了有力工具。

Abstract: With the rising global burden of chronic diseases and the multimodal and
heterogeneous clinical data (medical imaging, free-text recordings, wearable
sensor streams, etc.), there is an urgent need for a unified multimodal AI
framework that can proactively predict individual health risks. We propose
VL-RiskFormer, a hierarchical stacked visual-language multimodal Transformer
with a large language model (LLM) inference head embedded in its top layer. The
system builds on the dual-stream architecture of existing visual-linguistic
models (e.g., PaLM-E, LLaVA) with four key innovations: (i) pre-training with
cross-modal comparison and fine-grained alignment of radiological images,
fundus maps, and wearable device photos with corresponding clinical narratives
using momentum update encoders and debiased InfoNCE losses; (ii) a time fusion
block that integrates irregular visit sequences into the causal Transformer
decoder through adaptive time interval position coding; (iii) a disease
ontology map adapter that injects ICD-10 codes into visual and textual channels
in layers and infers comorbid patterns with the help of a graph attention
mechanism. On the MIMIC-IV longitudinal cohort, VL-RiskFormer achieved an
average AUROC of 0.90 with an expected calibration error of 2.7 percent.

</details>


### [22] [From "What to Eat?" to Perfect Recipe: ChefMind's Chain-of-Exploration for Ambiguous User Intent in Recipe Recommendation](https://arxiv.org/abs/2509.18226)
*Yu Fu,Linyue Cai,Ruoyu Wu,Yong Zhao*

Main category: cs.AI

TL;DR: ChefMind是一个混合架构的个性化菜谱推荐系统，结合了探索链、知识图谱、检索增强生成和大语言模型，解决了模糊用户意图、语义准确性和细节覆盖的挑战。


<details>
  <summary>Details</summary>
Motivation: 个性化菜谱推荐面临模糊用户意图处理、语义准确性保证和足够细节覆盖的挑战，需要更有效的解决方案。

Method: 提出ChefMind混合架构：探索链(CoE)将模糊查询细化为结构化条件，知识图谱(KG)提供语义推理和可解释性，检索增强生成(RAG)补充上下文烹饪细节，大语言模型(LLM)整合输出为连贯推荐。

Result: 在小厨方数据集和手动标注查询上的评估显示，ChefMind在准确性、相关性、完整性和清晰度方面表现优异，平均得分8.7分，优于仅使用LLM、KG或RAG的基准模型(6.4-6.7分)，未处理查询率降至1.6%。

Conclusion: ChefMind通过混合架构有效解决了菜谱推荐中的关键挑战，在各项指标上表现优越，特别在处理模糊需求方面展现出强大鲁棒性。

Abstract: Personalized recipe recommendation faces challenges in handling fuzzy user
intent, ensuring semantic accuracy, and providing sufficient detail coverage.
We propose ChefMind, a hybrid architecture combining Chain of Exploration
(CoE), Knowledge Graph (KG), Retrieval-Augmented Generation (RAG), and a Large
Language Model (LLM). CoE refines ambiguous queries into structured conditions,
KG offers semantic reasoning and interpretability, RAG supplements contextual
culinary details, and LLM integrates outputs into coherent recommendations. We
evaluate ChefMind on the Xiachufang dataset and manually annotated queries,
comparing it with LLM-only, KG-only, and RAG-only baselines. Results show that
ChefMind achieves superior performance in accuracy, relevance, completeness,
and clarity, with an average score of 8.7 versus 6.4-6.7 for ablation models.
Moreover, it reduces unprocessed queries to 1.6%, demonstrating robustness in
handling fuzzy demands.

</details>


### [23] [An N-Plus-1 GPT Agency for Critical Solution of Mechanical Engineering Analysis Problems](https://arxiv.org/abs/2509.18229)
*Anthony Patera,Rohan Abeyaratne*

Main category: cs.AI

TL;DR: 本文提出了一种"N-Plus-1" GPT代理框架，通过多个独立求解代理和比较代理来提高机械工程问题分析的可靠性，解决GPT单次求解的不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: GPT在机械工程分析中表现出不稳定性，成功概率仅为85%，这种不可靠性使其无法直接应用于教育或工程实践。需要一种机制来提高解决方案的可靠性。

Method: 采用"N-Plus-1"代理框架：首先启动N个独立求解代理产生N个解决方案，然后通过比较代理对这些方案进行汇总、比较，并推荐最优解决方案。基于孔多塞陪审团定理，当每个求解代理的成功概率大于1/2且N足够大时，多数方案很可能是正确的。

Result: 该框架能够显著提高问题求解的可靠性，比较代理还能整合不同的问题解释和数学建模方法。与Grok Heavy等商业多代理模型相比，该框架更注重透明度和教学价值。

Conclusion: 提出的N-Plus-1代理框架有效解决了GPT在机械工程分析中的不可靠性问题，通过集体决策机制提高了解决方案的质量和可靠性，特别适合教育应用场景。

Abstract: Generative AI, and specifically GPT, can produce a remarkable solution to a
mechanical engineering analysis problem - but also, on occasion, a flawed
solution. For example, an elementary mechanics problem is solved flawlessly in
one GPT instance and incorrectly in a subsequent GPT instance, with a success
probability of only 85%. This unreliability renders "out-of-the-box" GPT
unsuitable for deployment in education or engineering practice. We introduce an
"N-Plus-1" GPT Agency for Initial (Low-Cost) Analysis of mechanical engineering
Problem Statements. Agency first launches N instantiations of Agent Solve to
yield N independent Proposed Problem Solution Realizations; Agency then invokes
Agent Compare to summarize and compare the N Proposed Problem Solution
Realizations and to provide a Recommended Problem Solution. We argue from
Condorcet's Jury Theorem that, for a Problem Statement characterized by
per-Solve success probability greater than 1/2 (and N sufficiently large), the
Predominant (Agent Compare) Proposed Problem Solution will, with high
probability, correspond to a Correct Proposed Problem Solution. Furthermore,
Agent Compare can also incorporate aspects of Secondary (Agent Compare)
Proposed Problem Solutions, in particular when the latter represent alternative
Problem Statement interpretations - different Mathematical Models - or
alternative Mathematical Solution Procedures. Comparisons to Grok Heavy, a
commercial multi-agent model, show similarities in design and performance, but
also important differences in emphasis: our Agency focuses on transparency and
pedagogical value.

</details>


### [24] [Towards General Computer Control with Hierarchical Agents and Multi-Level Action Spaces](https://arxiv.org/abs/2509.18230)
*Zihan Dong,Xinyu Fan,Zixiang Tang,Yunqing Li*

Main category: cs.AI

TL;DR: ComputerAgent是一个轻量级分层强化学习框架，通过两级选项过程（管理器与子策略）控制桌面应用，解决了现有MLLM方法延迟高、样本效率差的问题，在135个真实桌面任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在桌面应用控制中存在推理延迟高、长视野稀疏奖励任务样本效率差、无法在设备上部署等问题，需要更实用的解决方案。

Method: 采用分层强化学习框架，包含管理器与子策略两级选项过程；使用三重模态状态编码器（截图、任务ID、数值状态）处理视觉和上下文多样性；集成元动作与早停机制减少无效交互；使用紧凑视觉骨干网络和小型策略网络实现设备端推理（1500万参数）。

Result: 在135个真实桌面任务中，简单任务（<8步）成功率92.1%，困难任务（≥8步）成功率58.8%，性能匹配或超过2000亿参数MLLM基线，同时模型大小减少四个数量级，推理时间减半。

Conclusion: 分层强化学习为计算机控制提供了一个实用、可扩展的替代方案，相比单一MLLM自动化方法具有明显优势。

Abstract: Controlling desktop applications via software remains a fundamental yet
under-served problem. Existing multi-modal large language models (MLLMs) ingest
screenshots and task instructions to generate keystrokes and mouse events, but
they suffer from prohibitive inference latency, poor sample efficiency on
long-horizon sparse-reward tasks, and infeasible on-device deployment. We
introduce a lightweight hierarchical reinforcement learning framework,
ComputerAgent, that formulates OS control as a two-level option process
(manager and subpolicy), employs a triple-modal state encoder (screenshot, task
ID, numeric state) to handle visual and contextual diversity, integrates
meta-actions with an early-stop mechanism to reduce wasted interactions, and
uses a compact vision backbone plus small policy networks for on-device
inference (15M parameters). On a suite of 135 real-world desktop tasks,
ComputerAgent attains 92.1% success on simple tasks (<8 steps) and 58.8% on
hard tasks (>=8 steps), matching or exceeding 200B-parameter MLLM baselines on
simple scenarios while reducing model size by over four orders of magnitude and
halving inference time. These results demonstrate that hierarchical RL offers a
practical, scalable alternative to monolithic MLLM-based automation for
computer control.

</details>


### [25] [The Illusion of Readiness: Stress Testing Large Frontier Models on Multimodal Medical Benchmarks](https://arxiv.org/abs/2509.18234)
*Yu Gu,Jingjing Fu,Xiaodong Liu,Jeya Maria Jose Valanarasu,Noel Codella,Reuben Tan,Qianchu Liu,Ying Jin,Sheng Zhang,Jinyu Wang,Rui Wang,Lei Song,Guanghui Qin,Naoto Usuyama,Cliff Wong,Cheng Hao,Hohin Lee,Praneeth Sanapathi,Sarah Hilado,Bian Jiang,Javier Alvarez-Valle,Mu Wei,Jianfeng Gao,Eric Horvitz,Matt Lungren,Hoifung Poon,Paul Vozila*

Main category: cs.AI

TL;DR: 论文指出当前医学基准测试存在缺陷，大型前沿模型在基准测试中取得高分但实际表现脆弱，容易受到输入变化影响，且存在走捷径学习的问题。


<details>
  <summary>Details</summary>
Motivation: 揭示医学AI基准测试的局限性，证明高分数并不等同于真实的医学理解能力，强调需要更严格的评估标准来确保AI在医疗领域的可靠性。

Method: 对6个旗舰模型在6个广泛使用的医学基准上进行压力测试，包括移除关键输入、改变提示词等方式，并通过临床医生指导的评分标准进行评估。

Result: 发现模型在基准测试中表现出脆弱性，容易猜测正确答案，在微小提示变化下改变答案，并生成看似合理但有缺陷的推理。不同基准测试测量内容差异很大但被等同对待。

Conclusion: 医学基准测试分数不能直接反映真实世界的准备程度，需要关注模型的鲁棒性、合理推理能力以及与真实医疗需求的匹配度，而不仅仅是排行榜分数。

Abstract: Large frontier models like GPT-5 now achieve top scores on medical
benchmarks. But our stress tests tell a different story. Leading systems often
guess correctly even when key inputs like images are removed, flip answers
under trivial prompt changes, and fabricate convincing yet flawed reasoning.
These aren't glitches; they expose how today's benchmarks reward test-taking
tricks over medical understanding. We evaluate six flagship models across six
widely used benchmarks and find that high leaderboard scores hide brittleness
and shortcut learning. Through clinician-guided rubric evaluation, we show that
benchmarks vary widely in what they truly measure yet are treated
interchangeably, masking failure modes. We caution that medical benchmark
scores do not directly reflect real-world readiness. If we want AI to earn
trust in healthcare, we must demand more than leaderboard wins and must hold
systems accountable for robustness, sound reasoning, and alignment with real
medical demands.

</details>


### [26] [Evaluating the Safety and Skill Reasoning of Large Reasoning Models Under Compute Constraints](https://arxiv.org/abs/2509.18382)
*Adarsha Balaji,Le Chen,Rajeev Thakur,Franck Cappello,Sandeep Madireddy*

Main category: cs.AI

TL;DR: 该论文研究通过推理长度约束和模型量化两种方法来降低推理模型的计算需求，并分析这些计算约束对模型安全性能的影响。


<details>
  <summary>Details</summary>
Motivation: 测试时计算扩展虽然能通过生成长链思维序列提高推理语言模型的性能，但计算成本显著增加。需要找到在保持性能的同时降低计算需求的方法。

Method: 1）使用长度控制策略优化的强化学习方法微调推理模型，满足用户定义的推理长度；2）应用量化技术，在用户定义的计算约束下最大化生成链式思维序列。

Result: 研究计算效率与模型安全性之间的权衡关系。

Conclusion: 计算约束策略（推理长度约束和模型量化）可以有效降低推理模型的计算需求，但需要平衡计算效率与安全性能之间的关系。

Abstract: Test-time compute scaling has demonstrated the ability to improve the
performance of reasoning language models by generating longer chain-of-thought
(CoT) sequences. However, this increase in performance comes with a significant
increase in computational cost. In this work, we investigate two compute
constraint strategies: (1) reasoning length constraint and (2) model
quantization, as methods to reduce the compute demand of reasoning models and
study their impact on their safety performance. Specifically, we explore two
approaches to apply compute constraints to reasoning models: (1) fine-tuning
reasoning models using a length controlled policy optimization (LCPO) based
reinforcement learning method to satisfy a user-defined CoT reasoning length,
and (2) applying quantization to maximize the generation of CoT sequences
within a user-defined compute constraint. Furthermore, we study the trade-off
between the computational efficiency and the safety of the model.

</details>


### [27] [Gödel Test: Can Large Language Models Solve Easy Conjectures?](https://arxiv.org/abs/2509.18383)
*Moran Feldman,Amin Karbasi*

Main category: cs.AI

TL;DR: 论文提出了Gödel测试，评估GPT-5在组合优化中解决未解简单猜想的能力，结果显示模型在常规推理上有进步，但在跨论文综合推理方面仍有局限。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型是否能在高级数学领域解决新的简单猜想，而不仅仅是高中和本科数学竞赛问题。

Method: 设计Gödel测试，让GPT-5解决五个组合优化中的未解猜想，提供相关源论文但不透露猜想本身，详细评估模型的推理过程。

Result: GPT-5在三个较简单问题上几乎正确解决；问题2中甚至推翻了原猜想并给出有效解；问题4（需要综合两篇论文）失败；问题5提出了正确算法但分析失败。

Conclusion: GPT-5在常规推理上取得有意义进展，偶尔展现原创性，但在跨论文综合推理方面存在明显局限，可能是通过Gödel测试的早期步骤。

Abstract: Recent announcements from frontier AI model labs have highlighted strong
results on high-school and undergraduate math competitions. Yet it remains
unclear whether large language models can solve new, simple conjectures in more
advanced areas of mathematics. We propose the G\"odel Test: evaluating whether
a model can produce correct proofs for very simple, previously unsolved
conjectures. To this end, we study the performance of GPT-5 on five conjectures
in combinatorial optimization. For each problem, we provided one or two source
papers from which the conjecture arose, withheld our own conjecture, and then
assessed the model's reasoning in detail. On the three easier problems, GPT-5
produced nearly correct solutions; for Problem 2 it even derived a different
approximation guarantee that, upon checking, refuted our conjecture while
providing a valid solution. The model failed on Problem 4, which required
combining results from two papers. On Problem 5, a harder case without a
validated conjecture, GPT-5 proposed the same algorithm we had in mind but
failed in the analysis, suggesting the proof is more challenging than expected.
Although our sample is small, the results point to meaningful progress on
routine reasoning, occasional flashes of originality, and clear limitations
when cross-paper synthesis is required. GPT-5 may represent an early step
toward frontier models eventually passing the G\"odel Test.

</details>


### [28] [ATLAS: Benchmarking and Adapting LLMs for Global Trade via Harmonized Tariff Code Classification](https://arxiv.org/abs/2509.18400)
*Pritish Yuvraj,Siva Devarakonda*

Main category: cs.AI

TL;DR: 该论文提出了首个HTS代码分类基准，基于美国海关CROSS系统构建，并展示了微调的Atlas模型在准确性和成本方面的显著优势。


<details>
  <summary>Details</summary>
Motivation: HTS代码分类是全球贸易中的关键瓶颈，但机器学习社区对此关注不足。错误分类会导致货物运输中断，主要邮政运营商因海关文件不完整而暂停向美国发货。

Method: 基于美国海关CROSS系统构建首个HTS代码分类基准，使用微调的Atlas模型（LLaMA-3.3-70B）进行10位和6位HTS代码分类。

Result: Atlas模型在10位分类中达到40%完全正确率，6位分类达到57.5%正确率，比GPT-5-Thinking和Gemini-2.5-Pro-Thinking分别提升15和27.5个百分点。成本方面，Atlas比GPT-5-Thinking便宜约5倍，比Gemini-2.5-Pro-Thinking便宜8倍。

Conclusion: Atlas模型为HTS分类设立了强基线，但该任务仍极具挑战性（仅40%的10位准确率）。通过发布数据集和模型，旨在将HTS分类定位为新的社区基准任务，并促进检索、推理和对齐方面的未来研究。

Abstract: Accurate classification of products under the Harmonized Tariff Schedule
(HTS) is a critical bottleneck in global trade, yet it has received little
attention from the machine learning community. Misclassification can halt
shipments entirely, with major postal operators suspending deliveries to the
U.S. due to incomplete customs documentation. We introduce the first benchmark
for HTS code classification, derived from the U.S. Customs Rulings Online
Search System (CROSS). Evaluating leading LLMs, we find that our fine-tuned
Atlas model (LLaMA-3.3-70B) achieves 40 percent fully correct 10-digit
classifications and 57.5 percent correct 6-digit classifications, improvements
of 15 points over GPT-5-Thinking and 27.5 points over Gemini-2.5-Pro-Thinking.
Beyond accuracy, Atlas is roughly five times cheaper than GPT-5-Thinking and
eight times cheaper than Gemini-2.5-Pro-Thinking, and can be self-hosted to
guarantee data privacy in high-stakes trade and compliance workflows. While
Atlas sets a strong baseline, the benchmark remains highly challenging, with
only 40 percent 10-digit accuracy. By releasing both dataset and model, we aim
to position HTS classification as a new community benchmark task and invite
future work in retrieval, reasoning, and alignment.

</details>


### [29] [Instruction-Following Evaluation in Function Calling for Large Language Models](https://arxiv.org/abs/2509.18420)
*Nikolai Skripko*

Main category: cs.AI

TL;DR: IFEval-FC是一个新的函数调用基准测试，专注于评估LLM对参数描述中格式指令的遵循能力，而不仅仅是参数正确性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试如BFCL、tau^2-Bench和ACEBench只评估参数正确性，但忽略了格式指令的遵循，这对于实际AI代理系统很重要。

Method: 在JSON schema描述中直接编码可验证的格式要求（如禁止标点符号），包含750个测试用例，每个用例包含一个函数和对应的用户查询，采用完全算法化评估。

Result: 即使是GPT-5和Claude 4.1 Opus等最先进的专有模型也经常无法遵循基本格式规则，揭示了实际代理系统的局限性。

Conclusion: IFEval-FC突出了当前LLM在精确指令遵循方面的不足，为改进函数调用能力提供了重要基准，代码和数据已开源。

Abstract: Function calling is a core capability of large language models, essential for
AI agents. Existing benchmarks such as the Berkeley Function Calling
Leaderboard (BFCL), tau^2-Bench (arXiv:2506.07982), and ACEBench
(arXiv:2501.12851) evaluate argument correctness but do not test adherence to
format instructions embedded in parameter descriptions, such as enclosing
values in double quotes or using ISO date formats.
  We introduce IFEval-FC, a benchmark inspired by IFEval (arXiv:2311.07911)
that assesses precise instruction following in function calling. IFEval-FC
encodes verifiable formats directly within JSON schema descriptions, for
example specifying that a value must not contain punctuation. It includes 750
test cases, each consisting of a function with an embedded format for one of
its input parameters and a corresponding user query. Evaluation is fully
algorithmic, ensuring objectivity, reproducibility, and scalability.
  Our results show that even state-of-the-art proprietary models, including
GPT-5 and Claude 4.1 Opus, frequently fail to follow basic formatting rules,
highlighting a practical limitation for real-world agent systems. The complete
codebase and data are publicly available at
https://github.com/Skripkon/IFEval-FC.

</details>


### [30] [Memory-QA: Answering Recall Questions Based on Multimodal Memories](https://arxiv.org/abs/2509.18436)
*Hongda Jiang,Xinyuan Zhang,Siddhant Garg,Rishab Arora,Shiun-Zu Kuo,Jiayang Xu,Christopher Brossman,Yue Liu,Aaron Colak,Ahmed Aly,Anuj Kumar,Xin Luna Dong*

Main category: cs.AI

TL;DR: Memory-QA是一个新颖的视觉记忆问答任务，需要从多模态记忆中回答回忆问题。提出的Pensieve管道通过记忆增强、时空感知检索和多记忆问答微调，在QA准确率上比现有方法提升高达14%。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界中从视觉记忆中回答回忆问题的挑战，包括创建任务导向记忆、有效利用记忆中的时空信息、以及从多个记忆中整合信息的能力。

Method: 提出Pensieve管道，包含记忆特定增强、时空感知多信号检索和多记忆问答微调三个核心组件。

Result: 在多模态基准测试中，Pensieve相比现有最优方法在问答准确率上提升高达14%。

Conclusion: 该工作成功解决了视觉记忆问答任务的关键挑战，证明了所提出方法的有效性，为现实世界记忆辅助应用提供了有力工具。

Abstract: We introduce Memory-QA, a novel real-world task that involves answering
recall questions about visual content from previously stored multimodal
memories. This task poses unique challenges, including the creation of
task-oriented memories, the effective utilization of temporal and location
information within memories, and the ability to draw upon multiple memories to
answer a recall question. To address these challenges, we propose a
comprehensive pipeline, Pensieve, integrating memory-specific augmentation,
time- and location-aware multi-signal retrieval, and multi-memory QA
fine-tuning. We created a multimodal benchmark to illustrate various real
challenges in this task, and show the superior performance of Pensieve over
state-of-the-art solutions (up to 14% on QA accuracy).

</details>


### [31] [FERA: Foil Fencing Referee Assistant Using Pose-Based Multi-Label Move Recognition and Rule Reasoning](https://arxiv.org/abs/2509.18527)
*Ziwen Chen,Zhong Wang*

Main category: cs.AI

TL;DR: FERA是一个用于击剑裁判的AI助手原型，通过姿态识别和规则推理来解决击剑裁判中的主观判断、人为错误等问题


<details>
  <summary>Details</summary>
Motivation: 击剑运动面临裁判主观判断、人为错误、偏见以及训练环境中裁判资源有限等挑战

Method: 结合姿态多标签动作识别和基于规则的推理，从视频中提取2D关节位置，计算101维运动学特征，使用Transformer进行多标签动作分类，并应用语言模型进行优先权和得分判定

Result: 在有限的手动标注数据下，5折交叉验证平均macro-F1得分为0.549，优于TCN、BiLSTM和普通Transformer等基线模型

Conclusion: 虽然尚未达到部署水平，但结果展示了在击剑裁判自动化方面的可行路径，并为AI在击剑教练等领域的应用开辟了新机会

Abstract: The sport of fencing, like many other sports, faces challenges in refereeing:
subjective calls, human errors, bias, and limited availability in practice
environments. We present FERA (Fencing Referee Assistant), a prototype AI
referee for foil fencing which integrates pose-based multi-label action
recognition and rule-based reasoning. FERA extracts 2D joint positions from
video, normalizes them, computes a 101-dimensional kinematic feature set, and
applies a Transformer for multi-label move and blade classification. To
determine priority and scoring, FERA applies a distilled language model with
encoded right-of-way rules, producing both a decision and an explanation for
each exchange. With limited hand-labeled data, a 5-fold cross-validation
achieves an average macro-F1 score of 0.549, outperforming multiple baselines,
including a Temporal Convolutional Network (TCN), BiLSTM, and a vanilla
Transformer. While not ready for deployment, these results demonstrate a
promising path towards automated referee assistance in foil fencing and new
opportunities for AI applications, such as coaching in the field of fencing.

</details>


### [32] [LLMZ+: Contextual Prompt Whitelist Principles for Agentic LLMs](https://arxiv.org/abs/2509.18557)
*Tom Pawelek,Raj Patel,Charlotte Crowell,Noorbakhsh Amiri,Sudip Mittal,Shahram Rahimi,Andy Perkins*

Main category: cs.AI

TL;DR: LLMZ+是一种基于提示白名单的新型防御机制，通过只允许上下文相关的安全消息与代理式LLM交互，提供对越狱攻击的强大防护。


<details>
  <summary>Details</summary>
Motivation: 代理式AI相比传统模型具有更高的安全风险，因为它们拥有对数据源和API工具的优先访问权，且依赖AI的非确定性行为。现有防御机制主要依赖恶意意图检测，存在局限性。

Method: 采用提示白名单方法，仅允许符合预定义用例和操作边界的上下文适当消息与代理式LLM交互，确保所有外部用户与LLM的交换都符合安全规范。

Result: 实证评估显示LLMZ+对常见越狱提示具有强大韧性，同时不干扰合法业务通信。在实验环境中误报率和漏报率均可降至0。

Conclusion: LLMZ+方法简化了安全框架，增强了长期韧性，减少了维持LLM信息安全所需的资源，为代理式AI提供了有效的安全防护方案。

Abstract: Compared to traditional models, agentic AI represents a highly valuable
target for potential attackers as they possess privileged access to data
sources and API tools, which are traditionally not incorporated into classical
agents. Unlike a typical software application residing in a Demilitarized Zone
(DMZ), agentic LLMs consciously rely on nondeterministic behavior of the AI
(only defining a final goal, leaving the path selection to LLM). This
characteristic introduces substantial security risk to both operational
security and information security. Most common existing defense mechanism rely
on detection of malicious intent and preventing it from reaching the LLM agent,
thus protecting against jailbreak attacks such as prompt injection. In this
paper, we present an alternative approach, LLMZ+, which moves beyond
traditional detection-based approaches by implementing prompt whitelisting.
Through this method, only contextually appropriate and safe messages are
permitted to interact with the agentic LLM. By leveraging the specificity of
context, LLMZ+ guarantees that all exchanges between external users and the LLM
conform to predefined use cases and operational boundaries. Our approach
streamlines the security framework, enhances its long-term resilience, and
reduces the resources required for sustaining LLM information security. Our
empirical evaluation demonstrates that LLMZ+ provides strong resilience against
the most common jailbreak prompts. At the same time, legitimate business
communications are not disrupted, and authorized traffic flows seamlessly
between users and the agentic LLM. We measure the effectiveness of approach
using false positive and false negative rates, both of which can be reduced to
0 in our experimental setting.

</details>


### [33] [Solving Math Word Problems Using Estimation Verification and Equation Generation](https://arxiv.org/abs/2509.18565)
*Mitchell Piehl,Dillon Wilson,Ananya Kalita,Jugal Kalita*

Main category: cs.AI

TL;DR: 提出了一种结合LLM和外部符号方程求解器的新方法，通过分解问题生成方程并验证答案，在数学应用题求解上达到新的SOTA结果


<details>
  <summary>Details</summary>
Motivation: LLM在解决数学应用题时面临挑战，需要结合推理和数学能力，现有方法仍有改进空间

Method: 先让LLM分解问题生成方程，用外部求解器得到答案，再让LLM估计答案进行验证，失败时采用迭代修正过程

Result: 在数值和代数应用题数据集上比之前最佳结果提升近2%，在三角函数应用题上也取得满意结果

Conclusion: 该方法有效提升了LLM解决复杂数学问题的能力，并引入了新的数据集推动LLM推理能力测试

Abstract: Large Language Models (LLMs) excel at various tasks, including
problem-solving and question-answering. However, LLMs often find Math Word
Problems (MWPs) challenging because solving them requires a range of reasoning
and mathematical abilities with which LLMs seem to struggle. Recent efforts
have helped LLMs solve more complex MWPs with improved prompts. This study
proposes a novel method that initially prompts an LLM to create equations from
a decomposition of the question, followed by using an external symbolic
equation solver to produce an answer. To ensure the accuracy of the obtained
answer, inspired by an established recommendation of math teachers, the LLM is
instructed to solve the MWP a second time, but this time with the objective of
estimating the correct answer instead of solving it exactly. The estimation is
then compared to the generated answer to verify. If verification fails, an
iterative rectification process is employed to ensure the correct answer is
eventually found. This approach achieves new state-of-the-art results on
datasets used by prior published research on numeric and algebraic MWPs,
improving the previous best results by nearly two percent on average. In
addition, the approach obtains satisfactory results on trigonometric MWPs, a
task not previously attempted to the authors' best knowledge. This study also
introduces two new datasets, SVAMPClean and Trig300, to further advance the
testing of LLMs' reasoning abilities.

</details>


### [34] [Adaptive Learning in Spatial Agent-Based Models for Climate Risk Assessment: A Geospatial Framework with Evolutionary Economic Agents](https://arxiv.org/abs/2509.18633)
*Yara Mohajerani*

Main category: cs.AI

TL;DR: 提出了一种结合地理空间建模与进化学习的智能体模型，用于评估气候变化对经济系统的直接和间接风险


<details>
  <summary>Details</summary>
Motivation: 气候变化风险评估需要建模复杂的地理灾害与经济系统之间的相互作用，现有模型难以捕捉供应链中的级联风险

Method: 开发了基于Mesa的地理空间智能体模型，集成CLIMADA气候影响评估，通过基于适应度的选择和变异让企业进化出预算分配、定价、工资和风险适应的策略

Result: 使用RCP8.5情景下的河流洪水预测显示，进化适应使企业能在数十年气候压力后恢复到基线生产水平；未直接暴露于洪水的企业也通过供应链中断受到影响，世纪末商品平均价格比基线高5.6%

Conclusion: 该开源框架为金融机构和公司提供了量化直接和级联气候风险的工具，同时评估成本效益适应的策略

Abstract: Climate risk assessment requires modelling complex interactions between
spatially heterogeneous hazards and adaptive economic systems. We present a
novel geospatial agent-based model that integrates climate hazard data with
evolutionary learning for economic agents. Our framework combines Mesa-based
spatial modelling with CLIMADA climate impact assessment, introducing adaptive
learning behaviours that allow firms to evolve strategies for budget
allocation, pricing, wages, and risk adaptation through fitness-based selection
and mutation. We demonstrate the framework using riverine flood projections
under RCP8.5 until 2100, showing that evolutionary adaptation enables firms to
converge with baseline (no hazard) production levels after decades of
disruption due to climate stress. Our results reveal systemic risks where even
agents that are not directly exposed to floods face impacts through supply
chain disruptions, with the end-of-century average price of goods 5.6% higher
under RCP8.5 compared to the baseline. This open-source framework provides
financial institutions and companies with tools to quantify both direct and
cascading climate risks while evaluating cost-effective adaptation strategies.

</details>


### [35] [TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2509.18667)
*Qiao Xiao,Hong Ting Tsang,Jiaxin Bai*

Main category: cs.AI

TL;DR: TERAG是一个低成本图检索增强生成框架，通过个性化PageRank实现高效检索，在仅使用3%-11%输出token的情况下达到主流图RAG方法80%以上的准确率


<details>
  <summary>Details</summary>
Motivation: 现有图RAG系统忽视了LLM token使用的高成本，阻碍了大规模应用

Method: 基于HippoRAG思想，在检索阶段引入个性化PageRank(PPR)来构建信息丰富的图结构

Result: TERAG在显著降低成本的同时，达到了主流图RAG方法80%以上的准确率

Conclusion: TERAG证明了通过优化检索策略可以在大幅降低token消耗的情况下保持图RAG的有效性

Abstract: Graph-based Retrieval-augmented generation (RAG) has become a widely studied
approach for improving the reasoning, accuracy, and factuality of Large
Language Models. However, many existing graph-based RAG systems overlook the
high cost associated with LLM token usage during graph construction, hindering
large-scale adoption. To address this, we propose TERAG, a simple yet effective
framework designed to build informative graphs at a significantly lower cost.
Inspired by HippoRAG, we incorporate Personalized PageRank (PPR) during the
retrieval phase, and we achieve at least 80% of the accuracy of widely used
graph-based RAG methods while consuming only 3%-11% of the output tokens.

</details>


### [36] [Implementation of airborne ML models with semantics preservation](https://arxiv.org/abs/2509.18681)
*Nicolas Valot,Louis Fabre,Benjamin Lesage,Ammar Mechouche,Claire Pagetti*

Main category: cs.AI

TL;DR: 本文探讨了机器学习在航空系统中的安全应用，重点区分了ML模型与其明确描述（MLMD）的区别，并提出了语义保持的概念以确保模型准确复制。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在航空系统中的广泛应用，需要确保其安全运行并符合相关法规要求。EASA和EUROCAE/SAE等机构已发布相关指导文件，但需要更具体的方法来验证ML模型的性能保持。

Method: 通过澄清ML模型与MLMD的区别，完善语义保持的概念，并在多个工业用例中应用这些概念来构建和比较目标模型。

Result: 提出了区分ML模型和MLMD的框架，并定义了语义保持的标准，通过工业用例验证了方法的有效性。

Conclusion: 该研究为航空系统中ML模型的安全认证提供了理论基础和实践指导，有助于确保ML模型在目标环境中的性能一致性。

Abstract: Machine Learning (ML) may offer new capabilities in airborne systems.
However, as any piece of airborne systems, ML-based systems will be required to
guarantee their safe operation. Thus, their development will have to be
demonstrated to be compliant with the adequate guidance. So far, the European
Union Aviation Safety Agency (EASA) has published a concept paper and an
EUROCAE/SAE group is preparing ED-324. Both approaches delineate high-level
objectives to confirm the ML model achieves its intended function and maintains
training performance in the target environment. The paper aims to clarify the
difference between an ML model and its corresponding unambiguous description,
referred to as the Machine Learning Model Description (MLMD). It then refines
the essential notion of semantics preservation to ensure the accurate
replication of the model. We apply our contributions to several industrial use
cases to build and compare several target models.

</details>


### [37] [Advances in Large Language Models for Medicine](https://arxiv.org/abs/2509.18690)
*Zhiyu Kan,Wensheng Gan,Zhenlian Qi,Philip S. Yu*

Main category: cs.AI

TL;DR: 本文系统综述了大型语言模型在医疗领域的最新研究进展，包括医疗大模型的训练技术、在医疗环境中的适应、相关应用及其优缺点，并对医疗LLMs进行了创新性分类和评估方法分类。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的快速发展，大型语言模型在医疗领域展现出巨大应用潜力，需要系统梳理当前研究进展，为后续研究提供指导。

Method: 采用系统性文献综述方法，对医疗LLMs的训练技术、适应方法、应用场景进行深入分析，并创新性地将医疗LLMs分为三类，评估方法分为两类。

Result: 系统总结了医疗LLMs的发展现状，提出了基于训练方法的分类体系和评估框架，识别了现有挑战并提出了解决方案。

Conclusion: 医疗LLMs的发展具有必要性，本文为理解其当前发展状态提供了深入视角，并为后续研究指明了清晰方向。

Abstract: Artificial intelligence (AI) technology has advanced rapidly in recent years,
with large language models (LLMs) emerging as a significant breakthrough. LLMs
are increasingly making an impact across various industries, with the medical
field standing out as the most prominent application area. This paper
systematically reviews the up-to-date research progress of LLMs in the medical
field, providing an in-depth analysis of training techniques for large medical
models, their adaptation in healthcare settings, related applications, as well
as their strengths and limitations. Furthermore, it innovatively categorizes
medical LLMs into three distinct types based on their training methodologies
and classifies their evaluation approaches into two categories. Finally, the
study proposes solutions to existing challenges and outlines future research
directions based on identified issues in the field of medical LLMs. By
systematically reviewing previous and advanced research findings, we aim to
highlight the necessity of developing medical LLMs, provide a deeper
understanding of their current state of development, and offer clear guidance
for subsequent research.

</details>


### [38] [Autonomous Data Agents: A New Opportunity for Smart Data](https://arxiv.org/abs/2509.18710)
*Yanjie Fu,Dongjie Wang,Wangyang Ying,Xiangliang Zhang,Huan Liu,Jian Pei*

Main category: cs.AI

TL;DR: 本文提出自主数据代理（DataAgents）的概念，通过集成LLM推理与任务分解、行动推理和工具调用，实现从数据到知识的自动化转换，代表数据管理向自主知识系统的范式转变。


<details>
  <summary>Details</summary>
Motivation: 随着数据规模和复杂性的增长，数据准备、转换和分析工作仍然劳动密集、重复且难以扩展。数据与AI之间的对齐至关重要，但现有数据结构往往不适合AI利用。

Method: DataAgents通过动态规划工作流、调用强大工具、适应多样化数据任务，能够处理数据收集、集成、预处理、选择、转换、重加权、增强、重编程、修复和检索等操作。

Result: DataAgents能够将复杂和非结构化数据转换为连贯且可操作的知识，为数据到知识系统带来革命性变化。

Conclusion: 需要协同努力推进行动工作流优化、建立开放数据集和基准生态系统、保护隐私、平衡效率与可扩展性，并开发可信的DataAgent防护机制以防止恶意行为。

Abstract: As data continues to grow in scale and complexity, preparing, transforming,
and analyzing it remains labor-intensive, repetitive, and difficult to scale.
Since data contains knowledge and AI learns knowledge from it, the alignment
between AI and data is essential. However, data is often not structured in ways
that are optimal for AI utilization. Moreover, an important question arises:
how much knowledge can we pack into data through intensive data operations?
Autonomous data agents (DataAgents), which integrate LLM reasoning with task
decomposition, action reasoning and grounding, and tool calling, can
autonomously interpret data task descriptions, decompose tasks into subtasks,
reason over actions, ground actions into python code or tool calling, and
execute operations. Unlike traditional data management and engineering tools,
DataAgents dynamically plan workflows, call powerful tools, and adapt to
diverse data tasks at scale. This report argues that DataAgents represent a
paradigm shift toward autonomous data-to-knowledge systems. DataAgents are
capable of handling collection, integration, preprocessing, selection,
transformation, reweighing, augmentation, reprogramming, repairs, and
retrieval. Through these capabilities, DataAgents transform complex and
unstructured data into coherent and actionable knowledge. We first examine why
the convergence of agentic AI and data-to-knowledge systems has emerged as a
critical trend. We then define the concept of DataAgents and discuss their
architectural design, training strategies, as well as the new skills and
capabilities they enable. Finally, we call for concerted efforts to advance
action workflow optimization, establish open datasets and benchmark ecosystems,
safeguard privacy, balance efficiency with scalability, and develop trustworthy
DataAgent guardrails to prevent malicious actions.

</details>


### [39] [Experience Scaling: Post-Deployment Evolution For Large Language Models](https://arxiv.org/abs/2509.18771)
*Xingkun Yin,Kaibin Huang,Dong In Kim,Hongyang Du*

Main category: cs.AI

TL;DR: 本文提出经验扩展框架，通过自主环境交互和协作经验共享实现LLM的持续进化，突破静态人类生成数据的限制


<details>
  <summary>Details</summary>
Motivation: 传统通过扩大模型规模、训练数据和计算能力的方法已接近饱和，人类生成文本资源耗尽，进一步增益减少

Method: 经验扩展框架：捕获原始交互→提炼为紧凑可重用知识→定期优化存储内容以保持相关性和效率

Result: 在模拟真实场景中验证，包括泛化到未见但相关任务、重复查询和过饱和知识库，经验扩展提高了准确性，维持了长期性能

Conclusion: 结构化部署后学习可以扩展LLM能力，超越静态人类生成数据的限制，为持续智能进步提供可扩展路径

Abstract: Scaling model size, training data, and compute power have driven advances in
large language models (LLMs), but these approaches are reaching saturation as
human-generated text is exhausted and further gains diminish. We propose
experience scaling, a framework for continuous post-deployment evolution for
LLMs through autonomous interaction with the environment and collaborative
sharing of accumulated experience. The framework captures raw interactions,
distills them into compact, reusable knowledge, and periodically refines stored
content to preserve relevance and efficiency. We validate the framework in
simulated real-world scenarios involving generalization to previously unseen
but related tasks, repetitive queries, and over-saturated knowledge stores.
Across all settings, experience scaling improves accuracy, sustains performance
over time, and maintains gains when applied to novel situations. These results
demonstrate that structured post-deployment learning can extend LLM
capabilities beyond the limits of static human-generated data, offering a
scalable path for continued intelligence progress.

</details>


### [40] [The AGNTCY Agent Directory Service: Architecture and Implementation](https://arxiv.org/abs/2509.18787)
*Luca Muscariello,Vijoy Pandey,Ramiz Polic*

Main category: cs.AI

TL;DR: ADS是一个分布式目录服务，用于发现AI代理的能力、元数据和来源，利用内容寻址存储、分层分类和加密签名实现高效、可验证的多维发现。


<details>
  <summary>Details</summary>
Motivation: 解决异构多代理系统中代理能力发现的问题，提供可验证和高效的发现机制。

Method: 基于Open Agentic Schema Framework (OASF)，采用两级映射和Kademlia-based DHT，重用OCI/ORAS基础设施，集成Sigstore用于来源验证。

Result: 构建了一个支持模式驱动扩展的分布式目录服务，能够适应新兴代理模式（如LLM提示代理、MCP服务器等）。

Conclusion: ADS在代理注册和互操作性倡议的广阔前景中定位明确，提供了安全和高性能的发现解决方案。

Abstract: The Agent Directory Service (ADS) is a distributed directory for the
discovery of AI agent capabilities, metadata, and provenance. It leverages
content-addressed storage, hierarchical taxonomies, and cryptographic signing
to enable efficient, verifiable, and multi-dimensional discovery across
heterogeneous Multi-Agent Systems (MAS). Built on the Open Agentic Schema
Framework (OASF), ADS decouples capability indexing from content location
through a two-level mapping realized over a Kademlia-based Distributed Hash
Table (DHT). It reuses mature OCI / ORAS infrastructure for artifact
distribution, integrates Sigstore for provenance, and supports schema-driven
extensibility for emerging agent modalities (LLM prompt agents, MCP servers,
A2A-enabled components). This paper formalizes the architectural model,
describes storage and discovery layers, explains security and performance
properties, and positions ADS within the broader landscape of emerging agent
registry and interoperability initiatives.

</details>


### [41] [Bounded PCTL Model Checking of Large Language Model Outputs](https://arxiv.org/abs/2509.18836)
*Dennis Gross,Helge Spieker,Arnaud Gotlieb*

Main category: cs.AI

TL;DR: LLMCHECKER是一种基于模型检测的验证方法，用于验证LLM文本生成过程的概率计算树逻辑(PCTL)属性。该方法通过α-k有界文本生成来限制验证范围，重点关注每个生成步骤中top-k令牌的最大累积概率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM文本生成过程缺乏形式化验证方法，无法确保生成文本的一致性和可靠性。作者发现文本生成过程中通常只有有限数量的令牌被选择，这为形式化验证提供了可能性。

Method: 提出α-k有界文本生成方法：在每一步生成过程中，只考虑累积概率超过阈值α的top-k个令牌。LLMCHECKER基于此构建有限状态模型，然后应用PCTL模型检测技术进行形式化验证。

Result: 该方法在多个LLM模型（Llama、Gemma、Mistral、Genstruct、BERT）上进行了验证，证明了其适用性。这是首次将PCTL模型检测应用于LLM文本生成过程的一致性检查。

Conclusion: LLMCHECKER为LLM文本生成过程提供了首个基于PCTL的形式化验证框架，能够有效验证文本质量和偏见等属性，为LLM的可靠应用提供了重要工具。

Abstract: In this paper, we introduce LLMCHECKER, a model-checking-based verification
method to verify the probabilistic computation tree logic (PCTL) properties of
an LLM text generation process. We empirically show that only a limited number
of tokens are typically chosen during text generation, which are not always the
same. This insight drives the creation of $\alpha$-$k$-bounded text generation,
narrowing the focus to the $\alpha$ maximal cumulative probability on the
top-$k$ tokens at every step of the text generation process. Our verification
method considers an initial string and the subsequent top-$k$ tokens while
accommodating diverse text quantification methods, such as evaluating text
quality and biases. The threshold $\alpha$ further reduces the selected tokens,
only choosing those that exceed or meet it in cumulative probability.
LLMCHECKER then allows us to formally verify the PCTL properties of
$\alpha$-$k$-bounded LLMs. We demonstrate the applicability of our method in
several LLMs, including Llama, Gemma, Mistral, Genstruct, and BERT. To our
knowledge, this is the first time PCTL-based model checking has been used to
check the consistency of the LLM text generation process.

</details>


### [42] [Model selection meets clinical semantics: Optimizing ICD-10-CM prediction via LLM-as-Judge evaluation, redundancy-aware sampling, and section-aware fine-tuning](https://arxiv.org/abs/2509.18846)
*Hong-Jie Dai,Zheng-Hao Li,An-Tai Lu,Bo-Tsz Shain,Ming-Ta Li,Tatheer Hussain Mir,Kuang-Te Wang,Min-I Su,Pei-Kang Liu,Ming-Ju Tsai*

Main category: cs.AI

TL;DR: 提出了一个模块化框架用于ICD-10-CM编码预测，通过原则性模型选择、冗余感知数据采样和结构化输入设计来解决现有LLM在医疗编码中的挑战。


<details>
  <summary>Details</summary>
Motivation: ICD编码对临床文档、计费和医疗分析至关重要，但目前仍是劳动密集且容易出错的任务。现有LLM在基础模型选择、输入上下文化和训练数据冗余方面存在局限性。

Method: 使用LLM-as-judge评估协议和Plackett-Luce聚合来评估开源LLM对ICD-10-CM代码定义的内在理解；引入基于嵌入的相似性度量和冗余感知采样策略；利用台湾医院的结构化出院摘要评估上下文效果。

Result: 实验表明，经过微调的基础模型在内部和外部评估中始终优于基线LLM；包含更多临床部分持续提高预测性能。

Conclusion: 该研究使用开源LLM建立了一个实用且原则性的ICD-10-CM编码预测方法，为自动化医疗编码系统的实际部署提供了可扩展的机构就绪解决方案。

Abstract: Accurate International Classification of Diseases (ICD) coding is critical
for clinical documentation, billing, and healthcare analytics, yet it remains a
labour-intensive and error-prone task. Although large language models (LLMs)
show promise in automating ICD coding, their challenges in base model
selection, input contextualization, and training data redundancy limit their
effectiveness. We propose a modular framework for ICD-10 Clinical Modification
(ICD-10-CM) code prediction that addresses these challenges through principled
model selection, redundancy-aware data sampling, and structured input design.
The framework integrates an LLM-as-judge evaluation protocol with Plackett-Luce
aggregation to assess and rank open-source LLMs based on their intrinsic
comprehension of ICD-10-CM code definitions. We introduced embedding-based
similarity measures, a redundancy-aware sampling strategy to remove
semantically duplicated discharge summaries. We leverage structured discharge
summaries from Taiwanese hospitals to evaluate contextual effects and examine
section-wise content inclusion under universal and section-specific modelling
paradigms. Experiments across two institutional datasets demonstrate that the
selected base model after fine-tuning consistently outperforms baseline LLMs in
internal and external evaluations. Incorporating more clinical sections
consistently improves prediction performance. This study uses open-source LLMs
to establish a practical and principled approach to ICD-10-CM code prediction.
The proposed framework provides a scalable, institution-ready solution for
real-world deployment of automated medical coding systems by combining informed
model selection, efficient data refinement, and context-aware prompting.

</details>


### [43] [MAPO: Mixed Advantage Policy Optimization](https://arxiv.org/abs/2509.18849)
*Wenke Huang,Quan Zhang,Yiyang Fang,Jian Liang,Xuankun Rong,Huanjin Yao,Guancheng Wan,Ke Liang,Wenwen He,Mingjun Li,Leszek Rutkowski,Mang Ye,Bo Du,Dacheng Tao*

Main category: cs.AI

TL;DR: 本文提出了一种新的强化学习策略MAPO，通过动态调整优势函数来解决GRPO中的优势反转和优势镜像问题，提高了基础模型在推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的GRPO方法在优势函数分配上存在优势反转和优势镜像问题，阻碍了不同查询样本间合理的优势分配，影响了基础模型的推理性能。

Method: 提出MAPO策略，引入轨迹确定性概念和优势百分比偏差，对高确定性轨迹样本动态重新加权优势函数，根据样本特性自适应配置优势函数。

Result: 通过与相关最先进方法的比较以及对不同优势变体的消融研究，验证了所提方法的有效性。

Conclusion: MAPO是一种简单但有效的GRPO策略，能够更好地处理轨迹确定性差异，提升基础模型在推理任务上的表现。

Abstract: Recent advances in reinforcement learning for foundation models, such as
Group Relative Policy Optimization (GRPO), have significantly improved the
performance of foundation models on reasoning tasks. Notably, the advantage
function serves as a central mechanism in GRPO for ranking the trajectory
importance. However, existing explorations encounter both advantage reversion
and advantage mirror problems, which hinder the reasonable advantage allocation
across different query samples. In this work, we propose an easy but effective
GRPO strategy, Mixed Advantage Policy Optimization (MAPO). We reveal that the
trajectory appears with different certainty and propose the advantage percent
deviation for samples with high-certainty trajectories. Furthermore, we
dynamically reweight the advantage function for samples with varying trajectory
certainty, thereby adaptively configuring the advantage function to account for
sample-specific characteristics. Comparison with related state-of-the-art
methods, along with ablation studies on different advantage variants, validates
the effectiveness of our approach.

</details>


### [44] [Conf-Profile: A Confidence-Driven Reasoning Paradigm for Label-Free User Profiling](https://arxiv.org/abs/2509.18864)
*Yingxin Li,Jianbo Zhao,Xueyu Ren,Jie Tang,Wangjie You,Xu Chen,Kan Zhou,Chao Feng,Jiao Ran,Yuan Meng,Zhi Wang*

Main category: cs.AI

TL;DR: 提出了ProfileBench基准和Conf-Profile框架，用于解决LLM在用户画像任务中缺乏基准和标签数据的问题，通过置信度驱动的两阶段方法实现无标签可靠用户画像。


<details>
  <summary>Details</summary>
Motivation: 用户画像作为用户理解的核心技术，LLM提供了有前景的解决方案，但缺乏全面基准和高质量标签数据限制了进展。

Method: 提出Conf-Profile框架：1）利用高级LLM合成高质量标签；2）置信度加权投票和校准；3）置信度引导的无监督强化学习。

Result: 实验结果显示Conf-Profile通过两阶段训练显著提升性能，在Qwen3-8B上F1分数提高13.97。

Conclusion: 该方法有效解决了用户画像中的标签稀缺和噪声数据问题，为LLM在用户画像任务中的应用提供了可靠解决方案。

Abstract: User profiling, as a core technique for user understanding, aims to infer
structural attributes from user information. Large Language Models (LLMs)
provide a promising avenue for user profiling, yet the progress is hindered by
the lack of comprehensive benchmarks. To bridge this gap, we propose
ProfileBench, an industrial benchmark derived from a real-world video platform,
encompassing heterogeneous user data and a well-structured profiling taxonomy.
However, the profiling task remains challenging due to the difficulty of
collecting large-scale ground-truth labels, and the heterogeneous and noisy
user information can compromise the reliability of LLMs. To approach label-free
and reliable user profiling, we propose a Confidence-driven Profile reasoning
framework Conf-Profile, featuring a two-stage paradigm. We first synthesize
high-quality labels by leveraging advanced LLMs with confidence hints, followed
by confidence-weighted voting for accuracy improvement and confidence
calibration for a balanced distribution. The multiple profile results,
rationales, and confidence scores are aggregated and distilled into a
lightweight LLM. We further enhance the reasoning ability via confidence-guided
unsupervised reinforcement learning, which exploits confidence for difficulty
filtering, quasi-ground truth voting, and reward weighting. Experimental
results demonstrate that Conf-Profile delivers substantial performance through
the two-stage training, improving F1 by 13.97 on Qwen3-8B.

</details>


### [45] [Memory in Large Language Models: Mechanisms, Evaluation and Evolution](https://arxiv.org/abs/2509.18868)
*Dianxing Zhang,Wendong Li,Kani Song,Jiaye Lu,Gang Li,Liuchun Yang,Sheng Li*

Main category: cs.AI

TL;DR: 本文提出了一个统一的LLM记忆操作定义和四部分分类法（参数化、上下文、外部、程序/情景记忆），建立了记忆四元组框架，并设计了分层评估协议和DMM Gov治理系统，为LLM记忆研究提供了可复现、可比较和可治理的坐标系。


<details>
  <summary>Details</summary>
Motivation: 当前LLM记忆研究缺乏统一的操作定义和评估标准，导致跨异构设置的比较失真。需要建立系统化的框架来整合机制、评估和治理，实现可复现和可比较的研究。

Method: 提出记忆四元组（位置、持久性、写入/访问路径、可控性）和三层评估协议（仅参数化、离线检索、在线检索），构建分层评估体系，并开发DMM Gov系统协调多种技术实现可审计的更新和遗忘循环。

Result: 建立了完整的LLM记忆评估框架，包括参数化记忆评估、上下文记忆分析、外部记忆验证以及程序/情景记忆测试，并提出了四个可测试的命题。

Conclusion: 该框架为LLM记忆研究提供了系统化的方法论，支持可复现、可比较和可治理的研究实践，有助于推动LLM记忆机制的深入理解和实际应用。

Abstract: Under a unified operational definition, we define LLM memory as a persistent
state written during pretraining, finetuning, or inference that can later be
addressed and that stably influences outputs. We propose a four-part taxonomy
(parametric, contextual, external, procedural/episodic) and a memory quadruple
(location, persistence, write/access path, controllability). We link mechanism,
evaluation, and governance via the chain write -> read -> inhibit/update. To
avoid distorted comparisons across heterogeneous setups, we adopt a
three-setting protocol (parametric only, offline retrieval, online retrieval)
that decouples capability from information availability on the same data and
timeline. On this basis we build a layered evaluation: parametric (closed-book
recall, edit differential, memorization/privacy), contextual (position curves
and the mid-sequence drop), external (answer correctness vs snippet
attribution/faithfulness), and procedural/episodic (cross-session consistency
and timeline replay, E MARS+). The framework integrates temporal governance and
leakage auditing (freshness hits, outdated answers, refusal slices) and
uncertainty reporting via inter-rater agreement plus paired tests with
multiple-comparison correction. For updating and forgetting, we present DMM
Gov: coordinating DAPT/TAPT, PEFT, model editing (ROME, MEND, MEMIT, SERAC),
and RAG to form an auditable loop covering admission thresholds, rollout,
monitoring, rollback, and change audits, with specs for timeliness, conflict
handling, and long-horizon consistency. Finally, we give four testable
propositions: minimum identifiability; a minimal evaluation card; causally
constrained editing with verifiable forgetting; and when retrieval with
small-window replay outperforms ultra-long-context reading. This yields a
reproducible, comparable, and governable coordinate system for research and
deployment.

</details>


### [46] [LongCat-Flash-Thinking Technical Report](https://arxiv.org/abs/2509.18883)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chengcheng Han,Chenhui Yang,Chi Zhang,Chong Peng,Chuyu Zhang,Cong Chen,Fengcun Li,Gang Xu,Guoyuan Lin,Hao Jiang,Hao Liang,Haomin Fu,Haoxiang Ma,Hong Liu,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiahao Liu,Jiahuan Li,Jialin Liu,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiaqi Sun,Jiaqi Zhang,Jiarong Shi,Jiawei Yang,Jingang Wang,Jinrui Ding,Jun Kuang,Jun Xu,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Li Wei,Liang Shi,Lin Qiu,Lingbin Kong,Lingchuan Liu,Linsen Guo,Longfei An,Mai Xia,Meng Zhou,Mengshen Zhu,Peng Pei,Pengcheng Jia,Qi Gu,Qi Guo,Qiong Huang,Quan Chen,Quanchi Weng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shanglin Lei,Shuai Du,Shuaikang Liu,Shuang Zhou,Shuhao Hu,Siyu Xu,Songshan Gong,Tao Liang,Tianhao Hu,Wei He,Wei Shi,Wei Wang,Wei Wu,Wei Zhuo,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Xi Su,Xiangcheng Liu,Xiangyu Xi,Xiangzhou Huang,Xiao Liu,Xiaochen Jiang,Xiaowei Shi,Xiaowen Shi,Xiaoyu Li,Xin Chen,Xinyue Zhao,Xuan Huang,Xuemiao Zhang,Xuezhi Cao,Xunliang Cai,Yajie Zhang,Yang Chen,Yang Liu,Yang Liu,Yang Zheng,Yaoming Wang,Yaqi Huo,Yerui Sun,Yifan Lu,Yiyang Li,Youshao Xiao,Yuanzhe Lei,Yuchen Xie,Yueqing Sun,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunke Zhao,Yuqing Ding,Yuwei Jiang,Zhaohua Yang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhongda Su,Ziran Li,Ziwen Wang,Ziyuan Zhuang,Zongyu Wang,Zunyuan Yang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking是一个5600亿参数的开源MoE推理模型，通过精心设计的训练流程（包括长链思维数据冷启动和大规模强化学习）实现高效推理能力。


<details>
  <summary>Details</summary>
Motivation: 开发一个高效的大规模推理模型，解决复杂推理任务中的性能瓶颈，特别是在STEM、代码和智能体推理等领域。

Method: 采用冷启动训练策略增强推理潜力，然后通过领域并行训练方案将不同领域的专家模型融合为单一Pareto最优模型，使用DORA系统实现大规模RL训练加速。

Result: 在复杂推理任务上达到开源模型的最先进性能，在AIME-25上智能体推理平均token消耗减少64.5%，任务准确率不降低。

Conclusion: LongCat-Flash-Thinking展示了高效推理系统的潜力，为推理系统和智能体AI研究的进一步发展提供了重要基础。

Abstract: We present LongCat-Flash-Thinking, an efficient 560-billion-parameter
open-source Mixture-of-Experts (MoE) reasoning model. Its advanced capabilities
are cultivated through a meticulously crafted training process, beginning with
long Chain-of-Thought (CoT) data cold-start and culminating in large-scale
Reinforcement Learning (RL). We first employ a well-designed cold-start
training strategy, which significantly enhances the reasoning potential and
equips the model with specialized skills in both formal and agentic reasoning.
Then, a core innovation is our domain-parallel training scheme, which decouples
optimization across distinct domains (e.g., STEM, Code, Agentic) and
subsequently fuses the resulting expert models into a single, nearly
Pareto-optimal model. This entire process is powered by our Dynamic
ORchestration for Asynchronous rollout (DORA) system, a large-scale RL
framework that delivers a greater than threefold training speedup over
synchronous methods on tens of thousands of accelerators. As a result,
LongCat-Flash-Thinking achieves state-of-the-art performance among open-source
models on a suite of complex reasoning tasks. The model exhibits exceptional
efficiency in agentic reasoning, reducing average token consumption by 64.5%
(from 19, 653 to 6, 965) on AIME-25, without degrading task accuracy. We
release LongCat-Flash-Thinking to promote further advances in reasoning systems
and agentic AI research.

</details>


### [47] [How Far are VLMs from Visual Spatial Intelligence? A Benchmark-Driven Perspective](https://arxiv.org/abs/2509.18905)
*Songsong Yu,Yuxin Chen,Hao Ju,Lianjie Jia,Fuxi Zhang,Shaofei Huang,Yuhan Wu,Rundi Cui,Binghao Ran,Zaibin Zhang,Zhedong Zheng,Zhipeng Zhang,Yifan Wang,Lin Song,Lijun Wang,Yanwei Li,Ying Shan,Huchuan Lu*

Main category: cs.AI

TL;DR: 本文系统研究了视觉语言模型中的视觉空间推理能力，提出了空间智能的三个能力层次，并创建了SIBench基准测试集。实验发现当前模型在感知任务上表现良好，但在理解和规划任务上存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 视觉空间推理是人类核心认知能力，也是推进具身智能和自主系统的关键要求。尽管视觉语言模型取得了进展，但由于三维空间表示和推理的复杂性，实现人类水平的视觉空间推理仍然极具挑战。

Method: 对现有方法进行系统回顾，涵盖输入模态、模型架构、训练策略和推理机制。将空间智能分为三个能力层次：基本感知、空间理解、空间规划，并构建SIBench基准测试集，包含近20个开源数据集和23个任务设置。

Result: 实验表明，最先进的视觉语言模型在感知和推理之间存在显著差距。模型在基本感知任务上表现良好，但在理解和规划任务上持续表现不佳，特别是在数值估计、多视角推理、时间动态和空间想象方面。

Conclusion: 这些发现强调了在实现空间智能方面仍然存在的重大挑战，同时为未来研究提供了系统路线图和全面基准。该研究的相关资源可在指定网址获取。

Abstract: Visual Spatial Reasoning (VSR) is a core human cognitive ability and a
critical requirement for advancing embodied intelligence and autonomous
systems. Despite recent progress in Vision-Language Models (VLMs), achieving
human-level VSR remains highly challenging due to the complexity of
representing and reasoning over three-dimensional space. In this paper, we
present a systematic investigation of VSR in VLMs, encompassing a review of
existing methodologies across input modalities, model architectures, training
strategies, and reasoning mechanisms. Furthermore, we categorize spatial
intelligence into three levels of capability, ie, basic perception, spatial
understanding, spatial planning, and curate SIBench, a spatial intelligence
benchmark encompassing nearly 20 open-source datasets across 23 task settings.
Experiments with state-of-the-art VLMs reveal a pronounced gap between
perception and reasoning, as models show competence in basic perceptual tasks
but consistently underperform in understanding and planning tasks, particularly
in numerical estimation, multi-view reasoning, temporal dynamics, and spatial
imagination. These findings underscore the substantial challenges that remain
in achieving spatial intelligence, while providing both a systematic roadmap
and a comprehensive benchmark to drive future research in the field. The
related resources of this study are accessible at
https://sibench.github.io/Awesome-Visual-Spatial-Reasoning/.

</details>


### [48] [Data Efficient Adaptation in Large Language Models via Continuous Low-Rank Fine-Tuning](https://arxiv.org/abs/2509.18942)
*Xiao Han,Zimo Zhao,Wanyu Wang,Maolin Wang,Zitao Liu,Yi Chang,Xiangyu Zhao*

Main category: cs.AI

TL;DR: 本文提出DEAL框架，通过将低秩适配（LoRA）与连续微调策略相结合，解决传统微调方法中的灾难性遗忘和数据效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 传统微调方法存在灾难性遗忘和次优数据效率的问题，限制了LLMs在实际应用中的适用性。

Method: DEAL框架整合了LoRA和连续微调策略，包含知识保留和自适应参数更新模块，在保护隐私的设置下保持效率。

Result: 在15个不同数据集上的实验表明，DEAL在任务准确性和资源效率方面均优于基线方法。

Conclusion: DEAL框架通过提升任务性能和资源效率，展示了在LLMs中推进持续适应的潜力。

Abstract: Recent advancements in Large Language Models (LLMs) have emphasized the
critical role of fine-tuning (FT) techniques in adapting LLMs to specific
tasks, especially when retraining from scratch is computationally infeasible.
Fine-tuning enables LLMs to leverage task- or domain-specific data, producing
models that more effectively meet the requirements of targeted applications.
However, con- ventional FT approaches often suffer from catastrophic forgetting
and suboptimal data efficiency, limiting their real-world applicability. To
address these challenges, this paper proposes DEAL, a novel framework that
integrates Low-Rank Adapta- tion (LoRA) with a continuous fine-tuning strategy.
By incorporating knowledge retention and adaptive parameter update modules, the
framework mitigates the lim- itations of existing FT methods while maintaining
efficiency in privacy-preserving settings. Experiments on 15 diverse datasets
show that DEAL consistently outper- forms baseline methods, yielding
substantial gains in task accuracy and resource efficiency. These findings
demonstrate the potential of our approach to advance continual adaptation in
LLMs by enhancing task performance while improving resource efficiency.

</details>


### [49] [LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions](https://arxiv.org/abs/2509.18970)
*Xixun Lin,Yucheng Ning,Jingwen Zhang,Yan Dong,Yilong Liu,Yongxuan Wu,Xiaohua Qi,Nan Sun,Yanmin Shang,Pengfei Cao,Lixin Zou,Xu Chen,Chuan Zhou,Jia Wu,Shirui Pan,Bin Wang,Yanan Cao,Kai Chen,Songlin Hu,Li Guo*

Main category: cs.AI

TL;DR: 本文是关于LLM智能代理幻觉问题的首个全面综述，分析了代理工作流程中不同阶段的幻觉类型、18种触发原因，并总结了缓解和检测方法。


<details>
  <summary>Details</summary>
Motivation: 随着LLM智能代理在现实应用中的广泛部署，其幻觉问题可能导致错误任务执行并影响系统可靠性，需要系统性地理解和解决这一关键挑战。

Method: 通过仔细分析代理的完整工作流程，提出了新的分类法识别不同阶段的幻觉类型，深入研究了18种触发原因，并综述了大量现有研究的缓解和检测方法。

Result: 提出了首个全面的LLM代理幻觉综述，建立了系统的分类框架，识别了多种幻觉类型和触发机制，为后续研究提供了理论基础。

Conclusion: 该综述旨在激发更多解决LLM代理幻觉问题的研究努力，最终促进开发更稳健可靠的代理系统。

Abstract: Driven by the rapid advancements of Large Language Models (LLMs), LLM-based
agents have emerged as powerful intelligent systems capable of human-like
cognition, reasoning, and interaction. These agents are increasingly being
deployed across diverse real-world applications, including student education,
scientific research, and financial analysis. However, despite their remarkable
potential, LLM-based agents remain vulnerable to hallucination issues, which
can result in erroneous task execution and undermine the reliability of the
overall system design. Addressing this critical challenge requires a deep
understanding and a systematic consolidation of recent advances on LLM-based
agents. To this end, we present the first comprehensive survey of
hallucinations in LLM-based agents. By carefully analyzing the complete
workflow of agents, we propose a new taxonomy that identifies different types
of agent hallucinations occurring at different stages. Furthermore, we conduct
an in-depth examination of eighteen triggering causes underlying the emergence
of agent hallucinations. Through a detailed review of a large number of
existing studies, we summarize approaches for hallucination mitigation and
detection, and highlight promising directions for future research. We hope this
survey will inspire further efforts toward addressing hallucinations in
LLM-based agents, ultimately contributing to the development of more robust and
reliable agent systems.

</details>


### [50] [From latent factors to language: a user study on LLM-generated explanations for an inherently interpretable matrix-based recommender system](https://arxiv.org/abs/2509.18980)
*Maxime Manderlier,Fabian Lecron,Olivier Vu Thanh,Nicolas Gillis*

Main category: cs.AI

TL;DR: 研究探索LLMs能否从数学可解释的推荐模型生成有效的用户导向解释，通过用户研究评估不同解释策略的质量。


<details>
  <summary>Details</summary>
Motivation: 现有可解释AI研究过度依赖自动评估指标，未能真正捕捉用户需求和感知，需要采用用户中心的方法来评估解释质量。

Method: 基于约束矩阵分解的推荐模型，通过精心设计的LLM提示将模型结构转化为自然语言解释，对326名参与者进行用户研究评估五种关键维度。

Result: 所有解释类型都受到良好接受，不同策略间存在中等统计差异，用户评论提供了超越定量结果的补充见解。

Conclusion: LLMs能够从数学可解释模型生成有效的用户导向解释，用户中心评估方法为可解释AI提供了更全面的评估视角。

Abstract: We investigate whether large language models (LLMs) can generate effective,
user-facing explanations from a mathematically interpretable recommendation
model. The model is based on constrained matrix factorization, where user types
are explicitly represented and predicted item scores share the same scale as
observed ratings, making the model's internal representations and predicted
scores directly interpretable. This structure is translated into natural
language explanations using carefully designed LLM prompts. Many works in
explainable AI rely on automatic evaluation metrics, which often fail to
capture users' actual needs and perceptions. In contrast, we adopt a
user-centered approach: we conduct a study with 326 participants who assessed
the quality of the explanations across five key dimensions-transparency,
effectiveness, persuasion, trust, and satisfaction-as well as the
recommendations themselves.To evaluate how different explanation strategies are
perceived, we generate multiple explanation types from the same underlying
model, varying the input information provided to the LLM. Our analysis reveals
that all explanation types are generally well received, with moderate
statistical differences between strategies. User comments further underscore
how participants react to each type of explanation, offering complementary
insights beyond the quantitative results.

</details>


### [51] [Remaining Time Prediction in Outbound Warehouse Processes: A Case Study (Short Paper)](https://arxiv.org/abs/2509.18986)
*Erik Penther,Michael Grohs,Jana-Rebecca Rehse*

Main category: cs.AI

TL;DR: 本文比较了四种剩余时间预测方法在真实物流公司出库流程中的表现，发现深度学习模型准确率最高，但浅层方法如传统提升技术在计算资源需求上更少且能达到竞争性准确率。


<details>
  <summary>Details</summary>
Motivation: 预测性流程监控是流程挖掘的子领域，旨在预测正在进行的流程执行的未来。一个常见的预测目标是剩余时间，即流程执行完成所需的时间。

Method: 在物流公司航空业务的真实出库流程中，比较了四种不同的剩余时间预测方法。使用了包含169,523条轨迹的新颖原始事件日志。

Result: 深度学习模型实现了最高准确率，但浅层方法如传统提升技术达到了竞争性准确率，且需要显著更少的计算资源。

Conclusion: 虽然深度学习在准确率上表现最佳，但浅层方法在计算效率和实用性方面具有优势，特别是在资源受限的环境中。

Abstract: Predictive process monitoring is a sub-domain of process mining which aims to
forecast the future of ongoing process executions. One common prediction target
is the remaining time, meaning the time that will elapse until a process
execution is completed. In this paper, we compare four different remaining time
prediction approaches in a real-life outbound warehouse process of a logistics
company in the aviation business. For this process, the company provided us
with a novel and original event log with 169,523 traces, which we can make
publicly available. Unsurprisingly, we find that deep learning models achieve
the highest accuracy, but shallow methods like conventional boosting techniques
achieve competitive accuracy and require significantly fewer computational
resources.

</details>


### [52] [Landmarks, Monuments, and Beacons: Understanding Generative Calls to Action](https://arxiv.org/abs/2509.19030)
*Victoire Hervé,Henrik Warpefelt,Christoph Salge*

Main category: cs.AI

TL;DR: 该论文提出了基于玩家视角的Landmarks、Monuments和Beacons概念，用于解决程序生成内容评估中难以找到与人类体验对齐的度量标准的问题。


<details>
  <summary>Details</summary>
Motivation: 程序生成内容的算法评估难以找到与人类体验一致的度量标准，特别是对于复合人工制品。自动分解需要满足一系列属性的概念。

Method: 借鉴游戏研究和游戏AI研究，引入基于可感知性、唤起性和行动召唤的Landmarks、Monuments和Beacons概念，这些概念具有游戏通用性，可跨类型使用。

Result: 这些实体可以通过当前研究和工业中使用的技术来发现和评估，为程序生成内容的完全自动化分解和重要子组件评估开辟了道路。

Conclusion: 该方法旨在建立人文学科与技术游戏研究之间的联系，实现更好的计算程序生成内容评估，虽然重点强调混合主动程序生成和组合程序生成，但适用范围更广。

Abstract: Algorithmic evaluation of procedurally generated content struggles to find
metrics that align with human experience, particularly for composite artefacts.
Automatic decomposition as a possible solution requires concepts that meet a
range of properties. To this end, drawing on Games Studies and Game AI
research, we introduce the nested concepts of \textit{Landmarks},
\textit{Monuments}, and \textit{Beacons}. These concepts are based on the
artefact's perceivability, evocativeness, and Call to Action, all from a
player-centric perspective. These terms are generic to games and usable across
genres. We argue that these entities can be found and evaluated with techniques
currently used in both research and industry, opening a path towards a fully
automated decomposition of PCG, and evaluation of the salient sub-components.
Although the work presented here emphasises mixed-initiative PCG and
compositional PCG, we believe it applies beyond those domains. With this
approach, we intend to create a connection between humanities and technical
game research and allow for better computational PCG evaluation

</details>


### [53] [Towards Causal Representation Learning with Observable Sources as Auxiliaries](https://arxiv.org/abs/2509.19058)
*Kwonho Kim,Heejeong Nam,Inwoo Hwang,Sanghack Lee*

Main category: cs.AI

TL;DR: 本文提出了一个使用可观测源作为辅助变量的因果表示学习框架，能够在已知潜因果图的情况下识别潜变量，并通过实验验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有因果表示学习框架通常将辅助变量限制在混合函数外部，但在某些情况下，系统驱动的潜因子可以从数据中观测或提取，可能有助于识别。

Method: 引入可观测源作为辅助变量的框架，使用保体积编码器识别潜变量，并提供变量选择方案来选择最大化潜因子可恢复性的辅助变量。

Result: 实验证明该框架在合成图和图像数据上有效，能够识别整个潜变量到子空间变换和排列的程度。

Conclusion: 该框架扩展了当前方法的边界，为因果表示学习提供了新的视角和工具。

Abstract: Causal representation learning seeks to recover latent factors that generate
observational data through a mixing function. Needing assumptions on latent
structures or relationships to achieve identifiability in general, prior works
often build upon conditional independence given known auxiliary variables.
However, prior frameworks limit the scope of auxiliary variables to be external
to the mixing function. Yet, in some cases, system-driving latent factors can
be easily observed or extracted from data, possibly facilitating
identification. In this paper, we introduce a framework of observable sources
being auxiliaries, serving as effective conditioning variables. Our main
results show that one can identify entire latent variables up to subspace-wise
transformations and permutations using volume-preserving encoders. Moreover,
when multiple known auxiliary variables are available, we offer a
variable-selection scheme to choose those that maximize recoverability of the
latent factors given knowledge of the latent causal graph. Finally, we
demonstrate the effectiveness of our framework through experiments on synthetic
graph and image data, thereby extending the boundaries of current approaches.

</details>


### [54] [Code Driven Planning with Domain-Adaptive Critic](https://arxiv.org/abs/2509.19077)
*Zikang Tian,Shaohui Peng,Du Huang,Jiaming Guo,Ruizhi Chen,Rui Zhang,Xishan Zhang,Yuxuan Guo,Zidong Du,Qi Guo,Ling Li,Yewen Pu,Xing Hu,Yunji Chen*

Main category: cs.AI

TL;DR: CoPiC提出了一种基于代码驱动规划和领域自适应评估器的LLM任务规划方法，通过生成多样化高级规划程序并利用训练好的评估器选择最优方案，显著减少LLM查询次数并提升长期奖励对齐。


<details>
  <summary>Details</summary>
Motivation: 现有LLM任务规划方法依赖频繁查询进行迭代优化，导致高查询成本且难以对齐长期奖励。需要一种既能减少查询次数又能优化长期规划效果的方法。

Method: CoPiC使用LLM生成多样化高级规划程序，这些程序迭代产生和优化候选计划。通过训练领域自适应评估器来评估候选计划并选择最符合长期奖励的方案执行。

Result: 在ALFWorld、NetHack和StarCraft II Unit Building三个环境中，CoPiC相比AdaPlanner和Reflexion基线，平均成功率提升23.33%，查询成本降低91.27%。

Conclusion: CoPiC通过代码驱动规划和领域自适应评估器的结合，有效解决了LLM任务规划中的查询成本高和长期奖励对齐问题，在多个复杂环境中表现出优越性能。

Abstract: Large Language Models (LLMs) have been widely adopted as task planners for AI
agents in sequential decision-making problems, leveraging their extensive world
knowledge. However, the gap between their general knowledge and
environment-specific requirements often leads to inaccurate plans. To address
this, existing approaches rely on frequent LLM queries to iteratively refine
plans based on immediate environmental feedback, which incurs substantial query
costs. However, this refinement is typically guided by short-term environmental
feedback, limiting LLMs from developing plans aligned with long-term rewards.
We propose Code Driven Planning with Domain-Adaptive Critic (CoPiC). Instead of
relying on frequent queries, CoPiC employs LLMs to generate a diverse set of
high-level planning programs, which iteratively produce and refine candidate
plans. A trained domain-adaptive critic then evaluates these candidates and
selects the one most aligned with long-term rewards for execution. Using
high-level planning programs as planner and domain-adaptive critic as
estimator, CoPiC improves planning while significantly reducing query costs.
Results in ALFWorld, NetHack, and StarCraft II Unit Building show that CoPiC
outperforms advanced LLM-based baselines, AdaPlanner and Reflexion, achieving
an average (1) 23.33% improvement in success rate and (2) 91.27% reduction in
query costs.

</details>


### [55] [AgentInit: Initializing LLM-based Multi-Agent Systems via Diversity and Expertise Orchestration for Effective and Efficient Collaboration](https://arxiv.org/abs/2509.19236)
*Chunhao Tian,Yutong Wang,Xuebo Liu,Zhexuan Wang,Liang Ding,Miao Zhang,Min Zhang*

Main category: cs.AI

TL;DR: AgentInit是一种多智能体系统初始化方法，通过优化智能体团队结构来提升系统性能，结合自然语言到格式机制和帕累托原则的平衡团队选择策略。


<details>
  <summary>Details</summary>
Motivation: 现有MAS初始化方法未能充分考虑生成智能体在后续阶段的协作需求，需要更好的团队组合原则来提升系统效率和效果。

Method: AgentInit包含多轮智能体交互和反思，采用自然语言到格式机制确保一致性，并使用帕累托原则进行平衡团队选择，同时考虑团队多样性和任务相关性。

Result: 实验表明AgentInit在各种框架和任务中均优于现有初始化方法和预定义策略，性能提升分别达1.2和1.6倍，同时显著减少token消耗。

Conclusion: AgentInit具有良好的可迁移性和关键组件的有效性，证明其作为可靠MAS初始化方法的能力和适应性。

Abstract: Proper initialization is crucial for any system, particularly in multi-agent
systems (MAS), where it plays a pivotal role in determining both the system's
efficiency and effectiveness. However, existing MAS initialization methods do
not fully account for the collaborative needs of the generated agents in
subsequent stages. Inspired by the principles of effective team composition, we
propose AgentInit, which aims to optimize the structure of agent teams.
Specifically, in addition to multi-round interactions and reflections between
agents during agent generation, AgentInit incorporates a Natural Language to
Format mechanism to ensure consistency and standardization. Balanced team
selection strategies using Pareto principles are subsequently applied to
jointly consider agent team diversity and task relevance to promote effective
and efficient collaboration and enhance overall system performance. Experiments
show that AgentInit consistently outperforms state-of-the-art initialization
methods and pre-defined strategies across various frameworks and tasks,
achieving an overall performance improvement of up to 1.2 and 1.6,
respectively, while also significantly reducing token consumption. Further
analysis confirms its strong transferability to similar tasks and verifies the
effectiveness of its key components, demonstrating its capability and
adaptability as a reliable MAS initialization method. Source code and models
are available at https://github.com/1737423697/AgentInit.

</details>


### [56] [Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World](https://arxiv.org/abs/2509.19265)
*Saeed Almheiri,Rania Hossam,Mena Attia,Chenxi Wang,Preslav Nakov,Timothy Baldwin,Fajri Koto*

Main category: cs.AI

TL;DR: 本文研究了LLMs在阿拉伯世界的跨文化常识推理迁移，发现仅需12个特定文化示例就能平均提升10%性能，且来自印尼和美国的跨文化演示也能达到或超越文化内对齐效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在西方中心偏见，限制了其在多元文化背景下的有效性。虽然已有研究探索文化对齐，但跨文化迁移潜力（利用一种文化的对齐来提升其他文化性能）仍未被充分探索。

Method: 使用涵盖13个阿拉伯国家的文化基础常识推理数据集，评估轻量级对齐方法（上下文学习、演示强化DITTO）以及基线方法（监督微调、直接偏好优化）。

Result: 仅需12个特定文化示例就能在阿拉伯国家间平均提升10%性能；来自印尼和美国的跨文化演示在MCQ推理中能匹配或超越文化内对齐效果。

Conclusion: 高效的跨文化对齐是可行的，为将LLMs适配到低资源文化环境提供了有前景的方法。

Abstract: Large language models (LLMs) often reflect Western-centric biases, limiting
their effectiveness in diverse cultural contexts. Although some work has
explored cultural alignment, the potential for cross-cultural transfer, using
alignment in one culture to improve performance in others, remains
underexplored. This paper investigates cross-cultural transfer of commonsense
reasoning in the Arab world, where linguistic and historical similarities
coexist with local cultural differences. Using a culturally grounded
commonsense reasoning dataset covering 13 Arab countries, we evaluate
lightweight alignment methods such as in-context learning and
demonstration-based reinforcement (DITTO), alongside baselines like supervised
fine-tuning and direct preference optimization. Our results show that merely 12
culture-specific examples from one country can improve performance in others by
10\% on average, within multilingual models. In addition, we demonstrate that
out-of-culture demonstrations from Indonesia and US contexts can match or
surpass in-culture alignment for MCQ reasoning, highlighting cultural
commonsense transferability beyond the Arab world. These findings demonstrate
that efficient cross-cultural alignment is possible and offer a promising
approach to adapt LLMs to low-resource cultural settings.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [57] [Functional Information Decomposition: A First-Principles Approach to Analyzing Functional Relationships](https://arxiv.org/abs/2509.18522)
*Clifford Bohm,Vincent R. Ragusa,Arend Hintze,Christoph Adami*

Main category: cs.IT

TL;DR: 本文提出了功能信息分解（FID）方法，用于解决多变量系统中信息分解的挑战，通过分析功能关系而非统计相关性来量化独立和协同贡献。


<details>
  <summary>Details</summary>
Motivation: 信息理论在神经科学、遗传学、物理学和机器学习等领域有广泛应用，但通常仅限于两个变量之间的互信息。扩展信息理论到多变量系统面临的核心挑战是分解问题：如何将多个变量共同提供的信息分解为可分配给单个变量或其相互作用的独立贡献。

Method: 引入功能信息分解（FID）方法，该方法与先前方法的不同之处在于操作于完整的功能关系而非统计相关性，从而能够精确量化独立和协同贡献。

Result: FID方法能够清晰分解多变量与目标之间的互信息，识别出各个变量及其相互作用的独立信息贡献。

Conclusion: 功能信息分解为多变量信息分析提供了新的工具，有望在复杂系统研究中发挥重要作用。

Abstract: Information theory, originating from Shannon's work on communication systems,
has become a fundamental tool across neuroscience, genetics, physics, and
machine learning. However, the application of information theory is often
limited to the simplest case: mutual information between two variables. A
central challenge in extending information theory to multivariate systems is
decomposition: understanding how the information that multiple variables
collectively provide about a target can be broken down into the distinct
contributions that are assignable to individual variables or their
interactions. To restate the problem clearly, what is sought after is a
decomposition of the mutual information between a set of inputs (or parts) and
an output (or whole). In this work, we introduce Functional Information
Decomposition (FID) a new approach to information decomposition that differs
from prior methods by operating on complete functional relationships rather
than statistical correlations, enabling precise quantification of independent
and synergistic contributions.

</details>


### [58] [Hybrid Neural/Traditional OFDM Receiver with Learnable Decider](https://arxiv.org/abs/2509.18574)
*Mohanad Obeed,Ming Jian*

Main category: cs.IT

TL;DR: 提出一种混合接收器架构，结合传统和神经网络接收器的优势，通过判别器网络动态选择最优接收器，解决DL接收器在无线OFDM系统中的泛化问题和信道波动跟踪难题。


<details>
  <summary>Details</summary>
Motivation: 深度学习接收器在无线OFDM系统中性能优越，但存在对未见信道条件泛化能力差和难以有效跟踪快速信道波动的挑战。

Method: 设计混合接收器架构，包含一个判别器神经网络，根据接收到的OFDM块特征动态选择传统或DL接收器。判别器使用标记的导频信号训练，这些信号编码了两个接收器的比较性能。

Result: 通过在训练中包含异常信道场景，所提出的混合接收器实现了稳健的性能，有效克服了独立DL方法的泛化问题。

Conclusion: 混合接收器架构成功整合了传统和DL接收器的优势，通过动态选择机制提升了系统在复杂信道环境下的鲁棒性和适应性。

Abstract: Deep learning (DL) methods have emerged as promising solutions for enhancing
receiver performance in wireless orthogonal frequency-division multiplexing
(OFDM) systems, offering significant improvements over traditional estimation
and detection techniques. However, DL-based receivers often face challenges
such as poor generalization to unseen channel conditions and difficulty in
effectively tracking rapid channel fluctuations. To address these limitations,
this paper proposes a hybrid receiver architecture that integrates the
strengths of both traditional and neural receivers. The core innovation is a
discriminator neural network trained to dynamically select the optimal receiver
whether it is the traditional or DL-based receiver according on the received
OFDM block characteristics. This discriminator is trained using labeled pilot
signals that encode the comparative performance of both receivers. By including
anomalous channel scenarios in training, the proposed hybrid receiver achieves
robust performance, effectively overcoming the generalization issues inherent
in standalone DL approaches.

</details>


### [59] [Ruled surfaces over finite fields, and some codes over them](https://arxiv.org/abs/2509.18698)
*Régis Blache,Emmanuel Hallouin*

Main category: cs.IT

TL;DR: 本文研究有限域上的直纹曲面及其不变量，并构建了渐近性能优于对应乘积码的评估码族。


<details>
  <summary>Details</summary>
Motivation: 研究有限域上直纹曲面的几何性质，并利用这些曲面构造具有良好渐近性能的编码方案。

Method: 第一部分引入直纹曲面的不变量并描述具体构造；第二部分在曲面上构建评估码，分析其参数并构造渐近好码族。

Result: 证明了所构造的评估码具有比对应乘积码更优的渐近参数，并研究了这些码的局部性质。

Conclusion: 有限域上的直纹曲面为构造高性能编码提供了有效的几何框架，所获得的渐近结果优于传统乘积码。

Abstract: In the first part of this article, we consider ruled surfaces defined over a
finite field; we introduce invariants for them, and describe some explicit
contructions that illustrate possible behaviour of these invariants. In the
second part, we consider evaluation codes on some such surfaces; we first
estimate their parameters, then we construct asymptotically good families of
such codes, and we show that their asymptotic parameters are better than the
ones of the corresponding product codes. We also consider local properties of
these codes.

</details>


### [60] [New constructions of cyclic constant-dimension subspace codes based on Sidon spaces and subspace polynomials](https://arxiv.org/abs/2509.18704)
*Gang Wang,Ming Xu,You Gao*

Main category: cs.IT

TL;DR: 本文提出了两种新的Sidon空间构造方法，通过巧妙添加参数和灵活调整参数数量，构建了具有更大尺寸的循环常数维码(CDC)，在特定参数下达到了近似球填充界的一半。


<details>
  <summary>Details</summary>
Motivation: 为了改进循环常数维码的构造，提高码的尺寸并接近理论界，特别是在n=4k的情况下，当k趋于无穷大时，使码的尺寸与球填充界的比例接近1/2。

Method: 使用两种新的Sidon空间构造方法：第一种基于参数n=(2r+1)k, r≥2；第二种基于参数n=2rk, r≥2。同时利用子空间多项式构造了最小距离≥2k-2s的循环CDC。

Result: 构造出的循环CDC尺寸大于已知最佳结果，在n=4k情况下，当k→∞时，码尺寸与球填充界的比例约为1/2。新构造方法在特定参数下提供了比基于三项式构造更大的码尺寸或更多可接受的N值。

Conclusion: 新提出的Sidon空间构造方法有效改进了循环常数维码的性能，特别是在尺寸方面取得了显著提升，为相关编码理论问题提供了更好的解决方案。

Abstract: In this paper, two new constructions of Sidon spaces are given by tactfully
adding new parameters and flexibly varying the number of parameters. Under the
parameters $ n= (2r+1)k, r \ge2 $ and $p_0=\max \{i\in \mathbb{N}^+: \lfloor
\frac{r}{i}\rfloor>\lfloor \frac{r}{i+1} \rfloor \}$, the first construction
produces a cyclic CDC in $\mathcal{G}_q(n, k)$ with minimum distance $2k-2$ and
size $\frac{\left((r+\sum\limits_{i=2}^{p_0}(\lfloor \frac{r}{i}\rfloor-\lfloor
\frac{r}{i+1} \rfloor))(q^k-1)(q-1)+r\right)(q^k-1)^{r-1}(q^n-1)}{q-1}$. Given
parameters $n=2rk,r\ge 2$ and if $r=2$, $p_0=1$, otherwise, $p_0=\max\{ i\in
\mathbb{N}^+: \lceil\frac{r}{i}\rceil-1>\lfloor \frac{r}{i+1} \rfloor \}$, a
cyclic CDC in $\mathcal{G}_q(n, k)$ with minimum distance $2k-2$ and size
$\frac{\left((r-1+\sum\limits_{i=2}^{p_0}(\lceil \frac{r}{i}\rceil-\lfloor
\frac{r}{i+1} \rfloor-1))(q^k-1)(q-1)+r-1\right)(q^k-1)^{r-2}\lfloor
\frac{q^k-2}{2}\rfloor(q^n-1)}{q-1}$ is produced by the second construction.
The sizes of our cyclic CDCs are larger than the best known results. In
particular, in the case of $n=4k$, when $k$ goes to infinity, the ratio between
the size of our cyclic CDC and the Sphere-packing bound (Johnson bound) is
approximately equal to $\frac{1}{2}$. Moreover, for a prime power $q$ and
positive integers $k,s$ with $1\le s< k-1$, a cyclic CDC in $\mathcal{G}_q(N,
k)$ of size $e\frac{q^N-1}{q-1}$ and minimum distance $\ge 2k-2s$ is provided
by subspace polynomials, where $N,e$ are positive integers. Our construction
generalizes previous results and, under certain parameters, provides cyclic
CDCs with larger sizes or more admissible values of $ N $ than constructions
based on trinomials.

</details>


### [61] [A Convex Demixing Approach for Hybrid-Field Channel Estimation of XL-MIMO Systems via Atomic Norm Minimization](https://arxiv.org/abs/2509.18752)
*Dehui Yang,Feng Xi,Yanxian Zhu*

Main category: cs.IT

TL;DR: 本文提出了一种基于原子范数最小化框架的凸混合方法，用于6G无线通信中XL-MIMO系统的混合场信道估计。该方法通过最小化两个原子范数的加权和来促进远场和近场分量在连续参数域中的稀疏性，并将其转化为可计算的半定规划问题。


<details>
  <summary>Details</summary>
Motivation: 在6G无线通信的XL-MIMO系统中，信道估计是关键任务。混合场信道模型能有效表征实际XL-MIMO系统中的远场和近场散射分量混合情况，需要开发有效的估计方法。

Method: 提出基于原子范数最小化框架的凸混合方法，通过最小化远场和近场分量的加权原子范数和来促进连续参数域中的稀疏性，并将该问题转化为可计算的半定规划问题。

Result: 数值实验表明，该方法在模拟数据上的性能优于现有的混合场信道估计方法。

Conclusion: 所提出的凸混合方法在原子范数最小化框架下有效解决了XL-MIMO系统的混合场信道估计问题，具有优越的性能和计算可行性。

Abstract: Channel estimation is a critical task in extremely large-scale multiple-input
multiple-output (XL-MIMO) systems for 6G wireless communications. A
hybrid-field channel model effectively characterizes the mixed far-field and
near-field scattering components in practical XL-MIMO systems. In this paper,
we propose a convex demixing approach for hybrid-field channel estimation
within the atomic norm minimization (ANM) framework. By promoting sparsity of
the far-field and near-field components directly in the continuous parameter
domain, a demixing scheme that minimizes a weighted sum of two atomic norms is
proposed. We show that the resulting ANM is equivalent to a computationally
feasible semi-definite programming (SDP). Numerical experiments on simulated
data demonstrate that our method outperforms existing approaches for
hybrid-field channel estimation.

</details>


### [62] [A Two-Dimensional Super-Resolution Method for Reconfigurable Intelligent Surface-Assisted Near-Field Localization](https://arxiv.org/abs/2509.18774)
*Feng Xi,Dehui Yang*

Main category: cs.IT

TL;DR: 本文提出了一种基于Fresnel近场近似的RIS辅助3D定位方法，通过将球面波模型分解为二维远场导向向量和距离相关二次相位啁啾的乘积，在低维子空间建模下将3D定位问题转化为2D超分辨率框架下的原子范数最小化问题。


<details>
  <summary>Details</summary>
Motivation: RIS辅助定位在辐射近场区域需要使用球面波模型，这种模型会耦合角度和距离信息，使得精确的3D定位变得复杂。需要开发能够有效解耦角度和距离参数的高精度定位方法。

Method: 采用Fresnel近似将RIS响应表示为二维远场导向向量与距离相关二次相位啁啾的逐元素乘积。通过低维子空间建模，将方位角、仰角和距离的联合恢复问题重新表述为2D原子范数最小化问题，并通过半定规划求解。

Result: 仿真结果表明，该方法能够实现精确的3D定位，相比子空间和压缩感知方法具有更强的鲁棒性。

Conclusion: 所提出的2D-ANM框架能够有效解决近场球面波模型下的3D定位问题，实现了无网格的角度估计和高精度的距离恢复。

Abstract: Reconfigurable intelligent surface (RIS)-aided localization in the radiating
near-field requires range-aware spherical-wave models, which inherently couple
angles and ranges and thus complicate accurate 3D positioning. Using the
Fresnel approximation, we show that the RIS response can be expressed as the
element-wise product of a 2D far-field steering vector and a range-dependent
quadratic-phase chirp. By modeling these chirp components within a
low-dimensional subspace, we reformulate the joint recovery of azimuth,
elevation, and range under a 2D super-resolution framework, resulting in a 2D
atomic norm minimization (2D-ANM) problem. Solving this via semi-definite
programming (SDP) yields gridless azimuth-elevation estimation and
high-accuracy range recovery. Simulations demonstrate accurate 3D localization
and enhanced robustness of the proposed scheme, compared with subspace and
compressive sensing methods.

</details>


### [63] [From Fixed to Fluid: Unlocking the New Potential with Fluid RIS (FRIS)](https://arxiv.org/abs/2509.18899)
*Han Xiao,Xiaoyan Hu,Kai-Kit Wong,Xusheng Zhu,Hanjiang Hong,Farshad Rostami Ghadi,Hao Xu,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 本文提出了一种新型可重构智能表面系统——流体RIS（FRIS），通过引入流体天线系统的概念，使RIS元件位置或辐射模式具有动态可重构性，从而增强波束成形灵活性和环境适应性。


<details>
  <summary>Details</summary>
Motivation: 当前RIS技术由于固定的几何结构和元件模式，其潜力只能部分发挥。为了克服这一限制，受流体天线系统概念的启发，开发了具有动态可重构特性的FRIS系统。

Method: FRIS允许元件位置或辐射模式表现出"流体"特性，即动态可重构性，以适应无线环境。该系统通过改变元件布局或辐射特性来实现更灵活的电磁信号操控。

Result: 本文对FRIS进行了全面概述，包括其分类、基本机制、优势、潜在应用场景，并通过两个案例研究展示了其潜力。

Conclusion: FRIS技术仍处于起步阶段，本文强调了该领域面临的主要开放挑战和未来研究方向，为后续研究提供了重要参考。

Abstract: Owing to its flexible and intelligent electromagnetic signal manipulation,
the technology of reconfigurable intelligent surfaces (RISs) has attracted
widespread attention. However, the potential of current RISs can only be partly
unlocked due to their fixed geometry and element patterns. Motivated by the
concept of the fluid antenna system (FAS), a novel RIS system, termed fluid RIS
(FRIS), has been developed. Unlike traditional RISs, FRIS allows the element
positions or radiation patterns to exhibit ``fluid" properties, i.e., dynamic
reconfigurability, to adapt to the wireless environment, offering enhanced
beamforming flexibility and environmental adaptability. Given that research on
FRIS is still in its infancy, this paper provides a comprehensive overview of
its current developments and future prospects. Specifically, the key features
of FRIS are first presented, including its classification, fundamental
mechanisms, and advantages. Next, potential application scenarios of FRIS are
analyzed and discussed, followed by two illustrative case studies demonstrating
its potential. Finally, the main open challenges and future research directions
related to FRIS are highlighted.

</details>


### [64] [1-bit RIS-aided Index Modulation with Quantum Annealing](https://arxiv.org/abs/2509.18932)
*Ioannis Krikidis,Constantinos Psomas,Gan Zheng*

Main category: cs.IT

TL;DR: 提出了一种基于索引调制的新型可重构智能表面通信方案，通过1位RIS相位分辨率实现额外信息传输，并利用量子退火设备解决组合优化问题


<details>
  <summary>Details</summary>
Motivation: 传统RIS辅助通信中，1位相位分辨率限制了性能。本文旨在通过索引调制技术嵌入额外信息比特，提升系统容量

Method: 将额外信息嵌入二进制RIS相位向量中，通过最大化接收端信噪比来选择IM向量。采用惩罚方法和增广拉格朗日优化技术解决带约束的二次二进制优化问题，并在D-WAVE量子退火设备上实现

Result: 实验结果表明D-WAVE启发式算法能有效解决组合优化问题，理论分析提供了平均容量界限，所提设计优于传统方案

Conclusion: 提出的索引调制方案在1位RIS相位分辨率下显著提升了通信性能，量子计算为解决复杂优化问题提供了有效途径

Abstract: In this paper, we investigate a new index modulation (IM) scheme for
reconfigurable intelligent surface (RIS)-assisted communications with 1-bit RIS
phase resolution. In addition to the traditional modulated symbols, extra bits
of information are embedded in the binary RIS phase vector by indexing the
cardinality of the positive phases shifts. To maximize capacity, the IM-based
RIS vector is selected so as to maximize the signal-to-noise ratio at the
receiver. The proposed IM design requires the solution of a quadratic binary
optimization problem with an equality constraint at the transmitter as well as
a quadratic unconstrained binary optimization (QUBO) problem at the receiver.
Since commercial solvers cannot directly handle constraints, a penalty method
that embeds the equality constraint in the objective function is investigated.
To overcome the empirical tuning of the penalty parameter, an iterative
Augmented Lagrangian optimization technique is also investigated where a QUBO
problem is solved at each iteration. The proposed design and associated
mathematical framework are tested in a real-world quantum annealing device
provided by D-WAVE. Rigorous experimental results demonstrate that the D-WAVE
heuristic efficiently solves the considered combinatorial problems.
Furthermore, theoretical bounds on the average capacity are provided. Both
experimental and theoretical results show that the proposed design outperforms
conventional counterparts.

</details>


### [65] [Optimum Spectrum Extension for PAPR Reduction of DFT-s-OFDM](https://arxiv.org/abs/2509.19064)
*Renaud-Alexandre Pitaval,Fredrik Berggren,Branislav M. Popovic*

Main category: cs.IT

TL;DR: 本文研究通过频谱扩展（SE）结合频域频谱整形（FDSS）来降低5G及后5G上行链路的峰均功率比（PAPR），优化频谱扩展大小和频移参数，发现PAPR最优和速率最优的SE大小存在差异且受FDSS窗口衰减影响。


<details>
  <summary>Details</summary>
Motivation: 蜂窝网络上行链路覆盖受限于最大UE发射功率，需要降低PAPR。虽然DFT-s-OFDM结合FDSS能显著降低PAPR，但在高速传输时PAPR仍然过高，需要进一步优化。

Method: 采用参数化FDSS窗口和子载波系数的任意循环移位，优化频移和SE大小，通过分析和仿真研究不同参数配置对PAPR和传输速率的影响。

Result: 发现存在PAPR最优和速率最优的SE大小，两者主要取决于窗口衰减但几乎与带宽成比例不变。PAPR最优SE大小对常规QAM调制阶数几乎不变，而速率最优SE大小还取决于SNR。

Conclusion: 为后5G上行链路覆盖增强提供实用指导，强调SE大小应根据用户的FDSS窗口和链路质量单独配置。

Abstract: Uplink coverage in cellular networks is constrained by the maximum UE
transmit power, making peak-to-average power ratio (PAPR) reduction essential.
While DFT-s-OFDM with frequency-domain spectral shaping (FDSS) achieves
significantly lower PAPR than OFDM, especially with pi/2-BPSK, the PAPR remains
too high for higher-rate transmission. Spectrum extension (SE) combined with
FDSS (FDSS-SE) can further reduce the PAPR for higher-order QAM. This paper
considers FDSS-SE with parametrized FDSS windows spanning a range of possible
power ripples, as well as arbitrary circular shifts of the subcarrier
coefficients. We optimize both the frequency shift and the SE size, and show
that there exists an optimal SE size for reducing the PAPR and another one for
increasing the rate. Analysis and simulations reveal that both optima largely
depend on the window attenuation but are nearly invariant in proportion to the
bandwidth. While the PAPR-optimal SE size is nearly invariant to the
constellation order of regular QAM, the rate-optimal SE size depends also on
the SNR. These insights provide practical guidelines for beyond-5G uplink
coverage enhancement, highlighting that SE size should be individually
configured according to the user's FDSS window and link quality.

</details>
