<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 4]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.IT](#cs.IT) [Total: 12]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [A Software-Defined Radio Testbed for Distributed LiDAR Point Cloud Sharing with IEEE 802.11p in V2V Networks](https://arxiv.org/abs/2509.14523)
*Mario Hernandez,Elijah Bryce,Peter Stubberud,Ebrahim Saberinia,Brendan Morris*

Main category: cs.NI

TL;DR: 基于SDR的IEEE 802.11p测试床，通过模块化代码库实现了成本效益的分布式车辆间通信，支持协作感知和分布式存储分析


<details>
  <summary>Details</summary>
Motivation: 突破网络模拟与实际部署之间的差距，为分布式车辆间通信提供一个成本效益高的实验平台

Method: 使用ADALM-Pluto SDR构建模块化代码库，支持Docker、ROS、Matlab等环境，通过分享LiDAR点云数据实现协作感知，并分析分布式存储系统的约束条件

Result: 实现了协作感知环境的构建，对分布式存储系统进行了理论分析，并提供了通道质量研究

Conclusion: 该平台成功地为V2V通信提供了一个实用的测试环境，在协作感知和分布式存储方面取得了积极进展

Abstract: We present a Software Defined Radio (SDR)-based IEEE 802.11p testbed for
distributed Vehicle-to-Vehicle (V2V) communication. The platform bridges the
gap between network simulation and deployment by providing a modular codebase
configured for cost-effective ADALM-Pluto SDRs. Any device capable of running a
Docker with ROS, executing Matlab and interface with a Pluto via USB can act as
a communication node. To demonstrate collaborative sensing, we share LiDAR
point clouds between nodes and fuse them into a collective perception
environment. We evaluated a theoretical model for leveraging decentralized
storage systems (IPFS and Filecoin), analyzing constraints such as node storage
convergence, latency, and scalability. In addition, we provide a channel
quality study.

</details>


### [2] [Chameleon: Integrated Sensing and Communication with Sub-Symbol Beam Switching in mmWave Networks](https://arxiv.org/abs/2509.14628)
*Zhihui Gao,Zhecun Liu,Tingjun Chen*

Main category: cs.NI

TL;DR: Chameleon是一个在5G毫米波网络中实现集成感知与通信(ISAC)的新框架，通过在DMRS符号期间快速切换波束成形器，在维持多用户通信的同时实现高精度感知功能


<details>
  <summary>Details</summary>
Motivation: 当前5G网络的波束成形通常只为通信或感知单独设计，缺乏同时实现高效通信和精确感知的集成解决方案

Method: 在每次解调参考信号(DMRS)符号期间增强并快速切换波束成形器，每个波束成形器在维持用户通信波束的同时向目标角度引入额外的感知波束

Result: 在28 GHz测试平台上实现多用户通信，总数据速率达0.80 Gbps，波束切换间隔仅0.24μs，0.875ms内完成31x31点2D成像，物体定位中位误差0.14米(距离)和0.24度(角度)，材料分类准确率达99.0%

Conclusion: Chameleon框架成功证明了在5G毫米波网络中同时实现高效通信和高精度感知的可行性，为下一代集成感知与通信网络提供了实用解决方案

Abstract: Next-generation cellular networks are envisioned to integrate sensing
capabilities with communication, particularly in the millimeter-wave (mmWave)
spectrum, where beamforming using large-scale antenna arrays enables
directional signal transmissions for improved spatial multiplexing. In current
5G networks, however, beamforming is typically designed either for
communication or sensing (e.g., beam training during link establishment). In
this paper, we present Chameleon, a novel framework that augments and rapidly
switches beamformers during each demodulation reference signal (DMRS) symbol to
achieve integrated sensing and communication (ISAC) in 5G mmWave networks. Each
beamformer introduces an additional sensing beam toward target angles while
maintaining the communication beams toward multiple users. We implement
Chameleon on a 28 GHz software-defined radio testbed supporting over-the-air 5G
physical downlink shared channel (PDSCH) transmissions. Extensive experiments
in open environments show that Chameleon achieves multi-user communication with
a sum data rate of up to 0.80 Gbps across two users. Simultaneously, Chameleon
employs a beamformer switching interval of only 0.24 {\mu}s, therefore
producing a 31x31-point 2D imaging within just 0.875 ms. Leveraging machine
learning, Chameleon further enables object localization with median errors of
0.14 m (distance) and 0.24{\deg} (angle), and material classification with
99.0% accuracy.

</details>


### [3] [1Q: First-Generation Wireless Systems Integrating Classical and Quantum Communication](https://arxiv.org/abs/2509.14731)
*Petar Popovski,Čedomir Stefanović,Beatriz Soret,Israel Leyva-Mayorga,Shashi Raj Pandey,René Bødker Christensen,Jakob Kaltoft Søndergaard,Kristian Skafte Jensen,Thomas Garm Pedersen,Angela Sara Cacciapuoti,Lajos Hanzo*

Main category: cs.NI

TL;DR: 1Q是首个集成经典和量子通信的无线通信框架，通过量子基站支持自由空间光链路的纠缠分发，扩展量子互联网到蜂窝无线网络


<details>
  <summary>Details</summary>
Motivation: 将量子通信扩展到无线蜂窝网络，实现经典通信与量子通信的集成，为量子密钥分发、盲量子计算和分布式量子传感等应用提供无线支持

Method: 提出量子基站(QBS)、量子小区、量子用户设备(QUE)等新组件，采用混合资源分配策略，扩展蜂窝连接管理协议以包含纠缠生成、分发和切换过程

Result: 建立了完整的1Q框架概念，识别了包括退相干时间、保真度要求、量子与经典错误概率相互作用等独特的量子约束

Conclusion: 1Q框架成功将量子互联网扩展到无线蜂窝领域，为未来集成经典和量子通信的无线网络奠定了基础

Abstract: We sketch out the concept of 1Q, the first wireless generation of integrated
classical and quantum communication. The 1Q framework features quantum base
stations (QBSs) that support entanglement distribution via free-space optical
links alongside traditional radio communications. Key new components include
quantum cells, quantum user equipment (QUEs), and hybrid resource allocation
spanning classical time-frequency and quantum entanglement domains. Several
application scenarios are discussed and illustrated through system design
requirements for quantum key distribution, blind quantum computing, and
distributed quantum sensing. A range of unique quantum constraints are
identified, including decoherence timing, fidelity requirements, and the
interplay between quantum and classical error probabilities. Protocol
adaptations extend cellular connection management to incorporate entanglement
generation, distribution, and handover procedures, expanding the Quantum
Internet to the cellular wireless.

</details>


### [4] [AI-Driven Multi-Agent Vehicular Planning for Battery Efficiency and QoS in 6G Smart Cities](https://arxiv.org/abs/2509.14877)
*Rohin Gillgallon,Giacomo Bergami,Reham Almutairi,Graham Morgan*

Main category: cs.NI

TL;DR: 扩展SimulatorOrchestrator模拟器，通过AI算法实现动态代理规划和优化，在车联网环境中降低车辆电池消耗并确保公平通信时间


<details>
  <summary>Details</summary>
Motivation: 现有车联网模拟器缺乏动态代理规划和优化功能，无法最小化车辆电池消耗同时保证公平通信时间

Method: 扩展SimulatorOrchestrator模拟器架构，集成AI算法进行交通预测和动态代理规划，引入期望区域概念

Result: 在城市数据集上的初步结果显示，车辆规划算法相比传统最短路径算法在电池和QoS性能方面有改进，期望区域的加入使更多救护车能以更少能耗到达目的地

Conclusion: AI驱动的动态代理规划和期望区域方法能有效优化车联网系统的能耗和通信性能

Abstract: While simulators exist for vehicular IoT nodes communicating with the Cloud
through Edge nodes in a fully-simulated osmotic architecture, they often lack
support for dynamic agent planning and optimisation to minimise vehicular
battery consumption while ensuring fair communication times. Addressing these
challenges requires extending current simulator architectures with AI
algorithms for both traffic prediction and dynamic agent planning. This paper
presents an extension of SimulatorOrchestrator (SO) to meet these requirements.
Preliminary results over a realistic urban dataset show that utilising
vehicular planning algorithms can lead to improved battery and QoS performance
compared with traditional shortest path algorithms. The additional inclusion of
desirability areas enabled more ambulances to be routed to their target
destinations while utilising less energy to do so, compared to traditional and
weighted algorithms without desirability considerations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [5] [Unified Crew Planning and Replanning Optimization in Multi-Line Metro Systems Considering Workforce Heterogeneity](https://arxiv.org/abs/2509.14251)
*Qihang Chen*

Main category: cs.AI

TL;DR: 基于层次时空网络模型的统一优化框架，解决多路线地铁乘务排班与紧急重排问题，通过列生成算法实现成本优化和任务完成率提升。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要集中在单路线地铁排班，缺乏多路线协调和紧急情况下的快速重新规划能力，而这对大型地铁网络的高效运营至关重要。

Method: 提出层次时空网络模型来表征统一乘务动作空间，建立计算高效的约束条件和数学模型，并发展基于列生成和最短路径调整的求解算法。

Result: 上海和北京地铁实际数据实验显示，该方法在成本减少和任务完成方面都超过传统假设算法，通过多路线协同操作特别是在故障情况下显著提高了效率。

Conclusion: 该研究强调了全局优化和多路线协调在地铁系统运营中的重要性，为智慧城市公共交通的高效可靠运行提供了有价值的见解。

Abstract: Metro crew planning is a key component of smart city development as it
directly impacts the operational efficiency and service reliability of public
transportation. With the rapid expansion of metro networks, effective
multi-line scheduling and emergency management have become essential for
large-scale seamless operations. However, current research focuses primarily on
individual metro lines,with insufficient attention on cross-line coordination
and rapid replanning during disruptions. Here, a unified optimization framework
is presented for multi-line metro crew planning and replanning with
heterogeneous workforce. Specifically, a hierarchical time-space network model
is proposed to represent the unified crew action space, and computationally
efficient constraints and formulations are derived for the crew's heterogeneous
qualifications and preferences. Solution algorithms based on column generation
and shortest path adjustment are further developed, utilizing the proposed
network model. Experiments with real data from Shanghai and Beijing Metro
demonstrate that the proposed methods outperform benchmark heuristics in both
cost reduction and task completion,and achieve notable efficiency gains by
incorporating cross-line operations, particularly for urgent tasks during
disruptions. This work highlights the role of global optimization and
cross-line coordination in multi-line metro system operations, providing
insights into the efficient and reliable functioning of public transportation
in smart cities.

</details>


### [6] [From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing](https://arxiv.org/abs/2509.14289)
*Lanxiao Huang,Daksh Dave,Ming Jin,Tyler Cody,Peter Beling*

Main category: cs.AI

TL;DR: 大语言模型在渗透测试中的效果评估，通过针对性增强模块显著提升复杂任务性能


<details>
  <summary>Details</summary>
Motivation: 评估LLM在渗透测试中的效果和可靠性，明确其在不同攻击阶段的表现

Method: 通过实验测量多种LLM基于模型的性能，分析五个核心功能能力的影响：全局上下文记忆、代理间消息传递、上下文条件调用、适应性规划、实时监控

Result: 针对性增强显著提升了模块化代理的性能，尤其在复杂、多步骤和实时渗透测试任务中

Conclusion: 针对性的功能增强能够有效提升LLM在渗透测试中的表现，尽管某些架构本身就具有部分这些特性

Abstract: Large language models (LLMs) are increasingly used to automate or augment
penetration testing, but their effectiveness and reliability across attack
phases remain unclear. We present a comprehensive evaluation of multiple
LLM-based agents, from single-agent to modular designs, across realistic
penetration testing scenarios, measuring empirical performance and recurring
failure patterns. We also isolate the impact of five core functional
capabilities via targeted augmentations: Global Context Memory (GCM),
Inter-Agent Messaging (IAM), Context-Conditioned Invocation (CCI), Adaptive
Planning (AP), and Real-Time Monitoring (RTM). These interventions support,
respectively: (i) context coherence and retention, (ii) inter-component
coordination and state management, (iii) tool use accuracy and selective
execution, (iv) multi-step strategic planning, error detection, and recovery,
and (v) real-time dynamic responsiveness. Our results show that while some
architectures natively exhibit subsets of these properties, targeted
augmentations substantially improve modular agent performance, especially in
complex, multi-step, and real-time penetration testing tasks.

</details>


### [7] [Detecting Pipeline Failures through Fine-Grained Analysis of Web Agents](https://arxiv.org/abs/2509.14382)
*Daniel Röder,Akhil Juneja,Roland Roller,Sven Schmeier*

Main category: cs.AI

TL;DR: 这篇论文提出了一种模块化评估框架，用于进行细粒度的错误分析，以改善基于大语言模型的网页自主代理系统的稳健性和通用性。


<details>
  <summary>Details</summary>
Motivation: 当前对网页自主代理的评估主要关注整体成功率，而忽视了中间错误，导致无法深入理解失败模式和进行系统改进。

Method: 提出模块化评估框架，将代理管道分解为可解释的阶段，进行详细错误分析，并使用SeeAct框架和Mind2Web数据集进行案例研究。

Result: 该方法发现了标准指标没有发现的可操作弱点，为构建更稳健和通用的网页代理提供了路径。

Conclusion: 通过模块化评估框架进行细粒度错误分析，可以更好地理解网页自主代理的失败模式，从而推动系统性改进和提升。

Abstract: Web agents powered by large language models (LLMs) can autonomously perform
complex, multistep tasks in dynamic web environments. However, current
evaluations mostly focus on the overall success while overlooking intermediate
errors. This limits insight into failure modes and hinders systematic
improvement. This work analyzes existing benchmarks and highlights the lack of
fine-grained diagnostic tools. To address this gap, we propose a modular
evaluation framework that decomposes agent pipelines into interpretable stages
for detailed error analysis. Using the SeeAct framework and the Mind2Web
dataset as a case study, we show how this approach reveals actionable
weaknesses missed by standard metrics - paving the way for more robust and
generalizable web agents.

</details>


### [8] [VCBench: Benchmarking LLMs in Venture Capital](https://arxiv.org/abs/2509.14448)
*Rick Chen,Joseph Ternasky,Afriyie Samuel Kwesi,Ben Griffin,Aaron Ontoyin Yin,Zakari Salifu,Kelvin Amoaba,Xianling Mu,Fuat Alican,Yigit Ihlamur*

Main category: cs.AI

TL;DR: VCBench是首个用于预测风险投资中创始人成功率的基准测试，包含9000个匿名创始人档案，评估显示LLM模型表现优于人类基准和顶级投资机构。


<details>
  <summary>Details</summary>
Motivation: 现有基准如SWE-bench和ARC-AGI显示共享数据集能加速AGI发展，但在风险投资领域缺乏标准化基准，该领域信号稀疏、结果不确定，即使顶级投资者表现也一般。

Method: 创建包含9000个匿名创始人档案的VCBench数据集，进行标准化处理以保留预测特征同时防止身份泄露，通过对抗性测试降低90%以上的重识别风险，评估9个最先进的LLM模型。

Result: 市场基准精度1.9%，Y Combinator比基准好1.7倍，顶级机构好2.9倍。DeepSeek-V3达到基准精度的6倍以上，GPT-4o获得最高F0.5分数，大多数模型超越人类基准。

Conclusion: VCBench作为公开演进资源，为早期风险预测领域建立了社区驱动的可重复且保护隐私的AGI评估标准，推动了风险投资预测领域的研究进展。

Abstract: Benchmarks such as SWE-bench and ARC-AGI demonstrate how shared datasets
accelerate progress toward artificial general intelligence (AGI). We introduce
VCBench, the first benchmark for predicting founder success in venture capital
(VC), a domain where signals are sparse, outcomes are uncertain, and even top
investors perform modestly. At inception, the market index achieves a precision
of 1.9%. Y Combinator outperforms the index by a factor of 1.7x, while tier-1
firms are 2.9x better. VCBench provides 9,000 anonymized founder profiles,
standardized to preserve predictive features while resisting identity leakage,
with adversarial tests showing more than 90% reduction in re-identification
risk. We evaluate nine state-of-the-art large language models (LLMs).
DeepSeek-V3 delivers over six times the baseline precision, GPT-4o achieves the
highest F0.5, and most models surpass human benchmarks. Designed as a public
and evolving resource available at vcbench.com, VCBench establishes a
community-driven standard for reproducible and privacy-preserving evaluation of
AGI in early-stage venture forecasting.

</details>


### [9] [From Mimicry to True Intelligence (TI) -- A New Paradigm for Artificial General Intelligence](https://arxiv.org/abs/2509.14474)
*Meltem Subasioglu,Nevzat Subasioglu*

Main category: cs.AI

TL;DR: 这篇论文提出了一种基于认知机制的真正智能(TI)定义，包含六个核心组件，并建立了五级AGI分类评估体系


<details>
  <summary>Details</summary>
Motivation: 解决当前AGI讨论中表现模仿与认知过程复制的根本分歧，提供有清晰研究路线图的机制基础定义

Method: 受人脑启发，提出包含体验感知融合、核心指令、动态模式创建、多专家架构、组织层和相互联结性的六大核心组件，并建立五级AGI分类评估体系

Result: 提供了首个整体性、机制基础的AGI定义，为研究社区提供了清晰可行的发展路径

Conclusion: 一旦系统实现了六个核心组件中的前五个可测量组件(达到第五级AGI)，它在功能和实践上就等同于真正智能，意识可能是集成高阶认知的涵生性质

Abstract: The debate around Artificial General Intelligence (AGI) remains open due to
two fundamentally different goals: replicating human-like performance versus
replicating human-like cognitive processes. We argue that current
performance-based definitions are inadequate because they provide no clear,
mechanism-focused roadmap for research, and they fail to properly define the
qualitative nature of genuine intelligence. Drawing inspiration from the human
brain, we propose a new paradigm that shifts the focus from external mimicry to
the development of foundational cognitive architectures. We define True
Intelligence (TI) as a system characterized by six core components: embodied
sensory fusion, core directives, dynamic schemata creation, a
highly-interconnected multi-expert architecture, an orchestration layer, and
lastly, the unmeasurable quality of Interconnectedness, which we hypothesize
results in consciousness and a subjective experience. We propose a practical,
five-level taxonomy of AGI based on the number of the first five measurable
components a system exhibits. This framework provides a clear path forward with
developmental milestones that directly address the challenge of building
genuinely intelligent systems. We contend that once a system achieves Level-5
AGI by implementing all five measurable components, the difference between it
and TI remains as a purely philosophical debate. For practical purposes - and
given theories indicate consciousness is an emergent byproduct of integrated,
higher-order cognition - we conclude that a fifth-level AGI is functionally and
practically equivalent to TI. This work synthesizes diverse insights from
analytical psychology, schema theory, metacognition, modern brain architectures
and latest works in AI to provide the first holistic, mechanism-based
definition of AGI that offers a clear and actionable path for the research
community.

</details>


### [10] [Beyond the high score: Prosocial ability profiles of multi-agent populations](https://arxiv.org/abs/2509.14485)
*Marko Tesic,Yue Zhao,Joel Z. Leibo,Rakshit S. Trivedi,Jose Hernandez-Orallo*

Main category: cs.AI

TL;DR: 采用贝叶斯测量布局方法分析熔炉测试中多段代理系统的社交能力，发现高分代理并非总是具有更强合作能力，而某些头部团队可能优化了无需合作的环境条件。


<details>
  <summary>Details</summary>
Motivation: 评估AI代理在复杂社交环境中的合作能力存在挑战，并需要更好地理解代理系统的社交能力索质。

Method: 应用贝叶斯测量布局方法来推断多段代理系统在Melting Pot测试套件中的能力索质。

Result: 能力索质不仅能预测未来表现，还显示了代理的利他能力。高分代理并非总是具有更强合作能力，而头部团队更可能在无需合作的场景中获得高分。

Conclusion: 贝叶斯测量布局提供了强大的预测能力和可操作的见解，为复杂社交环境中的AI系统评估提供了更透明和可推广的方法。

Abstract: The development and evaluation of social capabilities in AI agents require
complex environments where competitive and cooperative behaviours naturally
emerge. While game-theoretic properties can explain why certain teams or agent
populations outperform others, more abstract behaviours, such as convention
following, are harder to control in training and evaluation settings. The
Melting Pot contest is a social AI evaluation suite designed to assess the
cooperation capabilities of AI systems. In this paper, we apply a Bayesian
approach known as Measurement Layouts to infer the capability profiles of
multi-agent systems in the Melting Pot contest. We show that these capability
profiles not only predict future performance within the Melting Pot suite but
also reveal the underlying prosocial abilities of agents. Our analysis
indicates that while higher prosocial capabilities sometimes correlate with
better performance, this is not a universal trend-some lower-scoring agents
exhibit stronger cooperation abilities. Furthermore, we find that
top-performing contest submissions are more likely to achieve high scores in
scenarios where prosocial capabilities are not required. These findings,
together with reports that the contest winner used a hard-coded solution
tailored to specific environments, suggest that at least one top-performing
team may have optimised for conditions where cooperation was not necessary,
potentially exploiting limitations in the evaluation framework. We provide
recommendations for improving the annotation of cooperation demands and propose
future research directions to account for biases introduced by different
testing environments. Our results demonstrate that Measurement Layouts offer
both strong predictive accuracy and actionable insights, contributing to a more
transparent and generalisable approach to evaluating AI systems in complex
social settings.

</details>


### [11] [DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction](https://arxiv.org/abs/2509.14507)
*Jian Chen,Zhenyan Chen,Xuming Hu,Peilin Zhou,Yining Hua,Han Fang,Cissy Hing Yee Choy,Xinmei Ke,Jingfeng Luo,Zixuan Yuan*

Main category: cs.AI

TL;DR: DeKeyNLU数据集和DeKeySQL管道通过改进任务分解和关键词提取，显著提升了NL2SQL的准确性


<details>
  <summary>Details</summary>
Motivation: 解决现有NL2SQL方法中任务分解不准确和关键词提取错误的问题，这些问题是SQL生成错误的主要瓶颈

Method: 提出DeKeyNLU数据集（1500个标注QA对）和DeKeySQL RAG管道，包含三个模块：用户问题理解、实体检索和生成

Result: 在BIRD数据集上准确率从62.31%提升到69.10%，在Spider数据集上从84.2%提升到88.7%

Conclusion: DeKeyNLU数据集和DeKeySQL管道有效解决了NL2SQL中的关键挑战，显著提高了SQL生成准确性

Abstract: Natural Language to SQL (NL2SQL) provides a new model-centric paradigm that
simplifies database access for non-technical users by converting natural
language queries into SQL commands. Recent advancements, particularly those
integrating Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)
reasoning, have made significant strides in enhancing NL2SQL performance.
However, challenges such as inaccurate task decomposition and keyword
extraction by LLMs remain major bottlenecks, often leading to errors in SQL
generation. While existing datasets aim to mitigate these issues by fine-tuning
models, they struggle with over-fragmentation of tasks and lack of
domain-specific keyword annotations, limiting their effectiveness. To address
these limitations, we present DeKeyNLU, a novel dataset which contains 1,500
meticulously annotated QA pairs aimed at refining task decomposition and
enhancing keyword extraction precision for the RAG pipeline. Fine-tuned with
DeKeyNLU, we propose DeKeySQL, a RAG-based NL2SQL pipeline that employs three
distinct modules for user question understanding, entity retrieval, and
generation to improve SQL generation accuracy. We benchmarked multiple model
configurations within DeKeySQL RAG pipeline. Experimental results demonstrate
that fine-tuning with DeKeyNLU significantly improves SQL generation accuracy
on both BIRD (62.31% to 69.10%) and Spider (84.2% to 88.7%) dev datasets.

</details>


### [12] [Rationality Check! Benchmarking the Rationality of Large Language Models](https://arxiv.org/abs/2509.14546)
*Zhilun Zhou,Jing Yi Wang,Nicholas Sukiennik,Chen Gao,Fengli Xu,Yong Li,James Evans*

Main category: cs.AI

TL;DR: 提出了第一个评估大语言模型综合理性的基准测试，涵盖多个领域和模型，包含工具包和实验结果分析


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在模拟人类和AI助手方面的应用增多，需要评估它们在何种情况下像真实人类一样思考和行动，理性是评估人类行为的重要概念

Method: 开发了一个全面的基准测试框架，包括易用工具包、广泛的实验设计和对比分析，评估LLMs的理论理性和实践理性

Result: 通过实验揭示了LLMs与理想化人类理性之间的收敛和分歧点，提供了详细的实验结果和分析

Conclusion: 该基准测试可以作为LLMs开发者和用户的基础工具，帮助评估和理解LLMs的理性能力

Abstract: Large language models (LLMs), a recent advance in deep learning and machine
intelligence, have manifested astonishing capacities, now considered among the
most promising for artificial general intelligence. With human-like
capabilities, LLMs have been used to simulate humans and serve as AI assistants
across many applications. As a result, great concern has arisen about whether
and under what circumstances LLMs think and behave like real human agents.
Rationality is among the most important concepts in assessing human behavior,
both in thinking (i.e., theoretical rationality) and in taking action (i.e.,
practical rationality). In this work, we propose the first benchmark for
evaluating the omnibus rationality of LLMs, covering a wide range of domains
and LLMs. The benchmark includes an easy-to-use toolkit, extensive experimental
results, and analysis that illuminates where LLMs converge and diverge from
idealized human rationality. We believe the benchmark can serve as a
foundational tool for both developers and users of LLMs.

</details>


### [13] [(P)rior(D)yna(F)low: A Priori Dynamic Workflow Construction via Multi-Agent Collaboration](https://arxiv.org/abs/2509.14547)
*Yi Lin,Lujin Zhao,Yijie Shi*

Main category: cs.AI

TL;DR: 提出了一种先验动态框架用于自动化工作流构建，通过Q-table学习和先验决策机制，在利用历史经验的同时灵活适应不同任务特性，显著提升了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动化工作流构建方法过度依赖历史经验，导致效率和适应性受限。作者认为工作流构建应该同时考虑历史经验和任务特性，灵活响应每个任务的独特需求。

Method: 提出先验动态框架：1）使用Q-table学习优化决策空间，指导智能体决策并有效利用历史经验；2）智能体评估当前任务进度并做出先验决策，主动选择更适合的工作流结构；3）引入冷启动初始化、早停和剪枝机制提升效率。

Result: 在四个基准数据集上的实验表明，相比最先进基线方法，平均性能提升4.05%，同时将工作流构建和推理成本降低至现有方法的30.68%-48.31%。

Conclusion: 该框架通过结合历史经验学习和任务特性响应机制，实现了高效且自适应的自动化工作流构建，在性能和效率方面都取得了显著改进。

Abstract: Recent studies have shown that carefully designed workflows coordinating
large language models(LLMs) significantly enhance task-solving capabilities
compared to using a single model. While an increasing number of works focus on
autonomous workflow construction, most existing approaches rely solely on
historical experience, leading to limitations in efficiency and adaptability.
We argue that while historical experience is valuable, workflow construction
should also flexibly respond to the unique characteristics of each task. To
this end, we propose an a priori dynamic framework for automated workflow
construction. Our framework first leverages Q-table learning to optimize the
decision space, guiding agent decisions and enabling effective use of
historical experience. At the same time, agents evaluate the current task
progress and make a priori decisions regarding the next executing agent,
allowing the system to proactively select the more suitable workflow structure
for each given task. Additionally, we incorporate mechanisms such as cold-start
initialization, early stopping, and pruning to further improve system
efficiency. Experimental evaluations on four benchmark datasets demonstrate the
feasibility and effectiveness of our approach. Compared to state-of-the-art
baselines, our method achieves an average improvement of 4.05%, while reducing
workflow construction and inference costs to only 30.68%-48.31% of those
required by existing methods.

</details>


### [14] [SynBench: A Benchmark for Differentially Private Text Generation](https://arxiv.org/abs/2509.14594)
*Yidan Sun,Viktor Schlegel,Srinivasan Nandakumar,Iqra Zahid,Yuping Wu,Yulong Wu,Hao Li,Jie Zhang,Warren Del-Pinto,Goran Nenadic,Siew Kei Lam,Anil Anthony Bharath*

Main category: cs.AI

TL;DR: 这篇论文研究了在高风险领域中使用差分隐私技术生成合成文本数据的挑战，提出了评估框架、对比了各种方法的性能，并发现领域复杂性会导致性能下降，还提出了成员推断攻击方法来证明公开数据集可能会影响隐私保证。


<details>
  <summary>Details</summary>
Motivation: 高风险领域如医疗和金融中，数据共享遇到法规、机构和隐私问题的阻碍。虽然生成式AI模型在广泛任务中表现优异，但在敏感环境中采用仍遇到不可预测行为和隐私数据缺乏的挑战。现有匿名化方法对非结构化文本效果不佳，差分隐私提供了更理论化的解决方案。

Method: 论文通过三个关键贡献来解决这些问题：1）引入包含标准化效用和保真度指标的综合评估框架，涵盖9个经过精选的数据集；2）进行大规模实验研究，对比各种差分隐私文本生成方法和不同规模的大语言模型；3）开发专门针对合成文本的成员推断攻击方法。

Result: 研究发现：在差分隐私约束下生成高质量领域特定合成数据仍然是一个未解决的挑战，性能随着领域复杂性的增加而下降。同时，研究提供了首次实验证据，证明使用公开数据集（可能存在于预训练语料中）可能会使声称的隐私保证失效。

Conclusion: 这些发现强调了进行严格隐私审计的紧迫性，并指出了广泛领域与专业领域评估之间持续存在的差距。这为在隐私敏感、高风险环境中负责任地部署生成式AI提供了重要信息。

Abstract: Data-driven decision support in high-stakes domains like healthcare and
finance faces significant barriers to data sharing due to regulatory,
institutional, and privacy concerns. While recent generative AI models, such as
large language models, have shown impressive performance in open-domain tasks,
their adoption in sensitive environments remains limited by unpredictable
behaviors and insufficient privacy-preserving datasets for benchmarking.
Existing anonymization methods are often inadequate, especially for
unstructured text, as redaction and masking can still allow re-identification.
Differential Privacy (DP) offers a principled alternative, enabling the
generation of synthetic data with formal privacy assurances. In this work, we
address these challenges through three key contributions. First, we introduce a
comprehensive evaluation framework with standardized utility and fidelity
metrics, encompassing nine curated datasets that capture domain-specific
complexities such as technical jargon, long-context dependencies, and
specialized document structures. Second, we conduct a large-scale empirical
study benchmarking state-of-the-art DP text generation methods and LLMs of
varying sizes and different fine-tuning strategies, revealing that high-quality
domain-specific synthetic data generation under DP constraints remains an
unsolved challenge, with performance degrading as domain complexity increases.
Third, we develop a membership inference attack (MIA) methodology tailored for
synthetic text, providing first empirical evidence that the use of public
datasets - potentially present in pre-training corpora - can invalidate claimed
privacy guarantees. Our findings underscore the urgent need for rigorous
privacy auditing and highlight persistent gaps between open-domain and
specialist evaluations, informing responsible deployment of generative AI in
privacy-sensitive, high-stakes settings.

</details>


### [15] [AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production](https://arxiv.org/abs/2509.14647)
*NVJK Kartik,Garvit Sapra,Rishav Hada,Nikhil Pareek*

Main category: cs.AI

TL;DR: AgentCompass是首个专门用于多智能体工作流部署后监控和调试的评估框架，通过多阶段分析流程和双记忆系统实现持续学习，在真实部署和基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在多智能体工作流中的广泛应用，现有评估方法无法有效捕获错误、涌现行为和系统性故障，需要专门的监控调试工具来确保生产环境的可靠性。

Method: 框架模拟专家调试者的推理过程，采用结构化多阶段分析流程：错误识别分类、主题聚类、量化评分和策略总结，并配备情景记忆和语义记忆的双记忆系统实现持续学习。

Result: 在真实部署和TRAIL基准测试中取得最先进结果，发现了人工标注遗漏的关键问题，证明了其作为开发者中心化工具的实用性。

Conclusion: AgentCompass是一个强大的生产环境监控工具，能够可靠地监控和改进智能体系统，填补了现有评估方法的空白。

Abstract: With the growing adoption of Large Language Models (LLMs) in automating
complex, multi-agent workflows, organizations face mounting risks from errors,
emergent behaviors, and systemic failures that current evaluation methods fail
to capture. We present AgentCompass, the first evaluation framework designed
specifically for post-deployment monitoring and debugging of agentic workflows.
AgentCompass models the reasoning process of expert debuggers through a
structured, multi-stage analytical pipeline: error identification and
categorization, thematic clustering, quantitative scoring, and strategic
summarization. The framework is further enhanced with a dual memory
system-episodic and semantic-that enables continual learning across executions.
Through collaborations with design partners, we demonstrate the framework's
practical utility on real-world deployments, before establishing its efficacy
against the publicly available TRAIL benchmark. AgentCompass achieves
state-of-the-art results on key metrics, while uncovering critical issues
missed in human annotations, underscoring its role as a robust,
developer-centric tool for reliable monitoring and improvement of agentic
systems in production.

</details>


### [16] [Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld's Episode Theory](https://arxiv.org/abs/2509.14662)
*Ming Li,Nan Zhang,Chenrui Fan,Hong Jiao,Yanbin Fu,Sydney Peters,Qingshu Xu,Robert Lissitz,Tianyi Zhou*

Main category: cs.AI

TL;DR: 应用Schoenfeld的认知框架分析大型推理模型的思维过程，构建了第一个公开的细粒度机器推理分析标准数据集


<details>
  <summary>Details</summary>
Motivation: 缺乏理论基础来理解大型推理模型生成的链式思维的结构化特征

Method: 应用Schoenfeld认知感瞬理论，使用7个认知标签对数学问题模型解答进行注释分析

Result: 发现了LRM推理的特征模式，如认知状态过渡动态，并建立了公开注释语料库和详细注释指南

Conclusion: 提供了理论基础的LRM认知解释方法，为建立更可控制和透明的推理系统奠定基础

Abstract: While Large Reasoning Models (LRMs) generate extensive chain-of-thought
reasoning, we lack a principled framework for understanding how these thoughts
are structured. In this paper, we introduce a novel approach by applying
Schoenfeld's Episode Theory, a classic cognitive framework for human
mathematical problem-solving, to analyze the reasoning traces of LRMs. We
annotated thousands of sentences and paragraphs from model-generated solutions
to math problems using seven cognitive labels (e.g., Plan, Implement, Verify).
The result is the first publicly available benchmark for the fine-grained
analysis of machine reasoning, including a large annotated corpus and detailed
annotation guidebooks. Our preliminary analysis reveals distinct patterns in
LRM reasoning, such as the transition dynamics between cognitive states. This
framework provides a theoretically grounded methodology for interpreting LRM
cognition and enables future work on more controllable and transparent
reasoning systems.

</details>


### [17] [RationAnomaly: Log Anomaly Detection with Rationality via Chain-of-Thought and Reinforcement Learning](https://arxiv.org/abs/2509.14693)
*Song Xu,Yilun Liu,Minggui He,Mingchen Dai,Ziang Chen,Chunguang Zhao,Jingzhou Du,Shimin Tao,Weibin Meng,Shenglin Zhang,Yongqian Sun,Boxing Chen,Daimeng Wei*

Main category: cs.AI

TL;DR: RationAnomaly是一个结合思维链微调和强化学习的日志异常检测框架，通过专家修正数据集和多方奖励函数，显著提升检测准确性和逻辑一致性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有日志异常检测方法存在局限性：传统深度学习模型缺乏可解释性和泛化能力，而基于大语言模型的方法存在不可靠性和事实错误问题。

Method: 采用思维链引导的监督微调来灌输专家级推理模式，基于专家修正的高质量数据集；然后通过具有多方奖励函数的强化学习阶段优化准确性和逻辑一致性，减少幻觉问题。

Result: 在关键基准测试中实现了优越的F1分数，超越了最先进的基线方法，并提供透明的逐步分析输出。

Conclusion: RationAnomaly通过结合思维链微调和强化学习，有效解决了日志异常检测中的可解释性、泛化性和可靠性问题，为自动化系统监控提供了更可靠的解决方案。

Abstract: Logs constitute a form of evidence signaling the operational status of
software systems. Automated log anomaly detection is crucial for ensuring the
reliability of modern software systems. However, existing approaches face
significant limitations: traditional deep learning models lack interpretability
and generalization, while methods leveraging Large Language Models are often
hindered by unreliability and factual inaccuracies. To address these issues, we
propose RationAnomaly, a novel framework that enhances log anomaly detection by
synergizing Chain-of-Thought (CoT) fine-tuning with reinforcement learning. Our
approach first instills expert-like reasoning patterns using CoT-guided
supervised fine-tuning, grounded in a high-quality dataset corrected through a
rigorous expert-driven process. Subsequently, a reinforcement learning phase
with a multi-faceted reward function optimizes for accuracy and logical
consistency, effectively mitigating hallucinations. Experimentally,
RationAnomaly outperforms state-of-the-art baselines, achieving superior
F1-scores on key benchmarks while providing transparent, step-by-step
analytical outputs. We have released the corresponding resources, including
code and datasets.

</details>


### [18] [The NazoNazo Benchmark: A Cost-Effective and Extensible Test of Insight-Based Reasoning in LLMs](https://arxiv.org/abs/2509.14704)
*Masaharu Mizumoto,Dat Nguyen,Zhiheng Han,Jiyuan Fang,Heyuan Guan,Xingfu Li,Naoya Shiraishi,Xuyang Tian,Yo Nakawake,Le Minh Nguyen*

Main category: cs.AI

TL;DR: Nazonazo是一个基于日本儿童谜语构建的基准测试，用于评估LLM的洞察推理能力，具有成本效益、可扩展性和易更新性，解决了当前基准污染和饱和问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估面临基准饱和和污染问题，需要构建成本效益高、可扩展且易于更新的基准来测试洞察推理能力。

Method: 使用日本儿童谜语构建基准测试，包含120个谜题（主要为一句话），无需专业知识，可大规模生成，支持快速更新盲测集。评估了38个前沿模型和126名成年人。

Result: 除GPT-5外，所有模型性能均不及人类（52.9%平均准确率）。推理模型显著优于非推理模型，模型大小与准确率无可靠关联。分析发现模型常产生正确解但验证失败。

Conclusion: Nazonazo提供了解决评估危机的有效基准格式，同时揭示了模型的元认知弱点，为未来控制和校准方法提供了明确目标。

Abstract: Benchmark saturation and contamination undermine confidence in LLM
evaluation. We present Nazonazo, a cost-effective and extensible benchmark
built from Japanese children's riddles to test insight-based reasoning. Items
are short (mostly one sentence), require no specialized domain knowledge, and
can be generated at scale, enabling rapid refresh of blind sets when leakage is
suspected. We evaluate 38 frontier models and 126 adults on 120 riddles. No
model except for GPT-5 is comparable to human performance, which achieves a
52.9% mean accuracy. Model comparison on extended 201 items shows that
reasoning models significantly outperform non-reasoning peers, while model size
shows no reliable association with accuracy. Beyond aggregate accuracy, an
informal candidate-tracking analysis of thought logs reveals many cases of
verification failure: models often produce the correct solution among
intermediate candidates yet fail to select it as the final answer, which we
illustrate with representative examples observed in multiple models. Nazonazo
thus offers a cost-effective, scalable, and easily renewable benchmark format
that addresses the current evaluation crisis while also suggesting a recurrent
meta-cognitive weakness, providing clear targets for future control and
calibration methods.

</details>


### [19] [Enhancing Retrieval Augmentation via Adversarial Collaboration](https://arxiv.org/abs/2509.14750)
*Letian Zhang,Guanghao Meng,Xudong Ren,Yiming Wang,Shu-Tao Xia*

Main category: cs.AI

TL;DR: 提出了AC-RAG框架，通过对抗性协作解决检索增强生成中的检索幻觉问题，显著提升检索准确性和性能


<details>
  <summary>Details</summary>
Motivation: 解决RAG方法中存在的检索幻觉问题，即微调模型无法识别和处理低质量检索文档，导致性能下降

Method: 采用两个异构代理：通用检测器识别知识差距，领域专业解析器提供精确解决方案，通过对抗性协作进行迭代问题分析和知识检索

Result: 实验表明AC-RAG显著提高了检索准确性，在各种垂直领域中优于最先进的RAG方法

Conclusion: AC-RAG框架通过对抗性协作机制有效解决了检索幻觉问题，为领域特定LLMs提供了更可靠的检索增强生成方案

Abstract: Retrieval-augmented Generation (RAG) is a prevalent approach for
domain-specific LLMs, yet it is often plagued by "Retrieval Hallucinations"--a
phenomenon where fine-tuned models fail to recognize and act upon poor-quality
retrieved documents, thus undermining performance. To address this, we propose
the Adversarial Collaboration RAG (AC-RAG) framework. AC-RAG employs two
heterogeneous agents: a generalist Detector that identifies knowledge gaps, and
a domain-specialized Resolver that provides precise solutions. Guided by a
moderator, these agents engage in an adversarial collaboration, where the
Detector's persistent questioning challenges the Resolver's expertise. This
dynamic process allows for iterative problem dissection and refined knowledge
retrieval. Extensive experiments show that AC-RAG significantly improves
retrieval accuracy and outperforms state-of-the-art RAG methods across various
vertical domains.

</details>


### [20] [OpenLens AI: Fully Autonomous Research Agent for Health Infomatics](https://arxiv.org/abs/2509.14778)
*Yuxiao Cheng,Jinli Suo*

Main category: cs.AI

TL;DR: OpenLens AI是一个专为健康信息学设计的全自动研究框架，集成了文献综述、数据分析、代码生成和论文撰写等专业代理，通过视觉语言反馈和质控机制解决现有LLM代理在医学可视化和领域特定质量要求方面的不足。


<details>
  <summary>Details</summary>
Motivation: 健康信息学研究具有数据模态多样、知识快速扩展和需要跨学科整合的特点，现有LLM代理系统缺乏医学可视化解释能力和领域特定的质量要求机制，无法满足健康信息学研究需求。

Method: 开发OpenLens AI框架，集成专业代理进行文献综述、数据分析、代码生成和论文撰写，采用视觉语言反馈处理医学可视化，并建立质量控制机制确保可重复性，实现全自动研究流程并生成可发表的LaTeX稿件。

Result: 该框架能够自动化整个研究流程，生成具有透明可追溯工作流程的出版就绪LaTeX稿件，为健康信息学研究提供了领域适配的解决方案。

Conclusion: OpenLens AI通过专门设计的代理架构和质量控制机制，成功解决了现有LLM代理在健康信息学应用中的局限性，为自动化健康信息学研究提供了有效的领域专用框架。

Abstract: Health informatics research is characterized by diverse data modalities,
rapid knowledge expansion, and the need to integrate insights across biomedical
science, data analytics, and clinical practice. These characteristics make it
particularly well-suited for agent-based approaches that can automate knowledge
exploration, manage complex workflows, and generate clinically meaningful
outputs. Recent progress in large language model (LLM)-based agents has
demonstrated promising capabilities in literature synthesis, data analysis, and
even end-to-end research execution. However, existing systems remain limited
for health informatics because they lack mechanisms to interpret medical
visualizations and often overlook domain-specific quality requirements. To
address these gaps, we introduce OpenLens AI, a fully automated framework
tailored to health informatics. OpenLens AI integrates specialized agents for
literature review, data analysis, code generation, and manuscript preparation,
enhanced by vision-language feedback for medical visualization and quality
control for reproducibility. The framework automates the entire research
pipeline, producing publication-ready LaTeX manuscripts with transparent and
traceable workflows, thereby offering a domain-adapted solution for advancing
health informatics research.

</details>


### [21] [Explainable AI for Infection Prevention and Control: Modeling CPE Acquisition and Patient Outcomes in an Irish Hospital with Transformers](https://arxiv.org/abs/2509.14942)
*Minh-Khoi Pham,Tai Tan Mai,Martin Crane,Rob Brennan,Marie E. Ward,Una Geary,Declan Byrne,Brian O Connell,Colm Bergin,Donncha Creagh,Nick McDonald,Marija Bezbradica*

Main category: cs.AI

TL;DR: 本研究开发了一个可解释AI框架，使用Transformer模型分析电子病历数据，成功预测碳青霉烯酶肠杆菌感染相关风险，发现感染相关特征和网络变量是关键风险因素。


<details>
  <summary>Details</summary>
Motivation: 碳青霉烯酶肠杆菌在医院感染防控中至关重要，但利用现代深度学习方法预测相关风险（如再入院、死亡率和住院时间延长）的研究仍然不足。

Method: 使用爱尔兰医院的电子病历数据，整合诊断代码、病房转移、人口统计、感染相关变量和接触网络特征，比较多种Transformer架构与传统机器学习模型，并应用可解释AI技术解释模型决策。

Result: TabTransformer模型在多个临床预测任务中表现最优，特别是在CPE获取预测方面（AUROC和敏感性）。感染相关特征、历史医院暴露、入院环境和网络中心性度量对预测结果影响显著。

Conclusion: 研究提出了一个稳健且可解释的AI框架，用于分析复杂电子病历数据，识别关键风险因素并预测CPE相关结果，强调了Transformer模型的优越性能和多样化临床及网络特征的重要性。

Abstract: Carbapenemase-Producing Enterobacteriace poses a critical concern for
infection prevention and control in hospitals. However, predictive modeling of
previously highlighted CPE-associated risks such as readmission, mortality, and
extended length of stay (LOS) remains underexplored, particularly with modern
deep learning approaches. This study introduces an eXplainable AI modeling
framework to investigate CPE impact on patient outcomes from Electronic Medical
Records data of an Irish hospital. We analyzed an inpatient dataset from an
Irish acute hospital, incorporating diagnostic codes, ward transitions, patient
demographics, infection-related variables and contact network features. Several
Transformer-based architectures were benchmarked alongside traditional machine
learning models. Clinical outcomes were predicted, and XAI techniques were
applied to interpret model decisions. Our framework successfully demonstrated
the utility of Transformer-based models, with TabTransformer consistently
outperforming baselines across multiple clinical prediction tasks, especially
for CPE acquisition (AUROC and sensitivity). We found infection-related
features, including historical hospital exposure, admission context, and
network centrality measures, to be highly influential in predicting patient
outcomes and CPE acquisition risk. Explainability analyses revealed that
features like "Area of Residence", "Admission Ward" and prior admissions are
key risk factors. Network variables like "Ward PageRank" also ranked highly,
reflecting the potential value of structural exposure information. This study
presents a robust and explainable AI framework for analyzing complex EMR data
to identify key risk factors and predict CPE-related outcomes. Our findings
underscore the superior performance of the Transformer models and highlight the
importance of diverse clinical and network features.

</details>


### [22] [Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems](https://arxiv.org/abs/2509.14956)
*Diego Gosmar,Deborah A. Dahl*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的多自主体系统安全框架，通过分布式监控层（Sentinel Agents）和协调管理层（Coordinator Agent）的双层设计，有效防范多种安全威胁，并通过模拟测试验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 多自主体系统面临着谓济注入、幽灵生成、隐私泄漏等多种安全威胁，需要一种动态适应的安全框架来提高系统的可靠性和安全性。

Method: 设计了双层安全架构：分布式监控层（Sentinel Agents）使用语义分析、行为分析、检索增强验证等技术监控互动通信；协调管理层（Coordinator Agent）负责政策执行、威胁处理和系统整体管理。

Result: 在162个综合攻击模拟中，Sentinel Agents成功检测到了所有攻击尝试，证明了该监控方法的实际可行性。

Conclusion: 该框架为多自主体系统提供了一种动态适应的安全解决方案，能够有效防范多种安全威胁，同时提升系统可观测性和遵规性。

Abstract: This paper proposes a novel architectural framework aimed at enhancing
security and reliability in multi-agent systems (MAS). A central component of
this framework is a network of Sentinel Agents, functioning as a distributed
security layer that integrates techniques such as semantic analysis via large
language models (LLMs), behavioral analytics, retrieval-augmented verification,
and cross-agent anomaly detection. Such agents can potentially oversee
inter-agent communications, identify potential threats, enforce privacy and
access controls, and maintain comprehensive audit records. Complementary to the
idea of Sentinel Agents is the use of a Coordinator Agent. The Coordinator
Agent supervises policy implementation, and manages agent participation. In
addition, the Coordinator also ingests alerts from Sentinel Agents. Based on
these alerts, it can adapt policies, isolate or quarantine misbehaving agents,
and contain threats to maintain the integrity of the MAS ecosystem. This
dual-layered security approach, combining the continuous monitoring of Sentinel
Agents with the governance functions of Coordinator Agents, supports dynamic
and adaptive defense mechanisms against a range of threats, including prompt
injection, collusive agent behavior, hallucinations generated by LLMs, privacy
breaches, and coordinated multi-agent attacks. In addition to the architectural
design, we present a simulation study where 162 synthetic attacks of different
families (prompt injection, hallucination, and data exfiltration) were injected
into a multi-agent conversational environment. The Sentinel Agents successfully
detected the attack attempts, confirming the practical feasibility of the
proposed monitoring approach. The framework also offers enhanced system
observability, supports regulatory compliance, and enables policy evolution
over time.

</details>


### [23] [Set Contribution Functions for Quantitative Bipolar Argumentation and their Principles](https://arxiv.org/abs/2509.14963)
*Filip Naudot,Andreas Brännström,Vicenç Torra,Timotheus Kampik*

Main category: cs.AI

TL;DR: 本文提出了量化论证集合在定量双极论证图中对目标论证（主题）贡献程度的集合贡献函数，是现有单论证贡献函数的泛化。作者建立了集合贡献函数的原则框架，并引入了关注集合内论证交互特性的新原则，最后通过推荐系统应用场景展示了不同函数的原则表现。


<details>
  <summary>Details</summary>
Motivation: 现有的定量双极论证图研究主要关注单个论证对主题的贡献，缺乏对论证集合整体贡献的量化方法。需要开发能够评估论证集合协同作用的函数，以更全面地理解论证系统中的集体影响。

Method: 通过泛化现有单论证贡献函数来构建集合贡献函数，建立原则化分析框架，引入专门针对集合特性（如论证间交互）的新原则，并在推荐系统应用场景中进行验证。

Result: 成功开发了集合贡献函数的理论框架，提出了适用于集合评估的新原则，展示了不同函数在具体应用场景中的原则符合性和实际表现。

Conclusion: 集合贡献函数扩展了定量论证分析的能力，新引入的集合特定原则为评估论证集合的协同效应提供了重要工具，在推荐系统等实际应用中具有重要价值。

Abstract: We present functions that quantify the contribution of a set of arguments in
quantitative bipolar argumentation graphs to (the final strength of) an
argument of interest, a so-called topic. Our set contribution functions are
generalizations of existing functions that quantify the contribution of a
single contributing argument to a topic. Accordingly, we generalize existing
contribution function principles for set contribution functions and provide a
corresponding principle-based analysis. We introduce new principles specific to
set-based functions that focus on properties pertaining to the interaction of
arguments within a set. Finally, we sketch how the principles play out across
different set contribution functions given a recommendation system application
scenario.

</details>


### [24] [A Knowledge-driven Adaptive Collaboration of LLMs for Enhancing Medical Decision-making](https://arxiv.org/abs/2509.14998)
*Xiao Wu,Ting-Zhu Huang,Liang-Jian Deng,Yanyuan Qiao,Imran Razzak,Yutong Xie*

Main category: cs.AI

TL;DR: KAMAC是一个基于知识驱动的自适应多智能体协作框架，通过动态组建专家团队来解决复杂医疗诊断问题，在癌症预后等复杂场景中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体协作框架采用静态预分配角色，缺乏适应性和动态知识整合能力，无法有效应对复杂临床场景中不断变化的诊断需求。

Method: KAMAC从初始专家智能体开始，通过知识驱动的讨论识别知识缺口，动态招募所需专科医生加入团队，支持灵活可扩展的协作，最终通过审查更新的智能体评论来做出决策。

Result: 在两个真实医疗基准测试中，KAMAC显著优于单智能体和先进的多智能体方法，特别是在需要动态跨专科专业知识的复杂临床场景（如癌症预后）中表现突出。

Conclusion: KAMAC框架通过动态团队组建和知识驱动的协作，有效解决了复杂医疗决策中的知识整合问题，为多智能体协作提供了新的自适应范式。

Abstract: Medical decision-making often involves integrating knowledge from multiple
clinical specialties, typically achieved through multidisciplinary teams.
Inspired by this collaborative process, recent work has leveraged large
language models (LLMs) in multi-agent collaboration frameworks to emulate
expert teamwork. While these approaches improve reasoning through agent
interaction, they are limited by static, pre-assigned roles, which hinder
adaptability and dynamic knowledge integration. To address these limitations,
we propose KAMAC, a Knowledge-driven Adaptive Multi-Agent Collaboration
framework that enables LLM agents to dynamically form and expand expert teams
based on the evolving diagnostic context. KAMAC begins with one or more expert
agents and then conducts a knowledge-driven discussion to identify and fill
knowledge gaps by recruiting additional specialists as needed. This supports
flexible, scalable collaboration in complex clinical scenarios, with decisions
finalized through reviewing updated agent comments. Experiments on two
real-world medical benchmarks demonstrate that KAMAC significantly outperforms
both single-agent and advanced multi-agent methods, particularly in complex
clinical scenarios (i.e., cancer prognosis) requiring dynamic, cross-specialty
expertise. Our code is publicly available at:
https://github.com/XiaoXiao-Woo/KAMAC.

</details>


### [25] [Calibrated Generative AI as Meta-Reviewer: A Systemic Functional Linguistics Discourse Analysis of Reviews of Peer Reviews](https://arxiv.org/abs/2509.15035)
*Gabriela C. Zapata,Bill Cope,Mary Kalantzis,Duane Searsmith*

Main category: cs.AI

TL;DR: 研究探讨生成式AI如何通过机器生成的元评价来支持形成性评估，分析显示AI反馈能够近似人类有效反馈的修辞和关系特征


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI在在线研究生课程中支持形成性评估的潜力，特别是在peer review过程中提供机器生成的元评价

Method: 基于系统功能语言学和评价理论，分析了120个AI生成的元评价，从概念、人际和文本三个维度探索意义构建方式

Result: AI反馈能够平衡表扬与建设性批评，与评分标准对齐，并采用结构化呈现方式突出学生主体性，具有指导清晰性和支持性立场

Conclusion: AI元反馈有潜力搭建反馈素养支架，增强学习者参与peer review的积极性，能够模拟有效人类反馈的关键特征

Abstract: This study investigates the use of generative AI to support formative
assessment through machine generated reviews of peer reviews in graduate online
courses in a public university in the United States. Drawing on Systemic
Functional Linguistics and Appraisal Theory, we analyzed 120 metareviews to
explore how generative AI feedback constructs meaning across ideational,
interpersonal, and textual dimensions. The findings suggest that generative AI
can approximate key rhetorical and relational features of effective human
feedback, offering directive clarity while also maintaining a supportive
stance. The reviews analyzed demonstrated a balance of praise and constructive
critique, alignment with rubric expectations, and structured staging that
foregrounded student agency. By modeling these qualities, AI metafeedback has
the potential to scaffold feedback literacy and enhance leaner engagement with
peer review.

</details>


### [26] [From Sea to System: Exploring User-Centered Explainable AI for Maritime Decision Support](https://arxiv.org/abs/2509.15084)
*Doreen Jirak,Pieter Maes,Armeen Saroukanoff,Dirk van Rooy*

Main category: cs.AI

TL;DR: 本文强调可解释AI(XAI)在海上领域人机协作中的重要性，提出针对海事专业人员的信任、可用性和可解释性感知调查，以指导开发用户中心的海事XAI系统。


<details>
  <summary>Details</summary>
Motivation: 随着自主技术在海事操作中的广泛应用，理解AI决策原因与决策本身同等重要。在复杂动态的海事环境中，对AI的信任不仅取决于性能，还依赖于透明度和可解释性。

Method: 提出针对海事领域的专门调查问卷，旨在捕捉海事专业人员对信任、可用性和可解释性的感知，支持以用户为中心的XAI集成。

Result: 通过领域特定的调查方法，为开发面向海员和海事团队需求的用户中心XAI系统提供指导和意识培养。

Conclusion: 可解释AI是海事领域有效人机协作的基础，需要开发专门针对海事专业人员需求的用户中心XAI系统，以确保知情监督和共享理解。

Abstract: As autonomous technologies increasingly shape maritime operations,
understanding why an AI system makes a decision becomes as crucial as what it
decides. In complex and dynamic maritime environments, trust in AI depends not
only on performance but also on transparency and interpretability. This paper
highlights the importance of Explainable AI (XAI) as a foundation for effective
human-machine teaming in the maritime domain, where informed oversight and
shared understanding are essential. To support the user-centered integration of
XAI, we propose a domain-specific survey designed to capture maritime
professionals' perceptions of trust, usability, and explainability. Our aim is
to foster awareness and guide the development of user-centric XAI systems
tailored to the needs of seafarers and maritime teams.

</details>


### [27] [Internalizing Self-Consistency in Language Models: Multi-Agent Consensus Alignment](https://arxiv.org/abs/2509.15172)
*Ankur Samanta,Akshayaa Magesh,Youliang Yu,Runzhe Wu,Ayush Jain,Daniel Jiang,Boris Vidolov,Paul Sajda,Yonathan Efroni,Kaveh Hassani*

Main category: cs.AI

TL;DR: MACA是一个强化学习框架，通过多智能体辩论的多数/少数结果来后训练模型，使其偏好与内部共识一致推理轨迹，显著提升语言模型的自一致性和推理能力。


<details>
  <summary>Details</summary>
Motivation: 语言模型是不一致的推理者，经常对相同提示生成矛盾响应。现有推理时方法无法解决核心问题：模型难以可靠选择导致探索性采样下一致结果的推理路径。

Method: 提出多智能体共识对齐(MACA)强化学习框架，通过多智能体辩论产生多数/少数结果，后训练模型偏好与内部共识一致的推理轨迹，基于审议式交换而非简单多数投票。

Result: 在自一致性(GSM8K +27.6%)、单智能体推理(MATH +23.7%)、采样推理(MATH Pass@20 +22.4%)和多智能体决策(MathQA +42.7%)方面显著提升，在未见基准上也有强泛化能力。

Conclusion: MACA实现了强大的自对齐，更可靠地释放语言模型的潜在推理能力，使智能体能够自我教导变得更果断、简洁，并更好地利用多智能体设置中的同伴洞察。

Abstract: Language Models (LMs) are inconsistent reasoners, often generating
contradictory responses to identical prompts. While inference-time methods can
mitigate these inconsistencies, they fail to address the core problem: LMs
struggle to reliably select reasoning pathways leading to consistent outcomes
under exploratory sampling. To address this, we formalize self-consistency as
an intrinsic property of well-aligned reasoning models and introduce
Multi-Agent Consensus Alignment (MACA), a reinforcement learning framework that
post-trains models to favor reasoning trajectories aligned with their internal
consensus using majority/minority outcomes from multi-agent debate. These
trajectories emerge from deliberative exchanges where agents ground reasoning
in peer arguments, not just aggregation of independent attempts, creating
richer consensus signals than single-round majority voting. MACA enables agents
to teach themselves to be more decisive and concise, and better leverage peer
insights in multi-agent settings without external supervision, driving
substantial improvements across self-consistency (+27.6% on GSM8K),
single-agent reasoning (+23.7% on MATH), sampling-based inference (+22.4%
Pass@20 on MATH), and multi-agent ensemble decision-making (+42.7% on MathQA).
These findings, coupled with strong generalization to unseen benchmarks (+16.3%
on GPQA, +11.6% on CommonsenseQA), demonstrate robust self-alignment that more
reliably unlocks latent reasoning potential of language models.

</details>


### [28] [Generalizable Geometric Image Caption Synthesis](https://arxiv.org/abs/2509.15217)
*Yue Xin,Wenyuan Wang,Rui Pan,Ruida Wang,Howard Meng,Renjie Pi,Shizhe Diao,Tong Zhang*

Main category: cs.AI

TL;DR: 提出RLVR方法改进几何图像标注，通过强化学习验证奖励生成高质量数据集，提升多模态大语言模型在几何问题解决和其他推理任务中的性能


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在解决复杂几何问题时表现不佳，主要原因是缺乏高质量的几何图像-文本对数据集，且现有模板化数据合成方法泛化能力有限

Method: 引入强化学习与可验证奖励(RLVR)的数据生成流程，基于50个基本几何关系合成几何图像，利用数学问题解决任务产生的奖励信号优化图像标注

Result: 在MathVista和MathVerse的非几何图像任务中准确率提升2.8%-4.8%，在MMMU的艺术、设计、技术和工程任务中提升2.4%-3.9%

Conclusion: RLVR方法能有效捕捉几何问题解决的关键特征，提高任务泛化能力，并增强多模态大语言模型的通用推理能力

Abstract: Multimodal large language models have various practical applications that
demand strong reasoning abilities. Despite recent advancements, these models
still struggle to solve complex geometric problems. A key challenge stems from
the lack of high-quality image-text pair datasets for understanding geometric
images. Furthermore, most template-based data synthesis pipelines typically
fail to generalize to questions beyond their predefined templates. In this
paper, we bridge this gap by introducing a complementary process of
Reinforcement Learning with Verifiable Rewards (RLVR) into the data generation
pipeline. By adopting RLVR to refine captions for geometric images synthesized
from 50 basic geometric relations and using reward signals derived from
mathematical problem-solving tasks, our pipeline successfully captures the key
features of geometry problem-solving. This enables better task generalization
and yields non-trivial improvements. Furthermore, even in out-of-distribution
scenarios, the generated dataset enhances the general reasoning capabilities of
multimodal large language models, yielding accuracy improvements of
$2.8\%\text{-}4.8\%$ in statistics, arithmetic, algebraic, and numerical tasks
with non-geometric input images of MathVista and MathVerse, along with
$2.4\%\text{-}3.9\%$ improvements in Art, Design, Tech, and Engineering tasks
in MMMU.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [29] [Resource Allocation for Mutualistic Symbiotic Radio with Hybrid Active-Passive Communications](https://arxiv.org/abs/2509.14567)
*Hong Guo,Yinghui Ye,Haijian Sun,Liqin Shi,Rose Qingyang Hu*

Main category: cs.IT

TL;DR: 本文提出一种带有混合主动/被动传输的相互关聚超带后散通信系统，通过优化反射系数、功率分配和时间分配来提高次级用户的传输速率。


<details>
  <summary>Details</summary>
Motivation: 传统相互关聚超带后散系统中，次级用户的低调制速率导致传输速率极低，需要找到被动后散和主动传输之间的最佳平衡点。

Method: 提出两种问题模型：固定SIC排序和动态SIC排序问题，使用SCA基于和BCD基于迭代算法进行优化，联合优化反射系数、传输功率和时间分配。

Result: 模拟结果显示：1)新系统在同等约束下比传统设计获得更高的SU速率；2)高PT最小速率增益时动态SIC排序更优，低时两者性能接近。

Conclusion: 该方法通过混合主动/被动传输机制有效提升了相互关聚超带后散系统的次级用户传输速率，并为不同应用场景提供了最佳的SIC排序策略。

Abstract: Mutualistic SR is a communication paradigm that offers high spectrum
efficiency and low power consumption, where the SU transmits information by
modulating and backscattering the PT's signal, enabling shared use of spectrum
and power with PT. In return, the PT's performance can be enhanced by SU's
backscattered signal, forming a mutualistic relationship. However, the low
modulation rate causes extremely inferior transmission rates for SUs. To
improve the SU transmission rate, this paper proposes a new mutualistic SR with
HAPC to explore the tradeoff between BC and AC in terms of power consumption
and transmission rate, enabling each SU to transmit signal via passive BC and
AC alternatively. We propose two problems to maximize the total rate of all SUs
under the fixed and dynamic SIC ordering, respectively. The fixed SIC
ordering-based problem is to jointly optimize the SUs' reflection coefficients,
the transmit power of each SU during AC, and the time allocation for each SU
during BC and AC, subject to the energy causality constraint and the PT's
transmission rate gain constraint. In addition to pondering the constraints
involved in the fixed SIC ordering-based problem, the dynamic SIC
ordering-based problem, which is a mixed integer programming one, further
considers the SIC ordering constraint. The above two problems are solved by our
proposed SCA-based and BCD-based iterative algorithms, respectively. Simulation
results demonstrate that: 1) the proposed mutualistic SR system outperforms
traditional designs in terms of the rates achieved by SUs under the same
constraints; 2) the total rate of all SUs under the dynamic SIC ordering is
larger than that of the fixed one when the PT's minimum rate gain is high, and
becomes nearly identical when the PT's minimum rate gain is low.

</details>


### [30] [Joint Scheduling and Multiflow Maximization in Wireless Networks](https://arxiv.org/abs/2509.14582)
*Yanxiao Liu,Shenghao Yang,Cheuk Ting Li*

Main category: cs.IT

TL;DR: 本文研究了6G网络中的最大多流问题，提出了一种高效算法，能够在不需要整个调度速率区域的情况下直接求解准确的最优解。该算法通过联合计算调度速率区域和最大多流问题，避免了传统方法的NP难问题，并可扩展到包含传播延误的场景。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络的发展，需要集成大量多维平台设备，因此必须深入理解大规模网络的理论极限。传统解决最大多流问题的方法需要先计算调度速率区域（NP难问题），再求解最大多流，在大型网络中计算复杂度极高。

Method: 提出了一种高效算法，能够联合计算调度速率区域和解决最大多流问题，无需先获取整个调度速率区域。该算法通过有限迭代次数确保输出最优解，并使用图形框架扩展到包含传播延误的场景。

Result: 理论证明了算法总是在有限迭代次数内输出最优解。模拟实验结果显示，该方法在各种情况下都显著优于传统方法。该框架适用于最一般的多源多汞网络场景：使用网络编码的多播多播问题。

Conclusion: 该研究为大规模网络中的最大多流问题提供了一种高效的准确解决方案，免除了传统方法的计算瓶颈。通过联合调度和流量优化，该算法能够在不需要先计算全部调度速率区域的情况下直接获得最优解，为6G网络的发展提供了重要的理论支撑。

Abstract: Towards the development of 6G mobile networks, it is promising to integrate a
large number of devices from multi-dimensional platforms, and it is crucial to
have a solid understanding of the theoretical limits of large-scale networks.
We revisit a fundamental problem at the heart of network communication theory:
the maximum multiflow (MMF) problem in multi-hop networks, with network coding
performed at intermediate nodes. To derive the exact-optimal solution to the
MMF problem (as opposed to approximations), conventional methods usually
involve two steps: first calculate the scheduling rate region, and then find
the maximum multiflow that can be supported by the achievable link rates.
However, the NP-hardness of the scheduling part makes solving the MMF problem
in large networks computationally prohibitive. In this paper, while still
focusing on the exact-optimal solution, we provide efficient algorithms that
can jointly calculate the scheduling rate region and solve the MMF problem,
thereby outputting optimal values without requiring the entire scheduling rate
region. We theoretically prove that our algorithms always output optimal
solutions in a finite number of iterations, and we use various simulation
results to demonstrate our advantages over conventional approaches. Our
framework is applicable to the most general scenario in multi-source multi-sink
networks: the multiple multicast problem with network coding. Moreover, by
employing a graphical framework, we show that our algorithm can be extended to
scenarios where propagation delays are large (e.g., underwater networks), in
which recent studies have shown that the scheduling rate region can be
significantly improved by utilizing such delays.

</details>


### [31] [Inference of unknown syndrome values in the implementation of the Berlekamp-Massey-Sakata algorithm](https://arxiv.org/abs/2509.14835)
*J. J. Bernal,J. J. Simón*

Main category: cs.IT

TL;DR: 研究代数几何码中实现Berlekamp-Massey-Sakata算法所需的缺失校验子值的确定问题，并将结果应用于阿贝尔码的校验子校正


<details>
  <summary>Details</summary>
Motivation: 在代数几何码中实现Feng-Rao多数投票算法需要确定缺失的校验子值，这对于阿贝尔码的校验子校正具有重要意义

Method: 研究Berlekamp-Massey-Sakata算法在代数几何码中的应用，确定实现Feng-Rao多数投票所需的缺失校验子值

Result: 提出了确定缺失校验子值的方法，并成功应用于阿贝尔码的校验子校正问题

Conclusion: 该研究为代数几何码中校验子值的确定提供了有效方法，特别是在阿贝尔码的校验子校正方面具有实用价值

Abstract: We study the problem of finding those missing syndrome values that are needed
to implment the Berlekamp-Massey-Sakata algorithm as the Feng-Rao Majority
Voting for algebraic geometric codes. We apply our results to solve syndrome
correction in abelian codes.

</details>


### [32] [Beam Squint Assisted Joint Angle-Distance Localization for Near-Field Communications](https://arxiv.org/abs/2509.14850)
*Aibiao Zhang,Weizheng Zhang,Chiya Zhang*

Main category: cs.IT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: With the advent of extremely large-scale MIMO (XL-MIMO), mmWave/THz bands and
ultra-wideband transmission, future 6G systems demand real-time positioning
with centimeter or even millimeter level accuracy. This paper addresses the
pronounced near-field beam squint problem caused by phase shifter based
beamforming in wideband near-field scenarios and proposes a beam squint
assisted joint angle-distance localization scheme. The key idea is to employ
true-time-delay (TTD) units together with phase shifters (PS) to synthesize a
controllable joint angle-distance (JAD) trajectory that establishes a unique
mapping between subcarriers and spatial locations, enabling single scan
acquisition of target angle and range. To implement this paradigm efficiently,
we design a coarse to fine two stage estimator: a low complexity coarse stage
based on subcarrier power peaks for user separation and candidate region
selection, followed by a local high resolution refinement stage that applies
spatial smoothing and near-field multiple signal classification (MUSIC) over
multiple subcarriers and fuses the resulting spectra by geometric averaging to
suppress spurious peaks. We theoretically prove the correctness and uniqueness
of the MUSIC spatial spectrum peak under the proposed near-field steering
model, and derive the Cram\'er-Rao lower bound (CRLB) for joint angle-distance
estimation. Simulation results in single and multi-user scenarios validate that
the proposed method achieves very high accuracy and robustness, significantly
outperforming conventional two-step approaches, and is promising for practical
6G sensing and localization deployments.

</details>


### [33] [On Finite-Blocklength Noisy Classical-Quantum Channel Coding With Amplitude Damping Errors](https://arxiv.org/abs/2509.14852)
*Tamás Havas,Hsuan-Yin Lin,Eirik Rosnes,Ching-Yi Lai*

Main category: cs.IT

TL;DR: 在有限块长度下，简单的无编码方式在量子振幅激洛通道上无法实现量子优势，必须采用结合经典错误纠正编码和量子输入状态的复杂编码策略才能在有限块长度下实现量子性能提升


<details>
  <summary>Details</summary>
Motivation: 研究有限块长度下的经典-量子通道编码问题，探索如何通过量子输出可靠地传输经典信息，并在量子振幅激洛通道上实现量子优势

Method: 分析了在量子振幅激洛通道(ADC)上的经典-量子通道编码性能，比较了简单无编码方式与结合经典错误纠正编码和量子输入状态的复杂编码策略

Result: 发现对于任何有限块长度，简单的无编码方法无法在ADC上提供任何优势，而复杂的编码策略对于在有限块长度下实现量子性能提升至关重要

Conclusion: 在量子通信中，仅仅使用量子输出不足以实现量子优势，必须结合经典错误纠正技术和量子状态设计的综合编码策略才能在有限块长度下获得量子性能提升

Abstract: We investigate practical finite-blocklength classical-quantum channel coding
over the quantum amplitude damping channel (ADC), aiming to transmit classical
information reliably through quantum outputs. Our findings indicate that for
any finite blocklength, a naive (uncoded) approach fails to offer any advantage
over the ADC. Instead, sophisticated encoding strategies that leverage both
classical error-correcting codes and quantum input states are crucial for
realizing quantum performance gains at finite blocklengths.

</details>


### [34] [Four classes of LCD codes from (*)-(L,P)-twisted generalized Reed-Solomon codes](https://arxiv.org/abs/2509.14878)
*Zhonghao Liang,Qunying Liao*

Main category: cs.IT

TL;DR: 本文通过定义(*)-(L,P)-TGRS码统一了现有的LCD MDS码构造方法，给出了其奇偶校验矩阵，并构造了四类LCD码


<details>
  <summary>Details</summary>
Motivation: 统一Yue等人和Wu等人关于LCD MDS码的构造方法，提供更一般化的理论框架

Method: 定义(*)-(L,P)-扭曲广义Reed-Solomon码，推导其奇偶校验矩阵，基于此构造四类线性互补对偶码

Result: 成功统一了现有构造方法，提出了更一般的(*)-(L,P)-TGRS码框架，并给出了具体的LCD码构造实例

Conclusion: 所提出的(*)-(L,P)-TGRS码框架有效统一并推广了现有的LCD MDS码构造方法，为编码理论和实践提供了新的工具

Abstract: It's well-known that maximum distance separable codes (in short, MDS) and
linear complementary dual (in short, LCD) codes are very important in coding
theory and practice. In 2023, Yue et al. [25] constructed three classes of LCD
MDS codes via (*)-TGRS codes. Recently, Wu et al. [27] generalized the results
given by Yue et al. and constructed several classes of LCD MDS codes. In this
paper, we unify their constructions by defining the (*)-(L,P)-twisted
generalized Reed-Solomon (in short, (*)-(L,P)-TGRS) code, give the parity-check
matrix of (*)-(L,P)-TGRS codes, and then construct four classes of LCD codes.
Finally, some corresponding examples are given.

</details>


### [35] [Movable-Antenna Trajectory Optimization for Wireless Sensing: CRB Scaling Laws over Time and Space](https://arxiv.org/abs/2509.14905)
*Wenyan Ma,Lipeng Zhu,Rui Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种基于可移动天线(MA)的新型无线感知系统，通过天线持续移动提升了角度估计性能，在1D和2D情况下都得到了更优的效果。


<details>
  <summary>Details</summary>
Motivation: 传统固定位置天线(FPA)感知系统的角度估计性能有限，需要通过天线移动来提高感知性能和角分辨率。

Method: 推导了角度到达角(AoA)估计的Cramer-Rao界(CRB)，对1D情况求解全局最优轨迹，对2D情况设计交替优化算法获得局部最优轨迹。

Result: 数值结果显示，提出的1D/2D MA感知方案在CRB和实际AoA估计MSE方面都显著低于传统FPA感知和其他基准MA轨迹。

Conclusion: 可移动天线系统能够通过优化轨迹显著提高角度估计准确性，具有低相关性的指向向量，有效提升了角分辨率。

Abstract: In this paper, we present a new wireless sensing system utilizing a movable
antenna (MA) that continuously moves and receives sensing signals to enhance
sensing performance over the conventional fixed-position antenna (FPA) sensing.
We show that the angle estimation performance is fundamentally determined by
the MA trajectory, and derive the Cramer-Rao bound (CRB) of the mean square
error (MSE) for angle-of-arrival (AoA) estimation as a function of the
trajectory for both one-dimensional (1D) and two-dimensional (2D) antenna
movement. For the 1D case, a globally optimal trajectory that minimizes the CRB
is derived in closed form. Notably, the resulting CRB decreases cubically with
sensing time in the time-constrained regime, whereas it decreases linearly with
sensing time and quadratically with the movement line segment's length in the
space-constrained regime. For the 2D case, we aim to achieve the minimum of
maximum (min-max) CRBs of estimation MSE for the two AoAs with respect to the
horizontal and vertical axes. To this end, we design an efficient alternating
optimization algorithm that iteratively updates the MA's horizontal or vertical
coordinates with the other being fixed, yielding a locally optimal trajectory.
Numerical results show that the proposed 1D/2D MA-based sensing schemes
significantly reduce both the CRB and actual AoA estimation MSE compared to
conventional FPA-based sensing with uniform linear/planar arrays (ULAs/UPAs) as
well as various benchmark MA trajectories. Moreover, it is revealed that the
steering vectors of our designed 1D/2D MA trajectories have low correlation in
the angular domain, thereby effectively increasing the angular resolution for
achieving higher AoA estimation accuracy.

</details>


### [36] [Indoor Fluid Antenna Systems Enabled by Layout-Specific Modeling and Group Relative Policy Optimization](https://arxiv.org/abs/2509.15006)
*Tong Zhang,Qianren Li,Shuai Wang,Wanli Ni,Jiliang Zhang,Rui Wang,Kai-Kit Wong,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 流体天线系统在室内环境中通过动态优化天线位置、放大器调感和功率分配来改善通信性能，提出了专门的题布特定通道模型和GRPO算法，在计算效率和性能方面都较现有方案有显著提升。


<details>
  <summary>Details</summary>
Motivation: 室内环境中信号传播因结构障碍和复杂多径反射而严重恶化，需要新技术来动态优化通道条件和减轻多径衰落。

Method: 提出了题布特定通道模型和新的组相对策略优化(GRPO)算法，用于聚合优化天线位置、政大器调感和功率分配。

Result: 计算时间减少83.3%，RMSE提高3dB；GRPO算法在总速率上超过PPO等基准方法，仅需PPO 49.2%的计算资源；可以选择保守的组大小和轨迹长度而不牺牲性能。

Conclusion: 流体天线系统AS通过动态优化能够有效改善室内通信性能，提出的题布特定模型和GRPO算法在计算效率和性能方面都显示出优势，为室内无线通信提供了有效解决方案。

Abstract: The fluid antenna system (FAS) revolutionizes wireless communications by
employing position-flexible antennas that dynamically optimize channel
conditions and mitigate multipath fading. This innovation is particularly
valuable in indoor environments, where signal propagation is severely degraded
due to structural obstructions and complex multipath reflections. In this
paper, we study the channel modeling and joint optimization of antenna
positioning, beamforming, and power allocation for indoor FAS. In particular,
we propose, for the first time, a layout-specific channel model and a novel
group relative policy optimization (GRPO) algorithm for indoor FAS. Compared to
the state-of-the-art Sionna model, our approach achieves an $83.3\%$ reduction
in computation time with an approximately $3$ dB increase in root-mean-square
error (RMSE). When simplified to a two-ray model, our channel model enables a
closed-form solution for the optimal antenna position, achieving near-optimal
performance. {For the joint optimization problem, the proposed GRPO algorithm
outperforms proximal policy optimization (PPO) and other baselines in sum-rate,
while requiring only 49.2\% computational resources of PPO, due to its
group-based advantage estimation.} Simulation results reveal that increasing
either the group size or trajectory length in GRPO does not yield significant
improvements in sum-rate, suggesting that these parameters can be selected
conservatively without sacrificing performance.

</details>


### [37] [Version Age of Information with Contact Mobility in Gossip Networks](https://arxiv.org/abs/2509.15184)
*Irtiza Hasan,Ahmed Arafa*

Main category: cs.IT

TL;DR: 本文研究了移动性对gossip网络中信息新鲜度的影响，使用版本年龄信息(VAoI)作为度量指标，通过随机混合系统框架分析不同拓扑结构和移动性规模下的性能表现，并优化移动成本与信息新鲜度的权衡。


<details>
  <summary>Details</summary>
Motivation: 在移动gossip网络中，节点通过移动接触来获取信息，研究这种接触移动性如何影响信息传播的新鲜度，特别是在网络连接性谱的两个极端（断开连接和完全连接）情况下。

Method: 采用随机混合系统(SHS)框架分析不同网络拓扑和移动性规模，使用版本年龄信息(VAoI)作为新鲜度度量，通过数学分析和仿真验证理论结果，并构建优化问题最小化版本年龄与移动成本的加权和。

Result: 研究表明接触移动性能显著改善网络信息新鲜度，特别是在断开连接和完全连接的gossip网络中。通过优化移动成本，可以在控制成本的同时有效降低平均版本年龄。

Conclusion: 接触移动性是提升gossip网络信息新鲜度的有效机制，通过适当的移动性成本优化，可以实现信息新鲜度与移动成本之间的良好平衡，为移动网络设计提供理论指导。

Abstract: A gossip network is considered in which a source node updates its status
while other nodes in the network aim at keeping track of it as it varies over
time. Information gets disseminated by the source sending status updates to the
nodes, and the nodes gossiping with each other. In addition, the nodes in the
network are mobile, and can move to other nodes to get information, which we
term contact mobility. The goal for the nodes is to remain as fresh as
possible, i.e., to have the same information as the source's. To evaluate the
freshness of information, we use the Version Age-of-Information (VAoI) metric,
defined as the difference between the version of information available at a
given node and that at the source. We analyze the effect of contact mobility on
information dissemination in the gossip network using a Stochastic Hybrid
System (SHS) framework for different topologies and mobility scalings with
increasing number of nodes. It is shown that with the presence of contact
mobility the freshness of the network improves in both ends of the network
connectivity spectrum: disconnected and fully connected gossip networks. We
mathematically analyze the average version age scalings and validate our
theoretical results via simulations. Finally, we incorporate the cost of
mobility for the network by formulating and solving an optimization problem
that minimizes a weighted sum of version age and mobility cost. Our results
show that contact mobility, with optimized mobility cost, improves the average
version age in the network.

</details>


### [38] [Improved Constructions and Lower Bounds for Maximally Recoverable Grid Codes](https://arxiv.org/abs/2509.15013)
*Joshua Brakensiek,Manik Dhar,Sivakanth Gopi*

Main category: cs.IT

TL;DR: 本文研究最大可恢复网格码，针对m×n网格拓扑结构，在m和h为常数、n增长的情况下，提出了多项式字段大小的显式构造，并给出了新的字段大小下界。


<details>
  <summary>Details</summary>
Motivation: 先前研究主要关注m=n的情况，此时显式构造需要指数级字段大小。本文受实际应用驱动，研究m和h为常数、n增长的场景，以寻找更实用的多项式字段大小构造。

Method: 研究m×n网格拓扑的编码，每行每列有一个奇偶校验，加上h≥1个全局奇偶校验。在m和h为常数的设定下，提供多个新的显式构造方法。

Result: 提出了字段大小为n的多项式的显式构造方案，这些构造在m和h为常数时有效。同时给出了新的字段大小下界结果。

Conclusion: 在m和h为常数的实际应用场景下，成功实现了多项式字段大小的最大可恢复网格码构造，填补了先前研究的空白，并建立了相应的理论下界。

Abstract: In this paper, we continue the study of Maximally Recoverable (MR) Grid Codes
initiated by Gopalan et al. [SODA 2017]. More precisely, we study codes over an
$m \times n$ grid topology with one parity check per row and column of the grid
along with $h \ge 1$ global parity checks. Previous works have largely focused
on the setting in which $m = n$, where explicit constructions require field
size which is exponential in $n$. Motivated by practical applications, we
consider the regime in which $m,h$ are constants and $n$ is growing. In this
setting, we provide a number of new explicit constructions whose field size is
polynomial in $n$. We further complement these results with new field size
lower bounds.

</details>


### [39] [Integrated Sensing and Communication for Vehicular Networks: A Rate-Distortion Fundamental Limits of State Estimator](https://arxiv.org/abs/2509.15025)
*Lugaoze Feng,Guocheng Lv,Xunan Li,Ye Jin*

Main category: cs.IT

TL;DR: 本文建立了状态相关无记忆信道中传感性能的率失真函数，提出了改进的Blahut-Arimoto算法求解，并首次统一了通信与传感的信息理论结果。


<details>
  <summary>Details</summary>
Motivation: 现有工作中传感性能常被忽视，需要为车联网ISAC系统建立统一的通信与传感性能评估框架。

Method: 使用状态相关无记忆信道建模ISAC系统，建立率失真函数，提出改进的Blahut-Arimoto算法进行求解。

Result: 定义了容量-率-失真权衡区域，数值评估显示在某些信道中编码能提高估计速率。

Conclusion: 首次在单一优化框架内统一了通信与传感的信息理论结果，为ISAC系统性能分析提供了理论基础。

Abstract: The state-dependent memoryless channel (SDMC) is employed to model the
integrated sensing and communication (ISAC) system for connected vehicular
networks, where the transmitter conveys messages to the receiver while
simultaneously estimating the state parameter of interest via the received echo
signals. However, the performance of sensing has often been neglected in
existing works. To address this gap, we establish the rate-distortion function
for sensing performance in the SDMC model, which is defined based on standard
information-theoretic principles to ensure clear operational meaning. In
addition, we propose a modified Blahut-Arimoto type algorithm for solving the
rate-distortion function and provide convergence proofs for the algorithm. We
further define the capacity-rate-distortion tradeoff region, which, for the
first time, unifies information-theoretic results for communication and sensing
within a single optimization framework. Finally, we numerically evaluate the
capacity-rate-distortion region and demonstrate the benefit of coding in terms
of estimation rate for certain channels.

</details>


### [40] [Distributed Batch Matrix Multiplication: Trade-Offs in Download Rate, Randomness, and Privacy](https://arxiv.org/abs/2509.15047)
*Amirhosein Morteza,Remi A. Chou*

Main category: cs.IT

TL;DR: 本文研究了分布式批量矩阵乘法中通信速率与隐私保护的权衡，重点关注矩阵A的隐私保护，同时利用最快服务器的响应计算乘积AB。


<details>
  <summary>Details</summary>
Motivation: 随着分布式计算和云服务的普及，如何在保证计算效率的同时保护敏感数据的隐私成为一个重要问题。特别是在矩阵乘法等基础运算中，需要平衡通信开销与隐私保护水平。

Method: 采用信息论方法分析分布式矩阵乘法系统，设置隐私参数α控制信息泄露程度，研究不同服务器数量k和窃听者数量ℓ下的最优通信速率，并分析编码器所需本地随机性的影响。

Result: 建立了通信速率与隐私泄露之间的线性关系，确定了矩阵为方阵时的最优权衡边界，发现信息泄露与通信速率之间存在线性依赖关系。

Conclusion: 该研究为分布式矩阵计算提供了理论框架，证明了在给定隐私约束下存在最优的通信效率，为实际系统的设计提供了理论指导。

Abstract: We study the trade-off between communication rate and privacy for distributed
batch matrix multiplication of two independent sequences of matrices $\bold{A}$
and $\bold{B}$ with uniformly distributed entries. In our setting, $\bold{B}$
is publicly accessible by all the servers while $\bold{A}$ must remain private.
A user is interested in evaluating the product $\bold{AB}$ with the responses
from the $k$ fastest servers. For a given parameter $\alpha \in [0, 1]$, our
privacy constraint must ensure that any set of $\ell$ colluding servers cannot
learn more than a fraction $\alpha$ of $\bold{A}$. Additionally, we study the
trade-off between the amount of local randomness needed at the encoder and
privacy. Finally, we establish the optimal trade-offs when the matrices are
square and identify a linear relationship between information leakage and
communication rate.

</details>
