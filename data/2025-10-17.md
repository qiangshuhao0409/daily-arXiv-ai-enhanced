<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 7]
- [cs.AI](#cs.AI) [Total: 52]
- [cs.IT](#cs.IT) [Total: 11]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Joint Active RIS Configuration and User Power Control for Localization: A Neuroevolution-Based Approach](https://arxiv.org/abs/2510.13819)
*George Stamatelis,Hui Chen,Henk Wymeersch,George C. Alexandropoulos*

Main category: cs.NI

TL;DR: 提出了一种基于RIS的用户定位方法，结合神经进化和监督学习的混合算法，联合控制RIS相位配置和用户发射功率，仅需单比特反馈即可实现优于基线方法的定位性能。


<details>
  <summary>Details</summary>
Motivation: 利用RIS辅助用户定位，通过动态功率控制和RIS相位优化来提高定位精度，同时降低反馈开销。

Method: 采用多智能体算法，结合神经进化和监督学习的混合方法，联合控制RIS相位配置和用户发射功率，仅需单比特反馈消息。

Result: 数值实验表明该方法在性能上优于指纹识别、深度强化学习基线和基于反向传播的位置估计器。

Conclusion: 所提出的混合算法能够有效利用RIS进行用户定位，在降低反馈开销的同时实现了优越的定位性能。

Abstract: This paper studies user localization aided by a Reconfigurable Intelligent
Surface (RIS). A feedback link from the Base Station (BS) to the user is
adopted to enable dynamic power control of the user pilot transmissions in the
uplink. A novel multi-agent algorithm for the joint control of the RIS phase
configuration and the user transmit power is presented, which is based on a
hybrid approach integrating NeuroEvolution (NE) and supervised learning. The
proposed scheme requires only single-bit feedback messages for the uplink power
control, supports RIS elements with discrete responses, and is numerically
shown to outperform fingerprinting, deep reinforcement learning baselines and
backpropagation-based position estimators.

</details>


### [2] [Leveraging Wireless Sensor Networks for Real-Time Monitoring and Control of Industrial Environments](https://arxiv.org/abs/2510.13820)
*Muhammad Junaid Asif,Shazia Saqib,Rana Fayyaz Ahmad,Hamza Khan*

Main category: cs.NI

TL;DR: 提出基于NRF收发器和Arduino的物联网系统，通过无线传感器网络实时监测工业参数（温度、湿度、土壤湿度、火灾检测），并支持远程控制直流电机速度，提升工业操作效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决传统有线通信系统的局限性，减少物理监控需求，应对2020-2024年全球工业火灾频发问题，提升工业自动化水平和安全响应能力。

Method: 使用NRF收发器构建无线传感器网络，Arduino微控制器作为中央处理单元，集成多种传感器监测关键工业参数，并通过互联网实现远程监控和控制功能。

Result: 系统成功实现了工业参数的实时监测和远程控制，无线通信创新在工业过程自动化和安全中发挥关键作用，为智能响应操作环境铺平道路。

Conclusion: 物联网与无线传感器网络的整合显著降低了物理监控相关风险，在紧急情况下提供快速响应，有望在各种工业应用中革新监控和控制方式，提高生产力和安全性。

Abstract: This research proposes an extensive technique for monitoring and controlling
the industrial parameters using Internet of Things (IoT) technology based on
wireless communication. We proposed a system based on NRF transceivers to
establish a strong Wireless Sensor Network (WSN), enabling transfer of
real-time data from multiple sensors to a central setup that is driven by
ARDUINO microcontrollers. Different key parameters, crucial for industrial
setup such as temperature, humidity, soil moisture and fire detection, are
monitored and displayed on an LCD screen, enabling factory administration to
oversee the industrial operations remotely over the internet. Our proposed
system bypasses the need for physical presence for monitoring by addressing the
shortcomings of conventional wired communication systems. Other than
monitoring, there is an additional feature to remotely control these parameters
by controlling the speed of DC motors through online commands. Given the rising
incidence of industrial fires over the worldwide between 2020 and 2024 due to
an array of hazards, this system with dual functionality boosts the overall
operational efficiency and safety. This overall integration of IoT and Wireless
Sensor Network (WSN) reduces the potential risks linked with physical
monitoring, providing rapid responses in emergency scenarios, including the
activation of firefighting equipment. The results show that innovations in
wireless communication perform an integral part in industrial process
automation and safety, paving the way to more intelligent and responsive
operating environments. Overall, this study highlights the potential for change
of IoT-enabled systems to revolutionize monitoring and control in a variety of
industrial applications, resulting in increased productivity and safety.

</details>


### [3] [LLM Agent Communication Protocol (LACP) Requires Urgent Standardization: A Telecom-Inspired Protocol is Necessary](https://arxiv.org/abs/2510.13821)
*Xin Li,Mengbing Liu,Chau Yuen*

Main category: cs.NI

TL;DR: 提出LLM-Agent通信协议(LACP)，采用三层架构确保语义清晰、事务完整性和安全性，解决当前LLM代理通信碎片化问题，为下一代网络中的分布式AI提供统一通信标准。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理的临时通信方法导致生态系统碎片化，阻碍创新并带来重大风险，类似于早期网络协议战争的情况。

Method: 借鉴电信分层标准化协议，提出三层架构的LACP协议，确保语义清晰、事务完整性和内置安全机制。

Result: 提出了一种统一通信协议框架，为LLM代理在6G及以后网络中的安全可靠运行奠定基础。

Conclusion: 采用原则性、通用协议对于实现分布式AI潜力至关重要，特别是在6G等复杂实时应用场景中确保多代理系统的安全可靠运行。

Abstract: This position paper argues that the field of LLM agents requires a unified,
telecom-inspired communication protocol to ensure safety, interoperability, and
scalability, especially within the context of Next Generation (NextG) networks.
Current ad-hoc communication methods are creating a fragmented ecosystem,
reminiscent of the early "protocol wars" in networking, which stifles
innovation and poses significant risks. Drawing inspiration from the layered,
standardized protocols that underpin modern telecommunications, we propose the
LLM-Agent Communication Protocol (LACP). LACP establishes a three-layer
architecture designed to ensure semantic clarity in communication,
transactional integrity for complex tasks, and robust, built-in security. In
this position paper, we argue that adopting a principled, universal protocol is
not merely beneficial but essential for realizing the potential of distributed
AI. Such a standard is critical for ensuring that multi-agent systems can
operate safely and reliably in the complex, real-time applications envisioned
for 6G and beyond.

</details>


### [4] [A Simulator for FANETs Using 5G Vehicle-to-Everything Communications and Named-Data Networking](https://arxiv.org/abs/2510.13823)
*José Manuel Rúa-Estévez,Alicia Meleiro-Estévez,Pablo Fondo-Ferreiro,Felipe Gil-Castiñeira,Brais Sánchez-Rama,Lois Gomez-Gonzalez*

Main category: cs.NI

TL;DR: 开发了一个用于验证、评估和演示飞行自组织网络(FANETs)的模拟器，该模拟器集成了ns-3网络模拟器和Zenoh NDN协议，支持基于5G V2X通信和命名数据网络范式的多无人机多跳通信应用测试。


<details>
  <summary>Details</summary>
Motivation: 随着无人机应用的普及，需要一种能够真实测试多无人机间通信的模拟平台，特别是在使用5G V2X通信和NDN范式的情况下，现有工具难以满足这种特定场景的需求。

Method: 将ns-3网络模拟器与Zenoh NDN协议集成，构建了一个专门针对FANETs的模拟环境，支持基于5G V2X通信的多跳通信场景模拟。

Result: 成功开发了一个能够进行多无人机间多跳通信应用测试的模拟器，为FANETs的验证和评估提供了有效的工具。

Conclusion: 该模拟器为基于5G V2X和NDN的飞行自组织网络研究提供了一个实用的测试平台，有助于推动相关技术的发展和应用验证。

Abstract: This work presents a simulator designed for the validation, evaluation, and
demonstration of flying adhoc networks (FANETs) using 5G vehicle-to-everything
(V2X) communications and the named-data networking (NDN) paradigm. The
simulator integrates the ns-3 network simulator and the Zenoh NDN protocol,
enabling realistic testing of applications that involve the multi-hop
communication among multiple unmanned aerial vehicles (UAVs).

</details>


### [5] [DiffLoc: Diffusion Model-Based High-Precision Positioning for 6G Networks](https://arxiv.org/abs/2510.14111)
*Taekyun Lee,Tommaso Balercia,Heasung Kim,Hyeji Kim,Jeffrey G. Andrews*

Main category: cs.NI

TL;DR: DiffLoc框架使用条件生成扩散模型直接从大规模MIMO信道状态信息实现亚厘米级精度的室外用户设备定位，相比现有方法提升了一个数量级。


<details>
  <summary>Details</summary>
Motivation: 传统指纹定位方法难以扩展到大型动态室外环境，需要密集且不切实际的数据测量。需要克服这些限制，直接从原始上行链路参考信号指纹学习到连续地理坐标的映射。

Method: 应用条件生成扩散模型处理高维大规模MIMO信道状态信息，通过一致性训练将推理步骤从200步减少到2步，学习从SRS指纹到地理坐标的直接映射。

Result: 在逼真的东京城市宏小区环境中，DiffLoc-CT模型实现了0.5厘米的融合精度和1-2厘米的单基站精度，相比监督回归方法（超过10米误差）和基于网格的融合（3米误差）有数量级提升。

Conclusion: 该框架即使在高速用户（15-25米/秒）和未见过的用户轨迹下也能保持卓越精度，证明了其实时6G应用的实用可行性。

Abstract: This paper introduces a novel framework for high-accuracy outdoor user
equipment (UE) positioning that applies a conditional generative diffusion
model directly to high-dimensional massive MIMO channel state information
(CSI). Traditional fingerprinting methods struggle to scale to large, dynamic
outdoor environments and require dense, impractical data surveys. To overcome
these limitations, our approach learns a direct mapping from raw uplink
Sounding Reference Signal (SRS) fingerprints to continuous geographic
coordinates. We demonstrate that our DiffLoc framework achieves unprecedented
sub-centimeter precision, with our best model (DiffLoc-CT) delivering 0.5 cm
fusion accuracy and 1-2 cm single base station (BS) accuracy in a realistic,
ray-traced Tokyo urban macro-cell environment. This represents an
order-of-magnitude improvement over existing methods, including supervised
regression approaches (over 10 m error) and grid-based fusion (3 m error). Our
consistency training approach reduces inference time from 200 steps to just 2
steps while maintaining exceptional accuracy even for high-speed users (15-25
m/s) and unseen user trajectories, demonstrating the practical feasibility of
our framework for real-time 6G applications.

</details>


### [6] [Energy-Latency Optimization for Dynamic 5G Mobile Radio Access Networks](https://arxiv.org/abs/2510.14214)
*Gabriela N. Caspa H.,Carlos A. Astudillo,Nelson L. S. da Fonseca*

Main category: cs.NI

TL;DR: 提出一个混合整数线性规划模型，通过三个目标函数优化5G RAN配置：最小化前传延迟、最小化能耗、以及平衡延迟和能耗的双目标优化，确定最佳功能分割选项、RAN功能放置和路由。


<details>
  <summary>Details</summary>
Motivation: 5G网络中基站解耦和新服务对RAN配置提出挑战，需要在满足带宽和延迟约束的同时，解决能耗问题，因为RAN运营占移动网络运营商运营支出的主要部分。

Method: 使用混合整数线性规划模型，提出三种目标函数优化方法，并开发启发式算法来处理MILP执行时间长的问题，结合时间敏感网络建模进行延迟分析。

Result: 揭示了延迟和能耗之间的权衡关系，强调了动态RAN重新配置的必要性，为优化现有和未来RAN部署提供了基础。

Conclusion: 提出的优化模型和算法能够有效平衡服务性能与成本效益的能耗，为5G RAN配置提供了实用的解决方案。

Abstract: In 5G networks, base station (BS) disaggregation and new services present
challenges in radio access network (RAN) configuration, particularly in meeting
their bandwidth and latency constraints. The BS disaggregation is enabled by
functional splitting (FS), which distributes the RAN functions in processing
nodes and alleviates latency and bandwidth requirements in the fronthaul (FH).
Besides network performance, energy consumption is a critical concern for
mobile network operators (MNO), since RAN operation constitutes a major portion
of their operational expenses (OPEX). RAN configuration optimization is
essential to balance service performance with cost-effective energy
consumption. In this paper, we propose a mixed-integer linear programming
(MILP) model formulated with three objective functions: (i) minimizing
fronthaul (FH) latency, (ii) minimizing energy consumption, and (iii) a
bi-objective optimization that jointly balances both latency and energy
consumption. The model determines the optimal FS option, RAN function
placement, and routing for eMBB, URLLC, and mMTC slices. Although prior studies
have addressed RAN configuration either from an energy minimization or latency
reduction perspective, few have considered both aspects in realistic scenarios.
Our evaluation spans different topologies, accounts for variations in
aggregated gNB demand, explores diverse FS combinations, and incorporates Time
Sensitive Networking (TSN) modeling for latency analysis, as it is also crucial
in RAN performance. Given that MILP's execution time can be significant, we
propose a heuristic algorithm that adheres to RAN constraints. Our results
reveal a trade-off between latency and energy consumption, highlighting the
need for dynamic RAN reconfiguration. These insights provide a foundation to
optimize existing and future RAN deployments.

</details>


### [7] [Automated Extraction of Protocol State Machines from 3GPP Specifications with Domain-Informed Prompts and LLM Ensembles](https://arxiv.org/abs/2510.14348)
*Miao Zhang,Runhan Feng,Hongbo Tang,Yu Zhao,Jie Yang,Hang Qiu,Qi Liu*

Main category: cs.NI

TL;DR: SpecGPT是一个利用大型语言模型从3GPP文档中自动提取协议状态机的新框架，通过段落分割、领域知识提示和集成方法，在5G协议建模方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 移动通信网络对关键基础设施至关重要，但其安全性和可靠性依赖于准确的状态机建模。传统手动建模方法劳动密集、易出错且难以维护，而现有NLP方法难以处理蜂窝协议的规模和复杂性。

Method: 提出SpecGPT框架：将技术规范分割为有意义的段落，应用带有思维链推理的领域知识提示，并采用集成方法提高输出可靠性。

Result: 在三个代表性5G协议（NAS、NGAP和PFCP）上使用人工标注的真实数据进行评估，显示SpecGPT优于现有方法。

Conclusion: 证明了大型语言模型在大规模协议建模中的有效性，为自动提取协议状态机提供了可行方案。

Abstract: Mobile telecommunication networks are foundational to global infrastructure
and increasingly support critical sectors such as manufacturing,
transportation, and healthcare. The security and reliability of these networks
are essential, yet depend heavily on accurate modeling of underlying protocols
through state machines. While most prior work constructs such models manually
from 3GPP specifications, this process is labor-intensive, error-prone, and
difficult to maintain due to the complexity and frequent updates of the
specifications. Recent efforts using natural language processing have shown
promise, but remain limited in handling the scale and intricacy of cellular
protocols. In this work, we propose SpecGPT, a novel framework that leverages
large language models (LLMs) to automatically extract protocol state machines
from 3GPP documents. SpecGPT segments technical specifications into meaningful
paragraphs, applies domain-informed prompting with chain-of-thought reasoning,
and employs ensemble methods to enhance output reliability. We evaluate SpecGPT
on three representative 5G protocols (NAS, NGAP, and PFCP) using manually
annotated ground truth, and show that it outperforms existing approaches,
demonstrating the effectiveness of LLMs for protocol modeling at scale.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [Decision Oriented Technique (DOTechnique): Finding Model Validity Through Decision-Maker Context](https://arxiv.org/abs/2510.13858)
*Raheleh Biglari,Joachim Denil*

Main category: cs.AI

TL;DR: 提出了一种基于决策一致性的模型有效性验证方法DOTechnique，通过评估替代模型是否与高保真模型产生相同决策来确定有效性区域，无需预定义有效性边界。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖预定义的有效性框架，但这些框架可能不可用或不充分。需要一种能够基于决策一致性来确定模型有效性的新方法。

Method: DOTechnique方法通过评估替代模型与高保真模型在决策上的一致性来确定有效性，结合领域约束和符号推理来缩小搜索空间，提高计算效率。

Result: 以高速公路变道系统为例，展示了DOTechnique能够有效发现仿真模型的有效性区域。

Conclusion: 该技术有潜力通过决策者上下文来支持模型有效性的发现，为模型验证提供了新的视角。

Abstract: Model validity is as critical as the model itself, especially when guiding
decision-making processes. Traditional approaches often rely on predefined
validity frames, which may not always be available or sufficient. This paper
introduces the Decision Oriented Technique (DOTechnique), a novel method for
determining model validity based on decision consistency rather than output
similarity. By evaluating whether surrogate models lead to equivalent decisions
compared to high-fidelity models, DOTechnique enables efficient identification
of validity regions, even in the absence of explicit validity boundaries. The
approach integrates domain constraints and symbolic reasoning to narrow the
search space, enhancing computational efficiency. A highway lane change system
serves as a motivating example, demonstrating how DOTechnique can uncover the
validity region of a simulation model. The results highlight the potential of
the technique to support finding model validity through decision-maker context.

</details>


### [9] [Do Slides Help? Multi-modal Context for Automatic Transcription of Conference Talks](https://arxiv.org/abs/2510.13979)
*Supriti Sinhamahapatra,Jan Niehues*

Main category: cs.AI

TL;DR: 该论文提出了一种融合视觉信息（演讲幻灯片）的多模态自动语音识别方法，针对科学演讲场景，通过数据增强技术解决了数据集不足的问题，显著降低了词错误率。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的ASR系统主要依赖声学信息而忽略了多模态上下文。视觉信息对于消歧和适应至关重要，特别是在科学演讲场景中，演讲幻灯片包含重要的领域特定术语信息。

Method: 首先创建多模态演讲基准，然后探索用多模态信息增强语音模型的方法。通过数据增强技术解决缺乏配套幻灯片数据集的问题，最后使用增强数据集训练模型。

Result: 训练得到的模型在所有词汇上相对基线模型词错误率降低了约34%，在领域特定术语上降低了约35%。

Conclusion: 融合视觉信息（特别是演讲幻灯片）的多模态方法能显著提升ASR系统在科学演讲场景中的性能，特别是在处理领域特定术语方面效果显著。

Abstract: State-of-the-art (SOTA) Automatic Speech Recognition (ASR) systems primarily
rely on acoustic information while disregarding additional multi-modal context.
However, visual information are essential in disambiguation and adaptation.
While most work focus on speaker images to handle noise conditions, this work
also focuses on integrating presentation slides for the use cases of scientific
presentation.
  In a first step, we create a benchmark for multi-modal presentation including
an automatic analysis of transcribing domain-specific terminology. Next, we
explore methods for augmenting speech models with multi-modal information. We
mitigate the lack of datasets with accompanying slides by a suitable approach
of data augmentation. Finally, we train a model using the augmented dataset,
resulting in a relative reduction in word error rate of approximately 34%,
across all words and 35%, for domain-specific terms compared to the baseline
model.

</details>


### [10] [Do Large Language Models Show Biases in Causal Learning? Insights from Contingency Judgment](https://arxiv.org/abs/2510.13985)
*María Victoria Carro,Denise Alejandra Mester,Francisca Gauna Selasco,Giovanni Franco Gabriel Marraffini,Mario Alejandro Leiva,Gerardo I. Simari,María Vanina Martinez*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在零相关情境下会系统性地产生因果幻觉，错误推断不存在因果关系，这挑战了LLMs真正理解因果关系的假设。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型是否像人类一样容易产生因果幻觉，特别是在医学等需要准确因果推理的领域中，这对LLMs的实际应用具有重要意义。

Method: 构建了1000个医学领域的零相关情境数据集，使用经典认知科学范式——列联判断任务，让LLMs评估潜在原因的效力。

Result: 所有评估的模型都系统性地推断出无根据的因果关系，显示出对因果幻觉的强烈易感性。

Conclusion: 研究结果支持LLMs只是复制因果语言而非真正理解因果关系的假设，对在需要准确因果推理的领域中使用语言模型提出了担忧。

Abstract: Causal learning is the cognitive process of developing the capability of
making causal inferences based on available information, often guided by
normative principles. This process is prone to errors and biases, such as the
illusion of causality, in which people perceive a causal relationship between
two variables despite lacking supporting evidence. This cognitive bias has been
proposed to underlie many societal problems, including social prejudice,
stereotype formation, misinformation, and superstitious thinking. In this work,
we examine whether large language models are prone to developing causal
illusions when faced with a classic cognitive science paradigm: the contingency
judgment task. To investigate this, we constructed a dataset of 1,000 null
contingency scenarios (in which the available information is not sufficient to
establish a causal relationship between variables) within medical contexts and
prompted LLMs to evaluate the effectiveness of potential causes. Our findings
show that all evaluated models systematically inferred unwarranted causal
relationships, revealing a strong susceptibility to the illusion of causality.
While there is ongoing debate about whether LLMs genuinely understand causality
or merely reproduce causal language without true comprehension, our findings
support the latter hypothesis and raise concerns about the use of language
models in domains where accurate causal reasoning is essential for informed
decision-making.

</details>


### [11] [GammaZero: Learning To Guide POMDP Belief Space Search With Graph Representations](https://arxiv.org/abs/2510.14035)
*Rajesh Mangannavar,Prasad Tadepalli*

Main category: cs.AI

TL;DR: GammaZero提出了一个以动作为中心的图表示框架，用于在部分可观察马尔可夫决策过程（POMDPs）中学习指导规划。该方法通过图神经网络从专家演示中学习价值函数和策略，并能零样本泛化到比训练时大2-4倍的问题规模。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要领域特定的神经网络架构且难以扩展，GammaZero旨在开发一个统一的基于图的信念表示框架，能够在领域内跨问题规模实现泛化。

Method: 将信念状态系统性地转换为以动作为中心的图，使用图神经网络和编码器架构从专家演示中学习价值函数和策略，然后将学习到的启发式方法应用于蒙特卡洛树搜索来指导更大问题的规划。

Result: 在标准POMDP基准测试中，GammaZero在相同规模问题上与BetaZero性能相当，同时能够零样本泛化到比训练时大2-4倍的问题，在减少搜索需求的同时保持解的质量。

Conclusion: GammaZero通过以动作为中心的图表示框架，成功实现了在POMDPs中的可扩展规划，展示了跨问题规模的泛化能力，为大规模部分可观察环境中的规划问题提供了有效解决方案。

Abstract: We introduce an action-centric graph representation framework for learning to
guide planning in Partially Observable Markov Decision Processes (POMDPs).
Unlike existing approaches that require domain-specific neural architectures
and struggle with scalability, GammaZero leverages a unified graph-based belief
representation that enables generalization across problem sizes within a
domain. Our key insight is that belief states can be systematically transformed
into action-centric graphs where structural patterns learned on small problems
transfer to larger instances. We employ a graph neural network with a decoder
architecture to learn value functions and policies from expert demonstrations
on computationally tractable problems, then apply these learned heuristics to
guide Monte Carlo tree search on larger problems. Experimental results on
standard POMDP benchmarks demonstrate that GammaZero achieves comparable
performance to BetaZero when trained and tested on the same-sized problems,
while uniquely enabling zero-shot generalization to problems 2-4 times larger
than those seen during training, maintaining solution quality with reduced
search requirements.

</details>


### [12] [Position: Require Frontier AI Labs To Release Small "Analog" Models](https://arxiv.org/abs/2510.14053)
*Shriyash Upadhyay,Chaithanya Bandi,Narmeen Oozeer,Philip Quirke*

Main category: cs.AI

TL;DR: 本文提出了一种替代性监管方法：要求大型AI实验室发布小型、开放的类比模型，这些模型经过类似训练并从其最大专有模型中蒸馏而来，以在确保AI安全的同时积极促进创新。


<details>
  <summary>Details</summary>
Motivation: 当前前沿AI模型的监管提案因安全与创新的权衡而被搁置，需要一种既能确保安全又不阻碍创新的监管方法。

Method: 强制要求大型AI实验室发布小型、可公开访问的类比模型，这些模型作为公共代理，允许广泛参与安全验证、可解释性研究和算法透明度工作。

Result: 类比模型使更广泛的研究社区能够直接研究和创新，显著减少监管负担并加速安全进步，同时成本最小。

Conclusion: 这种监管方法不仅应该被采纳，而且展示了一个支持机器学习基础研究的更广泛原则：对模型的深入理解能够缓解安全与创新的权衡，让我们同时获得更多安全与创新。

Abstract: Recent proposals for regulating frontier AI models have sparked concerns
about the cost of safety regulation, and most such regulations have been
shelved due to the safety-innovation tradeoff. This paper argues for an
alternative regulatory approach that ensures AI safety while actively promoting
innovation: mandating that large AI laboratories release small, openly
accessible analog models (scaled-down versions) trained similarly to and
distilled from their largest proprietary models.
  Analog models serve as public proxies, allowing broad participation in safety
verification, interpretability research, and algorithmic transparency without
forcing labs to disclose their full-scale models. Recent research demonstrates
that safety and interpretability methods developed using these smaller models
generalize effectively to frontier-scale systems. By enabling the wider
research community to directly investigate and innovate upon accessible
analogs, our policy substantially reduces the regulatory burden and accelerates
safety advancements.
  This mandate promises minimal additional costs, leveraging reusable resources
like data and infrastructure, while significantly contributing to the public
good. Our hope is not only that this policy be adopted, but that it illustrates
a broader principle supporting fundamental research in machine learning: deeper
understanding of models relaxes the safety-innovation tradeoff and lets us have
more of both.

</details>


### [13] [Generating Fair Consensus Statements with Social Choice on Token-Level MDPs](https://arxiv.org/abs/2510.14106)
*Carter Blair,Kate Larson*

Main category: cs.AI

TL;DR: 本文提出了一种基于多目标马尔可夫决策过程的共识声明生成框架，通过社会选择理论保证公平性，包括两种方法：随机生成策略保证核心稳定性，以及搜索算法最大化平等主义福利。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型共识声明生成框架缺乏提供可证明公平性保证的结构，无法在聚合多样化自由形式意见时确保公平性。

Method: 将任务建模为多目标、令牌级的马尔可夫决策过程，每个目标对应一个代理的偏好。提出两种基于社会选择理论的方法：保证处于事前核心的随机生成策略，以及使用搜索算法最大化平等主义福利的单一声明生成方法。

Result: 实验表明，基于平等主义目标的搜索生成的共识声明在代理对齐的最坏情况下优于基线方法，包括Habermas Machine。

Conclusion: 该框架为共识声明生成提供了具有可证明公平性保证的结构化方法，通过社会选择理论原则实现了更好的代理对齐。

Abstract: Current frameworks for consensus statement generation with large language
models lack the inherent structure needed to provide provable fairness
guarantees when aggregating diverse free-form opinions. We model the task as a
multi-objective, token-level Markov Decision Process (MDP), where each
objective corresponds to an agent's preference. Token-level rewards for each
agent are derived from their policy (e.g., a personalized language model). This
approach utilizes the finding that such policies implicitly define optimal
Q-functions, providing a principled way to quantify rewards at each generation
step without a value function (Rafailov et al., 2024). This MDP formulation
creates a formal structure amenable to analysis using principles from social
choice theory. We propose two approaches grounded in social choice theory.
First, we propose a stochastic generation policy guaranteed to be in the
ex-ante core, extending core stability concepts from voting theory to text
generation. This policy is derived from an underlying distribution over
complete statements that maximizes proportional fairness (Nash Welfare).
Second, for generating a single statement, we target the maximization of
egalitarian welfare using search algorithms within the MDP framework.
Empirically, experiments using language models to instantiate agent policies
show that search guided by the egalitarian objective generates consensus
statements with improved worst-case agent alignment compared to baseline
methods, including the Habermas Machine (Tessler et al., 2024).

</details>


### [14] [STEMS: Spatial-Temporal Enhanced Safe Multi-Agent Coordination for Building Energy Management](https://arxiv.org/abs/2510.14112)
*Huiliang Zhang,Di Wu,Arnaud Zinflou,Benoit Boulet*

Main category: cs.AI

TL;DR: 提出STEMS框架，一个安全约束的多智能体强化学习系统，用于协调建筑能源管理，通过空间-时间图表示学习和控制屏障函数实现安全保证。


<details>
  <summary>Details</summary>
Motivation: 解决多建筑能源系统中空间-时间依赖性利用不足、缺乏严格安全保证和系统复杂性等关键挑战，实现碳减排、提升居住舒适度和降低能源成本。

Method: 集成两个核心组件：(1) 使用GCN-Transformer融合架构的空间-时间图表示学习框架，捕捉建筑间关系和时序模式；(2) 结合控制屏障函数的安全约束多智能体RL算法，提供数学安全保证。

Result: 在真实建筑数据集上的实验显示，STEMS相比现有方法实现了21%成本降低、18%排放减少，安全违规从35.1%降至5.6%，同时保持最佳舒适度（仅0.13不适比例）。

Conclusion: STEMS框架在极端天气条件下表现出强大鲁棒性，在不同建筑类型中保持有效性，为协调建筑能源管理提供了有效的安全约束解决方案。

Abstract: Building energy management is essential for achieving carbon reduction goals,
improving occupant comfort, and reducing energy costs. Coordinated building
energy management faces critical challenges in exploiting spatial-temporal
dependencies while ensuring operational safety across multi-building systems.
Current multi-building energy systems face three key challenges: insufficient
spatial-temporal information exploitation, lack of rigorous safety guarantees,
and system complexity. This paper proposes Spatial-Temporal Enhanced Safe
Multi-Agent Coordination (STEMS), a novel safety-constrained multi-agent
reinforcement learning framework for coordinated building energy management.
STEMS integrates two core components: (1) a spatial-temporal graph
representation learning framework using a GCN-Transformer fusion architecture
to capture inter-building relationships and temporal patterns, and (2) a
safety-constrained multi-agent RL algorithm incorporating Control Barrier
Functions to provide mathematical safety guarantees. Extensive experiments on
real-world building datasets demonstrate STEMS's superior performance over
existing methods, showing that STEMS achieves 21% cost reduction, 18% emission
reduction, and dramatically reduces safety violations from 35.1% to 5.6% while
maintaining optimal comfort with only 0.13 discomfort proportion. The framework
also demonstrates strong robustness during extreme weather conditions and
maintains effectiveness across different building types.

</details>


### [15] [Formalizing the Safety, Security, and Functional Properties of Agentic AI Systems](https://arxiv.org/abs/2510.14133)
*Edoardo Allegrini,Ananth Shreekumar,Z. Berkay Celik*

Main category: cs.AI

TL;DR: 提出了一个建模框架来解决多智能体AI系统中的语义鸿沟问题，通过主机智能体模型和任务生命周期模型提供统一语义框架，并定义了31个形式化属性来验证系统行为。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体AI系统的通信协议碎片化，导致无法进行严格的系统属性分析，存在架构错位和可被利用的协调问题等风险。

Method: 引入两个基础模型：主机智能体模型（负责与用户交互、任务分解和编排）和任务生命周期模型（详细描述子任务从创建到完成的状态转换），并定义了17个主机智能体属性和14个任务生命周期属性。

Result: 建立了首个严格基础、领域无关的框架，用于系统分析、设计和部署正确、可靠和鲁棒的多智能体AI系统，支持形式化验证和协调边缘情况检测。

Conclusion: 该框架为多AI智能体系统的行为推理提供了统一的语义基础，能够预防死锁和安全漏洞，提高系统的可靠性和鲁棒性。

Abstract: Agentic AI systems, which leverage multiple autonomous agents and Large
Language Models (LLMs), are increasingly used to address complex, multi-step
tasks. The safety, security, and functionality of these systems are critical,
especially in high-stakes applications. However, the current ecosystem of
inter-agent communication is fragmented, with protocols such as the Model
Context Protocol (MCP) for tool access and the Agent-to-Agent (A2A) protocol
for coordination being analyzed in isolation. This fragmentation creates a
semantic gap that prevents the rigorous analysis of system properties and
introduces risks such as architectural misalignment and exploitable
coordination issues. To address these challenges, we introduce a modeling
framework for agentic AI systems composed of two foundational models. The
first, the host agent model, formalizes the top-level entity that interacts
with the user, decomposes tasks, and orchestrates their execution by leveraging
external agents and tools. The second, the task lifecycle model, details the
states and transitions of individual sub-tasks from creation to completion,
providing a fine-grained view of task management and error handling. Together,
these models provide a unified semantic framework for reasoning about the
behavior of multi-AI agent systems. Grounded in this framework, we define 17
properties for the host agent and 14 for the task lifecycle, categorized into
liveness, safety, completeness, and fairness. Expressed in temporal logic,
these properties enable formal verification of system behavior, detection of
coordination edge cases, and prevention of deadlocks and security
vulnerabilities. Through this effort, we introduce the first rigorously
grounded, domain-agnostic framework for the systematic analysis, design, and
deployment of correct, reliable, and robust agentic AI systems.

</details>


### [16] [The Gatekeeper Knows Enough](https://arxiv.org/abs/2510.14881)
*Fikresilase Wondmeneh Abebayew*

Main category: cs.AI

TL;DR: 提出了Gatekeeper协议，一个领域无关的框架，通过让智能体先在低保真度的潜在状态表示上操作和推理，然后按需请求高保真度上下文，来解决LLM智能体的上下文窗口限制和状态不同步问题。


<details>
  <summary>Details</summary>
Motivation: LLM作为自主智能体部署时，受限于有限的上下文窗口和状态不同步，导致输出不可靠、行为不可预测、资源使用效率低，特别是在与大型结构化知识系统交互时。

Method: 引入Gatekeeper协议，要求智能体先在低保真度的潜在状态表示上操作和推理，然后战略性地按需请求高保真度上下文。所有交互通过统一的JSON格式进行，作为声明式的状态同步协议。

Result: 在软件开发的参考实现Sage中，该方法显著提高了智能体可靠性，通过最小化token消耗改善了计算效率，并实现了与复杂系统的可扩展交互。

Conclusion: Gatekeeper协议为在任何结构化知识领域构建更稳健、可预测和接地气的AI智能体提供了基础方法学。

Abstract: Large Language Models (LLMs) are increasingly deployed as autonomous agents,
yet their practical utility is fundamentally constrained by a limited context
window and state desynchronization resulting from the LLMs' stateless nature
and inefficient context management. These limitations lead to unreliable
output, unpredictable behavior, and inefficient resource usage, particularly
when interacting with large, structured, and sensitive knowledge systems such
as codebases and documents. To address these challenges, we introduce the
Gatekeeper Protocol, a novel, domain-agnostic framework that governs
agent-system interactions. Our protocol mandates that the agent first operate
and reason on a minimalist, low-fidelity "latent state" representation of the
system to strategically request high-fidelity context on demand. All
interactions are mediated through a unified JSON format that serves as a
declarative, state-synchronized protocol, ensuring the agent's model of the
system remains verifiably grounded in the system's reality. We demonstrate the
efficacy of this protocol with Sage, a reference implementation of the
Gatekeeper Protocol for software development. Our results show that this
approach significantly increases agent reliability, improves computational
efficiency by minimizing token consumption, and enables scalable interaction
with complex systems, creating a foundational methodology for building more
robust, predictable, and grounded AI agents for any structured knowledge
domain.

</details>


### [17] [A Multimodal Approach to Heritage Preservation in the Context of Climate Change](https://arxiv.org/abs/2510.14136)
*David Roqui,Adèle Cormier,nistor Grozavu,Ann Bourges*

Main category: cs.AI

TL;DR: 提出轻量级多模态架构，融合传感器数据和视觉图像预测文化遗产地退化严重程度，在数据稀缺情况下实现76.9%准确率


<details>
  <summary>Details</summary>
Motivation: 文化遗产地因气候变化加速退化，传统单模态监测方法无法捕捉环境压力与材料退化之间的复杂相互作用

Method: 采用简化的PerceiverIO架构，包含64D潜在空间的简化编码器，并使用自适应Barlow Twins损失函数鼓励模态互补性

Result: 在斯特拉斯堡大教堂数据上达到76.9%准确率，比标准多模态架构提升43%，比单模态方法提升显著

Conclusion: 架构简化结合对比正则化可在数据稀缺的遗产监测环境中实现有效的多模态学习，为AI驱动的保护决策支持系统奠定基础

Abstract: Cultural heritage sites face accelerating degradation due to climate change,
yet tradi- tional monitoring relies on unimodal analysis (visual inspection or
environmental sen- sors alone) that fails to capture the complex interplay
between environmental stres- sors and material deterioration. We propose a
lightweight multimodal architecture that fuses sensor data (temperature,
humidity) with visual imagery to predict degradation severity at heritage
sites. Our approach adapts PerceiverIO with two key innovations: (1) simplified
encoders (64D latent space) that prevent overfitting on small datasets (n=37
training samples), and (2) Adaptive Barlow Twins loss that encourages modality
complementarity rather than redundancy. On data from Strasbourg Cathedral, our
model achieves 76.9% accu- racy, a 43% improvement over standard multimodal
architectures (VisualBERT, Trans- former) and 25% over vanilla PerceiverIO.
Ablation studies reveal that sensor-only achieves 61.5% while image-only
reaches 46.2%, confirming successful multimodal synergy. A systematic
hyperparameter study identifies an optimal moderate correlation target ({\tau}
=0.3) that balances align- ment and complementarity, achieving 69.2% accuracy
compared to other {\tau} values ({\tau} =0.1/0.5/0.7: 53.8%, {\tau} =0.9:
61.5%). This work demonstrates that architectural sim- plicity combined with
contrastive regularization enables effective multimodal learning in data-scarce
heritage monitoring contexts, providing a foundation for AI-driven con-
servation decision support systems.

</details>


### [18] [CodeEvolve: An open source evolutionary coding agent for algorithm discovery and optimization](https://arxiv.org/abs/2510.14150)
*Henrique Assumpção,Diego Ferreira,Leandro Campos,Fabricio Murai*

Main category: cs.AI

TL;DR: CodeEvolve是一个开源进化编码代理，结合大型语言模型和遗传算法解决复杂计算问题，在多个数学基准测试中超越了Google DeepMind的AlphaEvolve。


<details>
  <summary>Details</summary>
Motivation: 将强大的进化概念应用于LLM领域，基于广义科学发现的最新方法，解决复杂计算问题，并促进开源协作。

Method: 采用基于岛屿的遗传算法保持种群多样性，引入基于启发的交叉机制利用LLM上下文窗口组合成功解决方案特征，实现元提示策略动态探索解空间。

Result: 在用于评估Google DeepMind闭源AlphaEvolve的数学基准测试子集上，CodeEvolve在多个挑战性问题上的表现超越了AlphaEvolve。

Conclusion: CodeEvolve成功展示了将进化算法与LLM结合的有效性，通过开源框架促进协作和加速进展。

Abstract: In this work, we introduce CodeEvolve, an open-source evolutionary coding
agent that unites Large Language Models (LLMs) with genetic algorithms to solve
complex computational problems. Our framework adapts powerful evolutionary
concepts to the LLM domain, building upon recent methods for generalized
scientific discovery. CodeEvolve employs an island-based genetic algorithm to
maintain population diversity and increase throughput, introduces a novel
inspiration-based crossover mechanism that leverages the LLMs context window to
combine features from successful solutions, and implements meta-prompting
strategies for dynamic exploration of the solution space. We conduct a rigorous
evaluation of CodeEvolve on a subset of the mathematical benchmarks used to
evaluate Google DeepMind's closed-source AlphaEvolve. Our findings show that
our method surpasses AlphaEvolve's performance on several challenging problems.
To foster collaboration and accelerate progress, we release our complete
framework as an open-source repository.

</details>


### [19] [Combining Reinforcement Learning and Behavior Trees for NPCs in Video Games with AMD Schola](https://arxiv.org/abs/2510.14154)
*Tian Liu,Alex Cann,Ian Colbert,Mehdi Saeedi*

Main category: cs.AI

TL;DR: 本文探讨了在商业视频游戏中应用强化学习（RL）的挑战，提出了将RL与传统行为树（BTs）结合的方法，并通过AMD Schola插件在复杂3D环境中验证了这种方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习研究进展迅速，但在商业视频游戏中的采用仍然缓慢。本文旨在解决游戏AI社区在使用RL驱动的NPC时面临的常见挑战，并探索RL与行为树的结合点。

Method: 使用AMD Schola插件在Unreal Engine中训练RL代理，创建多任务NPC，并在受《最后生还者》启发的复杂3D环境中展示联合训练RL模型与行为树的方法论。

Result: 证明了RL与行为树结合方法的可行性，展示了在复杂环境中训练多任务NPC的各种技能。

Conclusion: RL与行为树的交叉点是一个值得进一步探索的关键节点，虽然已有研究提出这种结合，但实际采用仍然罕见，本文通过实际案例验证了其潜力。

Abstract: While the rapid advancements in the reinforcement learning (RL) research
community have been remarkable, the adoption in commercial video games remains
slow. In this paper, we outline common challenges the Game AI community faces
when using RL-driven NPCs in practice, and highlight the intersection of RL
with traditional behavior trees (BTs) as a crucial juncture to be explored
further. Although the BT+RL intersection has been suggested in several research
papers, its adoption is rare. We demonstrate the viability of this approach
using AMD Schola -- a plugin for training RL agents in Unreal Engine -- by
creating multi-task NPCs in a complex 3D environment inspired by the commercial
video game ``The Last of Us". We provide detailed methodologies for jointly
training RL models with BTs while showcasing various skills.

</details>


### [20] [JEDA: Query-Free Clinical Order Search from Ambient Dialogues](https://arxiv.org/abs/2510.14169)
*Praphul Singh,Corey Barrett,Sumana Srivasta,Amitabh Saikia,Irfan Bulu,Sri Gadde,Krishnaram Kenthapadi*

Main category: cs.AI

TL;DR: JEDA是一个用于临床订单检索的双编码器系统，能够直接从临床对话中检索规范订单，支持显式查询和无查询模式，通过对比学习对齐异构意图表达。


<details>
  <summary>Details</summary>
Motivation: 临床对话包含显式指令和隐式推理，现有LLM重写方法存在延迟、不稳定和不透明问题，无法满足实时订单需求。

Method: 基于PubMedBERT初始化，使用对比学习目标微调，通过约束LLM指导将签名订单与互补表述绑定，包含查询和无查询两种模式。

Result: JEDA在实践中表现优异，显著优于基础编码器和近期开源嵌入模型，无查询模式对噪声具有鲁棒性。

Conclusion: JEDA提供了一个快速、可解释、无需LLM的检索层，能够实时将环境上下文链接到可操作的临床订单。

Abstract: Clinical conversations mix explicit directives (order a chest X-ray) with
implicit reasoning (the cough worsened overnight, we should check for
pneumonia). Many systems rely on LLM rewriting, adding latency, instability,
and opacity that hinder real-time ordering. We present JEDA (Joint Embedding
for Direct and Ambient clinical orders), a domain-initialized bi-encoder that
retrieves canonical orders directly and, in a query-free mode, encodes a short
rolling window of ambient dialogue to trigger retrieval. Initialized from
PubMedBERT and fine-tuned with a duplicate-safe contrastive objective, JEDA
aligns heterogeneous expressions of intent to shared order concepts. Training
uses constrained LLM guidance to tie each signed order to complementary
formulations (command only, context only, command+context, context+reasoning),
producing clearer inter-order separation, tighter query extendash order
coupling, and stronger generalization. The query-free mode is noise-resilient,
reducing sensitivity to disfluencies and ASR errors by conditioning on a short
window rather than a single utterance. Deployed in practice, JEDA yields large
gains and substantially outperforms its base encoder and recent open embedders
(Linq Embed Mistral, SFR Embedding, GTE Qwen, BGE large, Embedding Gemma). The
result is a fast, interpretable, LLM-free retrieval layer that links ambient
context to actionable clinical orders in real time.

</details>


### [21] [ARM-FM: Automated Reward Machines via Foundation Models for Compositional Reinforcement Learning](https://arxiv.org/abs/2510.14176)
*Roger Creus Castanyer,Faisal Mohamed,Pablo Samuel Castro,Cyrus Neary,Glen Berseth*

Main category: cs.AI

TL;DR: ARM-FM是一个利用基础模型自动生成奖励机器的强化学习框架，能够从自然语言规范自动构建奖励机器，实现任务分解和零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 强化学习算法对奖励函数设计高度敏感，这限制了其广泛应用。现有方法需要手动设计奖励函数，过程复杂且容易出错。

Method: 使用基础模型从自然语言规范自动生成奖励机器，为每个自动机状态关联语言嵌入以实现跨任务泛化，利用奖励机器的结构化形式进行任务分解。

Result: 在多个挑战性环境中验证了ARM-FM的有效性，展示了零样本泛化能力，证明该方法能够成功处理复杂的强化学习任务。

Conclusion: ARM-FM通过结合基础模型和奖励机器，实现了自动化的奖励设计，解决了强化学习中奖励函数设计的核心挑战，为更广泛的RL应用提供了可行方案。

Abstract: Reinforcement learning (RL) algorithms are highly sensitive to reward
function specification, which remains a central challenge limiting their broad
applicability. We present ARM-FM: Automated Reward Machines via Foundation
Models, a framework for automated, compositional reward design in RL that
leverages the high-level reasoning capabilities of foundation models (FMs).
Reward machines (RMs) -- an automata-based formalism for reward specification
-- are used as the mechanism for RL objective specification, and are
automatically constructed via the use of FMs. The structured formalism of RMs
yields effective task decompositions, while the use of FMs enables objective
specifications in natural language. Concretely, we (i) use FMs to automatically
generate RMs from natural language specifications; (ii) associate language
embeddings with each RM automata-state to enable generalization across tasks;
and (iii) provide empirical evidence of ARM-FM's effectiveness in a diverse
suite of challenging environments, including evidence of zero-shot
generalization.

</details>


### [22] [Implementation of AI in Precision Medicine](https://arxiv.org/abs/2510.14194)
*Göktuğ Bender,Samer Faraj,Anand Bhardwaj*

Main category: cs.AI

TL;DR: 对2019-2024年AI在精准医学中实施文献的范围综述，识别关键障碍和促进因素，提出基于生态系统的框架支持可信赖和可持续实施。


<details>
  <summary>Details</summary>
Motivation: AI在精准医学中日益重要，但临床实施仍然有限，需要系统分析实施障碍和促进因素。

Method: 采用范围综述方法，分析2019-2024年文献，识别数据质量、临床可靠性、工作流整合和治理等关键维度的障碍与促进因素。

Result: 建立了基于生态系统的框架，揭示了影响真实世界转化的相互依赖关系，识别了实施过程中的关键挑战。

Conclusion: 提出了支持可信赖和可持续AI实施在精准医学中的未来方向，强调生态系统方法的重要性。

Abstract: Artificial intelligence (AI) has become increasingly central to precision
medicine by enabling the integration and interpretation of multimodal data, yet
implementation in clinical settings remains limited. This paper provides a
scoping review of literature from 2019-2024 on the implementation of AI in
precision medicine, identifying key barriers and enablers across data quality,
clinical reliability, workflow integration, and governance. Through an
ecosystem-based framework, we highlight the interdependent relationships
shaping real-world translation and propose future directions to support
trustworthy and sustainable implementation.

</details>


### [23] [Echoes of Human Malice in Agents: Benchmarking LLMs for Multi-Turn Online Harassment Attacks](https://arxiv.org/abs/2510.14207)
*Trilok Padhi,Pinxian Lu,Abdulkadir Erol,Tanmay Sutar,Gauri Sharma,Mina Sonmez,Munmun De Choudhury,Ugur Kursuncu*

Main category: cs.AI

TL;DR: 提出了一个在线骚扰代理基准，包含多轮骚扰对话数据集、基于重复博弈论的多代理模拟、三种越狱攻击方法和混合评估框架。研究发现越狱调优使骚扰成功率大幅提升，闭源和开源模型表现出不同的升级轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有越狱研究主要关注单轮提示，而真实骚扰往往在多轮交互中展开，需要开发多轮理论驱动的攻击方法来评估LLM代理的安全性。

Method: 构建了包含多轮骚扰对话数据集、基于重复博弈论的多代理模拟、针对记忆、规划和微调的三种越狱攻击方法，以及混合评估框架的基准测试。使用LLaMA-3.1-8B-Instruct和Gemini-2.0-flash两个模型进行实验。

Result: 越狱调优使骚扰成功率从57.25-64.19%提升至95.78-96.89%（Llama），从98.46%提升至99.33%（Gemini）。最常见的毒性行为是侮辱（84.9-87.8% vs 44.2-50.8%）和谩骂（81.2-85.1% vs 31.5-38.8%）。闭源模型表现出显著脆弱性。

Conclusion: 多轮和理论驱动的攻击不仅成功率高，还能模拟人类骚扰动态，需要开发强大的安全防护机制来确保在线平台的安全和负责任。

Abstract: Large Language Model (LLM) agents are powering a growing share of interactive
web applications, yet remain vulnerable to misuse and harm. Prior jailbreak
research has largely focused on single-turn prompts, whereas real harassment
often unfolds over multi-turn interactions. In this work, we present the Online
Harassment Agentic Benchmark consisting of: (i) a synthetic multi-turn
harassment conversation dataset, (ii) a multi-agent (e.g., harasser, victim)
simulation informed by repeated game theory, (iii) three jailbreak methods
attacking agents across memory, planning, and fine-tuning, and (iv) a
mixed-methods evaluation framework. We utilize two prominent LLMs,
LLaMA-3.1-8B-Instruct (open-source) and Gemini-2.0-flash (closed-source). Our
results show that jailbreak tuning makes harassment nearly guaranteed with an
attack success rate of 95.78--96.89% vs. 57.25--64.19% without tuning in Llama,
and 99.33% vs. 98.46% without tuning in Gemini, while sharply reducing refusal
rate to 1-2% in both models. The most prevalent toxic behaviors are Insult with
84.9--87.8% vs. 44.2--50.8% without tuning, and Flaming with 81.2--85.1% vs.
31.5--38.8% without tuning, indicating weaker guardrails compared to sensitive
categories such as sexual or racial harassment. Qualitative evaluation further
reveals that attacked agents reproduce human-like aggression profiles, such as
Machiavellian/psychopathic patterns under planning, and narcissistic tendencies
with memory. Counterintuitively, closed-source and open-source models exhibit
distinct escalation trajectories across turns, with closed-source models
showing significant vulnerability. Overall, our findings show that multi-turn
and theory-grounded attacks not only succeed at high rates but also mimic
human-like harassment dynamics, motivating the development of robust safety
guardrails to ultimately keep online platforms safe and responsible.

</details>


### [24] [LiveResearchBench: A Live Benchmark for User-Centric Deep Research in the Wild](https://arxiv.org/abs/2510.14240)
*Jiayu Wang,Yifei Ming,Riya Dulepet,Qinglin Chen,Austin Xu,Zixuan Ke,Frederic Sala,Aws Albarghouthi,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: LiveResearchBench是一个包含100个专家策划任务的基准测试，用于评估深度研究系统，结合DeepEval评估套件对17个前沿系统进行了全面评估。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在评估深度研究系统时存在不足，往往聚焦于狭窄领域或提出模糊问题，无法公平比较。需要构建符合用户中心、动态性、明确性和多维度搜索要求的评估框架。

Method: 引入LiveResearchBench基准测试（100个任务，涵盖日常生活、企业和学术领域）和DeepEval评估套件（涵盖内容和报告质量的多维度评估），采用四种互补的评估协议确保稳定评估。

Result: 对17个前沿深度研究系统进行了全面评估，揭示了当前系统的优势、常见失败模式以及推进可靠深度研究所需的关键系统组件。

Conclusion: LiveResearchBench和DeepEval为系统评估深度研究能力提供了严格基础，识别了现有系统的局限性和未来发展方向。

Abstract: Deep research -- producing comprehensive, citation-grounded reports by
searching and synthesizing information from hundreds of live web sources --
marks an important frontier for agentic systems. To rigorously evaluate this
ability, four principles are essential: tasks should be (1) user-centric,
reflecting realistic information needs, (2) dynamic, requiring up-to-date
information beyond parametric knowledge, (3) unambiguous, ensuring consistent
interpretation across users, and (4) multi-faceted and search-intensive,
requiring search over numerous web sources and in-depth analysis. Existing
benchmarks fall short of these principles, often focusing on narrow domains or
posing ambiguous questions that hinder fair comparison. Guided by these
principles, we introduce LiveResearchBench, a benchmark of 100 expert-curated
tasks spanning daily life, enterprise, and academia, each requiring extensive,
dynamic, real-time web search and synthesis. Built with over 1,500 hours of
human labor, LiveResearchBench provides a rigorous basis for systematic
evaluation. To evaluate citation-grounded long-form reports, we introduce
DeepEval, a comprehensive suite covering both content- and report-level
quality, including coverage, presentation, citation accuracy and association,
consistency and depth of analysis. DeepEval integrates four complementary
evaluation protocols, each designed to ensure stable assessment and high
agreement with human judgments. Using LiveResearchBench and DeepEval, we
conduct a comprehensive evaluation of 17 frontier deep research systems,
including single-agent web search, single-agent deep research, and multi-agent
systems. Our analysis reveals current strengths, recurring failure modes, and
key system components needed to advance reliable, insightful deep research.

</details>


### [25] [Towards Agentic Self-Learning LLMs in Search Environment](https://arxiv.org/abs/2510.14253)
*Wangtao Sun,Xiang Cheng,Jialin Fan,Yao Xu,Xing Yu,Shizhu He,Jun Zhao,Kang Liu*

Main category: cs.AI

TL;DR: 本文提出了Agentic Self-Learning (ASL)框架，通过生成式奖励模型和多角色协同进化实现无需人工标注数据的智能体自我学习，在搜索任务中展现出持续改进的能力。


<details>
  <summary>Details</summary>
Motivation: 研究如何在不依赖人工标注数据集或预定义规则奖励的情况下，实现基于LLM的智能体的规模化训练。

Method: 提出了Agentic Self-Learning (ASL)框架，包含提示生成器、策略模型和生成式奖励模型，在共享工具环境和LLM骨干网络中形成任务生成、策略执行和评估的闭环强化学习。

Result: ASL实现了稳定、轮次递增的性能提升，超越了强基线方法（如Search-R1），在零标注数据条件下持续改进，表现出优异的样本效率和鲁棒性。

Conclusion: 奖励来源和数据规模是开放领域智能体学习的关键因素，多角色协同进化是实现可扩展、自我改进智能体的有效方法。

Abstract: We study whether self-learning can scale LLM-based agents without relying on
human-curated datasets or predefined rule-based rewards. Through controlled
experiments in a search-agent setting, we identify two key determinants of
scalable agent training: the source of reward signals and the scale of agent
task data. We find that rewards from a Generative Reward Model (GRM) outperform
rigid rule-based signals for open-domain learning, and that co-evolving the GRM
with the policy further boosts performance. Increasing the volume of agent task
data-even when synthetically generated-substantially enhances agentic
capabilities. Building on these insights, we propose \textbf{Agentic
Self-Learning} (ASL), a fully closed-loop, multi-role reinforcement learning
framework that unifies task generation, policy execution, and evaluation within
a shared tool environment and LLM backbone. ASL coordinates a Prompt Generator,
a Policy Model, and a Generative Reward Model to form a virtuous cycle of
harder task setting, sharper verification, and stronger solving. Empirically,
ASL delivers steady, round-over-round gains, surpasses strong RLVR baselines
(e.g., Search-R1) that plateau or degrade, and continues improving under
zero-labeled-data conditions, indicating superior sample efficiency and
robustness. We further show that GRM verification capacity is the main
bottleneck: if frozen, it induces reward hacking and stalls progress; continual
GRM training on the evolving data distribution mitigates this, and a small
late-stage injection of real verification data raises the performance ceiling.
This work establishes reward source and data scale as critical levers for
open-domain agent learning and demonstrates the efficacy of multi-role
co-evolution for scalable, self-improving agents. The data and code of this
paper are released at
https://github.com/forangel2014/Towards-Agentic-Self-Learning

</details>


### [26] [MorphoBench: A Benchmark with Difficulty Adaptive to Model Reasoning](https://arxiv.org/abs/2510.14265)
*Xukai Wang,Xuanbo Liu,Mingrui Chen,Haitian Zhong,Xuanlin Yang,Bohan Zeng,Jinbo Hu,Hao Liang,Junbo Niu,Xuchen Li,Ruitao Wu,Ruichuan An,Yang Shi,Liu Liu,Xu-Yao Zhang,Qiang Liu,Zhouchen Lin,Wentao Zhang,Bin Dong*

Main category: cs.AI

TL;DR: 提出了MorphoBench基准测试，通过多学科问题和自适应难度调整来评估大模型的推理能力，包含1300多个测试问题，可根据模型推理能力动态调整难度。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在评估大模型推理能力方面存在范围有限和灵活性不足的问题，无法根据模型推理能力的演变自适应调整难度。

Method: 从现有基准和奥林匹克级竞赛中收集复杂推理问题，利用模型推理过程中的关键陈述自适应修改问题分析难度，并使用仿真软件生成可动态调整难度的问题。

Result: 收集了1300多个测试问题，并基于o3和GPT-5等模型的推理能力迭代调整了MorphoBench的难度。

Conclusion: MorphoBench提高了模型推理评估的全面性和有效性，为提升大模型推理能力和科学稳健性提供了可靠指导。

Abstract: With the advancement of powerful large-scale reasoning models, effectively
evaluating the reasoning capabilities of these models has become increasingly
important. However, existing benchmarks designed to assess the reasoning
abilities of large models tend to be limited in scope and lack the flexibility
to adapt their difficulty according to the evolving reasoning capacities of the
models. To address this, we propose MorphoBench, a benchmark that incorporates
multidisciplinary questions to evaluate the reasoning capabilities of large
models and can adjust and update question difficulty based on the reasoning
abilities of advanced models. Specifically, we curate the benchmark by
selecting and collecting complex reasoning questions from existing benchmarks
and sources such as Olympiad-level competitions. Additionally, MorphoBench
adaptively modifies the analytical challenge of questions by leveraging key
statements generated during the model's reasoning process. Furthermore, it
includes questions generated using simulation software, enabling dynamic
adjustment of benchmark difficulty with minimal resource consumption. We have
gathered over 1,300 test questions and iteratively adjusted the difficulty of
MorphoBench based on the reasoning capabilities of models such as o3 and GPT-5.
MorphoBench enhances the comprehensiveness and validity of model reasoning
evaluation, providing reliable guidance for improving both the reasoning
abilities and scientific robustness of large models. The code has been released
in https://github.com/OpenDCAI/MorphoBench.

</details>


### [27] [A Guardrail for Safety Preservation: When Safety-Sensitive Subspace Meets Harmful-Resistant Null-Space](https://arxiv.org/abs/2510.14301)
*Bingjie Zhang,Yibo Yang,Renzhe,Dandan Guo,Jindong Gu,Philip Torr,Bernard Ghanem*

Main category: cs.AI

TL;DR: GuardSpace是一个保护大语言模型安全对齐的框架，通过安全敏感子空间和有害抵抗零空间来防止微调过程中安全性能退化。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在微调过程中容易丧失预训练的安全对齐能力，导致生成有害内容，需要一种方法来保持安全性能。

Method: 使用协方差预处理的奇异值分解将预训练权重分解为安全相关和安全无关组件，初始化低秩适配器时冻结安全相关部分，并构建零空间投影器限制适配器更新对有害提示的影响。

Result: 在多个下游任务实验中，GuardSpace优于现有方法，对于Llama-2-7B-Chat在GSM8K上的微调，将平均有害分数从14.4%降至3.6%，准确率从26.0%提升至28.0%。

Conclusion: GuardSpace能有效保护大语言模型在微调过程中的安全对齐，在保持安全性的同时提升任务性能。

Abstract: Large language models (LLMs) have achieved remarkable success in diverse
tasks, yet their safety alignment remains fragile during adaptation. Even when
fine-tuning on benign data or with low-rank adaptation, pre-trained safety
behaviors are easily degraded, leading to harmful responses in the fine-tuned
models. To address this challenge, we propose GuardSpace, a guardrail framework
for preserving safety alignment throughout fine-tuning, composed of two key
components: a safety-sensitive subspace and a harmful-resistant null space.
First, we explicitly decompose pre-trained weights into safety-relevant and
safety-irrelevant components using covariance-preconditioned singular value
decomposition, and initialize low-rank adapters from the safety-irrelevant
ones, while freezing safety-relevant components to preserve their associated
safety mechanism. Second, we construct a null space projector that restricts
adapter updates from altering safe outputs on harmful prompts, thereby
maintaining the original refusal behavior. Experiments with various pre-trained
models on multiple downstream tasks demonstrate that GuardSpace achieves
superior performance over existing methods. Notably, for Llama-2-7B-Chat
fine-tuned on GSM8K, GuardSpace outperforms the state-of-the-art method AsFT,
reducing the average harmful score from 14.4% to 3.6%, while improving the
accuracy from from 26.0% to 28.0%.

</details>


### [28] [Terrarium: Revisiting the Blackboard for Multi-Agent Safety, Privacy, and Security Studies](https://arxiv.org/abs/2510.14312)
*Mason Nakamura,Abhinav Kumar,Saaduddin Mahmud,Sahar Abdelnabi,Shlomo Zilberstein,Eugene Bagdasarian*

Main category: cs.AI

TL;DR: 提出了Terrarium框架，用于细粒度研究基于LLM的多智能体系统中的安全、隐私和安全性问题，通过模块化可配置测试床识别关键攻击向量并演示防御方案。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的多智能体系统能够自动化复杂用户任务，但引入了新的风险，包括错位、恶意方攻击、智能体被破坏或用户数据被盗等问题，需要系统化研究安全机制。

Method: 重新利用黑板设计（多智能体系统的早期方法），创建模块化、可配置的多智能体协作测试床，识别关键攻击向量如错位、恶意智能体、通信被破坏和数据投毒。

Result: 实现了三个协作多智能体场景和四种代表性攻击，展示了框架的灵活性，能够快速原型化、评估和迭代防御方案。

Conclusion: Terrarium框架通过提供工具来加速可信多智能体系统的进展，促进安全、隐私和安全性方面的研究。

Abstract: A multi-agent system (MAS) powered by large language models (LLMs) can
automate tedious user tasks such as meeting scheduling that requires
inter-agent collaboration. LLMs enable nuanced protocols that account for
unstructured private data, user constraints, and preferences. However, this
design introduces new risks, including misalignment and attacks by malicious
parties that compromise agents or steal user data. In this paper, we propose
the Terrarium framework for fine-grained study on safety, privacy, and security
in LLM-based MAS. We repurpose the blackboard design, an early approach in
multi-agent systems, to create a modular, configurable testbed for multi-agent
collaboration. We identify key attack vectors such as misalignment, malicious
agents, compromised communication, and data poisoning. We implement three
collaborative MAS scenarios with four representative attacks to demonstrate the
framework's flexibility. By providing tools to rapidly prototype, evaluate, and
iterate on defenses and designs, Terrarium aims to accelerate progress toward
trustworthy multi-agent systems.

</details>


### [29] [Metacognitive Self-Correction for Multi-Agent System via Prototype-Guided Next-Execution Reconstruction](https://arxiv.org/abs/2510.14319)
*Xu Shen,Qi Zhang,Song Wang,Zhen Tan,Xinyu Zhao,Laura Yao,Vaishnav Tadiparthi,Hossein Nourkhiz Mahjoub,Ehsan Moradi Pari,Kwonjoon Lee,Tianlong Chen*

Main category: cs.AI

TL;DR: MASC是一个元认知框架，通过实时无监督的步骤级错误检测和自我纠正来增强多智能体系统的鲁棒性，防止错误级联传播。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在协作解决问题方面表现出色，但对级联错误很脆弱：单个错误步骤可能在智能体间传播并破坏整个轨迹。

Method: MASC采用两种互补设计：1) 基于历史的下一个执行重构，从查询和交互历史预测下一步的嵌入以捕捉因果一致性；2) 原型引导增强，学习正常步骤嵌入的原型先验，在稀疏上下文下稳定重构和异常评分。检测到异常时触发纠正智能体。

Result: 在Who&When基准测试中，MASC始终优于所有基线，步骤级错误检测AUC-ROC提升高达8.47%；集成到不同MAS框架中，在各种架构上都能带来一致的端到端性能提升。

Conclusion: MASC的元认知监控和针对性纠正能够以最小开销缓解错误传播，为多智能体系统提供了有效的错误检测和纠正机制。

Abstract: Large Language Model based multi-agent systems (MAS) excel at collaborative
problem solving but remain brittle to cascading errors: a single faulty step
can propagate across agents and disrupt the trajectory. In this paper, we
present MASC, a metacognitive framework that endows MAS with real-time,
unsupervised, step-level error detection and self-correction. MASC rethinks
detection as history-conditioned anomaly scoring via two complementary designs:
(1) Next-Execution Reconstruction, which predicts the embedding of the next
step from the query and interaction history to capture causal consistency, and
(2) Prototype-Guided Enhancement, which learns a prototype prior over
normal-step embeddings and uses it to stabilize reconstruction and anomaly
scoring under sparse context (e.g., early steps). When an anomaly step is
flagged, MASC triggers a correction agent to revise the acting agent's output
before information flows downstream. On the Who&When benchmark, MASC
consistently outperforms all baselines, improving step-level error detection by
up to 8.47% AUC-ROC ; When plugged into diverse MAS frameworks, it delivers
consistent end-to-end gains across architectures, confirming that our
metacognitive monitoring and targeted correction can mitigate error propagation
with minimal overhead.

</details>


### [30] [AI for Service: Proactive Assistance with AI Glasses](https://arxiv.org/abs/2510.14359)
*Zichen Wen,Yiyu Wang,Chenfei Liao,Boxue Yang,Junxian Li,Weifeng Liu,Haocong He,Bolong Feng,Xuyang Liu,Yuanhuiyi Lyu,Xu Zheng,Xuming Hu,Linfeng Zhang*

Main category: cs.AI

TL;DR: 提出了AI4Service新范式，通过Alpha-Service框架实现主动式AI服务，能够从第一视角视频流中检测服务机会并提供个性化服务。


<details>
  <summary>Details</summary>
Motivation: 现有AI服务主要是被动响应，而真正智能的助手应该能够预测用户需求并在适当时机主动采取行动。

Method: 基于AI眼镜构建Alpha-Service框架，包含输入单元、中央处理单元、算术逻辑单元、内存单元和输出单元五个核心组件，采用多智能体系统实现。

Result: 案例研究展示了系统在实时21点顾问、博物馆导游和购物搭配助手等场景中，能够无缝感知环境、推断用户意图并提供及时有用的帮助。

Conclusion: Alpha-Service框架为实现主动式AI服务提供了可行方案，使AI能够从被动工具转变为主动伴侣。

Abstract: In an era where AI is evolving from a passive tool into an active and
adaptive companion, we introduce AI for Service (AI4Service), a new paradigm
that enables proactive and real-time assistance in daily life. Existing AI
services remain largely reactive, responding only to explicit user commands. We
argue that a truly intelligent and helpful assistant should be capable of
anticipating user needs and taking actions proactively when appropriate. To
realize this vision, we propose Alpha-Service, a unified framework that
addresses two fundamental challenges: Know When to intervene by detecting
service opportunities from egocentric video streams, and Know How to provide
both generalized and personalized services. Inspired by the von Neumann
computer architecture and based on AI glasses, Alpha-Service consists of five
key components: an Input Unit for perception, a Central Processing Unit for
task scheduling, an Arithmetic Logic Unit for tool utilization, a Memory Unit
for long-term personalization, and an Output Unit for natural human
interaction. As an initial exploration, we implement Alpha-Service through a
multi-agent system deployed on AI glasses. Case studies, including a real-time
Blackjack advisor, a museum tour guide, and a shopping fit assistant,
demonstrate its ability to seamlessly perceive the environment, infer user
intent, and provide timely and useful assistance without explicit prompts.

</details>


### [31] [Can MLLMs Absorb Math Reasoning Abilities from LLMs as Free Lunch?](https://arxiv.org/abs/2510.14387)
*Yijie Hu,Zihao Zhou,Kaizhu Huang,Xiaowei Huang,Qiufeng Wang*

Main category: cs.AI

TL;DR: IP-Merging是一种无需调优的方法，通过识别多模态大语言模型和数学大语言模型中的推理相关参数，将其投影到MLLM的子空间进行融合，直接提升MLLM的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型的数学推理能力落后于纯文本大语言模型，研究者希望探索能否让MLLM直接从现成的数学LLM中吸收推理能力，而无需进行复杂的训练。

Method: 提出IP-Merging方法：1）识别MLLM和数学LLM中的推理相关参数；2）将这些参数投影到MLLM的子空间以保持对齐；3）在子空间中融合参数。该方法无需调优，直接调整参数。

Result: 大量实验证明，IP-Merging方法能够在不损害MLLM其他能力的前提下，直接从数学LLM中增强MLLM的数学推理能力。

Conclusion: IP-Merging是一种有效的无需调优方法，能够成功将数学推理能力从纯文本LLM迁移到多模态LLM，解决了参数空间不对齐的问题。

Abstract: Math reasoning has been one crucial ability of large language models (LLMs),
where significant advancements have been achieved in recent years. However,
most efforts focus on LLMs by curating high-quality annotation data and
intricate training (or inference) paradigms, while the math reasoning
performance of multi-modal LLMs (MLLMs) remains lagging behind. Since the MLLM
typically consists of an LLM and a vision block, we wonder: Can MLLMs directly
absorb math reasoning abilities from off-the-shelf math LLMs without tuning?
Recent model-merging approaches may offer insights into this question. However,
they overlook the alignment between the MLLM and LLM, where we find that there
is a large gap between their parameter spaces, resulting in lower performance.
Our empirical evidence reveals two key factors behind this issue: the
identification of crucial reasoning-associated layers in the model and the
mitigation of the gaps in parameter space. Based on the empirical insights, we
propose IP-Merging that first identifies the reasoning-associated parameters in
both MLLM and Math LLM, then projects them into the subspace of MLLM, aiming to
maintain the alignment, and finally merges parameters in this subspace.
IP-Merging is a tuning-free approach since parameters are directly adjusted.
Extensive experiments demonstrate that our IP-Merging method can enhance the
math reasoning ability of MLLMs directly from Math LLMs without compromising
their other capabilities.

</details>


### [32] [Hi-Agent: Hierarchical Vision-Language Agents for Mobile Device Control](https://arxiv.org/abs/2510.14388)
*Zhe Wu,Hongjin Lu,Junliang Xing,Changhao Zhang,Yin Zhu,Yuhao Yang,Yuheng Jing,Kai Li,Kun Shao,Jianye Hao,Jun Wang,Yuanchun Shi*

Main category: cs.AI

TL;DR: Hi-Agent是一个可训练的分层视觉语言代理，用于移动设备控制，通过高层推理模型和低层动作模型的联合优化，在Android-in-the-Wild基准测试中达到87.9%的任务成功率，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的移动设备控制方法大多依赖直接的状态-动作映射，缺乏结构化推理和规划，导致在新任务或未见UI布局上泛化能力差。

Method: 提出分层架构：高层推理模型和低层动作模型联合优化。将多步决策重构为单步子目标序列，并提出前瞻优势函数，利用低层模型的执行反馈指导高层优化，缓解GRPO在长时任务中的路径爆炸问题。

Result: 在Android-in-the-Wild基准测试中达到87.9%的任务成功率，显著优于提示式(17.7%)、监督学习(54.5%)和强化学习方法(71.9%)。在ScreenSpot-v2基准测试中表现出竞争力的零样本泛化能力，在AndroidWorld基准测试中随骨干网络增大而扩展良好。

Conclusion: Hi-Agent通过分层设计和联合优化策略，在移动设备控制任务中实现了最先进的性能，并展示了良好的泛化能力和可扩展性。

Abstract: Building agents that autonomously operate mobile devices has attracted
increasing attention. While Vision-Language Models (VLMs) show promise, most
existing approaches rely on direct state-to-action mappings, which lack
structured reasoning and planning, and thus generalize poorly to novel tasks or
unseen UI layouts. We introduce Hi-Agent, a trainable hierarchical
vision-language agent for mobile control, featuring a high-level reasoning
model and a low-level action model that are jointly optimized. For efficient
training, we reformulate multi-step decision-making as a sequence of
single-step subgoals and propose a foresight advantage function, which
leverages execution feedback from the low-level model to guide high-level
optimization. This design alleviates the path explosion issue encountered by
Group Relative Policy Optimization (GRPO) in long-horizon tasks and enables
stable, critic-free joint training. Hi-Agent achieves a new State-Of-The-Art
(SOTA) 87.9% task success rate on the Android-in-the-Wild (AitW) benchmark,
significantly outperforming prior methods across three paradigms: prompt-based
(AppAgent: 17.7%), supervised (Filtered BC: 54.5%), and reinforcement
learning-based (DigiRL: 71.9%). It also demonstrates competitive zero-shot
generalization on the ScreenSpot-v2 benchmark. On the more challenging
AndroidWorld benchmark, Hi-Agent also scales effectively with larger backbones,
showing strong adaptability in high-complexity mobile control scenarios.

</details>


### [33] [IMAGINE: Integrating Multi-Agent System into One Model for Complex Reasoning and Planning](https://arxiv.org/abs/2510.14406)
*Xikai Zhang,Bo Wang,Likang Xiao,Yongzhi Li,Quan Chen,Wenju Wu,Liu Liu*

Main category: cs.AI

TL;DR: 提出IMAGINE框架，将多智能体系统的推理规划能力集成到单个紧凑模型中，显著超越原多智能体系统性能，在TravelPlanner基准上达到82.7%的最终通过率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在复杂推理和规划任务中的不足，以及多智能体系统存在的高推理成本、长延迟和端到端训练困难等问题。

Method: 提出IMAGINE框架，通过端到端训练将多智能体系统的能力集成到单个模型中，使用基础模型Qwen3-8B-Instruct进行训练。

Result: 在TravelPlanner基准测试中，训练后的模型达到82.7%的最终通过率，远超DeepSeek-R1-671B的40%，同时保持更小的模型规模。

Conclusion: IMAGINE框架成功将多智能体系统的能力集成到单个紧凑模型中，显著提升了推理规划性能，同时降低了模型规模和推理成本。

Abstract: Although large language models (LLMs) have made significant strides across
various tasks, they still face significant challenges in complex reasoning and
planning. For example, even with carefully designed prompts and prior
information explicitly provided, GPT-4o achieves only a 7% Final Pass Rate on
the TravelPlanner dataset in the sole-planning mode. Similarly, even in the
thinking mode, Qwen3-8B-Instruct and DeepSeek-R1-671B, only achieve Final Pass
Rates of 5.9% and 40%, respectively. Although well-organized Multi-Agent
Systems (MAS) can offer improved collective reasoning, they often suffer from
high reasoning costs due to multi-round internal interactions, long
per-response latency, and difficulties in end-to-end training. To address these
challenges, we propose a general and scalable framework called IMAGINE, short
for Integrating Multi-Agent System into One Model. This framework not only
integrates the reasoning and planning capabilities of MAS into a single,
compact model, but also significantly surpass the capabilities of the MAS
through a simple end-to-end training. Through this pipeline, a single
small-scale model is not only able to acquire the structured reasoning and
planning capabilities of a well-organized MAS but can also significantly
outperform it. Experimental results demonstrate that, when using
Qwen3-8B-Instruct as the base model and training it with our method, the model
achieves an 82.7% Final Pass Rate on the TravelPlanner benchmark, far exceeding
the 40% of DeepSeek-R1-671B, while maintaining a much smaller model size.

</details>


### [34] [Eliminating Negative Occurrences of Derived Predicates from PDDL Axioms](https://arxiv.org/abs/2510.14412)
*Claudia Grundke,Gabriele Röger*

Main category: cs.AI

TL;DR: 本文提出了一种转换方法，用于消除PDDL公理中派生谓词的负出现，证明这种限制实际上不会影响表达能力。


<details>
  <summary>Details</summary>
Motivation: PDDL标准限制公理体中谓词的负出现只能用于直接由动作设置的谓词，而不能用于由公理派生的谓词。然而文献中作者经常偏离这一限制，只要求公理集是可分层的。本文旨在证明这两种变体实际上可以表达相同的查询。

Method: 提出了相应的转换方法，通过消除派生谓词的负出现，将允许负出现的可分层公理集转换为符合PDDL标准限制的形式。

Result: 证明了两种变体（PDDL标准限制和可分层的负出现）都可以表达与最小不动点逻辑完全相同的查询，表明派生谓词的负出现可以被消除。

Conclusion: 派生谓词的负出现在PDDL公理中实际上是可以消除的，不会影响表达能力，这为PDDL标准提供了理论支持。

Abstract: Axioms are a feature of the Planning Domain Definition Language PDDL that can
be considered as a generalization of database query languages such as Datalog.
The PDDL standard restricts negative occurrences of predicates in axiom bodies
to predicates that are directly set by actions and not derived by axioms. In
the literature, authors often deviate from this limitation and only require
that the set of axioms is stratifiable. Both variants can express exactly the
same queries as least fixed-point logic, indicating that negative occurrences
of derived predicates can be eliminated. We present the corresponding
transformation.

</details>


### [35] [Helmsman: Autonomous Synthesis of Federated Learning Systems via Multi-Agent Collaboration](https://arxiv.org/abs/2510.14512)
*Haoyuan Li,Mathias Funk,Aaqib Saeed*

Main category: cs.AI

TL;DR: Helmsman是一个多智能体系统，通过模拟研发工作流程自动合成联邦学习系统，包括交互式规划、模块化代码生成和自主评估优化，在AgentFL-Bench基准测试中表现优于手工基线。


<details>
  <summary>Details</summary>
Motivation: 联邦学习系统设计复杂，需要处理数据异构性和系统约束等多方面挑战，现有解决方案往往脆弱且定制化，成为关键瓶颈。

Method: Helmsman采用三阶段协作方法：(1)交互式人机循环规划制定研究计划，(2)监督智能体团队进行模块化代码生成，(3)在沙盒模拟环境中进行自主评估和优化的闭环流程。

Result: 在16个多样化任务的AgentFL-Bench基准测试中，Helmsman生成的解决方案与手工基线相比具有竞争力，且往往更优。

Conclusion: 该工作代表了向复杂去中心化AI系统自动化工程迈出的重要一步。

Abstract: Federated Learning (FL) offers a powerful paradigm for training models on
decentralized data, but its promise is often undermined by the immense
complexity of designing and deploying robust systems. The need to select,
combine, and tune strategies for multifaceted challenges like data
heterogeneity and system constraints has become a critical bottleneck,
resulting in brittle, bespoke solutions. To address this, we introduce
Helmsman, a novel multi-agent system that automates the end-to-end synthesis of
federated learning systems from high-level user specifications. It emulates a
principled research and development workflow through three collaborative
phases: (1) interactive human-in-the-loop planning to formulate a sound
research plan, (2) modular code generation by supervised agent teams, and (3) a
closed-loop of autonomous evaluation and refinement in a sandboxed simulation
environment. To facilitate rigorous evaluation, we also introduce
AgentFL-Bench, a new benchmark comprising 16 diverse tasks designed to assess
the system-level generation capabilities of agentic systems in FL. Extensive
experiments demonstrate that our approach generates solutions competitive with,
and often superior to, established hand-crafted baselines. Our work represents
a significant step towards the automated engineering of complex decentralized
AI systems.

</details>


### [36] [JSPLIT: A Taxonomy-based Solution for Prompt Bloating in Model Context Protocol](https://arxiv.org/abs/2510.14537)
*Emanuele Antonioni,Stefan Markovic,Anirudha Shankar,Jaime Bernardo,Lovro Markovic,Silvia Pareti,Benedetto Proietti*

Main category: cs.AI

TL;DR: JSPLIT是一个基于分类学的框架，用于解决大型语言模型使用MCP工具时提示膨胀的问题。它通过层次化分类工具，根据用户查询选择最相关工具，显著减少提示大小，同时提高工具选择准确性和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统发展，用户期望超越简单文本交互，需要LLMs与外部工具交互。但工具数量增加导致提示膨胀，带来高token成本、延迟增加和任务成功率下降的问题。

Method: JSPLIT框架将工具组织成层次化分类学，使用用户提示基于查询和分类结构识别并仅包含最相关工具。包括分类设计、工具选择算法和评估数据集。

Result: JSPLIT显著减少了提示大小，且未显著影响代理响应能力。当可用工具数量大幅增加时，JSPLIT甚至提高了代理的工具选择准确性，在降低成本的同时改善了高复杂度环境中的任务成功率。

Conclusion: JSPLIT有效解决了MCP工具使用中的提示膨胀问题，通过分类学驱动的方法在减少成本的同时保持甚至提高了代理性能，特别适用于工具数量庞大的复杂代理环境。

Abstract: AI systems are continually evolving and advancing, and user expectations are
concurrently increasing, with a growing demand for interactions that go beyond
simple text-based interaction with Large Language Models (LLMs). Today's
applications often require LLMs to interact with external tools, marking a
shift toward more complex agentic systems. To support this, standards such as
the Model Context Protocol (MCP) have emerged, enabling agents to access tools
by including a specification of the capabilities of each tool within the
prompt. Although this approach expands what agents can do, it also introduces a
growing problem: prompt bloating. As the number of tools increases, the prompts
become longer, leading to high prompt token costs, increased latency, and
reduced task success resulting from the selection of tools irrelevant to the
prompt. To address this issue, we introduce JSPLIT, a taxonomy-driven framework
designed to help agents manage prompt size more effectively when using large
sets of MCP tools. JSPLIT organizes the tools into a hierarchical taxonomy and
uses the user's prompt to identify and include only the most relevant tools,
based on both the query and the taxonomy structure. In this paper, we describe
the design of the taxonomy, the tool selection algorithm, and the dataset used
to evaluate JSPLIT. Our results show that JSPLIT significantly reduces prompt
size without significantly compromising the agent's ability to respond
effectively. As the number of available tools for the agent grows
substantially, JSPLIT even improves the tool selection accuracy of the agent,
effectively reducing costs while simultaneously improving task success in
high-complexity agent environments.

</details>


### [37] [Symbol Grounding in Neuro-Symbolic AI: A Gentle Introduction to Reasoning Shortcuts](https://arxiv.org/abs/2510.14538)
*Emanuele Marconato,Samuele Bortolotti,Emile van Krieken,Paolo Morettin,Elena Umili,Antonio Vergari,Efthymia Tsamoura,Andrea Passerini,Stefano Teso*

Main category: cs.AI

TL;DR: 神经符号AI结合神经网络和符号推理，但存在推理捷径问题：模型可能通过错误地基础概念来获得高准确率，这会损害模型的可解释性、分布外性能和可靠性。本文综述了推理捷径的成因、后果、理论特征及应对方法。


<details>
  <summary>Details</summary>
Motivation: 神经符号AI是构建可靠可信AI的重要途径，但推理捷径问题会严重影响模型的解释性和可靠性。现有研究分散，需要统一视角来帮助研究人员理解和解决这一问题。

Method: 本文提供推理捷径的直观介绍，讨论其成因和后果，回顾现有理论特征，详细分析应对方法（包括缓解和意识策略），并评估各种方法的优缺点。

Result: 通过将高级材料重新表述为易于理解的形式，本文提供了关于推理捷径的统一视角，降低了解决这一问题的入门门槛。

Conclusion: 本文综述有助于推动可靠神经符号AI和可信AI模型的发展，为研究人员提供应对推理捷径问题的系统性指导。

Abstract: Neuro-symbolic (NeSy) AI aims to develop deep neural networks whose
predictions comply with prior knowledge encoding, e.g. safety or structural
constraints. As such, it represents one of the most promising avenues for
reliable and trustworthy AI. The core idea behind NeSy AI is to combine neural
and symbolic steps: neural networks are typically responsible for mapping
low-level inputs into high-level symbolic concepts, while symbolic reasoning
infers predictions compatible with the extracted concepts and the prior
knowledge. Despite their promise, it was recently shown that - whenever the
concepts are not supervised directly - NeSy models can be affected by Reasoning
Shortcuts (RSs). That is, they can achieve high label accuracy by grounding the
concepts incorrectly. RSs can compromise the interpretability of the model's
explanations, performance in out-of-distribution scenarios, and therefore
reliability. At the same time, RSs are difficult to detect and prevent unless
concept supervision is available, which is typically not the case. However, the
literature on RSs is scattered, making it difficult for researchers and
practitioners to understand and tackle this challenging problem. This overview
addresses this issue by providing a gentle introduction to RSs, discussing
their causes and consequences in intuitive terms. It also reviews and
elucidates existing theoretical characterizations of this phenomenon. Finally,
it details methods for dealing with RSs, including mitigation and awareness
strategies, and maps their benefits and limitations. By reformulating advanced
material in a digestible form, this overview aims to provide a unifying
perspective on RSs to lower the bar to entry for tackling them. Ultimately, we
hope this overview contributes to the development of reliable NeSy and
trustworthy AI models.

</details>


### [38] [LLM Agents Beyond Utility: An Open-Ended Perspective](https://arxiv.org/abs/2510.14548)
*Asen Nachkov,Xi Wang,Luc Van Gool*

Main category: cs.AI

TL;DR: 研究探讨了LLM代理是否能够成为具有自主规划、任务设计和抽象目标推理能力的实体，通过在开放环境中赋予其生成任务、积累知识和与环境交互的能力进行实验。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理能力的增强，研究其是否能从智能问题解决工具发展为具有自主性的实体，能够规划、设计任务并推理更广泛的模糊目标。

Method: 采用开放环境实验设置，增强预训练LLM代理的能力，使其能够生成自己的任务、积累知识并与环境进行广泛交互。

Result: 代理能够可靠地遵循复杂的多步骤指令，跨运行存储和重用信息，提出并解决自己的任务，但对提示设计敏感，容易重复生成任务，无法形成自我表征。

Conclusion: 研究展示了将预训练LLM适应开放性的前景和当前限制，指出了未来在训练代理管理记忆、有效探索和追求抽象长期目标方面的方向。

Abstract: Recent LLM agents have made great use of chain of thought reasoning and
function calling. As their capabilities grow, an important question arises: can
this software represent not only a smart problem-solving tool, but an entity in
its own right, that can plan, design immediate tasks, and reason toward
broader, more ambiguous goals? To study this question, we adopt an open-ended
experimental setting where we augment a pretrained LLM agent with the ability
to generate its own tasks, accumulate knowledge, and interact extensively with
its environment. We study the resulting open-ended agent qualitatively. It can
reliably follow complex multi-step instructions, store and reuse information
across runs, and propose and solve its own tasks, though it remains sensitive
to prompt design, prone to repetitive task generation, and unable to form
self-representations. These findings illustrate both the promise and current
limits of adapting pretrained LLMs toward open-endedness, and point to future
directions for training agents to manage memory, explore productively, and
pursue abstract long-term goals.

</details>


### [39] [ColorBench: Benchmarking Mobile Agents with Graph-Structured Framework for Complex Long-Horizon Tasks](https://arxiv.org/abs/2510.14621)
*Yuanyi Song,Heyuan Huang,Qiqiang Lin,Yin Zhao,Xiangmou Qu,Jun Wang,Xingyu Lou,Weiwen Liu,Zhuosheng Zhang,Jun Wang,Yong Yu,Weinan Zhang,Zhaoxiang Wang*

Main category: cs.AI

TL;DR: 本文提出了ColorBench，一个基于图结构的移动代理评估基准，专注于复杂长时程任务，支持多有效解决方案评估和原子级能力分析。


<details>
  <summary>Details</summary>
Motivation: 当前移动代理评估标准存在局限：离线静态基准只能验证单一预定义路径，而在线动态测试受限于真实设备的复杂性和不可重现性，两者都无法全面评估代理能力。

Method: 通过建模真实设备交互中观察到的有限状态，实现动态行为的静态模拟，开发了ColorBench基准，包含175个任务（74个单应用，101个跨应用），平均长度超过13步，每个任务包含至少两条正确路径和典型错误路径。

Result: 通过在各种基线模型上评估ColorBench，发现了现有模型的局限性，并基于实验结果提出了改进方向和可行的技术路径。

Conclusion: ColorBench框架填补了离线和在线评估之间的差距，提高了测试稳定性，为增强代理在复杂长时程问题上的性能提供了有效评估工具。

Abstract: The rapid advancement of multimodal large language models has enabled agents
to operate mobile devices by directly interacting with graphical user
interfaces, opening new possibilities for mobile automation. However,
real-world mobile tasks are often complex and allow for multiple valid
solutions. This contradicts current mobile agent evaluation standards: offline
static benchmarks can only validate a single predefined "golden path", while
online dynamic testing is constrained by the complexity and non-reproducibility
of real devices, making both approaches inadequate for comprehensively
assessing agent capabilities. To bridge the gap between offline and online
evaluation and enhance testing stability, this paper introduces a novel
graph-structured benchmarking framework. By modeling the finite states observed
during real-device interactions, it achieves static simulation of dynamic
behaviors. Building on this, we develop ColorBench, a benchmark focused on
complex long-horizon tasks. It supports evaluation of multiple valid solutions,
subtask completion rate statistics, and atomic-level capability analysis.
ColorBench contains 175 tasks (74 single-app, 101 cross-app) with an average
length of over 13 steps. Each task includes at least two correct paths and
several typical error paths, enabling quasi-dynamic interaction. By evaluating
ColorBench across various baselines, we discover limitations of existing models
and propose improvement directions and feasible technical pathways to enhance
agents' performance on complex, long-horizon problems based on experimental
results. Code and data are available at:
https://github.com/MadeAgents/ColorBench.

</details>


### [40] [Beyond Hallucinations: The Illusion of Understanding in Large Language Models](https://arxiv.org/abs/2510.14665)
*Rikard Rosenbacke,Carl Rosenbacke,Victor Rosenbacke,Martin McKee*

Main category: cs.AI

TL;DR: 该论文提出了Rose-Frame框架，用于诊断人机交互中的认知和认识论漂移，通过三个维度（地图vs领土、直觉vs理性、冲突vs确认）来识别AI模型的局限性，强调将AI直觉置于人类理性的监督之下。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然流畅且具有情感共鸣，但基于统计预测而非有根据的推理，存在幻觉风险。它们实现了系统1认知的大规模操作化：快速、联想且具有说服力，但缺乏反思或证伪能力。

Method: 引入Rose-Frame三维诊断框架：(i)地图vs领土-区分现实表征与现实本身；(ii)直觉vs理性-区分快速情感判断与慢速反思思维；(iii)冲突vs确认-检验观点是通过批判性测试还是简单相互验证。

Result: Rose-Frame不试图用更多数据或规则修复LLMs，而是提供一个反思工具，使模型局限性和用户假设可见，实现更透明和批判性意识的AI部署。

Conclusion: 将对齐重新定义为认知治理：无论是人类还是人工智能的直觉，都必须由人类理性来治理。只有通过嵌入反思性、可证伪的监督，才能将机器的流畅性与人类的理解对齐。

Abstract: Large language models (LLMs) are becoming deeply embedded in human
communication and decision-making, yet they inherit the ambiguity, bias, and
lack of direct access to truth inherent in language itself. While their outputs
are fluent, emotionally resonant, and coherent, they are generated through
statistical prediction rather than grounded reasoning. This creates the risk of
hallucination, responses that sound convincing but lack factual validity.
Building on Geoffrey Hinton's observation that AI mirrors human intuition
rather than reasoning, this paper argues that LLMs operationalize System 1
cognition at scale: fast, associative, and persuasive, but without reflection
or falsification. To address this, we introduce the Rose-Frame, a
three-dimensional framework for diagnosing cognitive and epistemic drift in
human-AI interaction. The three axes are: (i) Map vs. Territory, which
distinguishes representations of reality (epistemology) from reality itself
(ontology); (ii) Intuition vs. Reason, drawing on dual-process theory to
separate fast, emotional judgments from slow, reflective thinking; and (iii)
Conflict vs. Confirmation, which examines whether ideas are critically tested
through disagreement or simply reinforced through mutual validation. Each
dimension captures a distinct failure mode, and their combination amplifies
misalignment. Rose-Frame does not attempt to fix LLMs with more data or rules.
Instead, it offers a reflective tool that makes both the model's limitations
and the user's assumptions visible, enabling more transparent and critically
aware AI deployment. It reframes alignment as cognitive governance: intuition,
whether human or artificial, must remain governed by human reason. Only by
embedding reflective, falsifiable oversight can we align machine fluency with
human understanding.

</details>


### [41] [Machine Learning and Public Health: Identifying and Mitigating Algorithmic Bias through a Systematic Review](https://arxiv.org/abs/2510.14669)
*Sara Altamirano,Arjan Vreeken,Sennay Ghebreab*

Main category: cs.AI

TL;DR: 该论文系统评估了2021-2025年荷兰公共卫生机器学习研究中算法偏见的识别、讨论和报告情况，开发了RABAT评估工具，并提出了ACAR四阶段公平性框架来帮助研究人员在ML生命周期中解决公平性问题。


<details>
  <summary>Details</summary>
Motivation: 机器学习在公共卫生领域有巨大潜力，但如果不系统关注算法偏见，可能会无意中加剧现有的健康不平等。需要评估当前研究中对算法偏见的处理情况。

Method: 开发了RABAT评估工具（整合了Cochrane偏倚风险、PROBAST和微软负责任AI检查表），并应用于35篇同行评审研究进行系统文献回顾。

Result: 分析显示普遍存在差距：虽然数据采样和缺失数据处理记录良好，但大多数研究缺乏明确的公平性框架、亚组分析和潜在危害的透明讨论。

Conclusion: 提出了ACAR四阶段公平性框架（意识、概念化、应用、报告）和具体建议，帮助公共卫生ML从业者系统考虑算法偏见，确保算法创新促进而非损害健康公平。

Abstract: Machine learning (ML) promises to revolutionize public health through
improved surveillance, risk stratification, and resource allocation. However,
without systematic attention to algorithmic bias, ML may inadvertently
reinforce existing health disparities. We present a systematic literature
review of algorithmic bias identification, discussion, and reporting in Dutch
public health ML research from 2021 to 2025. To this end, we developed the Risk
of Algorithmic Bias Assessment Tool (RABAT) by integrating elements from
established frameworks (Cochrane Risk of Bias, PROBAST, Microsoft Responsible
AI checklist) and applied it to 35 peer-reviewed studies. Our analysis reveals
pervasive gaps: although data sampling and missing data practices are well
documented, most studies omit explicit fairness framing, subgroup analyses, and
transparent discussion of potential harms. In response, we introduce a
four-stage fairness-oriented framework called ACAR (Awareness,
Conceptualization, Application, Reporting), with guiding questions derived from
our systematic literature review to help researchers address fairness across
the ML lifecycle. We conclude with actionable recommendations for public health
ML practitioners to consistently consider algorithmic bias and foster
transparency, ensuring that algorithmic innovations advance health equity
rather than undermine it.

</details>


### [42] [TITAN: Graph-Executable Reasoning for Cyber Threat Intelligence](https://arxiv.org/abs/2510.14670)
*Marco Simoni,Aleksandar Fontana,Andrea Saracino,Paolo Mori*

Main category: cs.AI

TL;DR: TITAN是一个连接自然语言网络威胁查询与结构化知识图谱推理的框架，包含路径规划模型和图执行器，能够生成可执行的推理路径来回答威胁情报问题。


<details>
  <summary>Details</summary>
Motivation: 传统检索系统无法在威胁、行为和防御之间进行清晰可逆的推理，需要一种能够将自然语言查询映射到结构化知识图谱的可执行推理方法。

Method: 集成路径规划模型预测文本中的逻辑关系链，图执行器遍历TITAN本体图检索事实答案和证据，基于MITRE构建双向类型化图谱。

Result: 创建了包含88209个示例的TITAN数据集，实证评估显示TITAN能生成语法有效且语义连贯的可执行推理路径。

Conclusion: TITAN框架成功实现了自然语言威胁查询到结构化知识图谱的可执行推理，为威胁情报分析提供了新的自动化方法。

Abstract: TITAN (Threat Intelligence Through Automated Navigation) is a framework that
connects natural-language cyber threat queries with executable reasoning over a
structured knowledge graph. It integrates a path planner model, which predicts
logical relation chains from text, and a graph executor that traverses the
TITAN Ontology to retrieve factual answers and supporting evidence. Unlike
traditional retrieval systems, TITAN operates on a typed, bidirectional graph
derived from MITRE, allowing reasoning to move clearly and reversibly between
threats, behaviors, and defenses. To support training and evaluation, we
introduce the TITAN Dataset, a corpus of 88209 examples (Train: 74258; Test:
13951) pairing natural language questions with executable reasoning paths and
step by step Chain of Thought explanations. Empirical evaluations show that
TITAN enables models to generate syntactically valid and semantically coherent
reasoning paths that can be deterministically executed on the underlying graph.

</details>


### [43] [NAEL: Non-Anthropocentric Ethical Logic](https://arxiv.org/abs/2510.14676)
*Bianca Maria Lerma,Rafael Peñaloza*

Main category: cs.AI

TL;DR: NAEL是一个基于主动推理和符号推理的新型人工智能伦理框架，通过最小化全局期望自由能量来形式化伦理行为，采用神经符号架构让智能体在不确定环境中评估行为伦理后果。


<details>
  <summary>Details</summary>
Motivation: 传统以人类为中心的AI伦理方法存在局限性，需要发展不预设人类道德直觉的、能适应动态多智能体环境的伦理框架。

Method: 提出神经符号架构，结合主动推理和符号推理，让智能体在动态多智能体环境中通过最小化全局期望自由能量来发展伦理行为。

Result: 通过伦理资源分配的案例研究展示了NAEL能够动态平衡自我保存、认知学习和集体福利。

Conclusion: NAEL为人工智能提供了一种非人类中心主义的伦理框架，能够产生情境敏感、自适应和关系性的伦理行为。

Abstract: We introduce NAEL (Non-Anthropocentric Ethical Logic), a novel ethical
framework for artificial agents grounded in active inference and symbolic
reasoning. Departing from conventional, human-centred approaches to AI ethics,
NAEL formalizes ethical behaviour as an emergent property of intelligent
systems minimizing global expected free energy in dynamic, multi-agent
environments. We propose a neuro-symbolic architecture to allow agents to
evaluate the ethical consequences of their actions in uncertain settings. The
proposed system addresses the limitations of existing ethical models by
allowing agents to develop context-sensitive, adaptive, and relational ethical
behaviour without presupposing anthropomorphic moral intuitions. A case study
involving ethical resource distribution illustrates NAEL's dynamic balancing of
self-preservation, epistemic learning, and collective welfare.

</details>


### [44] [Practical, Utilitarian Algorithm Configuration](https://arxiv.org/abs/2510.14683)
*Devon Graham,Kevin Leyton-Brown*

Main category: cs.AI

TL;DR: 本文改进了COUP实用算法配置方法，通过一系列改进使其在保持理论保证的同时达到与启发式配置方法相当的实用性能，并展示了如何探索算法选择解对效用函数变化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: COUP方法虽然具有理论保证，但实际性能不如广泛使用的启发式配置方法。本文旨在弥合这一差距，使基于理论的实用算法配置方法在实际应用中具有竞争力。

Method: 提出了一系列对COUP方法的改进措施，这些改进在不降低理论保证的前提下提升了方法的实证性能，并通过实验验证了这些改进的有效性。

Result: 改进后的COUP方法在保持理论保证的同时，其实际性能达到了与无性能保证的启发式配置方法相当的水平。

Conclusion: 通过本文的改进，实用算法配置方法现在能够在实际应用中与广泛使用的启发式方法竞争，同时提供了理论性能保证，并通过案例研究展示了如何评估算法选择解对效用函数变化的鲁棒性。

Abstract: Utilitarian algorithm configuration identifies a parameter setting for a
given algorithm that maximizes a user's utility. Utility functions offer a
theoretically well-grounded approach to optimizing decision-making under
uncertainty and are flexible enough to capture a user's preferences over
algorithm runtimes (e.g., they can describe a sharp cutoff after which a
solution is no longer required, a per-hour cost for compute, or diminishing
returns from algorithms that take longer to run). COUP is a recently-introduced
utilitarian algorithm configuration procedure which was designed mainly to
offer strong theoretical guarantees about the quality of the configuration it
returns, with less attention paid to its practical performance. This paper
closes that gap, bringing theoretically-grounded, utilitarian algorithm
configuration to the point where it is competitive with widely used, heuristic
configuration procedures that offer no performance guarantees. We present a
series of improvements to COUP that improve its empirical performance without
degrading its theoretical guarantees and demonstrate their benefit
experimentally. Using a case study, we also illustrate ways of exploring the
robustness of a given solution to the algorithm selection problem to variations
in the utility function.

</details>


### [45] [Purifying Task Vectors in Knowledge-Aware Subspace for Model Merging](https://arxiv.org/abs/2510.14697)
*Bang An,Yibo Yang,Philip Torr,Bernard Ghanem*

Main category: cs.AI

TL;DR: 提出了PAVE方法，通过在知识感知子空间中净化任务向量，消除任务无关冗余，提升模型合并性能


<details>
  <summary>Details</summary>
Motivation: 现有模型合并方法中，任务向量包含任务无关冗余，导致合并模型性能显著下降。现有方法随机丢弃参数元素，缺乏知识感知且存在随机性

Method: 从每个任务采样训练样本，通过对应微调模型获取线性层前的协方差矩阵，进行上下文导向的奇异值分解，识别与目标知识最相关的权重分量，将微调模型权重分解为任务相关和冗余分量，通过剪枝冗余分量净化任务向量

Result: PAVE作为即插即用方案，适用于各种基于任务向量的合并方法，在多种合并方法、任务和模型架构上验证了有效性

Conclusion: PAVE方法能够有效净化任务向量中的冗余信息，显著提升模型合并性能，且具有良好的通用性

Abstract: Model merging aims to integrate task-specific abilities from individually
fine-tuned models into a single model without extra training. In recent model
merging methods, task vector has become a fundamental building block, as it can
encapsulate the residual information from finetuning. However, the merged model
often suffers from notable performance degradation due to the conflicts caused
by task-irrelevant redundancy in task vectors. Existing efforts in overcoming
redundancy by randomly dropping elements in the parameter space involves
randomness and lacks knowledge awareness. To address these challenges, in this
study, we propose Purifying TAsk Vectors (PAVE) in knowledge-aware subspace.
Concretely, we sample some training examples from each task, and feed them into
their corresponding fine-tuned models to acquire the covariance matrices before
linear layers. We then perform a context-oriented singular value decomposition,
which accentuates the weight components most relevant to the target knowledge.
As a result, we can split fine-tuned model weights into task-relevant and
redundant components in the knowledge-aware subspace, and purify the task
vector by pruning the redundant components. To induce fair pruning efforts
across models, we further introduce a spectral rank allocation strategy by
optimizing a normalized activated pruning error. The task vector purification
by our method as a plug-and-play scheme is applicable across various task
vector-based merging methods to improve their performance. In experiments, we
demonstrate the effectiveness of PAVE across a diverse set of merging methods,
tasks, and model architectures.

</details>


### [46] [Cognitive-Aligned Spatio-Temporal Large Language Models For Next Point-of-Interest Prediction](https://arxiv.org/abs/2510.14702)
*Penglong Zhai,Jie Li,Fanyi Di,Yue Liu,Yifang Yuan,Jie Huang,Peng Wu,Sicong Wang,Mingyang Yin,Tingting Hu,Yao Xu,Xin Li*

Main category: cs.AI

TL;DR: CoAST是一个认知对齐的时空大语言模型框架，通过自然语言界面整合世界知识、时空轨迹模式和个人资料，用于下一个兴趣点推荐。


<details>
  <summary>Details</summary>
Motivation: 现有LLM主要基于非结构化文本预训练，缺乏对结构化地理实体和移动模式的理解，且难以整合季节、天气、节假日等世界知识和用户认知信息。

Method: CoAST包含两个阶段：(1) 在脱敏用户的时空轨迹数据上继续预训练获取推荐知识；(2) 通过监督微调和强化学习实现认知对齐，使模型判断符合人类偏好。

Result: 在多个真实数据集上的离线实验和在AMAP App首页"猜你想去"功能中的在线实验都证明了CoAST的有效性。

Conclusion: CoAST框架成功解决了LLM在POI推荐中缺乏地理理解和认知对齐的问题，通过整合多源信息显著提升了推荐性能。

Abstract: The next point-of-interest (POI) recommendation task aims to predict the
users' immediate next destinations based on their preferences and historical
check-ins, holding significant value in location-based services. Recently,
large language models (LLMs) have shown great potential in recommender systems,
which treat the next POI prediction in a generative manner. However, these
LLMs, pretrained primarily on vast corpora of unstructured text, lack the
native understanding of structured geographical entities and sequential
mobility patterns required for next POI prediction tasks. Moreover, in
industrial-scale POI prediction applications, incorporating world knowledge and
alignment of human cognition, such as seasons, weather conditions, holidays,
and users' profiles (such as habits, occupation, and preferences), can enhance
the user experience while improving recommendation performance. To address
these issues, we propose CoAST (Cognitive-Aligned Spatial-Temporal LLMs), a
framework employing natural language as an interface, allowing for the
incorporation of world knowledge, spatio-temporal trajectory patterns,
profiles, and situational information. Specifically, CoAST mainly comprises of
2 stages: (1) Recommendation Knowledge Acquisition through continued
pretraining on the enriched spatial-temporal trajectory data of the
desensitized users; (2) Cognitive Alignment to align cognitive judgments with
human preferences using enriched training data through Supervised Fine-Tuning
(SFT) and a subsequent Reinforcement Learning (RL) phase. Extensive offline
experiments on various real-world datasets and online experiments deployed in
"Guess Where You Go" of AMAP App homepage demonstrate the effectiveness of
CoAST.

</details>


### [47] [ToolPRM: Fine-Grained Inference Scaling of Structured Outputs for Function Calling](https://arxiv.org/abs/2510.14703)
*Jianghao Lin,Yuanyuan Shi,Xin Peng,Renjie Ding,Hairui Wang,Yuxuan Peng,Bizhe Bai,Weixi Song,Fengshuo Bai,Huacan Chai,Weinan Zhang,Fei Huang,Ying Wen*

Main category: cs.AI

TL;DR: 提出了一个结合细粒度波束搜索和过程奖励模型ToolPRM的推理扩展框架，用于提升大语言模型在函数调用等结构化输出任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 当前推理扩展研究主要关注非结构化输出生成任务，而在函数调用等结构化输出领域的应用研究不足，需要填补这一空白。

Method: 构建了首个细粒度函数调用过程监督数据集，使用函数掩码技术自动标注步骤级奖励，训练ToolPRM过程奖励模型来评分函数调用的内部步骤，并与细粒度波束搜索结合。

Result: ToolPRM在预测准确性上优于粗粒度和结果奖励模型，推理扩展技术结合ToolPRM显著提升了骨干模型在各种函数调用任务和基准测试中的性能。

Conclusion: 揭示了将推理扩展技术应用于结构化输出的关键原则："多探索但少保留"，这是由结构化函数调用生成的不可恢复性特征决定的。

Abstract: Large language models (LLMs) are increasingly demonstrating strong
capabilities as autonomous agents, with function calling serving as a core
mechanism for interaction with the environment. Meanwhile, inference scaling
has become a cutting-edge technique to enhance LLM performance by allocating
more computational resources during the inference process. However, current
research on inference scaling primarily focuses on unstructured output
generation tasks, leaving its application in structured outputs, like function
calling, largely underexplored. To bridge this gap, we propose an inference
scaling framework that combines fine-grained beam search with a process reward
model, ToolPRM, which scores the internal steps of each single function call.
To train ToolPRM, we construct the first fine-grained intra-call process
supervision dataset, automatically annotated with function-masking techniques
to provide step-level rewards for structured tool-use reasoning. Extensive
experiments demonstrate that ToolPRM beats the coarse-grained and outcome
reward models in terms of predictive accuracy, indicating its stronger
capability in supervising the function calling inference process. Inference
scaling technique equipped with ToolPRM also significantly improves the
backbone model performance across various function calling tasks and
benchmarks. More importantly, we reveal a key principle for applying inference
scaling techniques to structured outputs: "explore more but retain less" due to
the unrecoverability characteristics of structured function calling generation.

</details>


### [48] [SimKO: Simple Pass@K Policy Optimization](https://arxiv.org/abs/2510.14807)
*Ruotian Peng,Yi Ren,Zhouliang Yu,Weiyang Liu,Yandong Wen*

Main category: cs.AI

TL;DR: 论文分析了RLVR方法存在的系统性偏向利用而非探索的问题，提出了SimKO方法来解决概率过度集中的问题，从而提高pass@K性能。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法存在系统性偏向利用而非探索的问题，表现为pass@1性能提升但pass@K(K>1)性能下降，需要理解并解决这一训练动态问题。

Method: 提出SimKO方法，采用非对称设计：对已验证正确的响应提升top-K候选的概率，对已验证错误的响应对top-1候选施加更强惩罚，特别是在高熵token上应用。

Result: 在各种数学和逻辑推理基准测试中，SimKO一致地为广泛的K值带来更高的pass@K性能，有效改善了RLVR的探索能力。

Conclusion: SimKO通过缓解概率过度集中问题，为改进RLVR的探索提供了一种简单有效的方法。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has advanced the
reasoning capabilities of large language models (LLMs). However, prevailing
RLVR methods exhibit a systematic bias toward exploitation over exploration, as
evidenced by improved pass@1 but reduced pass@K (K>1) performance. To
understand this issue, we analyze training dynamics of RLVR methods by tracking
the token-level probability distributions over vocabulary candidates. Our
analysis reveals a consistent probability concentration effect where the top-1
candidate increasingly accumulates probability mass and suppresses that of
other candidates. More importantly, stronger over-concentration correlates with
worse pass@K performance. Inspired by this finding, we propose Simple Pass@K
Optimization (SimKO), a method designed to mitigate the over-concentration
issue, thereby encouraging exploration. SimKO operates in an asymmetrical
manner. For verified-correct responses, it boosts the probabilities of the
top-K candidates. For verified-incorrect responses, it applies stronger
penalties to the top-1 candidate. We observe that this asymmetric design is
particularly effective at mitigating over-concentration when applied at tokens
with high entropy. Across various math and logical-reasoning benchmarks, SimKO
consistently yields higher pass@K for a wide range of K, providing a simple way
to improve RLVR's exploration.

</details>


### [49] [Agentic NL2SQL to Reduce Computational Costs](https://arxiv.org/abs/2510.14808)
*Dominik Jehle,Lennart Purucker,Frank Hutter*

Main category: cs.AI

TL;DR: Datalake Agent是一个代理系统，通过交互式循环选择性请求必要信息，大幅减少NL2SQL任务中的token使用量，降低成本同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 传统NL2SQL方法需要处理大量数据库元信息，导致提示过长、token数量多和处理成本高。

Method: 采用代理系统设计，使用交互式循环和推理框架，选择性请求必要信息来解决表格问答任务，而非一次性提供所有元信息。

Result: 在23个数据库和100个表格问答任务上的评估显示，token使用量减少高达87%，成本显著降低，同时保持有竞争力的性能。

Conclusion: Datalake Agent通过选择性信息请求机制，有效解决了NL2SQL任务中元信息过多导致的成本问题，实现了效率与性能的平衡。

Abstract: Translating natural language queries into SQL queries (NL2SQL or Text-to-SQL)
has recently been empowered by large language models (LLMs). Using LLMs to
perform NL2SQL methods on a large collection of SQL databases necessitates
processing large quantities of meta-information about the databases, which in
turn results in lengthy prompts with many tokens and high processing costs. To
address this challenge, we introduce Datalake Agent, an agentic system designed
to enable an LLM to solve NL2SQL tasks more efficiently. Instead of utilizing
direct solvers for NL2SQL that call the LLM once with all meta-information in
the prompt, the Datalake Agent employs an interactive loop to reduce the
utilized meta-information. Within the loop, the LLM is used in a reasoning
framework that selectively requests only the necessary information to solve a
table question answering task. We evaluate the Datalake Agent on a collection
of 23 databases with 100 table question answering tasks. The Datalake Agent
reduces the tokens used by the LLM by up to 87\% and thus allows for
substantial cost reductions while maintaining competitive performance.

</details>


### [50] [RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning](https://arxiv.org/abs/2510.14828)
*Jinrui Liu,Bingyan Nie,Boyu Li,Yaran Chen,Yuze Wang,Shunsen He,Haoran Li*

Main category: cs.AI

TL;DR: 提出了RoboGPT-R1，一个两阶段微调框架，通过监督训练获取基础知识，然后使用强化学习来提升视觉空间理解和推理能力，在EmbodiedBench基准上显著优于GPT-4o-mini和其他模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型和视觉语言模型在长视野操作任务中面临常识和推理能力受限的挑战，监督微调存在泛化能力差和物理理解不足的问题。

Method: 采用两阶段微调框架：监督训练从专家序列获取基础知识，强化学习解决模型的视觉空间理解和推理缺陷，设计了考虑长视野性能和动作约束的基于规则的奖励函数。

Result: 在Qwen2.5-VL-3B上训练的推理模型，在EmbodiedBench基准上比GPT-4o-mini高出21.33%，比在Qwen2.5-VL-7B上训练的其他工作高出20.33%。

Conclusion: RoboGPT-R1框架有效提升了具身智能体的推理能力，在复杂真实环境的长视野操作任务中表现出色。

Abstract: Improving the reasoning capabilities of embodied agents is crucial for robots
to complete complex human instructions in long-view manipulation tasks
successfully. Despite the success of large language models and vision language
models based on Supervised Fine-Tuning (SFT) in planning tasks, they continue
facing challenges in performing long-horizon manipulation tasks in complex
real-world environments, owing to their restricted common sense and reasoning
capabilities. Considering that aligning general-purpose vision language models
to robotic planning tasks via supervised fine-tuning suffers from poor
generalization and insufficient physical understanding, we propose RoboGPT-R1,
a two-stage fine-tuning framework for embodied planning. In this framework,
supervised training acquires foundational knowledge through expert sequences,
followed by RL to address the model's shortcomings in visual-spatial
understanding and reasoning. To achieve physical understanding and action
sequence consistency in multi-step reasoning tasks, we design a rule-based
reward function that simultaneously considers long-horizon performance and
action constraint in the environment. The reasoning model, trained on
Qwen2.5-VL-3B, significantly outperforms the larger-scale model, GPT-4o-mini,
by 21.33% and surpasses other work trained on Qwen2.5-VL-7B by 20.33% on the
EmbodiedBench benchmark.

</details>


### [51] [Boosting Instruction Following at Scale](https://arxiv.org/abs/2510.14842)
*Ben Elder,Evelyn Duesterwald,Vinod Muthusamy*

Main category: cs.AI

TL;DR: 提出Instruction Boosting方法，通过后生成处理提高LLM对提示指令的遵循率，最多可提升7个百分点。同时开发了SCALEDIF基准测试和冲突评分工具，分析多指令冲突对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 开发者通常通过修改提示来影响LLM行为，但仅添加更多指令无法保证它们会被遵循。需要一种方法来提高指令遵循的可靠性。

Method: 提出Instruction Boosting作为后生成方法，并引入SCALEDIF基准测试（最多包含10条指令的数据样本），开发定量冲突评分工具分析指令冲突。

Result: Instruction Boosting将指令遵循率最多提高7个百分点（两条指令）和4个百分点（十条指令）。冲突评分工具成功解释了性能随指令增加而下降的趋势。

Conclusion: Instruction Boosting能有效提高LLM对提示指令的遵循可靠性，冲突评分工具为开发者提供了评估额外指令对模型性能影响的方法。

Abstract: A typical approach developers follow to influence an LLM's behavior in an
application is through careful manipulation of the prompt, such as by adding or
modifying instructions. However, merely adding more instructions provides
little assurance that they will actually be followed. We introduce Instruction
Boosting as a post-generation method to increase the reliability of LLM prompt
instructions. We show that Instruction Boosting improves the instruction
following rate by up to 7 points for two instructions and up to 4 points for
ten instructions. To demonstrate these results we introduce SCALEDIF, a
benchmark with a scaled instruction volume of up to ten instructions per data
sample. We also present an analysis of the commonly observed trend that
performance degrades as more instructions are added. We show that an important
factor contributing to this trend is the degree of tension and conflict that
arises as the number of instructions is increased. We contribute a quantitative
conflict scoring tool that explains the observed performance trends and
provides feedback to developers on the impact that additional prompt
instructions have on a model's performance.

</details>


### [52] [Where to Search: Measure the Prior-Structured Search Space of LLM Agents](https://arxiv.org/abs/2510.14846)
*Zhuo-Yang Song*

Main category: cs.AI

TL;DR: 本文提出了一个紧凑的形式理论来描述和衡量由领域先验指导的LLM辅助迭代搜索，通过模糊关系算子表示智能体，使用覆盖生成函数来衡量可达性难度，并提供可测试的推断。


<details>
  <summary>Details</summary>
Motivation: 基于LLM的生成-过滤-精炼迭代范式在推理、编程和科学AI中的程序发现方面取得了进展，但搜索效果取决于如何将领域先验编码为操作结构化的假设空间。

Method: 将智能体表示为输入和输出的模糊关系算子来捕捉可行转换；通过单一延续参数加权所有可达路径并求和得到覆盖生成函数；提供几何解释和可测试推断。

Result: 该理论提供了一个可操作的语言和工具来衡量智能体及其搜索空间，通过多数投票实例验证了最简单的可测试推断。

Conclusion: 该理论为LLM构建的迭代搜索提供了系统性的形式化描述，能够测量智能体和搜索空间，为领域先验指导的搜索提供了理论基础。

Abstract: The generate-filter-refine (iterative paradigm) based on large language
models (LLMs) has achieved progress in reasoning, programming, and program
discovery in AI+Science. However, the effectiveness of search depends on where
to search, namely, how to encode the domain prior into an operationally
structured hypothesis space. To this end, this paper proposes a compact formal
theory that describes and measures LLM-assisted iterative search guided by
domain priors. We represent an agent as a fuzzy relation operator on inputs and
outputs to capture feasible transitions; the agent is thereby constrained by a
fixed safety envelope. To describe multi-step reasoning/search, we weight all
reachable paths by a single continuation parameter and sum them to obtain a
coverage generating function; this induces a measure of reachability
difficulty; and it provides a geometric interpretation of search on the graph
induced by the safety envelope. We further provide the simplest testable
inferences and validate them via a majority-vote instantiation. This theory
offers a workable language and operational tools to measure agents and their
search spaces, proposing a systematic formal description of iterative search
constructed by LLMs.

</details>


### [53] [LabOS: The AI-XR Co-Scientist That Sees and Works With Humans](https://arxiv.org/abs/2510.14861)
*Le Cong,Zaixi Zhang,Xiaotong Wang,Yin Di,Ruofan Jin,Michal Gerasimiuk,Yinkai Wang,Ravi K. Dinesh,David Smerkous,Alex Smerkous,Xuekun Wu,Shilong Liu,Peishan Li,Yi Zhu,Simran Serrao,Ning Zhao,Imran A. Mohammad,John B. Sunwoo,Joseph C. Wu,Mengdi Wang*

Main category: cs.AI

TL;DR: LabOS是首个将计算推理与物理实验相结合的AI合作科学家，通过多模态感知、自进化智能体和XR技术实现人机协作，将实验室转变为智能协作环境。


<details>
  <summary>Details</summary>
Motivation: 现代科学发展需要思想与行动的结合，当前AI主要停留在计算设计层面，缺乏与物理实验的深度融合。

Method: 通过连接多模型AI智能体、智能眼镜和人机协作，使AI能够看到科学家所见、理解实验背景并协助实时执行。

Result: 在癌症免疫治疗靶点发现和干细胞工程等应用中，LabOS证明AI能够超越计算设计，直接参与实验过程。

Conclusion: LabOS将实验室转变为智能协作环境，实现人类与机器发现共同演进。

Abstract: Modern science advances fastest when thought meets action. LabOS represents
the first AI co-scientist that unites computational reasoning with physical
experimentation through multimodal perception, self-evolving agents, and
Entended-Reality(XR)-enabled human-AI collaboration. By connecting multi-model
AI agents, smart glasses, and human-AI collaboration, LabOS allows AI to see
what scientists see, understand experimental context, and assist in real-time
execution. Across applications--from cancer immunotherapy target discovery to
stem-cell engineering -- LabOS shows that AI can move beyond computational
design to participation, turning the laboratory into an intelligent,
collaborative environment where human and machine discovery evolve together.

</details>


### [54] [Mapping Smarter, Not Harder: A Test-Time Reinforcement Learning Agent That Improves Without Labels or Model Updates](https://arxiv.org/abs/2510.14900)
*Wen-Kwang Tsao,Yao-Ching Yu,Chien-Ming Huang*

Main category: cs.AI

TL;DR: 提出了一种无需标注数据或模型权重更新的强化学习代理，通过生成针对性网络搜索查询来收集外部证据，迭代改进企业日志的模式映射准确性。


<details>
  <summary>Details</summary>
Motivation: 企业智能平台需要整合来自多个第三方供应商的日志，但供应商文档在测试时往往不可用、不匹配或格式混乱，导致模式映射困难。

Method: 使用强化学习代理：1)识别模糊的字段映射尝试；2)生成针对性网络搜索查询收集外部证据；3)应用基于置信度的奖励迭代优化映射。

Result: 将Microsoft Defender for Endpoint日志转换为通用模式，映射准确率从56.4%(仅LLM)提升到72.73%(RAG)再到93.94%(100次迭代)，同时将需要专家评审的低置信度映射减少了85%。

Conclusion: 该方法提供了一种证据驱动、透明的解决方案，为更鲁棒、可问责、可扩展、高效、灵活、适应性强和协作的行业问题解决铺平了道路。

Abstract: The Enterprise Intelligence Platform must integrate logs from numerous
third-party vendors in order to perform various downstream tasks. However,
vendor documentation is often unavailable at test time. It is either misplaced,
mismatched, poorly formatted, or incomplete, which makes schema mapping
challenging. We introduce a reinforcement learning agent that can self-improve
without labeled examples or model weight updates. During inference, the agent:
1) Identifies ambiguous field-mapping attempts. 2) Generates targeted
web-search queries to gather external evidence. 3) Applies a confidence-based
reward to iteratively refine its mappings. To demonstrate this concept, we
converted Microsoft Defender for Endpoint logs into a common schema. Our method
increased mapping accuracy from 56.4\%(LLM-only) to 72.73\%(RAG) to 93.94\%
over 100 iterations using GPT-4o. At the same time, it reduced the number of
low-confidence mappings requiring expert review by 85\%. This new approach
provides an evidence-driven, transparent method for solving future industry
problems, paving the way for more robust, accountable, scalable, efficient,
flexible, adaptable, and collaborative solutions.

</details>


### [55] [Budget-aware Test-time Scaling via Discriminative Verification](https://arxiv.org/abs/2510.14913)
*Kyle Montgomery,Sijun Tan,Yuqi Chen,Siyuan Zhuang,Tianjun Zhang,Raluca Ada Popa,Chenguang Wang*

Main category: cs.AI

TL;DR: 提出了一种结合判别式验证器和自一致性的混合测试时扩展方法，在固定计算预算下显著优于生成式验证方法，在AIME2025上准确率提升高达15.3%。


<details>
  <summary>Details</summary>
Motivation: 生成式验证器虽然性能强大，但计算成本过高，限制了实际应用。本研究转向更注重预算的判别式验证方法。

Method: 采用判别式验证器与自一致性结合的混合方法，在固定计算预算下进行测试时扩展。

Result: 在AIME2025数据集上，该方法比最先进的生成式验证方法准确率提升高达15.3%，且计算效率更高。

Conclusion: 对于实际应用，基于判别式验证器的预算感知扩展不仅是自一致性的"免费"升级，而且是比昂贵生成技术更有效和高效的替代方案。

Abstract: Test-time scaling is a powerful strategy for boosting the performance of
large language models on complex reasoning tasks. While state-of-the-art
approaches often employ generative verifiers to select the best solution from a
pool of candidates, this method incurs prohibitive computational costs,
limiting its practicality. In this work, we shift the focus to a more
budget-aware paradigm: discriminative verification. We conduct a thorough
empirical analysis and demonstrate that while discriminative verifiers may
underperform in isolation, combining them with self-consistency in a hybrid
approach creates a powerful and efficient test-time scaling mechanism. Notably,
under a fixed compute budget, this hybrid approach surpasses state-of-the-art
generative verification by a significant margin: achieving up to 15.3\% higher
accuracy on AIME2025. Our findings establish that for practical, real-world
applications, budget-aware scaling with discriminative verifiers is not only a
"free" upgrade over self-consistency, but also a more effective and efficient
alternative to costly generative techniques. Code is available at
https://github.com/wang-research-lab/verification.

</details>


### [56] [TRI-DEP: A Trimodal Comparative Study for Depression Detection Using Speech, Text, and EEG](https://arxiv.org/abs/2510.14922)
*Annisaa Fitri Nurfidausi,Eleonora Mancini,Paolo Torroni*

Main category: cs.AI

TL;DR: 本文系统研究了多模态抑郁症检测方法，比较了EEG、语音和文本三种模态的特征表示和建模策略，发现三模态组合能提升检测性能，预训练嵌入优于手工特征，精心设计的三模态模型达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 抑郁症检测面临挑战，现有研究范围有限、缺乏系统特征比较、评估协议不一致。本文旨在填补这些空白，系统探索多模态特征表示和建模策略。

Method: 系统评估手工特征与预训练嵌入，比较不同神经编码器，分析单模态、双模态和三模态配置，研究融合策略（特别关注EEG的作用），采用一致的受试者独立分割确保可复现性。

Result: 结果显示：(i) EEG、语音和文本三模态组合增强多模态检测；(ii) 预训练嵌入优于手工特征；(iii) 精心设计的三模态模型达到最先进性能。

Conclusion: 本研究为未来多模态抑郁症检测研究奠定了基础，证明了多模态方法的有效性。

Abstract: Depression is a widespread mental health disorder, yet its automatic
detection remains challenging. Prior work has explored unimodal and multimodal
approaches, with multimodal systems showing promise by leveraging complementary
signals. However, existing studies are limited in scope, lack systematic
comparisons of features, and suffer from inconsistent evaluation protocols. We
address these gaps by systematically exploring feature representations and
modelling strategies across EEG, together with speech and text. We evaluate
handcrafted features versus pre-trained embeddings, assess the effectiveness of
different neural encoders, compare unimodal, bimodal, and trimodal
configurations, and analyse fusion strategies with attention to the role of
EEG. Consistent subject-independent splits are applied to ensure robust,
reproducible benchmarking. Our results show that (i) the combination of EEG,
speech and text modalities enhances multimodal detection, (ii) pretrained
embeddings outperform handcrafted features, and (iii) carefully designed
trimodal models achieve state-of-the-art performance. Our work lays the
groundwork for future research in multimodal depression detection.

</details>


### [57] [Stable but Miscalibrated: A Kantian View on Overconfidence from Filters to Large Language Models](https://arxiv.org/abs/2510.14925)
*Akira Okutomi*

Main category: cs.AI

TL;DR: 将康德的《纯粹理性批判》重新解释为反馈稳定性理论，提出复合不稳定性指数H-Risk来评估推理系统的稳定性，发现在线性高斯模拟和大型语言模型中，高H-Risk与过度自信错误相关。


<details>
  <summary>Details</summary>
Motivation: 建立康德理性自我限制理论与反馈控制理论之间的结构性桥梁，为诊断和减少推理系统中的过度自信提供原则性视角。

Method: 提出复合不稳定性指数H-Risk（结合谱边界、条件数、时间敏感性和创新放大），在线性高斯模拟和大型语言模型中进行验证。

Result: 在线性高斯模拟中，高H-Risk预测过度自信错误；在LLMs中，脆弱的内部动态与校准不良和幻觉相关，批判式提示对校准和幻觉有混合影响。

Conclusion: 康德的自我限制理论与反馈控制之间存在结构性联系，H-Risk为诊断和选择性减少推理系统中的过度自信提供了原则性工具。

Abstract: We reinterpret Kant's Critique of Pure Reason as a theory of feedback
stability, viewing reason as a regulator that keeps inference within the bounds
of possible experience. We formalize this intuition via a composite instability
index (H-Risk) combining spectral margin, conditioning, temporal sensitivity,
and innovation amplification. In linear-Gaussian simulations, higher H-Risk
predicts overconfident errors even under formal stability, revealing a gap
between nominal and epistemic stability. Extending to large language models
(LLMs), we find that fragile internal dynamics correlate with miscalibration
and hallucination, while critique-style prompts show mixed effects on
calibration and hallucination. These results suggest a structural bridge
between Kantian self-limitation and feedback control, offering a principled
lens for diagnosing -- and selectively reducing -- overconfidence in reasoning
systems. This is a preliminary version; supplementary experiments and broader
replication will be reported in a future revision.

</details>


### [58] [GroundedPRM: Tree-Guided and Fidelity-Aware Process Reward Modeling for Step-Level Reasoning](https://arxiv.org/abs/2510.14942)
*Yao Zhang,Yu Wu,Haowei Zhang,Weiguo Li,Haokun Chen,Jingpei Wu,Guohao Li,Zhen Han,Volker Tresp*

Main category: cs.AI

TL;DR: GroundedPRM是一个基于树搜索和外部工具验证的自动过程监督框架，通过蒙特卡洛树搜索构建结构化推理路径，使用外部工具验证中间步骤，结合步骤级验证和全局结果评估，在仅使用10%数据的情况下实现了26%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型(PRMs)面临三大挑战：嘈杂的奖励信号、低事实保真度以及与步骤级推理目标的不对齐。这些问题的根源在于缺乏可扩展的高质量标注，现有方法依赖昂贵的人工标注、容易产生幻觉的LLM自评估或存在信用分配问题的蒙特卡洛估计。

Method: 1) 使用蒙特卡洛树搜索(MCTS)构建结构化推理路径，实现细粒度信用分配；2) 通过外部工具验证每个中间步骤，提供执行基础的正确性信号；3) 设计混合奖励聚合机制，融合工具验证和MCTS反馈；4) 将奖励信号格式化为推理增强的生成结构，提高可解释性。

Result: 仅使用40K自动标注样本(最佳PRM所用数据的10%)，在ProcessBench上实现了高达26%的相对性能提升。在奖励引导的贪婪搜索中，甚至超越了使用人工标注监督训练的PRMs。

Conclusion: GroundedPRM为高质量过程级推理提供了一条可扩展且可验证的路径，通过树引导和保真度感知的框架有效解决了现有PRMs的核心局限性。

Abstract: Process Reward Models (PRMs) aim to improve multi-step reasoning in Large
Language Models (LLMs) by supervising intermediate steps and identifying
errors. However, building effective PRMs remains challenging due to the lack of
scalable, high-quality annotations. Existing approaches rely on costly human
labeling, LLM-based self-evaluation that is prone to hallucination, or Monte
Carlo (MC) estimation, which infers step quality solely from rollout outcomes
and often introduces noisy, misaligned supervision due to credit
misattribution. These issues result in three core limitations: noisy rewards,
low factual fidelity, and misalignment with step-level reasoning objectives. To
address these challenges, we introduce GroundedPRM, a tree-guided and
fidelity-aware framework for automatic process supervision. To reduce reward
noise and enable fine-grained credit assignment, we construct structured
reasoning paths via Monte Carlo Tree Search (MCTS). To eliminate hallucinated
supervision, we validate each intermediate step using an external tool,
providing execution-grounded correctness signals. To combine both step-level
validation and global outcome assessment, we design a hybrid reward aggregation
mechanism that fuses tool-based verification with MCTS-derived feedback.
Finally, we format the reward signal into a rationale-enhanced, generative
structure to promote interpretability and compatibility with instruction-tuned
LLMs. GroundedPRM is trained on only 40K automatically labeled samples,
amounting to just 10% of the data used by the best-performing PRM trained with
auto-labeled supervision. Nevertheless, it achieves up to a 26% relative
improvement in average performance on ProcessBench. When used for reward-guided
greedy search, GroundedPRM outperforms even PRMs trained with human-labeled
supervision, offering a scalable and verifiable path toward high-quality
process-level reasoning.

</details>


### [59] [Agentic Design of Compositional Machines](https://arxiv.org/abs/2510.14980)
*Wenqian Zhang,Weiyang Liu,Zhen Liu*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型在组合式机器设计中的能力，通过BesiegeField测试平台评估LLMs在物理模拟环境中组装标准化组件以满足功能需求的表现，并探索了强化学习作为改进途径。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型是否能够学习创造性设计复杂机器，特别是通过组合标准化组件来满足物理环境中的功能需求，如移动或操作。

Method: 引入BesiegeField测试平台，基于Besiege游戏构建，支持基于部件的构造、物理模拟和奖励驱动评估；对最先进的LLMs进行基准测试，并探索强化学习微调方法。

Result: 当前开源模型在空间推理、战略组装和指令遵循等关键能力上表现不足；通过强化学习微调实验展示了改进潜力，但也指出了语言、机器设计和物理推理交叉领域的挑战。

Conclusion: 大型语言模型在组合式机器设计方面具有潜力，但需要进一步发展空间推理和物理理解能力；强化学习为改进提供了可行路径，但该领域仍面临重要挑战。

Abstract: The design of complex machines stands as both a marker of human intelligence
and a foundation of engineering practice. Given recent advances in large
language models (LLMs), we ask whether they, too, can learn to create. We
approach this question through the lens of compositional machine design: a task
in which machines are assembled from standardized components to meet functional
demands like locomotion or manipulation in a simulated physical environment. To
support this investigation, we introduce BesiegeField, a testbed built on the
machine-building game Besiege, which enables part-based construction, physical
simulation and reward-driven evaluation. Using BesiegeField, we benchmark
state-of-the-art LLMs with agentic workflows and identify key capabilities
required for success, including spatial reasoning, strategic assembly, and
instruction-following. As current open-source models fall short, we explore
reinforcement learning (RL) as a path to improvement: we curate a cold-start
dataset, conduct RL finetuning experiments, and highlight open challenges at
the intersection of language, machine design, and physical reasoning.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [60] [Information flow in multilayer perceptrons: an in-depth analysis](https://arxiv.org/abs/2510.13846)
*Giuliano Armano*

Main category: cs.IT

TL;DR: 本文从信息论角度分析多层感知机中信息流动，提出信息矩阵概念，研究监督学习中的信息处理机制，发现与信息瓶颈框架的优化策略相似性。


<details>
  <summary>Details</summary>
Motivation: 分析多层感知机各层间信息流动对理解人工神经网络至关重要，特别是在监督学习背景下研究信息处理方式。

Method: 从信息论角度构建问题框架，提出信息矩阵概念作为形式化工具，用于理解优化策略的病因学和研究信息流动。

Result: 定义了参数化优化策略，发现信息瓶颈框架中的优化策略与从信息矩阵推导的策略具有强相似性，揭示多层感知机作为"适配器"处理输入的功能。

Conclusion: 多层感知机本质上是一种根据给定目标处理输入的"适配器"，信息矩阵为理解优化策略和信息流动提供了有效框架。

Abstract: Analysing how information flows along the layers of a multilayer perceptron
is a topic of paramount importance in the field of artificial neural networks.
After framing the problem from the point of view of information theory, in this
position article a specific investigation is conducted on the way information
is processed, with particular reference to the requirements imposed by
supervised learning. To this end, the concept of information matrix is devised
and then used as formal framework for understanding the aetiology of
optimisation strategies and for studying the information flow. The underlying
research for this article has also produced several key outcomes: i) the
definition of a parametric optimisation strategy, ii) the finding that the
optimisation strategy proposed in the information bottleneck framework shares
strong similarities with the one derived from the information matrix, and iii)
the insight that a multilayer perceptron serves as a kind of "adaptor", meant
to process the input according to the given objective.

</details>


### [61] [Structure-Preserving Error-Correcting Codes for Polynomial Frames](https://arxiv.org/abs/2510.13882)
*Baigang Chen,Dongfang Zhao*

Main category: cs.IT

TL;DR: 提出了一种结构保持的可靠性层，在多项式环中操作，添加少量系统冗余，无需往返或格式转换即可纠正符号错误/标记擦除。


<details>
  <summary>Details</summary>
Motivation: 现代FFT/NTT分析、编码计算和隐私保护ML接口经常在NIC、存储和加速器之间传输多项式帧。即使罕见的静默数据损坏也可能翻转几个环系数并在下游算术中级联。传统防御不匹配当前低延迟流水线。

Method: 构建了两个互补方案：一个用于奇数长度通过Hensel提升的BCH理想与幂等编码器，另一个用于2的幂长度通过重复根负循环码与导数式解码。使用环自同构进行原地交织以分散突发错误。

Result: 在四个帧大小N=1024,2048,4096,8192上，在符号错误率10^-6-10^-5时达到每帧故障目标10^-9，t=8-9，仅产生0.20%-1.56%开销，交织后容忍约32-72字节未知错误突发（标记为擦除时约加倍）。

Conclusion: 通过将纠错与环语义对齐，从代数编码角度为多项式帧计算的可部署鲁棒性迈出了实际步骤。

Abstract: Modern FFT/NTT analytics, coded computation, and privacy-preserving ML
interface routinely move polynomial frames across NICs, storage, and
accelerators. However, even rare silent data corruption (SDC) can flip a few
ring coefficients and cascade through downstream arithmetic. Conventional
defenses are ill-matched to current low-latency pipelines:
detect-and-retransmit adds RTTs, while byte-stream ECC ignores the algebraic
structure and forces format conversions. To that end, we propose a
structure-preserving reliability layer that operates in the encoded data's
original polynomial ring, adds a small amount of systematic redundancy, and
corrects symbol errors/flagged erasures without round-trip or format changes.
We construct two complementary schemes: one for odd length $N_{odd}$ via a
Hensel-lifted BCH ideal with an idempotent encoder, and one for power-of-two
length $N_{2^m}$ via a repeated-root negacyclic code with derivative-style
decoding. In particular, to stay robust against clustered errors, a ring
automorphism provides in-place interleaving to disperse bursts. Implementation
wise, on four frame sizes $N\!=\!1024, 2048, 4096, 8192$, we meet a per-frame
failure target of $10^{-9}$ at symbol error rates $10^{-6}\text{--}10^{-5}$
with $t\!=\!8\text{--}9$, incurring only $0.20\%\text{--}1.56\%$ overhead and
tolerating $\sim\!32\text{--}72$\,B unknown-error bursts (roughly doubled when
flagged as erasures) after interleaving. By aligning error correction with ring
semantics, we take a practical step toward deployable robustness for
polynomial-frame computations from an algebraic coding perspective.

</details>


### [62] [Location-Aided Distributed Beamforming for Near-Field Communications with Element-Wise RIS](https://arxiv.org/abs/2510.14226)
*Xiao Zheng,Wenchi Cheng,Jingqing Wang,Zhuohui Yao,Jiangzhou Wang*

Main category: cs.IT

TL;DR: 提出了一种新的单元式RIS架构和分布式位置辅助传输方案，用于增强CSI受限的RIS辅助近场通信的反射增益，解决了信道估计困难和离散相位偏移约束问题。


<details>
  <summary>Details</summary>
Motivation: 现有工作忽视了RIS辅助系统中信道估计的固有困难以及实际部署中的离散相位偏移约束，需要设计低复杂度方案来增强反射增益。

Method: 设计了新的单元式RIS架构，提供动态单元选择能力；基于菲涅尔衍射理论构建空间域位置到相位域波相位分布的映射；提出基于确定-对齐相位的分布式波束成形设计。

Result: 渐近分析表明，当RIS较大时，该方案可以通过固定比例的反射单元实现最优增益，仿真验证了其相对于其他协议的优越性。

Conclusion: 所提出的方案能够有效降低估计开销，在CSI受限的RIS辅助近场通信中实现高性能的反射增益。

Abstract: Active reconfigurable intelligent surface (RIS) emerges as an effective
technique to resist the double-fading attenuation of passive RIS. By embedding
with power harvesting function, it further evolves to zero-power active RIS,
which can effectively enhance the flexibility of RIS deployment without
external power demand. Nevertheless, existing works neglected the inherent
difficulty of channel estimation (CE) for RIS-assisted systems, and the
discrete phase shift constraint in practical deployment. In this paper we
design a new element-wise RIS architecture and propose a distributed
location-aided transmission scheme with low complexity to enhance the reflected
gain for channel state information (CSI)-limited RIS-assisted near-field
communications. Specifically, the new element-wise RIS provides dynamic element
selection capability with low hardware resources. Based on Fresnel diffraction
theory, we construct the mapping from locations in space-domain to phase
distributions of waves in phase-domain and reveal the priority of elements for
harvesting and reflecting. {Then, the distributed beamforming design with the
phase of determine-then-align is proposed, where the estimation overhead
reduction stems from exempted requirements of RIS-associated CE at base station
(BS).} The asymptotic analysis indicates that the proposed scheme can achieve
the optimal gain with a fixed proportion of reflective elements when RIS is
large, followed by simulations to verify its superiority to other protocols.

</details>


### [63] [Spatial Computing Communications for Multi-User Virtual Reality in Distributed Mobile Edge Computing Network](https://arxiv.org/abs/2510.14243)
*Caolu Xu,Zhiyong Chen,Meixia Tao,Li Song,Wenjun Zhang*

Main category: cs.IT

TL;DR: 提出空间计算通信(SCC)框架，通过多目标组合优化和MO-CMPO算法解决多用户VR在移动边缘计算网络中的延迟和能耗问题。


<details>
  <summary>Details</summary>
Motivation: 沉浸式VR应用在多用户交互场景中对延迟、能效和计算资源有严格要求，需要解决分布式移动边缘计算网络中的性能瓶颈。

Method: 使用概率模型联合表示物理空间和虚拟空间，将资源部署建模为多目标组合优化问题，提出MO-CMPO算法结合监督学习和强化学习微调，利用稀疏图神经网络生成帕累托最优解。

Result: 在真实世界基站数据集上的仿真显示，MO-CMPO在超体积性能和推理延迟方面优于基线方法，延迟导向方案偏好本地MEC执行，能耗导向方案最小化冗余部署。

Conclusion: SCC框架和MO-CMPO算法能有效平衡多用户VR应用的延迟和能耗需求，为分布式MEC网络提供了实用的部署模式。

Abstract: Immersive virtual reality (VR) applications impose stringent requirements on
latency, energy efficiency, and computational resources, particularly in
multi-user interactive scenarios. To address these challenges, we introduce the
concept of spatial computing communications (SCC), a framework designed to meet
the latency and energy demands of multi-user VR over distributed mobile edge
computing (MEC) networks. SCC jointly represents the physical space, defined by
users and base stations, and the virtual space, representing shared immersive
environments, using a probabilistic model of user dynamics and resource
requirements. The resource deployment task is then formulated as a
multi-objective combinatorial optimization (MOCO) problem that simultaneously
minimizes system latency and energy consumption across distributed MEC
resources. To solve this problem, we propose MO-CMPO, a multi-objective
consistency model with policy optimization that integrates supervised learning
and reinforcement learning (RL) fine-tuning guided by preference weights.
Leveraging a sparse graph neural network (GNN), MO-CMPO efficiently generates
Pareto-optimal solutions. Simulations with real-world New Radio base station
datasets demonstrate that MO-CMPO achieves superior hypervolume performance and
significantly lower inference latency than baseline methods. Furthermore, the
analysis reveals practical deployment patterns: latency-oriented solutions
favor local MEC execution to reduce transmission delay, while energy-oriented
solutions minimize redundant placements to save energy.

</details>


### [64] [Reconfigurable Intelligent Surface-Enabled Channel Signature Modulation](https://arxiv.org/abs/2510.14290)
*M. A. Teeti*

Main category: cs.IT

TL;DR: 提出了一种轻量级的RIS信道签名调制方案，通过将RIS划分为不相交的组并使用预定义的二进制反射模式生成不同的信道签名，在接收端实现索引调制。


<details>
  <summary>Details</summary>
Motivation: 为可重构智能表面设计轻量级的索引调制方案，避免复杂的波束成形，实现简单的信道估计和可扩展的频谱效率。

Method: 将N元RIS划分为不相交的组，每组使用预定义的二进制反射模式生成不同的信道签名，信息嵌入在这些签名的索引中。

Result: 推导了误码概率的闭式上界和容量分析，揭示了分集阶数为n_R，编码增益与N成正比。瑞利衰落下的仿真结果验证了理论分析。

Conclusion: RIS-CSM是一种有效的轻量级调制方案，在低频谱效率下，RIS元素间的空间相关性可以改善系统性能。

Abstract: This work proposes RIS-enabled channel signature modulation (RIS-CSM), a
lightweight index modulation scheme for reconfigurable intelligent surfaces
(RIS). An N-element RIS is partitioned into disjoint groups, each employing
predetermined binary reflection patterns to generate distinct channel
signatures at an $n_R$-antenna receiver, without RIS-side beamforming.
Information is embedded in the indices of these signatures, enabling simple
channel estimation and scalable spectral efficiency. A closed-form upper bound
on error probability and capacity analysis are derived, revealing diversity
order $n_R$ and coding gain proportional to N. Simulation results under
Rayleigh fading validate the theoretical analysis. Moreover, simulations
indicate that spatial correlation among RIS elements can improve system
performance at low spectral efficiency.

</details>


### [65] [The asymptotic number of equivalence classes of linear codes with given dimension](https://arxiv.org/abs/2510.14424)
*Andrea Di Giusto,Alberto Ravagnani*

Main category: cs.IT

TL;DR: 本文研究了具有给定长度和维度的线性码等价类数量的渐近行为，推导了三种标准等价关系下的显式渐近公式，并建立了与布朗运动相关的离散高斯分布的连接。


<details>
  <summary>Details</summary>
Motivation: 之前的研究主要关注固定长度的线性码总数，但当维度随长度变化时的情况尚未被考虑。本文旨在填补这一空白，研究维度作为长度函数的线性码等价类渐近数量。

Method: 使用渐近分析方法，推导了线性码在三种标准等价关系下的显式渐近公式，同时得到了q-二项式系数和的精确渐近表达式。

Result: 获得了固定字母表大小和增长长度下，线性码等价类数量的渐近公式，并建立了这些渐近量与布朗运动产生的离散高斯分布之间的自然连接。

Conclusion: 本文不仅解决了该领域的开放性问题，还为线性码等价类渐近数量提供了概率解释，揭示了其与随机过程理论的深刻联系。

Abstract: We investigate the asymptotic number of equivalence classes of linear codes
with prescribed length and dimension. While the total number of inequivalent
codes of a given length has been studied previously, the case where the
dimension varies as a function of the length has not yet been considered. We
derive explicit asymptotic formulas for the number of equivalence classes under
three standard notions of equivalence, for a fixed alphabet size and increasing
length. Our approach also yields an exact asymptotic expression for the sum of
all q-binomial coefficients, which is of independent interest and answers an
open question in this context. Finally, we establish a natural connection
between these asymptotic quantities and certain discrete Gaussian distributions
arising from Brownian motion, providing a probabilistic interpretation of our
results.

</details>


### [66] [Rotatable Antenna-Enhanced Beamforming: Signal Enhancement and Interference Suppression](https://arxiv.org/abs/2510.14574)
*Jie Feng,Zhenbing Liu,Junjie Dai,Hongbin Chen,Fangjiong Chen*

Main category: cs.IT

TL;DR: 本文研究了可旋转天线增强的单/多波束形成技术，通过优化天线旋转来利用新的空间自由度，显著提高了阵列增益性能。


<details>
  <summary>Details</summary>
Motivation: 传统固定方向天线阵列由于不同转向角度下天线定向增益变化显著，难以有效增强信号和抑制干扰。

Method: 联合优化天线旋转向量和天线权重向量，提出交替优化算法迭代求解，在无干扰单波束情况下推导出闭式最优解。

Result: 仿真结果表明，所提出的可旋转天线方案在阵列增益方面显著优于传统固定方向天线和各向同性天线方案。

Conclusion: 通过利用天线旋转提供的额外空间自由度，可以有效提升波束形成性能，突破传统天线阵列的限制。

Abstract: Conventional beamforming with fixed-orientation antenna (FOA) arrays may
struggle to effectively enhance signal and/or suppress interference due to
significant variations in antenna directive gains over different steering
angles. To break this limitation, we investigate in this paper the rotatable
antenna (RA)-enhanced single/multi-beam forming by exploiting the new spatial
degrees of freedom (DoFs) via antennas' rotation optimization. Specifically,
the antenna rotation vector (ARV) and antenna weight vector (AWV) are jointly
optimized to maximize the minimum array gain over signal directions, subject to
a given constraint on the maximum array gain over interference directions. For
the special case of single-beam forming without interference, the optimal ARV
is derived in closed-form with the maximum ratio combining (MRC) beamformer
applied to the AWV. For the general case of multi-beam forming, we propose an
efficient alternating optimization (AO) algorithm to find a high-quality
suboptimal solution by iteratively optimizing one of the ARV and AWV with the
other being fixed. Simulation results demonstrate that the proposed RA-based
scheme can significantly outperform the traditional FOA-based and isotropic
antenna (IA)-based schemes in terms of array gain.

</details>


### [67] [Task-Based Quantization for Channel Estimation in RIS Empowered MmWave Systems](https://arxiv.org/abs/2510.14649)
*Gyoseung Lee,In-soo Kim,Yonina C. Eldar,A. Lee Swindlehurst,Hyeongtaek Lee,Minje Kim,Junil Choi*

Main category: cs.IT

TL;DR: 本文研究了在低分辨率量化下可重构智能表面赋能的毫米波多用户单输入多输出通信系统的信道估计，提出了基于任务量化的信道估计设计，在有限比特分辨率约束下提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 由于大规模天线阵列和宽信号带宽中模数转换器的高成本和功耗，设计具有低分辨率ADC的毫米波系统是有益的。

Method: 开发了两种信道估计器：针对纯无源RIS元件的级联信道估计器，以及利用RIS处少量半无源元件额外信息的分离信道估计器。

Result: 数值结果表明，所提出的基于任务量化的信道估计设计优于纯数字方法，并能有效接近无限分辨率ADC系统的性能。

Conclusion: 所提出的信道估计器在训练开销较小的情况下优于基线方法，证明了基于任务量化的信道估计在低分辨率ADC系统中的有效性。

Abstract: In this paper, we investigate channel estimation for reconfigurable
intelligent surface (RIS) empowered millimeter-wave (mmWave) multi-user
single-input multiple-output communication systems using low-resolution
quantization. Due to the high cost and power consumption of analog-to-digital
converters (ADCs) in large antenna arrays and for wide signal bandwidths,
designing mmWave systems with low-resolution ADCs is beneficial. To tackle this
issue, we propose a channel estimation design using task-based quantization
that considers the underlying hybrid analog and digital architecture in order
to improve the system performance under finite bit-resolution constraints. Our
goal is to accomplish a channel estimation task that minimizes the mean squared
error distortion between the true and estimated channel. We develop two types
of channel estimators: a cascaded channel estimator for an RIS with purely
passive elements, and an estimator for the separate RIS-related channels that
leverages additional information from a few semi-passive elements at the RIS
capable of processing the received signals with radio frequency chains.
Numerical results demonstrate that the proposed channel estimation designs
exploiting task-based quantization outperform purely digital methods and can
effectively approach the performance of a system with unlimited resolution
ADCs. Furthermore, the proposed channel estimators are shown to be superior to
baselines with small training overhead.

</details>


### [68] [Rate-Adaptive Spatially Coupled MacKay-Neal Codes with Thresholds Close to Capacity](https://arxiv.org/abs/2510.14843)
*Ayman Zahr,Gianluigi Liva*

Main category: cs.IT

TL;DR: 该论文分析了采用空间耦合低密度奇偶校验码作为内码的MacKay-Neal码的渐近性能，通过密度进化方法计算置信传播解码阈值，显示该码能在整个[0,1]码率范围内距离二进制输入加性高斯白噪声信道容量仅0.15dB。


<details>
  <summary>Details</summary>
Motivation: 研究如何设计能在整个码率范围内接近信道容量的自适应码结构，特别是结合空间耦合LDPC码的优势来提升性能。

Method: 使用密度进化方法分析MacKay-Neal码的渐近性能，其中内码采用原图空间耦合LDPC码，并建立适当的并行信道模型来计算置信传播解码阈值。

Result: 空间耦合MN码集合在整个[0,1]码率范围内能够实现距离二进制输入加性高斯白噪声信道容量仅0.15dB的性能。

Conclusion: 空间耦合MN码是一种有效的码率自适应编码方案，能够在宽码率范围内接近信道容量极限。

Abstract: We analyze by density evolution the asymptotic performance of rate-adaptive
MacKay-Neal (MN) code ensembles, where the inner code is a protograph spatially
coupled (SC) low-density parity-check code. By resorting to a suitably-defined
parallel channel model, we compute belief propagation decoding thresholds,
showing that SC MN code ensembles can perform within 0.15 dB from the
binary-input additive white Gaussian noise capacity over the full [0,1] rate
range.

</details>


### [69] [Rate-Adaptive Protograph-Based MacKay-Neal Codes](https://arxiv.org/abs/2510.14856)
*Ayman Zahr,Emna Ben Yacoub,Balázs Matuz,Gianluigi Liva*

Main category: cs.IT

TL;DR: 本文分析了基于原图的速率自适应MacKay-Neal码，通过外部分布匹配器和内层LDPC码实现速率自适应，在固定块长度下可在宽速率范围内接近香农极限1dB以内。


<details>
  <summary>Details</summary>
Motivation: 为高速无线（光）链路提供恒定块长度下的速率灵活性解决方案，使用单一LDPC码集合在宽速率范围内实现接近香农极限的性能。

Method: 采用外部分布匹配器与内层原图LDPC码相结合的非线性编码结构，通过等效通信模型分析性能，进行密度演进和误码平层分析。

Result: 设计示例显示，单一LDPC码集合可在宽速率范围内在香农极限1dB以内工作，速率通过调整DM参数选择。

Conclusion: 该构造为采用二进制输入调制的高速无线（光）链路提供了具有恒定块长度和固定内码的速率灵活性解决方案。

Abstract: Rate-adaptive MacKay-Neal (MN) codes based on protographs are analyzed. The
code construction employs an outer distribution matcher (DM) to adapt the rate
of the scheme. The DM is coupled with an inner protograph-based low-density
parity-check (LDPC) code. The performance achievable by the resulting code
structure, that is nonlinear, is studied by means of an equivalent
communication model that reduces the problem to the analysis of the inner
(linear) LDPC code with transmission that takes place in parallel over the
communication channel, and over a suitably defined binary symmetric channel. A
density evolution analysis of protograph MN code ensembles is outlined, and it
is complemented by an error floor analysis that relies on the derivation of the
average input-output weight distribution of the inner LDPC code ensemble.
Conditions on the shape of the normalized logarithmic asymptotic input-output
weight distribution are defined, which allow discarding code ensembles with bad
error floor properties during the code design phase. Examples of code designs
are provided, showing how the use of a single LDPC code ensemble allows
operating within 1 dB from the Shannon limit over a wide range of code rates,
where the code rate is selected by tuning the DM parameters. By enabling rate
flexibility with a constant blocklength, and with a fixed LDPC code as inner
code, the construction provides an appealing solution for very high-throughput
wireless (optical) links that employ binary-input modulations.

</details>


### [70] [The Whole Is Less than the Sum of Parts: Subsystem Inconsistency in Partial Information Decomposition](https://arxiv.org/abs/2510.14864)
*Aobo Lyu,Andrew Clark,Netanel Raviv*

Main category: cs.IT

TL;DR: 本文指出部分信息分解(PID)框架违反了整体等于部分之和的原则，提出了新的系统信息分解(SID)框架来解决三变量系统中的问题，但证明在四变量及以上系统中，基于格结构的分解方法无法完全消除这一矛盾。


<details>
  <summary>Details</summary>
Motivation: 部分信息分解(PID)自2010年提出以来在多个领域得到应用，但缺乏统一的理论框架，存在关键的概念和技术挑战。作者发现PID违反了整体等于部分之和的基本原则。

Method: 通过三变量系统的反例证明PID违反WESP原则，引入新的系统信息分解(SID)框架，基于协同关系重新定义信息原子的求和规则。

Result: SID框架成功解决了三变量系统中的WESP违反问题，但证明在四变量及以上系统中，任何基于格结构的部分求和方法都无法完全消除WESP不一致性。

Conclusion: 基于反链格结构的信息分解方法对于一般多变量系统存在固有的不适用性。

Abstract: Partial Information Decomposition (PID) was proposed by Williams and Beer in
2010 as a tool for analyzing fine-grained interactions between multiple random
variables, and has since found numerous applications ranging from neuroscience
to privacy. However, a unified theoretical framework remains elusive due to key
conceptual and technical challenges. We identify and illustrate a crucial
problem: PID violates the set-theoretic principle that the whole equals the sum
of its parts (WESP). Through a counterexample in a three-variable system, we
demonstrate how such violations naturally arise, revealing a fundamental
limitation of current lattice-based PID frameworks. To address this issue, we
introduce a new axiomatic framework, termed System Information Decomposition
(SID), specifically tailored for three-variable systems. SID resolves the WESP
violation by redefining the summation rules of decomposed information atoms
based on synergistic relationships. However, we further show that for systems
with four or more variables, no partial summation approach within the existing
lattice-based structures can fully eliminate WESP inconsistencies. Our results
thus highlight the inherent inadequacy of (antichain) lattice-based
decompositions for general multivariate systems.

</details>
