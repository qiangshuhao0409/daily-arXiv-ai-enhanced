<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 11]
- [cs.AI](#cs.AI) [Total: 31]
- [cs.IT](#cs.IT) [Total: 8]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Improving Reliability of Human Trafficking Alerts in Airports](https://arxiv.org/abs/2512.23865)
*Nana Oye Akrofi Quarcoo,Milena Radenkovic*

Main category: cs.NI

TL;DR: 该论文通过应用两种现有的延迟容忍网络协议（Spray and Wait和Epidemic），在机场个人紧急警报场景中评估其投递率和延迟性能，并探讨DTN网络在打击人口贩卖等全球问题中的潜在作用。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索在机场等特定环境中，如何利用延迟容忍网络技术实现个人紧急警报的有效传输，特别是在网络连接不稳定的情况下。同时，研究也关注DTN技术在解决人口贩卖等全球社会问题中的潜在应用价值。

Method: 研究方法包括：1）提供MANETs、DTNs和VANETs的背景知识；2）使用Opportunistic Network Environment（ONE）模拟器模拟机场紧急警报场景；3）应用并比较两种DTN协议：Spray and Wait和Epidemic；4）分析投递率和延迟等性能指标。

Result: 研究结果显示两种协议在机场紧急警报场景中的不同表现，分析了各自的优势和局限性。同时讨论了模拟实验设置的约束条件，并对DTN网络在打击人口贩卖等全球问题中的应用潜力进行了更广泛的探讨。

Conclusion: 结论表明延迟容忍网络协议在机场个人紧急警报场景中具有应用潜力，但需要根据具体需求选择合适的协议。研究还强调了DTN技术在解决人口贩卖等全球社会问题中的重要作用，为未来相关研究和应用提供了参考。

Abstract: This paper investigates the latter scenario of individual emergency alerts in airports by applying two existing benchmark delay tolerant network protocols and evaluating their performance of delivery ratio and latency. First, the paper provides a background on Mobile Ad Hoc Networks (MANETs) and Delay Tolerant Networks (DTNs), as well as Vehicular Ad Hoc Networks (VANETs) as a subset of MANETs. Next, the scenario is simulated using the Opportunistic Network Environment (ONE) simulator and runs the DTN protocols applying Spray and Wait and Epidemic. The study discusses the results, highlighting the advantages and limitations of each protocol within the scenario and addressing constraints of the simulation or experimental setup. A wider discussion then considers related research on technologies that combat human trafficking and the potential role of DTN networks in improving this global issue for the better.

</details>


### [2] [Wireless Multimodal Foundation Model (WMFM): Integrating Vision and Communication Modalities for 6G ISAC Systems](https://arxiv.org/abs/2512.23897)
*Mohammad Farzanullah,Han Zhang,Akram Bin Sediq,Ali Afana,Melike Erol-Kantarci*

Main category: cs.NI

TL;DR: 提出基于对比学习的无线多模态基础模型WMFM，联合学习无线信道系数和视觉图像，在LoS/nLoS分类和用户定位任务上显著优于端到端基准模型，同时大幅减少训练时间和数据需求。


<details>
  <summary>Details</summary>
Motivation: 多模态基础模型的发展为跨数据类型的联合理解提供了新范式。在下一代无线网络中，感知与通信的融合为开发通用性强、数据效率高的模型提供了独特机会。作者旨在建立一个可扩展的多模态学习框架，用于集成感知与通信系统。

Method: 提出无线多模态基础模型WMFM，采用对比学习进行预训练，对齐相机和信道数据的嵌入表示，无需显式标签。预训练编码器被冻结作为特征提取器，配合轻量级任务特定头部进行下游任务微调，包括用户定位和LoS/nLoS分类。

Result: 在DeepVerse6G数据集上的实验表明，WMFM在LoS/nLoS分类任务上平衡准确率提升17%，定位误差降低48.5%，同时训练时间减少高达90倍。即使仅使用20%的数据训练，WMFM仍优于完全监督的端到端模型。

Conclusion: WMFM为集成感知与通信系统中的可扩展多模态学习奠定了基础，为智能自适应6G网络的发展开辟了新途径。该方法展示了对比学习在多模态无线感知中的有效性和数据效率优势。

Abstract: The emergence of multimodal foundation models has revolutionized learning paradigms by enabling joint understanding across diverse data types. In the context of next-generation wireless networks, integrating sensing and communication modalities presents a unique opportunity to develop generalizable and data-efficient models. In this work, we introduce the contrastive learning based Wireless Multimodal Foundation Model (WMFM), a large-scale framework that jointly learns from wireless channel coefficients and visual imagery. The WMFM is pretrained using contrastive learning, a self-supervised learning technique that aligns embeddings of camera and channel data without requiring explicit labels. The pretrained encoders are then frozen and employed as feature extractors, with lightweight task-specific heads, fine-tuned for downstream tasks, including user localization and LoS/nLoS classification. Extensive experiments on the DeepVerse6G dataset demonstrate that the proposed WMFM achieves a 17% improvement in balanced accuracy for LoS/nLoS classification and a 48.5% reduction in localization error compared to the end-to-end (E2E) benchmark, while reducing training time by up to 90-fold. Even when trained with as little as 20% of the data, the WMFM-based heads outperform the fully supervised E2E model, underscoring their robustness and data-efficient learning. The proposed approach establishes a foundation for scalable, multimodal learning in Integrated Sensing and Communication (ISAC) systems, paving the way for intelligent and adaptive 6G networks.

</details>


### [3] [Road Rules for Radio: Why Your Wi-Fi Got Better](https://arxiv.org/abs/2512.23901)
*Bradley Fang,Michael Roger*

Main category: cs.NI

TL;DR: 本文是一篇关于WiFi技术发展的综合性文献综述，重点关注七个关键领域：带宽、电池寿命、流量冲突、干扰、数据密集型传输、多设备连接和峰值吞吐量/调制。文章采用高速公路类比帮助理解，并探讨了即将发布的WiFi 8标准。


<details>
  <summary>Details</summary>
Motivation: WiFi技术发展迅速但复杂难懂，现有文献缺乏对WiFi整体进展的全面概述。本文旨在填补这一空白，为读者提供对WiFi技术演进的系统性理解，特别是针对那些对WiFi了解有限的读者。

Method: 采用文献综述方法，聚焦七个关键技术领域：带宽、电池寿命、流量冲突、干扰、数据密集型传输、多设备连接和峰值吞吐量/调制。每个部分分析问题、解决方案及其局限性。创新性地使用高速公路类比来解释网络机制，并探讨即将发布的WiFi 8标准（基于IEEE 802.11bn UHR规范）。

Result: 提供了对WiFi技术发展的全面概述，特别强调了WiFi 8标准从单纯追求数据速率向优先考虑可靠性的重要转变。通过高速公路类比使复杂概念易于理解，使读者能够获得对WiFi技术的扎实理解。

Conclusion: 本文成功地为读者提供了对WiFi技术发展的全面理解，特别是通过创新的类比方法使复杂概念易于理解。WiFi 8标准代表了技术发展的重要方向转变，从单纯追求速度转向更注重可靠性，这将对未来无线网络发展产生重要影响。

Abstract: WiFi allows for the connection of devices and people around the globe. It has proven to be a monumental and revolutionary tool that keeps the world connected. However, recent WiFi advancements are numerous and at times confusing. WiFi has grown significantly over the years, yet few understand the scope and scale of WiFi progression as a whole. This paper tackles that problem, providing a broad literature review on the advancements of key WiFi features to date. This paper will center on seven key areas of focus: (1) bandwidth, (2) battery life, (3) traffic collisions, (4) interference, (5) data-intensive transmissions, (6) numerous devices, and (7) peak throughput/modulation. Each section will focus on WiFi's problems, how those problems were fixed, as well as the limitations of existing solutions. Moreover, the paper explains the role of new unreleased technologies in these seven areas. This includes exploring the upcoming WiFi 8 standard based on the IEEE 802.11bn "Ultra High Reliability" (UHR) specification and how it builds upon current specifications. Compared to previous specifications, WiFi 8 marks a stronger and more significant shift toward prioritizing reliability over pure data rates. Beyond a sole literature review, this paper uses a novel analogy. A road/highway analogy will be integrated throughout the paper to facilitate understanding of networking mechanisms. This paper is approachable and is written such that someone with very little WiFi knowledge should come away with a strong understanding of WiFi. As is typical of literature review papers, technical claims will be grounded in prior work.

</details>


### [4] [SRM at 30: Lessons from Early Data-Centric Networking and Their Impact on Named Data Networking](https://arxiv.org/abs/2512.23928)
*Tianyuan Yu,Adam Thieme,Junxiao Shi,Lan Wang,Lixia Zhang*

Main category: cs.NI

TL;DR: 本文回顾了1995年SRM可靠多播框架，分析其数据为中心的设计理念及其对后来命名数据网络(NDN)发展的影响，指出SRM在IP网络架构下的局限性以及NDN如何解决这些根本问题。


<details>
  <summary>Details</summary>
Motivation: 重新审视SRM框架，分析其面临的挑战、获得的经验教训，以及它对后来命名数据网络(NDN)发展的影响。探讨数据为中心的网络架构与IP地址为基础的网络架构之间的根本性不匹配问题。

Method: 通过回顾性分析，比较SRM的数据为中心框架与IP地址为基础的网络架构之间的不匹配，并研究SRM如何为NDN的设计提供关键见解。分析SRM的实验结果和架构局限性。

Result: SRM实验揭示了其数据为中心框架与IP地址为基础的网络层之间存在根本性的语义不匹配：应用层命名数据，但网络层对这些名称"视而不见"，导致低效的丢失恢复。NDN通过将网络传输与数据检索模型对齐，并直接保护数据而非通信通道，解决了这一架构摩擦。

Conclusion: SRM的早期见解为NDN的关键设计决策提供了重要信息，NDN的设计体现了数十年网络研究和开发的累积智慧。数据为中心的网络架构代表了网络发展的一个重要方向，解决了传统IP架构在内容分发方面的根本局限性。

Abstract: A 1995 SIGCOMM paper, "A Reliable Multicast Framework for Light-weight Sessions and Application-Level Framing", commonly known as SRM, explored a fundamentally new approach to reliable multiparty data delivery. Rather than adapting established sender-driven reliable unicast mechanisms to multicast, as most contemporaneous proposals did, SRM introduced a data-centric model in which data receivers recover losses by explicitly requesting missing data. Thirty years later, we revisit the SRM framework, examining the challenges it faced, the lessons learned, and its influence on the later development of Named Data Networking (NDN). Experimentations with SRM revealed a fundamental semantic mismatch between its data-centric framework and IP's address-based delivery; while the application layer named data, the network layer remained 'blind' to those names, resulting in inefficient loss recovery. NDN resolves this architectural friction by aligning network delivery with the data-retrieval model and by securing data directly rather than securing communication channels. This retrospective highlights how early insights from SRM informed key design decisions in NDN and illustrates how NDN's design emerged from the cumulative insights gained over decades of networking research and development.

</details>


### [5] [Beyond Dedicated-Active: A General Reliability Provisioning Framework for SFC Placement in Fog Computing](https://arxiv.org/abs/2512.24049)
*Negin Doostar,Mohammad Reza Heidarpour,Amir Khorsandi*

Main category: cs.NI

TL;DR: 本文提出一个可靠性感知的服务功能链放置框架，在异构雾服务器上通过四种冗余策略优化延迟和成本，同时满足可靠性和截止时间约束。


<details>
  <summary>Details</summary>
Motivation: 物联网设备爆炸式增长给传统云基础设施带来压力，需要低延迟和节能的替代方案。雾计算将计算放在网络边缘，但有限的异构雾资源带来可靠性挑战，特别是对任务关键型应用。同时，服务功能链部署方式比单体部署更容易失败，需要智能冗余和放置策略。

Method: 通过可靠性理论视角解决异构雾服务器上的可靠性感知SFC放置问题。探索四种冗余策略（共享vs专用、主动vs备用），提出通用框架以最小化延迟和成本，同时满足可靠性和截止时间约束。将问题建模为整数非线性规划，并开发两种基于遗传算法的解决方案。

Result: 仿真结果表明，共享备用冗余策略比传统的专用主动方法性能提升高达84%。

Conclusion: 本文提出的可靠性感知SFC放置框架能有效优化雾计算环境中的延迟和成本，共享备用冗余策略在异构雾服务器上表现优异，为任务关键型物联网应用提供了可行的解决方案。

Abstract: The explosive growth of Internet of Things (IoT) devices has strained traditional cloud infrastructures, highlighting the need for low-latency and energy-efficient alternatives. Fog computing addresses this by placing computation near the network edge. However, limited and heterogeneous fog resources pose reliability challenges, especially for mission-critical applications. On the other hand, to improve flexibility, applications are deployed as Service Function Chains (SFCs), where each function runs as a Virtual Network Function (VNF). While scalable, this approach is more failure-prone than monolithic deployments, necessitating intelligent redundancy and placement strategies. This paper addresses the reliability-aware SFC placement problem over heterogeneous fog servers through the lens of reliability theory. We explore four redundancy strategies, combining shared vs. dedicated and active vs. standby modes, and propose a general framework to minimize latency and cost while meeting reliability and deadline constraints. The problem is formulated as an Integer Non-Linear Program (INLP), and two genetic algorithm (GA)-based solutions are developed. Simulation results show that shared-standby redundancy outperforms the conventional dedicated-active approach by up to 84%.

</details>


### [6] [Privacy-Preserving Semantic Communications via Multi-Task Learning and Adversarial Perturbations](https://arxiv.org/abs/2512.24452)
*Yalin E. Sagduyu,Tugba Erpek,Aylin Yener,Sennur Ulukus*

Main category: cs.NI

TL;DR: 提出一种深度学习语义通信框架，支持多接收器任务同时限制向窃听者的语义泄露，通过最小-最大优化和对抗性扰动层实现可调隐私保护。


<details>
  <summary>Details</summary>
Motivation: 语义通信虽然提高了带宽效率和鲁棒性，但学习到的语义表示仍可能泄露敏感信息给窃听者。需要设计既能支持合法接收器任务又能限制语义泄露的通信框架。

Method: 采用深度学习框架，合法链路使用学习编码器，接收器训练解码器进行语义推理和数据重建。通过迭代最小-最大优化训练窃听器改进语义推理，同时训练合法收发对保持任务性能并降低窃听成功率。引入辅助层在传输波形上叠加对抗性扰动以降低语义泄露。

Result: 在瑞利衰落信道和加性高斯白噪声环境下，使用MNIST和CIFAR-10数据集评估。语义准确性和重建质量随潜在维度增加而提高，最小-最大机制显著降低窃听器推理性能而不影响合法接收器。扰动层即使在合法链路仅为自己任务训练时也能有效减少语义泄露。

Conclusion: 该框架为现实无线环境中对抗自适应对手提供了可调、端到端的隐私保护语义通信设计思路，实现了任务性能与隐私保护的良好平衡。

Abstract: Semantic communications conveys task-relevant meaning rather than focusing solely on message reconstruction, improving bandwidth efficiency and robustness for next-generation wireless systems. However, learned semantic representations can still leak sensitive information to unintended receivers (eavesdroppers). This paper presents a deep learning-based semantic communication framework that jointly supports multiple receiver tasks while explicitly limiting semantic leakage to an eavesdropper. The legitimate link employs a learned encoder at the transmitter, while the receiver trains decoders for semantic inference and data reconstruction. The security problem is formulated via an iterative min-max optimization in which an eavesdropper is trained to improve its semantic inference, while the legitimate transmitter-receiver pair is trained to preserve task performance while reducing the eavesdropper's success. We also introduce an auxiliary layer that superimposes a cooperative, adversarially crafted perturbation on the transmitted waveform to degrade semantic leakage to an eavesdropper. Performance is evaluated over Rayleigh fading channels with additive white Gaussian noise using MNIST and CIFAR-10 datasets. Semantic accuracy and reconstruction quality improve with increasing latent dimension, while the min-max mechanism reduces the eavesdropper's inference performance significantly without degrading the legitimate receiver. The perturbation layer is successful in reducing semantic leakage even when the legitimate link is trained only for its own task. This comprehensive framework motivates semantic communication designs with tunable, end-to-end privacy against adaptive adversaries in realistic wireless settings.

</details>


### [7] [CPePC: Cooperative and Predictive Popularity based Caching for Named Data Networks](https://arxiv.org/abs/2512.24073)
*Pankaj Chaudhary,Neminath Hubballi,Sameer G. Kulkarni*

Main category: cs.NI

TL;DR: CPePC是一种改进NDN网络性能的协作缓存技术，通过社区划分和领导者协调来减少流行度估计开销，并基于缓存占用和内容流行度预测参数来做出缓存决策。


<details>
  <summary>Details</summary>
Motivation: 现有NDN缓存技术主要基于内容流行度进行缓存，但这种方法需要大量的协调和流行度估计开销。为了解决这个问题，本文提出了CPePC技术，旨在通过减少流行度估计的开销来提高缓存性能。

Method: CPePC采用两种主要方法：1）使用社区估计算法将网络划分为多个非重叠社区，并选择领导者节点代表社区内所有节点进行协调，从而减少流行度估计开销；2）基于当前缓存占用率和内容流行度预测一个参数，该参数用于指导缓存决策。论文提供了社区检测、领导者选择、内容流行度估计和缓存决策的算法。

Result: 通过离散事件模拟器对CPePC与六种最先进的缓存技术进行比较评估，结果显示CPePC在性能上优于其他方法。

Conclusion: CPePC是一种有效的协作缓存技术，能够通过减少流行度估计开销和智能的缓存决策机制，显著提高命名数据网络的缓存性能。

Abstract: Caching content is an inherent feature of Named Data Networks. Limited cache capacity of routers warrants that the choice of content being cached is judiciously done. Existing techniques resort to caching popular content to maximize utilization. However, these methods experience significant overhead for coordinating and estimating the popularity of content. To address this issue, in this paper, we present CPePC, which is a cooperative caching technique designed to improve performance. It accomplishes this through a combination of two factors. First, CPePC enhances efficiency by minimizing the overhead of popularity estimation. Second, it forecasts a parameter that governs caching decisions. Efficiency in popularity estimation is achieved by dividing the network into several non-overlapping communities using a community estimation algorithm and selecting a leader node to coordinate this on behalf of all the nodes in the community. CPePC bases its caching decisions by predicting a parameter whose value is estimated using current cache occupancy and the popularity of the content into account. We present algorithms for community detection, leader selection, content popularity estimation, and caching decisions made by the CPePC method. We evaluate and compare it with six other state-of-the-art caching techniques, with simulations performed using a discrete event simulator to show that it outperforms others.

</details>


### [8] [Chat-Driven Optimal Management for Virtual Network Services](https://arxiv.org/abs/2512.24614)
*Yuya Miyaoka,Masaki Inoue,Kengo Urata,Shigeaki Harada*

Main category: cs.NI

TL;DR: 提出一个结合自然语言处理与优化算法的聊天驱动网络管理框架，通过两阶段系统（意图解释器+优化器）实现可靠、可解释的虚拟网络服务配置


<details>
  <summary>Details</summary>
Motivation: 传统基于意图的网络管理方法依赖统计语言模型解释用户意图，但无法保证生成配置的可行性。需要开发既能理解自然语言又能确保配置可行的框架

Method: 采用两阶段框架：1) 解释器使用NLP从自然语言提示中提取意图（两种实现：Sentence-BERT+SVM分类器和LLM），将用户聊天转换为参数更新方向；2) 优化器通过整数线性规划计算可行的虚拟机放置和路由方案

Result: 实验表明框架能在单用户和多用户场景中动态更新虚拟机放置和路由，同时保持可行性。LLM提取器在较少标注样本下达到更高准确率，Sentence-BERT+SVM分类器延迟显著更低，适合实时操作

Conclusion: 结合NLP驱动的意图提取与基于优化的分配方法，能实现安全、可解释、用户友好的虚拟网络管理，为网络自动化提供了有效解决方案

Abstract: This paper proposes a chat-driven network management framework that integrates natural language processing (NLP) with optimization-based virtual network allocation, enabling intuitive and reliable reconfiguration of virtual network services. Conventional intent-based networking (IBN) methods depend on statistical language models to interpret user intent but cannot guarantee the feasibility of generated configurations. To overcome this, we develop a two-stage framework consisting of an Interpreter, which extracts intent from natural language prompts using NLP, and an Optimizer, which computes feasible virtual machine (VM) placement and routing via an integer linear programming. In particular, the Interpreter translates user chats into update directions, i.e., whether to increase, decrease, or maintain parameters such as CPU demand and latency bounds, thereby enabling iterative refinement of the network configuration. In this paper, two intent extractors, which are a Sentence-BERT model with support vector machine (SVM) classifiers and a large language model (LLM), are introduced. Experiments in single-user and multi-user settings show that the framework dynamically updates VM placement and routing while preserving feasibility. The LLM-based extractor achieves higher accuracy with fewer labeled samples, whereas the Sentence-BERT with SVM classifiers provides significantly lower latency suitable for real-time operation. These results underscore the effectiveness of combining NLP-driven intent extraction with optimization-based allocation for safe, interpretable, and user-friendly virtual network management.

</details>


### [9] [Hierarchical Online Optimization Approach for IRS-enabled Low-altitude MEC in Vehicular Networks](https://arxiv.org/abs/2512.24659)
*Yixian Wang,Geng Sun,Zemin Sun,Jiacheng Wang,Changyuan Zhao,Daxin Tian,Dusit Niyato,Shiwen Mao*

Main category: cs.NI

TL;DR: 提出IRS增强的低空多接入边缘计算架构，通过分层在线优化方法最小化任务完成延迟和能耗，相比基准方法分别降低2.5%和3.1%。


<details>
  <summary>Details</summary>
Motivation: 为了解决空中-地面连接在遮挡环境下的通信问题，并优化边缘计算系统的任务完成延迟和能耗，提出结合智能反射表面（IRS）的低空多接入边缘计算架构。

Method: 采用分层在线优化方法（HOOA）：1）将多目标优化问题重构为Stackelberg博弈；2）在跟随者层面使用多对一匹配机制生成离散决策；3）在领导者层面提出生成扩散模型增强的TD3算法（GDMTD3）结合KKT方法确定连续决策。

Result: 相比最佳基准方法和最先进的DRL算法，平均任务完成延迟降低2.5%，平均能耗降低3.1%，在动态环境中表现出优越的收敛稳定性、鲁棒性和可扩展性。

Conclusion: 提出的IRS增强低空MEC架构和分层在线优化方法能有效解决NP-hard优化问题，显著提升系统性能，为动态环境中的边缘计算提供高效解决方案。

Abstract: In this paper, we propose an intelligent reflecting surface (IRS)-enabled low-altitude multi-access edge computing (MEC) architecture, where an aerial MEC server cooperates with a terrestrial MEC server to provide computing services, while hybrid IRSs (i.e., building-installed and UAV-carried IRSs) are deployed to enhance the air-ground connectivity under blockage. Based on this architecture, we formulate a multi-objective optimization problem (MOOP) to minimize the task completion delay and energy consumption by jointly optimizing task offloading, UAV trajectory control, IRS phase-shift configuration, and computation resource allocation. The considered problem is NP-hard, and thus we propose a hierarchical online optimization approach (HOOA) to efficiently solve the problem. Specifically, we reformulate the MOOP as a Stackelberg game, where MEC servers collectively act as the leader to determine the system-level decisions, while the vehicles act as followers to make individual decisions. At the follower level, we present a many-to-one matching mechanism to generate feasible discrete decisions. At the leader level, we propose a generative diffusion model-enhanced twin delayed deep deterministic policy gradient (GDMTD3) algorithm integrated with a Karush-Kuhn-Tucker (KKT)-based method, which is a deep reinforcement learning (DRL)-based approach, to determine the continuous decisions. Simulation results demonstrate that the proposed HOOA achieves significant improvements, which reduces average task completion delay by 2.5% and average energy consumption by 3.1% compared with the best-performing benchmark approach and state-of-the-art DRL algorithm, respectively. Moreover, the proposed HOOA exhibits superior convergence stability while maintaining strong robustness and scalability in dynamic environments.

</details>


### [10] [Analyzing Communication Predictability in LLM Training](https://arxiv.org/abs/2512.24750)
*Wenxue Li,Xiangzhou Liu,Yuxuan Li,Yilun Jin,Zhenghang Ren,Xudong Liao,Han Tian,Bo Ren,Zhizhen Zhong,Guyue Liu,Ying Zhang,Kai Chen*

Main category: cs.NI

TL;DR: 本文系统化地研究了分布式训练中通信可预测性，特别是在使用混合并行的大型语言模型训练中。通过分析流量模式和通信开销，开发了通信开销的解析公式，并基于此构建了配置调优工具ConfigTuner，显著提升了训练吞吐量。


<details>
  <summary>Details</summary>
Motivation: 分布式训练中通信可预测性对性能至关重要，但现有研究主要通过在线分析进行运行时优化，缺乏系统化的理解。特别是在使用混合并行的大型语言模型训练中，需要系统化地理解和利用通信可预测性来优化训练性能。

Method: 1. 系统化地形式化分布式训练中的通信可预测性，特别是在LLM混合并行训练中；2. 分析典型LLM中的可预测流量模式；3. 评估影响GPU利用率和有效带宽的各种因素；4. 开发通信开销的解析估计公式；5. 基于该公式构建配置调优工具ConfigTuner。

Result: 1. 开发的通信开销估计公式与经验数据高度吻合；2. ConfigTuner优化的训练配置相比Megatron-LM实现了最高1.36倍的吞吐量提升；3. 相比Alpa，ConfigTuner在生成相同配置建议的同时显著降低了搜索复杂度。

Conclusion: 本文系统化地研究了分布式训练中的通信可预测性，特别是在LLM混合并行训练中。通过开发准确的通信开销分析公式和构建ConfigTuner工具，显著提升了训练性能并降低了配置搜索复杂度，为分布式训练优化提供了有效方法。

Abstract: Effective communication is essential in distributed training, with predictability being one of its most significant characteristics. However, existing studies primarily focus on exploiting predictability through online profiling for runtime optimization, without a systematic understanding of it. In this work, we aim to systematically formulate communication predictability in distributed training, particularly in Large Language Models (LLMs) that utilize hybrid parallelism. Our analysis focuses on both traffic patterns and communication overhead. Specifically, we investigate predictable traffic patterns in typical LLMs and evaluate how various factors influence GPU utilization and effective bandwidth (two critical variables affecting communication overhead). Furthermore, we develop an analytical formulation to estimate communication overhead in LLM training, which is validated with high accuracy against empirical data. Leveraging this formulation, we propose a configuration tuning tool, ConfigTuner, to optimize training performance. Compared to Megatron-LM, the training configurations optimized by ConfigTuner demonstrate up to a 1.36$\times$ increase in throughput. Compared to Alpa, ConfigTuner generates the same configuration suggestion while significantly reducing the search complexity.

</details>


### [11] [Sidelink Positioning: Standardization Advancements, Challenges and Opportunities](https://arxiv.org/abs/2512.24803)
*Yuan Gao,Guangjin Pan,Zhiyong Zhong,Zhengyu Jin,Yichen Hu,Yifei Jin,Shugong Xu*

Main category: cs.NI

TL;DR: 本文全面总结了3GPP Rel-18中侧链路定位的最新标准化进展，评估了不同定位方法在非理想因素下的性能，并讨论了未来研究方向和挑战。


<details>
  <summary>Details</summary>
Motivation: 随着蜂窝网络在V2X、公共安全、工业物联网等需要精确定位信息的垂直行业中的集成，定位已成为未来无线网络的必要组成部分。传统蜂窝定位在UE与基站距离较远或非视距场景下性能下降，因此3GPP Rel-18提出标准化侧链路定位，通过UE间的直接定位信令扩展定位覆盖范围。

Method: 本文采用标准化分析和技术评估方法：1）全面总结3GPP在侧链路定位方面的标准化进展，包括网络架构、定位类型和性能要求；2）评估不同定位方法在各种非理想因素下的能力；3）基于3GPP Rel-19的演进讨论可能的研究方向和挑战。

Result: 文章系统梳理了3GPP侧链路定位的标准化框架，分析了不同定位方法在实际非理想条件下的性能表现，揭示了侧链路定位的能力边界，特别是实现3GPP定义定位精度所需的频谱资源问题。

Conclusion: 侧链路定位为扩展蜂窝网络定位覆盖提供了独特机会，但其实际能力仍存在争议，特别是在频谱需求方面。未来需要进一步研究以解决3GPP Rel-19演进中的技术挑战，推动侧链路定位在垂直行业中的实际应用。

Abstract: With the integration of cellular networks in vertical industries that demand precise location information, such as vehicle-to-everything (V2X), public safety, and Industrial Internet of Things (IIoT), positioning has become an imperative component for future wireless networks. By exploiting a wider spectrum, multiple antennas and flexible architectures, cellular positioning achieves ever-increasing positioning accuracy. Still, it faces fundamental performance degradation when the distance between user equipment (UE) and the base station (BS) is large or in non-line-of-sight (NLoS) scenarios. To this end, the 3rd generation partnership project (3GPP) Rel-18 proposes to standardize sidelink (SL) positioning, which provides unique opportunities to extend the positioning coverage via direct positioning signaling between UEs. Despite the standardization advancements, the capability of SL positioning is controversial, especially how much spectrum is required to achieve the positioning accuracy defined in 3GPP. To this end, this article summarizes the latest standardization advancements of 3GPP on SL positioning comprehensively, covering a) network architecture; b) positioning types; and c) performance requirements. The capability of SL positioning using various positioning methods under different imperfect factors is evaluated and discussed in-depth. Finally, according to the evolution of SL in 3GPP Rel-19, we discuss the possible research directions and challenges of SL positioning.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [BatteryAgent: Synergizing Physics-Informed Interpretation with LLM Reasoning for Intelligent Battery Fault Diagnosis](https://arxiv.org/abs/2512.24686)
*Songqi Zhou,Ruixue Liu,Boman Su,Jiazhou Wang,Yixing Wang,Benben Jiang*

Main category: cs.AI

TL;DR: 提出BatteryAgent框架，结合物理特征与LLM推理能力，实现锂电池故障的智能诊断与根因分析，超越传统二分类方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法的"黑盒"特性缺乏可解释性，且受限于二分类范式，无法提供根因分析和维护建议，需要更智能的诊断方案。

Method: 提出三层框架：物理感知层提取10个电化学机制特征；检测归因层使用梯度提升决策树和SHAP量化特征贡献；推理诊断层利用LLM作为智能体核心，构建"数值-语义"桥梁生成综合诊断报告。

Result: BatteryAgent有效纠正边界样本的误分类，AUROC达到0.986，显著优于现有方法，实现从二分类检测到多类型可解释诊断的扩展。

Conclusion: 该框架为电池安全管理提供了从"被动检测"到"智能诊断"的新范式转变，结合物理知识与LLM推理能力，实现全面故障分析。

Abstract: Fault diagnosis of lithium-ion batteries is critical for system safety. While existing deep learning methods exhibit superior detection accuracy, their "black-box" nature hinders interpretability. Furthermore, restricted by binary classification paradigms, they struggle to provide root cause analysis and maintenance recommendations. To address these limitations, this paper proposes BatteryAgent, a hierarchical framework that integrates physical knowledge features with the reasoning capabilities of Large Language Models (LLMs). The framework comprises three core modules: (1) A Physical Perception Layer that utilizes 10 mechanism-based features derived from electrochemical principles, balancing dimensionality reduction with physical fidelity; (2) A Detection and Attribution Layer that employs Gradient Boosting Decision Trees and SHAP to quantify feature contributions; and (3) A Reasoning and Diagnosis Layer that leverages an LLM as the agent core. This layer constructs a "numerical-semantic" bridge, combining SHAP attributions with a mechanism knowledge base to generate comprehensive reports containing fault types, root cause analysis, and maintenance suggestions. Experimental results demonstrate that BatteryAgent effectively corrects misclassifications on hard boundary samples, achieving an AUROC of 0.986, which significantly outperforms current state-of-the-art methods. Moreover, the framework extends traditional binary detection to multi-type interpretable diagnosis, offering a new paradigm shift from "passive detection" to "intelligent diagnosis" for battery safety management.

</details>


### [13] [The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models](https://arxiv.org/abs/2512.23850)
*Rahul Baxi*

Main category: cs.AI

TL;DR: 本文提出DDFT框架，通过语义压缩和对抗性伪造测试来评估语言模型的认知稳健性，发现模型规模与稳健性无关，而错误检测能力是关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评估（如MMLU、TruthfulQA）只测量理想条件下的知识掌握，无法评估在信息退化或对抗性攻击下的认知稳健性。需要新的评估方法来测量模型在现实压力下保持事实准确性的能力。

Method: 提出Drill-Down and Fabricate Test (DDFT)协议，通过渐进语义压缩和对抗性伪造来测试认知稳健性。采用两系统认知模型：语义系统生成流畅文本，认知验证器验证事实准确性。评估了9个前沿模型在8个知识领域和5个压缩级别（共1800次轮级评估）。

Result: 认知稳健性与传统设计范式正交：参数数量（r=0.083, p=0.832）和架构类型（r=0.153, p=0.695）均不显著预测稳健性。错误检测能力强烈预测整体稳健性（rho=-0.817, p=0.007）。旗舰模型表现出脆弱性，而较小模型可实现稳健性能。

Conclusion: 认知稳健性主要取决于训练方法和验证机制，而非模型规模。DDFT框架为关键应用部署前评估认知稳健性提供了理论基础和实用工具，挑战了模型规模与可靠性关系的传统假设。

Abstract: Current language model evaluations measure what models know under ideal conditions but not how robustly they know it under realistic stress. Static benchmarks like MMLU and TruthfulQA cannot distinguish a model that lacks knowledge from one whose verification mechanisms collapse when information degrades or adversaries probe for weaknesses. We introduce the Drill-Down and Fabricate Test (DDFT), a protocol that measures epistemic robustness: a model's ability to maintain factual accuracy under progressive semantic compression and adversarial fabrication. We propose a two-system cognitive model comprising a Semantic System that generates fluent text and an Epistemic Verifier that validates factual accuracy. Our findings, based on evaluating 9 frontier models across 8 knowledge domains at 5 compression levels (1,800 turn-level evaluations), reveal that epistemic robustness is orthogonal to conventional design paradigms. Neither parameter count (r=0.083, p=0.832) nor architectural type (r=0.153, p=0.695) significantly predicts robustness, suggesting it emerges from training methodology and verification mechanisms distinct from current approaches. Error detection capability strongly predicts overall robustness (rho=-0.817, p=0.007), indicating this is the critical bottleneck. We find that flagship models exhibit brittleness despite their scale, while smaller models can achieve robust performance, challenging assumptions about the relationship between model size and reliability. The DDFT framework provides both theoretical foundation and practical tools for assessing epistemic robustness before deployment in critical applications.

</details>


### [14] [CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution](https://arxiv.org/abs/2512.23880)
*Xu Huang,Junwu Chen,Yuxing Fei,Zhuohan Li,Philippe Schwaller,Gerbrand Ceder*

Main category: cs.AI

TL;DR: CASCADE是一个自进化的LLM智能体框架，通过持续学习和自我反思等元技能，使智能体能够掌握复杂外部工具并积累可执行技能，在科学任务上达到93.3%的成功率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体依赖预定义工具或脆弱的工具生成，限制了其在复杂科学任务中的能力和适应性。需要从"LLM+工具使用"向"LLM+技能获取"转变。

Method: CASCADE框架包含两个核心元技能：1) 通过网页搜索和代码提取进行持续学习；2) 通过内省和知识图谱探索进行自我反思。框架支持人类-智能体协作和记忆巩固。

Result: 在SciSkillBench基准测试（116个材料科学和化学研究任务）上，使用GPT-5的CASCADE达到93.3%的成功率，相比没有进化机制的35.4%有显著提升。展示了在计算分析、自主实验室实验和论文选择性复现等实际应用。

Conclusion: CASCADE通过积累可跨智能体和科学家共享的可执行技能，推动了可扩展的AI辅助科学研究，代表了从工具使用到技能获取的重要转变。

Abstract: Large language model (LLM) agents currently depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks. We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from "LLM + tool use" to "LLM + skill acquisition". CASCADE enables agents to master complex external tools and codify knowledge through two meta-skills: continuous learning via web search and code extraction, and self-reflection via introspection and knowledge graph exploration, among others. We evaluate CASCADE on SciSkillBench, a benchmark of 116 materials science and chemistry research tasks. CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms. We further demonstrate real-world applications in computational analysis, autonomous laboratory experiments, and selective reproduction of published papers. Along with human-agent collaboration and memory consolidation, CASCADE accumulates executable skills that can be shared across agents and scientists, moving toward scalable AI-assisted scientific research.

</details>


### [15] [A Proof-of-Concept for Explainable Disease Diagnosis Using Large Language Models and Answer Set Programming](https://arxiv.org/abs/2512.23932)
*Ioanna Gemou,Evangelos Lamprou*

Main category: cs.AI

TL;DR: McCoy框架结合大型语言模型与答案集编程，通过LLM将医学文献转化为ASP代码，结合患者数据生成可解释的疾病诊断预测。


<details>
  <summary>Details</summary>
Motivation: 准确疾病预测对及时干预和有效治疗至关重要。虽然符号AI已应用于医疗保健，但由于构建高质量知识库需要大量努力，其采用仍然有限。

Method: McCoy框架结合大型语言模型与答案集编程：1) LLM将医学文献翻译成ASP代码；2) 将生成的ASP代码与患者数据结合；3) 使用ASP求解器处理得出最终诊断。

Result: 初步结果显示McCoy在小规模疾病诊断任务上表现良好，创建了一个强大且可解释的预测框架。

Conclusion: McCoy通过结合LLM和ASP的优势，克服了传统符号AI在医疗领域应用中的知识库构建障碍，为疾病预测提供了可解释的解决方案。

Abstract: Accurate disease prediction is vital for timely intervention, effective treatment, and reducing medical complications. While symbolic AI has been applied in healthcare, its adoption remains limited due to the effort required for constructing high-quality knowledge bases. This work introduces McCoy, a framework that combines Large Language Models (LLMs) with Answer Set Programming (ASP) to overcome this barrier. McCoy orchestrates an LLM to translate medical literature into ASP code, combines it with patient data, and processes it using an ASP solver to arrive at the final diagnosis. This integration yields a robust, interpretable prediction framework that leverages the strengths of both paradigms. Preliminary results show McCoy has strong performance on small-scale disease diagnosis tasks.

</details>


### [16] [SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing](https://arxiv.org/abs/2512.24008)
*Gaurab Chhetri,Subasish Das,Tausif Islam Chowdhury*

Main category: cs.AI

TL;DR: SPARK是一个基于多智能体LLM的个性化搜索框架，通过角色化智能体协作实现动态检索和个性化，模拟人类信息寻求行为的复杂性。


<details>
  <summary>Details</summary>
Motivation: 传统个性化搜索系统受限于静态用户画像和单一检索流程，难以捕捉用户动态、多维的信息需求。需要能够建模用户信息寻求行为的复杂性、流动性和上下文敏感性的新一代搜索系统。

Method: SPARK框架包含：1）定义角色、专业领域、任务上下文和领域的角色空间；2）动态解释查询并激活相关专业智能体的角色协调器；3）每个智能体执行独立的检索增强生成过程，配备长短期记忆存储和上下文感知推理模块；4）通过共享内存库、迭代辩论和中继式知识转移等结构化通信协议促进智能体协作。

Result: 框架产生了关于协调效率、个性化质量和认知负载分布的可测试预测，同时包含持续角色细化的自适应学习机制。通过整合细粒度智能体专业化和协作检索，SPARK为能够捕捉人类信息寻求行为复杂性的下一代搜索系统提供了见解。

Conclusion: SPARK展示了如何通过分布式智能体行为和最小协调规则实现涌现的个性化特性，为建模用户动态、多维信息需求提供了认知架构、多智能体协调理论和信息检索原则的集成框架。

Abstract: Personalized search demands the ability to model users' evolving, multi-dimensional information needs; a challenge for systems constrained by static profiles or monolithic retrieval pipelines. We present SPARK (Search Personalization via Agent-Driven Retrieval and Knowledge-sharing), a framework in which coordinated persona-based large language model (LLM) agents deliver task-specific retrieval and emergent personalization. SPARK formalizes a persona space defined by role, expertise, task context, and domain, and introduces a Persona Coordinator that dynamically interprets incoming queries to activate the most relevant specialized agents. Each agent executes an independent retrieval-augmented generation process, supported by dedicated long- and short-term memory stores and context-aware reasoning modules. Inter-agent collaboration is facilitated through structured communication protocols, including shared memory repositories, iterative debate, and relay-style knowledge transfer. Drawing on principles from cognitive architectures, multi-agent coordination theory, and information retrieval, SPARK models how emergent personalization properties arise from distributed agent behaviors governed by minimal coordination rules. The framework yields testable predictions regarding coordination efficiency, personalization quality, and cognitive load distribution, while incorporating adaptive learning mechanisms for continuous persona refinement. By integrating fine-grained agent specialization with cooperative retrieval, SPARK provides insights for next-generation search systems capable of capturing the complexity, fluidity, and context sensitivity of human information-seeking behavior.

</details>


### [17] [ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment](https://arxiv.org/abs/2512.24040)
*Natchaya Temyingyong,Daman Jain,Neeraj Kumarsahu,Prabhat Kumar,Rachata Phondi,Wachiravit Modecrua,Krittanon Kaewtawee,Krittin Pachtrachai,Touchapon Kraisingkorn*

Main category: cs.AI

TL;DR: ROAD框架通过自动化调试而非随机搜索优化LLM提示，无需标注数据集，在冷启动场景下显著提升代理性能


<details>
  <summary>Details</summary>
Motivation: 现实软件工程中，LLM代理开发初期通常缺乏标注数据集，只有混乱的生产日志和不断演化的失败模式，需要一种无需黄金标准开发集的自动提示优化方法

Method: ROAD采用多智能体架构：分析器进行根因分析、优化器进行模式聚合、教练进行策略集成，将非结构化失败日志转换为结构化的决策树协议

Result: 在学术基准和生产知识管理引擎上，ROAD仅通过3次自动迭代就使成功率提升5.6%，搜索准确率提升3.8%；在零售领域复杂推理任务中，代理性能相对基线提升约19%

Conclusion: 模仿人类工程循环（失败分析和修复）为部署可靠LLM代理提供了一种可行且数据高效的方法，可作为资源密集型强化学习训练的替代方案

Abstract: Automatic Prompt Optimization (APO) has emerged as a critical technique for enhancing Large Language Model (LLM) performance, yet current state-of-the-art methods typically rely on large, labeled gold-standard development sets to compute fitness scores for evolutionary or Reinforcement Learning (RL) approaches. In real-world software engineering, however, such curated datasets are rarely available during the initial cold start of agent development, where engineers instead face messy production logs and evolving failure modes. We present ROAD (Reflective Optimization via Automated Debugging), a novel framework that bypasses the need for refined datasets by treating optimization as a dynamic debugging investigation rather than a stochastic search. Unlike traditional mutation strategies, ROAD utilizes a specialized multi-agent architecture, comprising an Analyzer for root-cause analysis, an Optimizer for pattern aggregation, and a Coach for strategy integration, to convert unstructured failure logs into robust, structured Decision Tree Protocols. We evaluated ROAD across both a standardized academic benchmark and a live production Knowledge Management engine. Experimental results demonstrate that ROAD is highly sample-efficient, achieving a 5.6 percent increase in success rate (73.6 percent to 79.2 percent) and a 3.8 percent increase in search accuracy within just three automated iterations. Furthermore, on complex reasoning tasks in the retail domain, ROAD improved agent performance by approximately 19 percent relative to the baseline. These findings suggest that mimicking the human engineering loop of failure analysis and patching offers a viable, data-efficient alternative to resource-intensive RL training for deploying reliable LLM agents.

</details>


### [18] [LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm](https://arxiv.org/abs/2512.24077)
*Chunhui Wan,Xunan Dai,Zhuo Wang,Minglei Li,Yanpeng Wang,Yinan Mao,Yu Lan,Zhiwen Xiao*

Main category: cs.AI

TL;DR: LoongFlow是一个自进化智能体框架，通过将LLM集成到"计划-执行-总结"认知范式中，解决了传统进化方法在代码空间中的过早收敛和低效探索问题，显著提升了进化效率并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统进化方法缺乏结构化推理，导致从静态LLM向自改进智能体过渡困难，现有方法在代码空间中存在过早收敛和低效探索的问题。

Method: 提出LoongFlow框架，将LLM集成到"计划-执行-总结"认知范式中，采用混合进化记忆系统（结合多岛模型、MAP-Elites和自适应玻尔兹曼选择）来平衡探索与利用，并实例化为通用智能体和ML智能体。

Result: 在AlphaEvolve基准测试和Kaggle竞赛中，LoongFlow比OpenEvolve、ShinkaEvolve等基线方法进化效率提升高达60%，同时发现了更优的解决方案。

Conclusion: LoongFlow在自主科学发现领域迈出了重要一步，能够以更低的计算开销生成专家级解决方案，标志着从静态LLM向自进化智能体的重要进展。

Abstract: The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address these challenges, we introduce LoongFlow, a self-evolving agent framework that achieves state-of-the-art solution quality with significantly reduced computational costs. Unlike "blind" mutation operators, LoongFlow integrates LLMs into a cognitive "Plan-Execute-Summarize" (PES) paradigm, effectively mapping the evolutionary search to a reasoning-heavy process. To sustain long-term architectural coherence, we incorporate a hybrid evolutionary memory system. By synergizing Multi-Island models with MAP-Elites and adaptive Boltzmann selection, this system theoretically balances the exploration-exploitation trade-off, maintaining diverse behavioral niches to prevent optimization stagnation. We instantiate LoongFlow with a General Agent for algorithmic discovery and an ML Agent for pipeline optimization. Extensive evaluations on the AlphaEvolve benchmark and Kaggle competitions demonstrate that LoongFlow outperforms leading baselines (e.g., OpenEvolve, ShinkaEvolve) by up to 60% in evolutionary efficiency while discovering superior solutions. LoongFlow marks a substantial step forward in autonomous scientific discovery, enabling the generation of expert-level solutions with reduced computational overhead.

</details>


### [19] [CogRec: A Cognitive Recommender Agent Fusing Large Language Models and Soar for Explainable Recommendation](https://arxiv.org/abs/2512.24113)
*Jiaxin Hu,Tao Wang,Bingsan Yang,Hongrun Wang*

Main category: cs.AI

TL;DR: CogRec是一个结合大语言模型和Soar认知架构的推荐系统，通过符号推理和在线学习机制提高推荐准确性、可解释性和长尾问题处理能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在推荐系统中存在"黑盒"特性、知识幻觉和在线学习能力有限等问题，而认知架构如Soar虽然推理过程结构化可解释，但知识获取困难。需要结合两者优势解决互补挑战。

Method: 提出CogRec认知推荐代理，以Soar作为核心符号推理引擎，利用LLM进行知识初始化填充工作记忆的生产规则。采用感知-认知-行动循环，遇到僵局时动态查询LLM获取推理解决方案，通过Soar的chunking机制将解决方案转化为新的符号生产规则，实现在线学习。

Result: 在三个公共数据集上的广泛评估表明，CogRec在推荐准确性、可解释性和解决长尾问题方面表现出显著优势。

Conclusion: CogRec成功结合了LLM和Soar认知架构的优势，通过符号推理和在线学习机制创建了一个可信赖且适应性强的推荐系统，能够持续进化知识库并提供高度可解释的推荐理由。

Abstract: Large Language Models (LLMs) have demonstrated a remarkable capacity in understanding user preferences for recommendation systems. However, they are constrained by several critical challenges, including their inherent "Black-Box" characteristics, susceptibility to knowledge hallucination, and limited online learning capacity. These factors compromise their trustworthiness and adaptability. Conversely, cognitive architectures such as Soar offer structured and interpretable reasoning processes, yet their knowledge acquisition is notoriously laborious. To address these complementary challenges, we propose a novel cognitive recommender agent called CogRec which synergizes the strengths of LLMs with the Soar cognitive architecture. CogRec leverages Soar as its core symbolic reasoning engine and leverages an LLM for knowledge initialization to populate its working memory with production rules. The agent operates on a Perception-Cognition-Action(PCA) cycle. Upon encountering an impasse, it dynamically queries the LLM to obtain a reasoned solution. This solution is subsequently transformed into a new symbolic production rule via Soar's chunking mechanism, thereby enabling robust online learning. This learning paradigm allows the agent to continuously evolve its knowledge base and furnish highly interpretable rationales for its recommendations. Extensive evaluations conducted on three public datasets demonstrate that CogRec demonstrates significant advantages in recommendation accuracy, explainability, and its efficacy in addressing the long-tail problem.

</details>


### [20] [Graph-Based Exploration for ARC-AGI-3 Interactive Reasoning Tasks](https://arxiv.org/abs/2512.24156)
*Evgenii Rudakov,Jonathan Shock,Benjamin Ultan Cowley*

Main category: cs.AI

TL;DR: 提出一种无需训练的图基方法，用于解决ARC-AGI-3基准中的交互式推理任务，通过视觉帧处理与系统化状态空间探索，在52个关卡中解决中位数30个，显著优于当前LLM方法。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的LLM无法可靠解决ARC-AGI-3基准中的交互式推理任务，这些任务需要智能体通过有限交互推断任务机制，并随着关卡进展适应增加的复杂性。需要一种能够形成假设、测试假设并跟踪已发现机制的方法。

Method: 结合基于视觉的帧处理与使用图结构表示的系统化状态空间探索。方法包括：将视觉帧分割为有意义的组件；基于视觉显著性优先选择动作；维护探索状态和转换的有向图；通过跟踪已访问状态和测试动作，优先选择提供到未测试状态-动作对最短路径的动作。

Result: 在ARC-AGI-3预览挑战中，该方法在六个游戏的52个关卡中解决了中位数30个关卡，在私有排行榜上排名第三，显著优于前沿的LLM智能体。

Conclusion: 即使无需学习，显式的图结构探索也能作为交互式推理的强大基线，并强调了在稀疏反馈环境中系统化状态跟踪和动作优先级的重要性，这些环境中当前LLM无法捕捉任务动态。

Abstract: We present a training-free graph-based approach for solving interactive reasoning tasks in the ARC-AGI-3 benchmark. ARC-AGI-3 comprises game-like tasks where agents must infer task mechanics through limited interactions, and adapt to increasing complexity as levels progress. Success requires forming hypotheses, testing them, and tracking discovered mechanics. The benchmark has revealed that state-of-the-art LLMs are currently incapable of reliably solving these tasks. Our method combines vision-based frame processing with systematic state-space exploration using graph-structured representations. It segments visual frames into meaningful components, prioritizes actions based on visual salience, and maintains a directed graph of explored states and transitions. By tracking visited states and tested actions, the agent prioritizes actions that provide the shortest path to untested state-action pairs. On the ARC-AGI-3 Preview Challenge, this structured exploration strategy solves a median of 30 out of 52 levels across six games and ranks 3rd on the private leaderboard, substantially outperforming frontier LLM-based agents. These results demonstrate that explicit graph-structured exploration, even without learning, can serve as a strong baseline for interactive reasoning and underscore the importance of systematic state tracking and action prioritization in sparse-feedback environments where current LLMs fail to capture task dynamics. The code is open source and available at https://github.com/dolphin-in-a-coma/arc-agi-3-just-explore.

</details>


### [21] [SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents](https://arxiv.org/abs/2512.24189)
*Yankai Jiang,Wenjie Lou,Lilong Wang,Zhenyu Tang,Shiyang Feng,Jiaxuan Lu,Haoran Sun,Yaning Pan,Shuang Gu,Haoyang Su,Feng Liu,Wangxu Wei,Pan Tan,Dongzhan Zhou,Fenghua Ling,Cheng Tan,Bo Zhang,Xiaosong Wang,Lei Bai,Bowen Zhou*

Main category: cs.AI

TL;DR: SCP（Science Context Protocol）是一个开源标准，旨在通过建立全球自主科学代理网络来加速科学发现。它提供统一的资源集成规范和实验生命周期管理架构，支持大规模科学工具生态系统。


<details>
  <summary>Details</summary>
Motivation: 当前科学工具、模型、数据集和物理仪器分散在不同平台和机构中，缺乏统一标准，导致AI代理和应用程序难以发现、调用和组合这些资源。这阻碍了跨平台协作、增加了集成成本，并影响了科学研究的可重复性和可扩展性。

Method: SCP基于两大支柱：1）统一资源集成：提供描述和调用科学资源的通用规范；2）编排的实验生命周期管理：包含中心化SCP Hub和联邦SCP Server的安全服务架构，管理实验注册、规划、执行、监控和归档全过程，实施细粒度认证授权，编排可追溯的端到端工作流。

Result: 基于SCP构建的科学发现平台已集成超过1,600个工具资源。在多样化用例中，SCP促进了异构AI系统与人类研究人员之间安全的大规模协作，显著降低了集成开销，增强了可重复性。

Conclusion: 通过在协议层面标准化科学上下文和工具编排，SCP为可扩展、多机构、代理驱动的科学研究建立了必要的基础设施，为加速科学发现提供了关键支撑。

Abstract: We introduce SCP: the Science Context Protocol, an open-source standard designed to accelerate discovery by enabling a global network of autonomous scientific agents. SCP is built on two foundational pillars: (1) Unified Resource Integration: At its core, SCP provides a universal specification for describing and invoking scientific resources, spanning software tools, models, datasets, and physical instruments. This protocol-level standardization enables AI agents and applications to discover, call, and compose capabilities seamlessly across disparate platforms and institutional boundaries. (2) Orchestrated Experiment Lifecycle Management: SCP complements the protocol with a secure service architecture, which comprises a centralized SCP Hub and federated SCP Servers. This architecture manages the complete experiment lifecycle (registration, planning, execution, monitoring, and archival), enforces fine-grained authentication and authorization, and orchestrates traceable, end-to-end workflows that bridge computational and physical laboratories. Based on SCP, we have constructed a scientific discovery platform that offers researchers and agents a large-scale ecosystem of more than 1,600 tool resources. Across diverse use cases, SCP facilitates secure, large-scale collaboration between heterogeneous AI systems and human researchers while significantly reducing integration overhead and enhancing reproducibility. By standardizing scientific context and tool orchestration at the protocol level, SCP establishes essential infrastructure for scalable, multi-institution, agent-driven science.

</details>


### [22] [Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem](https://arxiv.org/abs/2512.24251)
*Pengfu Wan,Jiawei Chen,Gangyan Xu*

Main category: cs.AI

TL;DR: 本文提出一种基于深度强化学习的方法来解决车队规模与混合车辆路径问题，能够在几秒内生成接近最优的解，特别适用于大规模和时间受限的场景。


<details>
  <summary>Details</summary>
Motivation: FSMVRP需要同时决定车队组成和路径规划，在现实场景中应用广泛（如短期车辆租赁和按需物流），但这也增加了问题的复杂性，特别是在大规模和时间受限的环境中面临显著挑战。

Method: 将问题建模为马尔可夫决策过程，开发了名为FRIPN的新型策略网络，无缝整合车队组成和路径决策。方法包含专门设计的输入嵌入，包括剩余图嵌入以促进有效的车辆使用决策。

Result: 在随机生成实例和基准数据集上的实验表明，该方法在计算效率和可扩展性方面表现出显著优势，特别是在大规模和时间受限的场景中。

Conclusion: 该方法在实际应用中具有潜力，并为将基于DRL的技术扩展到其他VRP变体提供了有价值的启发。

Abstract: The Fleet Size and Mix Vehicle Routing Problem (FSMVRP) is a prominent variant of the Vehicle Routing Problem (VRP), extensively studied in operations research and computational science. FSMVRP requires simultaneous decisions on fleet composition and routing, making it highly applicable to real-world scenarios such as short-term vehicle rental and on-demand logistics. However, these requirements also increase the complexity of FSMVRP, posing significant challenges, particularly in large-scale and time-constrained environments. In this paper, we propose a deep reinforcement learning (DRL)-based approach for solving FSMVRP, capable of generating near-optimal solutions within a few seconds. Specifically, we formulate the problem as a Markov Decision Process (MDP) and develop a novel policy network, termed FRIPN, that seamlessly integrates fleet composition and routing decisions. Our method incorporates specialized input embeddings designed for distinctdecision objectives, including a remaining graph embedding to facilitate effective vehicle employment decisions. Comprehensive experiments are conducted on both randomly generated instances and benchmark datasets. The experimental results demonstrate that our method exhibits notable advantages in terms of computational efficiency and scalability, particularly in large-scale and time-constrained scenarios. These strengths highlight the potential of our approach for practical applications and provide valuable inspiration for extending DRL-based techniques to other variants of VRP.

</details>


### [23] [Constrained Language Model Policy Optimization via Risk-aware Stepwise Alignment](https://arxiv.org/abs/2512.24263)
*Lijun Zhang,Lin Li,Wei Wei,Yajie Qi,Huizhong Song,Jun Wang,Yaodong Yang,Jiye Liang*

Main category: cs.AI

TL;DR: 提出Risk-aware Stepwise Alignment (RSA)方法，通过嵌套风险度量在策略优化中显式纳入风险意识，解决现有安全对齐方法风险中性不足的问题，有效抑制低概率高危害行为。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法（如Safe RLHF和SACPO）通常采用风险中性范式，不足以应对参考策略偏差带来的风险，且对罕见但可能灾难性的有害行为鲁棒性有限。需要一种能显式纳入风险意识的方法来确保模型的安全性和可信度。

Method: 提出Risk-aware Stepwise Alignment (RSA)方法：1) 将安全对齐建模为token级别的风险感知约束策略优化问题；2) 通过逐步对齐过程解决，利用嵌套风险度量推导token级别的策略更新；3) 设计旨在缓解模型过度偏离参考策略的风险，并显式抑制低概率高危害行为。

Result: 实验结果表明，该方法在保持高帮助性的同时确保了强安全性，并显著抑制了尾部风险（即低概率但高危害的不安全响应）。理论分析在温和假设下证明了策略的最优性。

Conclusion: RSA方法通过显式纳入风险意识，有效解决了现有安全对齐方法的局限性，在保持模型帮助性的同时显著提升了安全性和对尾部风险的鲁棒性，为语言模型的安全对齐提供了新思路。

Abstract: When fine-tuning pre-trained Language Models (LMs) to exhibit desired behaviors, maintaining control over risk is critical for ensuring both safety and trustworthiness. Most existing safety alignment methods, such as Safe RLHF and SACPO, typically operate under a risk-neutral paradigm that is insufficient to address the risks arising from deviations from the reference policy and offers limited robustness against rare but potentially catastrophic harmful behaviors. To address this limitation, we propose Risk-aware Stepwise Alignment (RSA), a novel alignment method that explicitly incorporates risk awareness into the policy optimization process by leveraging a class of nested risk measures. Specifically, RSA formulates safety alignment as a token-level risk-aware constrained policy optimization problem and solves it through a stepwise alignment procedure that yields token-level policy updates derived from the nested risk measures. This design offers two key benefits: (1) it mitigates risks induced by excessive model shift away from a reference policy, and (2) it explicitly suppresses low-probability yet high-impact harmful behaviors. Moreover, we provide theoretical analysis on policy optimality under mild assumptions. Experimental results demonstrate that our method achieves high levels of helpfulness while ensuring strong safety and significantly suppresses tail risks, namely low-probability yet high-impact unsafe responses.

</details>


### [24] [Align While Search: Belief-Guided Exploratory Inference for World-Grounded Embodied Agents](https://arxiv.org/abs/2512.24461)
*Seohui Bae,Jeonghye Kim,Youngchul Sung,Woohyung Lim*

Main category: cs.AI

TL;DR: 提出一种测试时自适应智能体，通过后验引导的信念精化进行探索性推理，无需梯度更新或额外训练，适用于部分可观测环境下的LLM智能体。


<details>
  <summary>Details</summary>
Motivation: 在部分可观测环境下，LLM智能体需要有效推断隐藏的世界状态，而现有方法如提示增强或检索增强LLM存在集成开销大、对齐效果有限的问题。

Method: 智能体维护外部结构化信念表示，通过动作条件观测迭代更新信念，并使用轻量级LLM代理估计信息增益来选择最大化信念空间信息获取的动作。

Result: 实验表明该方法在潜在世界状态对齐方面优于推理时扩展基线（如提示增强或检索增强LLM），且集成开销显著降低。

Conclusion: 后验引导的信念精化方法为部分可观测环境下的LLM智能体提供了一种高效、无需额外训练的测试时自适应解决方案。

Abstract: In this paper, we propose a test-time adaptive agent that performs exploratory inference through posterior-guided belief refinement without relying on gradient-based updates or additional training for LLM agent operating under partial observability. Our agent maintains an external structured belief over the environment state, iteratively updates it via action-conditioned observations, and selects actions by maximizing predicted information gain over the belief space. We estimate information gain using a lightweight LLM-based surrogate and assess world alignment through a novel reward that quantifies the consistency between posterior belief and ground-truth environment configuration. Experiments show that our method outperforms inference-time scaling baselines such as prompt-augmented or retrieval-enhanced LLMs, in aligning with latent world states with significantly lower integration overhead.

</details>


### [25] [What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?](https://arxiv.org/abs/2512.24497)
*Basile Terver,Tsung-Yen Yang,Jean Ponce,Adrien Bardes,Yann LeCun*

Main category: cs.AI

TL;DR: 该论文研究了在JEPA-WM世界模型表示空间中进行规划的方法，通过系统分析模型架构、训练目标和规划算法等关键组件，提出了优于现有基线的方法。


<details>
  <summary>Details</summary>
Motivation: 解决AI中长期存在的挑战：开发能够解决广泛物理任务并在新任务和环境中泛化的智能体。当前基于世界模型和规划的方法中，在表示空间进行规划的方法有潜力通过抽象无关细节来提高规划效率，但需要系统研究其技术选择。

Method: 将这类方法定义为JEPA-WMs，系统研究模型架构、训练目标和规划算法等关键组件。在模拟环境和真实机器人数据上进行实验，分析不同选择对规划成功率的影响。

Result: 提出的模型在导航和操作任务上优于两个现有基线方法（DINO-WM和V-JEPA-2-AC）。

Conclusion: 通过系统研究JEPA-WM家族中的技术选择，找到了最优方法组合，证明了在表示空间进行规划的有效性，并为未来研究提供了代码、数据和检查点。

Abstract: A long-standing challenge in AI is to develop agents capable of solving a wide range of physical tasks and generalizing to new, unseen tasks and environments. A popular recent approach involves training a world model from state-action trajectories and subsequently use it with a planning algorithm to solve new tasks. Planning is commonly performed in the input space, but a recent family of methods has introduced planning algorithms that optimize in the learned representation space of the world model, with the promise that abstracting irrelevant details yields more efficient planning. In this work, we characterize models from this family as JEPA-WMs and investigate the technical choices that make algorithms from this class work. We propose a comprehensive study of several key components with the objective of finding the optimal approach within the family. We conducted experiments using both simulated environments and real-world robotic data, and studied how the model architecture, the training objective, and the planning algorithm affect planning success. We combine our findings to propose a model that outperforms two established baselines, DINO-WM and V-JEPA-2-AC, in both navigation and manipulation tasks. Code, data and checkpoints are available at https://github.com/facebookresearch/jepa-wms.

</details>


### [26] [Thinking on Maps: How Foundation Model Agents Explore, Remember, and Reason Map Environments](https://arxiv.org/abs/2512.24504)
*Zhiwei Wei,Yuxing Liu,Hua Liao,Wenjia Xu*

Main category: cs.AI

TL;DR: 提出一个交互式评估框架，分析基础模型代理在符号地图环境中的探索、记忆和推理能力，发现结构化记忆对空间理解至关重要，而单纯模型缩放对空间推理提升有限。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型空间能力评估多基于静态地图或文本查询，忽视了空间理解的交互性和经验驱动特性。需要评估FM代理如何在交互式地图环境中探索、记忆和推理。

Method: 提出交互式评估框架，让代理在部分可观察的网格地图中增量探索（包含道路、交叉口和兴趣点），通过六种空间任务评估空间理解能力。系统变化探索策略、记忆表示和推理方案。

Result: 探索主要影响经验获取但对最终推理准确性影响有限；记忆表示在整合空间经验中起核心作用，结构化记忆（特别是序列和图表示）显著提升路径规划等结构密集型任务性能；推理方案影响存储知识的利用方式；空间推理性能在模型版本和规模超过一定阈值后趋于饱和。

Conclusion: 提升地图空间理解需要针对空间表示和推理的专门机制，而非单纯模型缩放。结构化记忆对空间理解至关重要，探索策略影响经验获取但非最终性能决定性因素。

Abstract: Map environments provide a fundamental medium for representing spatial structure. Understanding how foundation model (FM) agents understand and act in such environments is therefore critical for enabling reliable map-based reasoning and applications. However, most existing evaluations of spatial ability in FMs rely on static map inputs or text-based queries, overlooking the interactive and experience-driven nature of spatial understanding.In this paper, we propose an interactive evaluation framework to analyze how FM agents explore, remember, and reason in symbolic map environments. Agents incrementally explore partially observable grid-based maps consisting of roads, intersections, and points of interest (POIs), receiving only local observations at each step. Spatial understanding is then evaluated using six kinds of spatial tasks. By systematically varying exploration strategies, memory representations, and reasoning schemes across multiple foundation models, we reveal distinct functional roles of these components. Exploration primarily affects experience acquisition but has a limited impact on final reasoning accuracy. In contrast, memory representation plays a central role in consolidating spatial experience, with structured memories particularly sequential and graph-based representations, substantially improving performance on structure-intensive tasks such as path planning. Reasoning schemes further shape how stored spatial knowledge is used, with advanced prompts supporting more effective multi-step inference. We further observe that spatial reasoning performance saturates across model versions and scales beyond a certain capability threshold, indicating that improvements in map-based spatial understanding require mechanisms tailored to spatial representation and reasoning rather than scaling alone.

</details>


### [27] [Evaluating the Reasoning Abilities of LLMs on Underrepresented Mathematics Competition Problems](https://arxiv.org/abs/2512.24505)
*Samuel Golladay,Majid Bani-Yaghoub*

Main category: cs.AI

TL;DR: 该研究评估了三种主流LLM在代表性不足的数学竞赛问题上的表现，发现DeepSeek-V3在微积分、解析几何和离散数学中表现最佳，所有模型在几何问题上表现最弱，并揭示了不同模型的错误模式差异。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多使用相同的数据集评估LLM的数学推理能力，这限制了研究结果的普适性，且可能无法全面捕捉数学任务中的多样性挑战。本研究旨在分析LLM在代表性不足的数学竞赛问题上的表现。

Method: 使用密苏里大学数学竞赛中的微积分、解析几何和离散数学问题，测试GPT-4o-mini、Gemini-2.0-Flash和DeepSeek-V3三种LLM。将模型回答与已知正确答案比较以确定准确性，并分析推理过程以探索不同问题类型和模型间的错误模式。

Result: DeepSeek-V3在所有三个数学领域（微积分、解析几何、离散数学）的表现最佳，包括推理过程和最终答案。所有三种LLM在几何问题上表现明显较弱。DeepSeek-V3的主要错误是计算和逻辑错误，GPT-4o-mini常见逻辑和方法相关错误，而Gemini倾向于不完整推理和仓促结论。

Conclusion: 在代表性不足的数学竞赛数据集上评估LLM可以提供对其独特错误模式的深入洞察，并突显结构化推理方面的持续挑战，特别是在几何领域。

Abstract: Understanding the limitations of Large Language Models, or LLMs, in mathematical reasoning has been the focus of several recent studies. However, the majority of these studies use the same datasets for benchmarking, which limits the generalizability of their findings and may not fully capture the diverse challenges present in mathematical tasks. The purpose of the present study is to analyze the performance of LLMs on underrepresented mathematics competition problems. We prompted three leading LLMs, namely GPT-4o-mini, Gemini-2.0-Flash, and DeepSeek-V3, with the Missouri Collegiate Mathematics Competition problems in the areas of Calculus, Analytic Geometry, and Discrete Mathematics. The LLMs responses were then compared to the known correct solutions in order to determine the accuracy of the LLM for each problem domain. We also analyzed the LLMs reasoning to explore patterns in errors across problem types and models. DeepSeek-V3 has the best performance in all three categories of Calculus, Analytic Geometry, and Discrete Mathematics, both in reasoning and correct final answers. All three LLMs exhibited notably weak performance in Geometry. The majority of errors made by DeepSeek-V3 were attributed to computational and logical mistakes, whereas GPT-4o-mini frequently exhibited logical and approach-related errors. Gemini, on the other hand, tended to struggle with incomplete reasoning and drawing rushed conclusions. In conclusion, evaluating LLMs on underrepresented mathematics competition datasets can provide deeper insights into their distinct error patterns and highlight ongoing challenges in structured reasoning, particularly within the domain of Geometry.

</details>


### [28] [From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning](https://arxiv.org/abs/2512.24532)
*Amir Tahmasbi,Sadegh Majidi,Kazem Taram,Aniket Bera*

Main category: cs.AI

TL;DR: 本文提出一种两阶段方法，将空间推理分解为原子构建块及其组合，通过监督微调学习基本空间物理，然后训练轻量级LoRA适配器进行多步规划，在ASCII艺术环境中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型具有强大的通用语言能力，但在结构化环境中的空间变换和多步规划方面仍然存在困难，特别是在导航和规划等应用中需要更好的空间推理能力。

Method: 采用两阶段方法：1）对基本空间变换（如旋转、平移、缩放）进行监督微调，使模型具备基本空间物理知识；2）冻结该物理感知模型，在GRPO框架内训练轻量级LoRA适配器，以闭环方式学习组合这些构建块进行多步规划。为此合成了ASCII艺术数据集并构建了相应的基于ASCII的强化学习环境。

Result: 该方法在动态环境（具有显式状态更新）和静态环境（模型必须依赖其内部状态）中均一致优于基线方法，包括通用骨干模型、物理感知模型和端到端RL模型。此外，该方法收敛更快，训练更稳定，并且注意力模式分析显示微调确实改善了空间理解。

Conclusion: 通过将空间推理分解为原子构建块及其组合的两阶段方法，可以有效提升大语言模型在结构化环境中的空间推理能力，特别是在多步规划任务中表现出色，为导航和规划应用提供了有前景的解决方案。

Abstract: Spatial reasoning in large language models (LLMs) has gained increasing attention due to applications in navigation and planning. Despite strong general language capabilities, LLMs still struggle with spatial transformations and multi-step planning in structured environments. We propose a two-stage approach that decomposes spatial reasoning into atomic building blocks and their composition. First, we apply supervised fine-tuning on elementary spatial transformations, such as rotation, translation, and scaling, to equip the model with basic spatial physics. We then freeze this physics-aware model and train lightweight LoRA adapters within the GRPO framework to learn policies that compose these building blocks for multi-step planning in puzzle-based environments, in a closed-loop manner. To support this pipeline, we synthesize an ASCII-art dataset and construct a corresponding ASCII-based reinforcement learning environment. Our method consistently outperforms baselines, including the generic backbone, physics-aware model, and end-to-end RL models, under both Dynamic environments with explicit state updates and Static environments where the model must rely on its internal state across steps. In addition, the proposed approach converges faster and exhibits more stable training compared to end-to-end reinforcement learning from scratch. Finally, we analyze attention patterns to assess whether fine-tuning induces meaningful improvements in spatial understanding.

</details>


### [29] [MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use](https://arxiv.org/abs/2512.24565)
*Wenrui Liu,Zixiang Liu,Elsie Dai,Wenhan Yu,Lei Yu,Tong Yang*

Main category: cs.AI

TL;DR: MCPAgentBench：基于真实MCP定义构建的基准测试，用于评估智能体工具使用能力，包含真实任务、模拟工具和动态沙箱环境，测试模型在复杂多步工具调用中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前MCP评估集存在依赖外部MCP服务和缺乏难度感知的问题，需要更有效的基准来评估LLM作为自主智能体的工具使用能力。

Method: 构建包含真实任务和模拟MCP工具的数据集，采用动态沙箱环境，向智能体提供包含干扰项的工具候选列表，测试其工具选择和辨别能力，并引入综合指标衡量任务完成率和执行效率。

Result: 实验显示不同主流大语言模型在处理复杂多步工具调用时存在显著性能差异，验证了基准的有效性。

Conclusion: MCPAgentBench为解决当前MCP评估局限性提供了有效方案，有助于推动LLM作为自主智能体的工具使用能力发展，所有代码已开源。

Abstract: Large Language Models (LLMs) are increasingly serving as autonomous agents, and their utilization of external tools via the Model Context Protocol (MCP) is considered a future trend. Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness. To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. We construct a dataset containing authentic tasks and simulated MCP tools. The evaluation employs a dynamic sandbox environment that presents agents with candidate tool lists containing distractors, thereby testing their tool selection and discrimination abilities. Furthermore, we introduce comprehensive metrics to measure both task completion rates and execution efficiency. Experiments conducted on various latest mainstream Large Language Models reveal significant performance differences in handling complex, multi-step tool invocations. All code is open-source at Github.

</details>


### [30] [Recursive Language Models](https://arxiv.org/abs/2512.24601)
*Alex L. Zhang,Tim Kraska,Omar Khattab*

Main category: cs.AI

TL;DR: RLMs是一种推理策略，让LLMs能够递归处理远超上下文窗口的长提示，通过编程式检查、分解和递归调用来处理任意长度输入。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理超出其上下文窗口的长提示时面临困难，需要一种能够处理任意长度输入的推理策略。

Method: 提出递归语言模型（RLMs），将长提示视为外部环境，允许LLM编程式检查、分解并递归调用自身处理提示片段。

Result: RLMs能处理比模型上下文窗口长两个数量级的输入，在四个不同的长上下文任务中显著优于基础LLMs和常见长上下文框架，且查询成本相当或更低。

Conclusion: RLMs提供了一种有效处理任意长提示的推理策略，在保持成本效率的同时显著提升长上下文任务性能。

Abstract: We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs successfully handle inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of base LLMs and common long-context scaffolds across four diverse long-context tasks, while having comparable (or cheaper) cost per query.

</details>


### [31] [Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization](https://arxiv.org/abs/2512.24609)
*Dong Qiu,Duo Xu,Limengxi Yue*

Main category: cs.AI

TL;DR: 提出强化学习增强的LLM多智能体协作框架，采用Dec-POMDP建模和CTDE训练，通过GRPO优化策略，在写作和编程任务中显著提升协作效率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在单智能体任务中表现良好，但在多智能体协作场景中缺乏协作意识，难以优化全局性能，需要解决多智能体协作的优化问题。

Method: 1. 将协作建模为分散部分可观察马尔可夫决策过程（Dec-POMDP）；2. 采用集中训练分散执行（CTDE）框架；3. 提出组相对策略优化（GRPO）联合优化智能体策略；4. 设计简化的联合奖励函数平衡任务质量、速度和协调成本。

Result: 1. 在协作写作和编程基准测试中，任务处理速度比单智能体基线提高3倍；2. 写作任务中实现98.7%的结构/风格一致性；3. 编程任务中达到74.6%的测试通过率；4. 持续优于现有的多智能体LLM基线。

Conclusion: 该框架为复杂工作流中的可靠协作提供了实用路径，通过强化学习增强的LLM多智能体协作方法，显著提升了多智能体场景下的协作效率和任务完成质量。

Abstract: Large Language Models (LLMs) perform well in language tasks but often lack collaborative awareness and struggle to optimize global performance in multi-agent settings. We present a reinforcement learning-augmented LLM agent framework that formulates cooperation as a decentralized partially observable Markov decision process (Dec-POMDP) and adopts centralized training with decentralized execution (CTDE). We introduce Group Relative Policy Optimization (GRPO) to jointly optimize agent policies with access to global signals during training, together with a simplified joint reward that balances task quality, speed, and coordination cost. On collaborative writing and coding benchmarks, our framework delivers a 3x increase in task processing speed over single-agent baselines, 98.7% structural/style consistency in writing, and a 74.6% test pass rate in coding. The approach consistently outperforms strong multi-agent LLM baselines and provides a practical path toward reliable collaboration in complex workflows.

</details>


### [32] [Group Deliberation Oriented Multi-Agent Conversational Model for Complex Reasoning](https://arxiv.org/abs/2512.24613)
*Zheyu Shi,Dong Qiu,Shanlong Yu*

Main category: cs.AI

TL;DR: 提出基于群体审议的多智能体对话模型，通过角色分工、自博弈机制和检索增强，显著提升复杂推理任务的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 单一大型语言模型在复杂推理任务中存在局限性，需要多智能体协作来提升推理能力和事实一致性。

Method: 采用三层角色分工架构：生成智能体产生多样化推理视角，验证智能体检索外部知识并量化事实支持，仲裁智能体整合逻辑一致结论。引入自博弈机制扩展多路径推理轨迹，检索增强模块动态补充外部知识，设计结合事实一致性和逻辑连贯性的复合奖励函数，采用改进的近端策略优化策略进行协同训练。

Result: 在HotpotQA上多跳推理准确率提升16.8%，2WikiMultihopQA提升14.3%，MeetingBank提升19.2%，一致性提升21.5%。推理效率高于主流多智能体方法。

Conclusion: 该模型为复杂推理任务提供了有效且稳定的解决方案，通过多智能体协作显著提升了推理性能和一致性。

Abstract: This paper proposes a group deliberation oriented multi-agent conversational model to address the limitations of single large language models in complex reasoning tasks. The model adopts a three-level role division architecture consisting of generation, verification, and integration. An opinion generation agent produces diverse reasoning perspectives, an evidence verification agent retrieves external knowledge and quantifies factual support, and a consistency arbitration agent integrates logically coherent conclusions. A self-game mechanism is introduced to expand multi-path reasoning trajectories, while a retrieval enhancement module dynamically supplements external knowledge. A composite reward function combining factual consistency and logical coherence is designed, and an improved proximal policy optimization strategy is applied for collaborative training. Experimental results show that the proposed model improves multi-hop reasoning accuracy by 16.8 percent on HotpotQA, 14.3 percent on 2WikiMultihopQA, and 19.2 percent on MeetingBank, while improving consistency by 21.5 percent. The model achieves higher reasoning efficiency than mainstream multi-agent approaches, providing an effective and stable solution for complex reasoning tasks.

</details>


### [33] [Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization](https://arxiv.org/abs/2512.24615)
*Yuchen Shi,Yuzheng Cai,Siqi Cai,Zihan Xu,Lichao Chen,Yulei Qin,Zhijian Zhou,Xiang Fei,Chaofan Qiu,Xiaoyu Tan,Gang Li,Zongyi Li,Haojia Lin,Guocan Cai,Yong Mao,Yunsheng Wu,Ke Li,Xing Sun*

Main category: cs.AI

TL;DR: Youtu-Agent是一个模块化的LLM代理框架，通过自动化生成和持续演化解决现有代理框架配置成本高、能力静态的问题，支持工作流和元代理两种生成模式，并包含实践和强化学习两种优化模块。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理框架面临两大挑战：1) 高配置成本 - 构建高质量代理需要大量手动工具集成和提示工程；2) 静态能力 - 已部署代理难以适应动态环境，需要昂贵的微调。

Method: 提出模块化框架Youtu-Agent，包含：1) 结构化配置系统，解耦执行环境、工具包和上下文管理；2) 两种生成模式：工作流模式用于标准任务，元代理模式用于复杂需求，能自动生成工具代码、提示和配置；3) 混合策略优化系统：Agent Practice模块通过上下文优化积累经验，Agent RL模块集成分布式训练框架进行端到端大规模强化学习。

Result: 在WebWalkerQA上达到71.47%，GAIA上达到72.8%（开源模型SOTA）；自动化生成管道工具合成成功率超过81%；Practice模块在AIME 2024/2025上分别提升2.7%和5.4%；Agent RL训练在7B LLMs上实现40%加速，数学和通用/多跳QA基准上编码/推理和搜索能力分别提升35%和21%。

Conclusion: Youtu-Agent通过自动化生成和持续演化机制，有效解决了LLM代理框架的高配置成本和静态能力问题，实现了高性能、可扩展且能持续改进的代理系统。

Abstract: Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic environments without expensive fine-tuning. To address these issues, we propose \textbf{Youtu-Agent}, a modular framework designed for the automated generation and continuous evolution of LLM agents. Youtu-Agent features a structured configuration system that decouples execution environments, toolkits, and context management, enabling flexible reuse and automated synthesis. We introduce two generation paradigms: a \textbf{Workflow} mode for standard tasks and a \textbf{Meta-Agent} mode for complex, non-standard requirements, capable of automatically generating tool code, prompts, and configurations. Furthermore, Youtu-Agent establishes a hybrid policy optimization system: (1) an \textbf{Agent Practice} module that enables agents to accumulate experience and improve performance through in-context optimization without parameter updates; and (2) an \textbf{Agent RL} module that integrates with distributed training frameworks to enable scalable and stable reinforcement learning of any Youtu-Agents in an end-to-end, large-scale manner. Experiments demonstrate that Youtu-Agent achieves state-of-the-art performance on WebWalkerQA (71.47\%) and GAIA (72.8\%) using open-weight models. Our automated generation pipeline achieves over 81\% tool synthesis success rate, while the Practice module improves performance on AIME 2024/2025 by +2.7\% and +5.4\% respectively. Moreover, our Agent RL training achieves 40\% speedup with steady performance improvement on 7B LLMs, enhancing coding/reasoning and searching capabilities respectively up to 35\% and 21\% on Maths and general/multi-hop QA benchmarks.

</details>


### [34] [Multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis under unseen working conditions](https://arxiv.org/abs/2512.24679)
*Pengcheng Xia,Yixiang Huang,Chengjin Qin,Chengliang Liu*

Main category: cs.AI

TL;DR: 提出多模态跨域混合融合模型，通过双重解耦实现模态不变/特定特征和域不变/特定表示的分离，提升故障诊断在未见工况下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有故障诊断方法在未见工况下性能显著下降，域自适应方法依赖目标域样本，且大多依赖单模态信号，忽略了多模态信息的互补性。

Method: 1) 双重解耦框架：分离模态不变/特定特征和域不变/特定表示；2) 跨域混合融合策略：随机混合跨域模态信息增强多样性；3) 三模态融合机制：自适应集成多模态异构信息。

Result: 在感应电机故障诊断实验中，无论是未见恒定工况还是时变工况，该方法均优于先进方法，消融研究验证了各组件和多模态融合的有效性。

Conclusion: 该方法通过多模态融合和双重解耦实现了更好的域泛化能力，为实际工业场景中的故障诊断提供了有效解决方案。

Abstract: Intelligent fault diagnosis has become an indispensable technique for ensuring machinery reliability. However, existing methods suffer significant performance decline in real-world scenarios where models are tested under unseen working conditions, while domain adaptation approaches are limited to their reliance on target domain samples. Moreover, most existing studies rely on single-modal sensing signals, overlooking the complementary nature of multi-modal information for improving model generalization. To address these limitations, this paper proposes a multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis. A dual disentanglement framework is developed to decouple modality-invariant and modality-specific features, as well as domain-invariant and domain-specific representations, enabling both comprehensive multi-modal representation learning and robust domain generalization. A cross-domain mixed fusion strategy is designed to randomly mix modality information across domains for modality and domain diversity augmentation. Furthermore, a triple-modal fusion mechanism is introduced to adaptively integrate multi-modal heterogeneous information. Extensive experiments are conducted on induction motor fault diagnosis under both unseen constant and time-varying working conditions. The results demonstrate that the proposed method consistently outperforms advanced methods and comprehensive ablation studies further verify the effectiveness of each proposed component and multi-modal fusion. The code is available at: https://github.com/xiapc1996/MMDG.

</details>


### [35] [Explaining Why Things Go Where They Go: Interpretable Constructs of Human Organizational Preferences](https://arxiv.org/abs/2512.24829)
*Emmanuel Fashae,Michael Burke,Leimin Tian,Lingheng Meng,Pamela Carreno-Medrano*

Main category: cs.AI

TL;DR: 该论文提出了一个可解释的家庭物品摆放偏好模型，包含四个维度：空间实用性、习惯便利性、语义连贯性和常识适当性，并通过问卷验证和MCTS规划器应用。


<details>
  <summary>Details</summary>
Motivation: 当前基于人类演示的机器人系统偏好模型虽然有效，但缺乏可解释性，无法理解指导人类决策的因素。需要开发一个明确、可解释的物品摆放偏好模型。

Method: 1. 提出四个可解释的偏好维度：空间实用性、习惯便利性、语义连贯性、常识适当性；2. 设计并验证自报告问卷（63名参与者在线研究）；3. 将偏好维度整合到蒙特卡洛树搜索（MCTS）规划器中。

Result: 1. 问卷研究证实了四个心理维度的区分性和解释力；2. MCTS规划器在参与者偏好指导下能生成合理的物品摆放方案，与参与者生成的方案高度一致。

Conclusion: 该工作贡献了一个紧凑、可解释的物品摆放偏好模型，并展示了如何将其操作化用于机器人规划，为家庭机器人系统提供了更透明、可解释的决策框架。

Abstract: Robotic systems for household object rearrangement often rely on latent preference models inferred from human demonstrations. While effective at prediction, these models offer limited insight into the interpretable factors that guide human decisions. We introduce an explicit formulation of object arrangement preferences along four interpretable constructs: spatial practicality (putting items where they naturally fit best in the space), habitual convenience (making frequently used items easy to reach), semantic coherence (placing items together if they are used for the same task or are contextually related), and commonsense appropriateness (putting things where people would usually expect to find them). To capture these constructs, we designed and validated a self-report questionnaire through a 63-participant online study. Results confirm the psychological distinctiveness of these constructs and their explanatory power across two scenarios (kitchen and living room). We demonstrate the utility of these constructs by integrating them into a Monte Carlo Tree Search (MCTS) planner and show that when guided by participant-derived preferences, our planner can generate reasonable arrangements that closely align with those generated by participants. This work contributes a compact, interpretable formulation of object arrangement preferences and a demonstration of how it can be operationalized for robot planning.

</details>


### [36] [GenZ: Foundational models as latent variable generators within traditional statistical models](https://arxiv.org/abs/2512.24834)
*Marko Jojic,Nebojsa Jojic*

Main category: cs.AI

TL;DR: GenZ是一个混合模型，通过可解释的语义特征桥接基础模型和统计建模，在房价预测和电影推荐任务上显著优于纯基础模型方法。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型拥有广泛的领域知识，但往往无法捕捉对预测任务至关重要的数据集特定模式。需要一种方法能够结合基础模型的语义理解能力和统计建模的数据特定模式发现能力。

Method: 通过迭代过程发现语义特征描述，对比统计建模错误识别的项目组。采用广义EM算法联合优化语义特征描述符和统计模型参数，将冻结的基础模型判断视为潜在二元特征的噪声观测，通过学习的统计关系预测实值目标。

Result: 在房价预测任务中，使用多模态列表数据发现的语义特征实现了12%的中位数相对误差，显著优于GPT-5基线的38%误差。在Netflix电影嵌入预测中，仅从语义描述就能达到0.59余弦相似度，相当于传统协同过滤需要约4000个用户评分才能达到的性能。

Conclusion: GenZ成功结合了基础模型的语义理解能力和统计建模的数据特定模式发现能力，发现的特征揭示了与模型领域知识不同的数据集特定模式，在多个领域实现了显著性能提升。

Abstract: We present GenZ, a hybrid model that bridges foundational models and statistical modeling through interpretable semantic features. While large language models possess broad domain knowledge, they often fail to capture dataset-specific patterns critical for prediction tasks. Our approach addresses this by discovering semantic feature descriptions through an iterative process that contrasts groups of items identified via statistical modeling errors, rather than relying solely on the foundational model's domain understanding. We formulate this as a generalized EM algorithm that jointly optimizes semantic feature descriptors and statistical model parameters. The method prompts a frozen foundational model to classify items based on discovered features, treating these judgments as noisy observations of latent binary features that predict real-valued targets through learned statistical relationships. We demonstrate the approach on two domains: house price prediction (hedonic regression) and cold-start collaborative filtering for movie recommendations. On house prices, our model achieves 12\% median relative error using discovered semantic features from multimodal listing data, substantially outperforming a GPT-5 baseline (38\% error) that relies on the LLM's general domain knowledge. For Netflix movie embeddings, our model predicts collaborative filtering representations with 0.59 cosine similarity purely from semantic descriptions -- matching the performance that would require approximately 4000 user ratings through traditional collaborative filtering. The discovered features reveal dataset-specific patterns (e.g., architectural details predicting local housing markets, franchise membership predicting user preferences) that diverge from the model's domain knowledge alone.

</details>


### [37] [A study on constraint extraction and exception exclusion in care worker scheduling](https://arxiv.org/abs/2512.24853)
*Koki Suenaga,Tomohiro Furuta,Satoshi Ono*

Main category: cs.AI

TL;DR: 提出基于约束模板的方法，从养老机构管理者访谈中提取设施特定的排班约束条件，避免异常约束，用于约束规划求解器生成护工排班表。


<details>
  <summary>Details</summary>
Motivation: 养老机构的排班条件因机构而异，需要根据管理者访谈设计设施特定的约束条件，但现有约束提取技术难以处理异常约束。

Method: 使用约束模板提取各种约束组合（如连续日班模式、员工组合），通过改变天数、员工数量、提取焦点（模式或频率）来提取多样约束，并加入排除异常约束的机制。

Result: 实验表明，该方法成功生成了满足所有硬约束的排班表，并通过避免提取异常约束，减少了软约束违反次数。

Conclusion: 提出的约束模板方法能有效提取养老机构特定的排班约束，避免异常约束干扰，为约束规划求解器提供可靠输入，实现个性化排班生成。

Abstract: Technologies for automatically generating work schedules have been extensively studied; however, in long-term care facilities, the conditions vary between facilities, making it essential to interview the managers who create shift schedules to design facility-specific constraint conditions. The proposed method utilizes constraint templates to extract combinations of various components, such as shift patterns for consecutive days or staff combinations. The templates can extract a variety of constraints by changing the number of days and the number of staff members to focus on and changing the extraction focus to patterns or frequency. In addition, unlike existing constraint extraction techniques, this study incorporates mechanisms to exclude exceptional constraints. The extracted constraints can be employed by a constraint programming solver to create care worker schedules. Experiments demonstrated that our proposed method successfully created schedules that satisfied all hard constraints and reduced the number of violations for soft constraints by circumventing the extraction of exceptional constraints.

</details>


### [38] [Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem](https://arxiv.org/abs/2512.24873)
*Weixun Wang,XiaoXiao Xu,Wanhe An,Fangwen Dai,Wei Gao,Yancheng He,Ju Huang,Qiang Ji,Hanqi Jin,Xiaoyang Li,Yang Li,Zhongwen Li,Shirong Lin,Jiashun Liu,Zenan Liu,Tao Luo,Dilxat Muhtar,Yuanbin Qu,Jiaqiang Shi,Qinghui Sun,Yingshui Tan,Hao Tang,Runze Wang,Yi Wang,Zhaoguo Wang,Yanan Wu,Shaopan Xiong,Binchen Xu,Xander Xu,Yuchi Xu,Qipeng Zhang,Xixia Zhang,Haizhou Zhao,Jie Zhao,Shuaibing Zhao,Baihui Zheng,Jianhui Zheng,Suhang Zheng,Yanni Zhu,Mengze Cai,Kerui Cao,Xitong Chen,Yue Dai,Lifan Du,Tao Feng,Tao He,Jin Hu,Yijie Hu,Ziyu Jiang,Cheng Li,Xiang Li,Jing Liang,Chonghuan Liu,ZhenDong Liu,Haodong Mi,Yanhu Mo,Junjia Ni,Shixin Pei,Jingyu Shen,XiaoShuai Song,Cecilia Wang,Chaofan Wang,Kangyu Wang,Pei Wang,Tao Wang,Wei Wang,Ke Xiao,Mingyu Xu,Tiange Xu,Nan Ya,Siran Yang,Jianan Ye,Yaxing Zang,Duo Zhang,Junbo Zhang,Boren Zheng,Wanxi Deng,Ling Pan,Lin Qu,Wenbo Su,Jiamang Wang,Wei Wang,Hu Wei,Minggang Wu,Cheng Yu,Bing Zhao,Zhicheng Zheng,Bo Zheng*

Main category: cs.AI

TL;DR: ALE是一个端到端的智能体学习生态系统，包含ROLL权重优化框架、ROCK沙盒环境管理和iFlow CLI上下文工程工具。基于ALE训练的ROME智能体在多项基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 开源社区缺乏系统化的智能体开发基础设施，需要端到端的生态系统来优化智能体LLM的生产流程，支持多轮交互式环境中的操作。

Method: ALE包含三个组件：ROLL（权重优化后训练框架）、ROCK（轨迹生成沙盒环境管理器）、iFlow CLI（高效上下文工程框架）。提出数据合成协议和IPA算法（基于语义交互块的信用分配）。

Result: 发布了基于ALE训练的ROME智能体，在超过100万条轨迹上训练。在SWE-bench Verified和Terminal Bench等基准测试中表现出色，证明了ALE基础设施的有效性。

Conclusion: ALE为智能体开发提供了系统化的基础设施，ROME的成功验证了该生态系统的有效性，为开源社区提供了强大的智能体开发工具。

Abstract: Agentic crafting requires LLMs to operate in real-world environments over multiple turns by taking actions, observing outcomes, and iteratively refining artifacts. Despite its importance, the open-source community lacks a principled, end-to-end ecosystem to streamline agent development. We introduce the Agentic Learning Ecosystem (ALE), a foundational infrastructure that optimizes the production pipeline for agent LLMs. ALE consists of three components: ROLL, a post-training framework for weight optimization; ROCK, a sandbox environment manager for trajectory generation; and iFlow CLI, an agent framework for efficient context engineering. We release ROME (ROME is Obviously an Agentic Model), an open-source agent grounded by ALE and trained on over one million trajectories. Our approach includes data composition protocols for synthesizing complex behaviors and a novel policy optimization algorithm, Interaction-based Policy Alignment (IPA), which assigns credit over semantic interaction chunks rather than individual tokens to improve long-horizon training stability. Empirically, we evaluate ROME within a structured setting and introduce Terminal Bench Pro, a benchmark with improved scale and contamination control. ROME demonstrates strong performance across benchmarks like SWE-bench Verified and Terminal Bench, proving the effectiveness of the ALE infrastructure.

</details>


### [39] [Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing](https://arxiv.org/abs/2512.24896)
*Andrii Gamalii,Daniel Górniak,Robert Nowak,Bartłomiej Olber,Krystian Radlak,Jakub Winter*

Main category: cs.AI

TL;DR: 开发了一个半自动数据标注流水线，结合AI与人工专家，用于波兰驾驶场景多模态数据集标注，显著减少标注成本和时间


<details>
  <summary>Details</summary>
Motivation: DARTS项目需要创建波兰条件下的大规模多模态驾驶场景数据集，但手动标注异构数据成本高、耗时长

Method: 采用人在回路方法，结合AI与人工专家：系统自动生成初始标注，支持迭代模型重训练，包含数据匿名化和领域自适应技术，核心使用3D物体检测算法

Result: 开发的工具和方法显著节省时间，同时确保跨不同传感器模态的一致高质量标注

Conclusion: 该解决方案直接支持DARTS项目，加速了项目标准化格式的大规模标注数据集准备，加强了波兰自动驾驶研究的技术基础

Abstract: This report presents the design and implementation of a semi-automated data annotation pipeline developed within the DARTS project, whose goal is to create a large-scale, multimodal dataset of driving scenarios recorded in Polish conditions. Manual annotation of such heterogeneous data is both costly and time-consuming. To address this challenge, the proposed solution adopts a human-in-the-loop approach that combines artificial intelligence with human expertise to reduce annotation cost and duration. The system automatically generates initial annotations, enables iterative model retraining, and incorporates data anonymization and domain adaptation techniques. At its core, the tool relies on 3D object detection algorithms to produce preliminary annotations. Overall, the developed tools and methodology result in substantial time savings while ensuring consistent, high-quality annotations across different sensor modalities. The solution directly supports the DARTS project by accelerating the preparation of large annotated dataset in the project's standardized format, strengthening the technological base for autonomous vehicle research in Poland.

</details>


### [40] [Iterative Deployment Improves Planning Skills in LLMs](https://arxiv.org/abs/2512.24940)
*Augusto B. Corrêa,Yoav Gelberg,Luckeciano C. Melo,Ilia Shumailov,André G. Pereira,Yarin Gal*

Main category: cs.AI

TL;DR: 迭代部署LLM并通过用户数据筛选进行微调，能显著改变模型特性，在规划任务中实现能力提升和泛化，这本质上是一种隐式强化学习机制。


<details>
  <summary>Details</summary>
Motivation: 研究迭代部署大型语言模型时，用户从先前模型输出中筛选数据用于微调新模型，这一过程如何影响模型特性的演变，特别是其潜在的安全影响和训练机制。

Method: 在多个规划领域测试迭代部署机制：每个新模型基于用户从前一模型输出中精心筛选的数据进行微调，观察模型特性的变化和规划能力的提升。

Result: 迭代部署显著提升了模型的规划技能，后续模型展现出涌现的泛化能力，能够发现比初始模型长得多的规划方案。理论分析表明这一过程实现了隐式强化学习。

Conclusion: 迭代部署机制本质上是一种隐式强化学习，具有重要安全意义（奖励函数未明确定义）和训练价值（可作为显式强化学习的替代方案）。

Abstract: We show that iterative deployment of large language models (LLMs), each fine-tuned on data carefully curated by users from the previous models' deployment, can significantly change the properties of the resultant models. By testing this mechanism on various planning domains, we observe substantial improvements in planning skills, with later models displaying emergent generalization by discovering much longer plans than the initial models. We then provide theoretical analysis showing that iterative deployment effectively implements reinforcement learning (RL) training in the outer-loop (i.e. not as part of intentional model training), with an implicit reward function. The connection to RL has two important implications: first, for the field of AI safety, as the reward function entailed by repeated deployment is not defined explicitly, and could have unexpected implications to the properties of future model deployments. Second, the mechanism highlighted here can be viewed as an alternative training regime to explicit RL, relying on data curation rather than explicit rewards.

</details>


### [41] [AMAP Agentic Planning Technical Report](https://arxiv.org/abs/2512.24957)
*Yulan Hu,Xiangwen Zhang,Sheng Ouyang,Hao Yi,Lu Xu,Qinglin Lang,Lide Tan,Xiang Cheng,Tianchen Ye,Zhicong Li,Ge Chen,Wenjin Yang,Zheng Pan,Shaopan Xiong,Siran Yang,Ju Huang,Yan Zhang,Jiamang Wang,Yong Liu,Yinfeng Huang,Tucheng Lin,Xin Li,Ning Guo*

Main category: cs.AI

TL;DR: STAgent是一个专门用于时空理解的大语言模型代理，能够处理约束性兴趣点发现和行程规划等复杂任务，通过工具交互和多阶段训练实现高性能，同时保持通用能力。


<details>
  <summary>Details</summary>
Motivation: 需要开发一个专门处理时空场景复杂任务的智能代理模型，能够有效利用多种工具进行探索、验证和推理，同时保持模型的通用能力。

Method: 采用三阶段方法：1）构建包含10+领域特定工具的稳定工具环境；2）分层数据筛选框架，从海量数据中筛选高质量查询（筛选比例1:10,000）；3）级联训练方案：种子SFT阶段评估查询难度，第二SFT阶段针对高确定性查询微调，最终RL阶段利用低确定性数据。

Result: STAgent在TravelBench上表现出色，同时在广泛的通用基准测试中保持了良好的通用能力，证明了所提代理模型的有效性。

Conclusion: STAgent通过专门的工具环境、高质量数据筛选和多阶段训练，成功构建了一个既能处理复杂时空任务又能保持通用能力的代理模型，为时空智能代理的发展提供了有效方案。

Abstract: We present STAgent, an agentic large language model tailored for spatio-temporal understanding, designed to solve complex tasks such as constrained point-of-interest discovery and itinerary planning. STAgent is a specialized model capable of interacting with ten distinct tools within spatio-temporal scenarios, enabling it to explore, verify, and refine intermediate steps during complex reasoning. Notably, STAgent effectively preserves its general capabilities. We empower STAgent with these capabilities through three key contributions: (1) a stable tool environment that supports over ten domain-specific tools, enabling asynchronous rollout and training; (2) a hierarchical data curation framework that identifies high-quality data like a needle in a haystack, curating high-quality queries with a filter ratio of 1:10,000, emphasizing both diversity and difficulty; and (3) a cascaded training recipe that starts with a seed SFT stage acting as a guardian to measure query difficulty, followed by a second SFT stage fine-tuned on queries with high certainty, and an ultimate RL stage that leverages data of low certainty. Initialized with Qwen3-30B-A3B to establish a strong SFT foundation and leverage insights into sample difficulty, STAgent yields promising performance on TravelBench while maintaining its general capabilities across a wide range of general benchmarks, thereby demonstrating the effectiveness of our proposed agentic model.

</details>


### [42] [Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings](https://arxiv.org/abs/2512.25055)
*Tianzhi He,Farrokh Jazizadeh*

Main category: cs.AI

TL;DR: 提出基于大语言模型的建筑能源管理系统AI代理框架，通过自然语言交互实现智能建筑的上下文感知能源管理，在设备控制、记忆任务等方面表现良好，但在成本估算等复杂任务上仍需改进。


<details>
  <summary>Details</summary>
Motivation: 现有能源管理系统存在局限性，需要更智能、上下文感知的解决方案。利用大语言模型的自主数据分析能力，通过自然语言交互实现更智能的建筑能源管理。

Method: 提出包含感知、中央控制和行动三个模块的概念框架，形成闭环反馈系统。原型评估使用120个用户查询，基于四个真实住宅能源数据集，评估延迟、功能、能力、准确性和成本效益等指标。

Result: 设备控制准确率86%，记忆相关任务97%，调度和自动化74%，能源分析77%，但成本估算准确率仅49%。通过ANOVA测试验证了框架的泛化性。

Conclusion: 该研究为基于LLM的BEMS AI代理评估提供了框架，展示了在智能建筑能源管理中的潜力，同时指出了响应准确性与计算效率之间的权衡，为未来研究指明了方向。

Abstract: This study presents a conceptual framework and a prototype assessment for Large Language Model (LLM)-based Building Energy Management System (BEMS) AI agents to facilitate context-aware energy management in smart buildings through natural language interaction. The proposed framework comprises three modules: perception (sensing), central control (brain), and action (actuation and user interaction), forming a closed feedback loop that captures, analyzes, and interprets energy data to respond intelligently to user queries and manage connected appliances. By leveraging the autonomous data analytics capabilities of LLMs, the BEMS AI agent seeks to offer context-aware insights into energy consumption, cost prediction, and device scheduling, thereby addressing limitations in existing energy management systems. The prototype's performance was evaluated using 120 user queries across four distinct real-world residential energy datasets and different evaluation metrics, including latency, functionality, capability, accuracy, and cost-effectiveness. The generalizability of the framework was demonstrated using ANOVA tests. The results revealed promising performance, measured by response accuracy in device control (86%), memory-related tasks (97%), scheduling and automation (74%), and energy analysis (77%), while more complex cost estimation tasks highlighted areas for improvement with an accuracy of 49%. This benchmarking study moves toward formalizing the assessment of LLM-based BEMS AI agents and identifying future research directions, emphasizing the trade-off between response accuracy and computational efficiency.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [43] [Hierarchical Quasi-cyclic Codes from Reed-Solomon and Polynomial Evaluation Codes](https://arxiv.org/abs/2512.23872)
*Emily McMillon,Kathryn Haymaker*

Main category: cs.IT

TL;DR: 本文首次代数构造了分层准循环码，基于Reed-Solomon码和Kautz-Singleton叠加码构造，展示了层次数和指数由域大小决定，并给出了参数界限和具体实例。


<details>
  <summary>Details</summary>
Motivation: 现有相关编码构造主要基于仿真方法，缺乏代数分析。本文旨在通过代数方法构造分层准循环码，并建立参数的理论界限。

Method: 使用Reed-Solomon码和Kautz-Singleton的叠加码构造方法，代数构建分层准循环码。分析域大小对层次结构和指数的影响，并扩展到多项式评估码。

Result: 成功构造了首个代数分层准循环码，证明了层次数和指数由域大小决定。给出了具体参数表，部分码达到已知最佳最小距离，k=2时获得围长为6的Tanner图。

Conclusion: 本文提出了代数构造分层准循环码的新方法，建立了参数的理论界限，为相关编码设计提供了代数基础，区别于现有仿真为主的研究。

Abstract: We introduce the first example of algebraically constructed hierarchical quasi-cyclic codes. These codes are built from Reed-Solomon codes using a 1964 construction of superimposed codes by Kautz and Singleton. We show both the number of levels in the hierarchy and the index of these Reed-Solomon derived codes are determined by the field size. We show that this property also holds for certain additional classes of polynomial evaluation codes.
  We provide explicit code parameters and properties as well as some additional bounds on parameters such as rank and distance. In particular, starting with Reed-Solomon codes of dimension $k=2$ yields hierarchical quasi-cyclic codes with Tanner graphs of girth 6.
  We present a table of small code parameters and note that some of these codes meet the best known minimum distance for binary codes, with the additional hierarchical quasi-cyclic structure. We draw connections to similar constructions in the literature, but importantly, while existing literature on related codes is largely simulation-based, we present a novel algebraic approach to determining new bounds on parameters of these codes.

</details>


### [44] [Continuous Angular Power Spectrum Recovery From Channel Covariance via Chebyshev Polynomials](https://arxiv.org/abs/2512.24039)
*Shengsong Luo,Ruilin Wu,Chongbin Xu,Junjie Ma,Xiaojun Yuan,Xin Wang*

Main category: cs.IT

TL;DR: 提出基于切比雪夫多项式展开的框架，用于从信道协方差中恢复连续角度功率谱，通过正交多项式变换将病态反演问题转化为有限维线性回归，并引入半定约束和非负正则化。


<details>
  <summary>Details</summary>
Motivation: 在多天线系统中，从信道协方差中恢复连续角度功率谱是一个病态反演问题。传统方法面临数值不稳定性和精度限制，需要一种能够有效利用角度功率谱平滑性和非负性的新框架。

Method: 利用切比雪夫多项式在变换域中的正交性，推导协方差的精确级数表示，通过截断将APS反演转化为有限维线性回归问题。引入非负APS的半定特征化，并提出基于导数的正则化器以促进平滑变化同时保持簇的过渡。

Result: 仿真结果表明，所提出的切比雪夫框架能够实现准确的APS重建，并在频分双工设置中实现从上行链路测量到下行链路协方差的可靠预测。框架通过联合利用平滑性和非负性，为多天线系统中的协方差域处理提供了有效工具。

Conclusion: 切比雪夫多项式展开框架为连续角度功率谱恢复提供了一种有效的数学工具，通过将病态反演问题转化为可处理的线性回归，并引入适当的正则化约束，显著提升了重建精度和协方差预测的可靠性。

Abstract: This paper proposes a Chebyshev polynomial expansion framework for the recovery of a continuous angular power spectrum (APS) from channel covariance. By exploiting the orthogonality of Chebyshev polynomials in a transformed domain, we derive an exact series representation of the covariance and reformulate the inherently ill-posed APS inversion as a finite-dimensional linear regression problem via truncation. The associated approximation error is directly controlled by the tail of the APS's Chebyshev series and decays rapidly with increasing angular smoothness. Building on this representation, we derive an exact semidefinite characterization of nonnegative APS and introduce a derivative-based regularizer that promotes smoothly varying APS profiles while preserving transitions of clusters. Simulation results show that the proposed Chebyshev-based framework yields accurate APS reconstruction, and enables reliable downlink (DL) covariance prediction from uplink (UL) measurements in a frequency division duplex (FDD) setting. These findings indicate that jointly exploiting smoothness and nonnegativity in a Chebyshev domain provides an effective tool for covariance-domain processing in multi-antenna systems.

</details>


### [45] [Random Multiplexing](https://arxiv.org/abs/2512.24087)
*Lei Liu,Yuhao Chi,Shunqi Huang,Zhaoyang Zhang*

Main category: cs.IT

TL;DR: 提出随机复用技术，与物理信道解耦，适用于任意范数有界和谱收敛信道矩阵，通过构建随机变换域中的等效输入各向同性信道矩阵实现统计衰落信道遍历性，保证AMP类检测器在特定条件下的渐近最优性。


<details>
  <summary>Details</summary>
Motivation: 传统复用技术（如SC-FDE、OFDM、OTFS、AFDM）依赖特定信道结构实现低复杂度检测，但在动态现实环境中鲁棒性受限。需要一种与物理信道解耦的复用技术，适用于任意信道矩阵。

Method: 提出随机复用技术，通过构建随机变换域中的等效输入各向同性信道矩阵实现统计衰落信道遍历性。采用低复杂度跨域记忆AMP（CD-MAMP）检测器，利用时域信道稀疏性和等效信道随机性。推导最优功率分配以最小化BER和最大化约束容量。

Result: 随机复用技术保证AMP类检测器在任意范数有界、谱收敛信道矩阵和信号配置下的渐近最优性。CD-MAMP检测器在随机复用系统中具有最优编码原理和约束容量最优性。该技术在不同无线应用中展现出良好适应性。

Conclusion: 随机复用技术突破了传统复用技术对特定信道结构的依赖，为动态无线环境提供了鲁棒且通用的解决方案，在多种应用场景中展现出优越性能。

Abstract: As wireless communication applications evolve from traditional multipath environments to high-mobility scenarios like unmanned aerial vehicles, multiplexing techniques have advanced accordingly. Traditional single-carrier frequency-domain equalization (SC-FDE) and orthogonal frequency-division multiplexing (OFDM) have given way to emerging orthogonal time-frequency space (OTFS) and affine frequency-division multiplexing (AFDM). These approaches exploit specific channel structures to diagonalize or sparsify the effective channel, thereby enabling low-complexity detection. However, their reliance on these structures significantly limits their robustness in dynamic, real-world environments. To address these challenges, this paper studies a random multiplexing technique that is decoupled from the physical channels, enabling its application to arbitrary norm-bounded and spectrally convergent channel matrices. Random multiplexing achieves statistical fading-channel ergodicity for transmitted signals by constructing an equivalent input-isotropic channel matrix in the random transform domain. It guarantees the asymptotic replica MAP bit-error rate (BER) optimality of AMP-type detectors for linear systems with arbitrary norm-bounded, spectrally convergent channel matrices and signaling configurations, under the unique fixed point assumption. A low-complexity cross-domain memory AMP (CD-MAMP) detector is considered, leveraging the sparsity of the time-domain channel and the randomness of the equivalent channel. Optimal power allocations are derived to minimize the replica MAP BER and maximize the replica constrained capacity of random multiplexing systems. The optimal coding principle and replica constrained-capacity optimality of CD-MAMP detector are investigated for random multiplexing systems. Additionally, the versatility of random multiplexing in diverse wireless applications is explored.

</details>


### [46] [When Wires Can't Keep Up: Reconfigurable AI Data Centers Empowered by Terahertz Wireless Communications](https://arxiv.org/abs/2512.24110)
*Chong Han,Mingjie Zhu,Wenqi Zhao,Ziming Yu,Guolong Huang,Guangjian Wang,Wen Tong,Wenjun Zhang*

Main category: cs.IT

TL;DR: 太赫兹无线数据中心（THz-WDC）通过超宽带容量、单跳低延迟和短中距离（1-100米）能效，为AI数据中心提供革命性互连架构，替代传统铜缆和光缆。


<details>
  <summary>Details</summary>
Motivation: 现代数据中心AI工作负载爆炸式增长，传统铜缆和光缆互连在延迟、功耗和刚性方面面临根本性挑战，限制了分布式AI集群的可扩展性。

Method: 提出太赫兹无线数据中心愿景，探索数字孪生编排、低复杂度波束操纵技术、全硅太赫兹收发器、低复杂度模拟基带架构等关键技术，并进行数值分析比较太赫兹与光缆/铜缆互连的性能。

Result: 太赫兹无线链路可实现每链路高达1Tbps、通过空间复用总吞吐量达10Tbps、单跳延迟低于50ns、20米距离内能效低于10pJ/bit的性能，在特定距离和吞吐量域超越传统有线解决方案。

Conclusion: 太赫兹无线互连为未来量子和小芯片模块化架构数据中心提供灵活连接机制，是实现无线定义、可重构和可持续AI数据中心的路线图。

Abstract: The explosive growth of artificial intelligence (AI) workloads in modern data centers demands a radical transformation of interconnect architectures. Traditional copper and optical wiring face fundamental challenges in latency, power consumption, and rigidity, constraining the scalability of distributed AI clusters. This article introduces a vision for Terahertz (THz) Wireless Data Center (THz-WDC) that combines ultra-broadband capacity, one-hop low-latency communication, and energy efficiency in the short-to-medium range (1-100m). Performance and technical requirements are first articulated, including up to 1 Tbps per link, aggregate throughput up to 10 Tbps via spatial multiplexing, sub-50 ns single-hop latency, and sub-10 pJ/bit energy efficiency over 20m. To achieve these ambitious goals, key enabling technologies are explored, including digital-twin-based orchestration, low-complexity beam manipulation technologies, all-silicon THz transceivers, and low-complexity analog baseband architectures. Moreover, as future data centers shift toward quantum and chiplet-based modular architectures, THz wireless links provide a flexible mechanism for interconnecting, testing, and reconfiguring these modules. Finally, numerical analysis is presented on the latency and power regimes of THz versus optical and copper interconnects, identifying the specific distance and throughput domains where THz links can surpass conventional wired solutions. The article concludes with a roadmap toward wireless-defined, reconfigurable, and sustainable AI data centers.

</details>


### [47] [Efficient Decoding of Twisted GRS Codes and Roth--Lempel Codes](https://arxiv.org/abs/2512.24217)
*Runtian Zhu,Lingfei Jin*

Main category: cs.IT

TL;DR: 本文提出了针对TGRS码和Roth-Lempel码的高效列表解码和唯一解码算法，基于Guruswami-Sudan算法，在特定参数条件下实现接近线性的时间复杂度，显著改进现有二次复杂度方法。


<details>
  <summary>Details</summary>
Motivation: MDS码在实践中有广泛应用，但大多数已知MDS码都是广义Reed-Solomon码，非GRS码相对较少被研究。研究非GRS码既有理论意义，也有实际价值，因为GRS码的强代数结构在密码学场景中可能不受欢迎。TGRS码和Roth-Lempel码是两个重要的非GRS码族，虽然已有大量构造和结构分析工作，但解码问题研究相对较少，许多问题仍待解决。

Method: 基于Guruswami-Sudan算法，为TGRS码和Roth-Lempel码设计列表解码和唯一解码算法。对于TGRS码，支持最多O(n²)个扭曲的固定速率码；对于Roth-Lempel码，首次提供高效解码器。算法在特定参数条件下实现接近线性的时间复杂度。此外，将代数操作检测码整合到列表解码框架中，提高从输出列表中恢复正确消息的概率。

Result: 提出的算法在代码长度上实现接近线性的运行时间，显著改进先前已知的二次时间复杂度。TGRS解码器支持最多O(n²)个扭曲，大幅扩展了先前仅处理单扭曲情况的工作。对于Roth-Lempel码，提供了首个高效解码器。列表解码器在广泛参数范围内超越经典唯一解码半径。通过整合AMD码，能够以高概率从输出列表中恢复正确消息。

Conclusion: 本文为非GRS MDS码（特别是TGRS码和Roth-Lempel码）提供了高效的解码算法，填补了该领域的研究空白。算法在时间复杂度上取得显著改进，支持更多扭曲参数，并为Roth-Lempel码提供首个实用解码器。通过整合AMD码增强了列表解码的实用性，为这些码在实际应用中的部署奠定了基础。

Abstract: MDS codes play a central role in practice due to their broad applications. To date, most known MDS codes are generalized Reed-Solomon (GRS) codes, leaving codes that are not equivalent to GRS codes comparatively less understood. Studying this non-GRS regime is therefore of intrinsic theoretical interest, and is also practically relevant since the strong algebraic structure of GRS codes can be undesirable in cryptographic settings. Among the known non-GRS codes, twisted generalized Reed-Solomon (TGRS) codes and Roth-Lempel codes are two representative families of non-GRS codes that have attracted significant attention. Though substantial work has been devoted to the construction and structural analysis of TGRS and Roth-Lempel codes, comparatively little attention has been paid to their decoding, and many problems remain open. In this paper, we propose list and unique decoding algorithms for TGRS codes and Roth-Lempel codes based on the Guruswami-Sudan algorithm. Under suitable parameter conditions, our algorithms achieve near-linear running time in the code length, improving upon the previously best-known quadratic-time complexity. Our TGRS decoder supports fixed-rate TGRS codes with up to O(n^2) twists, substantially extending prior work that only handled the single-twist case. For Roth-Lempel codes, we provide what appears to be the first efficient decoder. Moreover, our list decoders surpass the classical unique-decoding radius for a broad range of parameters. Finally, we incorporate algebraic manipulation detection (AMD) codes into the list-decoding framework, enabling recovery of the correct message from the output list with high probability.

</details>


### [48] [SC-LDPC Codes Over $\mathbb{F}_q$: Minimum Distance, Decoding Analysis and Threshold Saturation](https://arxiv.org/abs/2512.24232)
*Jiaxin Lyu,Guanghui He*

Main category: cs.IT

TL;DR: 该论文研究了有限域上的随机空间耦合LDPC码，提出了改进的耦合结构，证明了其具有良好的最小距离和停止集尺寸，并建立了通用的阈值饱和理论框架。


<details>
  <summary>Details</summary>
Motivation: 研究有限域上空间耦合LDPC码的性能，特别是如何通过不同的变量节点边扩展规则来改进码的距离特性，并建立适用于任意有限域的迭代译码阈值分析框架。

Method: 定义了标准耦合和改进耦合两种随机Tanner图结构，使用独立均匀随机单项式映射。建立了对称概率测度理论框架，分析其在概率单纯形上的性质，并研究了退化理论。针对q进制输入对称信道，建立了通用的阈值饱和分析方法。

Result: 证明了两种耦合结构都具有渐近良好的最小距离和最小停止集尺寸。改进耦合结构在距离性能上优于标准耦合结构。建立了适用于任意有限域的通用阈值饱和结果，即随着耦合参数增加，置信传播阈值会饱和到一个仅取决于基本结构和信道族的确定阈值。

Conclusion: 有限域上的空间耦合LDPC码具有良好的距离特性和阈值饱和性能，改进的耦合结构能进一步提升性能。建立的对称概率测度理论框架为分析任意有限域上的迭代译码阈值提供了通用工具。

Abstract: We investigate random spatially coupled low-density parity-check (SC-LDPC) code ensembles over finite fields. Under different variable-node edge-spreading rules, the random Tanner graphs of several coupled ensembles are defined by multiple independent, uniformly random monomial maps. The two main coupled ensembles considered are referred to as the standard coupled ensemble and the improved coupled ensemble. We prove that both coupled ensembles exhibit asymptotically good minimum distance and minimum stopping set size. Theoretical and numerical results show that the improved coupled ensemble can achieve better distance performance than the standard coupled ensemble. We introduce the essential preliminaries and analytical tools needed to analyze the iterative decoding threshold of coupled ensembles over any finite field. We consider a class of memoryless channels with special symmetry, termed q-ary input memoryless symmetric channels (QMSCs), and show that, for these channels, the distribution of channel messages (in form of probability vectors) likewise exhibits this symmetry. Consequently, we define symmetric probability measures and their reference measures on a finite-dimensional probability simplex, analyze their foundational properties and those of their linear functionals, endow their respective spaces with metric topologies, and conduct an in-depth study of their degradation theory. Based on our analytical framework, we establish a universal threshold saturation result for both of the coupled ensembles over a q-ary finite field on QMSCs. Specifically, as the coupling parameters increase, the belief-propagation threshold of a coupled system saturates to a well-defined threshold that depends only on the underlying ensemble and the channel family.

</details>


### [49] [Infinite families of graphs and stable completion of arbitrary matrices, Part I](https://arxiv.org/abs/2512.24468)
*Augustin Cosse*

Main category: cs.IT

TL;DR: 研究确定性构造图，使得低秩矩阵的唯一补全在任意条目值下都通用可行，通过特定模式（自避行走的并集）与格图子图的关系来刻画可补全性，并设计无限图族使得固定秩矩阵可通过SOS层次实现精确稳定补全。


<details>
  <summary>Details</summary>
Motivation: 研究低秩矩阵补全问题，特别是在任意条目值下都能保证通用唯一补全的图结构构造。现有研究关注随机图上的补全，本文研究确定性构造，旨在找到保证补全可行性的图结构特征。

Method: 将矩阵补全的可补全性与格图子图中的特定模式（自避行走的并集）联系起来。通过分析双邻接矩阵支撑生成的格图子图，建立图结构与矩阵补全可行性的关系，从而设计满足条件的无限图族。

Result: 建立了矩阵补全可补全性与格图子图中特定模式存在的等价关系。构造了无限图族，使得对于任意固定秩矩阵，都能通过平方和（SOS）层次实现精确且稳定的补全。

Conclusion: 提出了确定性构造图的方法，使得低秩矩阵补全在任意条目值下都通用可行。通过图结构中的特定模式刻画可补全性，为设计保证补全可行性的图结构提供了理论框架和构造方法。

Abstract: We study deterministic constructions of graphs for which the unique completion of low rank matrices is generically possible regardless of the values of the entries. We relate the completability to the presence of some patterns (particular unions of self-avoiding walks) in the subgraph of the lattice graph generated from the support of the bi-adjacency matrix. The construction makes it possible to design infinite families of graphs on which exact and stable completion is possible for every fixed rank matrix through the sum-of-squares hierarchy.

</details>


### [50] [Throughput Optimization in UAV-Mounted RIS under Jittering and Imperfect CSI via DRL](https://arxiv.org/abs/2512.24773)
*Anas K. Saeed,Mahmoud M. Salim,Ali Arshad Nasir,Ali H. Muqaibel*

Main category: cs.IT

TL;DR: 该论文提出了一种基于深度强化学习的模型，用于优化无人机搭载可重构智能表面系统的吞吐量，解决了无人机抖动和信道不确定性的挑战。


<details>
  <summary>Details</summary>
Motivation: 无人机搭载的可重构智能表面系统性能对无人机抖动和级联信道不确定性敏感，传统优化方法在实时性和处理随机性方面存在局限，需要更有效的解决方案。

Method: 采用模型无关的深度强化学习框架，结合上下文多臂赌博机公式，使用可微分可行性层将连续动作映射为可行解，奖励函数基于期望吞吐量的蒙特卡洛估计。

Result: 在严重抖动和低信道状态信息质量下，所提算法比传统交替优化加权最小均方误差基准获得更高吞吐量，在线推理时间仅0.6毫秒，远低于传统方法的370-550毫秒。

Conclusion: 深度强化学习方法能有效处理无人机抖动和信道不确定性，在保持性能可比性的同时显著提升实时性，为无人机可重构智能表面系统优化提供了实用解决方案。

Abstract: Reconfigurable intelligent surfaces (RISs) mounted on unmanned aerial vehicles (UAVs) can reshape wireless propagation on-demand. However, their performance is sensitive to UAV jitter and cascaded channel uncertainty. This paper investigates a downlink multiple-input single-output UAV-mounted RIS system in which a ground multiple-antenna base station (BS) serves multiple single-antenna users under practical impairments. Our goal is to maximize the expected throughput under stochastic three-dimensional UAV jitter and imperfect cascaded channel state information (CSI) based only on the available channel estimates. This leads to a stochastic nonconvex optimization problem subject to a BS transmit power constraint and strict unit-modulus constraints on all RIS elements. To address this problem, we design a model-free deep reinforcement learning (DRL) framework with a contextual bandit formulation. A differentiable feasibility layer is utilized to map continuous actions to feasible solutions, while the reward is a Monte Carlo estimate of the expected throughput. We instantiate this framework with constrained variants of deep deterministic policy gradient (DDPG) and twin delayed deep deterministic policy gradient (TD3) that do not use target networks. Simulations show that the proposed algorithms yield higher throughput than conventional alternating optimization-based weighted minimum mean-square error (AO-WMMSE) baselines under severe jitter and low CSI quality. Across different scenarios, the proposed methods achieve performance that is either comparable to or slightly below the AO-WMMSE benchmark, based on sample average approximation (SAA) with a relative gap ranging from 0-12%. Moreover, the proposed DRL controllers achieve online inference times of 0.6 ms per decision versus roughly 370-550 ms for AO-WMMSE solvers.

</details>
