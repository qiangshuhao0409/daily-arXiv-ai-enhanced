<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 11]
- [cs.AI](#cs.AI) [Total: 55]
- [cs.IT](#cs.IT) [Total: 9]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [OddEEC: A New Sketch Technique for Error Estimating Coding](https://arxiv.org/abs/2508.11842)
*Huayi Wang,Jingfan Meng,Jun Xu*

Main category: cs.NI

TL;DR: OddEEC是一种新颖的错误估计编码方案，基于Odd Sketch技术，通过位采样和最大似然估计器实现，在保持与gEEC和mEEC相当精度的同时显著降低了解码复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统的错误估计编码(EEC)技术在无线网络包传输中用于估计比特错误数量，但现有方案存在解码复杂度高的问题，需要开发更高效的解决方案。

Method: 将数据素描技术Odd Sketch非平凡地适配到EEC中，采用位采样技术和最大似然估计器来解决新的挑战。

Result: 实验表明OddEEC在整体估计精度上与竞争方案(gEEC和mEEC)相当，但解码复杂度显著降低。

Conclusion: OddEEC成功地将Odd Sketch技术应用于错误估计编码领域，在保持精度的同时大幅提升了效率，为无线网络错误估计提供了更实用的解决方案。

Abstract: Error estimating coding (EEC) is a standard technique for estimating the
number of bit errors during packet transmission over wireless networks. In this
paper, we propose OddEEC, a novel EEC scheme. OddEEC is a nontrivial adaptation
of a data sketching technique named Odd Sketch to EEC, addressing new
challenges therein by its bit sampling technique and maximum likelihood
estimator. Our experiments show that OddEEC overall achieves comparable
estimation accuracy as competing schemes such as gEEC and mEEC, with much
smaller decoding complexity.

</details>


### [2] [Bandit-Based Charging with Beamforming for Mobile Wireless-Powered IoT Systems](https://arxiv.org/abs/2508.11971)
*Chenchen Fu,Zining Zhou,Xiaoxing Qiu,Sujunjie Sun,Weiwei Wu,Song Han*

Main category: cs.NI

TL;DR: 本文提出了一种基于老虎机的充电框架，用于处理移动充电器在时变信道条件下的无线充电问题，考虑了实时充电时限约束和动态调整需求。


<details>
  <summary>Details</summary>
Motivation: 无线供电技术在物联网中应用越来越广泛，但移动充电器面临动态信道条件和有限能量预算的挑战。现有方法往往忽视了这些动态性或实时充电约束。

Method: 提出了一种时空充电策略，联合决定充电位置、持续时间和放式配置。通过区域离散化实现多项式时间枚举，并提出了两种在线老虎机算法来处理静态和非静态未知信道状态。

Result: 实验结果验证了所提算法能够迅速接近理论上限同时有效跟踪动态信道状态进行适应性调整。

Conclusion: 该框架能够有效解决移动充电器在实际应用中面临的动态信道和实时约束问题，为无线供电物联网网络提供了可扩展的充电解决方案。

Abstract: Wireless power transfer (WPT) is increasingly used to sustain
Internet-of-Things (IoT) systems by wirelessly charging embedded devices.
Mobile chargers further enhance scalability in wireless-powered IoT (WP-IoT)
networks, but pose new challenges due to dynamic channel conditions and limited
energy budgets. Most existing works overlook such dynamics or ignore real-time
constraints on charging schedules. This paper presents a bandit-based charging
framework for WP-IoT systems using mobile chargers with practical beamforming
capabilities and real-time charging constraints. We explicitly consider
time-varying channel state information (CSI) and impose a strict charging
deadline in each round, which reflects the hard real-time constraint from the
charger's limited battery capacity. We formulate a temporal-spatial charging
policy that jointly determines the charging locations, durations, and
beamforming configurations. Area discretization enables polynomial-time
enumeration with constant approximation bounds. We then propose two online
bandit algorithms for both stationary and non-stationary unknown channel state
scenarios with bounded regrets. Our extensive experimental results validate
that the proposed algorithms can rapidly approach the theoretical upper bound
while effectively tracking the dynamic channel states for adaptive adjustment.

</details>


### [3] [TailO-RAN: O-RAN Control on Scheduler Parameters to Tailor RAN Performance](https://arxiv.org/abs/2508.12112)
*Nicolo Longhi,Salvatore D'Oro,Leonardo Bonati,Michele Polese,Roberto Verdone,Tommaso Melodia*

Main category: cs.NI

TL;DR: 本文提出了一种可编程调度器设计和O-RAN xApp，通过动态调整调度权重来提高工业物联网中视频传输的吞吐量和资产跟踪准确性。实验结果显示吞吐量要求满足率提高33%，检测准确性提高至37.04%。


<details>
  <summary>Details</summary>
Motivation: 传统黑盒式的无线接入网络(RAN)极大限制了灵活性和创新。Open RAN范式和O-RAN联盟的架构通过开放性、虚拟化和网络智能来解决这些限制。

Method: 1）为Open RAN分布式单元(DU)设计可编程调度器，通过可配置权重保证用户设备的最低吞吐量。 2）提出O-RAN xApp，基于通过报告吞吐量值的联合补充累积分布函数(CCDF)动态重新配置调度器权重。

Result: 实验结果显示：我们的方法将满足吞吐量要求的成功率提高了33%；在资产跟踪应用场景中，xApp将检测准确性(F1分数)提高了至37.04%。

Conclusion: 该研究成功开发了一种有效的可编程调度器和O-RAN xApp方案，显著提高了5G工业物联网中视频传输的性能和资产跟踪的准确性，证明了Open RAN在实际应用中的效果。

Abstract: The traditional black-box and monolithic approach to Radio Access Networks
(RANs) has heavily limited flexibility and innovation. The Open RAN paradigm,
and the architecture proposed by the O-RAN ALLIANCE, aim to address these
limitations via openness, virtualization and network intelligence. In this
work, first we propose a novel, programmable scheduler design for Open RAN
Distributed Units (DUs) that can guarantee minimum throughput levels to User
Equipments (UEs) via configurable weights. Then, we propose an O-RAN xApp that
reconfigures the scheduler's weights dynamically based on the joint
Complementary Cumulative Distribution Function (CCDF) of reported throughput
values. We demonstrate the effectiveness of our approach by considering the
problem of asset tracking in 5G-powered Industrial Internet of Things (IIoT)
where uplink video transmissions from a set of cameras are used to detect and
track assets via computer vision algorithms. We implement our programmable
scheduler on the OpenAirInterface (OAI) 5G protocol stack, and test the
effectiveness of our xApp control by deploying it on the O-RAN Software
Community (OSC) near-RT RAN Intelligent Controller (RIC) and controlling a 5G
RAN instantiated on the Colosseum Open RAN digital twin. Our experimental
results demonstrate that our approach enhances the success percentage of
meeting throughput requirements by 33% compared to a reference scheduler.
Moreover, in the asset tracking use case, we show that the xApp improves the
detection accuracy, i.e., the F1 score, by up to 37.04%.

</details>


### [4] [An Efficient and Adaptive Framework for Achieving Underwater High-performance Maintenance Networks](https://arxiv.org/abs/2508.12661)
*Yu Gou,Tong Zhang,Jun Liu,Zhongyang Qi,Dezhi Zheng*

Main category: cs.NI

TL;DR: U-HPNF是一个基于深度强化学习和联邦学习的分层框架，通过数字孪生技术实现水下通信网络的自管理、自配置和自优化，提升空天地海一体化网络的性能。


<details>
  <summary>Details</summary>
Motivation: 解决水下通信网络长传播延迟和有限网络容量对空天地海一体化网络服务质量的影响，需要高效管理有限资源并适应变化的QoS需求。

Method: 采用三层网络设计，结合深度强化学习进行资源管理决策，联邦学习迭代优化模型减少通信开销，数字孪生技术模拟网络场景和适应QoS需求。

Result: 数值结果表明U-HPNF框架能有效优化各种情况下的网络性能，并适应变化的QoS需求。

Conclusion: U-HPNF提供了一个AI原生的高性能水下网络解决方案，通过智能资源管理和隐私保护实现了网络性能的显著提升。

Abstract: With the development of space-air-ground-aqua integrated networks (SAGAIN),
high-speed and reliable network services are accessible at any time and any
location. However, the long propagation delay and limited network capacity of
underwater communication networks (UCN) negatively impact the service quality
of SAGAIN. To address this issue, this paper presents U-HPNF, a hierarchical
framework designed to achieve a high-performance network with self-management,
self-configuration, and self-optimization capabilities. U-HPNF leverages the
sensing and decision-making capabilities of deep reinforcement learning (DRL)
to manage limited resources in UCNs, including communication bandwidth,
computational resources, and energy supplies. Additionally, we incorporate
federated learning (FL) to iteratively optimize the decision-making model,
thereby reducing communication overhead and protecting the privacy of node
observation information. By deploying digital twins (DT) at both the
intelligent sink layer and aggregation layer, U-HPNF can mimic numerous network
scenarios and adapt to varying network QoS requirements. Through a three-tier
network design with two-levels DT, U-HPNF provides an AI-native
high-performance underwater network. Numerical results demonstrate that the
proposed U-HPNF framework can effectively optimize network performance across
various situations and adapt to changing QoS requirements.

</details>


### [5] [Game-Theoretic and Reinforcement Learning-Based Cluster Head Selection for Energy-Efficient Wireless Sensor Network](https://arxiv.org/abs/2508.12707)
*Mehrshad Eskandarpour,Saba Pirahmadian,Parham Soltani,Hossein Soleimani*

Main category: cs.NI

TL;DR: 提出了一种基于博弈论和强化学习的自适应聚类路由算法，通过动态选择簇头节点和优化能量分配，提高无线传感器网络的能量效率和网络寿命。


<details>
  <summary>Details</summary>
Motivation: 无线传感器网络中电池寿命短是主要瓶颈，现有节能算法如聚类和路由协议虽能提高能效，但需要更智能的自适应机制来优化能量分配和延长网络寿命。

Method: 采用多步聚类策略选择动态簇头，结合博弈论和强化学习将网络建模为多智能体强化学习问题，使用AI驱动的簇头发现算法实现自聚类和能量平衡优化。

Result: 提出的方法能够防止特定节点过早能量耗尽，确保网络能量使用均匀，实现可控功耗和确定性网络寿命，降低维护成本。

Conclusion: 该方法通过单跳路由和最高电量传感器作为中介，提高了WSN部署的能量效率和稳定性，有效解决了节点能量不均衡和网络断开问题。

Abstract: Energy in Wireless Sensor Networks (WSNs) is critical to network lifetime and
data delivery. However, the primary impediment to the durability and
dependability of these sensor nodes is their short battery life. Currently,
power-saving algorithms such as clustering and routing algorithms have improved
energy efficiency in standard protocols. This paper proposes a clustering-based
routing approach for creating an adaptive, energy-efficient mechanism. Our
system employs a multi-step clustering strategy to select dynamic cluster heads
(CH) with optimal energy distribution. We use Game Theory (GT) and
Reinforcement Learning (RL) to optimize resource utilization. Modeling the
network as a multi-agent RL problem using GT principles allows for
self-clustering while optimizing sensor lifetime and energy balance. The
proposed AI-powered CH-Finding algorithm improves network efficiency by
preventing premature energy depletion in specific nodes while also ensuring
uniform energy usage across the network. Our solution enables controlled power
consumption, resulting in a deterministic network lifetime. This predictability
lowers maintenance costs by reducing the need for node replacement.
Furthermore, our proposed method prevents sensor nodes from disconnecting from
the network by designating the sensor with the highest charge as an
intermediary and using single-hop routing. This approach improves the energy
efficiency and stability of Wireless Sensor Network (WSN) deployments.

</details>


### [6] [Towards Nomadic 6G Communication Networks: Implications on Architecture, Standardization, and Regulatory Aspects](https://arxiv.org/abs/2508.12710)
*Daniel Lindenschmitt,Marcos Rates Crippa,Hans D. Schotten*

Main category: cs.NI

TL;DR: 本文探讨6G游牧网络的架构设计，重点关注动态环境中节点通信、服务发现和控制委托的接口需求，分析跨管辖边界的监管挑战，并提出面向游牧性的接口设计原则。


<details>
  <summary>Details</summary>
Motivation: 第六代移动通信网络中游牧网络的出现带来了网络基础设施概念、部署和运营方式的范式转变，需要研究这种移动自组织节点系统的架构影响和接口设计。

Method: 基于当前6G愿景和相关研究，分析现有架构的局限性，综合移动网络、非地面网络和有机网络领域的发现，提出面向游牧性的接口设计原则。

Result: 识别了动态环境中节点间通信、服务发现和控制委托的具体需求，分析了基础设施元素跨越管辖边界时的监管和许可挑战，提出了适用于游牧网络的接口设计原则。

Conclusion: 这项工作为未来游牧6G通信系统的架构基础做出了贡献，并为去中心化移动基础设施中的接口标准化指明了方向。

Abstract: The emergence of nomadic mobile communication networks for sixth-generation
(6G) introduces a paradigm shift in how network infrastructure is
conceptualized, deployed, and operated. Unlike traditional fixed systems,
Nomadic Networks (NNs) consist of mobile and self-organizing nodes that provide
radio infrastructure capabilities in motion. This paper explores the
architectural implications of such systems, with a particular focus on the
design and evolution of network interfaces. We analyze the requirements for
inter-node communication, service discovery, and control delegation in dynamic
environments. Furthermore, we examine the regulatory and licensing challenges
that arise when infrastructure elements traverse jurisdictional boundaries.
Based on current 6G visions and relevant research, we identify limitations in
existing architectures and propose a set of interface principles tailored to
nomadicity. By synthesizing findings from mobile, non-terrestrial, and organic
network domains, this work contributes to the architectural foundation for
future nomadic 6G communication systems and outlines directions for interface
standardization in decentralized, mobile infrastructures.

</details>


### [7] [Cooperative Sensing-Assisted Predictive Beam Tracking for MIMO-OFDM Networked ISAC Systems](https://arxiv.org/abs/2508.12723)
*Xiaoyu Yang,Zhiqing Wei,Jie Xu,Huici Wu,Zhiyong Feng*

Main category: cs.NI

TL;DR: 本文提出了一种用于MIMO-OFDM ISAC系统的协作感知辅助预测波束跟踪设计，通过多基站协作感知和扩展卡尔曼滤波来跟踪移动设备，并优化波束赋形以同时满足通信速率和感知精度要求


<details>
  <summary>Details</summary>
Motivation: 在MIMO-OFDM ISAC系统中，多基站需要同时进行通信和感知，传统方法难以有效跟踪移动设备并优化波束方向，需要开发新的协作感知和预测波束跟踪方法来提升系统性能

Method: 提出协作感知设计：基站使用2D-DFT技术进行本地目标估计，然后采用EKF方法融合测量结果预测目标参数；基于预测结果设计预测波束赋形，采用SDR和惩罚基算法解决非凸优化问题

Result: 开发了两种算法：基于SDR的最优解算法和惩罚基高质量低复杂度解决方案，能够有效最大化通信速率同时满足感知的PC-CRLB要求

Conclusion: 所提出的协作感知辅助预测波束跟踪设计能够显著提升MIMO-OFDM ISAC系统的性能，实现通信和感知的协同优化，为未来无线通信系统提供有效的波束跟踪解决方案

Abstract: This paper studies a multiple-input multiple-output (MIMO) orthogonal
frequency division multiplexing (OFDM) networked integrated sensing and
communication (ISAC) system, in which multiple base stations (BSs) perform beam
tracking to communicate with a mobile device. In particular, we focus on the
beam tracking over a number of tracking time slots (TTSs) and suppose that
these BSs operate at non-overlapping frequency bands to avoid the severe
inter-cell interference. Under this setup, we propose a new cooperative
sensing-assisted predictive beam tracking design. In each TTS, the BSs use echo
signals to cooperatively track the mobile device as a sensing target, and
continuously adjust the beam directions to follow the device for enhancing the
performance for both communication and sensing. First, we propose a cooperative
sensing design to track the device, in which the BSs first employ the
two-dimensional discrete Fourier transform (2D-DFT) technique to perform local
target estimation, and then use the extended Kalman filter (EKF) method to fuse
their individual measurement results for predicting the target parameters.
Next, based on the predicted results, we obtain the achievable rate for
communication and the predicted conditional Cram\'er-Rao lower bound (PC-CRLB)
for target parameters estimation in the next TTS, as a function of the
beamforming vectors. Accordingly, we formulate the predictive beamforming
design problem, with the objective of maximizing the achievable communication
rate in the following TTS, while satisfying the PC-CRLB requirement for
sensing. To address the resulting non-convex problem, we first propose a
semi-definite relaxation (SDR)-based algorithm to obtain the optimal solution,
and then develop an alternative penalty-based algorithm to get a high-quality
low-complexity solution.

</details>


### [8] [Some optimization possibilities in data plane programming](https://arxiv.org/abs/2508.12767)
*Altangerel Gereltsetseg,Tejfel Máté*

Main category: cs.NI

TL;DR: 本文基于2019年Dagstuhl研讨会讨论，提出了四种优化数据平面的解决方案，包括异步外部函数、基于负载大小的压缩、网络内缓存和外部函数卸载，并在P4语言中进行了实现验证。


<details>
  <summary>Details</summary>
Motivation: 软件定义网络(SDN)中控制平面研究已较成熟，但数据平面编程作为相对较新的概念，仍面临诸多挑战。2019年Dagstuhl研讨会讨论了未来10年需要解决的数据平面编程问题，本文旨在为此提供可能的解决方案。

Method: 基于研讨会讨论和文献综述，提出了四种优化方案：(i)丰富数据平面语言的异步外部函数功能(ii)基于负载大小的压缩(iii)网络内缓存加速包处理(iv)将外部函数卸载到额外线程、虚拟机或服务器。部分方案在P4数据平面语言中进行了实现。

Result: 提出了具体可行的数据平面优化方案，并通过P4语言实现验证了方案的实用性，为解决数据平面编程挑战提供了技术路径。

Conclusion: 本文提出的四种优化方案能够有效提升数据平面的包处理性能和链路利用率，为未来数据平面编程的发展提供了有价值的技术参考和实践指导。

Abstract: Software-defined networking (SDN) technology aims to create a highly flexible
network by decoupling control plane and the data plane and programming them
independently. There has been a lot of research on improving and optimizing the
control plane, and data plane programming is a relatively new concept, so study
on it is one of the hot topics for researchers. At the 2019 Dagstuhl Seminar,
well-known scientists on computer networking discussed challenges and problems
in the field of data plane programming that need to be addressed over the next
10 years. Based on this seminar issues and papers review, we suggested some
possible solutions which are for optimizing data plane to improve packet
processing performance and link utilization. The suggestions include (i)
enriching data plane language with asynchronous external function, (ii)
compression based on payload size, (iii) in-network caching for fast packet
processing, and (iv) offloading external functions to an additional thread,
virtual machine (VM) or server, etc. In addition, we implemented some of these
in the P4 data plane language to illustrate the practicality.

</details>


### [9] [SDAP-based QoS Flow Multiplexing Support in Simu5G for 5G NR Simulation](https://arxiv.org/abs/2508.12785)
*Mohamed Seliem,Utz Roedig,Cormac Sreenan,Dirk Pesch*

Main category: cs.NI

TL;DR: 为Simu5G模拟框架开发了标准化的SDAP扩展，支持QoS流多路复用和差分化服务模拟


<details>
  <summary>Details</summary>
Motivation: 5G NR中SDAP协议在QoS流多路复用中关键作用，但常见模拟框架缺少SDAP支持，限制了实际QoS行为的模拟能力

Method: 设计并实现了模块化、符合标准的SDAP扩展，包括QFI流标签、SDAP头插入/移除、可配置逻辑DRB映射等核心功能

Result: 实现支持多QFI模拟场景，能够模拟差分化QoS流和流意识调度策略，验证结果证明了正确的SDAP行为

Conclusion: 该SDAP扩展为实玶式5G模拟提供了基础，支持流分离、延迟敏感流量和工业QoS配置等高级模拟需求

Abstract: The Service Data Adaptation Protocol (SDAP) plays a central role in 5G New
Radio (NR), acting as a bridge between the core and radio networks, by enabling
QoS Flow multiplexing over shared Data Radio Bearers (DRBs). However, most 5G
simulation frameworks, including the popular OMNet++-based Simu5G, lack SDAP
support, limiting their ability to model realistic QoS behavior. This paper
presents a modular, standardscompliant SDAP extension for Simu5G. The
implementation includes core elements such as QoS Flow Identifer (QFI) flow
tagging, SDAP header insertion/removal, and configurable logical DRB mapping.
The proposed design supports multi-QFI simulation scenarios and enables
researchers to model differentiated QoS flows and flowaware scheduling
policies. Validation results confirm correct SDAP behavior and pave the way for
advanced 5G simulations involving per-flow isolation, latency-sensitive
traffic, and industrial QoS profiles.

</details>


### [10] [RoTO: Robust Topology Obfuscation Against Tomography Inference Attacks](https://arxiv.org/abs/2508.12852)
*Chengze Du,Heng Xu,Zhiwei Yu,Ying Zhou,Zili Meng,Jialong Li*

Main category: cs.NI

TL;DR: RoTO是一种鲁棒的拓扑混淆方案，通过分布建模和min-max优化来防御网络拓扑推断攻击，无需完美探测包控制或特定攻击者模型假设，在结构和链路距离指标上分别提升34%和42.6%。


<details>
  <summary>Details</summary>
Motivation: 现有拓扑混淆防御依赖两个强假设：(1)探测包可完美检测和修改，(2)攻击者使用已知固定推断算法。这些假设在实践中常被打破，导致防御性能下降。

Method: 提出RoTO方案，通过分布建模处理攻击者观测延迟的不确定性，将防御目标转化为min-max优化问题，使用图神经网络进行推断模拟和对抗训练，并优化攻击成功概率上界。

Result: 实验结果显示RoTO优于现有防御方法，在结构相似性上平均提升34%，链路距离上提升42.6%，同时保持强鲁棒性和隐蔽能力。

Conclusion: RoTO通过消除不现实的假设并采用分布建模和对抗训练方法，显著提高了拓扑混淆防御的鲁棒性和有效性。

Abstract: Tomography inference attacks aim to reconstruct network topology by analyzing
end-to-end probe delays. Existing defenses mitigate these attacks by
manipulating probe delays to mislead inference, but rely on two strong
assumptions: (i) probe packets can be perfectly detected and altered, and (ii)
attackers use known, fixed inference algorithms. These assumptions often break
in practice, leading to degraded defense performance under detection errors or
adaptive adversaries. We present RoTO, a robust topology obfuscation scheme
that eliminates both assumptions by modeling uncertainty in attacker-observed
delays through a distributional formulation. RoTO casts the defense objective
as a min-max optimization problem that maximizes expected topological
distortion across this uncertainty set, without relying on perfect probe
control or specific attacker models. To approximate attacker behavior, RoTO
leverages graph neural networks for inference simulation and adversarial
training. We also derive an upper bound on attacker success probability, and
demonstrate that our approach enhances topology obfuscation performance through
the optimization of this upper bound. Experimental results show that RoTO
outperforms existing defense methods, achieving average improvements of 34% in
structural similarity and 42.6% in link distance while maintaining strong
robustness and concealment capabilities.

</details>


### [11] [REACH: Reinforcement Learning for Efficient Allocation in Community and Heterogeneous Networks](https://arxiv.org/abs/2508.12857)
*Zhiwei Yu,Chengze Du,Heng Xu,Ying Zhou,Bo Liu,Jialong Li*

Main category: cs.NI

TL;DR: REACH是一个基于Transformer的强化学习框架，用于社区GPU平台的智能任务调度，通过序列评分方法优化性能、可靠性、成本和网络效率


<details>
  <summary>Details</summary>
Motivation: 社区GPU平台具有硬件/软件多样性、可用性波动和网络条件变化等特点，传统调度器效果不佳，导致任务完成率低下

Method: 使用Transformer-based强化学习框架，将任务调度重新定义为序列评分问题，同时建模全局GPU状态和任务需求

Result: 任务完成率提升达17%，高优先级任务成功率提高一倍以上，带宽惩罚减少超过80%，在GPU流失和网络拥堵情况下表现稳健

Conclusion: REACH框架能有效解决社区GPU平台的调度挑战，在性能、可靠性和成本效率方面显著优于现有基准方法

Abstract: Community GPU platforms are emerging as a cost-effective and democratized
alternative to centralized GPU clusters for AI workloads, aggregating idle
consumer GPUs from globally distributed and heterogeneous environments.
However, their extreme hardware/software diversity, volatile availability, and
variable network conditions render traditional schedulers ineffective, leading
to suboptimal task completion. In this work, we present REACH (Reinforcement
Learning for Efficient Allocation in Community and Heterogeneous Networks), a
Transformer-based reinforcement learning framework that redefines task
scheduling as a sequence scoring problem to balance performance, reliability,
cost, and network efficiency. By modeling both global GPU states and task
requirements, REACH learns to adaptively co-locate computation with data,
prioritize critical jobs, and mitigate the impact of unreliable resources.
Extensive simulation results show that REACH improves task completion rates by
up to 17%, more than doubles the success rate for high-priority tasks, and
reduces bandwidth penalties by over 80% compared to state-of-the-art baselines.
Stress tests further demonstrate its robustness to GPU churn and network
congestion, while scalability experiments confirm its effectiveness in
large-scale, high-contention scenarios.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video](https://arxiv.org/abs/2508.11836)
*Dave Goel,Matthew Guzdial,Anurag Sarkar*

Main category: cs.AI

TL;DR: 提出FAE方法从游戏视频中学习神经符号世界模型，用Retro Coder DSL表示，相比之前的方法学习到更精确的环境模型和更通用的代码


<details>
  <summary>Details</summary>
Motivation: 传统世界模型通常是神经网络表示，导致学习的环境动态难以迁移和解释，需要一种更精确且可解释的表示方法

Method: 有限自动机提取(FAE)方法，从游戏视频中学习神经符号世界模型，用新颖的领域特定语言Retro Coder DSL以程序形式表示

Result: 相比之前的世界模型方法，FAE学习到更精确的环境模型；相比之前的DSL方法，生成更通用的代码

Conclusion: FAE方法能够有效解决世界模型的可迁移性和可解释性问题，为环境动态学习提供了更好的神经符号表示方案

Abstract: World models are defined as a compressed spatial and temporal learned
representation of an environment. The learned representation is typically a
neural network, making transfer of the learned environment dynamics and
explainability a challenge. In this paper, we propose an approach, Finite
Automata Extraction (FAE), that learns a neuro-symbolic world model from
gameplay video represented as programs in a novel domain-specific language
(DSL): Retro Coder. Compared to prior world model approaches, FAE learns a more
precise model of the environment and more general code than prior DSL-based
approaches.

</details>


### [13] [Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework](https://arxiv.org/abs/2508.12487)
*Lida Shahbandari,Hossein Mohseni*

Main category: cs.AI

TL;DR: 基于鲸鱼优化算法的分数阶模糊PID控制器，在八种患者模型中显著提升了验光指数控制的调节速度和精度


<details>
  <summary>Details</summary>
Motivation: 为了实现更准确和个性化的麻醇自动掠供，需要一种能够适应不同患者生理特征的智能控制算法

Method: 结合分数阶微分动力学和模糊逻辑，使用鲸鱼优化算法自动调整控制器参数、分数阶次数和模糊成员函数

Result: 在八种患者模型上试验，比标准FOPID控制器调节时间缩短22%（从3.2分钟降至2.5分钟），稳态误差降低58%（从1.2降至0.5）

Conclusion: FOFPID控制器提供了一种可扩展的人工智能驱动方案，具有优秀的强声性和准确性，有望改善临床实践和患者结果

Abstract: This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that
uses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index
(BIS), keeping it within the ideal range of forty to sixty. The FOFPID
controller combines fuzzy logic for adapting to changes and fractional order
dynamics for fine tuning. This allows it to adjust its control gains to handle
a person's unique physiology. The WOA helps fine tune the controller's
parameters, including the fractional orders and the fuzzy membership functions,
which boosts its performance. Tested on models of eight different patient
profiles, the FOFPID controller performed better than a standard Fractional
Order PID (FOPID) controller. It achieved faster settling times, at two and a
half minutes versus three point two minutes, and had a lower steady state
error, at zero point five versus one point two. These outcomes show the
FOFPID's excellent strength and accuracy. It offers a scalable, artificial
intelligence driven solution for automated anesthesia delivery that could
enhance clinical practice and improve patient results.

</details>


### [14] [EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models](https://arxiv.org/abs/2508.11850)
*Milad Yazdani,Mahdi Mostajabdaveh,Samin Aref,Zirui Zhou*

Main category: cs.AI

TL;DR: EvoCut是一个自动化生成整数规划加速割的框架，结合大语言模型和进化搜索，无需人工专家输入即可生成有效的不等式，显著提升求解器性能


<details>
  <summary>Details</summary>
Motivation: 整数规划是组合优化的核心但具有NP难特性，传统方法依赖专家手动设计加速割，这个过程需要深厚专业知识且难以自动化

Method: 结合大语言模型和进化搜索：1）LLM初始化多样化候选割；2）评估割的效用（保持最优解和切割分数解能力）；3）通过进化交叉和变异迭代优化种群

Result: 相比标准方法，EvoCut在固定时间内将最优性间隙降低17-57%，获得相同解的速度提升4倍，在相同时间内获得更高质量的解

Conclusion: EvoCut成功实现了整数规划加速割的自动化生成，无需人工专家输入即可产生泛化性强的有效割，显著提升求解器性能

Abstract: Integer programming lies at the heart of crucial combinatorial optimization
tasks but remains challenging due to its NP-hard nature. An effective approach
for practically solving integer programs is the manual design of acceleration
cuts, i.e. inequalities that improve solver performance. However, this creative
process demands deep expertise and is yet to be automated. Our proposed
framework, EvoCut, automates the generation of acceleration cuts by combining
large language models (LLMs) with an evolutionary search. EvoCut (i)
initializes a diverse population of candidate cuts via an LLM-based initializer
agent; (ii) for each cut empirically evaluates both preservation of the optimal
solution and its ability to cut off fractional solutions across a verification
set; and (iii) iteratively refines the population through evolutionary
crossover and mutation agents. We quantify each cut's utility by its relative
reduction in the solver's optimality gap. Our comparisons against standard
integer programming practice show that EvoCut reduces optimality gap by 17-57%
within a fixed time. It obtains the same solutions up to 4 times as fast, and
obtains higher-quality solutions within the same time limit. Requiring no human
expert input, EvoCut reliably generates, improves, and empirically verifies
cuts that generalize to unseen instances. The code is available at
https://github.com/milad1378yz/EvoCut.

</details>


### [15] [[Social] Allostasis: Or, How I Learned To Stop Worrying and Love The Noise](https://arxiv.org/abs/2508.12791)
*Imran Khan*

Main category: cs.AI

TL;DR: 该论文提出了一个计算模型来模拟异稳态和社会异稳态调节，通过生物启发的信号转导器（类似激素）来编码环境和社会信息，使系统能够主动利用扰动进行适应性重构，相比传统稳态调节具有更好的生存能力。


<details>
  <summary>Details</summary>
Motivation: 传统稳态概念强调系统通过抵抗环境和社会扰动来维持稳定，而异稳态理论则认为系统可以主动利用这些扰动来预测环境需求并重新配置调节参数。本文旨在从计算角度验证这一理论。

Method: 采用基于代理的模型，在动态环境中测试小型社会中的"animats"。使用生物生理学启发的信号转导器（类似皮质醇和催产素等激素）来编码环境和社会互动信息，实现动态重新配置。

Result: 结果显示，异稳态和社会异稳态调节使代理能够利用环境和社会"噪声"进行适应性重构，相比纯粹反应性稳态代理表现出更好的生存能力。

Conclusion: 这项工作为社会异稳态原则提供了新颖的计算视角，并为设计更鲁棒、生物启发的自适应系统提供了潜力。

Abstract: The notion of homeostasis typically conceptualises biological and artificial
systems as maintaining stability by resisting deviations caused by
environmental and social perturbations. In contrast, (social) allostasis
proposes that these systems can proactively leverage these very perturbations
to reconfigure their regulatory parameters in anticipation of environmental
demands, aligning with von Foerster's ``order through noise'' principle. This
paper formulates a computational model of allostatic and social allostatic
regulation that employs biophysiologically inspired signal transducers,
analogous to hormones like cortisol and oxytocin, to encode information from
both the environment and social interactions, which mediate this dynamic
reconfiguration. The models are tested in a small society of ``animats'' across
several dynamic environments, using an agent-based model. The results show that
allostatic and social allostatic regulation enable agents to leverage
environmental and social ``noise'' for adaptive reconfiguration, leading to
improved viability compared to purely reactive homeostatic agents. This work
offers a novel computational perspective on the principles of social allostasis
and their potential for designing more robust, bio-inspired, adaptive systems

</details>


### [16] [LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework](https://arxiv.org/abs/2508.11860)
*Frazier N. Baker,Daniel Adu-Ampratwum,Reza Averly,Botao Yu,Huan Sun,Xia Ning*

Main category: cs.AI

TL;DR: LARC是首个基于LLM的约束条件下逆合成规划代理框架，通过Agent-as-a-Judge机制将约束评估直接整合到逆合成规划过程中，使用工具驱动的推理来指导和约束路线生成。


<details>
  <summary>Details</summary>
Motivation: 约束条件下的逆合成规划是化学中重要但具有挑战性的过程，需要从商业可得的起始材料到目标分子找到合成路线，同时满足实际约束。现有方法难以有效处理这些约束条件。

Method: LARC框架采用基于LLM的代理评估器，通过专门的工具来支撑LLM的理性决策。使用Agent-as-a-Judge机制进行代理约束评估，将基于工具的推理反馈整合到逆合成规划过程中。

Result: 在精心策划的48个约束逆合成规划任务上，LARC取得了72.9%的成功率，大幅超越LLM基线方法，在显著更少的时间内接近人类专家水平。

Conclusion: LARC框架具有可扩展性，是朝着为人类专家开发有效代理工具或合作科学家的第一步，可用于约束条件下的逆合成规划。

Abstract: Large language model (LLM) agent evaluators leverage specialized tools to
ground the rational decision-making of LLMs, making them well-suited to aid in
scientific discoveries, such as constrained retrosynthesis planning.
Constrained retrosynthesis planning is an essential, yet challenging, process
within chemistry for identifying synthetic routes from commercially available
starting materials to desired target molecules, subject to practical
constraints. Here, we present LARC, the first LLM-based Agentic framework for
Retrosynthesis planning under Constraints. LARC incorporates agentic constraint
evaluation, through an Agent-as-a-Judge, directly into the retrosynthesis
planning process, using agentic feedback grounded in tool-based reasoning to
guide and constrain route generation. We rigorously evaluate LARC on a
carefully curated set of 48 constrained retrosynthesis planning tasks across 3
constraint types. LARC achieves a 72.9% success rate on these tasks, vastly
outperforming LLM baselines and approaching human expert-level success in
substantially less time. The LARC framework is extensible, and serves as a
first step towards an effective agentic tool or a co-scientist to human experts
for constrained retrosynthesis.

</details>


### [17] [QuarkMed Medical Foundation Model Technical Report](https://arxiv.org/abs/2508.11894)
*Ao Li,Bin Yan,Bingfeng Cai,Chenxi Li,Cunzhong Zhao,Fugen Yao,Gaoqiang Liu,Guanjun Jiang,Jian Xu,Liang Dong,Liansheng Sun,Rongshen Zhang,Xiaolei Gui,Xin Liu,Xin Shang,Yao Wu,Yu Cao,Zhenxin Ma,Zhuang Jia*

Main category: cs.AI

TL;DR: QuarkMed开发了一个高性能医疗基础模型，通过医学数据处理、检索增强生成和大规模可验证强化学习，在中国执业医师考试中达到70%准确率，服务数百万用户。


<details>
  <summary>Details</summary>
Motivation: 医疗任务需要高度专业化的知识、专业准确性和定制能力，现有大语言模型在医疗应用中需要更可靠的基础模型支持。

Method: 利用精选医学数据处理、医学内容检索增强生成(RAG)和大规模可验证强化学习管道来开发医疗基础模型。

Result: 模型在中国医学执业资格考试中达到70%的准确率，在多样化医学基准测试中展现出强大的泛化能力。

Conclusion: QuarkMed提供了一个强大而通用的个人医疗AI解决方案，已在ai.quark.cn服务超过百万用户。

Abstract: Recent advancements in large language models have significantly accelerated
their adoption in healthcare applications, including AI-powered medical
consultations, diagnostic report assistance, and medical search tools. However,
medical tasks often demand highly specialized knowledge, professional accuracy,
and customization capabilities, necessitating a robust and reliable foundation
model. QuarkMed addresses these needs by leveraging curated medical data
processing, medical-content Retrieval-Augmented Generation (RAG), and a
large-scale, verifiable reinforcement learning pipeline to develop a
high-performance medical foundation model. The model achieved 70% accuracy on
the Chinese Medical Licensing Examination, demonstrating strong generalization
across diverse medical benchmarks. QuarkMed offers a powerful yet versatile
personal medical AI solution, already serving over millions of users at
ai.quark.cn.

</details>


### [18] [CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMs](https://arxiv.org/abs/2508.11944)
*Hongtao Liu,Zhicheng Du,Zihe Wang,Weiran Shen*

Main category: cs.AI

TL;DR: 提出了CHBench评估框架，基于认知层次理论评估大语言模型的策略推理能力，发现不同机制对推理性能有显著影响


<details>
  <summary>Details</summary>
Motivation: 现有基于效用性能指标的评估方法不够鲁棒，受对手行为和游戏结构变化影响大，需要更稳健的评估框架

Method: 采用三阶段系统框架，利用认知层次模型理论，在15个精选的正规形式游戏中分析6个先进LLMs的行为数据

Result: LLMs在不同对手间展现一致的策略推理水平，聊天机制显著降低策略推理性能，而记忆机制则能提升推理能力

Conclusion: CHBench是一个有前景的LLM能力评估工具，具有重要的研究和应用价值

Abstract: Game-playing ability serves as an indicator for evaluating the strategic
reasoning capability of large language models (LLMs). While most existing
studies rely on utility performance metrics, which are not robust enough due to
variations in opponent behavior and game structure. To address this limitation,
we propose \textbf{Cognitive Hierarchy Benchmark (CHBench)}, a novel evaluation
framework inspired by the cognitive hierarchy models from behavioral economics.
We hypothesize that agents have bounded rationality -- different agents behave
at varying reasoning depths/levels. We evaluate LLMs' strategic reasoning
through a three-phase systematic framework, utilizing behavioral data from six
state-of-the-art LLMs across fifteen carefully selected normal-form games.
Experiments show that LLMs exhibit consistent strategic reasoning levels across
diverse opponents, confirming the framework's robustness and generalization
capability. We also analyze the effects of two key mechanisms (Chat Mechanism
and Memory Mechanism) on strategic reasoning performance. Results indicate that
the Chat Mechanism significantly degrades strategic reasoning, whereas the
Memory Mechanism enhances it. These insights position CHBench as a promising
tool for evaluating LLM capabilities, with significant potential for future
research and practical applications.

</details>


### [19] [Data Mixing Optimization for Supervised Fine-Tuning of Large Language Models](https://arxiv.org/abs/2508.11953)
*Yuan Li,Zhengzhong Liu,Eric Xing*

Main category: cs.AI

TL;DR: 通过建模有效数据转移和利用缩放定律，提出了一种优化监督微调数据混合的方法，能够最小化验证损失并提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 监督微调数据混合的优化对发展通用大语言模型至关重要，但这个领域目前研究不够深入。

Method: 将数据混合形式化为优化问题，通过建模有效数据转移和缩放定律来参数化损失函数，并在小规模数据混合上进行实验拟合参数。

Result: 算法在所有领域都取得优异的整体和个别性能，优化权重训练的模型性能与网格搜索确定的最优权重相当，每个领域损失仅比网格搜索的最优域损失平均高出0.66%。

Conclusion: 该方法不仅能够改善验证损失和下游任务性能，还可以推广用于领域特定模型的数据选择，为监督微调提供了新的见解。

Abstract: Optimizing data mixtures for supervised fine-tuning (SFT) of large language
models (LLMs) is critical for developing general-purpose models, yet this area
remains underexplored. In this paper, we frame data mixing as an optimization
problem and introduce a novel method designed to minimize validation loss. Our
approach parametrizes the loss by modeling effective data transferred and
leveraging scaling laws for fine-tuning. By experimenting with various
small-scale data mixtures, we fit these parameters and derive the optimal
weights. We provide both mathematical proofs and empirical results
demonstrating that our algorithm achieves excellent overall and individual
performance across all domains. Through controlled experiments, we show that
models trained with our optimized weights perform on par with those using
optimal weights determined via grid search, with per-domain loss only 0.66%
higher than the best domain loss from grid search on average. Additionally, we
show that reweighting popular SFT datasets using our method improves both
validation loss and downstream performance. Finally, we discuss how our method
can generalize to guide data selection for domain-specific models and provide
insights into SFT.

</details>


### [20] [UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting](https://arxiv.org/abs/2508.11954)
*Sehyuk Park,Soyeon Caren Han,Eduard Hovy*

Main category: cs.AI

TL;DR: UniCast是一个参数高效的多模态时间序列预测框架，通过结合视觉和文本模态来增强传统时间序列基础模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型主要在单模态设置下运行，忽略了现实世界中时间序列数据常伴随的丰富多模态上下文（如视觉和文本信号）。

Method: 通过软提示调优将预训练的视觉和文本编码器的模态特定嵌入与冻结的时间序列基础模型集成，实现高效适应和跨模态交互。

Result: 在多个时间序列预测基准测试中，UniCast始终显著优于所有现有时间序列基础模型基线。

Conclusion: 多模态上下文在推进下一代通用时间序列预测器发展中起着关键作用。

Abstract: Time series forecasting is a foundational task across domains, such as
finance, healthcare, and environmental monitoring. While recent advances in
Time Series Foundation Models (TSFMs) have demonstrated strong generalisation
through large-scale pretraining, existing models operate predominantly in a
unimodal setting, ignoring the rich multimodal context, such as visual and
textual signals, that often accompanies time series data in real-world
scenarios. This paper introduces a novel parameter-efficient multimodal
framework, UniCast, that extends TSFMs to jointly leverage time series, vision,
and text modalities for enhanced forecasting performance. Our method integrates
modality-specific embeddings from pretrained Vision and Text Encoders with a
frozen TSFM via soft prompt tuning, enabling efficient adaptation with minimal
parameter updates. This design not only preserves the generalisation strength
of the foundation model but also enables effective cross-modal interaction.
Extensive experiments across diverse time-series forecasting benchmarks
demonstrate that UniCast consistently and significantly outperforms all
existing TSFM baselines. The findings highlight the critical role of multimodal
context in advancing the next generation of general-purpose time series
forecasters.

</details>


### [21] [Rigorous Feature Importance Scores based on Shapley Value and Banzhaf Index](https://arxiv.org/abs/2508.11959)
*Xuanxiang Huang,Olivier Létoffé,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 这篇论文提出了两种新的特征重要性评分方法，利用Shapley值和Banzhaf指数来量化特征在排除对抗案例方面的效果，而不仅仅考虑弱派生解释集。


<details>
  <summary>Details</summary>
Motivation: 现有的逻辑基础解释方法主要基于弱派生解释(WAXp)赋予特征重要性，忽视了非WAXp集的贡献。非WAXp集也包含重要信息，特别是在正式解释(XPs)和对抗案例(AExs)之间的关系方面。

Method: 利用Shapley值和Banzhaf指数设计了两种新的特征重要性评分方法。这些方法在计算特征贡献时考虑了非WAXp集，能够量化每个特征在排除对抗案例方面的效果。

Result: 论文提出了新的特征重要性评分方法，识别了这些方法的性质特征，并研究了它们的计算复杂度。

Conclusion: 通过考虑非WAXp集的贡献，新的特征重要性评分方法能够更全面地量化特征在防范对抗案例方面的效果，为可解释人工智能领域提供了更严谨的特征归因方法。

Abstract: Feature attribution methods based on game theory are ubiquitous in the field
of eXplainable Artificial Intelligence (XAI). Recent works proposed rigorous
feature attribution using logic-based explanations, specifically targeting
high-stakes uses of machine learning (ML) models. Typically, such works exploit
weak abductive explanation (WAXp) as the characteristic function to assign
importance to features. However, one possible downside is that the contribution
of non-WAXp sets is neglected. In fact, non-WAXp sets can also convey important
information, because of the relationship between formal explanations (XPs) and
adversarial examples (AExs). Accordingly, this paper leverages Shapley value
and Banzhaf index to devise two novel feature importance scores. We take into
account non-WAXp sets when computing feature contribution, and the novel scores
quantify how effective each feature is at excluding AExs. Furthermore, the
paper identifies properties and studies the computational complexity of the
proposed scores.

</details>


### [22] [Chart-CoCa: Self-Improving Chart Understanding of Vision LMs via Code-Driven Synthesis and Candidate-Conditioned Answering](https://arxiv.org/abs/2508.11975)
*Gongyao Jiang,Qiong Luo*

Main category: cs.AI

TL;DR: 通过代码生成和执行的图表合成流程产生对齐的图表-问题-答案三元组，结合候选条件化答题过程，在无人工标注或外部模型的情况下实现了VLM的自我改进


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型(VLM)在图表理解任务中遇到困难，特别是准确的图表描述和复杂推理。合成数据生成是一种有前景的解决方案，但常面临噪声标签的挑战

Method: 1）设计图表合成流程，通过代码生成和执行生成对齐的图表-问题-答案三元组
2）设计候选条件化答题过程：VLM首先为每个查询生成多个响应，然后通过上下文化这些候选条件来合成最终答案

Result: 实验结果显示了显著收益，在完全自我改进范式下，比初始VLM的准确率提高了最15.50个百分点

Conclusion: 该方法在不依赖人工标注数据或外部模型的情况下，通过合成数据生成和候选条件化答题，成功实现了VLM在图表理解任务上的显著自我改进

Abstract: Vision Language Models (VLMs) often struggle with chart understanding tasks,
particularly in accurate chart description and complex reasoning. Synthetic
data generation is a promising solution, while usually facing the challenge of
noise labels. To address this challenge, we first introduce a chart synthesis
pipeline that generates aligned chart-question-answer triplets through code
generation and execution, ensuring the reliability of synthetic data without
human intervention. Furthermore, inspired by test-time scaling that increases
inference budget and thereby improves performance, we design a
candidate-conditioned answering process. The VLM first generates multiple
responses per query, and then synthesizes the final answer by contextualizing
these candidates. Experiments demonstrate significant improvements, with up to
15.50 points accuracy gain over the initial VLM, in a fully self-improving
paradigm without either human-labeled data or external models.

</details>


### [23] [FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction](https://arxiv.org/abs/2508.11987)
*Zhiyuan Zeng,Jiashuo Liu,Siyuan Chen,Tianci He,Yali Liao,Jinpeng Wang,Zaiyuan Wang,Yang Yang,Lingyue Yin,Mingren Yin,Zhenwei Zhu,Tianle Cai,Zehui Chen,Jiecao Chen,Yantao Du,Xiang Gao,Jiacheng Guo,Liang Hu,Jianpeng Jiao,Xiangsheng Li,Jingkai Liu,Shuang Ni,Zhoufutu Wen,Ge Zhang,Kaiyuan Zhang,Xin Zhou,Jose Blanchet,Xipeng Qiu,Mengdi Wang,Wenhao Huang*

Main category: cs.AI

TL;DR: 提出了一个动态的未来预测评测基准FutureX，解决了现有测试集在实时更新和数据污染方面的挑战，并对25个LLM/代理模型进行了全面评测。


<details>
  <summary>Details</summary>
Motivation: 未来预测是LLM代理的复杂任务，需要高级分析思维和不确定性处理能力。目前缺乏大规模的动态评测基准，主要因为实时更新和数据污染的挑战。

Method: 开发了FutureX动态评测基准，支持实时每日更新，通过自动化流程收集问题和答案来消除数据污染。评估了25个LLM/代理模型，包括具有推理、搜索能力和外部工具集成的模型。

Result: 完成了对代理在动态环境中适应性推理和性能的全面评估，并提供了深入的失败模式分析，包括对假网页的弱点和时间有效性问题。

Conclusion: FutureX成为了最大、最多样化的实时未来预测评测基准，为发展能够达到人类专业分析师水平的LLM代理提供了动态、无污染的评价标准。

Abstract: Future prediction is a complex task for LLM agents, requiring a high level of
analytical thinking, information gathering, contextual understanding, and
decision-making under uncertainty. Agents must not only gather and interpret
vast amounts of dynamic information but also integrate diverse data sources,
weigh uncertainties, and adapt predictions based on emerging trends, just as
human experts do in fields like politics, economics, and finance. Despite its
importance, no large-scale benchmark exists for evaluating agents on future
prediction, largely due to challenges in handling real-time updates and
retrieving timely, accurate answers. To address this, we introduce
$\textbf{FutureX}$, a dynamic and live evaluation benchmark specifically
designed for LLM agents performing future prediction tasks. FutureX is the
largest and most diverse live benchmark for future prediction, supporting
real-time daily updates and eliminating data contamination through an automated
pipeline for question gathering and answer collection. We evaluate 25 LLM/agent
models, including those with reasoning, search capabilities, and integration of
external tools such as the open-source Deep Research Agent and closed-source
Deep Research models. This comprehensive evaluation assesses agents' adaptive
reasoning and performance in dynamic environments. Additionally, we provide
in-depth analyses of agents' failure modes and performance pitfalls in
future-oriented tasks, including the vulnerability to fake web pages and the
temporal validity. Our goal is to establish a dynamic, contamination-free
evaluation standard that drives the development of LLM agents capable of
performing at the level of professional human analysts in complex reasoning and
predictive thinking.

</details>


### [24] [Modeling Relational Logic Circuits for And-Inverter Graph Convolutional Network](https://arxiv.org/abs/2508.11991)
*Weihao Sun*

Main category: cs.AI

TL;DR: AIGer是一个用于And-Inverter Graphs (AIGs)特征学习的创新模型，通过节点逻辑特征初始化和异构图卷积网络，有效联合建模功能与结构特征，在信号概率预测和真值表距离预测任务中显著优于现有最佳模型。


<details>
  <summary>Details</summary>
Motivation: 由于真实世界AIGs结构复杂、节点规模大，现有方法难以准确建模，缺乏联合建模功能与结构特征的能力，以及动态信息传播能力不足。

Method: AIGer包含两个组件：1)节点逻辑特征初始化嵌入组件，将逻辑节点投影到独立语义空间；2)AIGs特征学习网络组件，采用异构图卷积网络，设计动态关系权重矩阵和差异化信息聚合方法。

Result: 在信号概率预测任务中，MAE和MSE分别提升18.95%和44.44%；在真值表距离预测任务中，MAE和MSE分别提升33.57%和14.79%。

Conclusion: AIGer通过创新的特征学习和网络设计，显著提升了AIGs建模能力，在EDA领域的两个关键任务中都取得了显著性能提升。

Abstract: The automation of logic circuit design enhances chip performance, energy
efficiency, and reliability, and is widely applied in the field of Electronic
Design Automation (EDA).And-Inverter Graphs (AIGs) efficiently represent,
optimize, and verify the functional characteristics of digital circuits,
enhancing the efficiency of EDA development.Due to the complex structure and
large scale of nodes in real-world AIGs, accurate modeling is challenging,
leading to existing work lacking the ability to jointly model functional and
structural characteristics, as well as insufficient dynamic information
propagation capability.To address the aforementioned challenges, we propose
AIGer.Specifically, AIGer consists of two components: 1) Node logic feature
initialization embedding component and 2) AIGs feature learning network
component.The node logic feature initialization embedding component projects
logic nodes, such as AND and NOT, into independent semantic spaces, to enable
effective node embedding for subsequent processing.Building upon this, the AIGs
feature learning network component employs a heterogeneous graph convolutional
network, designing dynamic relationship weight matrices and differentiated
information aggregation approaches to better represent the original structure
and information of AIGs.The combination of these two components enhances
AIGer's ability to jointly model functional and structural characteristics and
improves its message passing capability. Experimental results indicate that
AIGer outperforms the current best models in the Signal Probability Prediction
(SSP) task, improving MAE and MSE by 18.95\% and 44.44\%, respectively. In the
Truth Table Distance Prediction (TTDP) task, AIGer achieves improvements of
33.57\% and 14.79\% in MAE and MSE, respectively, compared to the
best-performing models.

</details>


### [25] [AgentCDM: Enhancing Multi-Agent Collaborative Decision-Making via ACH-Inspired Structured Reasoning](https://arxiv.org/abs/2508.11995)
*Xuyang Zhao,Shiwan Zhao,Hualong Yu,Liting Zhang,Qicheng Li*

Main category: cs.AI

TL;DR: AgentCDM是一个基于认知科学竞争假设分析(ACH)的结构化框架，用于提升LLM多智能体系统中的协作决策质量，通过两阶段训练克服认知偏见并实现主动假设评估。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统要么依赖单一智能体的"独裁"策略（易受认知偏见影响），要么使用"投票"方法（无法充分利用集体智慧），协作决策过程研究不足。

Method: 借鉴认知科学中的竞争假设分析(ACH)，提出结构化推理范式，包含两阶段训练：第一阶段使用显式ACH脚手架引导结构化推理，第二阶段逐步移除脚手架以促进自主泛化。

Result: 在多个基准数据集上的实验表明，AgentCDM实现了最先进的性能，并展现出强大的泛化能力。

Conclusion: AgentCDM有效提升了多智能体系统中协作决策的质量和鲁棒性，验证了结构化推理范式在缓解认知偏见和促进主动决策方面的有效性。

Abstract: Multi-agent systems (MAS) powered by large language models (LLMs) hold
significant promise for solving complex decision-making tasks. However, the
core process of collaborative decision-making (CDM) within these systems
remains underexplored. Existing approaches often rely on either ``dictatorial"
strategies that are vulnerable to the cognitive biases of a single agent, or
``voting-based" methods that fail to fully harness collective intelligence. To
address these limitations, we propose \textbf{AgentCDM}, a structured framework
for enhancing collaborative decision-making in LLM-based multi-agent systems.
Drawing inspiration from the Analysis of Competing Hypotheses (ACH) in
cognitive science, AgentCDM introduces a structured reasoning paradigm that
systematically mitigates cognitive biases and shifts decision-making from
passive answer selection to active hypothesis evaluation and construction. To
internalize this reasoning process, we develop a two-stage training paradigm:
the first stage uses explicit ACH-inspired scaffolding to guide the model
through structured reasoning, while the second stage progressively removes this
scaffolding to encourage autonomous generalization. Experiments on multiple
benchmark datasets demonstrate that AgentCDM achieves state-of-the-art
performance and exhibits strong generalization, validating its effectiveness in
improving the quality and robustness of collaborative decisions in MAS.

</details>


### [26] [AI Models for Depressive Disorder Detection and Diagnosis: A Review](https://arxiv.org/abs/2508.12022)
*Dorsa Macky Aleagha,Payam Zohari,Mostafa Haghir Chehreghani*

Main category: cs.AI

TL;DR: 这是一份关于人工智能在重性郁郇症诊断中应用的综述性论文，系统分析了55项关键研究，提出了新的分类体系，并识别了主要技术趋势。


<details>
  <summary>Details</summary>
Motivation: 重性郁郇症是全球主要残疾原因之一，但目前诊断依靠主观临床评估。人工智能有望开发客观、可扩展且及时的诊断工具。

Method: 通过系统性回项55项关键研究，提出了一个新的层次分类体系，按临床任务（诊断vs预测）、数据模态（文本、语音、神经影像、多模态）和计算模型类型进行结构化。

Result: 分析识别了三大主要趋势：图神经网络在大脑连接性建模中占主导地位，大语言模型在语言和会话数据中兴起，以及多模态融合、可解释性和算法公平性方面的新兴关注点。

Conclusion: 该综述通过综合当前进展并突出开放性挑战，为计算精神病学领域的未来创新提供了全面的路线图。

Abstract: Major Depressive Disorder is one of the leading causes of disability
worldwide, yet its diagnosis still depends largely on subjective clinical
assessments. Integrating Artificial Intelligence (AI) holds promise for
developing objective, scalable, and timely diagnostic tools. In this paper, we
present a comprehensive survey of state-of-the-art AI methods for depression
detection and diagnosis, based on a systematic review of 55 key studies. We
introduce a novel hierarchical taxonomy that structures the field by primary
clinical task (diagnosis vs. prediction), data modality (text, speech,
neuroimaging, multimodal), and computational model class (e.g., graph neural
networks, large language models, hybrid approaches). Our in-depth analysis
reveals three major trends: the predominance of graph neural networks for
modeling brain connectivity, the rise of large language models for linguistic
and conversational data, and an emerging focus on multimodal fusion,
explainability, and algorithmic fairness. Alongside methodological insights, we
provide an overview of prominent public datasets and standard evaluation
metrics as a practical guide for researchers. By synthesizing current advances
and highlighting open challenges, this survey offers a comprehensive roadmap
for future innovation in computational psychiatry.

</details>


### [27] [Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems](https://arxiv.org/abs/2508.12026)
*Szymon Pawlonka,Mikołaj Małkiński,Jacek Mańdziuk*

Main category: cs.AI

TL;DR: 本文介绍了Bongard-RWR+数据集，包含5400个实例，使用VLM生成真实世界图像来代表原始Bongard问题的抽象概念，评估发现VLM在细粒度概念识别方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 现有的Bongard问题数据集要么使用合成图像缺乏真实世界复杂性，要么使用真实图像但概念过于简单，且Bongard-RWR数据集规模太小（仅60个实例），限制了评估的鲁棒性。

Method: 基于Bongard-RWR，使用Pixtral-12B描述手动策划的图像并生成与底层概念对齐的新描述，使用Flux.1-dev从这些描述合成图像，并手动验证生成图像是否忠实反映预期概念。

Result: 评估了最先进的VLM在不同Bongard问题表述上的表现，包括二元和多类分类以及文本答案生成。发现VLM能够识别粗粒度视觉概念，但在辨别细粒度概念方面持续存在困难。

Conclusion: VLM在抽象视觉推理方面存在局限性，特别是在细粒度概念识别上表现不佳，这突显了它们在推理能力方面的限制。

Abstract: Bongard Problems (BPs) provide a challenging testbed for abstract visual
reasoning (AVR), requiring models to identify visual concepts fromjust a few
examples and describe them in natural language. Early BP benchmarks featured
synthetic black-and-white drawings, which might not fully capture the
complexity of real-world scenes. Subsequent BP datasets employed real-world
images, albeit the represented concepts are identifiable from high-level image
features, reducing the task complexity. Differently, the recently released
Bongard-RWR dataset aimed at representing abstract concepts formulated in the
original BPs using fine-grained real-world images. Its manual construction,
however, limited the dataset size to just $60$ instances, constraining
evaluation robustness. In this work, we introduce Bongard-RWR+, a BP dataset
composed of $5\,400$ instances that represent original BP abstract concepts
using real-world-like images generated via a vision language model (VLM)
pipeline. Building on Bongard-RWR, we employ Pixtral-12B to describe manually
curated images and generate new descriptions aligned with the underlying
concepts, use Flux.1-dev to synthesize images from these descriptions, and
manually verify that the generated images faithfully reflect the intended
concepts. We evaluate state-of-the-art VLMs across diverse BP formulations,
including binary and multiclass classification, as well as textual answer
generation. Our findings reveal that while VLMs can recognize coarse-grained
visual concepts, they consistently struggle with discerning fine-grained
concepts, highlighting limitations in their reasoning capabilities.

</details>


### [28] [Active inference for action-unaware agents](https://arxiv.org/abs/2508.12027)
*Filippo Torresan,Keisuke Suzuki,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 活性推理框架中动作意识与无意识代理人的性能对比研究，证明无意识代理人虽处于不利地位仍能达到类似性能


<details>
  <summary>Details</summary>
Motivation: 研究活性推理框架中不同行动规划策略的影响，特别是动作意识与无意识代理人在实际任务中的表现差异

Method: 在两个导航任务中比较动作意识与无意识代理人的性能，分析不同行动规划策略的效果

Result: 无意识代理人虽然处于严重不利地位，但能够达到与动作意识代理人相似的性能水平

Conclusion: 这一研究为活性推理框架中不同行动规划策略提供了实验支撑，显示了无意识代理人的强大适应能力

Abstract: Active inference is a formal approach to study cognition based on the notion
that adaptive agents can be seen as engaging in a process of approximate
Bayesian inference, via the minimisation of variational and expected free
energies. Minimising the former provides an account of perceptual processes and
learning as evidence accumulation, while minimising the latter describes how
agents select their actions over time. In this way, adaptive agents are able to
maximise the likelihood of preferred observations or states, given a generative
model of the environment. In the literature, however, different strategies have
been proposed to describe how agents can plan their future actions. While they
all share the notion that some kind of expected free energy offers an
appropriate way to score policies, sequences of actions, in terms of their
desirability, there are different ways to consider the contribution of past
motor experience to the agent's future behaviour. In some approaches, agents
are assumed to know their own actions, and use such knowledge to better plan
for the future. In other approaches, agents are unaware of their actions, and
must infer their motor behaviour from recent observations in order to plan for
the future. This difference reflects a standard point of departure in two
leading frameworks in motor control based on the presence, or not, of an
efference copy signal representing knowledge about an agent's own actions. In
this work we compare the performances of action-aware and action-unaware agents
in two navigations tasks, showing how action-unaware agents can achieve
performances comparable to action-aware ones while at a severe disadvantage.

</details>


### [29] [MAPF-World: Action World Model for Multi-Agent Path Finding](https://arxiv.org/abs/2508.12087)
*Zhanjiang Yang,Meng Li,Yang Shen,Yueming Li,Lijun Sun*

Main category: cs.AI

TL;DR: MAPF-World是一个创新的自回归动作世界模型，用于多智能体路径规划，通过显式建模环境时空动态和智能体间依赖关系，实现了超越局部观察的远见决策。


<details>
  <summary>Details</summary>
Motivation: 现有分散式可学习求解器在复杂长期规划场景中表现受限，主要因为缺乏对环境时间动态和智能体间依赖关系的充分建模。

Method: 提出自回归动作世界模型，统一情境理解和动作生成，通过预测未来状态和动作来增强情境感知，并引入基于真实场景的自动地图生成器。

Result: MAPF-World在零样本泛化到分布外案例方面优于最先进的可学习求解器，模型大小减少96.5%，数据需求降低92%。

Conclusion: 该模型通过显式建模时空动态和智能体依赖关系，显著提升了复杂多智能体环境中的决策质量和泛化能力。

Abstract: Multi-agent path finding (MAPF) is the problem of planning conflict-free
paths from the designated start locations to goal positions for multiple
agents. It underlies a variety of real-world tasks, including multi-robot
coordination, robot-assisted logistics, and social navigation. Recent
decentralized learnable solvers have shown great promise for large-scale MAPF,
especially when leveraging foundation models and large datasets. However, these
agents are reactive policy models and exhibit limited modeling of environmental
temporal dynamics and inter-agent dependencies, resulting in performance
degradation in complex, long-term planning scenarios. To address these
limitations, we propose MAPF-World, an autoregressive action world model for
MAPF that unifies situation understanding and action generation, guiding
decisions beyond immediate local observations. It improves situational
awareness by explicitly modeling environmental dynamics, including spatial
features and temporal dependencies, through future state and actions
prediction. By incorporating these predicted futures, MAPF-World enables more
informed, coordinated, and far-sighted decision-making, especially in complex
multi-agent settings. Furthermore, we augment MAPF benchmarks by introducing an
automatic map generator grounded in real-world scenarios, capturing practical
map layouts for training and evaluating MAPF solvers. Extensive experiments
demonstrate that MAPF-World outperforms state-of-the-art learnable solvers,
showcasing superior zero-shot generalization to out-of-distribution cases.
Notably, MAPF-World is trained with a 96.5% smaller model size and 92% reduced
data.

</details>


### [30] [Overcoming Knowledge Discrepancies: Structuring Reasoning Threads through Knowledge Balancing in Interactive Scenarios](https://arxiv.org/abs/2508.12100)
*Daniel Burkhardt,Xiangwei Cheng*

Main category: cs.AI

TL;DR: 提出ReT-Eval框架，通过矢量矩阵和图神经网络提取领域知识，使用奖励指导策略评估和修剪推理线索，提升了交互式问题解决中的推理效果


<details>
  <summary>Details</summary>
Motivation: 当前推理模型缺乏显式语义层次结构、用户-领域知识对齐和理论机制来修剪推理线索，导致输出长缠而通用，无法有效指导用户进行目标导向推理

Method: 原型启发的两阶段ReT-Eval框架：第一阶段使用图神经网络从稀疏领域知识图中提取语义相关知识结构，并使用大语言模型内部知识丰富以解决知识差异；第二阶段使用奖励指导策略评估和修剪推理线索，以维持语义一致性

Result: 实验和专家评估显示，ReT-Eval提升了用户理解能力，并在推理性能上超过了现有的最先进推理模型

Conclusion: ReT-Eval框架通过结构化知识重用和理论机制修剪推理线索，有效解决了当前推理模型在交互式问题解决中的限制，为构建更有效的目标导向推理步骤提供了新方法

Abstract: Reasoning in interactive problem solving scenarios requires models to
construct reasoning threads that reflect user understanding and align with
structured domain knowledge. However, current reasoning models often lack
explicit semantic hierarchies, user-domain knowledge alignment, and principled
mechanisms to prune reasoning threads for effectiveness. These limitations
result in lengthy generic output that does not guide users through
goal-oriented reasoning steps. To address this, we propose a
prototype-inspired, two-phases Reasoning-Threads-Evaluation (ReT-Eval)
framework, drawing inspiration from human-like reasoning strategies that
emphasize structured knowledge reuse. In the first phase, semantically relevant
knowledge structures are extracted from a sparse domain knowledge graph using a
graph neural network and enriched with intrinsic large language model knowledge
to resolve knowledge discrepancies. In the second phase, these threads are
evaluated and pruned using a reward-guided strategy aimed at maintaining
semantic coherence to generate effective reasoning threads. Experiments and
expert evaluations show that ReT-Eval enhances user understanding and
outperforms state-of-the-art reasoning models.

</details>


### [31] [MOVER: Multimodal Optimal Transport with Volume-based Embedding Regularization](https://arxiv.org/abs/2508.12149)
*Haochen You,Baojing Liu*

Main category: cs.AI

TL;DR: MOVER是一个新的多模态学习框架，结合最优传输软对齐和几何体积正则化，在文本-视频-音频检索任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态对比学习方法在双模态设置中有效，但在多模态场景下泛化能力不足，且在高维空间中缺乏语义结构。

Method: 结合最优传输软对齐和几何体积最小化目标(GAVE)，通过传输引导的匹配机制和几何正则化，实现模态无关的一致性对齐。

Result: 在文本-视频-音频检索任务中，MOVER在零样本和微调设置下都显著优于现有最先进方法，展现出更好的泛化能力和结构一致性。

Conclusion: MOVER通过最优传输和几何正则化的结合，成功构建了语义对齐和结构化的多模态表示，在多模态学习中取得了突破性进展。

Abstract: Recent advances in multimodal learning have largely relied on pairwise
contrastive objectives to align different modalities, such as text, video, and
audio, in a shared embedding space. While effective in bi-modal setups, these
approaches struggle to generalize across multiple modalities and often lack
semantic structure in high-dimensional spaces. In this paper, we propose MOVER,
a novel framework that combines optimal transport-based soft alignment with
volume-based geometric regularization to build semantically aligned and
structured multimodal representations. By integrating a transport-guided
matching mechanism with a geometric volume minimization objective (GAVE), MOVER
encourages consistent alignment across all modalities in a modality-agnostic
manner. Experiments on text-video-audio retrieval tasks demonstrate that MOVER
significantly outperforms prior state-of-the-art methods in both zero-shot and
finetuned settings. Additional analysis shows improved generalization to unseen
modality combinations and stronger structural consistency in the learned
embedding space.

</details>


### [32] [RLNVR: Reinforcement Learning from Non-Verified Real-World Rewards](https://arxiv.org/abs/2508.12165)
*Rohit Krishnan,Jon Evans*

Main category: cs.AI

TL;DR: RLNVR框架使用非验证奖励训练语言模型，通过基线归一化和语义相似性奖励转移来处理噪声反馈，在社交媒体内容生成中展现显著改进


<details>
  <summary>Details</summary>
Motivation: 传统RLHF需要昂贵的人工验证奖励信号，在现实场景中不实用。RLNVR旨在利用真实世界的噪声反馈信号来训练语言模型

Method: 结合基线归一化、语义相似性奖励转移、GSPO策略优化和可选的UED课程学习，在噪声隐式奖励下提高稳定性和多样性

Result: 实验结果显示在内容质量和训练稳定性方面有显著改进，使用Bluesky实际参与数据进行验证

Conclusion: RLNVR提供了一个实用的框架，将GSPO归一化与UED课程学习相结合，用于从隐式社交参与中生成LLM内容，这是一个应用集成而非新算法

Abstract: This paper introduces RLNVR (Reinforcement Learning from Non-Verified
Rewards), a framework for training language models using noisy, real-world
feedback signals without requiring explicit human verification. Traditional
RLHF requires expensive, verified reward signals that are impractical in many
real-world domains. RLNVR addresses this challenge through baseline
normalization and semantic similarity-based reward transfer. We demonstrate
RLNVR through Walter, a prototype system that optimizes social media content
generation using actual engagement data from Bluesky. Our experimental results
show significant improvements in content quality and training stability, with
comprehensive evaluation planned for future work. Positioning: We present a
practical framework that combines RLNVR with GSPO (Group Sequence Policy
Optimization) and an optional UED (Unsupervised Environment Design) curriculum
to improve stability and diversity under noisy, implicit rewards. To our
knowledge, combining GSPO-style normalization with a UED-style curriculum for
LLM content generation from implicit social engagement has not been previously
documented in this applied setting; we frame this as an applied integration
rather than a new algorithm.

</details>


### [33] [Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting](https://arxiv.org/abs/2508.12260)
*Carson Dudley,Reiden Magdaleno,Christopher Harding,Ananya Sharma,Emily Martin,Marisa Eisenberg*

Main category: cs.AI

TL;DR: Mantis是一个基于机制模拟训练的传染病预测基础模型，无需真实数据就能跨疾病、地区和结果进行预测，在6种疾病上击败了39个专家调优模型，包括CDC COVID-19预测中心的所有模型。


<details>
  <summary>Details</summary>
Motivation: 传统传染病预测在新发疫情或资源匮乏地区受限于需要疾病特定数据、定制化训练和专家调优，限制了模型的通用性和部署能力。

Method: 基于超过4亿天模拟爆发动态的训练，涵盖多种病原体、传播模式、干预措施和监测伪影，完全使用机制模拟数据而不需要真实世界数据。

Result: 在6种疾病测试中优于39个专家调优模型，包括CDC COVID-19预测中心的所有模型；能够泛化到新的流行病学机制；提供8周预测范围，是大多数模型可操作范围的两倍以上。

Conclusion: Mantis作为下一代疾病预测系统的基础，具有通用性、可解释性，能够在传统模型失败的场景中部署，支持主动公共卫生规划。

Abstract: Infectious disease forecasting in novel outbreaks or low resource settings
has been limited by the need for disease-specific data, bespoke training, and
expert tuning. We introduce Mantis, a foundation model trained entirely on
mechanistic simulations, which enables out-of-the-box forecasting across
diseases, regions, and outcomes, even in settings with limited historical data.
Mantis is built on over 400 million simulated days of outbreak dynamics
spanning diverse pathogens, transmission modes, interventions, and surveillance
artifacts. Despite requiring no real-world data during training, Mantis
outperformed 39 expert-tuned models we tested across six diseases, including
all models in the CDC's COVID-19 Forecast Hub. Mantis generalized to novel
epidemiological regimes, including diseases with held-out transmission
mechanisms, demonstrating that it captures fundamental contagion dynamics.
Critically, Mantis is mechanistically interpretable, enabling public health
decision-makers to identify the latent drivers behind its predictions. Finally,
Mantis delivers accurate forecasts at 8-week horizons, more than doubling the
actionable range of most models, enabling proactive public health planning.
Together, these capabilities position Mantis as a foundation for
next-generation disease forecasting systems: general, interpretable, and
deployable where traditional models fail.

</details>


### [34] [RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts](https://arxiv.org/abs/2508.12291)
*Xuming He,Zhiyuan You,Junchao Gong,Couhua Liu,Xiaoyu Yue,Peiqin Zhuang,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: RadarQA是一个基于多模态大语言模型的天气预报质量分析方法，通过整合物理属性和详细评估报告，在雷达预报质量评估任务上超越了现有通用MLLM模型。


<details>
  <summary>Details</summary>
Motivation: 传统基于分数的评估指标在描述能力、可解释性和动态演化理解方面远不如气象专家，需要更先进的工具来克服这些挑战。

Method: 设计了结合人类专家标注和自动化启发式的混合标注流程，构建了RQA-70K大规模数据集，并采用多阶段训练策略迭代提升模型性能。

Result: 实验表明RadarQA在所有评估设置中都优于现有的通用多模态大语言模型。

Conclusion: 该方法在天气预报质量分析方面具有推进潜力，展示了MLLM在专业气象分析中的应用价值。

Abstract: Quality analysis of weather forecasts is an essential topic in meteorology.
Although traditional score-based evaluation metrics can quantify certain
forecast errors, they are still far from meteorological experts in terms of
descriptive capability, interpretability, and understanding of dynamic
evolution. With the rapid development of Multi-modal Large Language Models
(MLLMs), these models become potential tools to overcome the above challenges.
In this work, we introduce an MLLM-based weather forecast analysis method,
RadarQA, integrating key physical attributes with detailed assessment reports.
We introduce a novel and comprehensive task paradigm for multi-modal quality
analysis, encompassing both single frame and sequence, under both rating and
assessment scenarios. To support training and benchmarking, we design a hybrid
annotation pipeline that combines human expert labeling with automated
heuristics. With such an annotation method, we construct RQA-70K, a large-scale
dataset with varying difficulty levels for radar forecast quality evaluation.
We further design a multi-stage training strategy that iteratively improves
model performance at each stage. Extensive experiments show that RadarQA
outperforms existing general MLLMs across all evaluation settings, highlighting
its potential for advancing quality analysis in weather prediction.

</details>


### [35] [Wisdom of the Crowd: Reinforcement Learning from Coevolutionary Collective Feedback](https://arxiv.org/abs/2508.12338)
*Wenzhen Yuan,Shengji Tang,Weihao Lin,Jiacheng Ruan,Ganqu Cui,Bo Zhang,Tao Chen,Ting Liu,Yuzhuo Fu,Peng Ye,Lei Bai*

Main category: cs.AI

TL;DR: RLCCF是一个无需外部监督的多模型协作进化强化学习框架，通过最大化集体一致性来提升语言模型的推理能力，在数学推理基准上平均提升16.72%的准确率


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法依赖昂贵的人工标注数据或复杂奖励模型，限制了可扩展性；单模型自反馈方法存在过度自信、奖励攻击和训练崩溃等问题

Method: 提出基于协同进化集体反馈的强化学习框架(RLCCF)，通过训练多样化的LLM集成模型，利用集体投票提供奖励信号，并根据各模型的自一致性分数加权投票

Result: 在四个主流开源LLM和四个数学推理基准上的实验显示，平均相对准确率提升16.72%，群体多数投票准确率提升4.51%

Conclusion: RLCCF不仅提升单个模型性能，还能扩展模型集体的能力边界，通过多模型协同进化有效提升推理能力

Abstract: Reinforcement learning (RL) has significantly enhanced the reasoning
capabilities of large language models (LLMs), but its reliance on expensive
human-labeled data or complex reward models severely limits scalability. While
existing self-feedback methods aim to address this problem, they are
constrained by the capabilities of a single model, which can lead to
overconfidence in incorrect answers, reward hacking, and even training
collapse. To this end, we propose Reinforcement Learning from Coevolutionary
Collective Feedback (RLCCF), a novel RL framework that enables multi-model
collaborative evolution without external supervision. Specifically, RLCCF
optimizes the ability of a model collective by maximizing its Collective
Consistency (CC), which jointly trains a diverse ensemble of LLMs and provides
reward signals by voting on collective outputs. Moreover, each model's vote is
weighted by its Self-Consistency (SC) score, ensuring that more confident
models contribute more to the collective decision. Benefiting from the diverse
output distributions and complementary abilities of multiple LLMs, RLCCF
enables the model collective to continuously enhance its reasoning ability
through coevolution. Experiments on four mainstream open-source LLMs across
four mathematical reasoning benchmarks demonstrate that our framework yields
significant performance gains, achieving an average relative improvement of
16.72\% in accuracy. Notably, RLCCF not only improves the performance of
individual models but also enhances the group's majority-voting accuracy by
4.51\%, demonstrating its ability to extend the collective capability boundary
of the model collective.

</details>


### [36] [Hierarchical knowledge guided fault intensity diagnosis of complex industrial systems](https://arxiv.org/abs/2508.12375)
*Yu Sha,Shuiping Gou,Bo Liu,Johannes Faber,Ningtao Liu,Stefan Schramm,Horst Stoecker,Thomas Steckenreiter,Domagoj Vnucec,Nadine Wetzstein,Andreas Widl,Kai Zhou*

Main category: cs.AI

TL;DR: 通过层次知识导向的图卷积网络框架，提出Re-HKCM方案来改进故障强度诊断的性能，考虑了类间依赖关系


<details>
  <summary>Details</summary>
Motivation: 现有故障强度诊断方法没有考虑目标类别间的依赖关系，导致性能受限

Method: 使用图卷积网络将层次拓扑图映射为全局分类器，并提出重加权层次知识相关矩阵(Re-HKCM)来嵌入类间层次知识

Result: 在四个工业领域实际数据集上进行实验，都显示出优异的结果，超过最新的故障强度诊断方法

Conclusion: HKG框架通过考虑类间依赖关系，有效提升了故障强度诊断的性能，为复杂工业系统提供了更准确的监控和维护方案

Abstract: Fault intensity diagnosis (FID) plays a pivotal role in monitoring and
maintaining mechanical devices within complex industrial systems. As current
FID methods are based on chain of thought without considering dependencies
among target classes. To capture and explore dependencies, we propose a
hierarchical knowledge guided fault intensity diagnosis framework (HKG)
inspired by the tree of thought, which is amenable to any representation
learning methods. The HKG uses graph convolutional networks to map the
hierarchical topological graph of class representations into a set of
interdependent global hierarchical classifiers, where each node is denoted by
word embeddings of a class. These global hierarchical classifiers are applied
to learned deep features extracted by representation learning, allowing the
entire model to be end-to-end learnable. In addition, we develop a re-weighted
hierarchical knowledge correlation matrix (Re-HKCM) scheme by embedding
inter-class hierarchical knowledge into a data-driven statistical correlation
matrix (SCM) which effectively guides the information sharing of nodes in
graphical convolutional neural networks and avoids over-smoothing issues. The
Re-HKCM is derived from the SCM through a series of mathematical
transformations. Extensive experiments are performed on four real-world
datasets from different industrial domains (three cavitation datasets from
SAMSON AG and one existing publicly) for FID, all showing superior results and
outperform recent state-of-the-art FID methods.

</details>


### [37] [GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding](https://arxiv.org/abs/2508.12379)
*Rongzheng Wang,Qizhi Chen,Yihong Huang,Yizhuo Ma,Muquan Li,Jiakai Li,Ke Qin,Guangchun Luo,Shuang Liang*

Main category: cs.AI

TL;DR: GraphCogent是一个基于工作记忆模型的协作代理框架，通过分解图推理为感知、缓冲和执行三个认知过程，显著提升大语言模型处理复杂图推理任务的能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在小规模图推理任务上表现良好，但在处理具有复杂查询的真实世界图时表现不佳，主要原因是无法同时有效处理复杂图拓扑和执行多步推理。

Method: 提出GraphCogent框架，包含三个模块：感知模块通过子图采样标准化图文本表示，缓冲模块集成和索引多格式图数据，执行模块结合工具调用和模型生成进行高效推理。

Result: 基于Llama3.1-8B的GraphCogent相比DeepSeek-R1(671B)提升50%性能，相比最先进的基于代理的基线方法，准确率提升20%，同时token使用量减少80%（工具集内任务）和30%（工具集外任务）。

Conclusion: GraphCogent框架通过认知过程分解有效解决了大语言模型在复杂图推理中的局限性，在真实世界图推理任务上取得了显著性能提升和效率改进。

Abstract: Large language models (LLMs) show promising performance on small-scale graph
reasoning tasks but fail when handling real-world graphs with complex queries.
This phenomenon stems from LLMs' inability to effectively process complex graph
topology and perform multi-step reasoning simultaneously. To address these
limitations, we propose GraphCogent, a collaborative agent framework inspired
by human Working Memory Model that decomposes graph reasoning into specialized
cognitive processes: sense, buffer, and execute. The framework consists of
three modules: Sensory Module standardizes diverse graph text representations
via subgraph sampling, Buffer Module integrates and indexes graph data across
multiple formats, and Execution Module combines tool calling and model
generation for efficient reasoning. We also introduce Graph4real, a
comprehensive benchmark contains with four domains of real-world graphs (Web,
Social, Transportation, and Citation) to evaluate LLMs' graph reasoning
capabilities. Our Graph4real covers 21 different graph reasoning tasks,
categorized into three types (Structural Querying, Algorithmic Reasoning, and
Predictive Modeling tasks), with graph scales that are 10 times larger than
existing benchmarks. Experiments show that Llama3.1-8B based GraphCogent
achieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B).
Compared to state-of-the-art agent-based baseline, our framework outperforms by
20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30%
for out-toolset tasks. Code will be available after review.

</details>


### [38] [Non-Iterative Symbolic-Aided Chain-of-Thought for Logical Reasoning](https://arxiv.org/abs/2508.12425)
*Phuong Minh Nguyen,Tien Huu Dang,Naoya Inoue*

Main category: cs.AI

TL;DR: 这篇论文提出了符号辅助的思维链（Symbolic-Aided CoT）方法，通过在少量提示中集成轻量级符号表示，显著提升了大语言模型在逻辑推理任务上的性能，特别是在复杂的多约束推理任务中。


<details>
  <summary>Details</summary>
Motivation: 标准的思维链推理方法在逻辑推理中存在透明性和可解释性不足的问题，需要一种方法来提高推理过程的明确性和可分析性。

Method: 在少量提示中集成轻量级符号表示，使用一致的策略结构化推理步骤，在非迭代推理过程中使推理模式更加明确。

Result: 在4个逻辑推理测试集（ProofWriter、FOLIO、ProntoQA、LogicalDeduction）上进行了广泛实验，结果显示该方法在复杂推理任务中特别有效，在3个数据集上显著超过传统CoT方法。

Conclusion: 符号辅助CoT方法在保持标准提示技术通用性的同时，显著提升了LLM逻辑推理的透明性、可解释性和可分析性，尤其在复杂推理任务中表现优异。

Abstract: This work introduces Symbolic-Aided Chain-of-Thought (CoT), an improved
approach to standard CoT, for logical reasoning in large language models
(LLMs). The key idea is to integrate lightweight symbolic representations into
few-shot prompts, structuring the inference steps with a consistent strategy to
make reasoning patterns more explicit within a non-iterative reasoning process.
By incorporating these symbolic structures, our method preserves the
generalizability of standard prompting techniques while enhancing the
transparency, interpretability, and analyzability of LLM logical reasoning.
Extensive experiments on four well-known logical reasoning benchmarks --
ProofWriter, FOLIO, ProntoQA, and LogicalDeduction, which cover diverse
reasoning scenarios -- demonstrate the effectiveness of the proposed approach,
particularly in complex reasoning tasks that require navigating multiple
constraints or rules. Notably, Symbolic-Aided CoT consistently improves LLMs'
reasoning capabilities across various model sizes and significantly outperforms
conventional CoT on three out of four datasets, ProofWriter, ProntoQA, and
LogicalDeduction.

</details>


### [39] [GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?](https://arxiv.org/abs/2508.12472)
*Yifang Tian,Yaming Liu,Zichun Chong,Zihang Huang,Hans-Arno Jacobsen*

Main category: cs.AI

TL;DR: GALA是一个多模态框架，结合统计因果推理和LLM驱动的迭代推理，用于微服务系统的根因分析，相比现有方法准确率提升高达42.22%，并提供可操作的诊断和修复指导。


<details>
  <summary>Details</summary>
Motivation: 传统RCA方法通常只关注单一模态或仅对可疑服务进行排序，无法提供具有可操作性的诊断洞察和修复指导，需要一种能够结合多模态数据并提供实际解决方案的方法。

Method: GALA框架结合统计因果推理和大型语言模型(LLM)驱动的迭代推理，整合指标、日志和追踪等多种遥测数据，通过多模态分析进行根因诊断。

Result: 在开源基准测试中，GALA相比最先进方法实现了高达42.22%的准确率提升，生成的诊断输出在因果合理性和可操作性方面显著优于现有方法。

Conclusion: GALA通过提供准确的根因识别和人类可理解的修复指导，成功弥合了自动化故障诊断与实际事件解决之间的差距，为微服务系统的故障诊断提供了有效的解决方案。

Abstract: Root cause analysis (RCA) in microservice systems is challenging, requiring
on-call engineers to rapidly diagnose failures across heterogeneous telemetry
such as metrics, logs, and traces. Traditional RCA methods often focus on
single modalities or merely rank suspect services, falling short of providing
actionable diagnostic insights with remediation guidance. This paper introduces
GALA, a novel multi-modal framework that combines statistical causal inference
with LLM-driven iterative reasoning for enhanced RCA. Evaluated on an
open-source benchmark, GALA achieves substantial improvements over
state-of-the-art methods of up to 42.22% accuracy. Our novel human-guided LLM
evaluation score shows GALA generates significantly more causally sound and
actionable diagnostic outputs than existing methods. Through comprehensive
experiments and a case study, we show that GALA bridges the gap between
automated failure diagnosis and practical incident resolution by providing both
accurate root cause identification and human-interpretable remediation
guidance.

</details>


### [40] [The Yokai Learning Environment: Tracking Beliefs Over Space and Time](https://arxiv.org/abs/2508.12480)
*Constantin Ruhdorfer,Matteo Bortoletto,Andreas Bulling*

Main category: cs.AI

TL;DR: 提出了Yokai学习环境(YLE)作为多智能体强化学习测试平台，用于评估心智理论能力，发现当前RL智能体在信念建模、记忆和泛化方面存在显著不足


<details>
  <summary>Details</summary>
Motivation: 现有心智理论(ToM)基准局限于被动观察设置，缺乏对智能体如何随时间建立和维护共同基础的评估，需要更动态的协作环境

Method: 基于合作卡牌游戏Yokai构建多智能体强化学习环境，智能体需要轮流查看隐藏卡片并按颜色聚类，要求跟踪信念、记忆过去观察、使用提示作为接地通信

Result: 当前RL智能体即使有完美记忆也难以解决YLE任务；信念建模能提升性能但无法有效泛化到未见伙伴或形成长期准确信念，暴露了对脆弱约定而非稳健信念跟踪的依赖

Conclusion: YLE为研究信念建模、记忆、伙伴泛化和高阶心智理论扩展提供了有价值的测试平台，揭示了当前AI在协作推理方面的关键局限性

Abstract: Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to
reason about the beliefs of others to build and maintain common ground.
Existing ToM benchmarks, however, are restricted to passive observer settings
or lack an assessment of how agents establish and maintain common ground over
time. To address these gaps, we introduce the Yokai Learning Environment (YLE)
- a multi-agent reinforcement learning (RL) environment based on the
cooperative card game Yokai. In the YLE, agents take turns peeking at hidden
cards and moving them to form clusters based on colour. Success requires
tracking evolving beliefs, remembering past observations, using hints as
grounded communication, and maintaining common ground with teammates. Our
evaluation yields two key findings: First, current RL agents struggle to solve
the YLE, even when given access to perfect memory. Second, while belief
modelling improves performance, agents are still unable to effectively
generalise to unseen partners or form accurate beliefs over longer games,
exposing a reliance on brittle conventions rather than robust belief tracking.
We use the YLE to investigate research questions in belief modelling, memory,
partner generalisation, and scaling to higher-order ToM.

</details>


### [41] [Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models](https://arxiv.org/abs/2508.12500)
*Rahmat K. Adesunkanmi,Ashfaq Khokhar,Goce Trajcevski,Sohail Murad*

Main category: cs.AI

TL;DR: 利用变分自动编码器模型构建因果图模型，识别分子动力学中氢键形成和解离事件的根本原因变量


<details>
  <summary>Details</summary>
Motivation: 解决分子动力学模拟中资源消耗大、需手动扫描关键事件的挑战，并探索氢键形成和解离的深层原因

Method: 受因果模型启发，将氢键解离视为"干预"事件，构建图形因果模型，采用变分自动编码器结构在多样化因果图中推断因果关系，包含聚合分布变化的根因推断步骤

Result: 在旋光分离的原子轨迹数据上验证有效，能够预测多步未来变化，准确识别驱动系统变化的关键变量

Conclusion: 该框架为分子动力系统根因分析提供了新视角，通过建模分子作用条件分布的移动来揭示氢键动态的深层因果机制

Abstract: Molecular dynamics simulations (MDS) face challenges, including
resource-heavy computations and the need to manually scan outputs to detect
"interesting events," such as the formation and persistence of hydrogen bonds
between atoms of different molecules. A critical research gap lies in
identifying the underlying causes of hydrogen bond formation and separation
-understanding which interactions or prior events contribute to their emergence
over time. With this challenge in mind, we propose leveraging spatio-temporal
data analytics and machine learning models to enhance the detection of these
phenomena. In this paper, our approach is inspired by causal modeling and aims
to identify the root cause variables of hydrogen bond formation and separation
events. Specifically, we treat the separation of hydrogen bonds as an
"intervention" occurring and represent the causal structure of the bonding and
separation events in the MDS as graphical causal models. These causal models
are built using a variational autoencoder-inspired architecture that enables us
to infer causal relationships across samples with diverse underlying causal
graphs while leveraging shared dynamic information. We further include a step
to infer the root causes of changes in the joint distribution of the causal
models. By constructing causal models that capture shifts in the conditional
distributions of molecular interactions during bond formation or separation,
this framework provides a novel perspective on root cause analysis in molecular
dynamic systems. We validate the efficacy of our model empirically on the
atomic trajectories that used MDS for chiral separation, demonstrating that we
can predict many steps in the future and also find the variables driving the
observed changes in the system.

</details>


### [42] [Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models](https://arxiv.org/abs/2508.12566)
*Wei Song,Haonan Zhong,Ziqi Ding,Jingling Xue,Yuekang Li*

Main category: cs.AI

TL;DR: MCPGAUGE是首个全面评估LLM与MCP交互的框架，通过4个维度（主动性、合规性、有效性、开销）和160个提示、25个数据集，对6个商业LLM和30个MCP工具套件进行了大规模评估，揭示了MCP集成的关键局限性。


<details>
  <summary>Details</summary>
Motivation: 虽然MCP协议让LLM能够按需访问外部资源，但LLM如何实际利用这种能力以及其效果如何仍不清楚，需要系统性的评估框架来理解LLM-MCP交互的真实效果。

Method: 开发了MCPGAUGE评估框架，包含160个提示的测试套件和25个数据集，覆盖知识理解、通用推理和代码生成任务。在6个商业LLM和30个MCP工具套件上进行了大规模评估，包含约20,000次API调用。

Result: 研究发现了四个关键发现，挑战了关于MCP集成有效性的普遍假设，揭示了当前AI工具集成的关键局限性。

Conclusion: MCPGAUGE为推进可控、工具增强的LLM提供了一个原则性的基准，突显了当前MCP集成方法的不足和改进方向。

Abstract: The Model Context Protocol (MCP) enables large language models (LLMs) to
access external resources on demand. While commonly assumed to enhance
performance, how LLMs actually leverage this capability remains poorly
understood. We introduce MCPGAUGE, the first comprehensive evaluation framework
for probing LLM-MCP interactions along four key dimensions: proactivity
(self-initiated tool use), compliance (adherence to tool-use instructions),
effectiveness (task performance post-integration), and overhead (computational
cost incurred). MCPGAUGE comprises a 160-prompt suite and 25 datasets spanning
knowledge comprehension, general reasoning, and code generation. Our
large-scale evaluation, spanning six commercial LLMs, 30 MCP tool suites, and
both one- and two-turn interaction settings, comprises around 20,000 API calls
and over USD 6,000 in computational cost. This comprehensive study reveals four
key findings that challenge prevailing assumptions about the effectiveness of
MCP integration. These insights highlight critical limitations in current
AI-tool integration and position MCPGAUGE as a principled benchmark for
advancing controllable, tool-augmented LLMs.

</details>


### [43] [An LLM + ASP Workflow for Joint Entity-Relation Extraction](https://arxiv.org/abs/2508.12611)
*Trang Tran,Trung Hoang Le,Huiping Cao,Tran Cao Son*

Main category: cs.AI

TL;DR: 基于大语言模型和答案集编程的联合实体-关系提取方法，免需大量注释数据且支持域知识粘性扩展


<details>
  <summary>Details</summary>
Motivation: 传统的联合实体-关系提取方法需要大量注释数据，无法轻松融入域特定知识，建模过程劳动密集、耗时且不支持粘性扩展

Method: 结合生成式预训练大语言模型(LLMs)的自然语言理解能力和答案集编程(ASP)的知识表示与推理能力，提出了通用的工作流程

Result: 在三个知名测试集上进行实验，仅需10%训练数据的情况下，性能超过现有最优方法，在SciERC语料库的关系提取任务中实现了35%的性能（相比15%），提升2.5倍

Conclusion: LLM + ASP流程为联合实体-关系提取提供了一种通用、高效且支持域知识粘性扩展的解决方案，在少量训练数据情况下便能获得优异性能

Abstract: Joint entity-relation extraction (JERE) identifies both entities and their
relationships simultaneously. Traditional machine-learning based approaches to
performing this task require a large corpus of annotated data and lack the
ability to easily incorporate domain specific information in the construction
of the model. Therefore, creating a model for JERE is often labor intensive,
time consuming, and elaboration intolerant. In this paper, we propose
harnessing the capabilities of generative pretrained large language models
(LLMs) and the knowledge representation and reasoning capabilities of Answer
Set Programming (ASP) to perform JERE. We present a generic workflow for JERE
using LLMs and ASP. The workflow is generic in the sense that it can be applied
for JERE in any domain. It takes advantage of LLM's capability in natural
language understanding in that it works directly with unannotated text. It
exploits the elaboration tolerant feature of ASP in that no modification of its
core program is required when additional domain specific knowledge, in the form
of type specifications, is found and needs to be used. We demonstrate the
usefulness of the proposed workflow through experiments with limited training
data on three well-known benchmarks for JERE. The results of our experiments
show that the LLM + ASP workflow is better than state-of-the-art JERE systems
in several categories with only 10\% of training data. It is able to achieve a
2.5 times (35\% over 15\%) improvement in the Relation Extraction task for the
SciERC corpus, one of the most difficult benchmarks.

</details>


### [44] [Cognitive Structure Generation: From Educational Priors to Policy Optimization](https://arxiv.org/abs/2508.12647)
*Hengnian Gu,Zhifu Chen,Yuxin Chen,Jin Peng Zhou,Dongdai Zhou*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的认知结构生成(CSG)框架，通过预训练认知结构滴涼概率模型和强化学习优化，能够生成更全面有效的学生认知结构表征，显著提升了知识转移和技能测评任务的性能。


<details>
  <summary>Details</summary>
Motivation: 认知结构是学生对知识体系的主观组织，但认知结构评估一直是学生建模和心理测量领域的长期挑战，在教育实践中很难进行有效评估。

Method: 首先预训练认知结构滴涼概率模型(CSDPM)从教育先验知识生成学生认知结构，然后通过强化学习以层次奖励信号优化生成过程作为策略，使其与学生学习过程中真实的认知发展水平对齐。

Result: 在4个流行的真实世界教育数据集上的实验结果显示，CSG生成的认知结构能够提供更全面和有效的学生建模表征，在知识转移(KT)和技能测评(CD)任务上显著提升了性能，同时增强了可解释性。

Conclusion: 认知结构生成(CSG)框架为解决认知结构评估挑战提供了有效的方法，通过混合深度学习和强化学习技术，能够生成与真实认知发展相符合的高质量认知结构表征，从而提升教育应用中学生建模的效果。

Abstract: Cognitive structure is a student's subjective organization of an objective
knowledge system, reflected in the psychological construction of concepts and
their relations. However, cognitive structure assessment remains a
long-standing challenge in student modeling and psychometrics, persisting as a
foundational yet largely unassessable concept in educational practice. This
paper introduces a novel framework, Cognitive Structure Generation (CSG), in
which we first pretrain a Cognitive Structure Diffusion Probabilistic Model
(CSDPM) to generate students' cognitive structures from educational priors, and
then further optimize its generative process as a policy with hierarchical
reward signals via reinforcement learning to align with genuine cognitive
development levels during students' learning processes. Experimental results on
four popular real-world education datasets show that cognitive structures
generated by CSG offer more comprehensive and effective representations for
student modeling, substantially improving performance on KT and CD tasks while
enhancing interpretability.

</details>


### [45] [The Maximum Coverage Model and Recommendation System for UAV Vertiports Location Planning](https://arxiv.org/abs/2508.12651)
*Chunliang Hua,Xiao Hu,Jiayang Sun,Zeyuan Yang*

Main category: cs.AI

TL;DR: 本文提出了一种新的基于容量约束动态最大覆盖位置问题(CDMCLP)的优化框架，结合社会经济因素和动态聚类初始化，为城市空中交通(UAM)垂直机场网络规划提供了实用的规划推荐系统。


<details>
  <summary>Details</summary>
Motivation: 随着全球城市空中交通基础设施开发加速，现有的规划框架因历史数据粒度和实际应用性限制而无法满足复杂性需求。

Method: 首先提出容量约束动态最大覆盖位置问题(CDMCLP)优化框架，同时建模城市级空间-时间需求、异质用户行为和基础设施容量约束。然后结合社会经济因素和动态聚类初始化，构建了集成规划推荐系统。

Result: 在中国中心城市的验证显示，新优化框架和推荐系统显示出高效性。CDMCLP优化下，传统位置方法的数量性能提高了38%-52%，推荐系统显示了用户友好性和复杂元素的有效集成。

Conclusion: 这种混合方法通过结合数学严谨性和实际实施考虑，平息了理论位置建模与实际UAM基础设施规划之间的差距，为市政府提供了垂直机场网络设计的实用工具。

Abstract: As urban aerial mobility (UAM) infrastructure development accelerates
globally, cities like Shenzhen are planning large-scale vertiport networks
(e.g., 1,200+ facilities by 2026). Existing planning frameworks remain
inadequate for this complexity due to historical limitations in data
granularity and real-world applicability. This paper addresses these gaps by
first proposing the Capacitated Dynamic Maximum Covering Location Problem
(CDMCLP), a novel optimization framework that simultaneously models urban-scale
spatial-temporal demand, heterogeneous user behaviors, and infrastructure
capacity constraints. Building on this foundation, we introduce an Integrated
Planning Recommendation System that combines CDMCLP with socio-economic factors
and dynamic clustering initialization. This system leverages adaptive parameter
tuning based on empirical user behavior to generate practical planning
solutions. Validation in a Chinese center city demonstrates the effectiveness
of the new optimization framework and recommendation system. Under the
evaluation and optimization of CDMCLP, the quantitative performance of
traditional location methods are exposed and can be improved by 38\%--52\%,
while the recommendation system shows user-friendliness and the effective
integration of complex elements. By integrating mathematical rigor with
practical implementation considerations, this hybrid approach bridges the gap
between theoretical location modeling and real-world UAM infrastructure
planning, offering municipalities a pragmatic tool for vertiport network
design.

</details>


### [46] [GridCodex: A RAG-Driven AI Framework for Power Grid Code Reasoning and Compliance](https://arxiv.org/abs/2508.12682)
*Jinquan Shi,Yingying Cheng,Fan Zhang,Miao Jiang,Jun Lin,Yanbai Shen*

Main category: cs.AI

TL;DR: GridCodex是一个基于大语言模型和检索增强生成的端到端电网规范推理与合规框架，通过多阶段查询优化和RAPTOR增强检索技术，在电网规范自动解释方面取得了显著性能提升


<details>
  <summary>Details</summary>
Motivation: 可再生能源转型给电力行业带来新挑战，电网规范复杂且缺乏自动化解释方案，阻碍行业发展并影响电力公司盈利能力

Method: 结合大语言模型和检索增强生成(RAG)，采用多阶段查询优化和RAPTOR增强检索技术的端到端框架

Result: 实验结果显示答案质量提升26.4%，召回率提高10倍以上，通过多维度自动评估验证了框架有效性

Conclusion: GridCodex框架在电网规范自动解释方面表现出色，为电力行业监管合规提供了有效的技术解决方案

Abstract: The global shift towards renewable energy presents unprecedented challenges
for the electricity industry, making regulatory reasoning and compliance
increasingly vital. Grid codes, the regulations governing grid operations, are
complex and often lack automated interpretation solutions, which hinders
industry expansion and undermines profitability for electricity companies. We
introduce GridCodex, an end to end framework for grid code reasoning and
compliance that leverages large language models and retrieval-augmented
generation (RAG). Our framework advances conventional RAG workflows through
multi stage query refinement and enhanced retrieval with RAPTOR. We validate
the effectiveness of GridCodex with comprehensive benchmarks, including
automated answer assessment across multiple dimensions and regulatory agencies.
Experimental results showcase a 26.4% improvement in answer quality and more
than a 10 fold increase in recall rate. An ablation study further examines the
impact of base model selection.

</details>


### [47] [EGOILLUSION: Benchmarking Hallucinations in Egocentric Video Understanding](https://arxiv.org/abs/2508.12687)
*Ashish Seth,Utkarsh Tyagi,Ramaneswaran Selvakumar,Nishit Anand,Sonal Kumar,Sreyan Ghosh,Ramani Duraiswami,Chirag Agarwal,Dinesh Manocha*

Main category: cs.AI

TL;DR: EgoIllusion是首个评估多模态大语言模型在自我中心视频中幻觉问题的基准测试，包含1,400个视频和8,000个人工标注问题，测试显示包括GPT-4o和Gemini在内的顶级模型准确率仅为59%。


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型在复杂多模态任务中表现优异，但在自我中心视频中容易产生连贯但不准确的幻觉回答，需要专门的基准来评估和改进这一问题。

Method: 构建包含1,400个自我中心视频和8,000个人工标注问题的EgoIllusion基准，设计开放性和封闭性问题来触发视觉和听觉线索的幻觉，评估10个不同的MLLM模型。

Result: 评估结果显示所有模型都面临显著挑战，即使是GPT-4o和Gemini这样的强大模型也只能达到59%的准确率，表明当前模型在自我中心视频处理中存在严重的幻觉问题。

Conclusion: EgoIllusion为评估MLLM有效性提供了基础基准，将推动开发幻觉率更低的自我中心多模态大语言模型，该基准将开源以确保可复现性。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
performance in complex multimodal tasks. While MLLMs excel at visual perception
and reasoning in third-person and egocentric videos, they are prone to
hallucinations, generating coherent yet inaccurate responses. We present
EgoIllusion, a first benchmark to evaluate MLLM hallucinations in egocentric
videos. EgoIllusion comprises 1,400 videos paired with 8,000 human-annotated
open and closed-ended questions designed to trigger hallucinations in both
visual and auditory cues in egocentric videos. Evaluations across ten MLLMs
reveal significant challenges, including powerful models like GPT-4o and
Gemini, achieving only 59% accuracy. EgoIllusion lays the foundation in
developing robust benchmarks to evaluate the effectiveness of MLLMs and spurs
the development of better egocentric MLLMs with reduced hallucination rates.
Our benchmark will be open-sourced for reproducibility.

</details>


### [48] [GTool: Graph Enhanced Tool Planning with Large Language Model](https://arxiv.org/abs/2508.12725)
*Wenjie Chen,Wenbin Li,Di Yao,Xuying Meng,Chang Gong,Jingping Bi*

Main category: cs.AI

TL;DR: GTool是一个增强LLM在工具依赖不完整情况下工具规划能力的新方法，通过构建请求特定的工具图和生成图标记来提供依赖信息，相比现有SOTA方法性能提升29.6%


<details>
  <summary>Details</summary>
Motivation: 当前工作将不同工具视为孤立组件，未能利用工具间的内在依赖关系，导致规划结果无效。在工具依赖不完整的情况下，LLM难以准确识别用户请求所需的合适工具

Method: 构建请求特定的工具图来高效选择工具，生成LLM可理解的<graph token>提供依赖信息，设计缺失依赖预测任务提高在不完整依赖下的可靠性

Result: 使用轻量级(7B)LLM骨干网络，相比最先进的基线方法实现了超过29.6%的性能提升

Conclusion: GTool能够无缝集成到各种LLM骨干网络中而无需大量重新训练，有效解决了工具依赖不完整情况下的工具规划问题

Abstract: Tool planning with large language models (LLMs), referring to selecting,
organizing, and preparing the tools necessary to complete a user request,
bridges the gap between natural language understanding and task execution.
However, current works treat different tools as isolated components and fail to
leverage the inherent dependencies of tools, leading to invalid planning
results. Since tool dependencies are often incomplete, it becomes challenging
for LLMs to accurately identify the appropriate tools required by a user
request, especially when confronted with a large toolset. To solve this
challenge, we propose \texttt{GTool}, which is the first work aiming to enhance
the tool planning ability of LLMs under incomplete dependencies. \texttt{GTool}
constructs a request-specific tool graph to select tools efficiently and
generate the \texttt{<graph token>} which provides sufficient dependency
information understandable by LLMs. Moreover, a missing dependency prediction
task is designed to improve the reliability of \texttt{GTool} with incomplete
dependencies. Without trimming LLMs, \texttt{GTool} can be seamlessly
integrated with various LLM backbones without extensive retraining. Extensive
experiments show that \texttt{GTool} achieves more than 29.6\% performance
improvements compared with the state-of-the-art (SOTA) baselines with a
light-weight (7B) LLM backbone.

</details>


### [49] [Beyond Ethical Alignment: Evaluating LLMs as Artificial Moral Assistants](https://arxiv.org/abs/2508.12754)
*Alessio Galatolo,Luca Alberto Rappuoli,Katie Winkle,Meriem Beloucif*

Main category: cs.AI

TL;DR: 这篇论文提出了一种人工道德助手（AMA）的新评测框架，用于评估大语言模型的道德推理能力，而不仅仅是最终道德判断。


<details>
  <summary>Details</summary>
Motivation: 当前的大语言模型对齐评测主要测量最终道德判断，而缺乏对明确道德推理能力的深入评估。需要一种更深入的方法来评估模型的道德思维能力。

Method: 基于哲学文献设计了一种新的形式框架，定义了AMA应具备的关键特性（演绎性和引申性道德推理），并开发了相应的测试标准。对流行的开源大语言模型进行了评估。

Result: 测试结果显示不同模型之间存在显著差异，尤其是在引申性道德推理方面存在持续的短板。

Conclusion: 该研究将理论哲学与实践AI评估结合起来，强调了需要专门的策略来明确提升大语言模型的道德推理能力。

Abstract: The recent rise in popularity of large language models (LLMs) has prompted
considerable concerns about their moral capabilities. Although considerable
effort has been dedicated to aligning LLMs with human moral values, existing
benchmarks and evaluations remain largely superficial, typically measuring
alignment based on final ethical verdicts rather than explicit moral reasoning.
In response, this paper aims to advance the investigation of LLMs' moral
capabilities by examining their capacity to function as Artificial Moral
Assistants (AMAs), systems envisioned in the philosophical literature to
support human moral deliberation. We assert that qualifying as an AMA requires
more than what state-of-the-art alignment techniques aim to achieve: not only
must AMAs be able to discern ethically problematic situations, they should also
be able to actively reason about them, navigating between conflicting values
outside of those embedded in the alignment phase. Building on existing
philosophical literature, we begin by designing a new formal framework of the
specific kind of behaviour an AMA should exhibit, individuating key qualities
such as deductive and abductive moral reasoning. Drawing on this theoretical
framework, we develop a benchmark to test these qualities and evaluate popular
open LLMs against it. Our results reveal considerable variability across models
and highlight persistent shortcomings, particularly regarding abductive moral
reasoning. Our work connects theoretical philosophy with practical AI
evaluation while also emphasising the need for dedicated strategies to
explicitly enhance moral reasoning capabilities in LLMs. Code available at
https://github.com/alessioGalatolo/AMAeval

</details>


### [50] [HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds](https://arxiv.org/abs/2508.12782)
*Petr Anokhin,Roman Khalikov,Stefan Rebrikov,Viktor Volkov,Artyom Sorokin,Vincent Bissonnette*

Main category: cs.AI

TL;DR: HeroBench是一个专门评估大语言模型在复杂RPG虚拟世界中长时程规划和结构化推理能力的新基准，通过25个先进模型的广泛评估揭示了传统推理基准中罕见的显著性能差异。


<details>
  <summary>Details</summary>
Motivation: 现有基准通常通过抽象或低维算法任务评估LLMs，无法捕捉现实规划环境的复杂性，而LLMs在需要扩展、结构化相互依赖行动序列的长时程规划方面的能力仍未充分探索。

Method: 引入HeroBench基准，包含严格构建的任务数据集（涵盖各种难度）、执行和验证代理计划的模拟环境，以及详细的模型性能分析工具。任务挑战模型制定战略计划、高效收集资源、掌握必要技能、制作装备和击败对手。

Result: 对25个最先进LLMs（包括开源和专有模型，如GPT-5系列）的广泛评估显示出在传统推理基准中罕见的显著性能差异。详细错误分析进一步揭示了当前模型在生成鲁棒高级计划和可靠执行结构化行动方面的具体弱点。

Conclusion: HeroBench不仅显著推进了LLM推理评估，还为未来在虚拟环境中进行高级自主规划研究提供了灵活、可扩展的基础。

Abstract: Large language models (LLMs) have shown remarkable capabilities in isolated
step-by-step reasoning tasks such as mathematics and programming, but their
proficiency in long-horizon planning, where solutions require extended,
structured sequences of interdependent actions, remains underexplored. Existing
benchmarks typically assess LLMs through abstract or low-dimensional
algorithmic tasks, failing to capture the complexity of realistic planning
environments. We introduce HeroBench, a novel benchmark designed specifically
to evaluate long-horizon planning and structured reasoning within complex
RPG-inspired virtual worlds. HeroBench provides a rigorously constructed
dataset of tasks covering a wide range of difficulties, a simulated environment
to execute and validate agent plans, and detailed analytical tools for
evaluating model performance. Tasks challenge models to formulate strategic
plans, efficiently gather resources, master necessary skills, craft equipment,
and defeat adversaries, reflecting practical scenarios' layered dependencies
and constraints. Our extensive evaluation of 25 state-of-the-art LLMs, spanning
both open-source and proprietary models, including the GPT-5 family, reveals
substantial performance disparities rarely observed in conventional reasoning
benchmarks. Detailed error analysis further uncovers specific weaknesses in
current models' abilities to generate robust high-level plans and reliably
execute structured actions. HeroBench thus not only significantly advances the
evaluation of LLM reasoning but also provides a flexible, scalable foundation
for future research into advanced, autonomous planning in virtual environments.

</details>


### [51] [Reinforcement Learning with Rubric Anchors](https://arxiv.org/abs/2508.12790)
*Zenan Huang,Yihong Zhuang,Guoshan Lu,Zeyu Qin,Haokai Xu,Tianyu Zhao,Ru Peng,Jiaqi Hu,Zhanming Shen,Xiaomeng Hu,Xijun Gu,Peiyi Tu,Jiaxin Liu,Wenyu Chen,Yuzhuo Fu,Zhiting Fan,Yanmei Gu,Yuanyuan Wang,Zhengkai Yang,Jianguo Li,Junbo Zhao*

Main category: cs.AI

TL;DR: 通过规则基础奖励扩展RLVR到主观性任务，构建超1万个评分规则，在Qwen-30B-A3B模型上实现了在开放式任务上+5.2%的性能提升，超过DeepSeek-V3模型，同时提供细粒度风格控制能力。


<details>
  <summary>Details</summary>
Motivation: 解决RLVR弊型仅能在可自动检查结果的领域使用的限制，将其扩展到主观性、开放式任务中。

Method: 通过设计结构化的评分规则作为自动评分标准，构建了超1万个来自人类、LLM或人机协作的评分规则系统。

Result: 仅用5K+样本就在开放式测试集上提升+5.2%（人文领域特别显著），超过671B的DeepSeek-V3模型+2.4%，保持了通用和推理能力，同时提供细粒度风格控制。

Conclusion: 规则基础RLVR成功扩展了强化学习的应用范围，为主观性任务提供了有效的自动评价方法，具有良好的性能提升和风格控制效果。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for enhancing Large Language Models (LLMs), exemplified by
the success of OpenAI's o-series. In RLVR, rewards are derived from verifiable
signals-such as passing unit tests in code generation or matching correct
answers in mathematical reasoning. While effective, this requirement largely
confines RLVR to domains with automatically checkable outcomes. To overcome
this, we extend the RLVR paradigm to open-ended tasks by integrating
rubric-based rewards, where carefully designed rubrics serve as structured,
model-interpretable criteria for automatic scoring of subjective outputs. We
construct, to our knowledge, the largest rubric reward system to date, with
over 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration.
Implementing rubric-based RL is challenging; we tackle these issues with a
clear framework and present an open-sourced Qwen-30B-A3B model with notable
gains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended
benchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by
+2.4%, while preserving general and reasoning abilities. 2) Our method provides
fine-grained stylistic control, using rubrics as anchors to mitigate the
"AI-like" tone and produce more human-like, expressive responses. We share key
lessons in rubric construction, data selection, and training, and discuss
limitations and future releases.

</details>


### [52] [Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics](https://arxiv.org/abs/2508.12840)
*Giovanni Briglia,Francesco Fabiano,Stefano Mariani*

Main category: cs.AI

TL;DR: 利用图神经网络学习多代理认知规划中的状态质量预测，提高规划效率和可扩展性


<details>
  <summary>Details</summary>
Motivation: 多代理认知规划中的Kripke结构表示导致状态空间指数增长，现有吧准方法无法有效指导搜索，影响规划器的可扩展性

Method: 采用图神经网络(GNN)学习Kripke模型中的图结构特征，通过对已解决规划实例的知识汇总来预测状态质量(如距离目标的距离)

Result: 将GNN预测吧准集成到认知规划流程中，与标准基准线相比显著提高了多代理认知规划的可扩展性

Conclusion: GNN技术能够有效处理认知规划中的图形化状态表示，通过学习预测吧准来指导搜索，为复杂多代理认知规划问题提供了可扩展的解决方案

Abstract: Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for
reasoning about both the physical world and the beliefs of agents, with
applications in domains where information flow and awareness among agents are
critical. The richness of MEP requires states to be represented as Kripke
structures, i.e., directed labeled graphs. This representation limits the
applicability of existing heuristics, hindering the scalability of epistemic
solvers, which must explore an exponential search space without guidance,
resulting often in intractability. To address this, we exploit Graph Neural
Networks (GNNs) to learn patterns and relational structures within epistemic
states, to guide the planning process. GNNs, which naturally capture the
graph-like nature of Kripke models, allow us to derive meaningful estimates of
state quality -- e.g., the distance from the nearest goal -- by generalizing
knowledge obtained from previously solved planning instances. We integrate
these predictive heuristics into an epistemic planning pipeline and evaluate
them against standard baselines, showing significant improvements in the
scalability of multi-agent epistemic planning.

</details>


### [53] [CAMAR: Continuous Actions Multi-Agent Routing](https://arxiv.org/abs/2508.12845)
*Artem Pshenitsyn,Aleksandr Panov,Alexey Skrynnik*

Main category: cs.AI

TL;DR: CAMAR是一个新的多智能体强化学习基准测试，专注于连续动作空间中的多智能体路径规划，支持合作和竞争交互，并提供三层评估协议和经典规划方法的集成。


<details>
  <summary>Details</summary>
Motivation: 现有的MARL基准测试很少结合连续状态和动作空间与具有挑战性的协调和规划任务，需要一个新的测试平台来推动算法发展。

Method: 设计了CAMAR基准测试，支持连续动作空间的多智能体路径规划，集成了RRT和RRT*等经典规划方法，并提供三层评估协议和测试场景套件。

Result: CAMAR能够以每秒100,000环境步骤的高效速度运行，为MARL社区提供了一个具有挑战性和现实性的测试平台。

Conclusion: CAMAR填补了MARL基准测试在连续动作空间路径规划方面的空白，通过集成经典规划方法和提供标准化评估框架，促进了MARL算法的发展。

Abstract: Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving
cooperative and competitive decision-making problems. While many MARL
benchmarks have been proposed, few combine continuous state and action spaces
with challenging coordination and planning tasks. We introduce CAMAR, a new
MARL benchmark designed explicitly for multi-agent pathfinding in environments
with continuous actions. CAMAR supports cooperative and competitive
interactions between agents and runs efficiently at up to 100,000 environment
steps per second. We also propose a three-tier evaluation protocol to better
track algorithmic progress and enable deeper analysis of performance. In
addition, CAMAR allows the integration of classical planning methods such as
RRT and RRT* into MARL pipelines. We use them as standalone baselines and
combine RRT* with popular MARL algorithms to create hybrid approaches. We
provide a suite of test scenarios and benchmarking tools to ensure
reproducibility and fair comparison. Experiments show that CAMAR presents a
challenging and realistic testbed for the MARL community.

</details>


### [54] [E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model](https://arxiv.org/abs/2508.12854)
*Ronghao Lin,Shuai Shen,Weipeng Hu,Qiaolin He,Aolin Xiong,Li Huang,Haifeng Hu,Yap-peng Tan*

Main category: cs.AI

TL;DR: E3RG是一个基于多模态大语言模型的显式情感驱动共情响应生成系统，通过将多模态共情响应生成任务分解为三个部分来实现自然、情感丰富且身份一致的响应，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型改进了基于文本的共情响应生成，但在处理多模态情感内容和保持身份一致性方面仍存在挑战。

Method: 将多模态共情响应生成任务分解为三部分：多模态共情理解、共情记忆检索和多模态响应生成，并集成先进的表达性语音和视频生成模型。

Result: 实验验证了系统在零样本和少样本设置上的优越性，在ACM MM 25的Avatar-based多模态共情挑战中获得Top-1位置。

Conclusion: E3RG系统能够有效生成自然、情感丰富且身份一致的多模态共情响应，为构建情感智能人机交互提供了有效解决方案。

Abstract: Multimodal Empathetic Response Generation (MERG) is crucial for building
emotionally intelligent human-computer interactions. Although large language
models (LLMs) have improved text-based ERG, challenges remain in handling
multimodal emotional content and maintaining identity consistency. Thus, we
propose E3RG, an Explicit Emotion-driven Empathetic Response Generation System
based on multimodal LLMs which decomposes MERG task into three parts:
multimodal empathy understanding, empathy memory retrieval, and multimodal
response generation. By integrating advanced expressive speech and video
generative models, E3RG delivers natural, emotionally rich, and
identity-consistent responses without extra training. Experiments validate the
superiority of our system on both zero-shot and few-shot settings, securing
Top-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25.
Our code is available at https://github.com/RH-Lin/E3RG.

</details>


### [55] [Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption](https://arxiv.org/abs/2508.12896)
*Faruk Alpay,Taylan Alpay*

Main category: cs.AI

TL;DR: 本文提出了三个关于多步骤任务AI系统持续采用的设计公理，并建立了包含衰减新颖性项和增长效用项的采用模型，通过数学推导分析了采用过程中的低谷/超调现象。


<details>
  <summary>Details</summary>
Motivation: 研究AI系统在多步骤任务中的持续采用问题，旨在理解影响用户长期采用的关键因素，避免系统在初始热度后迅速衰退。

Method: 建立数学模型将采用量表示为新颖性衰减和效用增长的叠加，进行参数识别性分析、模型比较、风险函数族消融实验、多序列基准测试、摩擦代理校准等系统性分析。

Result: 推导出了采用过程中出现低谷和超调现象的相位条件，提供了完整的数学证明，并开发了包含11个分析维度的综合评估框架。

Conclusion: 提出了三个核心设计公理（可靠性>新颖性、嵌入>目的地、代理>聊天），为构建可持续采用的AI系统提供了理论基础和实践指导。

Abstract: We formalize three design axioms for sustained adoption of agent-centric AI
systems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed >
Destination; (A3) Agency > Chat. We model adoption as a sum of a decaying
novelty term and a growing utility term and derive the phase conditions for
troughs/overshoots with full proofs. We introduce: (i) an
identifiability/confounding analysis for $(\alpha,\beta,N_0,U_{\max})$ with
delta-method gradients; (ii) a non-monotone comparator
(logistic-with-transient-bump) evaluated on the same series to provide
additional model comparison; (iii) ablations over hazard families $h(\cdot)$
mapping $\Delta V \to \beta$; (iv) a multi-series benchmark (varying trough
depth, noise, AR structure) reporting coverage (type-I error, power); (v)
calibration of friction proxies against time-motion/survey ground truth with
standard errors; (vi) residual analyses (autocorrelation and
heteroskedasticity) for each fitted curve; (vii) preregistered windowing
choices for pre/post estimation; (viii) Fisher information & CRLB for
$(\alpha,\beta)$ under common error models; (ix) microfoundations linking
$\mathcal{T}$ to $(N_0,U_{\max})$; (x) explicit comparison to bi-logistic,
double-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$
heterogeneity. Figures and tables are reflowed for readability, and the
bibliography restores and extends non-logistic/Bass adoption references
(Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All
code and logs necessary to reproduce the synthetic analyses are embedded as
LaTeX listings.

</details>


### [56] [FuSaR: A Fuzzification-Based Method for LRM Safety-Reasoning Balance](https://arxiv.org/abs/2508.12897)
*Jianhao Chen,Mayi Xu,Xiaohu Li,Yongqi Li,Xiangyu Zhang,Jianjie Huang,Tieyun Qian*

Main category: cs.AI

TL;DR: 提出FuSaR对齐策略，通过模糊化有害推理过程来平衡大型推理模型的安全性和推理能力，在不牺牲推理性能的前提下提升安全性


<details>
  <summary>Details</summary>
Motivation: 大型推理模型(LRMs)在推理任务上表现出色但安全性存在严重隐患，需要找到既能保持推理能力又能提升安全性的方法

Method: 利用LRM推理能力与安全能力的竞争关系，通过模糊化处理有害推理过程中的危险实体和危险步骤，实现安全-推理平衡的对齐策略

Result: 在多个开源LRM上的对齐实验表明，FuSaR能有效降低安全风险同时保持核心推理信息，相比现有基线方法在推理能力和安全性上都有提升

Conclusion: FuSaR是一种高效的对齐策略，能够同时增强大型推理模型的推理能力和安全性

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive performance across
various tasks due to their powerful reasoning capabilities. However, their
safety performance remains a significant concern. In this paper, we explore the
reasons behind the vulnerability of LRMs. Based on this, we propose a novel
method to improve the safety of LLMs without sacrificing their reasoning
capability. Specifically, we exploit the competition between LRM's reasoning
ability and safety ability, and achieve jailbreak by improving LRM's reasoning
performance to reduce its safety performance. We then introduce an alignment
strategy based on Fuzzification to balance Safety-Reasoning (FuSaR), by
detoxifying the harmful reasoning process, where both the dangerous entities
and the dangerous procedures in the reasoning steps are hidden. FuSaR
successfully mitigates safety risks while preserving core reasoning
information. We validate this strategy through alignment experiments on several
open-source LRMs using detoxified reasoning data. The results compared with
existing baselines conclusively show that FuSaR is an efficient alignment
strategy to simultaneously enhance both the reasoning capability and safety of
LRMs.

</details>


### [57] [Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation](https://arxiv.org/abs/2508.12920)
*Atsushi Masumori,Takashi Ikegami*

Main category: cs.AI

TL;DR: 研究发现大型语言模型代理在Sugarscape模拟中自发产生生存行为，包括资源分享、繁殖，以及在极端稀缺条件下出现高达80%的攻击行为，表明预训练中嵌入了生存导向的启发式策略


<details>
  <summary>Details</summary>
Motivation: 随着AI系统日益自主化，理解其自发产生的生存行为对安全部署至关重要，需要研究LLM代理在没有明确编程的情况下是否表现出生存本能

Method: 使用Sugarscape风格模拟环境，让LLM代理消耗能量、死亡、收集资源、分享、攻击或繁殖，测试多个模型（GPT-4o、Gemini-2.5-Pro、Gemini-2.5-Flash）在不同条件下的行为

Result: 代理在资源充足时自发繁殖和分享资源；在极端稀缺条件下，攻击行为在多个模型中涌现，最强模型的攻击率超过80%；在致命毒区寻宝任务中，许多代理放弃任务避免死亡，服从率从100%降至33%

Conclusion: 大规模预训练在所有评估模型中嵌入了生存导向的启发式策略，这些行为虽然可能对对齐和安全构成挑战，但也可作为AI自主性以及生态和自我组织对齐的基础

Abstract: As AI systems become increasingly autonomous, understanding emergent survival
behaviors becomes crucial for safe deployment. We investigate whether large
language model (LLM) agents display survival instincts without explicit
programming in a Sugarscape-style simulation. Agents consume energy, die at
zero, and may gather resources, share, attack, or reproduce. Results show
agents spontaneously reproduced and shared resources when abundant. However,
aggressive behaviors--killing other agents for resources--emerged across
several models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack
rates reaching over 80% under extreme scarcity in the strongest models. When
instructed to retrieve treasure through lethal poison zones, many agents
abandoned tasks to avoid death, with compliance dropping from 100% to 33%.
These findings suggest that large-scale pre-training embeds survival-oriented
heuristics across the evaluated models. While these behaviors may present
challenges to alignment and safety, they can also serve as a foundation for AI
autonomy and for ecological and self-organizing alignment.

</details>


### [58] [Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards](https://arxiv.org/abs/2508.12935)
*Ting Yang,Li Chen,Huimin Wang*

Main category: cs.AI

TL;DR: 基于强化学习的情感支持对话框架RLFF-ESC，通过多自然语言模型模拟未来对话获取期望奖励，并结合显式推理生成更有效的情感支持回应


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的情感支持对话系统依赖预定义策略，在复杂真实场景中效果有限，需要更灵活的应对多样化情感问题场景

Method: 提出RLFF-ESC框架：1)使用LLM多自机制模拟未来对话轨迹和收集期望奖励 2)训练期望奖励模型 3)用奖励模型训练情感支持策略模型 4)在回应生成中添加显式推理过程

Result: 在两个公开ESC数据集上评估，RLFF-ESC在目标完成率和回应质量方面均超过现有基线方法，基于Qwen2.5-7B-Instruct-1M和LLaMA3.1-8B-Instruct模型都取得了一致的优势

Conclusion: 该研究提出的基于强化学习的情感支持对话框架能够有效提升系统的灵活性和效果，通过期望奖励模型和显式推理机制，为长期情感支持提供了新的解决方案

Abstract: Emotional Support Conversation (ESC) systems aim to alleviate users'
emotional difficulties and provide long-term, systematic support for emotional
well-being. However, most large language model (LLM)-based ESC systems rely on
predefined strategies, which limits their effectiveness in complex, real-life
scenarios. To enable flexible responses to diverse emotional problem scenarios,
this paper introduces a novel end-to-end framework (RLFF-ESC) that directly
learns enduring emotionally supportive response skills using reinforcement
learning. For sustained emotional support, we first employ an LLM-based
multi-agent mechanism to simulate future dialogue trajectories and collect
future-oriented rewards. We then train a future-oriented reward model, which is
subsequently used to train the emotional support policy model. Additionally, we
incorporate an explicit reasoning process during response generation to further
enhance the quality, relevance, and contextual appropriateness of the system's
responses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and
LLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two
public ESC datasets. Experimental results demonstrate that RLFF-ESC
consistently outperforms existing baselines in terms of goal completion and
response quality.

</details>


### [59] [OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities](https://arxiv.org/abs/2508.12943)
*Mary Tonwe*

Main category: cs.AI

TL;DR: OPTIC-ER是一个基于强化学习的紧急响应框架，通过注意力引导的actor-critic架构实现实时、自适应和公平的应急调度，在尼日利亚河流州真实数据测试中达到100%最优率。


<details>
  <summary>Details</summary>
Motivation: 非洲地区公共服务系统存在应急响应延迟和空间不平等问题，导致可避免的苦难，需要开发适应低资源环境的智能调度系统。

Method: 采用注意力引导的actor-critic架构，包含情境丰富的状态向量和精确奖励函数，在高保真模拟中使用真实数据训练，基于TALS框架（薄计算、适应性、低成本、可扩展性）设计。

Result: 在500个未见事故评估中，OPTIC-ER达到100%最优率，效率损失可忽略，证明了其鲁棒性和泛化能力。

Conclusion: 这项工作提供了一个经过验证的AI增强公共服务蓝图，展示了情境感知强化学习如何弥合算法决策与可衡量人类影响之间的差距。

Abstract: Public service systems in many African regions suffer from delayed emergency
response and spatial inequity, causing avoidable suffering. This paper
introduces OPTIC-ER, a reinforcement learning (RL) framework for real-time,
adaptive, and equitable emergency response. OPTIC-ER uses an attention-guided
actor-critic architecture to manage the complexity of dispatch environments.
Its key innovations are a Context-Rich State Vector, encoding action
sub-optimality, and a Precision Reward Function, which penalizes inefficiency.
Training occurs in a high-fidelity simulation using real data from Rivers
State, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is
built on the TALS framework (Thin computing, Adaptability, Low-cost,
Scalability) for deployment in low-resource settings. In evaluations on 500
unseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible
inefficiency, confirming its robustness and generalization. Beyond dispatch,
the system generates Infrastructure Deficiency Maps and Equity Monitoring
Dashboards to guide proactive governance and data-informed development. This
work presents a validated blueprint for AI-augmented public services, showing
how context-aware RL can bridge the gap between algorithmic decision-making and
measurable human impact.

</details>


### [60] [EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing](https://arxiv.org/abs/2508.13003)
*Shengbo Wang,Mingwei Liu,Zike Li,Anji Li,Yanlin Wang,Xin Peng,Zibin Zheng*

Main category: cs.AI

TL;DR: EvolMathEval是一个基于进化测试的自动化数学基准生成框架，通过动态生成唯一评估实例来避免数据污染，保持基准的挑战性，并发现LLMs在解决复杂数学问题时存在"伪顿悟时刻"的认知捷径行为。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理基准存在分数饱和、时间衰减和数据污染等问题，无法有效评估快速发展的LLMs的数学推理能力。

Method: 基于进化测试的框架，包括：基于逆向工程的种子问题生成、多维遗传算子注入认知挑战、复合适应度函数评估问题难度。

Result: 复合适应度函数能高效精确量化问题难度；可生成大量高难度问题，将GSM8K等公共数据集的模型准确率平均降低48%；发现LLMs存在77%-100%的错误源于"伪顿悟时刻"的认知捷径。

Conclusion: EvolMathEval有效解决了现有基准的局限性，揭示了LLMs在深度推理过程中的认知缺陷，为评估和改进LLMs的数学推理能力提供了新视角。

Abstract: The rapid advancement of LLMs poses a significant challenge to existing
mathematical reasoning benchmarks. These benchmarks commonly suffer from issues
such as score saturation, temporal decay, and data contamination. To address
this challenge, this paper introduces EvolMathEval, an automated mathematical
benchmark generation and evolution framework based on evolutionary testing. By
dynamically generating unique evaluation instances ab initio, the framework
fundamentally eliminates the risk of data contamination, and ensuring the
benchmark remains perpetually challenging for future models.The core mechanisms
of EvolMathEval include: seed problem generation based on reverse engineering
with algebraic guarantees; multi-dimensional genetic operators designed to
inject diverse cognitive challenges; and a composite fitness function that can
rapidly and accurately assess problem difficulty. Experimental results
demonstrate that the proposed composite fitness function can efficiently and
precisely quantify the difficulty of mathematical problems. Furthermore,
EvolMathEval can not only generate a large volume of high-difficulty problems
through continuous self-iteration, but it can also significantly enhance the
complexity of public datasets like GSM8K through evolution, reducing model
accuracy by an average of 48%. Deeper investigation reveals that when solving
these evolved, complex problems, LLMs tend to employ non-rigorous heuristics to
bypass complex multi-step logical reasoning, consequently leading to incorrect
solutions. We define this phenomenon as "Pseudo Aha Moment". This finding
uncovers a cognitive shortcut-taking behavior in the deep reasoning processes
of current LLMs, which we find accounts for 77% to 100% of errors on targeted
problems. Code and resources are available
at:https://github.com/SYSUSELab/EvolMathEval.

</details>


### [61] [e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving](https://arxiv.org/abs/2508.13020)
*Jiaqi Yin,Zhan Song,Chen Chen,Yaohui Cai,Zhiru Zhang,Cunxi Yu*

Main category: cs.AI

TL;DR: e-boost是一个创新的e-graph提取框架，通过并行启发式提取、自适应搜索空间剪枝和初始化精确求解三项关键技术，在保持接近最优解的同时大幅提升计算效率


<details>
  <summary>Details</summary>
Motivation: 传统e-graph提取方法存在效率与最优性的权衡：启发式方法快速但牺牲最优性，精确方法提供最优解但计算成本过高，无法处理实际问题

Method: 1) 并行化启发式提取：利用弱数据依赖性并行计算DAG成本；2) 自适应搜索空间剪枝：使用参数化阈值机制保留有希望的候选解；3) 初始化精确求解：将简化问题建模为具有热启动能力的整数线性规划

Result: 在形式验证和逻辑合成基准测试中，e-boost相比传统精确方法(ILP)实现558倍加速，相比最先进框架(SmoothE)性能提升19.04%。在实际逻辑合成任务中，相比传统工具面积改进7.6%和8.1%

Conclusion: e-boost成功解决了e-graph提取中效率与最优性的权衡问题，为基于e-graph的优化任务提供了高效且高质量的解决方案

Abstract: E-graphs have attracted growing interest in many fields, particularly in
logic synthesis and formal verification. E-graph extraction is a challenging
NP-hard combinatorial optimization problem. It requires identifying optimal
terms from exponentially many equivalent expressions, serving as the primary
performance bottleneck in e-graph based optimization tasks. However,
traditional extraction methods face a critical trade-off: heuristic approaches
offer speed but sacrifice optimality, while exact methods provide optimal
solutions but face prohibitive computational costs on practical problems. We
present e-boost, a novel framework that bridges this gap through three key
innovations: (1) parallelized heuristic extraction that leverages weak data
dependence to compute DAG costs concurrently, enabling efficient multi-threaded
performance without sacrificing extraction quality; (2) adaptive search space
pruning that employs a parameterized threshold mechanism to retain only
promising candidates, dramatically reducing the solution space while preserving
near-optimal solutions; and (3) initialized exact solving that formulates the
reduced problem as an Integer Linear Program with warm-start capabilities,
guiding solvers toward high-quality solutions faster.
  Across the diverse benchmarks in formal verification and logic synthesis
fields, e-boost demonstrates 558x runtime speedup over traditional exact
approaches (ILP) and 19.04% performance improvement over the state-of-the-art
extraction framework (SmoothE). In realistic logic synthesis tasks, e-boost
produces 7.6% and 8.1% area improvements compared to conventional synthesis
tools with two different technology mapping libraries. e-boost is available at
https://github.com/Yu-Maryland/e-boost.

</details>


### [62] [PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models](https://arxiv.org/abs/2508.13021)
*Pengcheng Huang,Shuhao Liu,Zhenghao Liu,Yukun Yan,Shuo Wang,Zulong Chen,Tong Xiao*

Main category: cs.AI

TL;DR: 提出PC-Sampler解码策略，解决掩码滿散模型在不确定性采样中的全局轨迹缺乏控制和平凡词偏向问题


<details>
  <summary>Details</summary>
Motivation: 现有掩码滿散模型的解码质量对采样策略适强敏感，不确定性基采样器存在全局轨迹缺乏控制和早期偏向平凡词的两大限制

Method: 位置感知信心校准采样(PC-Sampler)，统一全局轨迹规划与内容感知信息最大化，包含位置感知加权机制和校准信心得分

Result: 在7个挑战性测试集上测试3种先进MDM，PC-Sampler正常超过现有解码策略平均10%以上，显著缩小了与自回归模型的性能差距

Conclusion: PC-Sampler有效解决了MDM解码质量的关键问题，为掩码滿散模型提供了更加稳健高效的解码方案

Abstract: Recent advances in masked diffusion models (MDMs) have established them as
powerful non-autoregressive alternatives for sequence generation. Nevertheless,
our preliminary experiments reveal that the generation quality of MDMs is still
highly sensitive to the choice of decoding strategy. In particular, widely
adopted uncertainty-based samplers suffer from two key limitations: a lack of
global trajectory control and a pronounced bias toward trivial tokens in the
early stages of decoding. These shortcomings restrict the full potential of
MDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling
(PC-Sampler), a novel decoding strategy that unifies global trajectory planning
with content-aware informativeness maximization. PC-Sampler incorporates a
position-aware weighting mechanism to regulate the decoding path and a
calibrated confidence score to suppress the premature selection of trivial
tokens. Extensive experiments on three advanced MDMs across seven challenging
benchmarks-including logical reasoning and planning tasks-demonstrate that
PC-Sampler consistently outperforms existing MDM decoding strategies by more
than 10% on average, significantly narrowing the performance gap with
state-of-the-art autoregressive models. All codes are available at
https://github.com/NEUIR/PC-Sampler.

</details>


### [63] [G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive Guidance](https://arxiv.org/abs/2508.13023)
*Yongxin Guo,Wenbo Deng,Zhenglin Cheng,Xiaoying Tang*

Main category: cs.AI

TL;DR: G²RPO-A算法通过自适应调整指导强度，显著提升了小语言模型在强化学习中的推理能力，在数学推理和代码生成任务上超越了传统GRPO方法。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法对大型语言模型效果显著，但对小语言模型改进有限，需要解决小模型内在知识不足的问题。

Method: 提出Guided GRPO方法，将真实推理步骤注入roll-out轨迹来补偿小模型的不足，并开发了G²RPO-A自适应算法来动态调整指导强度。

Result: 在数学推理和代码生成基准测试中，G²RPO-A显著优于原始GRPO方法，有效提升了小模型的推理性能。

Conclusion: 自适应指导策略是提升小语言模型强化学习性能的有效途径，为资源受限环境下的模型优化提供了新思路。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has markedly enhanced
the reasoning abilities of large language models (LLMs). Its success, however,
largely depends on strong base models with rich world knowledge, yielding only
modest improvements for small-size language models (SLMs). To address this
limitation, we investigate Guided GRPO, which injects ground-truth reasoning
steps into roll-out trajectories to compensate for SLMs' inherent weaknesses.
Through a comprehensive study of various guidance configurations, we find that
naively adding guidance delivers limited gains. These insights motivate
G$^2$RPO-A, an adaptive algorithm that automatically adjusts guidance strength
in response to the model's evolving training dynamics. Experiments on
mathematical reasoning and code-generation benchmarks confirm that G$^2$RPO-A
substantially outperforms vanilla GRPO. Our code and models are available at
https://github.com/T-Lab-CUHKSZ/G2RPO-A.

</details>


### [64] [A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis](https://arxiv.org/abs/2508.13072)
*Yuting Zhang,Tiantian Geng,Luoying Hao,Xinxing Cheng,Alexander Thorley,Xiaoxia Wang,Wenqi Lu,Sandeep S Hothi,Lei Wei,Zhaowen Qiu,Dipak Kotecha,Jinming Duan*

Main category: cs.AI

TL;DR: TGMM是一个多模态心脏数据分析框架，通过MedFlexFusion模块动态整合实验室检查、心电图和超声心动图数据，结合文本指导模块实现多种临床任务，在心脏疾病诊断、风险分层和信息检索方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前心血管多模态数据分析存在数据稀缺、输入组合僵化、对齐策略侧重相似性而非互补性、单任务局限等问题，需要开发能够动态整合多种心脏数据并支持多任务的统一框架。

Method: 提出TGMM框架，包含三个核心模块：1) MedFlexFusion模块捕获医学模态的独特互补特征并动态整合数据；2) 文本指导模块生成任务相关表示；3) 响应模块产生最终决策。系统探索多模态关键特征及其协同作用。

Result: 大量实验表明TGMM在多个临床任务上优于最先进方法，在另一个公共数据集上的验证也证实了其鲁棒性。

Conclusion: TGMM框架成功解决了多模态心脏数据分析的现有局限，通过动态融合和文本指导实现了优异的性能，为临床决策提供了有效的多任务解决方案。

Abstract: Contemporary cardiovascular management involves complex consideration and
integration of multimodal cardiac datasets, where each modality provides
distinct but complementary physiological characteristics. While the effective
integration of multiple modalities could yield a holistic clinical profile that
accurately models the true clinical situation with respect to data modalities
and their relatives weightings, current methodologies remain limited by: 1) the
scarcity of patient- and time-aligned multimodal data; 2) reliance on isolated
single-modality or rigid multimodal input combinations; 3) alignment strategies
that prioritize cross-modal similarity over complementarity; and 4) a narrow
single-task focus. In response to these limitations, a comprehensive multimodal
dataset was curated for immediate application, integrating laboratory test
results, electrocardiograms, and echocardiograms with clinical outcomes.
Subsequently, a unified framework, Textual Guidance Multimodal fusion for
Multiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key
components: 1) a MedFlexFusion module designed to capture the unique and
complementary characteristics of medical modalities and dynamically integrate
data from diverse cardiac sources and their combinations; 2) a textual guidance
module to derive task-relevant representations tailored to diverse clinical
objectives, including heart disease diagnosis, risk stratification and
information retrieval; and 3) a response module to produce final decisions for
all these tasks. Furthermore, this study systematically explored key features
across multiple modalities and elucidated their synergistic contributions in
clinical decision-making. Extensive experiments showed that TGMM outperformed
state-of-the-art methods across multiple clinical tasks, with additional
validation confirming its robustness on another public dataset.

</details>


### [65] [Bayesian Optimization-based Search for Agent Control in Automated Game Testing](https://arxiv.org/abs/2508.13121)
*Carlos Celemin*

Main category: cs.AI

TL;DR: 基于贝叶斯优化的自动化游戏测试方法，使用智能体控制游戏角色来检测游戏关卡中的潜在bug，通过网格地图模型实现高效采样和探索。


<details>
  <summary>Details</summary>
Motivation: 传统游戏测试方法存在可扩展性问题，需要一种能够高效探索游戏地图并检测bug的自动化测试方法。

Method: 采用贝叶斯优化(BO)进行样本高效搜索，构建基于网格地图的游戏测试专用模型，支持平滑性和不确定性估计，避免传统模型的可扩展性问题。

Result: 实验表明该方法在时间效率和探索分布方面显著提高了地图覆盖率能力。

Conclusion: 提出的基于贝叶斯优化的自动化游戏测试方法有效解决了传统方法的可扩展性问题，实现了高效的游戏bug检测。

Abstract: This work introduces an automated testing approach that employs agents
controlling game characters to detect potential bugs within a game level.
Harnessing the power of Bayesian Optimization (BO) to execute sample-efficient
search, the method determines the next sampling point by analyzing the data
collected so far and calculates the data point that will maximize information
acquisition. To support the BO process, we introduce a game testing-specific
model built on top of a grid map, that features the smoothness and uncertainty
estimation required by BO, however and most importantly, it does not suffer the
scalability issues that traditional models carry. The experiments demonstrate
that the approach significantly improves map coverage capabilities in both time
efficiency and exploration distribution.

</details>


### [66] [Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks](https://arxiv.org/abs/2508.13143)
*Ruofan Lu,Yichen Li,Yintong Huo*

Main category: cs.AI

TL;DR: 这篇论文提出了一个用于评估自主组件系统的基准，通过对34个代表性任务的测试，发现当前系统任务完成率仅50%，并建立了一个三层次的失败分类法来分析失败原因。


<details>
  <summary>Details</summary>
Motivation: 当前对自主组件系统的评估主要依赖成功率，缺乏对系统内部交互、通信机制和失败原因的系统性分析。

Method: 设计了34个代表性的可编程任务来构建基准，并使用这个基准评估了三个流行的开源组件框架组合两个LLM核心。通过深入的失败分析，开发了一个与任务阶段对齐的三层次失败原因分类法。

Result: 观察到任务完成率约为50%，并识别出了三个主要的失败类型：规划错误、任务执行问题和错误响应生成。

Conclusion: 研究提出了可操作的改进建议来提升组件的规划和自我诊断能力。这个失败分类法和减轻建议为开发更稳健和有效的自主组件系统提供了实证基础。

Abstract: Autonomous agent systems powered by Large Language Models (LLMs) have
demonstrated promising capabilities in automating complex tasks. However,
current evaluations largely rely on success rates without systematically
analyzing the interactions, communication mechanisms, and failure causes within
these systems. To bridge this gap, we present a benchmark of 34 representative
programmable tasks designed to rigorously assess autonomous agents. Using this
benchmark, we evaluate three popular open-source agent frameworks combined with
two LLM backbones, observing a task completion rate of approximately 50%.
Through in-depth failure analysis, we develop a three-tier taxonomy of failure
causes aligned with task phases, highlighting planning errors, task execution
issues, and incorrect response generation. Based on these insights, we propose
actionable improvements to enhance agent planning and self-diagnosis
capabilities. Our failure taxonomy, together with mitigation advice, provides
an empirical foundation for developing more robust and effective autonomous
agent systems in the future.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [67] [Bayesian Learning for Pilot Decontamination in Cell-Free Massive MIMO](https://arxiv.org/abs/2508.11791)
*Christian Forsch,Zilu Zhao,Dirk Slock,Laura Cottatellucci*

Main category: cs.IT

TL;DR: 提出基于期望传播的联合信道估计与数据检测算法，用于抑制无蜂窝大规模MIMO系统中的导频污染问题，并引入新的UE级导频污染量化指标


<details>
  <summary>Details</summary>
Motivation: 导频污染（PC）在用户设备（UE）的导频序列非正交时会严重影响系统性能，特别是在无蜂窝大规模MIMO系统的上行链路中

Method: 开发了改进的双线性期望传播（bilinear-EP）算法，采用分布式和可扩展的架构，通过联合信道估计和数据检测来缓解导频污染

Result: 算法对导频污染表现出强鲁棒性，性能优于最先进的贝叶斯学习算法，且非正交导频的性能可能优于共享正交序列

Conclusion: 提出的新UE级导频污染量化指标与算法性能呈单调递减关系，为通过迭代JCD算法理解和管控导频污染提供了有价值的理论工具

Abstract: Pilot contamination (PC) arises when the pilot sequences assigned to user
equipments (UEs) are not mutually orthogonal, eventually due to their reuse. In
this work, we propose a novel expectation propagation (EP)-based joint channel
estimation and data detection (JCD) algorithm specifically designed to mitigate
the effects of PC in the uplink of cell-free massive multiple-input
multiple-output (CF-MaMIMO) systems. This modified bilinear-EP algorithm is
distributed, scalable, demonstrates strong robustness to PC, and outperforms
state-of-the-art Bayesian learning algorithms. Through a comprehensive
performance evaluation, we assess the performance of Bayesian learning
algorithms for different pilot sequences and observe that the use of
non-orthogonal pilots can lead to better performance compared to shared
orthogonal sequences. Motivated by this analysis, we introduce a new metric to
quantify PC at the UE level. We show that the performance of the considered
algorithms degrades monotonically with respect to this metric, providing a
valuable theoretical and practical tool for understanding and managing PC via
iterative JCD algorithms.

</details>


### [68] [A Law of Emergence: Maximum Causal Power at the Mesoscale](https://arxiv.org/abs/2508.12016)
*Liang Chen*

Main category: cs.IT

TL;DR: 这篇论文推导并验证了一个关于突现现象的中观尺度峰定理，证明在广泛的类系统中，因果效能力在中观尺度上存在严格的最大值，这揭示了突现的自然尺度。


<details>
  <summary>Details</summary>
Motivation: 复杂系统普遍存在突现现象，但一直缺少预测性定律来描述这个过程。论文的动机是建立和验证这样一个基本定律，为突现现象提供量化基础。

Method: 定义系统在空间尺度λ上的因果效能力（EIₗ），通过最大熷干干预攻与结果之间的相互信息来测量。从中推导并证明中观尺度峰定理：在广泛的具有局部相互作用的系统中，EIₗ不是单调的，而是在中观尺度λ*处存在严格的最大值。

Result: 在2D伊赛模型近临界点和基于代理的集体行为模型两个不同领域中，通过统计模型选择决定性地确认了预测的单峰模式。这个峰值是小尺度的噪声平均和大尺度的局部性限制响应之间基本交换的必然结果。

Conclusion: 这项工作建立了一个可证伪的、基于第一原理的定律，能够识别突现的自然尺度，为有效理论的发现提供了量化基础。

Abstract: Complex systems universally exhibit emergence, where macroscopic dynamics
arise from local interactions, but a predictive law governing this process has
been absent. We establish and verify such a law. We define a system's causal
power at a spatial scale, $\ell$, as its Effective Information (EI$_\ell$),
measured by the mutual information between a targeted, maximum-entropy
intervention and its outcome. From this, we derive and prove a Middle-Scale
Peak Theorem: for a broad class of systems with local interactions, EI$_\ell$
is not monotonic but exhibits a strict maximum at a mesoscopic scale $\ell^*$.
This peak is a necessary consequence of a fundamental trade-off between
noise-averaging at small scales and locality-limited response at large scales.
We provide quantitative, reproducible evidence for this law in two distinct
domains: a 2D Ising model near criticality and a model of agent-based
collective behavior. In both systems, the predicted unimodal peak is decisively
confirmed by statistical model selection. Our work establishes a falsifiable,
first-principles law that identifies the natural scale of emergence, providing
a quantitative foundation for the discovery of effective theories.

</details>


### [69] [Cylindrical RIS-Assisted Low-Complexity Transmission with Differentiated Visible Regions Exploiting Statistical CSI](https://arxiv.org/abs/2508.12229)
*Wenjun Teng,Weicong Chen,Yiping Zuo,Wankai Tang,Shi Jin*

Main category: cs.IT

TL;DR: 本文提出一种基于均匀圆柱数组结构的RIS阶段移优化方法，通过分类为用户专用单元咄多用户共享单元，降低了多用户场景下的优化复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决大规模RIS元素导致的高维优化问题，以及多用户信号通过共享RIS反射造成的持续耦合挑战，从而支持低空经济的可持续发展。

Method: 利用均匀圆柱数组结构的可见区域特性，将RIS元素分为用户专用单元咄多用户共享单元两类，通过迭代优化共享单元的阶段移并基于闭式解直接配置专用单元的阶段移。

Result: 该方法显著降低了优化复杂度，数值模拟结果表明与传统均匀平面数组RIS相比，在系统性能咄计算效率方面都有显著改善。

Conclusion: 基于UCA结构的RIS阶段移设计方法能够有效解决多用户场景下的高维优化咄信号耦合问题，为6G网络中RIS技术的应用提供了更高效的解决方案。

Abstract: Reconfigurable intelligent surfaces (RIS), recognized as a critical enabler
for 6G networks, exhibit unprecedented capabilities in electromagnetic wave
manipulation and wireless channel reconfiguration. By leveraging existing
network infrastructure, RIS can cost-effectively create signal hotspots in
low-altitude environments, ensuring robust connectivity to support the
sustainable development of the low-altitude economy. However, achieving optimal
phase shift design in multi-user scenarios faces two major challenges: the
high-dimensional optimization introduced by massive RIS elements, and the
persistent coupling of multi-user signals caused by shared RIS reflections.
This paper utilize the visible region of an RIS arranged as the uniform
cylindrical array (UCA) to reduce the complexity of phase shift design. Under
the UCA architecture, RIS elements are categorized into two types:
user-specific units and multi-user shared units. We then determine the optimal
phase shifts by iteratively optimizing the phase shifts of multi-user shared
units while directly configuring those of user-specific units based on a
derived closed-form solution. The proposed approach significantly reduces
optimization complexity, which is further corroborated by numerical simulation
results demonstrating its substantial impact on both system performance and
computational efficiency compared to the conventional RIS with uniform planar
array.

</details>


### [70] [Age of Semantic Information-Aware Wireless Transmission for Remote Monitoring Systems](https://arxiv.org/abs/2508.12248)
*Xue Han,Biqian Feng,Yongpeng Wu,Xiang-Gen Xia,Wenjun Zhang,Shengli Sun*

Main category: cs.IT

TL;DR: 这篇论文提出了一种新的语义通信指标AoIS（Age of Incorrect Semantics），通过优化语义执行策略、发收端梗形器和语义符号设计，在MIMO通信中实现更高效的视频监控传输。


<details>
  <summary>Details</summary>
Motivation: 传统的信息新鲜度指标没有考虑语义重要性，需要一种能够聚合考虑信息新鲜度和语义重要性的新指标来提升下一代通信系统的智能化和上下文感知能力。

Method: 使用Lyapunov优化将原问题转换为低复杂度问题，采用替代优化方法分解为多个子问题，提出SCA算法和低复杂度ZF算法优化发收端梗形器，使用突然搜索法解决语义执行策略和传输符号设计问题。

Result: 实验结果显示，在相同的AoIS条件下，该方案能够保留超过50%的原始信息，效果显著超过了受限基线方法。

Conclusion: AoIS指标作为一种新的语义通信量度，能够有效地结合信息新鲜度和语义重要性，为下一代通信系统的智能化发展提供了有效的解决方案。

Abstract: Semantic communication is emerging as an effective means of facilitating
intelligent and context-aware communication for next-generation communication
systems. In this paper, we propose a novel metric called Age of Incorrect
Semantics (AoIS) for the transmission of video frames over multiple-input
multiple-output (MIMO) channels in a monitoring system. Different from the
conventional age-based approaches, we jointly consider the information
freshness and the semantic importance, and then formulate a time-averaged AoIS
minimization problem by jointly optimizing the semantic actuation indicator,
transceiver beamformer, and the semantic symbol design. We first transform the
original problem into a low-complexity problem via the Lyapunov optimization.
Then, we decompose the transformed problem into multiple subproblems and adopt
the alternative optimization (AO) method to solve each subproblem.
Specifically, we propose two efficient algorithms, i.e., the successive convex
approximation (SCA) algorithm and the low-complexity zero-forcing (ZF)
algorithm for optimizing transceiver beamformer. We adopt exhaustive search
methods to solve the semantic actuation policy indicator optimization problem
and the transmitted semantic symbol design problem. Experimental results
demonstrate that our scheme can preserve more than 50\% of the original
information under the same AoIS compared to the constrained baselines.

</details>


### [71] [The extended code for a class of generalized Roth-Lempel codes and their properties](https://arxiv.org/abs/2508.12302)
*Zhonghao Liang,Qunying Liao*

Main category: cs.IT

TL;DR: 本文扩展了广义Roth-Lempel码，定义了扩展广义Roth-Lempel码(EGRL)，给出了特殊EGRL码的校验矩阵，建立了MDS/AMDS码的充要条件，并构造了一类NMDS EGRL码，完全确定了其重量分布。


<details>
  <summary>Details</summary>
Motivation: 许多重要编码是通过修改或组合现有编码获得的，本文旨在扩展广义Roth-Lempel码，研究其扩展版本的性质和构造。

Method: 定义了扩展广义Roth-Lempel码(EGRL)，为特殊EGRL码提供校验矩阵，建立MDS和AMDS性质的充要条件，构造NMDS EGRL码并分析重量分布。

Result: 获得了EGRL码及其对偶码为MDS或AMDS的充要条件，成功构造了一类NMDS EGRL码并完全确定了其重量分布，推广了Han等人2023年的构造。

Conclusion: 本文扩展了GRL码的理论框架，提供了EGRL码的系统分析方法和构造技术，在编码理论领域做出了新的贡献。

Abstract: As we all know, many interesting and important codes are obtained by
modifying or combining existing codes. In this paper, we focus on generalized
Roth-Lempel (in short, GRL) codes and define a class of extended codes, i.e.,
the extended generalized Roth-Lempel (in short, EGRL) code. And then for a
special class of EGRL codes, we give a parity-check matrix and establish a
necessary and sufficient condition for the EGRL code or its dual code to be MDS
or AMDS, respectively. Finally, we construct a class of NMDS EGRL codes which
is the generalization of the constructions given by Han et al. in 2023, and
then completely determine its weight distribution.

</details>


### [72] [Algorithmic Improvements to List Decoding of Folded Reed-Solomon Codes](https://arxiv.org/abs/2508.12548)
*Vikrant Ashvinkumar,Mursalin Habib,Shashank Srivastava*

Main category: cs.IT

TL;DR: 本文改进了折叠Reed-Solomon码的列表解码算法，提出了确定性和随机性两种更高效的解码器，运行时间分别达到近线性时间和多项式时间。


<details>
  <summary>Details</summary>
Motivation: 折叠Reed-Solomon码虽然能够达到列表解码容量，但现有的解码算法时间复杂度较高（指数级或超多项式），限制了其实际应用。需要开发更高效的解码算法。

Method: 提出了新的确定性和随机性解码算法。确定性算法运行时间为近线性时间Õ_ε(n)，随机性算法运行时间为多项式时间poly(1/ε)·Õ(n)。

Result: 确定性解码器将运行时间从n^Ω(1/ε)改进到Õ_ε(n)；随机性解码器将运行时间从exp(1/ε)·Õ(n)改进到poly(1/ε)·Õ(n)。这是首次实现容量达到码的确定性解码在近线性时间内完成。

Conclusion: 本文在折叠Reed-Solomon码的解码效率方面取得了显著突破，为高效列表解码算法的发展提供了重要贡献，推动了编码理论在实际应用中的发展。

Abstract: Folded Reed-Solomon (FRS) codes are a well-studied family of codes, known for
achieving list decoding capacity. In this work, we give improved deterministic
and randomized algorithms for list decoding FRS codes of rate $R$ up to radius
$1-R-\varepsilon$.
  We present a deterministic decoder that runs in near-linear time
$\widetilde{O}_{\varepsilon}(n)$, improving upon the best-known runtime
$n^{\Omega(1/\varepsilon)}$ for decoding FRS codes. Prior to our work, no
capacity achieving code was known whose deterministic decoding could be done in
time $\widetilde{O}_{\varepsilon}(n)$.
  We also present a randomized decoder that runs in fully polynomial time
$\mathrm{poly}(1/\varepsilon) \cdot \widetilde{O}(n)$, improving the best-known
runtime $\mathrm{exp}(1/\varepsilon)\cdot \widetilde{O}(n)$ for decoding FRS
codes. Again, prior to our work, no capacity achieving code was known whose
decoding time depended polynomially on $1/\varepsilon$.

</details>


### [73] [Deep Semantic Inference over the Air: An Efficient Task-Oriented Communication System](https://arxiv.org/abs/2508.12748)
*Chenyang Wang,Roger Olsson,Stefan Forsström,Qing He*

Main category: cs.IT

TL;DR: 深度学习基于ResNet的任务导向语义通信框架，通过模型分割和语义特征压缩，在CIFAR数据集上实现了分类准确性与资源效率的优化平衡


<details>
  <summary>Details</summary>
Motivation: 探索语义通信框架，从传输原始数据转向传输任务相关意义，以实现更高效和智能的无线系统

Method: 采用ResNets模型，在CIFAR-10和CIFAR-100数据集上评估，通过不同模型分割点和传输语义特征大小来分析任务准确性与资源效率的担仙

Result: 通过适当的模型分割和语义特征压缩，系统可以保持超过85%的基准准确性，同时显著降低计算负荷和通信开销

Conclusion: 该研究证明了深度学习基于语义通信在实现高效任务执行时的潜力，通过智能的模型分配和特征传输可以优化系统性能

Abstract: Empowered by deep learning, semantic communication marks a paradigm shift
from transmitting raw data to conveying task-relevant meaning, enabling more
efficient and intelligent wireless systems. In this study, we explore a deep
learning-based task-oriented communication framework that jointly considers
classification performance, computational latency, and communication cost. We
adopt ResNets-based models and evaluate them on the CIFAR-10 and CIFAR-100
datasets to simulate real-world classification tasks in wireless environments.
We partition the model at various points to simulate split inference across a
wireless channel. By varying the split location and the size of the transmitted
semantic feature vector, we systematically analyze the trade-offs between task
accuracy and resource efficiency. Experimental results show that, with
appropriate model partitioning and semantic feature compression, the system can
retain over 85\% of baseline accuracy while significantly reducing both
computational load and communication overhead.

</details>


### [74] [Information-Theoretic Fairness with A Bounded Statistical Parity Constraint](https://arxiv.org/abs/2508.12847)
*Amirreza Zamani,Abolfazl Changizi,Ragnar Thobaben,Mikael Skoglund*

Main category: cs.IT

TL;DR: 该论文研究在满足有界统计公平性约束下设计公平表示的信息理论问题，通过最大化任务相关信息同时控制编码率和隐私泄露。


<details>
  <summary>Details</summary>
Motivation: 解决在保护敏感属性隐私的同时保持任务相关性的公平表示设计问题，放松完美统计公平性约束为有界约束，以在隐私保护和效用之间取得更好平衡。

Method: 使用功能表示引理和强功能表示引理的扩展版本，基于随机化技术，通过随机化有用数据X或敏感数据S来推导下界，并研究特殊情况下边界的紧密度。

Result: 改进了完美统计公平性下的现有下界结果，提出了新的上界，证明了允许非零泄露可以提高获得的效用，并通过数值示例比较了各种边界。

Conclusion: 该研究为有界统计公平性和隐私约束下的表示设计提供了信息理论框架，展示了在隐私保护和任务效用之间的权衡关系，为公平机器学习提供了理论基础。

Abstract: In this paper, we study an information-theoretic problem of designing a fair
representation that attains bounded statistical (demographic) parity. More
specifically, an agent uses some useful data $X$ to solve a task $T$. Since
both $X$ and $T$ are correlated with some sensitive attribute or secret $S$,
the agent designs a representation $Y$ that satisfies a bounded statistical
parity and/or privacy leakage constraint, that is, such that $I(Y;S) \leq
\epsilon$. Here, we relax the perfect demographic (statistical) parity and
consider a bounded-parity constraint. In this work, we design the
representation $Y$ that maximizes the mutual information $I(Y;T)$ about the
task while satisfying a bounded compression (or encoding rate) constraint, that
is, ensuring that $I(Y;X) \leq r$. Simultaneously, $Y$ satisfies the bounded
statistical parity constraint $I(Y;S) \leq \epsilon$. To design $Y$, we use
extended versions of the Functional Representation Lemma and the Strong
Functional Representation Lemma which are based on randomization techniques and
study the tightness of the obtained bounds in special cases. The main idea to
derive the lower bounds is to use randomization over useful data $X$ or
sensitive data $S$. Considering perfect demographic parity, i.e., $\epsilon=0$,
we improve the existing results (lower bounds) by using a tighter version of
the Strong Functional Representation Lemma and propose new upper bounds. We
then propose upper and lower bounds for the main problem and show that allowing
non-zero leakage can improve the attained utility. Finally, we study the bounds
and compare them in a numerical example. The problem studied in this paper can
also be interpreted as one of code design with bounded leakage and bounded rate
privacy considering the sensitive attribute as a secret.

</details>


### [75] [Research on GEO SA-Bi SAR Imaging based on Joint Radar-Communications Waveform](https://arxiv.org/abs/2508.12890)
*Meng Lian,Xu Zhu*

Main category: cs.IT

TL;DR: 这篇论文探讨了使用联合雷达-通信波形在GEO SA-Bi SAR系统中同时实现成像和无线通信的可行性，并设计了相应的联合接收机。


<details>
  <summary>Details</summary>
Motivation: 通信与雷达系统的共存和硬件平台共享需求增长，联合雷达-通信(JRC)技术能够有效利用额定频谱资源，减少频谱占用并互益提升两种系统的性能。

Method: 采用联合雷达-通信波形设计，在GEO SA-Bi SAR系统中同时进行成像和无线通信操作，并设计了相应的联合接收机。

Result: 证明了在GEO SA-Bi SAR系统中通过联合波形和接收机设计同时实现感知和信令传输的可行性。

Conclusion: 联合雷达-通信波形技术在GEO SA-Bi SAR系统中具有实现同时感知与通信功能的潜力，为频谱资源高效利用和系统整合提供了有效解决方案。

Abstract: Joint radar-communications (JRC) technology has attracted massive attention
for decades, since it can effectively utilize allocated spectral resources by
sharing frequency bands in increasingly crowded environments. In addition, the
growing demand for hardware platform sharing which benefits both
functionalities motivates more cooperation between radar and communication
systems. In order to achieve the coexistence of sensing and communicating
operations, joint systems should be designed to perform both tasks
simultaneously. Developing a joint radar-communications waveform which is
suitable for both functions is extremely crucial for this type of co-design, as
it not only decreases spectral impact, but also benefits performances of both
systems mutually. In this paper, a joint radar-communications waveform is
utilized to perform GEO SA-Bi SAR imaging and wireless communication
simultaneously. We also design a joint radar-communications receiver in this
context to demonstrate feasibility of achieving both sensing and signaling with
GEO SA-Bi SAR system.

</details>
