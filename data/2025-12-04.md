<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 4]
- [cs.AI](#cs.AI) [Total: 17]
- [cs.IT](#cs.IT) [Total: 10]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Mobility Induced Sensitivity of UAV based Nodes to Jamming in Private 5G Airfield Networks An Experimental Study](https://arxiv.org/abs/2512.03536)
*Pavlo Mykytyn,Ronald Chitauro,Onur Yener,Peter Langendoerfer*

Main category: cs.NI

TL;DR: 该研究通过实验评估了在定向SDR干扰攻击下，无人机作为UE节点在私有5G机场网络中的性能表现，分析了信号退化、切换性能和服务稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估私有5G机场网络在面对定向干扰攻击时的鲁棒性，特别是在无人机作为移动用户设备节点的场景下，了解网络在对抗性环境中的性能表现。

Method: 使用搭载QualiPoc Android UE的四旋翼无人机，在受控的定向SDR干扰环境下进行实验，评估不同飞行速度、高度和移动模式对网络性能的影响，记录CQI、MCS、RSRP、SINR、BLER、吞吐量和RLF等关键指标。

Result: 实验结果揭示了无人机UE节点移动性水平对链路稳定性和信号退化的依赖关系，展示了在私有5G机场网络中自主和自动操作时的网络性能变化。

Conclusion: 该研究为私有5G机场网络在对抗性环境中的性能评估提供了实验数据，揭示了无人机移动性对网络稳定性的影响，对设计和部署抗干扰的5G网络具有参考价值。

Abstract: This work presents an experimental performance evaluation of a private 5G airfield network under controlled directional SDR jamming attacks targeting UAV-based UE nodes. Using a QualiPoc Android UE, mounted as a payload on a quadcopter UAV, we conducted a series of experiments to evaluate signal degradation, handover performance, and ser-vice stability in the presence of constant directional jamming. The conducted experiments aimed to examine the effects of varying travel speeds, altitudes, and moving patterns of a UAV-based UE to record and analyze the key physical-layer and network-layer metrics such as CQI, MCS, RSRP, SINR, BLER, Net PDSCH Throughput and RLF. The re-sults of this work describe the link stability and signal degradation dependencies, caused by the level of mobility of the UAV-based UE nodes during autonomous and automatic operation in private 5G Airfield networks

</details>


### [2] [Performance Evaluation of Parallel Wi-Fi Redundancy with Deferral Techniques](https://arxiv.org/abs/2512.03569)
*Gianluca Cena,Pietro Chiavassa,Stefano Scanzio*

Main category: cs.NI

TL;DR: 评估Wi-Fi并行冗余在工业无线通信中的性能，通过真实数据集分析其对软实时应用传输延迟的改善效果


<details>
  <summary>Details</summary>
Motivation: Wi-Fi在工业环境中应用日益广泛，但其可靠性常被认为不适合实时控制系统。本文旨在从定量角度评估并行冗余技术是否能改善Wi-Fi在工业环境中的实时性能

Method: 使用真实实验设置采集大量数据集，分析并行冗余对软实时应用相关性能指标的影响，特别关注延迟传输性能

Result: 延迟并行冗余在有限频谱消耗成本下，能显著改善最坏情况传输延迟，为无线控制环路提供实用解决方案

Conclusion: 并行冗余技术可有效提升Wi-Fi在工业环境中的实时性能，特别适用于包含无线连接的控制环路，具有实际应用价值

Abstract: Wireless communication is increasingly used in industrial environments, since it supports mobility of interconnected devices. Among the transmission technologies operating in unlicensed bands available to this purpose, Wi-Fi is certainly one of the most interesting, because of its high performance and the relatively low deployment costs. Unfortunately, its dependability is often deemed unsuitable for real-time control systems. In this paper, the use of parallel redundancy is evaluated from a quantitative viewpoint, by considering a number of performance indices that are relevant for soft real-time applications. Analysis is carried out on a large dataset acquired from a real setup, to provide realistic insights on the advantages this kind of approaches can provide. As will be seen, deferred parallel redundancy provides clear advantages in terms of the worst-case transmission latency, at limited costs concerning the amount of consumed spectrum. Hence, it can be practically exploited every time a wireless connection is included in a control loop.

</details>


### [3] [Machine Learning to Predict Slot Usage in TSCH Wireless Sensor Networks](https://arxiv.org/abs/2512.03570)
*Stefano Scanzio,Gabriele Formis,Tullio Facchinetti,Gianluca Cena*

Main category: cs.NI

TL;DR: 该论文提出使用机器学习学习TSCH协议网络的流量模式，通过预测空闲时段让节点进入深度睡眠状态，从而提高无线传感器网络的能效。


<details>
  <summary>Details</summary>
Motivation: 工业无线传感器网络需要超低功耗和确定性操作。TSCH协议能满足这两个要求，但仍有进一步节能的空间。通过机器学习预测网络流量模式，可以在无传输计划时让节点进入深度睡眠状态，从而进一步提高能效。

Method: 使用机器学习模型学习基于TSCH协议的网络的流量模式。在典型的树形网络拓扑中分析不同网络层级上机器学习模型的预测能力，研究模型性能随接近树根节点的变化情况。基于无线传感器节点的精确建模进行模拟数据验证。

Result: 分析表明机器学习模型在不同网络层级上都能做出良好预测，但其预测能力在接近树根节点时会逐渐下降。模拟结果显示所研究的算法能够显著降低TSCH网络的功耗。

Conclusion: 机器学习方法可以有效学习TSCH网络的流量模式，通过预测空闲时段让节点进入深度睡眠状态，从而进一步提高无线传感器网络的能量效率，特别是在工业应用中具有重要价值。

Abstract: Wireless sensor networks (WSNs) are employed across a wide range of industrial applications where ultra-low power consumption is a critical prerequisite. At the same time, these systems must maintain a certain level of determinism to ensure reliable and predictable operation. In this view, time slotted channel hopping (TSCH) is a communication technology that meets both conditions, making it an attractive option for its usage in industrial WSNs. This work proposes the use of machine learning to learn the traffic pattern generated in networks based on the TSCH protocol, in order to turn nodes into a deep sleep state when no transmission is planned and thus to improve the energy efficiency of the WSN. The ability of machine learning models to make good predictions at different network levels in a typical tree network topology was analyzed in depth, showing how their capabilities degrade while approaching the root of the tree. The application of these models on simulated data based on an accurate modeling of wireless sensor nodes indicates that the investigated algorithms can be suitably used to further and substantially reduce the power consumption of a TSCH network.

</details>


### [4] [Tutorial on Large Language Model-Enhanced Reinforcement Learning for Wireless Networks](https://arxiv.org/abs/2512.03722)
*Lingyi Cai,Wenjie Fu,Yuxi Huang,Ruichen Zhang,Yinqiu Liu,Jiawen Kang,Zehui Xiong,Tao Jiang,Dusit Niyato,Xianbin Wang,Shiwen Mao,Xuemin Shen*

Main category: cs.NI

TL;DR: 本文是关于LLM增强RL在无线网络中的综合教程，提出了LLM在RL中的四种角色分类，并通过案例研究展示了应用方法。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在无线网络动态环境中存在泛化能力不足、学习反馈有限、可解释性差和样本效率低等问题，而大语言模型在知识泛化、上下文推理和交互生成方面具有卓越能力，有望增强传统RL的性能。

Method: 提出一个分类法，将LLM在RL中的角色分为四种关键功能：状态感知器、奖励设计器、决策制定器和生成器。通过案例研究展示LLM增强RL在低空经济网络、车载网络和空天地一体化网络中的设计和应用方法。

Result: 建立了LLM增强RL的系统性框架，为无线网络中的自适应优化提供了新的解决方案。通过角色分类和案例研究，展示了LLM如何在不同阶段增强RL管道，为实际应用提供了指导。

Conclusion: LLM增强RL为无线网络优化提供了有前景的方向，未来需要进一步探索其在实际部署中的潜力，并讨论了该领域未来的发展方向。

Abstract: Reinforcement Learning (RL) has shown remarkable success in enabling adaptive and data-driven optimization for various applications in wireless networks. However, classical RL suffers from limitations in generalization, learning feedback, interpretability, and sample efficiency in dynamic wireless environments. Large Language Models (LLMs) have emerged as a transformative Artificial Intelligence (AI) paradigm with exceptional capabilities in knowledge generalization, contextual reasoning, and interactive generation, which have demonstrated strong potential to enhance classical RL. This paper serves as a comprehensive tutorial on LLM-enhanced RL for wireless networks. We propose a taxonomy to categorize the roles of LLMs into four critical functions: state perceiver, reward designer, decision-maker, and generator. Then, we review existing studies exploring how each role of LLMs enhances different stages of the RL pipeline. Moreover, we provide a series of case studies to illustrate how to design and apply LLM-enhanced RL in low-altitude economy networking, vehicular networks, and space-air-ground integrated networks. Finally, we conclude with a discussion on potential future directions for LLM-enhanced RL and offer insights into its future development in wireless networks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [5] [Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation](https://arxiv.org/abs/2512.03048)
*Austin Spizzirri*

Main category: cs.AI

TL;DR: 本文提出AI对齐应重新构想为通过过程性、多智能体、发展性机制构建具有熵减（syntropic）和理由响应能力的智能体，而非编码固定的人类价值内容。


<details>
  <summary>Details</summary>
Motivation: 传统基于内容的价值规范方法存在结构性不稳定问题，包括"是-应该"鸿沟、价值多元主义和扩展框架问题，这构成了"规范陷阱"，需要新的对齐框架。

Method: 提出三个哲学贡献：1) 阐述"规范陷阱"论证；2) 提出"熵减"作为理解多智能体对齐动态的信息论框架；3) 基于相容论的指导控制理论建立真实与模拟道德能力的功能区分，并设计具身实验范式和验证机制。

Result: 建立了新的AI对齐理论框架，生成关于人工系统中价值涌现和道德能动性的具体、可证伪预测，但实证验证仍在进行中。

Conclusion: AI对齐应从内容编码转向过程性、发展性机制，通过熵减和理由响应性构建真正的道德能力，这为AI对齐研究提供了新的哲学基础和方法论方向。

Abstract: I argue that AI alignment should be reconceived as architecting syntropic, reasons-responsive agents through process-based, multi-agent, developmental mechanisms rather than encoding fixed human value content. The paper makes three philosophical contributions. First, I articulate the ``specification trap'' argument demonstrating why content-based value specification appears structurally unstable due to the conjunction of the is-ought gap, value pluralism, and the extended frame problem. Second, I propose syntropy -- the recursive reduction of mutual uncertainty between agents through state alignment -- as an information-theoretic framework for understanding multi-agent alignment dynamics. Third, I establish a functional distinction between genuine and simulated moral capacity grounded in compatibilist theories of guidance control, coupled with an embodied experimental paradigm and verification regime providing operational criteria independent of phenomenological claims. This paper represents the philosophical component of a broader research program whose empirical validation is being developed in a separate project currently in preparation. While the framework generates specific, falsifiable predictions about value emergence and moral agency in artificial systems, empirical validation remains pending.

</details>


### [6] [Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI](https://arxiv.org/abs/2512.03072)
*Hu Keyi*

Main category: cs.AI

TL;DR: 提出基于第一性原理的"权重计算主义"认知架构，通过逻辑原子和基本操作实现可解释、可对齐的通用人工智能


<details>
  <summary>Details</summary>
Motivation: 当前AI范式在可解释性和价值对齐方面存在根本性挑战，需要一种新的认知架构来构建可信赖的通用人工智能

Method: 将认知解构为不可分割的逻辑原子和两个基本操作（指向和比较），通过可解释的权重计算模型（权重=收益×概率）形式化决策，所有值都可追溯到可审计的初始权重集

Result: 该架构实现了透明的类人推理和在新颖场景中的稳健学习，为构建可信赖和对齐的AGI奠定了实践和理论基础

Conclusion: 权重计算主义是基于第一性原理的可行AGI路径，通过原子分解实现根本可解释性、内在通用性和可追溯的价值对齐

Abstract: Current AI paradigms, as "architects of experience," face fundamental challenges in explainability and value alignment. This paper introduces "Weight-Calculatism," a novel cognitive architecture grounded in first principles, and demonstrates its potential as a viable pathway toward Artificial General Intelligence (AGI). The architecture deconstructs cognition into indivisible Logical Atoms and two fundamental operations: Pointing and Comparison. Decision-making is formalized through an interpretable Weight-Calculation model (Weight = Benefit * Probability), where all values are traceable to an auditable set of Initial Weights. This atomic decomposition enables radical explainability, intrinsic generality for novel situations, and traceable value alignment. We detail its implementation via a graph-algorithm-based computational engine and a global workspace workflow, supported by a preliminary code implementation and scenario validation. Results indicate that the architecture achieves transparent, human-like reasoning and robust learning in unprecedented scenarios, establishing a practical and theoretical foundation for building trustworthy and aligned AGI.

</details>


### [7] [When Do Symbolic Solvers Enhance Reasoning in Large Language Models?](https://arxiv.org/abs/2512.03272)
*Zhiyuan He,Dingmin Wang*

Main category: cs.AI

TL;DR: 本文探讨了符号求解器集成方法何时能增强传统长思维链的性能，发现该方法仅在问题需要有限隐式推理但涉及充足搜索空间时有效。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通过生成长思维链在复杂推理任务上表现良好，但这种方法会产生大量token开销，且模型可能"过度思考"产生冗长推理链甚至错误答案。符号求解器集成方法利用LLM的代码生成能力将推理任务转换为可执行代码，然后用符号求解器解决，但何时这种集成方法能增强传统长思维链仍是一个开放问题。

Method: 采用符号求解器集成方法，利用LLM的代码生成能力将推理任务翻译成可执行代码，然后使用符号求解器解决。通过实验比较传统长思维链方法与符号求解器集成方法在不同类型问题上的表现。

Result: 实验结果表明：1) 符号求解器集成方法仅在问题需要有限隐式推理但涉及充足搜索空间时有效；2) GPT-4o等最新LLM在推理深度较浅的演绎问题上表现更好；3) 符号求解器集成方法显著提高了LLM在需要重复回溯的约束满足问题上的性能；4) 提供声明性示例时，即使是CodeLlama-13B也能在困难的斑马谜题上超越GPT-4o。

Conclusion: 符号求解器集成方法对特定类型的推理问题（需要有限隐式推理但涉及充足搜索空间的问题）有显著帮助，特别是在约束满足问题上。该方法为LLM推理提供了有价值的补充，特别是在需要大量搜索和回溯的场景中。

Abstract: Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models "overthink" by producing lengthy reasoning chains, which can even lead to incorrect answers. A promising direction is the symbolic-solver-integrated approach, which leverages the code generation capabilities of LLMs to translate reasoning tasks into executable code and then solve them with a symbolic solver. In this paper, we explore an open question of when the conventional long-CoT can be enhanced by symbolic solvers. Our experimental results show that the symbolic-solver-integrated method only helps when the problem requires limited implicit reasoning but involves an ample search space. The latest LLMs, like GPT-4o, show better performance on deductive problems with shallow reasoning depth, while the symbolic-solver-integrated method significantly improves the LLMs' performance in constraint satisfaction problems that require repeated backtracks. When a declarative exemplar is provided, even CodeLlama-13B can outperform GPT-4o in difficult Zebra puzzles.

</details>


### [8] [Prior preferences in active inference agents: soft, hard, and goal shaping](https://arxiv.org/abs/2512.03293)
*Filippo Torresan,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 研究比较了主动推理中四种偏好分布定义方式（硬目标vs软目标，有无目标塑造）在网格世界导航任务中的表现，发现目标塑造能提升性能但会牺牲对环境的探索学习。


<details>
  <summary>Details</summary>
Motivation: 主动推理使用期望自由能作为规划决策目标，但偏好分布如何定义及其对推理学习的影响在文献中很少被关注。本研究旨在探索不同偏好分布定义方式对智能体性能的影响。

Method: 考虑了四种偏好分布定义方式：硬目标vs软目标，以及有无目标塑造（中间目标）。在网格世界导航任务中比较了四种智能体的表现。

Result: 目标塑造能带来最佳整体性能（促进利用），但会牺牲对环境转移动态的学习（阻碍探索）。

Conclusion: 偏好分布的定义方式显著影响主动推理智能体的性能权衡，目标塑造虽然提升利用效率但会限制探索学习，需要在具体应用中权衡考虑。

Abstract: Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).

</details>


### [9] [Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia](https://arxiv.org/abs/2512.03318)
*Chandler Smith,Marwa Abdulhai,Manfred Diaz,Marko Tesic,Rakshit S. Trivedi,Alexander Sasha Vezhnevets,Lewis Hammond,Jesse Clifton,Minsuk Chang,Edgar A. Duéñez-Guzmán,John P. Agapiou,Jayd Matyas,Danny Karmon,Akash Kundu,Aliaksei Korshuk,Ananya Ananya,Arrasy Rahman,Avinaash Anand Kulandaivel,Bain McHale,Beining Zhang,Buyantuev Alexander,Carlos Saith Rodriguez Rojas,Caroline Wang,Chetan Talele,Chenao Liu,Chichen Lin,Diana Riazi,Di Yang Shi,Emanuel Tewolde,Elizaveta Tennant,Fangwei Zhong,Fuyang Cui,Gang Zhao,Gema Parreño Piqueras,Hyeonggeun Yun,Ilya Makarov,Jiaxun Cui,Jebish Purbey,Jim Dilkes,Jord Nguyen,Lingyun Xiao,Luis Felipe Giraldo,Manuela Chacon-Chamorro,Manuel Sebastian Rios Beltran,Marta Emili García Segura,Mengmeng Wang,Mogtaba Alim,Nicanor Quijano,Nico Schiavone,Olivia Macmillan-Scott,Oswaldo Peña,Peter Stone,Ram Mohan Rao Kadiyala,Rolando Fernandez,Ruben Manrique,Sunjia Lu,Sheila A. McIlraith,Shamika Dhuri,Shuqing Shi,Siddhant Gupta,Sneheel Sarangi,Sriram Ganapathi Subramanian,Taehun Cha,Toryn Q. Klassen,Wenming Tu,Weijian Fan,Wu Ruiyang,Xue Feng,Yali Du,Yang Liu,Yiding Wang,Yipeng Kang,Yoonchang Sung,Yuxuan Chen,Zhaowei Zhang,Zhihan Wang,Zhiqiang Wu,Ziang Chen,Zilong Zheng,Zixia Jia,Ziyan Wang,Dylan Hadfield-Menell,Natasha Jaques,Tim Baarslag,Jose Hernandez-Orallo,Joel Z. Leibo*

Main category: cs.AI

TL;DR: 该论文提出了一种评估LLM智能体在零样本、混合动机环境中合作能力的方法，使用Concordia多智能体模拟环境，揭示了当前智能体在合作泛化能力上的显著差距。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在社会互动方面展现出强大能力，但现有评估方法无法衡量这些能力在新颖社交情境中的泛化表现，特别是在混合动机的合作场景中。

Method: 引入Concordia自然语言多智能体模拟环境，通过测试智能体在不同合作伙伴和情境中识别和利用互利机会的能力，来评估其一般合作智能。

Result: 基于NeurIPS 2024 Concordia竞赛的实证结果显示，当前智能体能力与稳健泛化所需水平存在显著差距，特别是在需要说服和规范执行的场景中。

Conclusion: LLM智能体在合作能力方面仍需显著改进，特别是在复杂社交情境中的泛化能力，这为未来研究提供了重要方向。

Abstract: Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical frontier for LLM-based agents, yet existing evaluation methods fail to measure how well these capabilities generalize to novel social situations. In this paper, we introduce a method for evaluating the ability of LLM-based agents to cooperate in zero-shot, mixed-motive environments using Concordia, a natural language multi-agent simulation environment. Our method measures general cooperative intelligence by testing an agent's ability to identify and exploit opportunities for mutual gain across diverse partners and contexts. We present empirical results from the NeurIPS 2024 Concordia Contest, where agents were evaluated on their ability to achieve mutual gains across a suite of diverse scenarios ranging from negotiation to collective action problems. Our findings reveal significant gaps between current agent capabilities and the robust generalization required for reliable cooperation, particularly in scenarios demanding persuasion and norm enforcement.

</details>


### [10] [Multimodal Reinforcement Learning with Agentic Verifier for AI Agents](https://arxiv.org/abs/2512.03438)
*Reuben Tan,Baolin Peng,Zhengyuan Yang,Hao Cheng,Oier Mees,Theodore Zhao,Andrea Tupini,Isar Meijier,Qianhui Wu,Yuncong Yang,Lars Liden,Yu Gu,Sheng Zhang,Xiaodong Liu,Lijuan Wang,Marc Pollefeys,Yong Jae Lee,Jianfeng Gao*

Main category: cs.AI

TL;DR: Argos是一个用于多模态强化学习的智能奖励代理，通过选择性地组合教师模型和规则评分函数来评估最终答案、时空定位和推理过程质量，显著提升智能体训练效果。


<details>
  <summary>Details</summary>
Motivation: 当前多模态强化学习主要依赖基于最终结果的稀疏奖励，缺乏对推理过程的细粒度指导。不同样本需要不同的评分函数，且教师模型可能提供噪声信号，因此需要更智能的奖励机制。

Method: 提出Argos奖励代理，为每个样本从教师模型和规则评分函数池中选择合适的评分函数，同时评估：1)最终响应准确性；2)时空定位质量；3)推理过程质量。在SFT数据筛选和RL训练中都使用该验证器。

Result: 在空间推理、视觉幻觉、机器人和具身AI等多个智能体任务上取得最先进结果。证明仅依赖SFT后训练会崩溃到非接地的解决方案，而在线验证能防止奖励黑客攻击。

Conclusion: Argos通过帕累托最优性理论证明其有效性，为多模态强化学习提供了更精细的奖励机制，显著提升智能体性能并减少奖励黑客问题。

Abstract: Agentic reasoning models trained with multimodal reinforcement learning (MMRL) have become increasingly capable, yet they are almost universally optimized using sparse, outcome-based rewards computed based on the final answers. Richer rewards computed from the reasoning tokens can improve learning significantly by providing more fine-grained guidance. However, it is challenging to compute more informative rewards in MMRL beyond those based on outcomes since different samples may require different scoring functions and teacher models may provide noisy reward signals too. In this paper, we introduce the Argos (Agentic Reward for Grounded & Objective Scoring), a principled reward agent to train multimodal reasoning models for agentic tasks. For each sample, Argos selects from a pool of teacher-model derived and rule-based scoring functions to simultaneously evaluate: (i) final response accuracy, (ii) spatiotemporal localization of referred entities and actions, and (iii) the quality of the reasoning process. We find that by leveraging our agentic verifier across both SFT data curation and RL training, our model achieves state-of-the-art results across multiple agentic tasks such as spatial reasoning, visual hallucination as well as robotics and embodied AI benchmarks. Critically, we demonstrate that just relying on SFT post-training on highly curated reasoning data is insufficient, as agents invariably collapse to ungrounded solutions during RL without our online verification. We also show that our agentic verifier can help to reduce reward-hacking in MMRL. Finally, we also provide a theoretical justification for the effectiveness of Argos through the concept of pareto-optimality.

</details>


### [11] [Multi-Agent Reinforcement Learning with Communication-Constrained Priors](https://arxiv.org/abs/2512.03528)
*Guang Yang,Tianpei Yang,Jingwen Qiao,Yanqing Wu,Jing Huo,Xingguo Chen,Yang Gao*

Main category: cs.AI

TL;DR: 提出一种通信受限的多智能体强化学习框架，通过双互信息估计器区分有损和无损消息对分布式决策的影响，并将其量化到全局奖励中


<details>
  <summary>Details</summary>
Motivation: 现实世界中普遍存在有损通信问题，现有多智能体强化学习通信方法由于可扩展性和鲁棒性有限，难以应用于复杂动态的真实环境

Method: 提出通用通信约束模型统一描述不同场景的通信条件，作为学习先验区分有损和无损消息；使用双互信息估计器解耦有损和无损消息对分布式决策的影响；引入通信约束多智能体强化学习框架，将通信消息影响量化到全局奖励

Result: 在多个通信约束基准测试中验证了方法的有效性

Conclusion: 提出的通信约束多智能体强化学习框架能够有效处理现实世界中的有损通信问题，提高在复杂动态环境中的适用性

Abstract: Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.

</details>


### [12] [PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks](https://arxiv.org/abs/2512.03549)
*Yuki Orimo,Iori Kurata,Hodaka Mori,Ryuhei Okuno,Ryohto Sawada,Daisuke Okanohara*

Main category: cs.AI

TL;DR: PARC是一个用于自主执行长时程计算任务的编码代理，采用分层多智能体架构，具备自我评估和反馈机制，能够在材料科学和Kaggle竞赛中自主完成复杂任务。


<details>
  <summary>Details</summary>
Motivation: 开发能够自主执行长时程计算任务的AI系统，减少人工干预，实现大规模科学和分析工作的自动化。

Method: 采用分层多智能体架构，包含任务规划、执行、自我评估和反馈机制，能够从独立上下文评估自身行为并纠正高层次战略错误。

Result: 在材料科学中成功复现锂离子传导和合金偏析研究的关键结果，协调数十个并行模拟任务（每个约43小时计算）；在Kaggle实验中，从自然语言指令出发，实现数据分析并产生与人工基准竞争的结果。

Conclusion: 分层多智能体系统结合自我评估和反馈机制能够实现AI系统独立进行大规模科学和分析工作的潜力。

Abstract: We introduce PARC, a coding agent for the autonomous and robust execution of long-horizon computational tasks. PARC is built on a hierarchical multi-agent architecture incorporating task planning, execution, and a mechanism that evaluates its own actions and their outcomes from an independent context and provides feedback, namely self-assessment and self-feedback. This design enables PARC to detect and correct high-level strategic errors and sustain progress without human intervention. We evaluate PARC across computational science and data science tasks. In materials science, it autonomously reproduces key results from studies on lithium-ion conduction and alloy segregation. In particular, it coordinates dozens of parallel simulation tasks, each requiring roughly 43 hours of computation, managing orchestration, monitoring, and error correction end-to-end. In Kaggle-based experiments, starting from minimal natural-language instructions, PARC conducts data analysis and implements search strategies, producing solutions competitive with human-engineered baselines. These results highlight the potential of integrating a hierarchical multi-agent system with self-assessment and self-feedback to enable AI systems capable of independent, large-scale scientific and analytical work.

</details>


### [13] [Reason-Plan-ReAct: A Reasoner-Planner Supervising a ReAct Executor for Complex Enterprise Tasks](https://arxiv.org/abs/2512.03560)
*Gianni Molinari,Fabio Ciravegna*

Main category: cs.AI

TL;DR: RP-ReAct是一种新型多智能体方法，通过将战略规划与低级执行解耦，解决企业环境中自主智能体处理复杂任务时的轨迹不稳定性和上下文窗口限制问题。


<details>
  <summary>Details</summary>
Motivation: 企业领域复杂任务需要协调多个工具和处理多样化数据源，但现有自主智能体面临两个主要限制：1）单智能体架构的单一规划-执行循环导致轨迹不稳定；2）数据隐私要求使用本地开源模型，但较小上下文窗口会因大型工具输出而迅速耗尽。

Method: RP-ReAct采用多智能体架构，包含Reasoner Planner Agent（RPA）负责使用大型推理模型进行战略规划和分析执行结果，以及一个或多个Proxy-Execution Agent（PEA）使用ReAct方法将子步骤转换为具体工具交互。PEA中采用上下文保存策略，通过外部存储和按需访问管理大型工具输出。

Result: 在具有挑战性的多领域ToolQA基准测试中，使用六种不同的开源推理模型进行评估，RP-ReAct在性能、泛化能力和鲁棒性方面均优于现有最先进基线方法，在不同模型规模下表现出增强的稳定性和可靠性。

Conclusion: RP-ReAct通过解耦规划与执行、管理上下文窗口限制，为企业环境提供了有效且可部署的智能体解决方案，在多领域复杂任务处理中展现出优越性能。

Abstract: Despite recent advances, autonomous agents often struggle to solve complex tasks in enterprise domains that require coordinating multiple tools and processing diverse data sources. This struggle is driven by two main limitations. First, single-agent architectures enforce a monolithic plan-execute loop, which directly causes trajectory instability. Second, the requirement to use local open-weight models for data privacy introduces smaller context windows leading to the rapid consumption of context from large tool outputs. To solve this problem we introduce RP-ReAct (Reasoner Planner-ReAct), a novel multi-agent approach that fundamentally decouples strategic planning from low-level execution to achieve superior reliability and efficiency. RP-ReAct consists of a Reasoner Planner Agent (RPA), responsible for planning each sub-step, continuously analysing the execution results using the strong reasoning capabilities of a Large Reasoning Model, and one or multiple Proxy-Execution Agent (PEA) that translates sub-steps into concrete tool interactions using a ReAct approach. Crucially, we incorporate a context-saving strategy within the PEA to mitigate context window overflow by managing large tool outputs via external storage and on-demand access. We evaluate RP-ReAct, on the challenging, multi-domain ToolQA benchmark using a diverse set of six open-weight reasoning models. Our empirical results show that RP-ReAct achieves superior performance and improved generalization ability over state-of-the-art baselines when addressing diverse complex tasks across the evaluated domains. Furthermore we establish the enhanced robustness and stability of our approach across different model scales, paving the way for effective and deployable agentic solutions for enterprises.

</details>


### [14] [EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths](https://arxiv.org/abs/2512.03571)
*Zhening Li,Armando Solar-Lezama,Yisong Yue,Stephan Zheng*

Main category: cs.AI

TL;DR: 提出PAN编程模型，通过分离核心工作流逻辑和推理时策略，简化LLM智能体开发，并实现EnCompass框架


<details>
  <summary>Details</summary>
Motivation: 当前智能体编程方法通常将核心工作流逻辑和推理时策略（如树搜索）耦合在一起，这种耦合使得实验不同推理策略变得困难

Method: 提出"概率天使非确定性"（PAN）编程模型，分离工作流和推理策略；实现EnCompass框架，使用Python装饰器将智能体工作流程序编译为搜索空间

Result: 通过三个案例研究证明，该框架能让程序员快速提高智能体可靠性，轻松切换不同推理时策略，且只需少量额外编码

Conclusion: PAN编程模型和EnCompass框架为LLM智能体开发提供了更灵活、可维护的方法，解耦了工作流设计和推理策略选择

Abstract: We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce "probabilistic angelic nondeterminism" ("PAN"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.

</details>


### [15] [DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization](https://arxiv.org/abs/2512.03607)
*Yusen Wu,Xiaotie Deng*

Main category: cs.AI

TL;DR: DeepRule是一个用于零售品类和定价优化的自动化业务规则生成框架，通过三层架构解决理论模型与现实经济复杂性之间的不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 现有理论模型与真实世界经济复杂性存在系统性不匹配，具体表现为三个关键差距：1) 非结构化文本数据模态不匹配；2) 动态特征纠缠挑战；3) 多层业务约束导致的运营不可行性。

Method: 采用三层架构：1) 混合知识融合引擎，使用LLM深度语义解析非结构化文本；2) 博弈论约束优化机制，通过双边效用函数动态协调供应链利益；3) 可解释决策蒸馏接口，利用LLM引导的符号回归优化定价策略和可审计业务规则。

Result: 在真实零售环境中验证，相比系统性B2C基线实现了更高的利润，同时确保运营可行性。

Conclusion: 建立了一个闭环管道，统一了非结构化知识注入、多智能体优化和可解释策略合成，为真实经济智能提供了解决方案。

Abstract: This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.
  Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.

</details>


### [16] [MemVerse: Multimodal Memory for Lifelong Learning Agents](https://arxiv.org/abs/2512.03627)
*Junming Liu,Yifei Sun,Weihua Cheng,Haodong Lei,Yirong Chen,Licheng Wen,Xuemeng Yang,Daocheng Fu,Pinlong Cai,Nianchen Deng,Yi Yu,Shuyue Hu,Botian Shi,Ding Wang*

Main category: cs.AI

TL;DR: MemVerse是一个模型无关的即插即用记忆框架，通过结合快速参数化召回与分层检索式记忆，解决AI代理的记忆问题，支持多模态持续学习。


<details>
  <summary>Details</summary>
Motivation: 尽管大规模语言和视觉模型进展迅速，但AI代理仍缺乏记忆能力，导致灾难性遗忘、长时推理困难以及在多模态交互环境中无法连贯操作。

Method: MemVerse采用模型无关的即插即用架构，结合短期记忆和分层检索式长期记忆（组织为层次知识图谱），通过周期性蒸馏机制将长期记忆压缩到参数模型中，实现快速可微召回。

Result: 大量实验表明，MemVerse显著提升了多模态推理和持续学习效率，使代理能够在扩展交互中记忆、适应和连贯推理。

Conclusion: MemVerse通过桥接参数化与检索式记忆，解决了AI代理的记忆瓶颈，为实现可扩展、自适应的多模态智能提供了有效框架。

Abstract: Despite rapid progress in large-scale language and vision models, AI agents still suffer from a fundamental limitation: they cannot remember. Without reliable memory, agents catastrophically forget past experiences, struggle with long-horizon reasoning, and fail to operate coherently in multimodal or interactive environments. We introduce MemVerse, a model-agnostic, plug-and-play memory framework that bridges fast parametric recall with hierarchical retrieval-based memory, enabling scalable and adaptive multimodal intelligence. MemVerse maintains short-term memory for recent context while transforming raw multimodal experiences into structured long-term memories organized as hierarchical knowledge graphs. This design supports continual consolidation, adaptive forgetting, and bounded memory growth. To handle real-time demands, MemVerse introduces a periodic distillation mechanism that compresses essential knowledge from long-term memory into the parametric model, allowing fast, differentiable recall while preserving interpretability. Extensive experiments demonstrate that MemVerse significantly improves multimodal reasoning and continual learning efficiency, empowering agents to remember, adapt, and reason coherently across extended interactions.

</details>


### [17] [RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design](https://arxiv.org/abs/2512.03762)
*Jiawei Xu,Fengfeng Wei,Weineng Chen*

Main category: cs.AI

TL;DR: RoCo是一个基于多智能体角色协作的自动启发式设计系统，通过四个专门角色（探索者、利用者、批评者、整合者）协同工作，在组合优化问题上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的自动启发式设计研究通常只考虑单一角色，限制了启发式的多样性和质量。需要一种多角色协作系统来增强自动启发式设计的能力。

Method: 提出RoCo多智能体角色协作系统，包含四个专门角色：探索者（创造性、多样性驱动）、利用者（保守性、效率导向）、批评者（评估效果并提供反馈）、整合者（平衡创新与利用）。这些智能体通过结构化的多轮过程进行交互，包括反馈、精炼和精英突变。

Result: 在五个不同的组合优化问题上，无论是白盒还是黑盒设置下，RoCo都表现出优越性能，生成的启发式方法超越了包括ReEvo和HSEvo在内的现有方法。

Conclusion: 这种基于角色的协作范式为稳健且高性能的自动启发式设计建立了新标准，通过多角色协作显著提升了启发式设计的多样性和质量。

Abstract: Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.

</details>


### [18] [Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning](https://arxiv.org/abs/2512.03783)
*Dongchao Yang,Songxiang Liu,Disong Wang,Yuanyuan Wang,Guanglu Wan,Helen Meng*

Main category: cs.AI

TL;DR: Omni-AutoThink：一种自适应推理框架，根据任务难度动态调整Omni模型的推理深度，提升多模态推理性能


<details>
  <summary>Details</summary>
Motivation: 现有Omni模型存在推理行为僵化的问题，要么对简单问题过度推理，要么在需要推理时无法有效推理。需要一种能够根据任务难度自适应调整推理深度的框架。

Method: 提出两阶段框架：1）自适应监督微调阶段，使用大规模推理增强数据赋予模型基础推理能力；2）自适应强化学习阶段，基于任务复杂度和奖励反馈优化推理行为。构建了涵盖文本、音频、视觉等多模态的自适应推理基准。

Result: 实验结果表明，该框架相比先前基线显著提升了自适应推理性能。所有基准数据和代码将公开。

Conclusion: Omni-AutoThink框架有效解决了Omni模型推理行为僵化问题，通过自适应调整推理深度提升了多模态推理能力，为自适应推理研究提供了新的基准和工具。

Abstract: Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.

</details>


### [19] [A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)](https://arxiv.org/abs/2512.03887)
*Saurav Prateek*

Main category: cs.AI

TL;DR: 提出Static-DRA：基於樹狀靜態工作流的深度研究代理，通過可調參數Depth和Breadth控制研究強度，平衡報告質量與計算成本


<details>
  <summary>Details</summary>
Motivation: 為克服靜態RAG管道在處理複雜多輪研究任務時的局限性，需要更先進的代理系統來進行深度研究

Method: 設計基於樹狀靜態工作流的架構，包含Supervisor、Independent和Worker代理，引入Depth和Breadth兩個用戶可調參數控制研究深度和廣度

Result: 在DeepResearch Bench上使用RACE框架評估，配置Depth=2、Breadth=5，使用gemini-2.5-pro模型獲得34.72分，驗證參數增加可提升研究深度和評分

Conclusion: Static-DRA提供實用且資源感知的解決方案，讓用戶能透明控制深度研究過程，在報告質量與計算成本間取得平衡

Abstract: The advancement in Large Language Models has driven the creation of complex agentic systems, such as Deep Research Agents (DRAs), to overcome the limitations of static Retrieval Augmented Generation (RAG) pipelines in handling complex, multi-turn research tasks. This paper introduces the Static Deep Research Agent (Static-DRA), a novel solution built upon a configurable and hierarchical Tree-based static workflow.
  The core contribution is the integration of two user-tunable parameters, Depth and Breadth, which provide granular control over the research intensity. This design allows end-users to consciously balance the desired quality and comprehensiveness of the research report against the associated computational cost of Large Language Model (LLM) interactions. The agent's architecture, comprising Supervisor, Independent, and Worker agents, facilitates effective multi-hop information retrieval and parallel sub-topic investigation.
  We evaluate the Static-DRA against the established DeepResearch Bench using the RACE (Reference-based Adaptive Criteria-driven Evaluation) framework. Configured with a depth of 2 and a breadth of 5, and powered by the gemini-2.5-pro model, the agent achieved an overall score of 34.72. Our experiments validate that increasing the configured Depth and Breadth parameters results in a more in-depth research process and a correspondingly higher evaluation score. The Static-DRA offers a pragmatic and resource-aware solution, empowering users with transparent control over the deep research process. The entire source code, outputs and benchmark results are open-sourced at https://github.com/SauravP97/Static-Deep-Research/

</details>


### [20] [Autonomous Agents and Policy Compliance: A Framework for Reasoning About Penalties](https://arxiv.org/abs/2512.03931)
*Vineel Tummala,Daniela Inclezan*

Main category: cs.AI

TL;DR: 提出基于逻辑编程的框架，使自主智能体能推理政策违规的惩罚并相应行动，扩展AOPL语言纳入惩罚机制，使用ASP进行推理，生成更优计划并提升可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注确保合规性，但实际场景中可能需要偏离政策以实现高风险目标。同时，建模不合规行为有助于政策制定者模拟真实的人类决策过程。

Method: 扩展Gelfond和Lobo的授权与义务政策语言(AOPL)以纳入惩罚机制，集成答案集编程(ASP)进行推理，开发从扩展AOPL到ASP的自动翻译，并改进基于ASP的规划算法以考虑惩罚。

Result: 在两个领域的实验中，该框架生成了更高质量的计划，避免了有害行动，并在某些情况下提高了计算效率。能够区分不合规计划，优先选择惩罚最小的方案。

Conclusion: 该框架有潜力增强自主决策能力并为政策完善提供信息，通过明确识别规则违反及其后果提高了可解释性，同时确保政策格式良好并考虑政策优先级。

Abstract: This paper presents a logic programming-based framework for policy-aware autonomous agents that can reason about potential penalties for non-compliance and act accordingly. While prior work has primarily focused on ensuring compliance, our approach considers scenarios where deviating from policies may be necessary to achieve high-stakes goals. Additionally, modeling non-compliant behavior can assist policymakers by simulating realistic human decision-making. Our framework extends Gelfond and Lobo's Authorization and Obligation Policy Language (AOPL) to incorporate penalties and integrates Answer Set Programming (ASP) for reasoning. Compared to previous approaches, our method ensures well-formed policies, accounts for policy priorities, and enhances explainability by explicitly identifying rule violations and their consequences. Building on the work of Harders and Inclezan, we introduce penalty-based reasoning to distinguish between non-compliant plans, prioritizing those with minimal repercussions. To support this, we develop an automated translation from the extended AOPL into ASP and refine ASP-based planning algorithms to account for incurred penalties. Experiments in two domains demonstrate that our framework generates higher-quality plans that avoid harmful actions while, in some cases, also improving computational efficiency. These findings underscore its potential for enhancing autonomous decision-making and informing policy refinement. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [21] [Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol](https://arxiv.org/abs/2512.03955)
*Niklas Jobs,Luis Miguel Vieira da Silva,Jayanth Somashekaraiah,Maximilian Weigand,David Kube,Felix Gehlhoff*

Main category: cs.AI

TL;DR: 该论文提出了一个用于评估LLM智能体在工业自动化中规划与执行能力的标准化基准测试框架，包含可执行的Blocksworld仿真环境和五个复杂度类别，通过MCP协议实现不同智能体架构的无缝连接和评估。


<details>
  <summary>Details</summary>
Motivation: 工业自动化需要能够适应变化任务和环境的灵活控制策略，基于大语言模型的智能体具有这种自适应规划和执行潜力，但缺乏用于系统比较的标准化基准测试。

Method: 引入一个包含可执行仿真环境的基准测试，基于Blocksworld问题提供五个复杂度类别，通过集成模型上下文协议作为标准化工具接口，使不同智能体架构无需实现特定修改即可连接和评估。

Result: 通过单智能体实现展示了基准测试的适用性，建立了用于比较基于LLM的规划与执行方法的定量指标。

Conclusion: 该基准测试框架为评估和比较LLM智能体在工业自动化中的自适应规划与执行能力提供了标准化平台，有助于推动该领域的研究发展。

Abstract: Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [22] [CFO-Robust Detection for 5G PRACH under Fading Channels: Analytical Modeling and Performance Evaluation](https://arxiv.org/abs/2512.03096)
*Daniel Alarcón-Martín,Mari Carmen Aguayo-Torres,Francisco J. Martín-Vega,Gerardo Gómez*

Main category: cs.IT

TL;DR: 该论文提出了一个统一的PRACH检测分析框架，推导了相干合并与功率合并策略的统计分布和最优阈值，并设计了一种利用CFO相关性的低复杂度检测器。


<details>
  <summary>Details</summary>
Motivation: PRACH检测对高用户密度、大载波频率偏移和快速衰落等损伤高度敏感，现有研究要么局限于特定场景，要么缺乏全面的性能分析表征。

Method: 1) 建立统一分析框架，在平坦瑞利衰落下表征接收功率延迟剖面的统计分布，支持相干合并和功率合并重复策略；2) 推导每种策略的最优阈值表达式和闭式检测概率；3) 分析相干时间相关的两种关键情况；4) 利用CFO在循环移位中引起的相关性设计新型低复杂度检测器。

Result: 数值结果表明：在独立信道条件下功率合并优于相干合并，而在相同实现条件下相干合并可能更优；提出的CFO感知检测器在严重CFO条件下表现出更强的鲁棒性。

Conclusion: 该研究为PRACH检测提供了全面的分析框架和优化策略，特别是在高CFO条件下提出的新型检测器具有实际应用价值，为5G/6G网络中的初始接入和同步提供了改进方案。

Abstract: The Physical Random Access Channel (PRACH) is essential for initial access and synchronization in both 5G and future 6G networks; however, its detection is highly sensitive to impairments such as high user density, large carrier frequency offset (CFO), and fast fading. Although prior studies have examined PRACH detection, they are often restricted to specific scenarios or lack a comprehensive analytical characterization of performance. We introduce a unified analytical framework that characterizes the statistical distribution of the received power delay profile (PDP) under flat Rayleigh fading and supports both coherent combining (CC) and power combining (PC) repetition strategies. For each strategy, we derive optimal threshold expressions and closed-form detection probabilities. Furthermore, we analyze two key cases depending on the coherence time: identical and independent channel realizations per repetition. Secondly, we exploit the correlation induced by CFO across cyclic shifts to design a novel low-complexity detector that exploits PDP dependencies. Numerical results indicate that PC outperforms CC when repetitions experience independent channels, while CC can be preferable under identical realizations in limited settings. On the other hand, the proposed CFO-aware detector delivers improved robustness under severe CFO conditions.

</details>


### [23] [Strengthening Han's Fourier Entropy-Influence Inequality via an Information-Theoretic Proof](https://arxiv.org/abs/2512.03117)
*Peijie Li,Guangyue Han*

Main category: cs.IT

TL;DR: 本文改进了Han的傅里叶熵-影响不等式，将常数从C₁=3+2ln2、C₂=1优化到C₁=C₂=1，适用于所有单位L²范数的实值布尔函数。


<details>
  <summary>Details</summary>
Motivation: Han的傅里叶熵-影响不等式是布尔函数分析中的重要结果，但原始证明中的常数不是最优的。本文旨在通过信息论方法获得该不等式的尖锐常数，揭示香农熵与影响之间的基本结构关系。

Method: 采用简短的信息论证明方法，通过分析实值布尔函数的傅里叶系数与影响之间的关系，推导出最优常数。

Result: 成功证明了傅里叶熵-影响不等式在C₁=C₂=1时对所有单位L²范数的实值布尔函数成立，这是该不等式的最优常数。

Conclusion: 该不等式作为香农熵与影响之间基本结构性质的体现，通过信息论方法获得了尖锐常数，深化了对布尔函数傅里叶分析的理解。

Abstract: We strengthen Han's Fourier entropy-influence inequality $$ H[\widehat{f}] \leq C_{1}I(f) + C_{2}\sum_{i\in [n]}I_{i}(f)\ln\frac{1}{I_{i}(f)} $$ originally proved for $\{-1,1\}$-valued Boolean functions with $C_{1}=3+2\ln 2$ and $C_{2}=1$. We show, by a short information-theoretic proof, that it in fact holds with sharp constants $C_{1}=C_{2}=1$ for all real-valued Boolean functions of unit $L^{2}$-norm, thereby establishing the inequality as an elementary structural property of Shannon entropy and influence.

</details>


### [24] [Multi-Source M/G/1/1 Queues with Probabilistic Preemption](https://arxiv.org/abs/2512.03241)
*Mohammad Moltafet,Hamid R. Sadjadpour,Zouheir Rezki,Marian Codreanu,Roy D. Yates*

Main category: cs.IT

TL;DR: 本文研究了多源状态更新系统，提出了一种概率抢占式数据包管理策略，推导了AoI和PAoI的矩生成函数，并通过数值结果验证了策略的有效性。


<details>
  <summary>Details</summary>
Motivation: 在多源状态更新系统中，如何有效管理数据包以优化信息年龄(AoI)是一个重要问题。现有系统通常采用完全抢占或非抢占策略，但缺乏灵活的概率控制机制。

Method: 将系统建模为多源M/G/1/1排队系统，提出概率抢占式数据包管理策略：当同一源的新数据包到达时，以固定概率替换系统中已有的同源数据包。推导了每个源的信息年龄(AoI)和峰值信息年龄(PAoI)的矩生成函数。

Result: 数值结果表明，所提出的概率抢占式数据包管理策略能够有效优化信息年龄性能，相比传统策略具有更好的灵活性。

Conclusion: 概率抢占式策略为多源状态更新系统提供了一种灵活的数据包管理方法，能够通过调整抢占概率来平衡系统性能，为实际网络设计提供了理论指导。

Abstract: We consider a multi-source status update system consisting of multiple independent sources, a single server, and a single sink. Each source generates packets according to a Poisson process, and packets are served according to a general service time distribution. The system has a capacity of one packet, i.e., no waiting buffer, and is modeled as a multi-source M/G/1/1 queueing system. We introduce a probabilistically preemptive packet management policy, under which an existing packet from the same source in the system is replaced by an arriving packet with a fixed probability. We derive the moment generating functions (MGFs) of the age of information (AoI) and peak AoI (PAoI) for each source under this policy. Numerical results demonstrate the effectiveness of the proposed packet management policy.

</details>


### [25] [Generalized Orthogonal Approximate Message-Passing for Sublinear Sparsity](https://arxiv.org/abs/2512.03326)
*Keigo Takeuchi*

Main category: cs.IT

TL;DR: 针对亚线性稀疏信号的广义线性测量重建问题，提出了广义正交AMP算法，通过Onsager校正实现误差的渐近高斯性，在亚线性稀疏极限下优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 传统研究假设信号稀疏度与信号维度成正比，而实际应用中稀疏度往往是亚线性的。传统近似消息传递算法在非标准高斯测量矩阵下收敛性差，需要针对亚线性稀疏信号设计新的重建算法。

Method: 提出广义正交AMP算法，通过Onsager校正实现估计误差的渐近高斯性。该校正基于正交不变测量矩阵在亚线性稀疏极限下的状态演化设计，其中信号稀疏度和测量维度以亚线性速度趋于无穷。

Result: 当非零信号支撑不包含原点邻域时，使用贝叶斯去噪器的GOAMP在线性测量下能实现无误差信号重建，当且仅当测量维度大于某个阈值，该阈值与标准高斯测量矩阵下AMP的阈值相同。数值模拟显示在病态测量矩阵下，GOAMP优于现有算法。

Conclusion: GOAMP算法有效解决了亚线性稀疏信号的重建问题，在正交不变测量矩阵下具有优越性能，特别是在病态矩阵情况下显著优于现有算法，为亚线性稀疏信号处理提供了有效工具。

Abstract: This paper addresses the reconstruction of sparse signals from generalized linear measurements. Signal sparsity is assumed to be sublinear in the signal dimension while it was proportional to the signal dimension in conventional research. Approximate message-passing (AMP) has poor convergence properties for sensing matrices beyond standard Gaussian matrices. To solve this convergence issue, generalized orthogonal AMP (GOAMP) is proposed for signals with sublinear sparsity. The main feature of GOAMP is the so-called Onsager correction to realize asymptotic Gaussianity of estimation errors. The Onsager correction in GOAMP is designed via state evolution for orthogonally invariant sensing matrices in the sublinear sparsity limit, where the signal sparsity and measurement dimension tend to infinity at sublinear speed in the signal dimension. When the support of non-zero signals does not contain a neighborhood of the origin, GOAMP using Bayesian denoisers is proved to achieve error-free signal reconstruction for linear measurements if and only if the measurement dimension is larger than a threshold, which is equal to that of AMP for standard Gaussian sensing matrices. Numerical simulations are also presented for linear measurements and 1-bit compressed sensing. When ill-conditioned sensing matrices are used, GOAMP for sublinear sparsity is shown to outperform existing reconstruction algorithms, including generalized AMP for sublinear sparsity.

</details>


### [26] [From Reliability to Security: How RIS-Assisted Adaptive SM and SSK Enhances Wireless Systems](https://arxiv.org/abs/2512.03518)
*Chaorong Zhang,Benjamin K. Ng,Ke Wang,Hui Xu,Chan-Tong Lam*

Main category: cs.IT

TL;DR: 该论文提出了两种新型无线传输方案：RIS辅助接收自适应空间调制(RASM)和RIS辅助接收自适应空间移位键控(RASSK)，旨在提高频谱效率和物理层安全性。


<details>
  <summary>Details</summary>
Motivation: 传统无线通信系统在频谱效率和物理层安全性方面存在挑战，需要更高效、安全且节能的传输方案。RIS技术为动态调整无线传播环境提供了新可能。

Method: 利用RIS在每个时隙的特性，在接收天线处动态映射传输比特，增强特定选定天线的信噪比。这种自适应方法能够在发射端减少射频链成本的同时，向接收端传递额外比特。

Result: 提出的RASM和RASSK方案在频谱效率、误码率和保密率方面表现优越，具有改进的错误性能和抗窃听鲁棒性，同时实现节能通信。

Conclusion: RIS辅助的RASM和RASSK方案为未来无线应用提供了可靠、高效且安全的解决方案，展示了在频谱效率、物理层安全性和能效方面的显著优势。

Abstract: This paper proposes two novel wireless transmission schemes, namely reconfigurable intelligent surface (RIS)-assisted received adaptive spatial modulation (RASM) scheme and RIS-assisted received adaptive space shift keying (RASSK) scheme, designed to enhance spectral efficiency (SE) and physical layer security (PLS).In both proposed schemes, transmitting bits are dynamically mapped at receive antennas by leveraging the characteristics of the RIS in each time slot, which enables the enhancement of signal-to-noise ratio (SNR) at specific selected antennas with near few power, thus leading a reliable and green wireless communication. This adaptive approach facilitates the conveyance of extra bits to the receiver, which means it needs less cost of radio-frequency chains at transmitter while improving SE. Besides, the proposed schemes offer an inherent PLS security advantage, as the eavesdropper is unable to completely detect signals reflected from the RIS. To comprehensively evaluate the performance of the proposed RASM and RASSK schemes, this paper presents a detailed analytical performance of their spectral efficiency, detection complexity, bit error rate, and secrecy rate, which are accompanied by insightful findings and conclusions. Simulation and analytical results demonstrate the superiority of the proposed schemes, showcasing their improved error performance and robustness against wiretapping, while also highlighting the potential of the RASM and RASSK schemes for future wireless applications.

</details>


### [27] [Expected Confidence Dependency: A Novel Rough Set-Based Approach to Feature Selection](https://arxiv.org/abs/2512.03612)
*Saeed Rasouli,Hamid Karamikabir*

Main category: cs.IT

TL;DR: 提出了一种新的基于期望置信度的依赖度量方法ECD，用于粗糙集理论框架下的特征选择，相比传统二元表征方法，它通过置信度分配和归一化期望算子来评估特征依赖关系。


<details>
  <summary>Details</summary>
Motivation: 传统粗糙集依赖度量方法基于条件块的二元表征，存在局限性。需要一种更精细、基于置信度的软计算方法来更好地评估特征依赖关系，以改进特征选择效果。

Method: 提出期望置信依赖度（ECD），为单个等价块分配基于置信度的贡献值，然后通过归一化期望算子进行聚合。该方法在粗糙集理论框架内工作，是一种软计算导向的精度驱动依赖度量。

Result: 正式建立了ECD的多个理想性质：归一化、与经典依赖度的兼容性、单调性，以及在结构变换和标签保持变换下的不变性。

Conclusion: ECD是一种新颖有效的特征选择依赖度量方法，克服了传统方法的局限性，具有理论上的良好性质，为粗糙集框架下的特征选择提供了更精细的评估工具。

Abstract: This paper proposes Expected Confidence Dependency (ECD), a novel, soft computing-oriented, accuracy driven dependency measure for feature selection within the rough set theory framework. Unlike traditional rough set dependency measures that rely on binary characterizations of conditional blocks, ECD assigns confidence-based contributions to individual equivalence blocks and aggregates them through a normalized expectation operator. We formally establish several desirable properties of ECD, including normalization, compatibility with classical dependency, monotonicity, and invariance under structural and label-preserving transformations.

</details>


### [28] [Semi-Markov Decision Process Framework for Age of Incorrect Information Minimization](https://arxiv.org/abs/2512.04077)
*Ismail Cosandal,Sennur Ulukus,Nail Akar*

Main category: cs.IT

TL;DR: 研究远程估计系统中基于年龄错误信息(AoII)的多阈值传输策略优化问题，通过半马尔可夫决策过程和新型随机工具DR-AMC/DR-DPH求解最优阈值


<details>
  <summary>Details</summary>
Motivation: 在远程估计系统中，传统的信息新鲜度度量如AoI(信息年龄)无法充分反映估计误差的语义信息。AoII(错误信息年龄)作为一种语义感知的新鲜度度量，能更好地捕捉估计质量。研究如何在具有一般离散时间相型分布信道延迟的系统中优化AoII性能。

Method: 采用多阈值传输策略，当AoII超过特定阈值时触发传输。将问题建模为半马尔可夫决策过程(SMDP)，状态空间与原始离散时间马尔可夫链相同。使用新型随机工具双机制吸收马尔可夫链(DR-AMC)及其吸收时间分布DR-DPH来计算SMDP参数。

Result: 通过SMDP框架和DR-AMC/DR-DPH工具，能够获得最优的多阈值传输策略，最小化AoII函数和传输成本的加权时间平均值。

Conclusion: 该研究为具有一般信道延迟的远程估计系统提供了一种有效的AoII优化方法，通过多阈值策略和新型随机分析工具，实现了语义感知新鲜度度量的性能优化。

Abstract: For a remote estimation system, we study age of incorrect information (AoII), which is a recently proposed semantic-aware freshness metric. In particular, we assume an information source observing a discrete-time finite-state Markov chain (DTMC) and employing push-based transmissions of status update packets towards the monitor which is tasked with remote estimation of the source. The source-to-monitor channel delay is assumed to have a general discrete-time phase-type (DPH) distribution, whereas the zero-delay reverse channel ensures that the source has perfect information on AoII and the remote estimate. A multi-threshold transmission policy is employed where packet transmissions are initiated when the AoII process exceeds a threshold which may be different for each estimation value. In this general setting, our goal is to minimize the weighted sum of time average of an arbitrary function of AoII and estimation, and transmission costs, by suitable choice of the thresholds. We formulate the problem as a semi-Markov decision process (SMDP) with the same state-space as the original DTMC to obtain the optimum multi-threshold policy whereas the parameters of the SMDP are obtained by using a novel stochastic tool called dual-regime absorbing Markov chain (DR-AMC), and its corresponding absorption time distribution named as dual-regime DPH (DR-DPH).

</details>


### [29] [Over-the-Air Federated Learning: Rethinking Edge AI Through Signal Processing](https://arxiv.org/abs/2512.03719)
*Seyed Mohammad Azimi-Abarghouyi,Carlo Fischione,Kaibin Huang*

Main category: cs.IT

TL;DR: AirFL是一种新兴的联邦学习范式，通过无线信号叠加特性同时进行通信和模型聚合，显著降低延迟、带宽和能耗。本文提供了AirFL的教程式介绍，将其分为三种设计方法：CSIT感知、盲式和加权AirFL。


<details>
  <summary>Details</summary>
Motivation: 随着边缘计算和分布式机器学习的发展，需要一种能够有效整合无线信号处理和机器学习的方法。传统联邦学习在通信开销、延迟和能耗方面存在瓶颈，而AirFL通过利用无线信号的叠加特性，能够同时进行通信和模型聚合，为边缘AI提供可扩展的解决方案。

Method: 本文提出了AirFL的三种设计方法分类：1) CSIT感知AirFL：利用信道状态信息进行优化设计；2) 盲式AirFL：无需信道状态信息；3) 加权AirFL：通过加权机制处理不同用户的数据质量差异。文章提供了理论基础、性能分析、复杂度考虑和实践限制的全面指南。

Result: 文章系统性地介绍了AirFL技术，建立了完整的分类框架，分析了各种方法的性能特征和适用场景。通过理论分析和实践考量，为研究人员和工程师提供了AirFL的设计指南和实施参考。

Conclusion: AirFL作为一种有前景的边缘AI技术，通过无线信号处理与联邦学习的深度融合，能够显著提升系统效率。文章提出的三种设计方法为不同应用场景提供了灵活选择，并为未来研究方向提供了指导，包括性能优化、实际部署挑战和新兴应用探索。

Abstract: Over-the-Air Federated Learning (AirFL) is an emerging paradigm that tightly integrates wireless signal processing and distributed machine learning to enable scalable AI at the network edge. By leveraging the superposition property of wireless signals, AirFL performs communication and model aggregation of the learning process simultaneously, significantly reducing latency, bandwidth, and energy consumption. This article offers a tutorial treatment of AirFL, presenting a novel classification into three design approaches: CSIT-aware, blind, and weighted AirFL. We provide a comprehensive guide to theoretical foundations, performance analysis, complexity considerations, practical limitations, and prospective research directions.

</details>


### [30] [Movable Signals with Dual-Polarized Fixed Intelligent Surfaces: Beyond Diagonal Reflection Matrices](https://arxiv.org/abs/2512.03872)
*Matteo Nerini,Bruno Clerckx*

Main category: cs.IT

TL;DR: 本文研究双极化智能表面辅助的无线系统，比较可重构智能表面(RIS)和固定智能表面(FIS)配合可移动信号的性能。FIS始终优于RIS，至少获得4倍增益，当收发极化不同时，非对角FIS性能更佳。


<details>
  <summary>Details</summary>
Motivation: 研究双极化智能表面在无线系统中的性能，比较不同配置的智能表面（可重构与固定）对系统性能的影响，探索极化差异条件下的最优配置方案。

Method: 比较两种智能表面：RIS（调整反射矩阵）和FIS（固定表面特性，调整信号频率）。每种表面又分为对角型（对角反射矩阵）和非对角型（非对角反射矩阵）。分析在不同极化条件下的性能差异。

Result: FIS始终优于RIS，至少获得4倍性能增益。当发射机和接收机极化不同时，非对角FIS能进一步提升性能表现。

Conclusion: 在双极化智能表面辅助的无线系统中，固定智能表面配合可移动信号比可重构智能表面具有显著优势，特别是在收发极化不同的场景下，非对角固定智能表面是最佳选择。

Abstract: This paper investigates wireless systems aided by dual-polarized intelligent surfaces. We compare reconfigurable intelligent surface (RIS), which adjust their reflection matrices, with movable signals operating with fixed intelligent surface (FIS), which adjust the signal frequency while the surface properties remain fixed. For both RIS and FIS, we consider surfaces with a diagonal reflection matrix, named diagonal RIS/FIS, and surfaces with a reflection matrix not limited to being diagonal, named beyond-diagonal RIS/FIS. Movable signals with FIS always outperform RIS, achieving at least a fourfold gain. When transmitter and receiver polarizations differ, beyond-diagonal FIS further enhances performance.

</details>


### [31] [On topological and algebraic structures of categorical random variables](https://arxiv.org/abs/2512.04020)
*Inocencio Ortiz,Santiago Gómez-Guerrero,Christian E. Schaerer*

Main category: cs.IT

TL;DR: 基于熵和对称不确定性，为分类随机变量定义了一种度量，该度量可在分类随机变量的适当商空间中推广，且该商空间具有自然的交换幺半群结构，与度量诱导的拓扑相容。


<details>
  <summary>Details</summary>
Motivation: 为分类随机变量建立一种度量结构，并探索其代数性质与拓扑性质之间的相容关系。

Method: 基于熵和对称不确定性定义分类随机变量的度量，构造商空间，并证明该空间具有交换幺半群结构。

Result: 成功定义了分类随机变量的度量，该度量可在商空间中推广，且商空间具有与度量拓扑相容的连续交换幺半群运算。

Conclusion: 分类随机变量可以配备度量结构，其商空间同时具有代数（交换幺半群）和拓扑结构，且两者相容，为信息论与代数拓扑的交叉研究提供了新视角。

Abstract: Based on entropy and symmetrical uncertainty (SU), we define a metric for categorical random variables and show that this metric can be promoted into an appropriate quotient space of categorical random variables. Moreover, we also show that there is a natural commutative monoid structure in the same quotient space, which is compatible with the topology induced by the metric, in the sense that the monoid operation is continuous.

</details>
