<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 6]
- [cs.AI](#cs.AI) [Total: 17]
- [cs.IT](#cs.IT) [Total: 2]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [OpenRASE: Service Function Chain Emulation](https://arxiv.org/abs/2507.22131)
*Theviyanthan Krishnamohan,Paul Harvey*

Main category: cs.NI

TL;DR: OpenRASE是一个基于Mininet和Docker的SFC仿真器，旨在动态环境中探索资源分配算法，并测量实际CPU使用和延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的SFC资源分配算法评估工具存在不准确、低保真、不可扩展、不灵活或需要额外代码的问题，OpenRASE旨在解决这些问题。

Method: 基于Mininet和Docker设计并实现OpenRASE仿真器，用于动态评估SFC资源分配算法，包括在线遗传算法。

Result: 实验表明OpenRASE能有效评估动态网络条件下的资源分配算法，验证了其实际应用价值。

Conclusion: OpenRASE为SFC资源分配算法的动态评估提供了高效、灵活的工具，解决了现有工具的局限性。

Abstract: Service Function Chains (SFCs) are one of the key enablers in providing
programmable computer networks, paving the way for network autonomy. However,
this also introduces new challenges, such as resource allocation and
optimisation related to their operation, requiring new algorithms to address
these challenges. Various tools have been used in the literature to evaluate
these algorithms. However, these tools suffer from inaccuracy, low fidelity,
unscalability, inflexibility, or additional code requirements. This paper
introduces an emulator based on Mininet and Docker for SFCs called OpenRASE.
The goal of OpenRASE is to enable the exploration of resource allocation
algorithms for SFCs in a dynamic setting, allowing real CPU usage and latency
to be measured. We describe the design and implementation of OpenRASE and
discuss its characteristics. We also experimentally evaluate two different
algorithms to address the SFC resource allocation challenge, including an
online Genetic Algorithm, using OpenRASE to show its effectiveness and
practicality for dynamic network conditions.

</details>


### [2] [AdapSCA-PSO: An Adaptive Localization Algorithm with AI-Based Hybrid SCA-PSO for IoT WSNs](https://arxiv.org/abs/2507.22317)
*Ze Zhang,Qian Dong,Wenhan Wang*

Main category: cs.NI

TL;DR: 提出了一种混合元启发式定位算法，结合SCA和PSO，通过自适应切换模块动态选择算法，显著降低了定位误差和迭代次数。


<details>
  <summary>Details</summary>
Motivation: 物联网应用中传感器节点的精确定位是关键需求，需适应多样化环境。

Method: 整合SCA（全局搜索）和PSO（局部搜索），引入自适应切换模块，优化初始化和参数设置。

Result: 相比单独PSO和未优化的SCAPSO，迭代次数减少，平均定位误差降低84.97%。

Conclusion: 该算法在多样化环境中表现优异，显著提升了定位精度和效率。

Abstract: The accurate localization of sensor nodes is a fundamental requirement for
the practical application of the Internet of Things (IoT). To enable robust
localization across diverse environments, this paper proposes a hybrid
meta-heuristic localization algorithm. Specifically, the algorithm integrates
the Sine Cosine Algorithm (SCA), which is effective in global search, with
Particle Swarm Optimization (PSO), which excels at local search. An adaptive
switching module is introduced to dynamically select between the two
algorithms. Furthermore, the initialization, fitness evaluation, and parameter
settings of the algorithm have been specifically redesigned and optimized to
address the characteristics of the node localization problem. Simulation
results across varying numbers of sensor nodes demonstrate that, compared to
standalone PSO and the unoptimized SCAPSO algorithm, the proposed method
significantly reduces the number of required iterations and achieves an average
localization error reduction of 84.97%.

</details>


### [3] [802.11bf Multiband Passive Sensing: Reusing Wi-Fi Signaling for Sensing](https://arxiv.org/abs/2507.22591)
*Pablo Picazo-Martinez,Carlos Barroso-Fernández,Alejandro Calvillo-Fernandez,Milan Groshev,Carlos J. Bernardos,Antonio de la Oliva,Alain Mourad*

Main category: cs.NI

TL;DR: 本文提出了一种新型多频段被动传感系统，利用IEEE 802.11bf Wi-Fi信号进行环境感知，结合多频段数据提升检测精度。


<details>
  <summary>Details</summary>
Motivation: 通过结合多个频段的信道状态信息（CSI），提升室内环境中人类存在、移动和活动检测的准确性和可靠性。

Method: 采用名为MILAGRO的新模型，结合多频段数据，实现高精度检测。

Result: 实验结果显示系统准确率高达95-100%，并通过多频段数据集成进一步提升了性能。

Conclusion: 该系统减少了主动传感基础设施的依赖，扩展了低成本、非侵入式环境监测的能力，同时解决了相关的安全风险。

Abstract: This paper presents a novel multiband passive sensing system that leverages
IEEE 802.11bf Wi-Fi signals for environmental sensing, focusing on both sub-7
GHz and millimeter-wave (mmWave) bands. By combining Channel State Information
(CSI) from multiple bands, the system enhances accuracy and reliability in
detecting human presence, movement, and activities in indoor environments.
Utilizing a novel model, called MILAGRO, the system demonstrates robust
performance across different scenarios, including monitoring human presence in
workspaces and tracking movement in corridors. Experimental results show high
accuracy (95-100%), with improved performance by integrating multiband data.
The system also addresses key security concerns associated with passive
sensing, proposing measures to mitigate potential risks. This work advances the
use of Wi-Fi for passive sensing by reducing reliance on active sensing
infrastructure and extending the capabilities of low-cost, non-intrusive
environmental monitoring.

</details>


### [4] [Bifröst: Spatial Networking with Bigraphs](https://arxiv.org/abs/2507.22687)
*Josh Millar,Ryan Gibb,Roy Ang,Anil Madhavapeddy,Hamed Haddadi*

Main category: cs.NI

TL;DR: 提出基于bigraph的统一表示和分层代理架构，实现分布式空间推理和低延迟空间网络。


<details>
  <summary>Details</summary>
Motivation: 现代网络环境缺乏协调物理空间的统一表示，导致空间访问策略等任务脆弱且依赖人工。

Method: 1. 使用bigraph统一表示空间、社交和通信关系；2. 提出分层代理架构，支持分布式空间推理和上下文感知执行。

Result: 实现了私有、可靠且低延迟的空间网络，能够安全地与代理工作流交互。

Conclusion: 该方法为现代网络环境提供了高效的空间推理和协调解决方案。

Abstract: Modern networked environments increasingly rely on spatial reasoning, but
lack a coherent representation for coordinating physical space. Consequently,
tasks such as enforcing spatial access policies remain fragile and manual. We
first propose a unifying representation based on bigraphs, capturing spatial,
social, and communication relationships within a single formalism, with
user-facing tools to generate bigraphs from physical environments. Second, we
present a hierarchical agent architecture for distributed spatial reasoning,
with runtimes for agentic processes to interact the spatial representation, and
a context-aware execution model that scopes reasoning to the smallest viable
subspace. Together, these enable private, reliable, and low-latency spatial
networking that can safely interact with agentic workflows.

</details>


### [5] [OFCnetLLM: Large Language Model for Network Monitoring and Alertness](https://arxiv.org/abs/2507.22711)
*Hong-Jun Yoon,Mariam Kiran,Danial Ebling,Joe Breen*

Main category: cs.NI

TL;DR: 论文探讨了利用大型语言模型（LLMs）优化网络监控管理，通过增强异常检测、自动化根因分析和事件分析，降低管理大规模监控数据库的成本。


<details>
  <summary>Details</summary>
Motivation: 网络基础设施的快速演进带来了新的挑战和机遇，尤其是在高效管理、优化和安全性方面。大规模监控数据库的高成本探索促使研究利用AI和生成式AI技术。

Method: 开发了基于开源LLM模型的多代理系统OFCNetLLM，应用于OFC会议网络，以提升查询发现和模式分析的效率。

Result: 初步结果显示，OFCNetLLM在网络监控管理中具有实际应用潜力，尤其是在异常检测和自动化分析方面。

Conclusion: LLMs在网络监控管理中的应用前景广阔，OFCNetLLM的持续发展为未来研究提供了方向。

Abstract: The rapid evolution of network infrastructure is bringing new challenges and
opportunities for efficient network management, optimization, and security.
With very large monitoring databases becoming expensive to explore, the use of
AI and Generative AI can help reduce costs of managing these datasets. This
paper explores the use of Large Language Models (LLMs) to revolutionize network
monitoring management by addressing the limitations of query finding and
pattern analysis. We leverage LLMs to enhance anomaly detection, automate
root-cause analysis, and automate incident analysis to build a well-monitored
network management team using AI. Through a real-world example of developing
our own OFCNetLLM, based on the open-source LLM model, we demonstrate practical
applications of OFCnetLLM in the OFC conference network. Our model is developed
as a multi-agent approach and is still evolving, and we present early results
here.

</details>


### [6] [Morph: ChirpTransformer-based Encoder-decoder Co-design for Reliable LoRa Communication](https://arxiv.org/abs/2507.22851)
*Yidong Ren,Maolin Gan,Chenning Li,Shakhrul Iman Siam,Mi Zhang,Shigang Chen,Zhichao Cao*

Main category: cs.NI

TL;DR: Morph是一种LoRa编码器-解码器协同设计，旨在极低信噪比（SNR）下提升通信可靠性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 标准LoRa编码器在商用节点上仅支持6种扩频因子（SF），无法满足极低SNR需求。Morph通过模拟更大SF配置，兼容现有节点并提升性能。

Method: 开发基于SF配置的编码器模拟更大SF，利用DNN解码器捕获多维特征以最大化SNR增益，并优化DNN结构和训练方法。

Result: 在室内和校园测试中，Morph在-28.8dB SNR下可靠解码数据，比标准LoRa（SF-12）低6.4dB，且DNN解码器计算效率提升3倍。

Conclusion: Morph通过编码器-解码器协同设计，显著提升了LoRa在极低SNR下的性能和效率，具有实际应用潜力。

Abstract: In this paper, we propose Morph, a LoRa encoder-decoder co-design to enhance
communication reliability while improving its computation efficiency in
extremely-low signal-to-noise ratio (SNR) situations. The standard LoRa encoder
controls 6 Spreading Factors (SFs) to tradeoff SNR tolerance with data rate.
SF-12 is the maximum SF providing the lowest SNR tolerance on commercial
off-the-shelf (COTS) LoRa nodes. In Morph, we develop an SF-configuration based
encoder to mimic the larger SFs beyond SF-12 while it is compatible with COTS
LoRa nodes. Specifically, we manipulate four SF configurations of a Morph
symbol to encode 2-bit data. Accordingly, we recognize the used SF
configuration of the symbol for data decoding. We leverage a Deep Neural
Network (DNN) decoder to fully capture multi-dimensional features among diverse
SF configurations to maximize the SNR gain. Moreover, we customize the input
size, neural network structure, and training method of the DNN decoder to
improve its efficiency, reliability, and generalizability. We implement Morph
with COTS LoRa nodes and a USRP N210, then evaluate its performance on indoor
and campus-scale testbeds. Results show that we can reliably decode data at
-28.8~dB SNR, which is 6.4~dB lower than the standard LoRa with SF-12 chirps.
In addition, the computation efficiency of our DNN decoder is about 3x higher
than state-of-the-art.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [When Truthful Representations Flip Under Deceptive Instructions?](https://arxiv.org/abs/2507.22149)
*Xianxuan Long,Yao Fu,Runchao Li,Mu Sheng,Haotian Yu,Xiaotian Han,Pan Li*

Main category: cs.AI

TL;DR: 论文研究了大型语言模型（LLM）在欺骗性指令下内部表征的变化，发现欺骗性指令会导致显著的表征偏移，主要集中在早期到中间层。


<details>
  <summary>Details</summary>
Motivation: 理解欺骗性指令如何改变LLM的内部表征，以解决模型安全性问题。

Method: 通过线性探测和稀疏自编码器（SAEs）分析Llama-3.1-8B-Instruct和Gemma-2-9B-Instruct在事实验证任务中的内部表征。

Result: 欺骗性指令导致显著的表征偏移，且这些偏移集中在早期到中间层；特定SAE特征对欺骗性指令高度敏感。

Conclusion: 研究揭示了欺骗性指令的表征特征，为LLM的检测和控制提供了新思路。

Abstract: Large language models (LLMs) tend to follow maliciously crafted instructions
to generate deceptive responses, posing safety challenges. How deceptive
instructions alter the internal representations of LLM compared to truthful
ones remains poorly understood beyond output analysis. To bridge this gap, we
investigate when and how these representations ``flip'', such as from truthful
to deceptive, under deceptive versus truthful/neutral instructions. Analyzing
the internal representations of Llama-3.1-8B-Instruct and Gemma-2-9B-Instruct
on a factual verification task, we find the model's instructed True/False
output is predictable via linear probes across all conditions based on the
internal representation. Further, we use Sparse Autoencoders (SAEs) to show
that the Deceptive instructions induce significant representational shifts
compared to Truthful/Neutral representations (which are similar), concentrated
in early-to-mid layers and detectable even on complex datasets. We also
identify specific SAE features highly sensitive to deceptive instruction and
use targeted visualizations to confirm distinct truthful/deceptive
representational subspaces. % Our analysis pinpoints layer-wise and
feature-level correlates of instructed dishonesty, offering insights for LLM
detection and control. Our findings expose feature- and layer-level signatures
of deception, offering new insights for detecting and mitigating instructed
dishonesty in LLMs.

</details>


### [8] [Explainability Through Systematicity: The Hard Systematicity Challenge for Artificial Intelligence](https://arxiv.org/abs/2507.22197)
*Matthieu Queloz*

Main category: cs.AI

TL;DR: 本文探讨了AI的系统性（systematicity）问题，认为解释性只是系统性的一部分，并提出了一个区分系统性四种含义的框架，以缓解系统性与连接主义之间的紧张关系。


<details>
  <summary>Details</summary>
Motivation: 探讨AI是否应满足更高标准的系统性，以及这种系统性如何影响AI的理性、权威性和科学性。

Method: 提出一个概念框架，区分系统性的四种含义，并分析五种系统化的理由在AI中的应用。

Result: 揭示了"硬系统性挑战"，并指出系统化需求应由其理由动态调节。

Conclusion: 系统性需求应根据其理由动态调整，以确定AI模型需要多高的系统性以及何时需要。

Abstract: This paper argues that explainability is only one facet of a broader ideal
that shapes our expectations towards artificial intelligence (AI).
Fundamentally, the issue is to what extent AI exhibits systematicity--not
merely in being sensitive to how thoughts are composed of recombinable
constituents, but in striving towards an integrated body of thought that is
consistent, coherent, comprehensive, and parsimoniously principled. This richer
conception of systematicity has been obscured by the long shadow of the
"systematicity challenge" to connectionism, according to which network
architectures are fundamentally at odds with what Fodor and colleagues termed
"the systematicity of thought." I offer a conceptual framework for thinking
about "the systematicity of thought" that distinguishes four senses of the
phrase. I use these distinctions to defuse the perceived tension between
systematicity and connectionism and show that the conception of systematicity
that historically shaped our sense of what makes thought rational,
authoritative, and scientific is more demanding than the Fodorian notion. To
determine whether we have reason to hold AI models to this ideal of
systematicity, I then argue, we must look to the rationales for systematization
and explore to what extent they transfer to AI models. I identify five such
rationales and apply them to AI. This brings into view the "hard systematicity
challenge." However, the demand for systematization itself needs to be
regulated by the rationales for systematization. This yields a dynamic
understanding of the need to systematize thought, which tells us how systematic
we need AI models to be and when.

</details>


### [9] [CoEx -- Co-evolving World-model and Exploration](https://arxiv.org/abs/2507.22281)
*Minsoo Kim,Seung-won Hwang*

Main category: cs.AI

TL;DR: CoEx提出了一种分层代理架构，通过动态更新世界模型解决LLM代理在规划中的静态世界模型问题。


<details>
  <summary>Details</summary>
Motivation: 现有代理设计无法有效利用新观察动态更新世界模型，导致规划与真实世界状态不一致。

Method: 采用分层状态抽象，结合LLM推理和神经符号信念状态（文本推断与代码符号记忆）动态更新世界模型。

Result: 在ALFWorld、PDDL和Jericho等复杂任务中，CoEx在规划和探索方面优于现有代理范式。

Conclusion: CoEx通过动态世界模型更新和分层规划，显著提升了代理的规划能力和适应性。

Abstract: Planning in modern LLM agents relies on the utilization of LLM as an internal
world model, acquired during pretraining. However, existing agent designs fail
to effectively assimilate new observations into dynamic updates of the world
model. This reliance on the LLM's static internal world model is progressively
prone to misalignment with the underlying true state of the world, leading to
the generation of divergent and erroneous plans. We introduce a hierarchical
agent architecture, CoEx, in which hierarchical state abstraction allows LLM
planning to co-evolve with a dynamically updated model of the world. CoEx plans
and interacts with the world by using LLM reasoning to orchestrate dynamic
plans consisting of subgoals, and its learning mechanism continuously
incorporates these subgoal experiences into a persistent world model in the
form of a neurosymbolic belief state, comprising textual inferences and
code-based symbolic memory. We evaluate our agent across a diverse set of agent
scenarios involving rich environments and complex tasks including ALFWorld,
PDDL, and Jericho. Our experiments show that CoEx outperforms existing agent
paradigms in planning and exploration.

</details>


### [10] [An Explainable Emotion Alignment Framework for LLM-Empowered Agent in Metaverse Service Ecosystem](https://arxiv.org/abs/2507.22326)
*Qun Ma,Xiao Xue,Ming Zhang,Yifan Shen,Zihan Zhao*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型（LLM）的可解释情感对齐框架，用于解决元宇宙服务生态中虚拟与现实服务融合的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的兴起，元宇宙服务生态中的代理面临虚拟与现实服务融合的挑战，如角色数据融合、知识关联和伦理安全问题。

Method: 提出了一种可解释情感对齐框架，将事实因素融入LLM代理的决策循环，实现更关系化的事实对齐。

Result: 在离线到离线外卖场景的模拟实验中验证了框架的有效性，获得了更真实的社会涌现。

Conclusion: 该框架为LLM代理在元宇宙服务生态中的应用提供了可行的解决方案，提升了虚拟与现实服务的融合效果。

Abstract: Metaverse service is a product of the convergence between Metaverse and
service systems, designed to address service-related challenges concerning
digital avatars, digital twins, and digital natives within Metaverse. With the
rise of large language models (LLMs), agents now play a pivotal role in
Metaverse service ecosystem, serving dual functions: as digital avatars
representing users in the virtual realm and as service assistants (or NPCs)
providing personalized support. However, during the modeling of Metaverse
service ecosystems, existing LLM-based agents face significant challenges in
bridging virtual-world services with real-world services, particularly
regarding issues such as character data fusion, character knowledge
association, and ethical safety concerns. This paper proposes an explainable
emotion alignment framework for LLM-based agents in Metaverse Service
Ecosystem. It aims to integrate factual factors into the decision-making loop
of LLM-based agents, systematically demonstrating how to achieve more
relational fact alignment for these agents. Finally, a simulation experiment in
the Offline-to-Offline food delivery scenario is conducted to evaluate the
effectiveness of this framework, obtaining more realistic social emergence.

</details>


### [11] [Magentic-UI: Towards Human-in-the-loop Agentic Systems](https://arxiv.org/abs/2507.22358)
*Hussein Mozannar,Gagan Bansal,Cheng Tan,Adam Fourney,Victor Dibia,Jingya Chen,Jack Gerrits,Tyler Payne,Matheus Kunzler Maldaner,Madeleine Grunde-McLaughlin,Eric Zhu,Griffin Bassman,Jacob Alber,Peter Chang,Ricky Loynd,Friederike Niedtner,Ece Kamar,Maya Murad,Rafah Hosn,Saleema Amershi*

Main category: cs.AI

TL;DR: 论文探讨了AI代理在复杂任务中的局限性及安全风险，提出人机协作系统Magentic-UI，通过六种交互机制提升效率与安全性。


<details>
  <summary>Details</summary>
Motivation: AI代理在复杂任务中表现不足且存在安全风险，需结合人类监督以提高性能与安全性。

Method: 开发Magentic-UI，支持多工具扩展，提供六种交互机制（如协作规划、任务守卫等），并通过四项评估验证其有效性。

Result: Magentic-UI在任务完成、用户测试、定性研究和安全评估中表现优异，展示了人机协作的潜力。

Conclusion: Magentic-UI为人机协作提供了安全高效的解决方案，未来可进一步优化与扩展。

Abstract: AI agents powered by large language models are increasingly capable of
autonomously completing complex, multi-step tasks using external tools. Yet,
they still fall short of human-level performance in most domains including
computer use, software development, and research. Their growing autonomy and
ability to interact with the outside world, also introduces safety and security
risks including potentially misaligned actions and adversarial manipulation. We
argue that human-in-the-loop agentic systems offer a promising path forward,
combining human oversight and control with AI efficiency to unlock productivity
from imperfect systems. We introduce Magentic-UI, an open-source web interface
for developing and studying human-agent interaction. Built on a flexible
multi-agent architecture, Magentic-UI supports web browsing, code execution,
and file manipulation, and can be extended with diverse tools via Model Context
Protocol (MCP). Moreover, Magentic-UI presents six interaction mechanisms for
enabling effective, low-cost human involvement: co-planning, co-tasking,
multi-tasking, action guards, and long-term memory. We evaluate Magentic-UI
across four dimensions: autonomous task completion on agentic benchmarks,
simulated user testing of its interaction capabilities, qualitative studies
with real users, and targeted safety assessments. Our findings highlight
Magentic-UI's potential to advance safe and efficient human-agent
collaboration.

</details>


### [12] [LLM-Crowdsourced: A Benchmark-Free Paradigm for Mutual Evaluation of Large Language Models](https://arxiv.org/abs/2507.22359)
*Qianhong Guo,Wei Xie,Xiaofang Cai,Enze Wang,Shuoyoucheng Ma,Kai Chen,Xiaofeng Wang,Baosheng Wang*

Main category: cs.AI

TL;DR: 提出了一种名为LLM-Crowdsourced的无基准评估范式，通过LLM生成问题、独立回答和相互评估，解决了现有评估方法的数据污染、黑箱操作和主观偏好问题。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法存在数据污染、黑箱操作和主观偏好等问题，难以全面评估LLM的真实能力。

Method: 提出LLM-Crowdsourced方法，利用LLM生成问题、独立回答和相互评估，满足动态、透明、客观和专业的评估标准。

Result: 在数学和编程领域的八种主流LLM上验证了方法的优势，并发现了一些传统方法难以检测的新现象。

Conclusion: LLM-Crowdsourced方法在评估LLM能力方面具有显著优势，能够揭示传统方法难以发现的现象。

Abstract: Although large language models (LLMs) demonstrate remarkable capabilities
across various tasks, evaluating their capabilities remains a challenging task.
Existing evaluation methods suffer from issues such as data contamination,
black-box operation, and subjective preference. These issues make it difficult
to evaluate the LLMs' true capabilities comprehensively. To tackle these
challenges, we propose a novel benchmark-free evaluation paradigm,
LLM-Crowdsourced. It utilizes LLMs to generate questions, answer independently,
and evaluate mutually. This method integrates four key evaluation criteria:
dynamic, transparent, objective, and professional, which existing evaluation
methods cannot satisfy simultaneously. Experiments on eight mainstream LLMs
across mathematics and programming verify the advantages of our method in
distinguishing LLM performance. Furthermore, our study reveals several novel
findings that are difficult for traditional methods to detect, including but
not limited to: (1) Gemini demonstrates the highest original and professional
question-design capabilities among others; (2) Some LLMs exhibit
''memorization-based answering'' by misrecognizing questions as familiar ones
with a similar structure; (3) LLM evaluation results demonstrate high
consistency (robustness).

</details>


### [13] [Beyond Accuracy: How AI Metacognitive Sensitivity improves AI-assisted Decision Making](https://arxiv.org/abs/2507.22365)
*ZhaoBin Li,Mark Steyvers*

Main category: cs.AI

TL;DR: AI的元认知敏感性（准确区分预测正确与否的能力）与预测准确性共同影响人类决策质量。研究发现，元认知敏感性高的AI即使预测准确性较低，也能提升人类决策表现。


<details>
  <summary>Details</summary>
Motivation: 探讨AI的预测准确性和元认知敏感性如何共同影响人类决策质量。

Method: 提出理论框架分析AI预测准确性和元认知敏感性的联合影响，并通过行为实验验证。

Result: 元认知敏感性高的AI能提升人类决策表现，即使其预测准确性较低。

Conclusion: 评估AI辅助时需同时考虑预测准确性和元认知敏感性，优化两者以实现更优决策结果。

Abstract: In settings where human decision-making relies on AI input, both the
predictive accuracy of the AI system and the reliability of its confidence
estimates influence decision quality. We highlight the role of AI metacognitive
sensitivity -- its ability to assign confidence scores that accurately
distinguish correct from incorrect predictions -- and introduce a theoretical
framework for assessing the joint impact of AI's predictive accuracy and
metacognitive sensitivity in hybrid decision-making settings. Our analysis
identifies conditions under which an AI with lower predictive accuracy but
higher metacognitive sensitivity can enhance the overall accuracy of human
decision making. Finally, a behavioral experiment confirms that greater AI
metacognitive sensitivity improves human decision performance. Together, these
findings underscore the importance of evaluating AI assistance not only by
accuracy but also by metacognitive sensitivity, and of optimizing both to
achieve superior decision outcomes.

</details>


### [14] [On the Definition of Intelligence](https://arxiv.org/abs/2507.22423)
*Kei-Sing Ng*

Main category: cs.AI

TL;DR: 论文提出了一个基于样本保真度的通用智能标准，即智能是能够根据类别样本生成同类样本的能力，并形式化为ε-类别智能。


<details>
  <summary>Details</summary>
Motivation: 为了构建通用人工智能（AGI），需要一种能够评估智能本质的物种无关形式，同时涵盖多种智能行为范式。

Method: 提出ε-类别智能框架，通过样本生成能力定义智能，并设计可区分的评估协议。

Result: 形式化框架和实证协议为智能评估、安全性和泛化性提供了理论基础。

Conclusion: 该标准为AGI的发展提供了一种通用且可操作的智能定义和评估方法。

Abstract: To engineer AGI, we should first capture the essence of intelligence in a
species-agnostic form that can be evaluated, while being sufficiently general
to encompass diverse paradigms of intelligent behavior, including reinforcement
learning, generative models, classification, analogical reasoning, and
goal-directed decision-making. We propose a general criterion based on sample
fidelity: intelligence is the ability, given sample(s) from a category, to
generate sample(s) from the same category. We formalise this intuition as
{\epsilon}-category intelligence: it is {\epsilon}-intelligent with respect to
a category if no chosen admissible distinguisher can separate generated from
original samples beyond tolerance {\epsilon}. We present the formal framework,
outline empirical protocols, and discuss implications for evaluation, safety,
and generalization.

</details>


### [15] [Cross-Border Legal Adaptation of Autonomous Vehicle Design based on Logic and Non-monotonic Reasoning](https://arxiv.org/abs/2507.22432)
*Zhe Yu,Yiwei Lu,Burkhard Schafer,Zhe Lin*

Main category: cs.AI

TL;DR: 论文探讨了跨国背景下自动驾驶车辆的法律合规挑战，从设计者视角出发，结合论证理论和优先级表达逻辑，为设计过程提供法律推理支持。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶车辆在跨国应用中的法律合规问题，帮助设计者在设计过程中更好地理解和适应不同法律环境。

Method: 基于论证理论，引入逻辑表示论证性实践（规范性）推理的基本属性，并结合自然数的偏序集表达优先级。

Result: 通过法律文本的案例分析，展示了所提推理系统如何帮助设计者更灵活地调整设计方案，并更容易理解其决策的法律影响。

Conclusion: 论文提出的推理系统为自动驾驶车辆跨国应用中的法律合规提供了实用工具，增强了设计者对法律环境的适应能力。

Abstract: This paper focuses on the legal compliance challenges of autonomous vehicles
in a transnational context. We choose the perspective of designers and try to
provide supporting legal reasoning in the design process. Based on
argumentation theory, we introduce a logic to represent the basic properties of
argument-based practical (normative) reasoning, combined with partial order
sets of natural numbers to express priority. Finally, through case analysis of
legal texts, we show how the reasoning system we provide can help designers to
adapt their design solutions more flexibly in the cross-border application of
autonomous vehicles and to more easily understand the legal implications of
their decisions.

</details>


### [16] [Nearest-Better Network for Visualizing and Analyzing Combinatorial Optimization Problems: A Unified Tool](https://arxiv.org/abs/2507.22440)
*Yiya Diao,Changhe Li,Sanyou Zeng,Xinye Cai,Wenjian Luo,Shengxiang Yang,Carlos A. Coello Coello*

Main category: cs.AI

TL;DR: 本文提出了一种高效的NBN计算方法，解决了其计算耗时问题，并首次揭示了OneMax和TSP问题的景观特征及算法局限性。


<details>
  <summary>Details</summary>
Motivation: 解决NBN计算耗时问题，并扩展其应用于组合优化问题，以分析算法行为。

Method: 通过理论推导证明NBN作为最大概率转移网络的功能，并提出对数线性时间复杂度的NBN计算方法。

Result: 发现OneMax问题具有中性、崎岖性和模态特征；TSP问题的主要挑战是崎岖性、模态性和欺骗性。EAX和LKH算法在应对模态性和欺骗性时存在局限性。

Conclusion: 高效的NBN计算方法为优化问题分析提供了新工具，揭示了算法在复杂景观中的行为特征和局限性。

Abstract: The Nearest-Better Network (NBN) is a powerful method to visualize sampled
data for continuous optimization problems while preserving multiple landscape
features. However, the calculation of NBN is very time-consuming, and the
extension of the method to combinatorial optimization problems is challenging
but very important for analyzing the algorithm's behavior. This paper provides
a straightforward theoretical derivation showing that the NBN network
essentially functions as the maximum probability transition network for
algorithms. This paper also presents an efficient NBN computation method with
logarithmic linear time complexity to address the time-consuming issue. By
applying this efficient NBN algorithm to the OneMax problem and the Traveling
Salesman Problem (TSP), we have made several remarkable discoveries for the
first time: The fitness landscape of OneMax exhibits neutrality, ruggedness,
and modality features. The primary challenges of TSP problems are ruggedness,
modality, and deception. Two state-of-the-art TSP algorithms (i.e., EAX and
LKH) have limitations when addressing challenges related to modality and
deception, respectively. LKH, based on local search operators, fails when there
are deceptive solutions near global optima. EAX, which is based on a single
population, can efficiently maintain diversity. However, when multiple
attraction basins exist, EAX retains individuals within multiple basins
simultaneously, reducing inter-basin interaction efficiency and leading to
algorithm's stagnation.

</details>


### [17] [Collaborative Medical Triage under Uncertainty: A Multi-Agent Dynamic Matching Approach](https://arxiv.org/abs/2507.22504)
*Hongyan Cheng,Chengzhang Yu,Yanshu Shi,Chiyue Wang,Cong Liu,Zhanpeng Jin*

Main category: cs.AI

TL;DR: 提出了一种多代理交互智能系统，解决AI分诊中的医疗专业化不足、机构异构性和低效提问问题，实验显示高准确率。


<details>
  <summary>Details</summary>
Motivation: 疫情后医疗需求激增和护士短缺，急需AI驱动的分诊创新方案。

Method: 采用三个专业代理（RecipientAgent、InquirerAgent、DepartmentAgent）协作，通过结构化提问和科室规则实现精准分诊。

Result: 系统在四轮交互后，主科室分类准确率达89.2%，次科室达73.9%。

Conclusion: 该系统为AI辅助分诊提供了可扩展框架，适应医疗机构异构性并确保临床决策可靠性。

Abstract: The post-pandemic surge in healthcare demand, coupled with critical nursing
shortages, has placed unprecedented pressure on emergency department triage
systems, necessitating innovative AI-driven solutions. We present a multi-agent
interactive intelligent system for medical triage that addresses three
fundamental challenges in current AI-based triage systems: insufficient medical
specialization leading to hallucination-induced misclassifications,
heterogeneous department structures across healthcare institutions, and
inefficient detail-oriented questioning that impedes rapid triage decisions.
Our system employs three specialized agents - RecipientAgent, InquirerAgent,
and DepartmentAgent - that collaborate through structured inquiry mechanisms
and department-specific guidance rules to transform unstructured patient
symptoms into accurate department recommendations. To ensure robust evaluation,
we constructed a comprehensive Chinese medical triage dataset from a medical
website, comprising 3,360 real-world cases spanning 9 primary departments and
62 secondary departments. Through systematic data imputation using large
language models, we address the prevalent issue of incomplete medical records
in real-world data. Experimental results demonstrate that our multi-agent
system achieves 89.2% accuracy in primary department classification and 73.9%
accuracy in secondary department classification after four rounds of patient
interaction. The system's pattern-matching-based guidance mechanisms enable
efficient adaptation to diverse hospital configurations while maintaining high
triage accuracy. Our work provides a scalable framework for deploying
AI-assisted triage systems that can accommodate the organizational
heterogeneity of healthcare institutions while ensuring clinically sound
decision-making.

</details>


### [18] [MetaAgent: Automatically Constructing Multi-Agent Systems Based on Finite State Machines](https://arxiv.org/abs/2507.22606)
*Yaolun Zhang,Xiaogeng Liu,Chaowei Xiao*

Main category: cs.AI

TL;DR: MetaAgent是一个基于有限状态机的框架，能自动生成多智能体系统，并通过优化算法改进，性能优于其他自动设计方法，接近人工设计的系统。


<details>
  <summary>Details</summary>
Motivation: 现有的人工设计多智能体框架局限于预定义场景，自动设计方法存在工具集成不足、依赖外部数据、通信结构僵化等问题。

Method: 提出MetaAgent框架，基于有限状态机自动生成多智能体系统，并通过优化算法优化。

Result: 实验表明，生成的多智能体系统优于其他自动设计方法，性能接近人工设计的系统。

Conclusion: MetaAgent为解决多智能体系统自动设计问题提供了有效方案。

Abstract: Large Language Models (LLMs) have demonstrated the ability to solve a wide
range of practical tasks within multi-agent systems. However, existing
human-designed multi-agent frameworks are typically limited to a small set of
pre-defined scenarios, while current automated design methods suffer from
several limitations, such as the lack of tool integration, dependence on
external training data, and rigid communication structures. In this paper, we
propose MetaAgent, a finite state machine based framework that can
automatically generate a multi-agent system. Given a task description,
MetaAgent will design a multi-agent system and polish it through an
optimization algorithm. When the multi-agent system is deployed, the finite
state machine will control the agent's actions and the state transitions. To
evaluate our framework, we conduct experiments on both text-based tasks and
practical tasks. The results indicate that the generated multi-agent system
surpasses other auto-designed methods and can achieve a comparable performance
with the human-designed multi-agent system, which is optimized for those
specific tasks.

</details>


### [19] [Enhancing Manufacturing Knowledge Access with LLMs and Context-aware Prompting](https://arxiv.org/abs/2507.22619)
*Sebastian Monka,Irlan Grangel-González,Stefan Schmid,Lavdim Halilaj,Marc Rickart,Oliver Rudolph,Rui Dias*

Main category: cs.AI

TL;DR: 论文探讨了如何利用大语言模型（LLMs）将自然语言查询转换为SPARQL查询，以简化知识图谱（KGs）在制造业中的使用，并通过上下文提示技术提高查询准确性。


<details>
  <summary>Details</summary>
Motivation: 制造业中知识图谱（KGs）的使用对非专家用户存在门槛，需要复杂的SPARQL查询。大语言模型（LLMs）有望通过自然语言查询转换降低这一门槛。

Method: 评估了多种策略，利用LLMs作为中介，从制造业特定的KGs（如Bosch Line Information System KG和I40 Core Information Model）中检索信息，并比较了不同上下文提示方法的效果。

Result: 研究发现，当LLMs获得适当的KG上下文时，其生成正确和完整查询的能力显著提升，上下文提示技术减少了幻觉风险。

Conclusion: 提出的技术有助于LLMs简化对复杂数据存储库的访问，支持制造业中的决策制定。

Abstract: Knowledge graphs (KGs) have transformed data management within the
manufacturing industry, offering effective means for integrating disparate data
sources through shared and structured conceptual schemas. However, harnessing
the power of KGs can be daunting for non-experts, as it often requires
formulating complex SPARQL queries to retrieve specific information. With the
advent of Large Language Models (LLMs), there is a growing potential to
automatically translate natural language queries into the SPARQL format, thus
bridging the gap between user-friendly interfaces and the sophisticated
architecture of KGs. The challenge remains in adequately informing LLMs about
the relevant context and structure of domain-specific KGs, e.g., in
manufacturing, to improve the accuracy of generated queries. In this paper, we
evaluate multiple strategies that use LLMs as mediators to facilitate
information retrieval from KGs. We focus on the manufacturing domain,
particularly on the Bosch Line Information System KG and the I40 Core
Information Model. In our evaluation, we compare various approaches for feeding
relevant context from the KG to the LLM and analyze their proficiency in
transforming real-world questions into SPARQL queries. Our findings show that
LLMs can significantly improve their performance on generating correct and
complete queries when provided only the adequate context of the KG schema. Such
context-aware prompting techniques help LLMs to focus on the relevant parts of
the ontology and reduce the risk of hallucination. We anticipate that the
proposed techniques help LLMs to democratize access to complex data
repositories and empower informed decision-making in manufacturing settings.

</details>


### [20] [ASP-FZN: A Translation-based Constraint Answer Set Solver](https://arxiv.org/abs/2507.22774)
*Thomas Eiter,Tobias Geibinger,Tobias Kaminski,Nysret Musliu,Johannes Oetsch*

Main category: cs.AI

TL;DR: asp-fzn是一个用于约束答案集编程（CASP）的求解器，通过将CASP程序转换为FlatZinc语言支持多种后端求解器，性能与现有ASP求解器相当，并在某些CASP基准测试中优于clingcon。


<details>
  <summary>Details</summary>
Motivation: 扩展ASP以支持线性约束，提供更丰富的约束语言，并利用FlatZinc的多后端求解器支持。

Method: 将CASP程序翻译为FlatZinc语言，支持多种约束编程和整数编程后端求解器。

Result: asp-fzn在ASP基准测试中表现优异，并在某些CASP问题上优于clingcon。

Conclusion: asp-fzn是一个有竞争力的CASP求解器，性能优越，尤其在支持线性约束方面表现突出。

Abstract: We present the solver asp-fzn for Constraint Answer Set Programming (CASP),
which extends ASP with linear constraints. Our approach is based on translating
CASP programs into the solver-independent FlatZinc language that supports
several Constraint Programming and Integer Programming backend solvers. Our
solver supports a rich language of linear constraints, including some common
global constraints. As for evaluation, we show that asp-fzn is competitive with
state-of-the-art ASP solvers on benchmarks taken from past ASP competitions.
Furthermore, we evaluate it on several CASP problems from the literature and
compare its performance with clingcon, which is a prominent CASP solver that
supports most of the asp-fzn language. The performance of asp-fzn is very
promising as it is already competitive on plain ASP and even outperforms
clingcon on some CASP benchmarks.

</details>


### [21] [Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic Policies](https://arxiv.org/abs/2507.22782)
*Hugo Garrido-Lestache,Jeremy Kedziora*

Main category: cs.AI

TL;DR: TAAC是一种强化学习算法，通过多注意力机制和集中训练/执行方案提升多智能体协作能力。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体协作中联合动作空间指数增长和高效沟通的问题。

Method: 采用集中训练/执行方案，结合多注意力机制和惩罚损失函数。

Result: 在模拟足球环境中表现优于基准算法，协作行为更优。

Conclusion: TAAC在多智能体协作任务中表现出色，具有实际应用潜力。

Abstract: This paper introduces Team-Attention-Actor-Critic (TAAC), a reinforcement
learning algorithm designed to enhance multi-agent collaboration in cooperative
environments. TAAC employs a Centralized Training/Centralized Execution scheme
incorporating multi-headed attention mechanisms in both the actor and critic.
This design facilitates dynamic, inter-agent communication, allowing agents to
explicitly query teammates, thereby efficiently managing the exponential growth
of joint-action spaces while ensuring a high degree of collaboration. We
further introduce a penalized loss function which promotes diverse yet
complementary roles among agents. We evaluate TAAC in a simulated soccer
environment against benchmark algorithms representing other multi-agent
paradigms, including Proximal Policy Optimization and Multi-Agent
Actor-Attention-Critic. We find that TAAC exhibits superior performance and
enhanced collaborative behaviors across a variety of metrics (win rates, goal
differentials, Elo ratings, inter-agent connectivity, balanced spatial
distributions, and frequent tactical interactions such as ball possession
swaps).

</details>


### [22] [The Incomplete Bridge: How AI Research (Mis)Engages with Psychology](https://arxiv.org/abs/2507.22847)
*Han Jiang,Pengda Wang,Xiaoyuan Yi,Xing Xie,Ziang Xiao*

Main category: cs.AI

TL;DR: 本文分析了AI与心理学的跨学科整合，通过研究1006篇AI论文及其引用的2544篇心理学文献，揭示了整合模式、高频引用领域及未充分探索的方向。


<details>
  <summary>Details</summary>
Motivation: 探索AI与心理学的跨学科协同效应，以促进更深入的合作并推动AI系统发展。

Method: 分析2023至2025年间发表的1006篇AI论文及其引用的2544篇心理学文献，识别整合模式、高频引用领域及操作化方法。

Result: 揭示了心理学在AI中的整合模式，指出了高频引用领域和未充分探索的方向，并提供了更有效整合的指导。

Conclusion: 本研究为AI与心理学的跨学科合作提供了全面地图，有助于深化合作并推动AI系统进步。

Abstract: Social sciences have accumulated a rich body of theories and methodologies
for investigating the human mind and behaviors, while offering valuable
insights into the design and understanding of Artificial Intelligence (AI)
systems. Focusing on psychology as a prominent case, this study explores the
interdisciplinary synergy between AI and the field by analyzing 1,006
LLM-related papers published in premier AI venues between 2023 and 2025, along
with the 2,544 psychology publications they cite. Through our analysis, we
identify key patterns of interdisciplinary integration, locate the psychology
domains most frequently referenced, and highlight areas that remain
underexplored. We further examine how psychology theories/frameworks are
operationalized and interpreted, identify common types of misapplication, and
offer guidance for more effective incorporation. Our work provides a
comprehensive map of interdisciplinary engagement between AI and psychology,
thereby facilitating deeper collaboration and advancing AI systems.

</details>


### [23] [Automatically discovering heuristics in a complex SAT solver with large language models](https://arxiv.org/abs/2507.22876)
*Yiwen Sun,Furong Ye,Zhihan Chen,Ke Wei,Shaowei Cai*

Main category: cs.AI

TL;DR: AutoModSAT利用大型语言模型（LLM）优化SAT求解器，通过模块化设计、自动提示优化和高效搜索策略，性能提升50%，超越现有最优求解器30%，速度提升20%。


<details>
  <summary>Details</summary>
Motivation: 现代SAT求解器架构复杂，传统自动配置框架性能提升有限，需新方法优化。

Method: 提出模块化求解器设计、自动提示优化和进化算法搜索策略。

Result: 性能提升50%，超越SOTA求解器30%，速度提升20%。

Conclusion: AutoModSAT为AI驱动的启发式发现与系统优化提供方法论和实证结果。

Abstract: Satisfiability problem (SAT) is a cornerstone of computational complexity
with broad industrial applications, and it remains challenging to optimize
modern SAT solvers in real-world settings due to their intricate architectures.
While automatic configuration frameworks have been developed, they rely on
manually constrained search spaces and yield limited performance gains. This
work introduces a novel paradigm which effectively optimizes complex SAT
solvers via Large Language Models (LLMs), and a tool called AutoModSAT is
developed. Three fundamental challenges are addressed in order to achieve
superior performance: (1) LLM-friendly solver: Systematic guidelines are
proposed for developing a modularized solver to meet LLMs' compatibility,
emphasizing code simplification, information share and bug reduction; (2)
Automatic prompt optimization: An unsupervised automatic prompt optimization
method is introduced to advance the diversity of LLMs' output; (3) Efficient
search strategy: We design a presearch strategy and an EA evolutionary
algorithm for the final efficient and effective discovery of heuristics.
Extensive experiments across a wide range of datasets demonstrate that
AutoModSAT achieves 50% performance improvement over the baseline solver and
achieves 30% superiority against the state-of-the-art (SOTA) solvers. Moreover,
AutoModSAT attains a 20% speedup on average compared to parameter-tuned
alternatives of the SOTA solvers, showcasing the enhanced capability in
handling complex problem instances. This work bridges the gap between AI-driven
heuristics discovery and mission-critical system optimization, and provides
both methodological advancements and empirically validated results for
next-generation complex solver development.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [24] [Age of Estimates: When to Submit Jobs to a Markov Machine to Maximize Revenue](https://arxiv.org/abs/2507.22865)
*Sahan Liyanaarachchi,Sennur Ulukus*

Main category: cs.IT

TL;DR: 论文提出了一种最大化马尔可夫机器（MM）效用的方法，通过优化作业提交时间来提高平均收益。


<details>
  <summary>Details</summary>
Motivation: 随着AI工厂的兴起，有效跟踪和利用计算资源变得至关重要。现有研究多关注资源跟踪，而忽略了如何优化其利用。

Method: 假设泊松作业到达过程和基于查询的采样方法，研究如何最优提交作业以最大化平均收益。

Result: 根据MM参数，最优策略表现为阈值策略或基于状态估计年龄的切换策略。

Conclusion: 优化作业提交时间能显著提高MM的效用，为资源管理提供了新思路。

Abstract: With the dawn of AI factories ushering a new era of computing supremacy,
development of strategies to effectively track and utilize the available
computing resources is garnering utmost importance. These computing resources
are often modeled as Markov sources, which oscillate between free and busy
states, depending on their internal load and external utilization, and are
commonly referred to as Markov machines (MMs). Most of the prior work solely
focuses on the problem of tracking these MMs, while often assuming a
rudimentary decision process that governs their utilization. Our key
observation is that the ultimate goal of tracking a MM is to properly utilize
it. In this work, we consider the problem of maximizing the utility of a MM,
where the utility is defined as the average revenue generated by the MM.
Assuming a Poisson job arrival process and a query-based sampling procedure to
sample the state of the MM, we find the optimal times to submit the available
jobs to the MM so as to maximize the average revenue generated per unit job. We
show that, depending on the parameters of the MM, the optimal policy is in the
form of either a \emph{threshold policy} or a \emph{switching policy} based on
the \emph{age of our estimate} of the state of the MM.

</details>


### [25] [Dynamic Exponent Market Maker: Personalized Portfolio Manager and One Pool to Trade Them All](https://arxiv.org/abs/2507.22732)
*Wittawat Kositwattanarerk*

Main category: cs.IT

TL;DR: 提出一种新型AMM协议，允许流动性提供者以任意比例存入代币，并通过动态不变函数实现单一池交易，但需防范闪电贷攻击。


<details>
  <summary>Details</summary>
Motivation: 解决现有去中心化交易所（如Uniswap和Balancer）中流动性提供需特定代币比例及多池交易导致的高费用问题。

Method: 设计一种动态不变函数的AMM协议，支持任意代币比例存入，并保持总价值比例，实现单一池交易。

Result: 协议能够简化流动性提供和交易流程，降低费用，但存在闪电贷攻击风险。

Conclusion: 新型AMM协议在优化交易体验的同时，需结合防范措施以应对潜在攻击。

Abstract: Decentralized exchange platforms such as Uniswap and Balancer operate on
several pools where each pool contains two or more cryptocurrencies and
constitutes direct trading pairs. The drawbacks here are that liquidity
providing requires contribution of tokens in a specific proportion, and trading
may require hopping between pools, hence increasing transaction fee and gas
fee. We propose an automated market maker (AMM) protocol where liquidity
providers can deposit any amount of tokens into the pool. The protocol will
preserve the proportion of tokens by total value at the time of deposit and can
be seen as a personalized self-balancing portfolio manager. In addition, since
the invariant function is dynamic, all exchange pairs are executed from a
single composite pool. Nevertheless, the scheme is vulnerable to flash loan
attacks and must be used in conjunction with preventive measures.

</details>
