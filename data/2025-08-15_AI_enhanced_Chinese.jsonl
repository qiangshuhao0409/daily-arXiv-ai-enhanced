{"id": "2508.10139", "categories": ["cs.IT", "math.IT", "math.RA"], "pdf": "https://arxiv.org/pdf/2508.10139", "abs": "https://arxiv.org/abs/2508.10139", "authors": ["Susanne Pumpluen"], "title": "Using nonassociative algebras to classify skew polycyclic codes up to isometry and equivalence", "comment": null, "summary": "We propose new definitions of equivalence and isometry for skew polycyclic\ncodes that will lead to tighter classifications than existing ones. This helps\nto reduce the number of previously known isometry and equivalence classes, and\nstate precisely when these different notions coincide. In the process, we\nclassify classes of skew $(f,\\sigma,\\delta)$-polycyclic codes with the same\nperformance parameters, to avoid duplicating already existing codes.\n  We exploit that the generator of a skew polycyclic code is in one-one\ncorrespondence with the generator of a principal left ideal in its ambient\nalgebra. Algebra isomorphisms that preserve the Hamming distance (called\nisometries) map generators of principal left ideals to generators of principal\nleft ideals and preserve length, dimension and Hamming distance of the codes.\nWe allow the ambient algebras to be nonassociative, thus eliminating the need\non restrictions on the length of the codes. The isometries between the ambient\nalgebras can also be used to classify corresponding linear codes equipped with\nthe rank metric.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u65b0\u7684\u659c\u591a\u73af\u7801\u7684\u7b49\u4ef7\u548c\u7b49\u8ddd\u5b9a\u4e49\uff0c\u4ee5\u51cf\u5c11\u5df2\u77e5\u5206\u7c7b\u6570\u91cf\u5e76\u660e\u786e\u4e0d\u540c\u6982\u5ff5\u7684\u91cd\u5408\u6761\u4ef6\u3002", "motivation": "\u6539\u8fdb\u73b0\u6709\u659c\u591a\u73af\u7801\u7684\u7b49\u4ef7\u548c\u7b49\u8ddd\u5206\u7c7b\uff0c\u907f\u514d\u91cd\u590d\u7f16\u7801\uff0c\u5e76\u6269\u5c55\u975e\u7ed3\u5408\u4ee3\u6570\u73af\u5883\u4e0b\u7684\u5e94\u7528\u3002", "method": "\u5229\u7528\u659c\u591a\u73af\u7801\u751f\u6210\u5668\u4e0e\u4e3b\u5de6\u7406\u60f3\u751f\u6210\u5668\u7684\u4e00\u4e00\u5bf9\u5e94\u5173\u7cfb\uff0c\u901a\u8fc7\u4fdd\u6301\u6c49\u660e\u8ddd\u79bb\u7684\u4ee3\u6570\u540c\u6784\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u51cf\u5c11\u4e86\u7b49\u4ef7\u548c\u7b49\u8ddd\u7c7b\u6570\u91cf\uff0c\u660e\u786e\u4e86\u91cd\u5408\u6761\u4ef6\uff0c\u5e76\u9002\u7528\u4e8e\u975e\u7ed3\u5408\u4ee3\u6570\u548c\u79e9\u5ea6\u91cf\u7ebf\u6027\u7801\u3002", "conclusion": "\u65b0\u5b9a\u4e49\u63d0\u4f9b\u4e86\u66f4\u7d27\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u4ee3\u6570\u7ed3\u6784\u548c\u7f16\u7801\u573a\u666f\u3002"}}
{"id": "2508.10244", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.10244", "abs": "https://arxiv.org/abs/2508.10244", "authors": ["Jiawei Qiu", "Harry Leib"], "title": "Space-time Coded Differential Modulation for Reconfigurable Intelligent Surfaces", "comment": null, "summary": "Reconfigurable Intelligent Surfaces (RIS) hold the promise of improving\nsignificantly coverage, as well as spectral and energy efficiency in wireless\ncommunication systems. Techniques based on RIS form a key technology for 6G\nsystems. An important issue in RIS technology is Channel State Information\n(CSI), which is much more difficult to acquire in such systems. This work\nintroduces a Differential Space-Time Modulation (DSTM) scheme integrated with\nDifferential Reflecting Modulation (DRM) to bypass the requirement for CSI in\nsuch systems, while providing error rate gains. The DSTM scheme is based on\nunitary group codes. We first consider uncoded DRM for RIS to serve as a\nreference point. Next we provide an overview of DSTM and outline the procedures\nfor its integration with DRM. Furthermore, we explore the extension of both the\noriginal DRM and the coded DRM-DSTM scheme to a larger number of RIS reflecting\npatterns $K$, and provide tables of codes for $K= 2, 3, 4$. Encoding and\ndecoding complexities are studied as well. Extensives simulation results over\nquasi-static Rayleigh fading channels confirm the effectiveness of the DRM-DSTM\ncoded system, illustrating its advantages over uncoded DRM with proper system\nparameters.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5dee\u5206\u7a7a\u65f6\u8c03\u5236\uff08DSTM\uff09\u548c\u5dee\u5206\u53cd\u5c04\u8c03\u5236\uff08DRM\uff09\u7684\u65b9\u6848\uff0c\u4ee5\u7ed5\u8fc7RIS\u7cfb\u7edf\u4e2d\u7684CSI\u83b7\u53d6\u9700\u6c42\uff0c\u540c\u65f6\u63d0\u5347\u8bef\u7801\u7387\u6027\u80fd\u3002", "motivation": "RIS\u6280\u672f\u57286G\u7cfb\u7edf\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46CSI\u83b7\u53d6\u56f0\u96be\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e0\u9700CSI\u7684\u65b9\u6848\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u9149\u7fa4\u7801\u7684DSTM\u65b9\u6848\uff0c\u5e76\u4e0eDRM\u7ed3\u5408\uff0c\u6269\u5c55\u5230\u66f4\u591a\u53cd\u5c04\u6a21\u5f0f\uff08K=2,3,4\uff09\uff0c\u7814\u7a76\u4e86\u7f16\u89e3\u7801\u590d\u6742\u5ea6\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cDRM-DSTM\u7f16\u7801\u7cfb\u7edf\u5728\u51c6\u9759\u6001\u745e\u5229\u8870\u843d\u4fe1\u9053\u4e2d\u4f18\u4e8e\u672a\u7f16\u7801\u7684DRM\u3002", "conclusion": "DRM-DSTM\u65b9\u6848\u6709\u6548\u89e3\u51b3\u4e86RIS\u7cfb\u7edf\u4e2d\u7684CSI\u83b7\u53d6\u95ee\u9898\uff0c\u5e76\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2508.10282", "categories": ["cs.IT", "cs.LG", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.10282", "abs": "https://arxiv.org/abs/2508.10282", "authors": ["Marco Bondaschi", "Michael Gastpar"], "title": "The Conditional Regret-Capacity Theorem for Batch Universal Prediction", "comment": null, "summary": "We derive a conditional version of the classical regret-capacity theorem.\nThis result can be used in universal prediction to find lower bounds on the\nminimal batch regret, which is a recently introduced generalization of the\naverage regret, when batches of training data are available to the predictor.\nAs an example, we apply this result to the class of binary memoryless sources.\nFinally, we generalize the theorem to R\\'enyi information measures, revealing a\ndeep connection between the conditional R\\'enyi divergence and the conditional\nSibson's mutual information.", "AI": {"tldr": "\u672c\u6587\u63a8\u5bfc\u4e86\u7ecf\u5178\u9057\u61be\u5bb9\u91cf\u5b9a\u7406\u7684\u6761\u4ef6\u7248\u672c\uff0c\u7528\u4e8e\u901a\u7528\u9884\u6d4b\u4e2d\u5bfb\u627e\u6700\u5c0f\u6279\u91cf\u9057\u61be\u7684\u4e0b\u754c\uff0c\u5e76\u5e94\u7528\u4e8e\u4e8c\u5143\u65e0\u8bb0\u5fc6\u6e90\u7c7b\uff0c\u540c\u65f6\u63a8\u5e7f\u5230R\u00e9nyi\u4fe1\u606f\u5ea6\u91cf\u3002", "motivation": "\u7814\u7a76\u901a\u7528\u9884\u6d4b\u4e2d\u6279\u91cf\u6570\u636e\u53ef\u7528\u65f6\u7684\u6700\u5c0f\u6279\u91cf\u9057\u61be\u4e0b\u754c\uff0c\u63a2\u7d22\u6761\u4ef6R\u00e9nyi\u6563\u5ea6\u4e0e\u6761\u4ef6Sibson\u4e92\u4fe1\u606f\u4e4b\u95f4\u7684\u6df1\u5c42\u8054\u7cfb\u3002", "method": "\u63a8\u5bfc\u6761\u4ef6\u9057\u61be\u5bb9\u91cf\u5b9a\u7406\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u4e8c\u5143\u65e0\u8bb0\u5fc6\u6e90\u7c7b\uff0c\u8fdb\u4e00\u6b65\u63a8\u5e7f\u5230R\u00e9nyi\u4fe1\u606f\u5ea6\u91cf\u3002", "result": "\u63ed\u793a\u4e86\u6761\u4ef6R\u00e9nyi\u6563\u5ea6\u4e0e\u6761\u4ef6Sibson\u4e92\u4fe1\u606f\u4e4b\u95f4\u7684\u6df1\u5c42\u8054\u7cfb\uff0c\u5e76\u63d0\u4f9b\u4e86\u6700\u5c0f\u6279\u91cf\u9057\u61be\u7684\u4e0b\u754c\u3002", "conclusion": "\u6761\u4ef6\u9057\u61be\u5bb9\u91cf\u5b9a\u7406\u4e3a\u901a\u7528\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u5de5\u5177\uff0c\u540c\u65f6\u6269\u5c55\u4e86\u4fe1\u606f\u5ea6\u91cf\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2508.10290", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.10290", "abs": "https://arxiv.org/abs/2508.10290", "authors": ["Long Yuan", "Wenkun Wen", "Junlin Liu", "Peiran Wu", "Minghua Xia"], "title": "Energy-Efficient Index and Code Index Modulations for Spread CPM Signals in Internet of Things", "comment": "14 pages, 9 figures, 2 tables; To appear in IEEE Internet of Things\n  Journal", "summary": "The evolution of Internet of Things technologies is driven by four key\ndemands: ultra-low power consumption, high spectral efficiency, reduced\nimplementation cost, and support for massive connectivity. To address these\nchallenges, this paper proposes two novel modulation schemes that integrate\ncontinuous phase modulation (CPM) with spread spectrum (SS) techniques. We\nbegin by establishing the quasi-orthogonality properties of CPM-SS sequences.\nThe first scheme, termed IM-CPM-SS, employs index modulation (IM) to select\nspreading sequences from the CPM-SS set, thereby improving spectral efficiency\nwhile maintaining the constant-envelope property. The second scheme, referred\nto as CIM-CPM-SS, introduces code index modulation (CIM), which partitions the\ninput bits such that one subset is mapped to phase-shift keying symbols and the\nother to CPM-SS sequence indices. Both schemes are applied to downlink\nnon-orthogonal multiple access (NOMA) systems. We analyze their performance in\nterms of bit error rate (BER), spectral and energy efficiency, computational\ncomplexity, and peak-to-average power ratio characteristics under nonlinear\namplifier conditions. Simulation results demonstrate that both schemes\noutperform conventional approaches in BER while preserving the benefits of\nconstant-envelope, continuous-phase signaling. Furthermore, they achieve higher\nspectral and energy efficiency and exhibit strong resilience to nonlinear\ndistortions in downlink NOMA scenarios.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u65b0\u578b\u8c03\u5236\u65b9\u6848\uff08IM-CPM-SS\u548cCIM-CPM-SS\uff09\uff0c\u7ed3\u5408CPM\u4e0eSS\u6280\u672f\uff0c\u4ee5\u89e3\u51b3\u7269\u8054\u7f51\u6280\u672f\u4e2d\u7684\u4f4e\u529f\u8017\u3001\u9ad8\u6548\u9891\u8c31\u5229\u7528\u7b49\u9700\u6c42\uff0c\u5e76\u5728\u4e0b\u884cNOMA\u7cfb\u7edf\u4e2d\u9a8c\u8bc1\u5176\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u7269\u8054\u7f51\u6280\u672f\u53d1\u5c55\u9762\u4e34\u4f4e\u529f\u8017\u3001\u9ad8\u6548\u9891\u8c31\u5229\u7528\u3001\u4f4e\u6210\u672c\u548c\u5927\u89c4\u6a21\u8fde\u63a5\u7b49\u9700\u6c42\uff0c\u73b0\u6709\u65b9\u6848\u96be\u4ee5\u540c\u65f6\u6ee1\u8db3\u8fd9\u4e9b\u8981\u6c42\u3002", "method": "\u63d0\u51faIM-CPM-SS\u548cCIM-CPM-SS\u4e24\u79cd\u8c03\u5236\u65b9\u6848\uff0c\u5206\u522b\u5229\u7528\u7d22\u5f15\u8c03\u5236\u548c\u7801\u7d22\u5f15\u8c03\u5236\uff0c\u7ed3\u5408CPM\u4e0eSS\u6280\u672f\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u4e24\u79cd\u65b9\u6848\u5728BER\u3001\u9891\u8c31\u6548\u7387\u3001\u80fd\u91cf\u6548\u7387\u7b49\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4e14\u5bf9\u975e\u7ebf\u6027\u5931\u771f\u5177\u6709\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "\u4e24\u79cd\u65b0\u578b\u8c03\u5236\u65b9\u6848\u5728\u6ee1\u8db3\u7269\u8054\u7f51\u9700\u6c42\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u4e0b\u884cNOMA\u573a\u666f\u3002"}}
{"id": "2508.10247", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.10247", "abs": "https://arxiv.org/abs/2508.10247", "authors": ["Laura Landon", "Vipindev Adat Vasudevan", "Junmo Sung", "Muriel M\u00e9dard"], "title": "Rethinking Reliability Using Network Coding: a Practical 5G Evaluation", "comment": "LCN Conference 2025", "summary": "This work presents the design and implementation of a real-time network\ncoding system integrated into the IP layer of a 5G testbed, offering an\nalternative to conventional retransmission-based reliability mechanisms such as\nARQ and HARQ. Using a netfilter-based packet interception framework, we inject\nforward erasure correction using Random Linear Network Coding (RLNC) into live\ntraffic between a gNB and UE over a 3GPP RF link. We evaluate a block coding\nscheme, analyzing its impact on throughput, jitter, and resource usage. Results\nshow that with appropriate code rate selection, RLNC can fully recover from\npacket losses using fewer transmissions than ARQ/HARQ and maintain a high\nthroughput, particularly under moderate-to-high packet loss rates. These\nfindings demonstrate that network coding can effectively replace\nretransmission-based reliability in future wireless systems, with the potential\nfor more efficient resource utilization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57285G\u6d4b\u8bd5\u5e8aIP\u5c42\u96c6\u6210\u5b9e\u65f6\u7f51\u7edc\u7f16\u7801\u7684\u7cfb\u7edf\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684ARQ/HARQ\u91cd\u4f20\u673a\u5236\u3002\u901a\u8fc7RLNC\u6280\u672f\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u9ad8\u4e22\u5305\u7387\u4e0b\u80fd\u66f4\u9ad8\u6548\u6062\u590d\u6570\u636e\u5e76\u4fdd\u6301\u9ad8\u541e\u5410\u91cf\u3002", "motivation": "\u4f20\u7edfARQ/HARQ\u91cd\u4f20\u673a\u5236\u5728\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u6548\u7387\u8f83\u4f4e\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u4e22\u5305\u7387\u4e0b\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u7f51\u7edc\u7f16\u7801\uff08\u5982RLNC\uff09\u662f\u5426\u80fd\u66f4\u9ad8\u6548\u5730\u66ff\u4ee3\u8fd9\u4e9b\u673a\u5236\u3002", "method": "\u57285G\u6d4b\u8bd5\u5e8a\u4e2d\uff0c\u901a\u8fc7netfilter\u62e6\u622a\u6570\u636e\u5305\uff0c\u5e76\u6ce8\u5165RLNC\u524d\u5411\u7ea0\u9519\u6280\u672f\uff0c\u8bc4\u4f30\u5176\u5bf9\u541e\u5410\u91cf\u3001\u6296\u52a8\u548c\u8d44\u6e90\u4f7f\u7528\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRLNC\u5728\u9002\u5f53\u7801\u7387\u9009\u62e9\u4e0b\uff0c\u80fd\u4ee5\u66f4\u5c11\u4f20\u8f93\u6b21\u6570\u5b8c\u5168\u6062\u590d\u4e22\u5305\uff0c\u5e76\u5728\u4e2d\u9ad8\u4e22\u5305\u7387\u4e0b\u4fdd\u6301\u9ad8\u541e\u5410\u91cf\u3002", "conclusion": "\u7f51\u7edc\u7f16\u7801\uff08RLNC\uff09\u53ef\u6709\u6548\u66ff\u4ee3\u4f20\u7edf\u91cd\u4f20\u673a\u5236\uff0c\u63d0\u5347\u672a\u6765\u65e0\u7ebf\u7cfb\u7edf\u7684\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002"}}
{"id": "2508.10047", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10047", "abs": "https://arxiv.org/abs/2508.10047", "authors": ["Ziyang Xiao", "Jingrong Xie", "Lilin Xu", "Shisi Guan", "Jingyan Zhu", "Xiongwei Han", "Xiaojin Fu", "WingYin Yu", "Han Wu", "Wei Shi", "Qingcan Kang", "Jiahui Duan", "Tao Zhong", "Mingxuan Yuan", "Jia Zeng", "Yuan Wang", "Gang Chen", "Dongxiang Zhang"], "title": "A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions", "comment": null, "summary": "By virtue of its great utility in solving real-world problems, optimization\nmodeling has been widely employed for optimal decision-making across various\nsectors, but it requires substantial expertise from operations research\nprofessionals. With the advent of large language models (LLMs), new\nopportunities have emerged to automate the procedure of mathematical modeling.\nThis survey presents a comprehensive and timely review of recent advancements\nthat cover the entire technical stack, including data synthesis and fine-tuning\nfor the base model, inference frameworks, benchmark datasets, and performance\nevaluation. In addition, we conducted an in-depth analysis on the quality of\nbenchmark datasets, which was found to have a surprisingly high error rate. We\ncleaned the datasets and constructed a new leaderboard with fair performance\nevaluation in terms of base LLM model and datasets. We also build an online\nportal that integrates resources of cleaned datasets, code and paper repository\nto benefit the community. Finally, we identify limitations in current\nmethodologies and outline future research opportunities.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u81ea\u52a8\u5316\u6570\u5b66\u5efa\u6a21\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5305\u62ec\u6570\u636e\u5408\u6210\u3001\u6a21\u578b\u5fae\u8c03\u3001\u63a8\u7406\u6846\u67b6\u3001\u57fa\u51c6\u6570\u636e\u96c6\u548c\u6027\u80fd\u8bc4\u4f30\uff0c\u5e76\u6784\u5efa\u4e86\u65b0\u7684\u516c\u5e73\u8bc4\u4f30\u6392\u884c\u699c\u548c\u5728\u7ebf\u8d44\u6e90\u95e8\u6237\u3002", "motivation": "\u4f18\u5316\u5efa\u6a21\u5728\u89e3\u51b3\u5b9e\u9645\u95ee\u9898\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u9700\u8981\u5927\u91cf\u4e13\u4e1a\u77e5\u8bc6\u3002LLMs\u7684\u51fa\u73b0\u4e3a\u81ea\u52a8\u5316\u6570\u5b66\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\u3002", "method": "\u7efc\u8ff0\u4e86\u6280\u672f\u6808\u7684\u5404\u4e2a\u65b9\u9762\uff0c\u5305\u62ec\u6570\u636e\u5408\u6210\u3001\u6a21\u578b\u5fae\u8c03\u3001\u63a8\u7406\u6846\u67b6\u7b49\uff0c\u5e76\u6e05\u7406\u4e86\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6784\u5efa\u4e86\u65b0\u7684\u6392\u884c\u699c\u548c\u5728\u7ebf\u95e8\u6237\u3002", "result": "\u53d1\u73b0\u57fa\u51c6\u6570\u636e\u96c6\u9519\u8bef\u7387\u9ad8\uff0c\u6e05\u7406\u540e\u6784\u5efa\u4e86\u516c\u5e73\u8bc4\u4f30\u7684\u6392\u884c\u699c\u548c\u5728\u7ebf\u8d44\u6e90\u95e8\u6237\u3002", "conclusion": "\u5f53\u524d\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.10317", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.10317", "abs": "https://arxiv.org/abs/2508.10317", "authors": ["Yichao Xu", "Xiaoming Chen", "Ming Ying", "Zhaoyang Zhang"], "title": "Integrated Communication and Remote Sensing in LEO Satellite Systems: Protocol, Architecture and Prototype", "comment": null, "summary": "In this paper, we explore the integration of communication and synthetic\naperture radar (SAR)-based remote sensing in low Earth orbit (LEO) satellite\nsystems to provide real-time SAR imaging and information transmission.\nConsidering the high-mobility characteristics of satellite channels and limited\nprocessing capabilities of satellite payloads, we propose an integrated\ncommunication and remote sensing architecture based on an orthogonal\ndelay-Doppler division multiplexing (ODDM) signal waveform. Both communication\nand SAR imaging functionalities are achieved with an integrated transceiver\nonboard the LEO satellite, utilizing the same waveform and radio frequency (RF)\nfront-end. Based on such an architecture, we propose a transmission protocol\ncompatible with the 5G NR standard using downlink pilots for joint channel\nestimation and SAR imaging. Furthermore, we design a unified signal processing\nframework for the integrated satellite receiver to simultaneously achieve\nhigh-performance channel sensing, low-complexity channel equalization and\ninterference-free SAR imaging. Finally, the performance of the proposed\nintegrated system is demonstrated through comprehensive analysis and extensive\nsimulations in the sub-6 GHz band. Moreover, a software-defined radio (SDR)\nprototype is presented to validate its effectiveness for real-time SAR imaging\nand information transmission in satellite direct-connect user equipment (UE)\nscenarios within the millimeter-wave (mmWave) band.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6b63\u4ea4\u5ef6\u8fdf\u591a\u666e\u52d2\u5206\u590d\u7528\uff08ODDM\uff09\u4fe1\u53f7\u6ce2\u5f62\u7684\u96c6\u6210\u901a\u4fe1\u4e0eSAR\u9065\u611f\u67b6\u6784\uff0c\u7528\u4e8e\u4f4e\u5730\u7403\u8f68\u9053\uff08LEO\uff09\u536b\u661f\u7cfb\u7edf\uff0c\u5b9e\u73b0\u5b9e\u65f6SAR\u6210\u50cf\u4e0e\u4fe1\u606f\u4f20\u8f93\u3002", "motivation": "\u89e3\u51b3\u536b\u661f\u4fe1\u9053\u9ad8\u52a8\u6001\u7279\u6027\u548c\u536b\u661f\u8f7d\u8377\u5904\u7406\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u901a\u4fe1\u4e0eSAR\u6210\u50cf\u529f\u80fd\u7684\u96c6\u6210\u3002", "method": "\u91c7\u7528ODDM\u6ce2\u5f62\u548c5G NR\u517c\u5bb9\u7684\u4f20\u8f93\u534f\u8bae\uff0c\u8bbe\u8ba1\u7edf\u4e00\u7684\u4fe1\u53f7\u5904\u7406\u6846\u67b6\uff0c\u5b9e\u73b0\u9ad8\u6027\u80fd\u4fe1\u9053\u611f\u77e5\u3001\u4f4e\u590d\u6742\u5ea6\u5747\u8861\u548c\u65e0\u5e72\u6270SAR\u6210\u50cf\u3002", "result": "\u901a\u8fc7\u5206\u6790\u4e0e\u4eff\u771f\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u57286 GHz\u4ee5\u4e0b\u9891\u6bb5\u7684\u6027\u80fd\uff0c\u5e76\u901a\u8fc7SDR\u539f\u578b\u9a8c\u8bc1\u4e86\u6beb\u7c73\u6ce2\u9891\u6bb5\u7684\u5b9e\u65f6SAR\u6210\u50cf\u4e0e\u4fe1\u606f\u4f20\u8f93\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u96c6\u6210\u67b6\u6784\u548c\u4fe1\u53f7\u5904\u7406\u6846\u67b6\u6709\u6548\u5b9e\u73b0\u4e86\u901a\u4fe1\u4e0eSAR\u6210\u50cf\u7684\u534f\u540c\u5de5\u4f5c\uff0c\u4e3a\u672a\u6765\u536b\u661f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.10283", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.10283", "abs": "https://arxiv.org/abs/2508.10283", "authors": ["Zekun Wang", "Binghao Yue", "Weitao Pan", "Jiangyi Shi", "Yue Hao"], "title": "Design of a Timer Queue Supporting Dynamic Update Operations", "comment": null, "summary": "Large-scale timers are ubiquitous in network processing, including flow table\nentry expiration control in software defined network (SDN) switches, MAC\naddress aging in Ethernet bridges, and retransmission timeout management in\nTCP/IP protocols. Conventional implementations suffer from critical\nlimitations: low timing accuracy due to large-scale timer traversal and high\ncomputational overhead for new timer insertion. This paper presents a\nhybrid-architecture hardware priority queue based on systolic arrays and shift\nregisters for efficient timer queue management. The design uniquely supports\nfive operations: enqueue, dequeue, delete, update, and peek.To the best of our\nknowledge, it is the first hardware priority queue enabling in-queue priority\nupdates. By leveraging centralized Boolean logic encoding within systolic\nblocks, the design efficiently generates set/shift control signals while the\nnovel push-first operation ensures FIFO ordering for same-priority timers\nwithout additional metadata. Experimental results demonstrate that the design\noperates at over 400 MHz on FPGAs, achieving a 2.2-2.8x reduction in resource\nconsumption compared to state-of-the-art implementations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8109\u52a8\u9635\u5217\u548c\u79fb\u4f4d\u5bc4\u5b58\u5668\u7684\u6df7\u5408\u67b6\u6784\u786c\u4ef6\u4f18\u5148\u7ea7\u961f\u5217\uff0c\u7528\u4e8e\u9ad8\u6548\u7ba1\u7406\u8ba1\u65f6\u5668\u961f\u5217\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5b9e\u73b0\u4e2d\u8ba1\u65f6\u7cbe\u5ea6\u4f4e\u548c\u8ba1\u7b97\u5f00\u9500\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u89c4\u6a21\u8ba1\u65f6\u5668\u5728\u7f51\u7edc\u5904\u7406\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u4f20\u7edf\u5b9e\u73b0\u5b58\u5728\u8ba1\u65f6\u7cbe\u5ea6\u4f4e\u548c\u8ba1\u7b97\u5f00\u9500\u9ad8\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u8109\u52a8\u9635\u5217\u548c\u79fb\u4f4d\u5bc4\u5b58\u5668\u7684\u6df7\u5408\u67b6\u6784\u786c\u4ef6\u4f18\u5148\u7ea7\u961f\u5217\uff0c\u652f\u6301\u4e94\u79cd\u64cd\u4f5c\uff08\u5165\u961f\u3001\u51fa\u961f\u3001\u5220\u9664\u3001\u66f4\u65b0\u548c\u67e5\u770b\uff09\uff0c\u5e76\u9996\u6b21\u5b9e\u73b0\u961f\u5217\u5185\u4f18\u5148\u7ea7\u66f4\u65b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u8bbe\u8ba1\u5728FPGA\u4e0a\u8fd0\u884c\u9891\u7387\u8d85\u8fc7400 MHz\uff0c\u8d44\u6e90\u6d88\u8017\u6bd4\u73b0\u6709\u6700\u4f18\u5b9e\u73b0\u51cf\u5c112.2-2.8\u500d\u3002", "conclusion": "\u8be5\u8bbe\u8ba1\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u65f6\u5668\u961f\u5217\u7ba1\u7406\u7684\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2508.10108", "categories": ["cs.AI", "cs.CL", "I.2.7; I.2.6; E.0"], "pdf": "https://arxiv.org/pdf/2508.10108", "abs": "https://arxiv.org/abs/2508.10108", "authors": ["Sattvik Sahai", "Prasoon Goyal", "Michael Johnston", "Anna Gottardi", "Yao Lu", "Lucy Hu", "Luke Dai", "Shaohua Liu", "Samyuth Sagi", "Hangjie Shi", "Desheng Zhang", "Lavina Vaz", "Leslie Ball", "Maureen Murray", "Rahul Gupta", "Shankar Ananthakrishna"], "title": "Amazon Nova AI Challenge -- Trusted AI: Advancing secure, AI-assisted software development", "comment": "18 pages, 1st Proceedings of Amazon Nova AI Challenge (Trusted AI\n  2025)", "summary": "AI systems for software development are rapidly gaining prominence, yet\nsignificant challenges remain in ensuring their safety. To address this, Amazon\nlaunched the Trusted AI track of the Amazon Nova AI Challenge, a global\ncompetition among 10 university teams to drive advances in secure AI. In the\nchallenge, five teams focus on developing automated red teaming bots, while the\nother five create safe AI assistants. This challenge provides teams with a\nunique platform to evaluate automated red-teaming and safety alignment methods\nthrough head-to-head adversarial tournaments where red teams have multi-turn\nconversations with the competing AI coding assistants to test their safety\nalignment. Along with this, the challenge provides teams with a feed of high\nquality annotated data to fuel iterative improvement. Throughout the challenge,\nteams developed state-of-the-art techniques, introducing novel approaches in\nreasoning-based safety alignment, robust model guardrails, multi-turn\njail-breaking, and efficient probing of large language models (LLMs). To\nsupport these efforts, the Amazon Nova AI Challenge team made substantial\nscientific and engineering investments, including building a custom baseline\ncoding specialist model for the challenge from scratch, developing a tournament\norchestration service, and creating an evaluation harness. This paper outlines\nthe advancements made by university teams and the Amazon Nova AI Challenge team\nin addressing the safety challenges of AI for software development,\nhighlighting this collaborative effort to raise the bar for AI safety.", "AI": {"tldr": "\u4e9a\u9a6c\u900aNova AI\u6311\u6218\u8d5b\u901a\u8fc7\u5bf9\u6297\u6027\u7ade\u8d5b\u63a8\u52a8AI\u5b89\u5168\u6027\u7814\u7a76\uff0c\u5927\u5b66\u56e2\u961f\u5f00\u53d1\u4e86\u5148\u8fdb\u6280\u672f\uff0c\u5305\u62ec\u5b89\u5168\u5bf9\u9f50\u548c\u6a21\u578b\u9632\u62a4\u3002", "motivation": "\u89e3\u51b3AI\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5b89\u5168\u6027\u6311\u6218\uff0c\u63a8\u52a8\u5b89\u5168AI\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u5bf9\u6297\u6027\u7ade\u8d5b\uff08\u7ea2\u961f\u4e0e\u5b89\u5168AI\u52a9\u624b\u5bf9\u6218\uff09\u548c\u591a\u8f6e\u5bf9\u8bdd\u6d4b\u8bd5\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u9ad8\u8d28\u91cf\u6570\u636e\u652f\u6301\u3002", "result": "\u56e2\u961f\u5f00\u53d1\u4e86\u63a8\u7406\u5b89\u5168\u5bf9\u9f50\u3001\u6a21\u578b\u9632\u62a4\u548c\u591a\u8f6e\u8d8a\u72f1\u7b49\u5148\u8fdb\u6280\u672f\u3002", "conclusion": "\u6311\u6218\u8d5b\u63d0\u5347\u4e86AI\u5b89\u5168\u6027\u6807\u51c6\uff0c\u5c55\u793a\u4e86\u534f\u4f5c\u7814\u7a76\u7684\u4ef7\u503c\u3002"}}
{"id": "2508.10720", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.10720", "abs": "https://arxiv.org/abs/2508.10720", "authors": ["Kan Yu", "Kaixuan Li", "Xiaowu Liu", "Qixun Zhang", "Zhiyong Feng"], "title": "Predictive Position Control for Movable Antenna Arrays in UAV Communications: A Spatio-Temporal Transformer-LSTM Framework", "comment": null, "summary": "In complex urban environments, dynamic obstacles and multipath effects lead\nto significant link attenuation and pervasive coverage blind spots.\nConventional approaches based on large-scale fixed antenna arrays and UAV\ntrajectory optimization struggle to balance energy efficiency, real-time\nadaptation, and spatial flexibility. The movable antenna (MA) technology has\nemerged as a promising solution, offering enhanced spatial flexibility and\nreduced energy consumption to overcome the bottlenecks of urban low-altitude\ncommunications. However, MA deployment faces a critical velocity mismatch\nbetween UAV mobility and mechanical repositioning latency, undermining\nreal-time link optimization and security assurance. To overcome this, we\npropose a predictive MA-UAV collaborative control framework. First, optimal\nantenna positions are derived via secrecy rate maximization. Second, a\nTransformer-enhanced long short-term memory (LSTM) network predicts future MA\npositions by capturing spatio-temporal correlations in antenna trajectories.\nExtensive simulations demonstrate superior prediction accuracy (NMSE reduction\nexceeds 49\\%) and communication reliability versus current popular benchmarks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9884\u6d4b\u6027MA-UAV\u534f\u540c\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u5929\u7ebf\u4f4d\u7f6e\u548c\u9884\u6d4b\u672a\u6765\u4f4d\u7f6e\uff0c\u89e3\u51b3\u4e86\u52a8\u6001\u969c\u788d\u548c\u591a\u5f84\u6548\u5e94\u5bfc\u81f4\u7684\u901a\u4fe1\u95ee\u9898\u3002", "motivation": "\u5728\u590d\u6742\u57ce\u5e02\u73af\u5883\u4e2d\uff0c\u52a8\u6001\u969c\u788d\u548c\u591a\u5f84\u6548\u5e94\u5bfc\u81f4\u901a\u4fe1\u94fe\u8def\u8870\u51cf\u548c\u8986\u76d6\u76f2\u533a\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u80fd\u6548\u3001\u5b9e\u65f6\u9002\u5e94\u6027\u548c\u7a7a\u95f4\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51fa\u9884\u6d4b\u6027MA-UAV\u534f\u540c\u63a7\u5236\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u4fdd\u5bc6\u7387\u6700\u5927\u5316\u4f18\u5316\u5929\u7ebf\u4f4d\u7f6e\uff1b2\uff09\u4f7f\u7528Transformer\u589e\u5f3a\u7684LSTM\u7f51\u7edc\u9884\u6d4b\u672a\u6765\u5929\u7ebf\u4f4d\u7f6e\u3002", "result": "\u4eff\u771f\u663e\u793a\uff0c\u8be5\u6846\u67b6\u5728\u9884\u6d4b\u7cbe\u5ea6\uff08NMSE\u964d\u4f4e\u8d85\u8fc749%\uff09\u548c\u901a\u4fe1\u53ef\u9760\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86MA\u90e8\u7f72\u4e2d\u7684\u901f\u5ea6\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u57ce\u5e02\u4f4e\u7a7a\u901a\u4fe1\u7684\u6027\u80fd\u3002"}}
{"id": "2508.10338", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.10338", "abs": "https://arxiv.org/abs/2508.10338", "authors": ["Bo Wu", "Pengfei Zhou"], "title": "Near-realtime Earth Observation Via Starlink LEO Satellite Constellation", "comment": null, "summary": "Earth observation (EO) satellites in Low Earth Orbit (LEO) are collecting\nvast amounts of data, which are invaluable for applications such as monitoring\nforest fires. However, data downloading from EO satellites faces significant\nchallenges due to the limited number of ground stations and the brief\ncommunication windows with them. Conversely, emerging LEO constellations like\nStarlink have enabled continuous connectivity and revolutionized access for\nordinary users globally, who can connect via a simple satellite dish. In this\npaper, we study the feasibility of supporting EO satellites with Starlink\nsatellite infrastructure and introduce a novel data delivery system, designated\nas \"Starlink Space User\" (SSU), for relaying data from observation satellites.\nSSU treats EO satellites as space users of Starlink, facilitating efficient\ndata transfer to Earth. At the core of SSU is a novel class of algorithms\ndesigned for link and PoP selection, as well as system scheduling optimization,\nthat operate effectively atop Starlink's proprietary infrastructure. We assess\nthe performance of SSU using trace-driven simulations alongside real-world\nStarlink performance measurements. Our results demonstrate that the proposed\nStarlink-aided design can significantly reduce the median backlog (data not\ndelivered) per satellite.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528Starlink\u536b\u661f\u57fa\u7840\u8bbe\u65bd\u652f\u6301\u5730\u7403\u89c2\u6d4b\u536b\u661f\u6570\u636e\u4f20\u8f93\u7684\u53ef\u884c\u6027\uff0c\u63d0\u51fa\u201cStarlink Space User\u201d\uff08SSU\uff09\u7cfb\u7edf\uff0c\u663e\u8457\u51cf\u5c11\u6570\u636e\u79ef\u538b\u3002", "motivation": "\u5730\u7403\u89c2\u6d4b\u536b\u661f\u6570\u636e\u4f20\u8f93\u53d7\u9650\u4e8e\u5730\u9762\u7ad9\u6570\u91cf\u548c\u77ed\u6682\u901a\u4fe1\u7a97\u53e3\uff0c\u800cStarlink\u536b\u661f\u661f\u5ea7\u63d0\u4f9b\u6301\u7eed\u8fde\u63a5\uff0c\u4e3a\u6570\u636e\u4f20\u8f93\u63d0\u4f9b\u65b0\u53ef\u80fd\u3002", "method": "\u63d0\u51faSSU\u7cfb\u7edf\uff0c\u5c06\u89c2\u6d4b\u536b\u661f\u89c6\u4e3aStarlink\u7684\u7a7a\u95f4\u7528\u6237\uff0c\u8bbe\u8ba1\u94fe\u8def\u548cPoP\u9009\u62e9\u7b97\u6cd5\u53ca\u8c03\u5ea6\u4f18\u5316\uff0c\u57fa\u4e8eStarlink\u57fa\u7840\u8bbe\u65bd\u5b9e\u73b0\u9ad8\u6548\u6570\u636e\u4f20\u8f93\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u548c\u5b9e\u6d4b\u9a8c\u8bc1\uff0cSSU\u663e\u8457\u964d\u4f4e\u4e86\u6bcf\u9897\u536b\u661f\u7684\u4e2d\u4f4d\u6570\u6570\u636e\u79ef\u538b\u3002", "conclusion": "SSU\u7cfb\u7edf\u5229\u7528Starlink\u57fa\u7840\u8bbe\u65bd\uff0c\u4e3a\u5730\u7403\u89c2\u6d4b\u536b\u661f\u6570\u636e\u4f20\u8f93\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.10143", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10143", "abs": "https://arxiv.org/abs/2508.10143", "authors": ["Alexandru-Andrei Avram", "Adrian Groza", "Alexandru Lecu"], "title": "MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection", "comment": "8 pages + 1 page references, 5 figures, 4 tables, Registered for the\n  27th International Symposium on Symbolic and Numeric Algorithms for\n  Scientific Computing, 2025, Timisoara", "summary": "The large spread of disinformation across digital platforms creates\nsignificant challenges to information integrity. This paper presents a\nmulti-agent system that uses relation extraction to detect disinformation in\nnews articles, focusing on titles and short text snippets. The proposed Agentic\nAI system combines four agents: (i) a machine learning agent (logistic\nregression), (ii) a Wikipedia knowledge check agent (which relies on named\nentity recognition), (iii) a coherence detection agent (using LLM prompt\nengineering), and (iv) a web-scraped data analyzer that extracts relational\ntriplets for fact checking. The system is orchestrated via the Model Context\nProtocol (MCP), offering shared context and live learning across components.\nResults demonstrate that the multi-agent ensemble achieves 95.3% accuracy with\nan F1 score of 0.964, significantly outperforming individual agents and\ntraditional approaches. The weighted aggregation method, mathematically derived\nfrom individual agent misclassification rates, proves superior to algorithmic\nthreshold optimization. The modular architecture makes the system easily\nscalable, while also maintaining details of the decision processes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u5173\u7cfb\u63d0\u53d6\u68c0\u6d4b\u65b0\u95fb\u6807\u9898\u548c\u77ed\u6587\u672c\u4e2d\u7684\u865a\u5047\u4fe1\u606f\uff0c\u7ed3\u5408\u56db\u79cd\u667a\u80fd\u4f53\uff0c\u5b9e\u73b0\u4e8695.3%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u6570\u5b57\u5e73\u53f0\u4e0a\u865a\u5047\u4fe1\u606f\u7684\u5e7f\u6cdb\u4f20\u64ad\u5bf9\u4fe1\u606f\u5b8c\u6574\u6027\u6784\u6210\u6311\u6218\uff0c\u9700\u8981\u9ad8\u6548\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u7cfb\u7edf\u7ed3\u5408\u56db\u79cd\u667a\u80fd\u4f53\uff1a\u673a\u5668\u5b66\u4e60\u3001\u7ef4\u57fa\u767e\u79d1\u77e5\u8bc6\u68c0\u67e5\u3001\u4e00\u81f4\u6027\u68c0\u6d4b\u548c\u7f51\u7edc\u6570\u636e\u6293\u53d6\u5206\u6790\uff0c\u901a\u8fc7MCP\u534f\u8bae\u534f\u8c03\u3002", "result": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u51c6\u786e\u7387\u8fbe95.3%\uff0cF1\u5206\u65700.964\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u6a21\u5757\u5316\u67b6\u6784\u4f7f\u7cfb\u7edf\u6613\u4e8e\u6269\u5c55\uff0c\u540c\u65f6\u4fdd\u7559\u51b3\u7b56\u8fc7\u7a0b\u7ec6\u8282\uff0c\u52a0\u6743\u805a\u5408\u65b9\u6cd5\u4f18\u4e8e\u9608\u503c\u4f18\u5316\u3002"}}
{"id": "2508.10791", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.10791", "abs": "https://arxiv.org/abs/2508.10791", "authors": ["Markus Tremmel", "Roland Zink"], "title": "MapLibre Tile: A Next Generation Vector Tile Format", "comment": null, "summary": "The Mapbox Vector Tile (MVT) format is widely considered the leading open\nstandard for large-scale map visualization, as evidenced by its widespread\nadoption by major technology companies such as AWS, Meta, and Microsoft for\ntheir products and services. However, MVT was developed nearly a decade ago\nand, consequently, does not fully align with the capabilities of new geospatial\ndata sources that are characterized by rapidly increasing data volumes due to\nadvancements in geospatial sensors and automated detection through artificial\nintelligence. In this paper, we introduce the MapLibre Tile (MLT) format, a\nnovel vector tile specification designed from the ground up to address the\nlimitations of MVT. Our experiments, simulating user sessions on widely used\nbasemap datasets, demonstrate that MLT achieves up to three times better\ncompression ratios compared to MVT on encoded tilesets, with over six times\nbetter on certain large tiles. Additionally, MLT offers decoding speeds that\nare up to three times faster and significantly enhances processing performance.\nMLT also introduces new functionalities and is specifically designed to lay the\nfoundation for the next generation of map renderers, which we expect to\nentirely offload processing to the GPU, thereby overcoming the stagnation of\nMoore`s law.", "AI": {"tldr": "Mapbox Vector Tile (MVT)\u683c\u5f0f\u867d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5df2\u8fc7\u65f6\u3002\u672c\u6587\u63d0\u51faMapLibre Tile (MLT)\u683c\u5f0f\uff0c\u4f18\u5316\u538b\u7f29\u6bd4\u548c\u89e3\u7801\u901f\u5ea6\uff0c\u5e76\u652f\u6301GPU\u5904\u7406\u3002", "motivation": "MVT\u683c\u5f0f\u5df2\u65e0\u6cd5\u6ee1\u8db3\u73b0\u4ee3\u5730\u7406\u7a7a\u95f4\u6570\u636e\u7684\u9700\u6c42\uff0c\u9700\u65b0\u683c\u5f0f\u4ee5\u5e94\u5bf9\u6570\u636e\u91cf\u589e\u957f\u548c\u65b0\u6280\u672f\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0MLT\u683c\u5f0f\uff0c\u901a\u8fc7\u5b9e\u9a8c\u5bf9\u6bd4\u5176\u4e0eMVT\u5728\u538b\u7f29\u6bd4\u3001\u89e3\u7801\u901f\u5ea6\u548c\u6027\u80fd\u4e0a\u7684\u8868\u73b0\u3002", "result": "MLT\u538b\u7f29\u6bd4\u63d0\u53473\u500d\uff0c\u89e3\u7801\u901f\u5ea6\u5feb3\u500d\uff0c\u5904\u7406\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "MLT\u4e3a\u4e0b\u4e00\u4ee3\u5730\u56fe\u6e32\u67d3\u5668\u5960\u5b9a\u57fa\u7840\uff0c\u652f\u6301GPU\u5904\u7406\uff0c\u7a81\u7834\u6469\u5c14\u5b9a\u5f8b\u9650\u5236\u3002"}}
{"id": "2508.10413", "categories": ["cs.NI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.10413", "abs": "https://arxiv.org/abs/2508.10413", "authors": ["Sanghoon Lee", "Hyung-Seok Park", "Jiyeong Chae", "Kyung-Joon Park"], "title": "Probabilistic Latency Analysis of the Data Distribution Service in ROS 2", "comment": "12 pages, 5 figures", "summary": "Robot Operating System 2 (ROS 2) is now the de facto standard for robotic\ncommunication, pairing UDP transport with the Data Distribution Service (DDS)\npublish-subscribe middleware. DDS achieves reliability through periodic\nheartbeats that solicit acknowledgments for missing samples and trigger\nselective retransmissions. In lossy wireless networks, the tight coupling among\nheartbeat period, IP fragmentation, and retransmission interval obscures end to\nend latency behavior and leaves practitioners with little guidance on how to\ntune these parameters. To address these challenges, we propose a probabilistic\nlatency analysis (PLA) that analytically models the reliable transmission\nprocess of ROS 2 DDS communication using a discrete state approach. By\nsystematically analyzing both middleware level and transport level events, PLA\ncomputes the steady state probability distribution of unacknowledged messages\nand the retransmission latency. We validate our PLA across 270 scenarios,\nexploring variations in packet delivery ratios, message sizes, and both\npublishing and retransmission intervals, demonstrating a close alignment\nbetween analytical predictions and experimental results. Our findings establish\na theoretical basis to systematically optimize reliability, latency, and\nperformance in wireless industrial robotics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6982\u7387\u5ef6\u8fdf\u5206\u6790\uff08PLA\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u5efa\u6a21ROS 2 DDS\u901a\u4fe1\u4e2d\u7684\u53ef\u9760\u4f20\u8f93\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u65e0\u7ebf\u7f51\u7edc\u4e2d\u53c2\u6570\u8c03\u4f18\u7684\u6311\u6218\u3002", "motivation": "\u5728\u65e0\u7ebf\u7f51\u7edc\u4e2d\uff0cROS 2 DDS\u901a\u4fe1\u7684\u5fc3\u8df3\u5468\u671f\u3001IP\u5206\u7247\u548c\u91cd\u4f20\u95f4\u9694\u7684\u7d27\u5bc6\u8026\u5408\u5bfc\u81f4\u7aef\u5230\u7aef\u5ef6\u8fdf\u884c\u4e3a\u4e0d\u660e\u786e\uff0c\u7f3a\u4e4f\u8c03\u4f18\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u79bb\u6563\u72b6\u6001\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u4e2d\u95f4\u4ef6\u548c\u4f20\u8f93\u5c42\u4e8b\u4ef6\uff0c\u8ba1\u7b97\u672a\u786e\u8ba4\u6d88\u606f\u7684\u7a33\u6001\u6982\u7387\u5206\u5e03\u548c\u91cd\u4f20\u5ef6\u8fdf\u3002", "result": "\u5728270\u79cd\u573a\u666f\u4e0b\u9a8c\u8bc1\u4e86PLA\uff0c\u7ed3\u679c\u663e\u793a\u5206\u6790\u9884\u6d4b\u4e0e\u5b9e\u9a8c\u7ed3\u679c\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "PLA\u4e3a\u65e0\u7ebf\u5de5\u4e1a\u673a\u5668\u4eba\u4e2d\u7684\u53ef\u9760\u6027\u3001\u5ef6\u8fdf\u548c\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2508.10146", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10146", "abs": "https://arxiv.org/abs/2508.10146", "authors": ["Hana Derouiche", "Zaki Brahmi", "Haithem Mazeni"], "title": "Agentic AI Frameworks: Architectures, Protocols, and Design Challenges", "comment": null, "summary": "The emergence of Large Language Models (LLMs) has ushered in a transformative\nparadigm in artificial intelligence, Agentic AI, where intelligent agents\nexhibit goal-directed autonomy, contextual reasoning, and dynamic multi-agent\ncoordination. This paper provides a systematic review and comparative analysis\nof leading Agentic AI frameworks, including CrewAI, LangGraph, AutoGen,\nSemantic Kernel, Agno, Google ADK, and MetaGPT, evaluating their architectural\nprinciples, communication mechanisms, memory management, safety guardrails, and\nalignment with service-oriented computing paradigms. Furthermore, we identify\nkey limitations, emerging trends, and open challenges in the field. To address\nthe issue of agent communication, we conduct an in-depth analysis of protocols\nsuch as the Contract Net Protocol (CNP), Agent-to-Agent (A2A), Agent Network\nProtocol (ANP), and Agora. Our findings not only establish a foundational\ntaxonomy for Agentic AI systems but also propose future research directions to\nenhance scalability, robustness, and interoperability. This work serves as a\ncomprehensive reference for researchers and practitioners working to advance\nthe next generation of autonomous AI systems.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u56de\u987e\u548c\u6bd4\u8f83\u4e86\u591a\u79cdAgentic AI\u6846\u67b6\uff0c\u5206\u6790\u4e86\u5176\u67b6\u6784\u3001\u901a\u4fe1\u673a\u5236\u7b49\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63a2\u7d22Agentic AI\u6846\u67b6\u7684\u73b0\u72b6\u3001\u5c40\u9650\u6027\u548c\u672a\u6765\u53d1\u5c55\u8d8b\u52bf\uff0c\u4e3a\u81ea\u4e3bAI\u7cfb\u7edf\u7684\u7814\u7a76\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u5bf9CrewAI\u3001LangGraph\u7b49\u6846\u67b6\u8fdb\u884c\u7cfb\u7edf\u56de\u987e\u548c\u6bd4\u8f83\u5206\u6790\uff0c\u6df1\u5165\u7814\u7a76\u4e86\u901a\u4fe1\u534f\u8bae\u5982CNP\u3001A2A\u7b49\u3002", "result": "\u5efa\u7acb\u4e86Agentic AI\u7cfb\u7edf\u7684\u57fa\u7840\u5206\u7c7b\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u589e\u5f3a\u53ef\u6269\u5c55\u6027\u3001\u9c81\u68d2\u6027\u548c\u4e92\u64cd\u4f5c\u6027\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u8bba\u6587\u4e3a\u4e0b\u4e00\u4ee3\u81ea\u4e3bAI\u7cfb\u7edf\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u5168\u9762\u53c2\u8003\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u6311\u6218\u548c\u8d8b\u52bf\u3002"}}
{"id": "2508.10574", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.10574", "abs": "https://arxiv.org/abs/2508.10574", "authors": ["Anshika Singh", "Siddhartha S. Borkotoky"], "title": "Federated Learning Over LoRa Networks: Simulator Design and Performance Evaluation", "comment": null, "summary": "Federated learning (FL) over long-range (LoRa) low-power wide area networks\nfaces unique challenges due to limited bandwidth, interference, and strict\nduty-cycle constraints. We develop a Python-based simulator that integrates and\nextends the Flower and LoRaSim frameworks to evaluate centralized FL over LoRa\nnetworks. The simulator employs a detailed link-level model for FL update\ntransfer over LoRa channels, capturing LoRa's receiver sensitivity,\ninterference characteristics, block-fading effects, and constraints on the\nmaximum transmission unit. It supports update sparsification, quantization,\ncompression, forward frame-erasure correction (FEC), and duty cycling.\nNumerical results illustrate the impact of transmission parameters (spreading\nfactor, FEC rate) and interference on FL performance. Demonstrating the\ncritical role of FEC in enabling FL over LoRa networks, we perform an in-depth\nevaluation of the impact of FEC on FL convergence and device airtime, providing\ninsights for communication protocol design for FL over LoRa networks.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8ePython\u7684\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u8bc4\u4f30\u5728LoRa\u7f51\u7edc\u4e0a\u7684\u8054\u90a6\u5b66\u4e60\u6027\u80fd\uff0c\u91cd\u70b9\u5173\u6ce8FEC\u5bf9\u5b66\u4e60\u6536\u655b\u548c\u8bbe\u5907\u901a\u4fe1\u65f6\u95f4\u7684\u5f71\u54cd\u3002", "motivation": "\u89e3\u51b3\u5728LoRa\u7f51\u7edc\u4e2d\u5b9e\u73b0\u8054\u90a6\u5b66\u4e60\u65f6\u9762\u4e34\u7684\u5e26\u5bbd\u9650\u5236\u3001\u5e72\u6270\u548c\u4e25\u683c\u5360\u7a7a\u6bd4\u7ea6\u675f\u7b49\u6311\u6218\u3002", "method": "\u6574\u5408\u5e76\u6269\u5c55Flower\u548cLoRaSim\u6846\u67b6\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u6a21\u62df\u5668\uff0c\u8be6\u7ec6\u5efa\u6a21\u4e86LoRa\u4fe1\u9053\u4e0a\u7684FL\u66f4\u65b0\u4f20\u8f93\uff0c\u652f\u6301\u591a\u79cd\u4f18\u5316\u6280\u672f\uff08\u5982\u7a00\u758f\u5316\u3001\u91cf\u5316\u3001\u538b\u7f29\u3001FEC\u548c\u5360\u7a7a\u6bd4\u63a7\u5236\uff09\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u4f20\u8f93\u53c2\u6570\uff08\u5982\u6269\u9891\u56e0\u5b50\u3001FEC\u7387\uff09\u548c\u5e72\u6270\u5bf9FL\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0cFEC\u5728LoRa\u7f51\u7edc\u4e2d\u5b9e\u73b0FL\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "FEC\u5bf9FL\u7684\u6536\u655b\u548c\u8bbe\u5907\u901a\u4fe1\u65f6\u95f4\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4e3aLoRa\u7f51\u7edc\u4e0a\u7684FL\u901a\u4fe1\u534f\u8bae\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2508.10152", "categories": ["cs.AI", "I.2.7; H.3.3"], "pdf": "https://arxiv.org/pdf/2508.10152", "abs": "https://arxiv.org/abs/2508.10152", "authors": ["Doaa Allabadi", "Kyle Bradbury", "Jordan M. Malof"], "title": "Improving and Evaluating Open Deep Research Agents", "comment": "8 pages, 2 figures, 2 tables", "summary": "We focus here on Deep Research Agents (DRAs), which are systems that can take\na natural language prompt from a user, and then autonomously search for, and\nutilize, internet-based content to address the prompt. Recent DRAs have\ndemonstrated impressive capabilities on public benchmarks however, recent\nresearch largely involves proprietary closed-source systems. At the time of\nthis work, we only found one open-source DRA, termed Open Deep Research (ODR).\nIn this work we adapt the challenging recent BrowseComp benchmark to compare\nODR to existing proprietary systems. We propose BrowseComp-Small (BC-Small),\ncomprising a subset of BrowseComp, as a more computationally-tractable DRA\nbenchmark for academic labs. We benchmark ODR and two other proprietary systems\non BC-Small: one system from Anthropic and one system from Google. We find that\nall three systems achieve 0% accuracy on the test set of 60 questions. We\nintroduce three strategic improvements to ODR, resulting in the ODR+ model,\nwhich achieves a state-of-the-art 10% success rate on BC-Small among both\nclosed-source and open-source systems. We report ablation studies indicating\nthat all three of our improvements contributed to the success of ODR+.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5f00\u6e90\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\uff08ODR\uff09\u4e0e\u95ed\u6e90\u7cfb\u7edf\u5728BrowseComp-Small\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u901a\u8fc7\u6539\u8fdb\u63d0\u51fa\u4e86ODR+\u6a21\u578b\uff0c\u4f7f\u5176\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523010%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\uff08DRAs\uff09\u591a\u4e3a\u95ed\u6e90\u7cfb\u7edf\uff0c\u7f3a\u4e4f\u5f00\u6e90\u9009\u9879\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6539\u8fdb\u5f00\u6e90ODR\u6a21\u578b\uff0c\u63d0\u5347\u5176\u5728\u6311\u6218\u6027\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51faBrowseComp-Small\uff08BC-Small\uff09\u4f5c\u4e3a\u66f4\u6613\u5904\u7406\u7684\u57fa\u51c6\uff0c\u6bd4\u8f83ODR\u4e0e\u95ed\u6e90\u7cfb\u7edf\uff08Anthropic\u548cGoogle\uff09\u7684\u8868\u73b0\uff0c\u5e76\u901a\u8fc7\u4e09\u9879\u6539\u8fdb\u63d0\u51faODR+\u6a21\u578b\u3002", "result": "\u6240\u6709\u7cfb\u7edf\u572860\u4e2a\u6d4b\u8bd5\u95ee\u9898\u4e0a\u7684\u521d\u59cb\u51c6\u786e\u7387\u4e3a0%\uff0c\u6539\u8fdb\u540e\u7684ODR+\u8fbe\u523010%\u7684\u6210\u529f\u7387\uff0c\u4f18\u4e8e\u5176\u4ed6\u7cfb\u7edf\u3002", "conclusion": "ODR+\u901a\u8fc7\u4e09\u9879\u6539\u8fdb\u5728BC-Small\u4e0a\u53d6\u5f97\u6700\u4f73\u8868\u73b0\uff0c\u4e3a\u5f00\u6e90DRAs\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2508.10588", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.10588", "abs": "https://arxiv.org/abs/2508.10588", "authors": ["Siddhartha S. Borkotoky"], "title": "Balancing the Energy Consumption and Latency of Over-the-Air Firmware Updates in LoRaWAN", "comment": null, "summary": "Over-the-air firmware updates are crucial for mitigating security threats and\nmaintaining up-to-date device functionality in Long Range Wide Area Networks\n(LoRaWANs). LoRaWAN end devices are usually energy-constrained, and LoRaWAN\ntransmissions are subject to duty-cycle restrictions. Consequently, controlling\nthe energy expenditure and update-delivery latency of FUOTA are key challenges.\nWe propose a flexible scheme that achieves a tunable trade-off between the\nenergy consumption and delivery delay. The scheme employs the LoRa spreading\nfactors sequentially to transmit update-carrying frames, sending a fixed number\nof frames with a given spreading factor before moving to the next. By adjusting\nthe smallest spreading factor to be used and the number of transmissions per\nspreading factor, a suitable energy-delay trade-off can be achieved. Thus,\ntime-sensitive updates, such as security patches, may be sent with a\nlow-delay-high-energy setting, whereas a more energy-efficient but higher-delay\nsetting may be used for non-critical updates.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7075\u6d3b\u65b9\u6848\uff0c\u5728LoRaWAN\u4e2d\u5b9e\u73b0\u80fd\u91cf\u6d88\u8017\u4e0e\u66f4\u65b0\u5ef6\u8fdf\u7684\u53ef\u8c03\u6743\u8861\u3002", "motivation": "\u89e3\u51b3LoRaWAN\u7ec8\u7aef\u8bbe\u5907\u56e0\u80fd\u91cf\u53d7\u9650\u548c\u4f20\u8f93\u5468\u671f\u9650\u5236\u5bfc\u81f4\u7684\u56fa\u4ef6\u66f4\u65b0\u80fd\u91cf\u6d88\u8017\u4e0e\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u91c7\u7528LoRa\u6269\u9891\u56e0\u5b50\u987a\u5e8f\u4f20\u8f93\u66f4\u65b0\u5e27\uff0c\u901a\u8fc7\u8c03\u6574\u6700\u5c0f\u6269\u9891\u56e0\u5b50\u548c\u6bcf\u4e2a\u6269\u9891\u56e0\u5b50\u7684\u4f20\u8f93\u6b21\u6570\u5b9e\u73b0\u6743\u8861\u3002", "result": "\u65b9\u6848\u53ef\u6839\u636e\u9700\u6c42\u9009\u62e9\u4f4e\u5ef6\u8fdf\u9ad8\u80fd\u8017\u6216\u9ad8\u5ef6\u8fdf\u4f4e\u80fd\u8017\u7684\u66f4\u65b0\u8bbe\u7f6e\u3002", "conclusion": "\u8be5\u65b9\u6848\u4e3aLoRaWAN\u56fa\u4ef6\u66f4\u65b0\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u80fd\u91cf\u4e0e\u5ef6\u8fdf\u6743\u8861\u7b56\u7565\u3002"}}
{"id": "2508.10164", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10164", "abs": "https://arxiv.org/abs/2508.10164", "authors": ["Bin Hong", "Jiayu Liu", "Zhenya Huang", "Kai Zhang", "Mengdi Zhang"], "title": "Pruning Long Chain-of-Thought of Large Reasoning Models via Small-Scale Preference Optimization", "comment": "19 pages, 5 figures", "summary": "Recent advances in Large Reasoning Models (LRMs) have demonstrated strong\nperformance on complex tasks through long Chain-of-Thought (CoT) reasoning.\nHowever, their lengthy outputs increase computational costs and may lead to\noverthinking, raising challenges in balancing reasoning effectiveness and\nefficiency. Current methods for efficient reasoning often compromise reasoning\nquality or require extensive resources. This paper investigates efficient\nmethods to reduce the generation length of LRMs. We analyze generation path\ndistributions and filter generated trajectories through difficulty estimation.\nSubsequently, we analyze the convergence behaviors of the objectives of various\npreference optimization methods under a Bradley-Terry loss based framework.\nBased on the analysis, we propose Length Controlled Preference Optimization\n(LCPO) that directly balances the implicit reward related to NLL loss. LCPO can\neffectively learn length preference with limited data and training. Extensive\nexperiments demonstrate that our approach significantly reduces the average\noutput length by over 50\\% across multiple benchmarks while maintaining the\nreasoning performance. Our work highlights the potential for computationally\nefficient approaches in guiding LRMs toward efficient reasoning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLCPO\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a7\u5236\u751f\u6210\u957f\u5ea6\u6765\u5e73\u8861\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8f93\u51fa\u957f\u5ea6\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u957f\u63a8\u7406\u94fe\u589e\u52a0\u4e86\u8ba1\u7b97\u6210\u672c\u5e76\u53ef\u80fd\u5bfc\u81f4\u8fc7\u5ea6\u601d\u8003\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u6548\u7387\u548c\u63a8\u7406\u8d28\u91cf\u4e4b\u95f4\u96be\u4ee5\u5e73\u8861\u3002", "method": "\u5206\u6790\u751f\u6210\u8def\u5f84\u5206\u5e03\u5e76\u901a\u8fc7\u96be\u5ea6\u4f30\u8ba1\u8fc7\u6ee4\u8f68\u8ff9\uff0c\u63d0\u51faLCPO\u65b9\u6cd5\u76f4\u63a5\u5e73\u8861NLL\u635f\u5931\u76f8\u5173\u7684\u9690\u5f0f\u5956\u52b1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLCPO\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u5c06\u5e73\u5747\u8f93\u51fa\u957f\u5ea6\u51cf\u5c1150%\u4ee5\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "LCPO\u5c55\u793a\u4e86\u5728\u6709\u9650\u6570\u636e\u548c\u8bad\u7ec3\u4e0b\u6307\u5bfc\u5927\u578b\u63a8\u7406\u6a21\u578b\u9ad8\u6548\u63a8\u7406\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.10177", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10177", "abs": "https://arxiv.org/abs/2508.10177", "authors": ["Stepan Kulibaba", "Artem Dzhalilov", "Roman Pakhomov", "Oleg Svidchenko", "Alexander Gasnikov", "Aleksei Shpilman"], "title": "KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems", "comment": null, "summary": "Recent Large Language Model (LLM)-based AutoML systems demonstrate impressive\ncapabilities but face significant limitations such as constrained exploration\nstrategies and a severe execution bottleneck. Exploration is hindered by\none-shot methods lacking diversity and Monte Carlo Tree Search (MCTS)\napproaches that fail to recombine strong partial solutions. The execution\nbottleneck arises from lengthy code validation cycles that stifle iterative\nrefinement. To overcome these challenges, we introduce KompeteAI, a novel\nAutoML framework with dynamic solution space exploration. Unlike previous MCTS\nmethods that treat ideas in isolation, KompeteAI introduces a merging stage\nthat composes top candidates. We further expand the hypothesis space by\nintegrating Retrieval-Augmented Generation (RAG), sourcing ideas from Kaggle\nnotebooks and arXiv papers to incorporate real-world strategies. KompeteAI also\naddresses the execution bottleneck via a predictive scoring model and an\naccelerated debugging method, assessing solution potential using early stage\nmetrics to avoid costly full-code execution. This approach accelerates pipeline\nevaluation 6.9 times. KompeteAI outperforms leading methods (e.g., RD-agent,\nAIDE, and Ml-Master) by an average of 3\\% on the primary AutoML benchmark,\nMLE-Bench. Additionally, we propose Kompete-bench to address limitations in\nMLE-Bench, where KompeteAI also achieves state-of-the-art results", "AI": {"tldr": "KompeteAI\u662f\u4e00\u4e2a\u65b0\u578bAutoML\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4\u63a2\u7d22\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u89e3\u51b3\u73b0\u6709LLM-based AutoML\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u5982\u63a2\u7d22\u7b56\u7565\u5355\u4e00\u548c\u6267\u884c\u74f6\u9888\u3002", "motivation": "\u73b0\u6709LLM-based AutoML\u7cfb\u7edf\u5b58\u5728\u63a2\u7d22\u7b56\u7565\u5355\u4e00\uff08\u5982\u4e00\u6b21\u6027\u65b9\u6cd5\u7f3a\u4e4f\u591a\u6837\u6027\uff09\u548c\u6267\u884c\u74f6\u9888\uff08\u5982\u4ee3\u7801\u9a8c\u8bc1\u5468\u671f\u957f\uff09\uff0c\u9650\u5236\u4e86\u6027\u80fd\u63d0\u5347\u3002", "method": "KompeteAI\u5f15\u5165\u52a8\u6001\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4\u63a2\u7d22\uff0c\u5305\u62ec\u5408\u5e76\u9636\u6bb5\u4ee5\u7ec4\u5408\u5019\u9009\u65b9\u6848\uff0c\u5e76\u96c6\u6210RAG\u4eceKaggle\u548carXiv\u83b7\u53d6\u771f\u5b9e\u7b56\u7565\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u9884\u6d4b\u8bc4\u5206\u6a21\u578b\u548c\u52a0\u901f\u8c03\u8bd5\u65b9\u6cd5\u51cf\u5c11\u6267\u884c\u65f6\u95f4\u3002", "result": "KompeteAI\u5728MLE-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd53%\uff0c\u5e76\u5c06\u7ba1\u9053\u8bc4\u4f30\u901f\u5ea6\u63d0\u53476.9\u500d\u3002", "conclusion": "KompeteAI\u901a\u8fc7\u521b\u65b0\u63a2\u7d22\u7b56\u7565\u548c\u6267\u884c\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86AutoML\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5Kompete-bench\u3002"}}
{"id": "2508.10241", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10241", "abs": "https://arxiv.org/abs/2508.10241", "authors": ["Mark Zilberman"], "title": "Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence", "comment": "10 pages", "summary": "This work demonstrates how the concept of the entropic potential of events --\na parameter quantifying the influence of discrete events on the expected future\nentropy of a system -- can enhance uncertainty quantification, decision-making,\nand interpretability in artificial intelligence (AI). Building on its original\nformulation in physics, the framework is adapted for AI by introducing an\nevent-centric measure that captures how actions, observations, or other\ndiscrete occurrences impact uncertainty at future time horizons. Both the\noriginal and AI-adjusted definitions of entropic potential are formalized, with\nthe latter emphasizing conditional expectations to account for counterfactual\nscenarios. Applications are explored in policy evaluation, intrinsic reward\ndesign, explainable AI, and anomaly detection, highlighting the metric's\npotential to unify and strengthen uncertainty modeling in intelligent systems.\nConceptual examples illustrate its use in reinforcement learning, Bayesian\ninference, and anomaly detection, while practical considerations for\ncomputation in complex AI models are discussed. The entropic potential\nframework offers a theoretically grounded, interpretable, and versatile\napproach to managing uncertainty in AI, bridging principles from\nthermodynamics, information theory, and machine learning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u71b5\u4e8b\u4ef6\u52bf\u7684\u6982\u5ff5\uff0c\u7528\u4e8e\u589e\u5f3aAI\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3001\u51b3\u7b56\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5e94\u7528\u5c55\u793a\u4e86\u5176\u6f5c\u529b\u3002", "motivation": "\u901a\u8fc7\u5f15\u5165\u71b5\u4e8b\u4ef6\u52bf\u7684\u6982\u5ff5\uff0c\u65e8\u5728\u7edf\u4e00\u548c\u52a0\u5f3a\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\uff0c\u7ed3\u5408\u7269\u7406\u5b66\u3001\u4fe1\u606f\u8bba\u548c\u673a\u5668\u5b66\u4e60\u7684\u539f\u7406\u3002", "method": "\u5c06\u7269\u7406\u5b66\u4e2d\u7684\u71b5\u4e8b\u4ef6\u52bf\u6846\u67b6\u8c03\u6574\u4e3aAI\u9002\u7528\uff0c\u5f15\u5165\u4e8b\u4ef6\u4e2d\u5fc3\u5ea6\u91cf\uff0c\u5f3a\u8c03\u6761\u4ef6\u671f\u671b\u4ee5\u8003\u8651\u53cd\u4e8b\u5b9e\u573a\u666f\u3002", "result": "\u5728\u7b56\u7565\u8bc4\u4f30\u3001\u5185\u5728\u5956\u52b1\u8bbe\u8ba1\u3001\u53ef\u89e3\u91caAI\u548c\u5f02\u5e38\u68c0\u6d4b\u7b49\u5e94\u7528\u4e2d\u5c55\u793a\u4e86\u71b5\u4e8b\u4ef6\u52bf\u7684\u6f5c\u529b\u3002", "conclusion": "\u71b5\u4e8b\u4ef6\u52bf\u6846\u67b6\u4e3aAI\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u7ba1\u7406\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3001\u53ef\u89e3\u91ca\u6027\u548c\u591a\u529f\u80fd\u6027\uff0c\u8fde\u63a5\u4e86\u591a\u4e2a\u5b66\u79d1\u9886\u57df\u3002"}}
{"id": "2508.10265", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.10265", "abs": "https://arxiv.org/abs/2508.10265", "authors": ["Jingde Cheng"], "title": "Why Cannot Large Language Models Ever Make True Correct Reasoning?", "comment": "8 pages. arXiv admin note: substantial text overlap with\n  arXiv:2412.12408", "summary": "Recently, with the application progress of AIGC tools based on large language\nmodels (LLMs), led by ChatGPT, many AI experts and more non-professionals are\ntrumpeting the \"understanding ability\" and \"reasoning ability\" of the LLMs. The\npresent author considers that the so-called \"understanding ability\" and\n\"reasoning ability\" of LLMs are just illusions of those people who with vague\nconcepts. In fact, the LLMs can never have the true understanding ability and\ntrue reasoning ability. This paper intents to explain that, because the\nessential limitations of their working principle, the LLMs can never have the\nability of true correct reasoning.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684AIGC\u5de5\u5177\uff08\u5982ChatGPT\uff09\u7684\u6240\u8c13\u201c\u7406\u89e3\u80fd\u529b\u201d\u548c\u201c\u63a8\u7406\u80fd\u529b\u201d\u53ea\u662f\u6a21\u7cca\u6982\u5ff5\u4e0b\u7684\u5e7b\u89c9\uff0cLLMs\u672c\u8d28\u4e0a\u65e0\u6cd5\u5177\u5907\u771f\u6b63\u7684\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u63a2\u8ba8LLMs\u662f\u5426\u771f\u6b63\u5177\u5907\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\uff0c\u63ed\u793a\u5176\u5de5\u4f5c\u539f\u7406\u7684\u672c\u8d28\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790LLMs\u7684\u5de5\u4f5c\u539f\u7406\uff0c\u8bba\u8bc1\u5176\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u6b63\u786e\u63a8\u7406\u3002", "result": "LLMs\u7531\u4e8e\u5176\u672c\u8d28\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u5177\u5907\u771f\u6b63\u7684\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "LLMs\u7684\u201c\u7406\u89e3\u201d\u548c\u201c\u63a8\u7406\u201d\u53ea\u662f\u8868\u8c61\uff0c\u65e0\u6cd5\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u7684\u771f\u6b63\u80fd\u529b\u3002"}}
{"id": "2508.10293", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10293", "abs": "https://arxiv.org/abs/2508.10293", "authors": ["Chuhuai Yue", "Chengqi Dong", "Yinan Gao", "Hang He", "Jiajun Chai", "Guojun Yin", "Wei Lin"], "title": "Promoting Efficient Reasoning with Verifiable Stepwise Reward", "comment": null, "summary": "Large reasoning models (LRMs) have recently achieved significant progress in\ncomplex reasoning tasks, aided by reinforcement learning with verifiable\nrewards. However, LRMs often suffer from overthinking, expending excessive\ncomputation on simple problems and reducing efficiency. Existing efficient\nreasoning methods typically require accurate task assessment to preset token\nbudgets or select reasoning modes, which limits their flexibility and\nreliability. In this work, we revisit the essence of overthinking and identify\nthat encouraging effective steps while penalizing ineffective ones is key to\nits solution. To this end, we propose a novel rule-based verifiable stepwise\nreward mechanism (VSRM), which assigns rewards based on the performance of\nintermediate states in the reasoning trajectory. This approach is intuitive and\nnaturally fits the step-by-step nature of reasoning tasks. We conduct extensive\nexperiments on standard mathematical reasoning benchmarks, including AIME24 and\nAIME25, by integrating VSRM with PPO and Reinforce++. Results show that our\nmethod achieves substantial output length reduction while maintaining original\nreasoning performance, striking an optimal balance between efficiency and\naccuracy. Further analysis of overthinking frequency and pass@k score before\nand after training demonstrates that our approach in deed effectively\nsuppresses ineffective steps and encourages effective reasoning, fundamentally\nalleviating the overthinking problem. All code will be released upon\nacceptance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c4\u5219\u7684\u53ef\u9a8c\u8bc1\u9010\u6b65\u5956\u52b1\u673a\u5236\uff08VSRM\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u7b80\u5355\u95ee\u9898\u4e0a\u8fc7\u5ea6\u601d\u8003\u7684\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u7b80\u5355\u95ee\u9898\u4e0a\u4f1a\u8fc7\u5ea6\u601d\u8003\uff0c\u964d\u4f4e\u6548\u7387\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u9884\u8bbe\u9884\u7b97\u6216\u9009\u62e9\u6a21\u5f0f\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51faVSRM\u673a\u5236\uff0c\u6839\u636e\u63a8\u7406\u8f68\u8ff9\u4e2d\u4e2d\u95f4\u72b6\u6001\u7684\u8868\u73b0\u5206\u914d\u5956\u52b1\uff0c\u9f13\u52b1\u6709\u6548\u6b65\u9aa4\u5e76\u60e9\u7f5a\u65e0\u6548\u6b65\u9aa4\u3002", "result": "\u5728AIME24\u548cAIME25\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVSRM\u663e\u8457\u51cf\u5c11\u4e86\u8f93\u51fa\u957f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u6027\u80fd\uff0c\u6709\u6548\u6291\u5236\u4e86\u65e0\u6548\u6b65\u9aa4\u3002", "conclusion": "VSRM\u901a\u8fc7\u9010\u6b65\u5956\u52b1\u673a\u5236\uff0c\u4ece\u6839\u672c\u4e0a\u7f13\u89e3\u4e86\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5e73\u8861\u4e86\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002"}}
{"id": "2508.10337", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.10337", "abs": "https://arxiv.org/abs/2508.10337", "authors": ["Chenliang Zhang", "Lin Wang", "Yuanyuan Lu", "Yusheng Qi", "Kexin Wang", "Peixu Hou", "Wenshi Chen"], "title": "A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering", "comment": null, "summary": "This paper describes the solutions of the Dianping-Trust-Safety team for the\nMETA CRAG-MM challenge. The challenge requires building a comprehensive\nretrieval-augmented generation system capable for multi-modal multi-turn\nquestion answering. The competition consists of three tasks: (1) answering\nquestions using structured data retrieved from an image-based mock knowledge\ngraph, (2) synthesizing information from both knowledge graphs and web search\nresults, and (3) handling multi-turn conversations that require context\nunderstanding and information aggregation from multiple sources. For Task 1,\nour solution is based on the vision large language model, enhanced by\nsupervised fine-tuning with knowledge distilled from GPT-4.1. We further\napplied curriculum learning strategies to guide reinforcement learning,\nresulting in improved answer accuracy and reduced hallucination. For Task 2 and\nTask 3, we additionally leveraged web search APIs to incorporate external\nknowledge, enabling the system to better handle complex queries and multi-turn\nconversations. Our approach achieved 1st place in Task 1 with a significant\nlead of 52.38\\%, and 3rd place in Task 3, demonstrating the effectiveness of\nthe integration of curriculum learning with reinforcement learning in our\ntraining pipeline.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86Dianping-Trust-Safety\u56e2\u961f\u5728META CRAG-MM\u6311\u6218\u4e2d\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6d89\u53ca\u591a\u6a21\u6001\u591a\u8f6e\u95ee\u7b54\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u89c6\u89c9\u5927\u8bed\u8a00\u6a21\u578b\u3001\u76d1\u7763\u5fae\u8c03\u548c\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u591a\u8f6e\u95ee\u7b54\u4e2d\u7684\u590d\u6742\u4efb\u52a1\uff0c\u5305\u62ec\u7ed3\u6784\u5316\u6570\u636e\u68c0\u7d22\u3001\u591a\u6e90\u4fe1\u606f\u5408\u6210\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\u3002", "method": "\u7ed3\u5408\u89c6\u89c9\u5927\u8bed\u8a00\u6a21\u578b\u3001GPT-4.1\u77e5\u8bc6\u84b8\u998f\u3001\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u5e76\u5229\u7528\u7f51\u7edc\u641c\u7d22API\u589e\u5f3a\u5916\u90e8\u77e5\u8bc6\u3002", "result": "\u5728\u4efb\u52a11\u4e2d\u4ee552.38%\u7684\u4f18\u52bf\u6392\u540d\u7b2c\u4e00\uff0c\u4efb\u52a13\u4e2d\u6392\u540d\u7b2c\u4e09\u3002", "conclusion": "\u8bfe\u7a0b\u5b66\u4e60\u4e0e\u5f3a\u5316\u5b66\u4e60\u7684\u7ed3\u5408\u5728\u591a\u6a21\u6001\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2508.10340", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10340", "abs": "https://arxiv.org/abs/2508.10340", "authors": ["Chak Lam Shek", "Guangyao Shi", "Pratap Tokekar"], "title": "Multi-Agent Trust Region Policy Optimisation: A Joint Constraint Approach", "comment": null, "summary": "Multi-agent reinforcement learning (MARL) requires coordinated and stable\npolicy updates among interacting agents. Heterogeneous-Agent Trust Region\nPolicy Optimization (HATRPO) enforces per-agent trust region constraints using\nKullback-Leibler (KL) divergence to stabilize training. However, assigning each\nagent the same KL threshold can lead to slow and locally optimal updates,\nespecially in heterogeneous settings. To address this limitation, we propose\ntwo approaches for allocating the KL divergence threshold across agents:\nHATRPO-W, a Karush-Kuhn-Tucker-based (KKT-based) method that optimizes\nthreshold assignment under global KL constraints, and HATRPO-G, a greedy\nalgorithm that prioritizes agents based on improvement-to-divergence ratio. By\nconnecting sequential policy optimization with constrained threshold\nscheduling, our approach enables more flexible and effective learning in\nheterogeneous-agent settings. Experimental results demonstrate that our methods\nsignificantly boost the performance of HATRPO, achieving faster convergence and\nhigher final rewards across diverse MARL benchmarks. Specifically, HATRPO-W and\nHATRPO-G achieve comparable improvements in final performance, each exceeding\n22.5%. Notably, HATRPO-W also demonstrates more stable learning dynamics, as\nreflected by its lower variance.", "AI": {"tldr": "HATRPO-W\u548cHATRPO-G\u901a\u8fc7\u52a8\u6001\u5206\u914dKL\u9608\u503c\u4f18\u5316\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7b56\u7565\u66f4\u65b0\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u5728\u5f02\u6784\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\uff0c\u56fa\u5b9aKL\u9608\u503c\u53ef\u80fd\u5bfc\u81f4\u7b56\u7565\u66f4\u65b0\u7f13\u6162\u548c\u5c40\u90e8\u6700\u4f18\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u9608\u503c\u5206\u914d\u65b9\u6cd5\u3002", "method": "\u63d0\u51faHATRPO-W\uff08\u57fa\u4e8eKKT\u7684\u5168\u5c40\u4f18\u5316\uff09\u548cHATRPO-G\uff08\u57fa\u4e8e\u8d2a\u5a6a\u7b97\u6cd5\u7684\u4f18\u5148\u7ea7\u5206\u914d\uff09\uff0c\u52a8\u6001\u8c03\u6574KL\u9608\u503c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e24\u79cd\u65b9\u6cd5\u5747\u663e\u8457\u63d0\u5347\u6027\u80fd\uff08\u8d85\u8fc722.5%\uff09\uff0cHATRPO-W\u8fd8\u8868\u73b0\u51fa\u66f4\u4f4e\u7684\u65b9\u5dee\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "\u52a8\u6001KL\u9608\u503c\u5206\u914d\u5728\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u6709\u6548\uff0cHATRPO-W\u548cHATRPO-G\u4e3a\u5f02\u6784\u73af\u5883\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.10358", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10358", "abs": "https://arxiv.org/abs/2508.10358", "authors": ["Mengtao Zhou", "Sifan Wu", "Huan Zhang", "Qi Sima", "Bang Liu"], "title": "What to Ask Next? Probing the Imaginative Reasoning of LLMs with TurtleSoup Puzzles", "comment": null, "summary": "We investigate the capacity of Large Language Models (LLMs) for imaginative\nreasoning--the proactive construction, testing, and revision of hypotheses in\ninformation-sparse environments. Existing benchmarks, often static or focused\non social deduction, fail to capture the dynamic, exploratory nature of this\nreasoning process. To address this gap, we introduce a comprehensive research\nframework based on the classic \"Turtle Soup\" game, integrating a benchmark, an\nagent, and an evaluation protocol. We present TurtleSoup-Bench, the first\nlarge-scale, bilingual, interactive benchmark for imaginative reasoning,\ncomprising 800 turtle soup puzzles sourced from both the Internet and expert\nauthors. We also propose Mosaic-Agent, a novel agent designed to assess LLMs'\nperformance in this setting. To evaluate reasoning quality, we develop a\nmulti-dimensional protocol measuring logical consistency, detail completion,\nand conclusion alignment. Experiments with leading LLMs reveal clear capability\nlimits, common failure patterns, and a significant performance gap compared to\nhumans. Our work offers new insights into LLMs' imaginative reasoning and\nestablishes a foundation for future research on exploratory agent behavior.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4fe1\u606f\u7a00\u758f\u73af\u5883\u4e2d\u7684\u60f3\u8c61\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u201c\u4e4c\u9f9f\u6c64\u201d\u6e38\u620f\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u63ed\u793a\u4e86LLMs\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u6355\u6349\u52a8\u6001\u63a2\u7d22\u6027\u63a8\u7406\u8fc7\u7a0b\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u201c\u4e4c\u9f9f\u6c64\u201d\u6e38\u620f\u7684\u6846\u67b6\uff0c\u5305\u62ecTurtleSoup-Bench\u57fa\u51c6\u3001Mosaic-Agent\u548c\u591a\u7ef4\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u5b9e\u9a8c\u663e\u793aLLMs\u5728\u60f3\u8c61\u63a8\u7406\u4e2d\u5b58\u5728\u660e\u663e\u80fd\u529b\u9650\u5236\uff0c\u4e0e\u4eba\u7c7b\u8868\u73b0\u5dee\u8ddd\u663e\u8457\u3002", "conclusion": "\u7814\u7a76\u4e3aLLMs\u7684\u60f3\u8c61\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u5e76\u4e3a\u672a\u6765\u63a2\u7d22\u6027\u4ee3\u7406\u884c\u4e3a\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.10391", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10391", "abs": "https://arxiv.org/abs/2508.10391", "authors": ["Yaoze Zhang", "Rong Wu", "Pinlong Cai", "Xiaoman Wang", "Guohang Yan", "Song Mao", "Ding Wang", "Botian Shi"], "title": "LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) plays a crucial role in grounding Large\nLanguage Models by leveraging external knowledge, whereas the effectiveness is\noften compromised by the retrieval of contextually flawed or incomplete\ninformation. To address this, knowledge graph-based RAG methods have evolved\ntowards hierarchical structures, organizing knowledge into multi-level\nsummaries. However, these approaches still suffer from two critical,\nunaddressed challenges: high-level conceptual summaries exist as disconnected\n``semantic islands'', lacking the explicit relations needed for cross-community\nreasoning; and the retrieval process itself remains structurally unaware, often\ndegenerating into an inefficient flat search that fails to exploit the graph's\nrich topology. To overcome these limitations, we introduce LeanRAG, a framework\nthat features a deeply collaborative design combining knowledge aggregation and\nretrieval strategies. LeanRAG first employs a novel semantic aggregation\nalgorithm that forms entity clusters and constructs new explicit relations\namong aggregation-level summaries, creating a fully navigable semantic network.\nThen, a bottom-up, structure-guided retrieval strategy anchors queries to the\nmost relevant fine-grained entities and then systematically traverses the\ngraph's semantic pathways to gather concise yet contextually comprehensive\nevidence sets. The LeanRAG can mitigate the substantial overhead associated\nwith path retrieval on graphs and minimizes redundant information retrieval.\nExtensive experiments on four challenging QA benchmarks with different domains\ndemonstrate that LeanRAG significantly outperforming existing methods in\nresponse quality while reducing 46\\% retrieval redundancy. Code is available\nat: https://github.com/RaZzzyz/LeanRAG", "AI": {"tldr": "LeanRAG\u901a\u8fc7\u77e5\u8bc6\u805a\u5408\u548c\u68c0\u7d22\u7b56\u7565\u7684\u6df1\u5ea6\u534f\u4f5c\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31RAG\u65b9\u6cd5\u4e2d\u8bed\u4e49\u5b64\u5c9b\u548c\u68c0\u7d22\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u95ee\u7b54\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31RAG\u65b9\u6cd5\u5b58\u5728\u8bed\u4e49\u5b64\u5c9b\u548c\u68c0\u7d22\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6548\u679c\u3002", "method": "LeanRAG\u91c7\u7528\u8bed\u4e49\u805a\u5408\u7b97\u6cd5\u6784\u5efa\u53ef\u5bfc\u822a\u7684\u8bed\u4e49\u7f51\u7edc\uff0c\u5e76\u7ed3\u5408\u81ea\u5e95\u5411\u4e0a\u7684\u7ed3\u6784\u5f15\u5bfc\u68c0\u7d22\u7b56\u7565\uff0c\u4f18\u5316\u68c0\u7d22\u8fc7\u7a0b\u3002", "result": "\u5728\u56db\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLeanRAG\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u51cf\u5c11\u4e8646%\u7684\u68c0\u7d22\u5197\u4f59\u3002", "conclusion": "LeanRAG\u901a\u8fc7\u521b\u65b0\u7684\u8bed\u4e49\u805a\u5408\u548c\u68c0\u7d22\u7b56\u7565\uff0c\u6709\u6548\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31RAG\u7684\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2508.10425", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.10425", "abs": "https://arxiv.org/abs/2508.10425", "authors": ["Yan Ting Chok", "Soyon Park", "Seungheun Baek", "Hajung Kim", "Junhyun Lee", "Jaewoo Kang"], "title": "HiRef: Leveraging Hierarchical Ontology and Network Refinement for Robust Medication Recommendation", "comment": null, "summary": "Medication recommendation is a crucial task for assisting physicians in\nmaking timely decisions from longitudinal patient medical records. However,\nreal-world EHR data present significant challenges due to the presence of\nrarely observed medical entities and incomplete records that may not fully\ncapture the clinical ground truth. While data-driven models trained on\nlongitudinal Electronic Health Records often achieve strong empirical\nperformance, they struggle to generalize under missing or novel conditions,\nlargely due to their reliance on observed co-occurrence patterns. To address\nthese issues, we propose Hierarchical Ontology and Network Refinement for\nRobust Medication Recommendation (HiRef), a unified framework that combines two\ncomplementary structures: (i) the hierarchical semantics encoded in curated\nmedical ontologies, and (ii) refined co-occurrence patterns derived from\nreal-world EHRs. We embed ontology entities in hyperbolic space, which\nnaturally captures tree-like relationships and enables knowledge transfer\nthrough shared ancestors, thereby improving generalizability to unseen codes.\nTo further improve robustness, we introduce a prior-guided sparse\nregularization scheme that refines the EHR co-occurrence graph by suppressing\nspurious edges while preserving clinically meaningful associations. Our model\nachieves strong performance on EHR benchmarks (MIMIC-III and MIMIC-IV) and\nmaintains high accuracy under simulated unseen-code settings. Extensive\nexperiments with comprehensive ablation studies demonstrate HiRef's resilience\nto unseen medical codes, supported by in-depth analyses of the learned\nsparsified graph structure and medical code embeddings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faHiRef\u6846\u67b6\uff0c\u7ed3\u5408\u533b\u5b66\u672c\u4f53\u5c42\u6b21\u7ed3\u6784\u548c\u4f18\u5316\u7684\u5171\u73b0\u6a21\u5f0f\uff0c\u63d0\u5347\u836f\u7269\u63a8\u8350\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u4e2d\u7f55\u89c1\u5b9e\u4f53\u548c\u4e0d\u5b8c\u6574\u8bb0\u5f55\u5bfc\u81f4\u7684\u6a21\u578b\u6cdb\u5316\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u533b\u5b66\u672c\u4f53\u5c42\u6b21\u7ed3\u6784\uff08\u5d4c\u5165\u53cc\u66f2\u7a7a\u95f4\uff09\u548c\u4f18\u5316\u7684\u5171\u73b0\u56fe\uff08\u7a00\u758f\u6b63\u5219\u5316\uff09\uff0c\u63d0\u5347\u6a21\u578b\u5bf9\u672a\u89c1\u4ee3\u7801\u7684\u9002\u5e94\u80fd\u529b\u3002", "result": "\u5728MIMIC-III\u548cMIMIC-IV\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u5728\u6a21\u62df\u672a\u89c1\u4ee3\u7801\u573a\u666f\u4e0b\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "HiRef\u901a\u8fc7\u7ed3\u5408\u672c\u4f53\u77e5\u8bc6\u548c\u4f18\u5316\u5171\u73b0\u6a21\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u836f\u7269\u63a8\u8350\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2508.10429", "categories": ["cs.AI", "cs.CR", "cs.CV", "I.2.10; I.2.6"], "pdf": "https://arxiv.org/pdf/2508.10429", "abs": "https://arxiv.org/abs/2508.10429", "authors": ["Yi Dong", "Yusuke Muraoka", "Scott Shi", "Yi Zhang"], "title": "MM-Food-100K: A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance", "comment": "10 pages, 5 figures, 6 tables. The dataset is available at\n  https://huggingface.co/datasets/Codatta/MM-Food-100K", "summary": "We present MM-Food-100K, a public 100,000-sample multimodal food intelligence\ndataset with verifiable provenance. It is a curated approximately 10% open\nsubset of an original 1.2 million, quality-accepted corpus of food images\nannotated for a wide range of information (such as dish name, region of\ncreation). The corpus was collected over six weeks from over 87,000\ncontributors using the Codatta contribution model, which combines community\nsourcing with configurable AI-assisted quality checks; each submission is\nlinked to a wallet address in a secure off-chain ledger for traceability, with\na full on-chain protocol on the roadmap. We describe the schema, pipeline, and\nQA, and validate utility by fine-tuning large vision-language models (ChatGPT\n5, ChatGPT OSS, Qwen-Max) on image-based nutrition prediction. Fine-tuning\nyields consistent gains over out-of-box baselines across standard metrics; we\nreport results primarily on the MM-Food-100K subset. We release MM-Food-100K\nfor publicly free access and retain approximately 90% for potential commercial\naccess with revenue sharing to contributors.", "AI": {"tldr": "MM-Food-100K\u662f\u4e00\u4e2a\u5305\u542b10\u4e07\u6837\u672c\u7684\u591a\u6a21\u6001\u98df\u54c1\u6570\u636e\u96c6\uff0c\u5177\u6709\u53ef\u9a8c\u8bc1\u6765\u6e90\uff0c\u7528\u4e8e\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4ee5\u9884\u6d4b\u98df\u54c1\u8425\u517b\u4fe1\u606f\u3002", "motivation": "\u63d0\u4f9b\u9ad8\u8d28\u91cf\u3001\u53ef\u8ffd\u6eaf\u7684\u591a\u6a21\u6001\u98df\u54c1\u6570\u636e\u96c6\uff0c\u652f\u6301\u98df\u54c1\u667a\u80fd\u7814\u7a76\u3002", "method": "\u901a\u8fc7Codatta\u8d21\u732e\u6a21\u578b\u6536\u96c6\u6570\u636e\uff0c\u7ed3\u5408\u793e\u533a\u4f17\u5305\u548cAI\u8f85\u52a9\u8d28\u91cf\u68c0\u67e5\uff0c\u5e76\u9a8c\u8bc1\u6570\u636e\u5b9e\u7528\u6027\u3002", "result": "\u5fae\u8c03\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u8425\u517b\u9884\u6d4b\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "conclusion": "MM-Food-100K\u6570\u636e\u96c6\u516c\u5f00\u514d\u8d39\u63d0\u4f9b\uff0c\u652f\u6301\u98df\u54c1\u667a\u80fd\u7814\u7a76\uff0c\u540c\u65f6\u4fdd\u7559\u5546\u4e1a\u6f5c\u529b\u3002"}}
{"id": "2508.10433", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.10433", "abs": "https://arxiv.org/abs/2508.10433", "authors": ["Runqi Qiao", "Qiuna Tan", "Peiqing Yang", "Yanzi Wang", "Xiaowan Wang", "Enhui Wan", "Sitong Zhou", "Guanting Dong", "Yuchen Zeng", "Yida Xu", "Jie Wang", "Chong Sun", "Chen Li", "Honggang Zhang"], "title": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning", "comment": "Working in progress", "summary": "Multimodal Large Language Models (MLLMs) have demonstrated impressive\ncapabilities across various tasks, but still struggle with complex mathematical\nreasoning. Existing research primarily focuses on dataset construction and\nmethod optimization, often overlooking two critical aspects: comprehensive\nknowledge-driven design and model-centric data space modeling. In this paper,\nwe introduce We-Math 2.0, a unified system that integrates a structured\nmathematical knowledge system, model-centric data space modeling, and a\nreinforcement learning (RL)-based training paradigm to comprehensively enhance\nthe mathematical reasoning abilities of MLLMs. The key contributions of We-Math\n2.0 are fourfold: (1) MathBook Knowledge System: We construct a five-level\nhierarchical system encompassing 491 knowledge points and 1,819 fundamental\nprinciples. (2) MathBook-Standard & Pro: We develop MathBook-Standard, a\ndataset that ensures broad conceptual coverage and flexibility through dual\nexpansion. Additionally, we define a three-dimensional difficulty space and\ngenerate 7 progressive variants per problem to build MathBook-Pro, a\nchallenging dataset for robust training. (3) MathBook-RL: We propose a\ntwo-stage RL framework comprising: (i) Cold-Start Fine-tuning, which aligns the\nmodel with knowledge-oriented chain-of-thought reasoning; and (ii) Progressive\nAlignment RL, leveraging average-reward learning and dynamic data scheduling to\nachieve progressive alignment across difficulty levels. (4) MathBookEval: We\nintroduce a comprehensive benchmark covering all 491 knowledge points with\ndiverse reasoning step distributions. Experimental results show that\nMathBook-RL performs competitively with existing baselines on four widely-used\nbenchmarks and achieves strong results on MathBookEval, suggesting promising\ngeneralization in mathematical reasoning.", "AI": {"tldr": "We-Math 2.0\u662f\u4e00\u4e2a\u7edf\u4e00\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6570\u5b66\u77e5\u8bc6\u7cfb\u7edf\u3001\u6a21\u578b\u4e2d\u5fc3\u6570\u636e\u7a7a\u95f4\u5efa\u6a21\u548c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8303\u5f0f\uff0c\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5728\u590d\u6742\u6570\u5b66\u63a8\u7406\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u77e5\u8bc6\u9a71\u52a8\u7684\u8bbe\u8ba1\u548c\u6570\u636e\u7a7a\u95f4\u5efa\u6a21\u3002", "method": "\u6784\u5efa\u4e94\u7ea7\u6570\u5b66\u77e5\u8bc6\u7cfb\u7edf\uff0c\u5f00\u53d1\u6807\u51c6\u4e0e\u8fdb\u9636\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u5168\u9762\u8bc4\u4f30\u57fa\u51c6\u3002", "result": "MathBook-RL\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u793a\u51fa\u826f\u597d\u7684\u6570\u5b66\u63a8\u7406\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "We-Math 2.0\u901a\u8fc7\u7efc\u5408\u8bbe\u8ba1\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.10467", "categories": ["cs.AI", "cs.DL"], "pdf": "https://arxiv.org/pdf/2508.10467", "abs": "https://arxiv.org/abs/2508.10467", "authors": ["Xueli Pan", "Victor de Boer", "Jacco van Ossenbruggen"], "title": "FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs", "comment": "Accepted at 17th International Joint Conference on Knowledge\n  Discovery, Knowledge Engineering and Knowledge Management (IC3K)", "summary": "Question answering over Scholarly Knowledge Graphs (SKGs) remains a\nchallenging task due to the complexity of scholarly content and the intricate\nstructure of these graphs. Large Language Model (LLM) approaches could be used\nto translate natural language questions (NLQs) into SPARQL queries; however,\nthese LLM-based approaches struggle with SPARQL query generation due to limited\nexposure to SKG-specific content and the underlying schema. We identified two\nmain types of errors in the LLM-generated SPARQL queries: (i) structural\ninconsistencies, such as missing or redundant triples in the queries, and (ii)\nsemantic inaccuracies, where incorrect entities or properties are shown in the\nqueries despite a correct query structure. To address these issues, we propose\nFIRESPARQL, a modular framework that supports fine-tuned LLMs as a core\ncomponent, with optional context provided via retrieval-augmented generation\n(RAG) and a SPARQL query correction layer. We evaluate the framework on the\nSciQA Benchmark using various configurations (zero-shot, zero-shot with RAG,\none-shot, fine-tuning, and fine-tuning with RAG) and compare the performance\nwith baseline and state-of-the-art approaches. We measure query accuracy using\nBLEU and ROUGE metrics, and query result accuracy using relaxed exact\nmatch(RelaxedEM), with respect to the gold standards containing the NLQs,\nSPARQL queries, and the results of the queries. Experimental results\ndemonstrate that fine-tuning achieves the highest overall performance, reaching\n0.90 ROUGE-L for query accuracy and 0.85 RelaxedEM for result accuracy on the\ntest set.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faFIRESPARQL\u6846\u67b6\uff0c\u901a\u8fc7\u5fae\u8c03LLM\u548c\u7ed3\u5408RAG\u6280\u672f\uff0c\u89e3\u51b3SKG\u95ee\u7b54\u4e2dSPARQL\u67e5\u8be2\u751f\u6210\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u9519\u8bef\uff0c\u5b9e\u9a8c\u663e\u793a\u5fae\u8c03\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u89e3\u51b3LLM\u5728SKG\u95ee\u7b54\u4e2d\u751f\u6210SPARQL\u67e5\u8be2\u65f6\u56e0\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\u5bfc\u81f4\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u9519\u8bef\u3002", "method": "\u63d0\u51faFIRESPARQL\u6846\u67b6\uff0c\u7ed3\u5408\u5fae\u8c03LLM\u3001RAG\u6280\u672f\u548cSPARQL\u67e5\u8be2\u4fee\u6b63\u5c42\uff0c\u8bc4\u4f30\u591a\u79cd\u914d\u7f6e\uff08\u96f6\u6837\u672c\u3001\u5355\u6837\u672c\u3001\u5fae\u8c03\u7b49\uff09\u3002", "result": "\u5fae\u8c03\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\uff0cROUGE-L\u8fbe0.90\uff0cRelaxedEM\u8fbe0.85\u3002", "conclusion": "FIRESPARQL\u6846\u67b6\u6709\u6548\u63d0\u5347SKG\u95ee\u7b54\u4e2dSPARQL\u67e5\u8be2\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u7ed3\u679c\u8d28\u91cf\u3002"}}
{"id": "2508.10486", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10486", "abs": "https://arxiv.org/abs/2508.10486", "authors": ["Ivan Khai Ze Lim", "Ningyi Liao", "Yiming Yang", "Gerald Wei Yong Yip", "Siqiang Luo"], "title": "SEQ-GPT: LLM-assisted Spatial Query via Example", "comment": null, "summary": "Contemporary spatial services such as online maps predominantly rely on user\nqueries for location searches. However, the user experience is limited when\nperforming complex tasks, such as searching for a group of locations\nsimultaneously. In this study, we examine the extended scenario known as\nSpatial Exemplar Query (SEQ), where multiple relevant locations are jointly\nsearched based on user-specified examples. We introduce SEQ-GPT, a spatial\nquery system powered by Large Language Models (LLMs) towards more versatile SEQ\nsearch using natural language. The language capabilities of LLMs enable unique\ninteractive operations in the SEQ process, including asking users to clarify\nquery details and dynamically adjusting the search based on user feedback. We\nalso propose a tailored LLM adaptation pipeline that aligns natural language\nwith structured spatial data and queries through dialogue synthesis and\nmulti-model cooperation. SEQ-GPT offers an end-to-end demonstration for\nbroadening spatial search with realistic data and application scenarios.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSEQ-GPT\uff0c\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u67e5\u8be2\u7cfb\u7edf\uff0c\u7528\u4e8e\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u591a\u4f4d\u7f6e\u8054\u5408\u641c\u7d22\u4efb\u52a1\u3002", "motivation": "\u5f53\u524d\u7a7a\u95f4\u670d\u52a1\uff08\u5982\u5728\u7ebf\u5730\u56fe\uff09\u4e3b\u8981\u4f9d\u8d56\u7528\u6237\u67e5\u8be2\u8fdb\u884c\u4f4d\u7f6e\u641c\u7d22\uff0c\u4f46\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\uff08\u5982\u540c\u65f6\u641c\u7d22\u591a\u4e2a\u76f8\u5173\u4f4d\u7f6e\uff09\u65f6\u7528\u6237\u4f53\u9a8c\u53d7\u9650\u3002", "method": "\u5f15\u5165SEQ-GPT\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u80fd\u529b\uff0c\u652f\u6301\u4ea4\u4e92\u5f0f\u64cd\u4f5c\uff08\u5982\u6f84\u6e05\u67e5\u8be2\u7ec6\u8282\u548c\u52a8\u6001\u8c03\u6574\u641c\u7d22\uff09\u3002\u63d0\u51fa\u5b9a\u5236\u5316\u7684LLM\u9002\u5e94\u6d41\u7a0b\uff0c\u901a\u8fc7\u5bf9\u8bdd\u5408\u6210\u548c\u591a\u6a21\u578b\u534f\u4f5c\u5c06\u81ea\u7136\u8bed\u8a00\u4e0e\u7ed3\u6784\u5316\u7a7a\u95f4\u6570\u636e\u5bf9\u9f50\u3002", "result": "SEQ-GPT\u5c55\u793a\u4e86\u5728\u771f\u5b9e\u6570\u636e\u548c\u573a\u666f\u4e2d\u6269\u5c55\u7a7a\u95f4\u641c\u7d22\u7684\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "SEQ-GPT\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u591a\u6a21\u578b\u534f\u4f5c\uff0c\u63d0\u5347\u4e86\u590d\u6742\u7a7a\u95f4\u67e5\u8be2\u7684\u6548\u7387\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2508.10492", "categories": ["cs.AI", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.10492", "abs": "https://arxiv.org/abs/2508.10492", "authors": ["Shicheng Xu", "Xin Huang", "Zihao Wei", "Liang Pang", "Huawei Shen", "Xueqi Cheng"], "title": "Reverse Physician-AI Relationship: Full-process Clinical Diagnosis Driven by a Large Language Model", "comment": "39 pages", "summary": "Full-process clinical diagnosis in the real world encompasses the entire\ndiagnostic workflow that begins with only an ambiguous chief complaint. While\nartificial intelligence (AI), particularly large language models (LLMs), is\ntransforming clinical diagnosis, its role remains largely as an assistant to\nphysicians. This AI-assisted working pattern makes AI can only answer specific\nmedical questions at certain parts within the diagnostic process, but lack the\nability to drive the entire diagnostic process starting from an ambiguous\ncomplaint, which still relies heavily on human physicians. This gap limits AI's\nability to fully reduce physicians' workload and enhance diagnostic efficiency.\nTo address this, we propose a paradigm shift that reverses the relationship\nbetween physicians and AI: repositioning AI as the primary director, with\nphysicians serving as its assistants. So we present DxDirector-7B, an LLM\nendowed with advanced deep thinking capabilities, enabling it to drive the\nfull-process diagnosis with minimal physician involvement. Furthermore,\nDxDirector-7B establishes a robust accountability framework for misdiagnoses,\ndelineating responsibility between AI and human physicians. In evaluations\nacross rare, complex, and real-world cases under full-process diagnosis\nsetting, DxDirector-7B not only achieves significant superior diagnostic\naccuracy but also substantially reduces physician workload than\nstate-of-the-art medical LLMs as well as general-purpose LLMs. Fine-grained\nanalyses across multiple clinical departments and tasks validate its efficacy,\nwith expert evaluations indicating its potential to serve as a viable\nsubstitute for medical specialists. These findings mark a new era where AI,\ntraditionally a physicians' assistant, now drives the entire diagnostic process\nto drastically reduce physicians' workload, indicating an efficient and\naccurate diagnostic solution.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDxDirector-7B\uff0c\u4e00\u79cd\u80fd\u591f\u4e3b\u5bfc\u5168\u6d41\u7a0b\u4e34\u5e8a\u8bca\u65ad\u7684AI\u6a21\u578b\uff0c\u663e\u8457\u51cf\u5c11\u533b\u751f\u5de5\u4f5c\u91cf\u5e76\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524dAI\u5728\u4e34\u5e8a\u8bca\u65ad\u4e2d\u4ec5\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\uff0c\u65e0\u6cd5\u4e3b\u5bfc\u4ece\u6a21\u7cca\u4e3b\u8bc9\u5f00\u59cb\u7684\u5b8c\u6574\u8bca\u65ad\u6d41\u7a0b\uff0c\u9650\u5236\u4e86\u5176\u51cf\u8f7b\u533b\u751f\u8d1f\u62c5\u548c\u63d0\u5347\u6548\u7387\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51faDxDirector-7B\uff0c\u4e00\u79cd\u5177\u5907\u6df1\u5ea6\u601d\u8003\u80fd\u529b\u7684LLM\uff0c\u80fd\u591f\u4e3b\u5bfc\u5168\u6d41\u7a0b\u8bca\u65ad\u5e76\u5efa\u7acb\u8d23\u4efb\u6846\u67b6\u3002", "result": "\u5728\u7f55\u89c1\u3001\u590d\u6742\u548c\u771f\u5b9e\u75c5\u4f8b\u4e2d\uff0cDxDirector-7B\u7684\u8bca\u65ad\u51c6\u786e\u6027\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u533b\u5b66LLM\uff0c\u5e76\u5927\u5e45\u51cf\u5c11\u533b\u751f\u5de5\u4f5c\u91cf\u3002", "conclusion": "DxDirector-7B\u6807\u5fd7\u7740AI\u4ece\u8f85\u52a9\u5de5\u5177\u8f6c\u53d8\u4e3a\u8bca\u65ad\u4e3b\u5bfc\u8005\uff0c\u4e3a\u9ad8\u6548\u3001\u51c6\u786e\u7684\u8bca\u65ad\u63d0\u4f9b\u4e86\u65b0\u65b9\u6848\u3002"}}
{"id": "2508.10501", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.10501", "abs": "https://arxiv.org/abs/2508.10501", "authors": ["Yushi Feng", "Junye Du", "Yingying Hong", "Qifan Wang", "Lequan Yu"], "title": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning", "comment": null, "summary": "Existing tool-augmented agentic systems are limited in the real world by (i)\nblack-box reasoning steps that undermine trust of decision-making and pose\nsafety risks, (ii) poor multimodal integration, which is inherently critical\nfor healthcare tasks, and (iii) rigid and computationally inefficient agentic\npipelines. We introduce PASS (Probabilistic Agentic Supernet Sampling), the\nfirst multimodal framework to address these challenges in the context of Chest\nX-Ray (CXR) reasoning. PASS adaptively samples agentic workflows over a\nmulti-tool graph, yielding decision paths annotated with interpretable\nprobabilities. Given the complex CXR reasoning task with multimodal medical\ndata, PASS leverages its learned task-conditioned distribution over the agentic\nsupernet. Thus, it adaptively selects the most suitable tool at each supernet\nlayer, offering probability-annotated trajectories for post-hoc audits and\ndirectly enhancing medical AI safety. PASS also continuously compresses salient\nfindings into an evolving personalized memory, while dynamically deciding\nwhether to deepen its reasoning path or invoke an early exit for efficiency. To\noptimize a Pareto frontier balancing performance and cost, we design a novel\nthree-stage training procedure, including expert knowledge warm-up, contrastive\npath-ranking, and cost-aware reinforcement learning. To facilitate rigorous\nevaluation, we introduce CAB-E, a comprehensive benchmark for multi-step,\nsafety-critical, free-form CXR reasoning. Experiments across various benchmarks\nvalidate that PASS significantly outperforms strong baselines in multiple\nmetrics (e.g., accuracy, AUC, LLM-J.) while balancing computational costs,\npushing a new paradigm shift towards interpretable, adaptive, and multimodal\nmedical agentic systems.", "AI": {"tldr": "PASS\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u6846\u67b6\uff0c\u901a\u8fc7\u6982\u7387\u91c7\u6837\u548c\u81ea\u9002\u5e94\u5de5\u5177\u9009\u62e9\u89e3\u51b3\u533b\u7597AI\u4e2d\u7684\u4fe1\u4efb\u3001\u5b89\u5168\u6027\u548c\u6548\u7387\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u589e\u5f3a\u7684\u4ee3\u7406\u7cfb\u7edf\u5b58\u5728\u9ed1\u76d2\u63a8\u7406\u3001\u591a\u6a21\u6001\u6574\u5408\u4e0d\u8db3\u548c\u6548\u7387\u4f4e\u4e0b\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u3002", "method": "PASS\u901a\u8fc7\u591a\u5de5\u5177\u56fe\u91c7\u6837\u4ee3\u7406\u5de5\u4f5c\u6d41\uff0c\u7ed3\u5408\u4efb\u52a1\u6761\u4ef6\u5206\u5e03\u548c\u4e2a\u6027\u5316\u8bb0\u5fc6\uff0c\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u4f18\u5316\u6027\u80fd\u4e0e\u6210\u672c\u5e73\u8861\u3002", "result": "PASS\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0c\u540c\u65f6\u5e73\u8861\u8ba1\u7b97\u6210\u672c\uff0c\u63a8\u52a8\u53ef\u89e3\u91ca\u3001\u81ea\u9002\u5e94\u548c\u591a\u6a21\u6001\u533b\u7597\u4ee3\u7406\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "conclusion": "PASS\u4e3a\u533b\u7597AI\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u3001\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.10530", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.10530", "abs": "https://arxiv.org/abs/2508.10530", "authors": ["Zetian Sun", "Dongfang Li", "Baotian Hu"], "title": "Diversity First, Quality Later: A Two-Stage Assumption for Language Model Alignment", "comment": null, "summary": "The alignment of language models (LMs) with human preferences is critical for\nbuilding reliable AI systems. The problem is typically framed as optimizing an\nLM policy to maximize the expected reward that reflects human preferences.\nRecently, Direct Preference Optimization (DPO) was proposed as a LM alignment\nmethod that directly optimize the policy from static preference data, and\nfurther improved by incorporating on-policy sampling (i.e., preference\ncandidates generated during the training loop) for better LM alignment.\nHowever, we show on-policy data is not always optimal, with systematic\neffectiveness difference emerging between static and on-policy preference\ncandidates. For example, on-policy data can result in a 3$\\times$ effectiveness\ncompared with static data for Llama-3, and a 0.4$\\times$ effectiveness for\nZephyr. To explain the phenomenon, we propose the alignment stage assumption,\nwhich divides the alignment process into two distinct stages: the preference\ninjection stage, which benefits from diverse data, and the preference\nfine-tuning stage, which favors high-quality data. Through theoretical and\nempirical analysis, we characterize these stages and propose an effective\nalgorithm to identify the boundaries between them. We perform experiments on 5\nmodels (Llama, Zephyr, Phi-2, Qwen, Pythia) and 2 alignment methods (DPO,\nSLiC-HF) to show the generalizability of alignment stage assumption and\nboundary measurement.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u8bed\u8a00\u6a21\u578b\uff08LM\uff09\u5bf9\u9f50\u4eba\u7c7b\u504f\u597d\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5bf9\u9f50\u9636\u6bb5\u5047\u8bbe\uff0c\u5e76\u5206\u6790\u4e86\u9759\u6001\u548c\u52a8\u6001\u504f\u597d\u6570\u636e\u7684\u6709\u6548\u6027\u5dee\u5f02\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u5bf9\u6784\u5efa\u53ef\u9760AI\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u5982DPO\u867d\u6709\u6548\uff0c\u4f46\u52a8\u6001\u504f\u597d\u6570\u636e\u7684\u6548\u679c\u56e0\u6a21\u578b\u800c\u5f02\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u5bf9\u9f50\u9636\u6bb5\u5047\u8bbe\uff0c\u5c06\u5bf9\u9f50\u5206\u4e3a\u504f\u597d\u6ce8\u5165\u548c\u504f\u597d\u5fae\u8c03\u4e24\u4e2a\u9636\u6bb5\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u5206\u6790\u5176\u8fb9\u754c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u52a8\u6001\u6570\u636e\u5bf9Llama-3\u6548\u679c\u63d0\u53473\u500d\uff0c\u4f46\u5bf9Zephyr\u6548\u679c\u964d\u4f4e0.4\u500d\u3002\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u6709\u6548\u8bc6\u522b\u9636\u6bb5\u8fb9\u754c\u3002", "conclusion": "\u5bf9\u9f50\u9636\u6bb5\u5047\u8bbe\u5177\u6709\u666e\u9002\u6027\uff0c\u4e3aLM\u5bf9\u9f50\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2508.10539", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.10539", "abs": "https://arxiv.org/abs/2508.10539", "authors": ["Zetian Sun", "Dongfang Li", "Baotian Hu", "Min Zhang"], "title": "Improving Value-based Process Verifier via Low-Cost Variance Reduction", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable success in a wide range\nof tasks. However, their reasoning capabilities, particularly in complex\ndomains like mathematics, remain a significant challenge. Value-based process\nverifiers, which estimate the probability of a partial reasoning chain leading\nto a correct solution, are a promising approach for improving reasoning.\nNevertheless, their effectiveness is often hindered by estimation error in\ntheir training annotations, a consequence of the limited number of Monte Carlo\n(MC) samples feasible due to the high cost of LLM inference. In this paper, we\nidentify that the estimation error primarily arises from high variance rather\nthan bias, and the MC estimator is a Minimum Variance Unbiased Estimator\n(MVUE). To address the problem, we propose the \\textsc{Com}pound \\textsc{M}onte\n\\textsc{C}arlo \\textsc{S}ampling (ComMCS) method, which constructs an unbiased\nestimator by linearly combining the MC estimators from the current and\nsubsequent steps. Theoretically, we show that our method leads to a predictable\nreduction in variance, while maintaining an unbiased estimation without\nadditional LLM inference cost. We also perform empirical experiments on the\nMATH-500 and GSM8K benchmarks to demonstrate the effectiveness of our method.\nNotably, ComMCS outperforms regression-based optimization method by 2.8 points,\nthe non-variance-reduced baseline by 2.2 points on MATH-500 on Best-of-32\nsampling experiment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faComMCS\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u5f53\u524d\u548c\u540e\u7eed\u6b65\u9aa4\u7684\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u5668\uff0c\u51cf\u5c11\u65b9\u5dee\u5e76\u4fdd\u6301\u65e0\u504f\u4f30\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u9886\u57df\uff08\u5982\u6570\u5b66\uff09\u7684\u63a8\u7406\u80fd\u529b\u4ecd\u6709\u6311\u6218\uff0c\u73b0\u6709\u57fa\u4e8e\u503c\u7684\u9a8c\u8bc1\u65b9\u6cd5\u56e0\u8499\u7279\u5361\u6d1b\u6837\u672c\u6709\u9650\u5bfc\u81f4\u4f30\u8ba1\u8bef\u5dee\u3002", "method": "\u63d0\u51faComMCS\u65b9\u6cd5\uff0c\u7ebf\u6027\u7ed3\u5408\u5f53\u524d\u548c\u540e\u7eed\u6b65\u9aa4\u7684\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u5668\uff0c\u51cf\u5c11\u65b9\u5dee\u4e14\u4e0d\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u3002", "result": "\u5728MATH-500\u548cGSM8K\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cComMCS\u4f18\u4e8e\u56de\u5f52\u4f18\u5316\u65b9\u6cd52.8\u5206\uff0c\u4f18\u4e8e\u65e0\u65b9\u5dee\u7f29\u51cf\u57fa\u7ebf2.2\u5206\u3002", "conclusion": "ComMCS\u901a\u8fc7\u6709\u6548\u51cf\u5c11\u65b9\u5dee\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2508.10599", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10599", "abs": "https://arxiv.org/abs/2508.10599", "authors": ["Xinyan Jiang", "Lin Zhang", "Jiayi Zhang", "Qingsong Yang", "Guimin Hu", "Di Wang", "Lijie Hu"], "title": "MSRS: Adaptive Multi-Subspace Representation Steering for Attribute Alignment in Large Language Models", "comment": null, "summary": "Activation steering offers a promising approach to controlling the behavior\nof Large Language Models by directly manipulating their internal activations.\nHowever, most existing methods struggle to jointly steer multiple attributes,\noften resulting in interference and undesirable trade-offs. To address this\nchallenge, we propose Multi-Subspace Representation Steering (MSRS), a novel\nframework for effective multi-attribute steering via subspace representation\nfine-tuning. MSRS reduces inter-attribute interference by allocating orthogonal\nsubspaces to each attribute, isolating their influence within the model's\nrepresentation space. MSRS also incorporates a hybrid subspace composition\nstrategy: it combines attribute-specific subspaces for unique steering\ndirections with a shared subspace for common steering directions. A dynamic\nweighting function learns to efficiently integrate these components for precise\ncontrol. During inference, MSRS introduces a token-level steering mechanism\nthat dynamically identifies and intervenes on the most semantically relevant\ntokens, enabling fine-grained behavioral modulation. Experimental results show\nthat MSRS significantly reduces attribute conflicts, surpasses existing methods\nacross a range of attributes, and generalizes effectively to diverse downstream\ntasks.", "AI": {"tldr": "MSRS\u662f\u4e00\u79cd\u901a\u8fc7\u5b50\u7a7a\u95f4\u8868\u793a\u5fae\u8c03\u5b9e\u73b0\u591a\u5c5e\u6027\u63a7\u5236\u7684\u65b0\u6846\u67b6\uff0c\u51cf\u5c11\u5c5e\u6027\u95f4\u5e72\u6270\u5e76\u63d0\u5347\u63a7\u5236\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u63a7\u5236\u591a\u4e2a\u5c5e\u6027\uff0c\u5e38\u5bfc\u81f4\u5e72\u6270\u548c\u4e0d\u826f\u6743\u8861\uff0c\u9700\u6539\u8fdb\u3002", "method": "MSRS\u5206\u914d\u6b63\u4ea4\u5b50\u7a7a\u95f4\u9694\u79bb\u5c5e\u6027\u5f71\u54cd\uff0c\u7ed3\u5408\u5171\u4eab\u5b50\u7a7a\u95f4\u548c\u52a8\u6001\u6743\u91cd\u51fd\u6570\uff0c\u5e76\u5f15\u5165\u4ee4\u724c\u7ea7\u5e72\u9884\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMSRS\u663e\u8457\u51cf\u5c11\u5c5e\u6027\u51b2\u7a81\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u591a\u6837\u4e0b\u6e38\u4efb\u52a1\u3002", "conclusion": "MSRS\u4e3a\u591a\u5c5e\u6027\u63a7\u5236\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.10669", "categories": ["cs.AI", "cs.IR", "H.3.3; I.2.7; H.2.8"], "pdf": "https://arxiv.org/pdf/2508.10669", "abs": "https://arxiv.org/abs/2508.10669", "authors": ["Zhenye Yang", "Jinpeng Chen", "Huan Li", "Xiongnan Jin", "Xuanyang Li", "Junwei Zhang", "Hongbo Gao", "Kaimin Wei", "Senzhang Wang"], "title": "STEP: Stepwise Curriculum Learning for Context-Knowledge Fusion in Conversational Recommendation", "comment": "10 pages; 4 figures; 6 tables; code available at\n  https://github.com/Alex-bupt/STEP", "summary": "Conversational recommender systems (CRSs) aim to proactively capture user\npreferences through natural language dialogue and recommend high-quality items.\nTo achieve this, CRS gathers user preferences via a dialog module and builds\nuser profiles through a recommendation module to generate appropriate\nrecommendations. However, existing CRS faces challenges in capturing the deep\nsemantics of user preferences and dialogue context. In particular, the\nefficient integration of external knowledge graph (KG) information into\ndialogue generation and recommendation remains a pressing issue. Traditional\napproaches typically combine KG information directly with dialogue content,\nwhich often struggles with complex semantic relationships, resulting in\nrecommendations that may not align with user expectations.\n  To address these challenges, we introduce STEP, a conversational recommender\ncentered on pre-trained language models that combines curriculum-guided\ncontext-knowledge fusion with lightweight task-specific prompt tuning. At its\nheart, an F-Former progressively aligns the dialogue context with\nknowledge-graph entities through a three-stage curriculum, thus resolving\nfine-grained semantic mismatches. The fused representation is then injected\ninto the frozen language model via two minimal yet adaptive prefix prompts: a\nconversation prefix that steers response generation toward user intent and a\nrecommendation prefix that biases item ranking toward knowledge-consistent\ncandidates. This dual-prompt scheme allows the model to share cross-task\nsemantics while respecting the distinct objectives of dialogue and\nrecommendation. Experimental results show that STEP outperforms mainstream\nmethods in the precision of recommendation and dialogue quality in two public\ndatasets.", "AI": {"tldr": "STEP\u662f\u4e00\u79cd\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bfe\u7a0b\u5f15\u5bfc\u7684\u4e0a\u4e0b\u6587-\u77e5\u8bc6\u878d\u5408\u548c\u8f7b\u91cf\u7ea7\u4efb\u52a1\u7279\u5b9a\u63d0\u793a\u8c03\u4f18\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7cfb\u7edf\u5728\u6355\u6349\u7528\u6237\u504f\u597d\u548c\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u6df1\u5c42\u8bed\u4e49\u65b9\u9762\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u96be\u4ee5\u6709\u6548\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u56fe\u8c31\u4fe1\u606f\u5230\u5bf9\u8bdd\u751f\u6210\u548c\u63a8\u8350\u4e2d\uff0c\u5bfc\u81f4\u63a8\u8350\u7ed3\u679c\u4e0e\u7528\u6237\u671f\u671b\u4e0d\u7b26\u3002", "method": "STEP\u91c7\u7528\u4e09\u9636\u6bb5\u8bfe\u7a0b\u9010\u6b65\u5bf9\u9f50\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u4e0e\u77e5\u8bc6\u56fe\u8c31\u5b9e\u4f53\uff0c\u5e76\u901a\u8fc7\u53cc\u63d0\u793a\u65b9\u6848\uff08\u5bf9\u8bdd\u524d\u7f00\u548c\u63a8\u8350\u524d\u7f00\uff09\u5c06\u878d\u5408\u8868\u793a\u6ce8\u5165\u51bb\u7ed3\u7684\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSTEP\u5728\u4e24\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u63a8\u8350\u7cbe\u5ea6\u548c\u5bf9\u8bdd\u8d28\u91cf\u4f18\u4e8e\u4e3b\u6d41\u65b9\u6cd5\u3002", "conclusion": "STEP\u901a\u8fc7\u4e0a\u4e0b\u6587-\u77e5\u8bc6\u878d\u5408\u548c\u53cc\u63d0\u793a\u8c03\u4f18\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2508.10703", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10703", "abs": "https://arxiv.org/abs/2508.10703", "authors": ["Yiping Song", "Jiaoyan Chen", "Renate A. Schmidt"], "title": "GenOM: Ontology Matching with Description Generation and Large Language Model", "comment": null, "summary": "Ontology matching (OM) plays an essential role in enabling semantic\ninteroperability and integration across heterogeneous knowledge sources,\nparticularly in the biomedical domain which contains numerous complex concepts\nrelated to diseases and pharmaceuticals. This paper introduces GenOM, a large\nlanguage model (LLM)-based ontology alignment framework, which enriches the\nsemantic representations of ontology concepts via generating textual\ndefinitions, retrieves alignment candidates with an embedding model, and\nincorporates exact matching-based tools to improve precision. Extensive\nexperiments conducted on the OAEI Bio-ML track demonstrate that GenOM can often\nachieve competitive performance, surpassing many baselines including\ntraditional OM systems and recent LLM-based methods. Further ablation studies\nconfirm the effectiveness of semantic enrichment and few-shot prompting,\nhighlighting the framework's robustness and adaptability.", "AI": {"tldr": "GenOM\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u672c\u4f53\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u6587\u672c\u5b9a\u4e49\u4e30\u5bcc\u672c\u4f53\u6982\u5ff5\u7684\u8bed\u4e49\u8868\u793a\uff0c\u7ed3\u5408\u5d4c\u5165\u6a21\u578b\u548c\u7cbe\u786e\u5339\u914d\u5de5\u5177\u63d0\u5347\u6027\u80fd\u3002\u5728OAEI Bio-ML\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u8fd1\u671fLLM\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u751f\u7269\u533b\u5b66\u9886\u57df\u4e2d\u5f02\u6784\u77e5\u8bc6\u6e90\u7684\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\u548c\u6574\u5408\u95ee\u9898\uff0c\u56e0\u8be5\u9886\u57df\u5305\u542b\u5927\u91cf\u590d\u6742\u6982\u5ff5\uff08\u5982\u75be\u75c5\u548c\u836f\u7269\uff09\u3002", "method": "1. \u751f\u6210\u6587\u672c\u5b9a\u4e49\u4ee5\u4e30\u5bcc\u8bed\u4e49\u8868\u793a\uff1b2. \u4f7f\u7528\u5d4c\u5165\u6a21\u578b\u68c0\u7d22\u5bf9\u9f50\u5019\u9009\uff1b3. \u7ed3\u5408\u7cbe\u786e\u5339\u914d\u5de5\u5177\u63d0\u9ad8\u7cbe\u5ea6\u3002", "result": "\u5728OAEI Bio-ML\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u4f20\u7edf\u672c\u4f53\u5339\u914d\u7cfb\u7edf\u548c\u8fd1\u671fLLM\u65b9\u6cd5\u3002", "conclusion": "GenOM\u6846\u67b6\u901a\u8fc7\u8bed\u4e49\u589e\u5f3a\u548c\u5c11\u6837\u672c\u63d0\u793a\u5c55\u793a\u4e86\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\uff0c\u4e3a\u751f\u7269\u533b\u5b66\u672c\u4f53\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.10745", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.MA", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.10745", "abs": "https://arxiv.org/abs/2508.10745", "authors": ["Sayan Nag", "K J Joseph", "Koustava Goswami", "Vlad I Morariu", "Balaji Vasan Srinivasan"], "title": "Agentic Design Review System", "comment": null, "summary": "Evaluating graphic designs involves assessing it from multiple facets like\nalignment, composition, aesthetics and color choices. Evaluating designs in a\nholistic way involves aggregating feedback from individual expert reviewers.\nTowards this, we propose an Agentic Design Review System (AgenticDRS), where\nmultiple agents collaboratively analyze a design, orchestrated by a meta-agent.\nA novel in-context exemplar selection approach based on graph matching and a\nunique prompt expansion method plays central role towards making each agent\ndesign aware. Towards evaluating this framework, we propose DRS-BENCH\nbenchmark. Thorough experimental evaluation against state-of-the-art baselines\nadapted to the problem setup, backed-up with critical ablation experiments\nbrings out the efficacy of Agentic-DRS in evaluating graphic designs and\ngenerating actionable feedback. We hope that this work will attract attention\nto this pragmatic, yet under-explored research direction.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u8bbe\u8ba1\u8bc4\u5ba1\u7cfb\u7edf\uff08AgenticDRS\uff09\uff0c\u901a\u8fc7\u56fe\u5339\u914d\u548c\u63d0\u793a\u6269\u5c55\u65b9\u6cd5\u63d0\u5347\u8bbe\u8ba1\u8bc4\u4f30\u6548\u679c\uff0c\u5e76\u5efa\u7acb\u4e86DRS-BENCH\u57fa\u51c6\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8bbe\u8ba1\u8bc4\u4f30\u9700\u7efc\u5408\u8003\u8651\u591a\u4e2a\u65b9\u9762\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51faAgenticDRS\u7cfb\u7edf\uff0c\u5229\u7528\u56fe\u5339\u914d\u548c\u63d0\u793a\u6269\u5c55\u65b9\u6cd5\u4f7f\u667a\u80fd\u4f53\u5177\u5907\u8bbe\u8ba1\u611f\u77e5\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5143\u667a\u80fd\u4f53\u534f\u8c03\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAgenticDRS\u5728\u8bc4\u4f30\u56fe\u5f62\u8bbe\u8ba1\u548c\u751f\u6210\u53cd\u9988\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "AgenticDRS\u4e3a\u8bbe\u8ba1\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u547c\u5401\u5173\u6ce8\u8fd9\u4e00\u5b9e\u7528\u4f46\u672a\u5145\u5206\u63a2\u7d22\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.10747", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.10747", "abs": "https://arxiv.org/abs/2508.10747", "authors": ["Sangwoo Jeon", "Juchul Shin", "Gyeong-Tae Kim", "YeonJe Cho", "Seongwoo Kim"], "title": "Scaling Up without Fading Out: Goal-Aware Sparse GNN for RL-based Generalized Planning", "comment": "16 pages, 10 figures", "summary": "Generalized planning using deep reinforcement learning (RL) combined with\ngraph neural networks (GNNs) has shown promising results in various symbolic\nplanning domains described by PDDL. However, existing approaches typically\nrepresent planning states as fully connected graphs, leading to a combinatorial\nexplosion in edge information and substantial sparsity as problem scales grow,\nespecially evident in large grid-based environments. This dense representation\nresults in diluted node-level information, exponentially increases memory\nrequirements, and ultimately makes learning infeasible for larger-scale\nproblems. To address these challenges, we propose a sparse, goal-aware GNN\nrepresentation that selectively encodes relevant local relationships and\nexplicitly integrates spatial features related to the goal. We validate our\napproach by designing novel drone mission scenarios based on PDDL within a grid\nworld, effectively simulating realistic mission execution environments. Our\nexperimental results demonstrate that our method scales effectively to larger\ngrid sizes previously infeasible with dense graph representations and\nsubstantially improves policy generalization and success rates. Our findings\nprovide a practical foundation for addressing realistic, large-scale\ngeneralized planning tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7a00\u758f\u3001\u76ee\u6807\u611f\u77e5\u7684GNN\u8868\u793a\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5bc6\u96c6\u56fe\u8868\u793a\u5728\u5927\u89c4\u6a21\u7f51\u683c\u73af\u5883\u4e2d\u7684\u7ec4\u5408\u7206\u70b8\u548c\u4fe1\u606f\u7a00\u758f\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728PDDL\u63cf\u8ff0\u7684\u7b26\u53f7\u89c4\u5212\u9886\u57df\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u7f51\u683c\u73af\u5883\u4e2d\u56e0\u5bc6\u96c6\u56fe\u8868\u793a\u5bfc\u81f4\u4fe1\u606f\u7a00\u758f\u548c\u5185\u5b58\u9700\u6c42\u6fc0\u589e\uff0c\u96be\u4ee5\u5b66\u4e60\u3002", "method": "\u91c7\u7528\u7a00\u758f\u3001\u76ee\u6807\u611f\u77e5\u7684GNN\u8868\u793a\uff0c\u9009\u62e9\u6027\u7f16\u7801\u5c40\u90e8\u76f8\u5173\u5173\u7cfb\u5e76\u663e\u5f0f\u6574\u5408\u76ee\u6807\u76f8\u5173\u7684\u7a7a\u95f4\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u6269\u5c55\u5230\u66f4\u5927\u7f51\u683c\u89c4\u6a21\uff0c\u663e\u8457\u63d0\u5347\u7b56\u7565\u6cdb\u5316\u80fd\u529b\u548c\u6210\u529f\u7387\u3002", "conclusion": "\u4e3a\u5904\u7406\u73b0\u5b9e\u4e2d\u7684\u5927\u89c4\u6a21\u5e7f\u4e49\u89c4\u5212\u4efb\u52a1\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u3002"}}
{"id": "2508.10769", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.10769", "abs": "https://arxiv.org/abs/2508.10769", "authors": ["Zhiqi Shen", "Shaojing Fan", "Danni Xu", "Terence Sim", "Mohan Kankanhalli"], "title": "Modeling Human Responses to Multimodal AI Content", "comment": null, "summary": "As AI-generated content becomes widespread, so does the risk of\nmisinformation. While prior research has primarily focused on identifying\nwhether content is authentic, much less is known about how such content\ninfluences human perception and behavior. In domains like trading or the stock\nmarket, predicting how people react (e.g., whether a news post will go viral),\ncan be more critical than verifying its factual accuracy. To address this, we\ntake a human-centered approach and introduce the MhAIM Dataset, which contains\n154,552 online posts (111,153 of them AI-generated), enabling large-scale\nanalysis of how people respond to AI-generated content. Our human study reveals\nthat people are better at identifying AI content when posts include both text\nand visuals, particularly when inconsistencies exist between the two. We\npropose three new metrics: trustworthiness, impact, and openness, to quantify\nhow users judge and engage with online content. We present T-Lens, an LLM-based\nagent system designed to answer user queries by incorporating predicted human\nresponses to multimodal information. At its core is HR-MCP (Human Response\nModel Context Protocol), built on the standardized Model Context Protocol\n(MCP), enabling seamless integration with any LLM. This integration allows\nT-Lens to better align with human reactions, enhancing both interpretability\nand interaction capabilities. Our work provides empirical insights and\npractical tools to equip LLMs with human-awareness capabilities. By\nhighlighting the complex interplay among AI, human cognition, and information\nreception, our findings suggest actionable strategies for mitigating the risks\nof AI-driven misinformation.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86AI\u751f\u6210\u5185\u5bb9\u5bf9\u4eba\u7c7b\u884c\u4e3a\u548c\u611f\u77e5\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86MhAIM\u6570\u636e\u96c6\u548cT-Lens\u7cfb\u7edf\uff0c\u4ee5\u91cf\u5316\u7528\u6237\u5bf9\u5185\u5bb9\u7684\u53cd\u5e94\uff0c\u5e76\u589e\u5f3aLLM\u7684\u4eba\u7c7b\u611f\u77e5\u80fd\u529b\u3002", "motivation": "\u968f\u7740AI\u751f\u6210\u5185\u5bb9\u7684\u666e\u53ca\uff0c\u5176\u5bf9\u4eba\u7c7b\u884c\u4e3a\u548c\u611f\u77e5\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\uff0c\u5c24\u5176\u662f\u5728\u91d1\u878d\u7b49\u9886\u57df\uff0c\u9884\u6d4b\u7528\u6237\u53cd\u5e94\u6bd4\u9a8c\u8bc1\u5185\u5bb9\u771f\u5b9e\u6027\u66f4\u4e3a\u91cd\u8981\u3002", "method": "\u901a\u8fc7MhAIM\u6570\u636e\u96c6\uff08\u5305\u542b154,552\u4e2a\u5728\u7ebf\u5e16\u5b50\uff09\u5206\u6790\u4eba\u7c7b\u5bf9AI\u5185\u5bb9\u7684\u53cd\u5e94\uff0c\u63d0\u51fa\u4fe1\u4efb\u5ea6\u3001\u5f71\u54cd\u529b\u548c\u5f00\u653e\u6027\u4e09\u4e2a\u65b0\u6307\u6807\uff0c\u5e76\u5f00\u53d1T-Lens\u7cfb\u7edf\uff08\u57fa\u4e8eHR-MCP\u534f\u8bae\uff09\u9884\u6d4b\u7528\u6237\u53cd\u5e94\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4eba\u7c7b\u5728\u6587\u672c\u548c\u89c6\u89c9\u4e0d\u4e00\u81f4\u65f6\u66f4\u5bb9\u6613\u8bc6\u522bAI\u5185\u5bb9\uff1bT-Lens\u7cfb\u7edf\u80fd\u66f4\u597d\u5730\u7ed3\u5408\u4eba\u7c7b\u53cd\u5e94\uff0c\u63d0\u5347\u4ea4\u4e92\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u4e3aLLM\u63d0\u4f9b\u4e86\u4eba\u7c7b\u611f\u77e5\u80fd\u529b\u7684\u5de5\u5177\u548c\u7b56\u7565\uff0c\u6709\u52a9\u4e8e\u7f13\u89e3AI\u9a71\u52a8\u7684\u9519\u8bef\u4fe1\u606f\u98ce\u9669\u3002"}}
{"id": "2508.10777", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10777", "abs": "https://arxiv.org/abs/2508.10777", "authors": ["Ma\u00ebl Jullien", "Marco Valentino", "Andr\u00e9 Freitas"], "title": "The Knowledge-Reasoning Dissociation: Fundamental Limitations of LLMs in Clinical Natural Language Inference", "comment": "19 pages", "summary": "Large language models are often assumed to acquire increasingly structured,\ngeneralizable internal representations simply by scaling data and parameters.\nWe interrogate this assumption by introducing a Clinical Trial Natural Language\nInference benchmark comprising four reasoning families, Causal Attribution,\nCompositional Grounding, Epistemic Verification, and Risk State Abstraction.\nEach item is paired with a targeted Ground Knowledge and Meta-Level Reasoning\nVerification (GKMRV) probe, allowing us to dissociate failures of factual\naccess from failures of inference. We evaluate six contemporary LLMs under both\ndirect and chain of thought prompting.\n  Models achieve near-ceiling GKMRV accuracy (mean accuracy 0.918) yet perform\npoorly on the main reasoning tasks (mean accuracy 0.25). Despite low accuracy,\noutput inferences are highly consistent across samples (mean 0.87), indicating\na systematic application of underlying heuristics and shortcuts.\n  These results reveal fundamental structural and representational limitations:\ncurrent LLMs often possess the relevant clinical knowledge but lack the\nstructured, composable internal representations needed to deploy it reliably\n(e.g., integrating constraints, weighing evidence, or simulating\ncounterfactuals). Decoupling knowledge from reasoning with GKMRV makes this\ndissociation explicit and measurable, providing an effective framework for\nprobing the reliability of LLMs in high-stakes domains.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u4e34\u5e8a\u8bd5\u9a8c\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u867d\u80fd\u51c6\u786e\u83b7\u53d6\u77e5\u8bc6\uff0c\u4f46\u5728\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u63ed\u793a\u4e86\u5176\u5185\u90e8\u8868\u5f81\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u63a2\u8ba8\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u901a\u8fc7\u6570\u636e\u4e0e\u53c2\u6570\u6269\u5c55\u83b7\u5f97\u7ed3\u6784\u5316\u3001\u53ef\u6cdb\u5316\u7684\u5185\u90e8\u8868\u5f81\u3002", "method": "\u5f15\u5165\u4e34\u5e8a\u8bd5\u9a8c\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u57fa\u51c6\uff08\u542b\u56db\u79cd\u63a8\u7406\u7c7b\u578b\uff09\uff0c\u5e76\u8bbe\u8ba1GKMRV\u63a2\u9488\u8bc4\u4f30\u516d\u79cd\u5f53\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5728\u77e5\u8bc6\u83b7\u53d6\uff08GKMRV\uff09\u4e0a\u8868\u73b0\u4f18\u5f02\uff08\u51c6\u786e\u73870.918\uff09\uff0c\u4f46\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u5dee\uff08\u51c6\u786e\u73870.25\uff09\uff0c\u8f93\u51fa\u4e00\u81f4\u6027\u9ad8\uff080.87\uff09\u3002", "conclusion": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u7ed3\u6784\u5316\u3001\u53ef\u7ec4\u5408\u7684\u5185\u90e8\u8868\u5f81\uff0c\u5bfc\u81f4\u77e5\u8bc6\u65e0\u6cd5\u53ef\u9760\u5e94\u7528\u4e8e\u63a8\u7406\u4efb\u52a1\uff0cGKMRV\u6846\u67b6\u4e3a\u9ad8\u98ce\u9669\u9886\u57df\u6a21\u578b\u53ef\u9760\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2508.10806", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10806", "abs": "https://arxiv.org/abs/2508.10806", "authors": ["Maria J. P. Peixoto", "Akriti Pandey", "Ahsan Zaman", "Peter R. Lewis"], "title": "Who Benefits from AI Explanations? Towards Accessible and Interpretable Systems", "comment": "Paper accepted for the IJCAI 2025 Workshop on Explainable Artificial\n  Intelligence (XAI): https://sites.google.com/view/xai2025/proceedings", "summary": "As AI systems are increasingly deployed to support decision-making in\ncritical domains, explainability has become a means to enhance the\nunderstandability of these outputs and enable users to make more informed and\nconscious choices. However, despite growing interest in the usability of\neXplainable AI (XAI), the accessibility of these methods, particularly for\nusers with vision impairments, remains underexplored. This paper investigates\naccessibility gaps in XAI through a two-pronged approach. First, a literature\nreview of 79 studies reveals that evaluations of XAI techniques rarely include\ndisabled users, with most explanations relying on inherently visual formats.\nSecond, we present a four-part methodological proof of concept that\noperationalizes inclusive XAI design: (1) categorization of AI systems, (2)\npersona definition and contextualization, (3) prototype design and\nimplementation, and (4) expert and user assessment of XAI techniques for\naccessibility. Preliminary findings suggest that simplified explanations are\nmore comprehensible for non-visual users than detailed ones, and that\nmultimodal presentation is required for more equitable interpretability.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u53ef\u89e3\u91caAI\uff08XAI\uff09\u5728\u89c6\u89c9\u969c\u788d\u7528\u6237\u4e2d\u7684\u53ef\u8bbf\u95ee\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u65b9\u6cd5\u9a8c\u8bc1\u63d0\u51fa\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u5728\u5173\u952e\u9886\u57df\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u5e94\u7528\u589e\u52a0\uff0c\u53ef\u89e3\u91ca\u6027\u6210\u4e3a\u63d0\u5347\u7528\u6237\u7406\u89e3\u548c\u9009\u62e9\u7684\u5173\u952e\uff0c\u4f46\u89c6\u89c9\u969c\u788d\u7528\u6237\u7684\u53ef\u8bbf\u95ee\u6027\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u6587\u732e\u7efc\u8ff0\uff0879\u9879\u7814\u7a76\uff09\u548c\u56db\u90e8\u5206\u65b9\u6cd5\u9a8c\u8bc1\uff08\u5206\u7c7b\u3001\u89d2\u8272\u5b9a\u4e49\u3001\u539f\u578b\u8bbe\u8ba1\u3001\u8bc4\u4f30\uff09\u5206\u6790XAI\u7684\u53ef\u8bbf\u95ee\u6027\u3002", "result": "\u521d\u6b65\u53d1\u73b0\u7b80\u5316\u89e3\u91ca\u5bf9\u975e\u89c6\u89c9\u7528\u6237\u66f4\u6613\u7406\u89e3\uff0c\u591a\u6a21\u6001\u5448\u73b0\u6709\u52a9\u4e8e\u516c\u5e73\u89e3\u91ca\u3002", "conclusion": "XAI\u8bbe\u8ba1\u9700\u8003\u8651\u89c6\u89c9\u969c\u788d\u7528\u6237\uff0c\u7b80\u5316\u89e3\u91ca\u548c\u591a\u6a21\u6001\u5448\u73b0\u662f\u63d0\u5347\u53ef\u8bbf\u95ee\u6027\u7684\u5173\u952e\u3002"}}
