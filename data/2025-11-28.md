<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 6]
- [cs.AI](#cs.AI) [Total: 29]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Real-World Performance Evaluations of Low-Band 5G NR/4G LTE 4x4 MIMO on Commercial Smartphones](https://arxiv.org/abs/2511.20959)
*Pasapong Wongprasert,Kasidis Arunruangsirilert,Jiro Katto*

Main category: cs.NI

TL;DR: 本文研究了索尼Xperia 1 III和IV在泰国b28/n28频段上的4x4 MIMO实际性能，包括不同信号条件下的可靠性测试和最优条件下的吞吐量测试。


<details>
  <summary>Details</summary>
Motivation: 大多数商用5G设备在低频段(<1GHz)缺乏4x4 MIMO支持，而泰国运营商在b28/n28频段部署了4T4R，需要验证实际性能增益。

Method: 使用索尼Xperia 1 III和IV智能手机，通过固件修改配置2Rx和4Rx模式，在不同信号条件下进行可靠性测试和吞吐量测试，与其他厂商设备进行对比。

Result: 在支持4T4R部署的b28/n28频段上，4x4 MIMO相比2x2 MIMO能够提供性能改进，具体表现为更高的可靠性和吞吐量。

Conclusion: 低频段4x4 MIMO在适当网络部署下确实能带来性能提升，但大多数设备制造商由于设计挑战或运营商部署不足而选择不支持。

Abstract: All 3GPP-compliant commercial 5G New Radio (NR)-capable UEs on the market are equipped with 4x4 MIMO support for Mid-Band frequencies (>1.7 GHz) and above, enabling up to rank 4 MIMO transmission. This doubles the theoretical throughput compared to rank 2 MIMO and also improves reception performance. However, 4x4 MIMO support on low-band frequencies (<1 GHz) is absent in every commercial UEs, with the exception of the Xperia 1 flagship smartphones manufactured by Sony Mobile and the Xiaomi 14 Pro as of January 2024. The reason most manufacturers omit 4x4 MIMO support for low-band frequencies is likely due to design challenges or relatively small performance gains in real-world usage due to the lack of 4T4R deployment on low-band by mobile network operators around the world.
  In Thailand, 4T4R deployment on the b28/n28 (APT) band is common on True-H and dtac networks, enabling 4x4 MIMO transmission on supported UEs. In this paper, the real-world 4x4 MIMO performance on the b28/n28 (APT) band will be investigated by evaluating the reliability test under different signal conditions and the maximum throughput test by evaluating the performance under optimal conditions, using the Sony Xperia 1 III and the Sony Xperia 1 IV smartphone. Devices from other manufacturers are also used in the experiment to investigate the performance with 2Rx antennas for comparison. Through firmware modifications, the Sony Xperia 1 III and IV can be configured to use only 2 Rx ports on low-band, enabling the collection of comparative 2 Rx performance data as a reference.

</details>


### [2] [Performance Evaluation of Low-Latency Live Streaming of MPEG-DASH UHD video over Commercial 5G NSA/SA Network](https://arxiv.org/abs/2511.20961)
*Kasidis Arunruangsirilert,Bo Wei,Hang Song,Jiro Katto*

Main category: cs.NI

TL;DR: 5G SA在泰国已覆盖76%人口，相比5G NSA和LTE，能更可靠地支持低延迟UHD视频直播，在各类场景下成功交付超过95%的视频段。


<details>
  <summary>Details</summary>
Motivation: 评估5G SA、5G NSA和LTE网络在实时UHD视频直播中的性能差异，特别是针对低延迟应用的需求。

Method: 使用MPEG-DASH协议在不同移动网络技术（5G SA、5G NSA、LTE）上实时直播UHD视频，最小化缓冲区以降低延迟，并在静止、城市移动、高速移动和理想SINR条件下测试性能指标。

Result: 5G SA在所有测试场景中能成功交付超过95%的UHD视频段，5G NSA表现不一取决于LTE网络状况，而LTE网络有超过20%的视频段无法按时交付。

Conclusion: 5G SA对于低延迟UHD视频流至关重要，5G NSA因依赖传统控制信号可能无法满足此类应用需求。

Abstract: 5G Standalone (SA) is the goal of the 5G evolution, which aims to provide higher throughput and lower latency than the existing LTE network. One of the main applications of 5G is the real-time distribution of Ultra High-Definition (UHD) content with a resolution of 4K or 8K. In Q2/2021, Advanced Info Service (AIS), the biggest operator in Thailand, launched 5G SA, providing both 5G SA/NSA service nationwide in addition to the existing LTE network. While many parts of the world are still in process of rolling out the first phase of 5G in Non-Standalone (NSA) mode, 5G SA in Thailand already covers more than 76% of the population.
  In this paper, UHD video will be a real-time live streaming via MPEG-DASH over different mobile network technologies with minimal buffer size to provide the lowest latency. Then, performance such as the number of dropped segments, MAC throughput, and latency are evaluated in various situations such as stationary, moving in the urban area, moving at high speed, and also an ideal condition with maximum SINR. It has been found that 5G SA can deliver more than 95% of the UHD video segment successfully within the required time window in all situations, while 5G NSA produced mixed results depending on the condition of the LTE network. The result also reveals that the LTE network failed to deliver more than 20% of the video segment within the deadline, which shows that 5G SA is absolutely necessary for low-latency UHD video streaming and 5G NSA may not be good enough for such task as it relies on the legacy control signal.

</details>


### [3] [5G Network Automation Using Local Large Language Models and Retrieval-Augmented Generation](https://arxiv.org/abs/2511.21084)
*Ahmadreza Majlesara,Ali Majlesi,Ali Mamaghani,Alireza Shokrani,Babak Hossein Khalaj*

Main category: cs.NI

TL;DR: 本文展示了一种结合本地部署的轻量级大语言模型(LLaMA-3 8b Q-4b)和检索增强生成(RAG)的5G网络管理自动化方案，强调隐私保护。


<details>
  <summary>Details</summary>
Motivation: 解决5G网络管理中隐私保护问题，避免敏感数据通过外部API传输到互联网，同时让非专业用户也能轻松配置网络。

Method: 在本地或边缘设备上部署轻量级LLM，结合RAG从数据库中检索相关信息，基于自然语言输入生成准确的网络配置。

Result: 该方法提高了网络配置的准确性和效率，简化了私有网络的创建和配置过程，使非专业用户也能使用。

Conclusion: 本地LLM与RAG的结合为5G网络提供了安全、高效且适应性强的解决方案，推动了隐私保护和多功能5G网络的发展。

Abstract: This demonstration showcases the integration of a lightweight, locally deployed Large Language Model (LLaMA-3 8b Q-4b) empowered by retrieval augmented generation (RAG) to automate 5G network management, with a strong emphasis on privacy. By running the LLM on local or edge devices ,we eliminate the need for external APIs, ensuring that sensitive data remains secure and is not transmitted over the internet. Although lightweight models may not match the performance of more complex models like GPT-4, we enhance their efficiency and accuracy through RAG. RAG retrieves relevant information from a comprehensive database, enabling the LLM to generate more precise and effective network configurations based on natural language user input. This approach not only improves the accuracy of the generated configurations but also simplifies the process of creating and configuring private networks, making it accessible to users without extensive networking or programming experience. The objective of this demonstration is to highlight the potential of combining local LLMs and RAG to deliver secure, efficient, and adaptable 5G network solutions, paving the way for a future where 5G networks are both privacy-conscious and versatile across diverse user profiles.

</details>


### [4] [Digital Twin-Driven Secure Access Strategy for SAGIN-Enabled IoT Networks](https://arxiv.org/abs/2511.21156)
*Hui Liang,Zhihui Wu,Runqi Yuan,Guobin Zhang,Yanfeng Zhang,Jinkai Zheng,Tom H. Luan*

Main category: cs.NI

TL;DR: 提出了一种基于数字孪生（DT）的安全接入策略，用于空间-空中-地面一体化网络（SAGIN）中的物联网设备，通过量化保密容量来评估窃听风险，并利用演化博弈模型平衡安全性和排队延迟。


<details>
  <summary>Details</summary>
Motivation: SAGIN支持的物联网网络面临日益严重的窃听攻击风险，数据机密性受到威胁，需要开发有效的安全接入机制。

Method: 在DT框架中创建物理SAGIN环境的虚拟副本，持续评估动态窃听风险；使用演化博弈模型平衡DT更新的保密容量与排队延迟；开发分布式算法获取均衡接入策略。

Result: 仿真结果表明，所提出的基于DT的方法显著提高了SAGIN物联网网络的安全性，有效平衡系统负载，防止过载发生，并减少排队延迟。

Conclusion: DT驱动的安全接入策略能够全面改善网络性能，在安全性和效率之间实现良好平衡，优于基准方案。

Abstract: In space-air-ground integrated networks (SAGIN)-enabled IoT networks, secure access has become a significant challenge due to the increasing risks of eavesdropping attacks. To address these threats to data confidentiality, this paper proposes a Digital Twin (DT)-driven secure access strategy. The strategy leverages a virtual replica of the physical SAGIN environment within the DT framework to continuously assess dynamic eavesdropping risks by quantifying secrecy capacity. Operating within this DT framework, an evolutionary game model dynamically balances the DT-updated secrecy capacity against queuing delay, steering IoT devices toward more secure and efficient access decisions. Furthermore, a novel distributed algorithm, integral to the DT operation, is developed to obtain the equilibrium access strategy for each device in a scalable manner. Simulation results demonstrate that the proposed DT-based approach substantially improves the security of SAGIN-enabled IoT networks. Additionally, it effectively balances system load, prevents overload occurrences, and decreases queuing delay compared to benchmark schemes, thereby comprehensively improving overall network performance.

</details>


### [5] [LatencyScope: A System-Level Mathematical Framework for 5G RAN Latency](https://arxiv.org/abs/2511.21277)
*Arman Maghsoudnia,Aoyu Gong,Raphael Cannatà,Dan Mihai Dumitriu,Haitham Hassanieh*

Main category: cs.NI

TL;DR: LatencyScope是一个用于准确计算5G RAN中单向延迟的数学框架，能够建模各层延迟源并识别系统级瓶颈，同时包含配置优化器以找到满足延迟可靠性目标的系统配置。


<details>
  <summary>Details</summary>
Motivation: 5G网络中需要满足超可靠低延迟通信(URLLC)要求，但现有分析模型和仿真器无法准确捕捉延迟的随机性和复杂依赖关系，需要更精确的延迟计算框架。

Method: 开发了数学框架建模RAN各层的延迟源，识别系统级瓶颈（如无线接口、调度策略、硬件/软件约束），并包含配置优化器搜索数百亿种配置。

Result: 在两个开源5G RAN测试平台(srsRAN和OAI)上验证，LatencyScope能够紧密匹配经验延迟分布，显著优于现有分析模型和常用仿真器，并能找到满足URLLC目标的系统配置。

Conclusion: LatencyScope为网络运营商提供了高效识别最佳系统设置的工具，能够准确计算5G RAN延迟并优化配置以满足严格的延迟可靠性要求。

Abstract: This paper presents LatencyScope, a mathematical framework for accurately computing one-way latency (for uplink and downlink) in the 5G RAN across diverse system configurations. LatencyScope models latency sources at every layer of the Radio Access Network (RAN), pinpointing system-level bottlenecks--such as radio interfaces, scheduling policies, and hardware/software constraints--while capturing their intricate dependencies and their stochastic nature. LatencyScope also includes a configuration optimizer that uses its mathematical models to search through hundreds of billions of configurations and find settings that meet latency-reliability targets under user constraints. We validate LatencyScope on two open-sourced 5G RAN testbeds (srsRAN and OAI), demonstrating that it can closely match empirical latency distributions and significantly outperform prior analytical models and widely used simulators (MATLAB 5G Toolbox, 5G-LENA). It can also find system configurations that meet Ultra-Reliable Low-Latency Communications (URLLC) targets and enable network operators to efficiently identify the best setup for their systems.

</details>


### [6] [Toward Secure Content-Centric Approaches for 5G-Based IoT: Advances and Emerging Trends](https://arxiv.org/abs/2511.21336)
*Ghada Jaber,Mohamed Ali Zormati,Walid Cavelius,Louka Chapiro,Mohamed El Ahmadi*

Main category: cs.NI

TL;DR: 本文综述了在5G物联网环境中部署内容中心网络(CCN)的安全挑战和解决方案，重点分析了内容认证、数据完整性、隐私保护等关键问题，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着物联网和5G技术的融合，内容中心网络作为传统IP架构的替代方案展现出优势，但在5G物联网环境中部署CCN面临严重的安全挑战，需要系统性的安全解决方案。

Method: 采用综述研究方法，对现有内容中心架构在物联网-5G场景中的安全解决方案进行分类和评估，分析当前趋势和局限性。

Result: 识别了内容中心网络在5G物联网环境中的主要安全威胁，包括内容认证、数据完整性、隐私保护等问题，并对现有安全方案进行了系统分类。

Conclusion: 需要开发轻量级和自适应的安全机制来应对5G物联网环境中内容中心网络的安全挑战，并指出了未来的研究方向。

Abstract: The convergence of the Internet of Things (IoT) and 5G technologies is transforming modern communication systems by enabling massive connectivity, low latency, and high-speed data transmission. In this evolving landscape, Content-Centric Networking (CCN) is emerging as a promising alternative to traditional Internet Protocol (IP)-based architectures. CCN offers advantages such as in-network caching, scalability, and efficient content dissemination, all of which are particularly well-suited to the constraints of the IoT. However, deploying content-centric approaches in 5G-based IoT environments introduces significant security challenges. Key concerns include content authentication, data integrity, privacy protection, and resilience against attacks such as spoofing and cache poisoning. Such issues are exacerbated by the distributed, mobile, and heterogeneous nature of IoT and 5G systems. In this survey, we review and classify existing security solutions for content-centric architectures in IoT-5G scenarios. We highlight current trends, identify limitations in existing approaches, and outline future research directions with a focus on lightweight and adaptive security mechanisms.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [Learning Multi-Access Point Coordination in Agentic AI Wi-Fi with Large Language Models](https://arxiv.org/abs/2511.20719)
*Yifan Fan,Le Liang,Peng Liu,Xiao Li,Ziyang Guo,Qiao Lan,Shi Jin,Wen Tong*

Main category: cs.AI

TL;DR: 本文提出了一个基于大型语言模型代理的Agentic AI Wi-Fi框架，通过AP间的实时协作和协商来动态适应网络条件，显著提升了密集Wi-Fi网络中的吞吐量性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多接入点协调协议依赖静态规则，无法适应动态网络条件（如干扰水平和拓扑变化），限制了在密集重叠基本服务集中提升吞吐量的能力。

Method: 将每个接入点建模为自主的大型语言模型代理，通过认知工作流程进行自然语言对话，利用集成记忆、反思和工具使用来协作推理网络状态并实时协商自适应协调策略。

Result: 综合仿真结果表明，该代理框架成功适应了多样化和动态的网络环境，显著优于最先进的空间复用基准方法。

Conclusion: 该框架验证了其作为未来无线网络稳健智能解决方案的潜力，能够通过动态协作学习适应复杂网络条件。

Abstract: Multi-access point coordination (MAPC) is a key technology for enhancing throughput in next-generation Wi-Fi within dense overlapping basic service sets. However, existing MAPC protocols rely on static, protocol-defined rules, which limits their ability to adapt to dynamic network conditions such as varying interference levels and topologies. To address this limitation, we propose a novel Agentic AI Wi-Fi framework where each access point, modeled as an autonomous large language model agent, collaboratively reasons about the network state and negotiates adaptive coordination strategies in real time. This dynamic collaboration is achieved through a cognitive workflow that enables the agents to engage in natural language dialogue, leveraging integrated memory, reflection, and tool use to ground their decisions in past experience and environmental feedback. Comprehensive simulation results demonstrate that our agentic framework successfully learns to adapt to diverse and dynamic network environments, significantly outperforming the state-of-the-art spatial reuse baseline and validating its potential as a robust and intelligent solution for future wireless networks.

</details>


### [8] [Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring](https://arxiv.org/abs/2511.20679)
*Melika Ayoughi,Pascal Mettes,Paul Groth*

Main category: cs.AI

TL;DR: 本文研究利用大语言模型自动重构层次结构以优化双曲嵌入质量，实验证明LLM重构的层次结构能显著提升嵌入质量，并提供可解释的重组理由。


<details>
  <summary>Details</summary>
Motivation: 双曲嵌入的质量与输入层次结构密切相关，而现有层次结构往往不满足最优嵌入所需的高分支因子和单继承特性。本文旨在探索LLM是否能够自动重构层次结构以满足这些标准。

Method: 提出基于提示的方法，利用LLM根据双曲嵌入的理想标准来转换现有层次结构，在16个不同层次结构上进行实验验证。

Result: 实验表明，LLM重构的层次结构在多个标准嵌入质量指标上始终产生更高质量的双曲嵌入，同时能够提供可解释的重组理由。

Conclusion: LLM能够有效自动重构层次结构以优化双曲嵌入质量，为知识工程师提供了一种可解释的重组方法。

Abstract: Hyperbolic geometry is an effective geometry for embedding hierarchical data structures. Hyperbolic learning has therefore become increasingly prominent in machine learning applications where data is hierarchically organized or governed by hierarchical semantics, ranging from recommendation systems to computer vision. The quality of hyperbolic embeddings is tightly coupled to the structure of the input hierarchy, which is often derived from knowledge graphs or ontologies. Recent work has uncovered that for an optimal hyperbolic embedding, a high branching factor and single inheritance are key, while embedding algorithms are robust to imbalance and hierarchy size. To assist knowledge engineers in reorganizing hierarchical knowledge, this paper investigates whether Large Language Models (LLMs) have the ability to automatically restructure hierarchies to meet these criteria. We propose a prompt-based approach to transform existing hierarchies using LLMs, guided by known desiderata for hyperbolic embeddings. Experiments on 16 diverse hierarchies show that LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard embedding quality metrics. Moreover, we show how LLM-guided hierarchy restructuring enables explainable reorganizations, providing justifications to knowledge engineers.

</details>


### [9] [AssurAI: Experience with Constructing Korean Socio-cultural Datasets to Discover Potential Risks of Generative AI](https://arxiv.org/abs/2511.20686)
*Chae-Gyun Lim,Seung-Ho Han,EunYoung Byun,Jeongyun Han,Soohyun Cho,Eojin Joo,Heehyeon Kim,Sieun Kim,Juhoon Lee,Hyunsoo Lee,Dongkun Lee,Jonghwan Hyeon,Yechan Hwang,Young-Jun Lee,Kyeongryul Lee,Minhyeong An,Hyunjun Ahn,Jeongwoo Son,Junho Park,Donggyu Yoon,Taehyung Kim,Jeemin Kim,Dasom Choi,Kwangyoung Lee,Hyunseung Lim,Yeohyun Jung,Jongok Hong,Sooyohn Nam,Joonyoung Park,Sungmin Na,Yubin Choi,Jeanne Choi,Yoojin Hong,Sueun Jang,Youngseok Seo,Somin Park,Seoungung Jo,Wonhye Chae,Yeeun Jo,Eunyoung Kim,Joyce Jiyoung Whang,HwaJung Hong,Joseph Seering,Uichin Lee,Juho Kim,Sunna Choi,Seokyeon Ko,Taeho Kim,Kyunghoon Kim,Myungsik Ha,So Jung Lee,Jemin Hwang,JoonHo Kwak,Ho-Jin Choi*

Main category: cs.AI

TL;DR: 提出了AssurAI，一个针对韩语多模态生成AI安全评估的质量控制数据集，包含11,480个文本、图像、视频和音频实例，覆盖35种AI风险因素。


<details>
  <summary>Details</summary>
Motivation: 当前的安全数据集主要是英语中心的，无法捕捉非英语（如韩语）社会文化背景下的特定风险，且通常仅限于文本模态。

Method: 定义了35种AI风险因素分类法，采用两阶段构建（专家引导种子和众包扩展）、三重独立标注和迭代专家红队循环的严格质量控制流程。

Result: 试点研究验证了AssurAI在评估最新LLM安全性方面的有效性。

Conclusion: 发布AssurAI以促进为韩国社区开发更安全可靠的生成AI系统。

Abstract: The rapid evolution of generative AI necessitates robust safety evaluations. However, current safety datasets are predominantly English-centric, failing to capture specific risks in non-English, socio-cultural contexts such as Korean, and are often limited to the text modality. To address this gap, we introduce AssurAI, a new quality-controlled Korean multimodal dataset for evaluating the safety of generative AI. First, we define a taxonomy of 35 distinct AI risk factors, adapted from established frameworks by a multidisciplinary expert group to cover both universal harms and relevance to the Korean socio-cultural context. Second, leveraging this taxonomy, we construct and release AssurAI, a large-scale Korean multimodal dataset comprising 11,480 instances across text, image, video, and audio. Third, we apply the rigorous quality control process used to ensure data integrity, featuring a two-phase construction (i.e., expert-led seeding and crowdsourced scaling), triple independent annotation, and an iterative expert red-teaming loop. Our pilot study validates AssurAI's effectiveness in assessing the safety of recent LLMs. We release AssurAI to the public to facilitate the development of safer and more reliable generative AI systems for the Korean community.

</details>


### [10] [$A^2Flow:$ Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators](https://arxiv.org/abs/2511.20693)
*Mingming Zhao,Xiaokang Wei,Yuanqi Shao,Kaiwen Zhou,Lin Yang,Siwei Rao,Junhui Zhan,Zhitang Chen*

Main category: cs.AI

TL;DR: A²Flow是一个完全自动化的智能体工作流生成框架，通过自适应的抽象操作符避免了手动预定义操作符的限制，在性能和资源效率方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法严重依赖手动预定义的操作符，限制了智能体工作流的泛化能力和可扩展性。

Method: 采用三阶段操作符提取过程：1)基于案例的初始操作符生成；2)操作符聚类和初步抽象；3)深度提取抽象执行操作符，并结合操作符记忆机制增强工作流搜索。

Result: 在通用和具身基准测试中，A²Flow平均性能提升2.4%和19.3%，资源使用减少37%。

Conclusion: A²Flow通过完全自动化的操作符提取和工作流构建，为智能体工作流设计提供了更通用和可扩展的解决方案。

Abstract: Large language models (LLMs) have shown strong potential in automating the design of agentic workflows. However, existing methods still rely heavily on manually predefined operators, limiting generalization and scalability. To address this issue, we propose $A^2Flow$, a fully automated framework for agentic workflow generation based on self-adaptive abstraction operators. $A^2Flow$ employs a three-stage operator extraction process: 1) Case-based Initial Operator Generation: leveraging expert demonstrations and LLM reasoning to generate case-specific operators; 2) Operator Clustering and Preliminary Abstraction: grouping similar operators across tasks to form preliminary abstractions; and 3) Deep Extraction for Abstract Execution Operators: applying long chain-of-thought prompting and multi-path reasoning to derive compact and generalizable execution operators. These operators serve as reusable building blocks for workflow construction without manual predefinition. Furthermore, we enhance node-level workflow search with an operator memory mechanism, which retains historical outputs to enrich context and improve decision-making. Experiments on general and embodied benchmarks show that $A^2Flow$ achieves a 2.4\% and 19.3\% average performance improvement and reduces resource usage by 37\% over state-of-the-art baselines. Homepage:https://github.com/pandawei-ele/A2FLOW

</details>


### [11] [Reasoning With a Star: A Heliophysics Dataset and Benchmark for Agentic Scientific Reasoning](https://arxiv.org/abs/2511.20694)
*Kevin Lee,Russell Spiewak,James Walsh*

Main category: cs.AI

TL;DR: 提出了一个用于太阳物理推理的数据集和基准测试方法，发现基于系统工程原理的多智能体工作流在需要演绎推理的问题上表现优于直接提示。


<details>
  <summary>Details</summary>
Motivation: 解决太阳物理领域大型语言模型推理需要整合物理假设、保持单位一致性和提供清晰科学格式的挑战。

Method: 构建了来自NASA和UCAR Living With a Star暑期学校问题集的数据集，采用程序化评分器检查预测结果，并比较了单次提示和四种多智能体模式。

Result: 通过系统工程原理分解工作流在需要演绎推理的问题上表现优于直接提示，而不是纯粹的归纳回忆。

Conclusion: 多智能体工作流分解方法在太阳物理推理任务中具有优势，特别是在需要复杂推理的问题上。

Abstract: Scientific reasoning through Large Language Models in heliophysics involves more than just recalling facts: it requires incorporating physical assumptions, maintaining consistent units, and providing clear scientific formats through coordinated approaches. To address these challenges, we present Reasoning With a Star, a newly contributed heliophysics dataset applicable to reasoning; we also provide an initial benchmarking approach. Our data are constructed from National Aeronautics and Space Administration & University Corporation for Atmospheric Research Living With a Star summer school problem sets and compiled into a readily consumable question-and-answer structure with question contexts, reasoning steps, expected answer type, ground-truth targets, format hints, and metadata. A programmatic grader checks the predictions using unit-aware numerical tolerance, symbolic equivalence, and schema validation. We benchmark a single-shot baseline and four multi-agent patterns, finding that decomposing workflows through systems engineering principles outperforms direct prompting on problems requiring deductive reasoning rather than pure inductive recall.

</details>


### [12] [A Brief History of Digital Twin Technology](https://arxiv.org/abs/2511.20695)
*Yunqi Zhang,Kuangyu Shi,Biao Li*

Main category: cs.AI

TL;DR: 数字孪生技术从NASA航天器模拟发展而来，现正推动医疗健康转型，通过创建患者特异性虚拟模型来支持诊断、治疗规划和药物开发，但仍面临互操作性、数据隐私等挑战。


<details>
  <summary>Details</summary>
Motivation: 将数字孪生技术从工业领域引入医疗，旨在实现从被动治疗向预测性、预防性和个性化医疗的转变，通过患者特异性模拟提升医疗决策质量。

Method: 整合医学影像、生物传感器和计算模型，创建动态数据驱动的患者虚拟副本，支持实时双向交互，应用于心脏、肿瘤和药物研发等领域。

Result: 已开发出心脏数字孪生预测心律失常治疗效果、肿瘤数字孪生追踪肿瘤进展优化放疗、药物数字孪生加速药物发现等代表性应用。

Conclusion: 数字孪生技术有望彻底改变医疗模式，但需要解决互操作性、数据隐私等挑战，未来需发展多器官数字孪生、基因组学整合和伦理治理框架。

Abstract: Emerging from NASA's spacecraft simulations in the 1960s, digital twin technology has advanced through industrial adoption to spark a healthcare transformation. A digital twin is a dynamic, data-driven virtual counterpart of a physical system, continuously updated through real-time data streams and capable of bidirectional interaction. In medicine, digital twin integrates imaging, biosensors, and computational models to generate patient-specific simulations that support diagnosis, treatment planning, and drug development. Representative applications include cardiac digital twin for predicting arrhythmia treatment outcomes, oncology digital twin for tracking tumor progression and optimizing radiotherapy, and pharmacological digital twin for accelerating drug discovery. Despite rapid progress, major challenges, including interoperability, data privacy, and model fidelity, continue to limit widespread clinical integration. Emerging solutions such as explainable AI, federated learning, and harmonized regulatory frameworks offer promising pathways forward. Looking ahead, advances in multi-organ digital twin, genomics integration, and ethical governance will be essential to ensure that digital twin shifts healthcare from reactive treatment to predictive, preventive, and truly personalized medicine.

</details>


### [13] [Paraconsistent-Lib: an intuitive PAL2v algorithm Python Library](https://arxiv.org/abs/2511.20700)
*Arnaldo de Carvalho Junior,Diego Oliveira da Cruz,Bruno da Silva Alves,Fernando da Silva Paulo Junior,João Inacio da Silva Filho*

Main category: cs.AI

TL;DR: Paraconsistent-Lib是一个开源的Python库，用于构建PAL2v算法，支持12种经典格区域分析、分析节点输出和决策输出，简化了复杂算法的实现。


<details>
  <summary>Details</summary>
Motivation: 为推理和决策系统提供一个易于使用的PAL2v算法构建工具，减少代码复杂度和错误，支持用户需求驱动的持续开发。

Method: 设计为通用PAL2v标准计算库，提供三种结果类型：12种经典格区域的不一致分析、分析节点输出和决策输出，支持独立或网络形式的算法实现。

Result: 实现了Para-analyzer、ParaExtrCTX、PAL2v Filter、PANnet和PNN等知名PAL2v算法，通过两个示例展示了代码复杂度和错误减少的效果。

Conclusion: Paraconsistent-Lib是一个稳定且持续发展的开源库，能够有效简化PAL2v算法的实现，并通过GitHub接收用户反馈进行功能增强。

Abstract: This paper introduces Paraconsistent-Lib, an open-source, easy-to-use Python library for building PAL2v algorithms in reasoning and decision-making systems. Paraconsistent-Lib is designed as a general-purpose library of PAL2v standard calculations, presenting three types of results: paraconsistent analysis in one of the 12 classical lattice PAL2v regions, paraconsistent analysis node (PAN) outputs, and a decision output. With Paraconsistent-Lib, well-known PAL2v algorithms such as Para-analyzer, ParaExtrCTX, PAL2v Filter, paraconsistent analysis network (PANnet), and paraconsistent neural network (PNN) can be written in stand-alone or network form, reducing complexity, code size, and bugs, as two examples presented in this paper. Given its stable state, Paraconsistent-Lib is an active development to respond to user-required features and enhancements received on GitHub.

</details>


### [14] [Cross Domain Evaluation of Multimodal Chain-of-Thought Reasoning of different datasets into the Amazon CoT Framework](https://arxiv.org/abs/2511.20701)
*Nitya Tiwari,Parv Maheshwari,Vidisha Agarwal*

Main category: cs.AI

TL;DR: 该研究对多模态思维链推理进行了跨领域分析，发现在科学推理之外的常识推理任务中，多模态CoT的有效性存在显著差异，视觉特征能减少幻觉但常识推理仍是挑战。


<details>
  <summary>Details</summary>
Motivation: 探索多模态思维链推理在科学问答之外的通用性，评估其在需要广泛常识和世界知识的跨领域任务中的表现。

Method: 采用Zhang等人提出的两阶段框架，将理由生成与答案推理分离，通过门控融合机制整合视觉特征与T5语言模型，并进行系统性消融研究。

Result: 视觉整合显著减少了理由生成中的幻觉，但CoT推理的有效性在不同问题类型间差异很大，常识推理尤其具有挑战性。

Conclusion: 为多模态推理系统的实现提供实用见解，并确定了跨领域泛化的关键改进方向。

Abstract: While recent work has extended CoT to multimodal settings, achieving state-of-the-art results on science question answering benchmarks like ScienceQA, the generalizability of these approaches across diverse domains remains underexplored. This work presents a comprehensive analysis of Multimodal Chain-of-Thought (Multimodal-CoT) reasoning, evaluating its effectiveness on the A-OKVQA, OKVQA and ChartQA datasets, which requires broad commonsense and world knowledge beyond scientific reasoning. We implement the two-stage framework proposed by Zhang et al. [3], which separates rationale generation from answer inference and integrates vision features through a gated fusion mechanism with T5-based language models. Through systematic ablation studies, we analyze the contributions of vision features, rationale quality, and architectural choices. Our findings reveal that while vision integration significantly reduces hallucination in rationale generation, the effectiveness of CoT reasoning varies substantially across question types, with commonsense reasoning presenting particular challenges. This work provides practical insights for researchers implementing multimodal reasoning systems and identifies key areas for future improvement in cross-domain generalization.

</details>


### [15] [OpenApps: Simulating Environment Variations to Measure UI-Agent Reliability](https://arxiv.org/abs/2511.20766)
*Karen Ullrich,Jingtong Su,Claudia Shi,Arjun Subramonian,Amir Bar,Ivan Evtimov,Nikolaos Tsilivis,Randall Balestriero,Julia Kempe,Mark Ibrahim*

Main category: cs.AI

TL;DR: OpenApps是一个轻量级开源生态系统，包含6个可配置应用，用于评估多模态UI代理在不同应用变体中的可靠性。研究发现，虽然代理在固定应用中的可靠性相对稳定，但在不同应用变体中的成功率波动可达50%以上。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法依赖固定环境，无法衡量代理在不同应用设计和内容变体中的可靠性，而实际部署时代理会遇到各种应用变体，这会影响任务完成能力。

Method: 开发OpenApps生态系统，包含6个可配置应用（消息、日历、地图等），只需单个CPU即可运行，能够生成和部署数千个应用版本。进行了超过10,000次独立评估，研究7个领先多模态代理的可靠性。

Result: 代理在固定应用中的可靠性相对稳定，但在不同应用变体中的成功率波动显著。例如Kimi-VL-3B的平均成功率在不同应用版本中从63%跌至4%。代理行为（如循环或幻觉操作）也因环境配置而异。

Conclusion: 测量代理在应用变体维度上的可靠性至关重要，OpenApps为这一新维度的评估提供了工具，揭示了当前代理在面对应用变化时的脆弱性。

Abstract: Reliability is key to realizing the promise of autonomous UI-Agents, multimodal agents that directly interact with apps in the same manner as humans, as users must be able to trust an agent to complete a given task. Current evaluations rely on fixed environments, often clones of existing apps, which are limited in that they can only shed light on whether or how often an agent can complete a task within a specific environment. When deployed however, agents are likely to encounter variations in app design and content that can affect an agent's ability to complete a task. To address this blind spot of measuring agent reliability across app variations, we develop OpenApps, a light-weight open-source ecosystem with six apps (messenger, calendar, maps, etc.) that are configurable in appearance and content. OpenApps requires just a single CPU to run, enabling easy generation and deployment of thousands of versions of each app. Specifically, we run more than 10,000 independent evaluations to study reliability across seven leading multimodal agents. We find that while standard reliability within a fixed app is relatively stable, reliability can vary drastically when measured across app variations. Task success rates for many agents can fluctuate by more than $50\%$ across app variations. For example, Kimi-VL-3B's average success across all tasks fluctuates from $63\%$ to just $4\%$ across app versions. We also find agent behaviors such as looping or hallucinating actions can differ drastically depending on the environment configuration. These initial findings highlight the importance of measuring reliability along this new dimension of app variations. OpenApps is available at https://facebookresearch.github.io/OpenApps/

</details>


### [16] [Representation Interventions Enable Lifelong Unstructured Knowledge Control](https://arxiv.org/abs/2511.20892)
*Xuyuan Liu,Zhengzhang Chen,Xinshuai Dong,Yanchi Liu,Xujiang Zhao,Shengyu Chen,Haoyu Wang,Yujun Yan,Haifeng Chen*

Main category: cs.AI

TL;DR: RILKE是一种在表示空间进行干预的知识控制方法，通过低维子空间更新和查询自适应路由，实现大规模知识编辑而不影响模型通用能力。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型知识过时或错误的问题，避免昂贵的重新训练，在终身学习设置中实现高效准确的知识更新。

Method: 在模型表示空间进行干预，学习抗释义和编辑局部化的模块，将每个更新限制在低维子空间以减少干扰，推理时使用查询自适应路由选择合适模块。

Result: 在LLaMA和Qwen模型的知识编辑基准测试中，RILKE具有高编辑成功率、强释义泛化能力，保持通用效用且内存开销小。

Conclusion: RILKE是LLM终身知识控制的有效且可扩展解决方案。

Abstract: Large language models (LLMs) often produce incorrect or outdated content. Updating their knowledge efficiently and accurately without costly retraining is a major challenge. This problem is especially hard for complex, unstructured knowledge in a lifelong setting, where many edits must coexist without interference. We introduce RILKE (Representation Intervention for Lifelong KnowledgE Control), a robust and scalable method that treats knowledge control as interventions within the model's representation space. Leveraging representation-space expressiveness, we identify two properties enabling RILKE to deliver fine-grained control over complex, unstructured knowledge while maintaining general utility with frozen base weights. During training, RILKE learns paraphrase-robust and edit-localized modules that limit each update to a low-dimensional subspace to minimize cross-edit interference. In inference, a query-adaptive router selects the appropriate module to guide the model's generation. In evaluation on knowledge editing benchmarks with LLaMA and Qwen models, RILKE is scalable to large-scale datasets, demonstrating high edit success, strong paraphrase generalization, and preserving general utility with modest memory overhead. These results show RILKE is an effective and scalable solution for lifelong knowledge control in LLMs.

</details>


### [17] [Guaranteed Optimal Compositional Explanations for Neurons](https://arxiv.org/abs/2511.20934)
*Biagio La Rosa,Leilani H. Gilpin*

Main category: cs.AI

TL;DR: 本文提出了第一个计算保证最优组合解释的理论框架，通过分解空间对齐因素、设计启发式估计和开发新算法，在计算机视觉和CNN中验证了beam search方法有10-40%的解释是次优的。


<details>
  <summary>Details</summary>
Motivation: 当前神经元组合解释方法使用beam search计算概念组合，但无法提供最优性保证，不清楚当前解释与真正最优解的接近程度。

Method: 提出包含三个组件的框架：(i)识别影响空间对齐因素的分解方法，(ii)在搜索任何阶段估计对齐的启发式方法，(iii)能在可行时间内计算最优组合解释的首个算法。

Result: 在计算机视觉和CNN的流行设置中，当涉及重叠概念时，beam search获得的解释有10-40%是次优的。基于本文分解和启发式的beam search变体在运行时间上匹配或优于先前方法。

Conclusion: 本文建立了首个保证最优组合解释的理论框架，揭示了现有方法的次优性问题，并提供了更灵活高效的替代方案。

Abstract: While neurons are the basic units of deep neural networks, it is still unclear what they learn and if their knowledge is aligned with that of humans. Compositional explanations aim to answer this question by describing the spatial alignment between neuron activations and concepts through logical rules. These logical descriptions are typically computed via a search over all possible concept combinations. Since computing the spatial alignment over the entire state space is computationally infeasible, the literature commonly adopts beam search to restrict the space. However, beam search cannot provide any theoretical guarantees of optimality, and it remains unclear how close current explanations are to the true optimum. In this theoretical paper, we address this gap by introducing the first framework for computing guaranteed optimal compositional explanations. Specifically, we propose: (i) a decomposition that identifies the factors influencing the spatial alignment, (ii) a heuristic to estimate the alignment at any stage of the search, and (iii) the first algorithm that can compute optimal compositional explanations within a feasible time. Using this framework, we analyze the differences between optimal and non-optimal explanations in the most popular settings for compositional explanations, the computer vision domain and Convolutional Neural Networks. In these settings, we demonstrate that 10-40 percent of explanations obtained with beam search are suboptimal when overlapping concepts are involved. Finally, we evaluate a beam-search variant guided by our proposed decomposition and heuristic, showing that it matches or improves runtime over prior methods while offering greater flexibility in hyperparameters and computational resources.

</details>


### [18] [ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction](https://arxiv.org/abs/2511.20937)
*Qineng Wang,Wenlong Huang,Yu Zhou,Hang Yin,Tianwei Bao,Jianwen Lyu,Weiyu Liu,Ruohan Zhang,Jiajun Wu,Li Fei-Fei,Manling Li*

Main category: cs.AI

TL;DR: ENACT是一个评估视觉语言模型是否表现出具身认知的基准测试，通过视觉问答形式测试世界建模能力，包含前向和逆向世界建模任务。


<details>
  <summary>Details</summary>
Motivation: 探究现代视觉语言模型是否具有具身认知特征，尽管它们主要在非具身方式下训练。具身认知认为智能源于感知运动交互而非被动观察。

Method: 将具身认知评估构建为部分可观察马尔可夫决策过程中的世界建模问题，包含两个序列重排序任务：前向世界建模（根据动作重排观察序列）和逆向世界建模（根据观察重排动作序列）。

Result: 前沿视觉语言模型与人类之间存在性能差距，且随着交互视野延长而扩大。模型在逆向任务上表现优于前向任务，并表现出人类中心偏见，如偏好右手动作、当相机参数或视角偏离人类视觉时性能下降。

Conclusion: ENACT基准揭示了视觉语言模型在具身认知能力上的局限性，为理解和发展具身智能提供了重要评估工具。

Abstract: Embodied cognition argues that intelligence arises from sensorimotor interaction rather than passive observation. It raises an intriguing question: do modern vision-language models (VLMs), trained largely in a disembodied manner, exhibit signs of embodied cognition? We introduce ENACT, a benchmark that casts evaluation of embodied cognition as world modeling from egocentric interaction in a visual question answering (VQA) format. Framed as a partially observable Markov decision process (POMDP) whose actions are scene graph changes, ENACT comprises two complementary sequence reordering tasks: forward world modeling (reorder shuffled observations given actions) and inverse world modeling (reorder shuffled actions given observations). While conceptually simple, solving these tasks implicitly demands capabilities central to embodied cognition-affordance recognition, action-effect reasoning, embodied awareness, and interactive, long-horizon memory from partially observable egocentric input, while avoiding low-level image synthesis that could confound the evaluation. We provide a scalable pipeline that synthesizes QA pairs from robotics simulation (BEHAVIOR) and evaluates models on 8,972 QA pairs spanning long-horizon home-scale activities. Experiments reveal a performance gap between frontier VLMs and humans that widens with interaction horizon. Models consistently perform better on the inverse task than the forward one and exhibit anthropocentric biases, including a preference for right-handed actions and degradation when camera intrinsics or viewpoints deviate from human vision. Website at https://enact-embodied-cognition.github.io/.

</details>


### [19] [Improving Procedural Skill Explanations via Constrained Generation: A Symbolic-LLM Hybrid Architecture](https://arxiv.org/abs/2511.20942)
*Rahul Dass,Thomas Bowlin,Zebing Li,Xiao Jin,Ashok Goel*

Main category: cs.AI

TL;DR: Ivy是一个AI教学系统，通过结合符号化的TMK模型和生成式解释层，提供结构化、多步骤的解释，以改善LLM在程序技能学习中的教学价值。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在程序技能学习中往往产生流畅但浅显的响应，缺乏因果、目标导向和组合逻辑的结构。

Method: 结合符号化的任务-方法-知识模型和生成式解释层，TMK编码因果转换、目标层次和问题分解，在明确的结构边界内指导LLM。

Result: 与GPT和检索增强的GPT基线相比，符号约束持续改善了"如何"和"为什么"问题的解释结构质量。

Conclusion: 这项研究展示了一种可扩展的AI教育方法，增强了AI生成解释在智能教学系统中的教学价值。

Abstract: In procedural skill learning, instructional explanations must convey not just steps, but the causal, goal-directed, and compositional logic behind them. Large language models (LLMs) often produce fluent yet shallow responses that miss this structure. We present Ivy, an AI coaching system that delivers structured, multi-step explanations by combining symbolic Task-Method-Knowledge (TMK) models with a generative interpretation layer-an LLM that constructs explanations while being constrained by TMK structure. TMK encodes causal transitions, goal hierarchies, and problem decompositions, and guides the LLM within explicit structural bounds. We evaluate Ivy against responses against GPT and retrieval-augmented GPT baselines using expert and independent annotations across three inferential dimensions. Results show that symbolic constraints consistently improve the structural quality of explanations for "how" and "why" questions. This study demonstrates a scalable AI for education approach that strengthens the pedagogical value of AI-generated explanations in intelligent coaching systems.

</details>


### [20] [ICPO: Intrinsic Confidence-Driven Group Relative Preference Optimization for Efficient Reinforcement Learning](https://arxiv.org/abs/2511.21005)
*Jinpeng Wang,Chao Li,Ting Ye,Mengyuan Zhang,Wei Liu,Jian Luan*

Main category: cs.AI

TL;DR: 提出ICPO方法解决RLVR中的奖励粒度粗、奖励噪声和探索效率低等问题，通过利用LLM生成概率的内在置信度来指导探索过程。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法存在奖励粒度粗、奖励噪声和探索效率低等问题，导致训练不稳定和熵崩溃，需要更有效的优化方法。

Method: ICPO方法基于LLM生成不同响应的概率反映其推理过程自评估的直觉，通过计算多个响应在相同输入提示下的相对生成概率得到偏好优势分数，并与可验证奖励结合指导探索。

Result: 在四个通用领域基准和三个数学基准上的综合实验表明，ICPO相比GRPO能稳定提升推理能力。

Conclusion: 偏好优势分数不仅能缓解奖励粒度和噪声问题，还能有效抑制过度自信错误，增强被低估高质量响应的相对优势，防止模型对特定策略过拟合，促进更彻底的探索。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) demonstrates significant potential in enhancing the reasoning capabilities of Large Language Models (LLMs). However, existing RLVR methods are often constrained by issues such as coarse-grained rewards, reward noise, and inefficient exploration, which lead to unstable training and entropy collapse. To address this challenge, we propose the Intrinsic Confidence-Driven Group Relative Preference Optimization method (ICPO). The intuition behind it lies in the fact that the probabilities of an LLM generating different responses can inherently and directly reflect its self-assessment of the reasoning process. Inspired by the idea of preference modeling, ICPO calculates a preference advantage score for each response by comparing the relative generation probabilities of multiple responses under the same input prompt, and integrates this score with verifiable rewards to guide the exploration process. We have discovered that the preference advantage score not only alleviates the issues of coarse-grained rewards and reward noise but also effectively curbs overconfident errors, enhances the relative superiority of undervalued high-quality responses, and prevents the model from overfitting to specific strategies, thereby facilitating more thorough exploration. Comprehensive experiments across four general-domain benchmarks and three mathematical benchmarks demonstrate that ICPO steadily boosts reasoning compared to GRPO.

</details>


### [21] [Towards Trustworthy Legal AI through LLM Agents and Formal Reasoning](https://arxiv.org/abs/2511.21033)
*Linze Chen,Yufan Cai,Zhe Hou,Jinsong Dong*

Main category: cs.AI

TL;DR: L4M框架结合对抗性LLM代理和SMT求解器证明，将自然语言的解释灵活性与符号验证的严谨性相结合，用于法律裁决。


<details>
  <summary>Details</summary>
Motivation: 现有LLM系统擅长表层文本分析，但缺乏原则性法理学所需的保证。法律理性包括实质理性（结果公平性）和形式理性（遵循明确规则），需要结合两者的方法。

Method: 三阶段流程：(1)法规形式化：将法律条款转换为逻辑公式；(2)双重事实和法规提取：检察官和辩护方LLM独立提取事实和法规；(3)求解器中心裁决：将双方论点编译为逻辑约束，通过不满足核心触发迭代自我批评，最终由法官LLM生成透明裁决。

Result: 在公共基准测试中，该系统超越了GPT-4-mini、DeepSeek-V3、Claude 4等先进LLM以及最先进的法律AI基线，同时提供严谨且可解释的符号证明。

Conclusion: L4M框架成功地将自然语言的灵活性与符号验证的严谨性相结合，为法律AI系统提供了既具有解释灵活性又具备形式保证的解决方案。

Abstract: The rationality of law manifests in two forms: substantive rationality, which concerns the fairness or moral desirability of outcomes, and formal rationality, which requires legal decisions to follow explicitly stated, general, and logically coherent rules. Existing LLM-based systems excel at surface-level text analysis but lack the guarantees required for principled jurisprudence. We introduce L4M, a novel framework that combines adversarial LLM agents with SMT-solver-backed proofs to unite the interpretive flexibility of natural language with the rigor of symbolic verification. The pipeline consists of three phases: (1) Statute Formalization, where domain-specific prompts convert legal provisions into logical formulae; (2) Dual Fact and Statute Extraction, in which prosecutor- and defense-aligned LLMs independently map case narratives to fact tuples and statutes, ensuring role isolation; and (3) Solver-Centric Adjudication, where an autoformalizer compiles both parties' arguments into logic constraints, and unsat cores trigger iterative self-critique until a satisfiable formula is achieved, which is then verbalized by a Judge-LLM into a transparent verdict and optimized sentence. Experimental results on public benchmarks show that our system surpasses advanced LLMs including GPT-o4-mini, DeepSeek-V3, and Claude 4 as well as state-of-the-art Legal AI baselines, while providing rigorous and explainable symbolic justifications.

</details>


### [22] [OVOD-Agent: A Markov-Bandit Framework for Proactive Visual Reasoning and Self-Evolving Detection](https://arxiv.org/abs/2511.21064)
*Chujie Wang,Jianyu Lu,Zhiyuan Luo,Xi Chen,Chu He*

Main category: cs.AI

TL;DR: OVOD-Agent将开放词汇目标检测从被动的类别匹配转变为主动的视觉推理和自我进化检测，通过视觉思维链和弱马尔可夫决策过程提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇目标检测方法虽然在多模态数据上预训练，但推理仍局限于固定类别名称，存在多模态训练与单模态推理之间的差距。文本空间的潜力尚未充分挖掘。

Method: 提出OVOD-Agent框架：1）将文本优化过程扩展为可解释的视觉思维链；2）将视觉上下文转换建模为八状态空间的弱马尔可夫决策过程；3）使用Bandit模块生成探索信号；4）整合马尔可夫转移矩阵与Bandit轨迹进行自监督奖励模型优化。

Result: 在COCO和LVIS数据集上的实验表明，OVOD-Agent在各种OVOD骨干网络上均能提供一致的性能提升，特别是在稀有类别上表现突出。

Conclusion: OVOD-Agent框架通过主动视觉推理和自我进化检测机制，有效提升了开放词汇目标检测的性能，证明了所提方法的有效性。

Abstract: Open-Vocabulary Object Detection (OVOD) aims to enable detectors to generalize across categories by leveraging semantic information. Although existing methods are pretrained on large vision-language datasets, their inference is still limited to fixed category names, creating a gap between multimodal training and unimodal inference. Previous work has shown that improving textual representation can significantly enhance OVOD performance, indicating that the textual space is still underexplored. To this end, we propose OVOD-Agent, which transforms passive category matching into proactive visual reasoning and self-evolving detection. Inspired by the Chain-of-Thought (CoT) paradigm, OVOD-Agent extends the textual optimization process into an interpretable Visual-CoT with explicit actions. OVOD's lightweight nature makes LLM-based management unsuitable; instead, we model visual context transitions as a Weakly Markovian Decision Process (w-MDP) over eight state spaces, which naturally represents the agent's state, memory, and interaction dynamics. A Bandit module generates exploration signals under limited supervision, helping the agent focus on uncertain regions and adapt its detection policy. We further integrate Markov transition matrices with Bandit trajectories for self-supervised Reward Model (RM) optimization, forming a closed loop from Bandit exploration to RM learning. Experiments on COCO and LVIS show that OVOD-Agent provides consistent improvements across OVOD backbones, particularly on rare categories, confirming the effectiveness of the proposed framework.

</details>


### [23] [Causality Without Causal Models](https://arxiv.org/abs/2511.21260)
*Joseph Y. Halpern,Rafael Pass*

Main category: cs.AI

TL;DR: 本文提出了Halpern-Pearl因果关系的抽象定义，使其能应用于任何定义了反事实的模型，扩展了原定义的应用范围和处理能力。


<details>
  <summary>Details</summary>
Motivation: Halpern-Pearl的因果定义局限于因果模型，无法处理包含析取、否定、信念和嵌套反事实的复杂公式，需要更通用的抽象定义。

Method: 通过抽象化Halpern-Pearl定义的关键特征，构建可在任何反事实模型中应用的因果定义框架。

Result: 新定义不仅能处理更广泛的模型类型（如允许回溯的模型），还能处理复杂逻辑公式，并扩展到解释概念的抽象定义。

Conclusion: 抽象化方法扩展了因果定义的应用范围，提供了更深入的理解，并为解释概念提供了通用框架。

Abstract: Perhaps the most prominent current definition of (actual) causality is due to Halpern and Pearl.  It is defined using causal models (also known as structural equations models).  We abstract the definition, extracting its key features, so that it can be applied to any other model where counterfactuals are defined. By abstracting the definition, we gain a number of benefits. Not only can we apply the definition in a wider range of models, including ones that allow, for example, backtracking, but we can apply the definition to determine if A is a cause of B  even if A and B are formulas involving disjunctions, negations, beliefs, and nested counterfactuals (none of which can be handled by the Halpern-Pearl definition). Moreover, we can extend the ideas to getting an abstract definition of explanation that can be applied beyond causal models. Finally, we gain a deeper understanding of features of the definition  even in causal models.

</details>


### [24] [Prune4Web: DOM Tree Pruning Programming for Web Agent](https://arxiv.org/abs/2511.21398)
*Jiayuan Zhang,Kaiquan Chen,Zhihao Lu,Enshen Zhou,Qian Yu,Jing Zhang*

Main category: cs.AI

TL;DR: Prune4Web是一种新的网页自动化范式，通过将DOM处理从资源密集的LLM读取转向高效的程序化剪枝，解决了复杂网页DOM结构过大的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的网页代理在处理大型DOM结构（通常包含1万到10万个token）时效率低下，现有策略要么依赖粗略的DOM截断（可能丢失关键信息），要么使用低效的启发式方法和单独的排名模型，无法在精度和可扩展性之间达到最佳平衡。

Method: 提出DOM树剪枝编程方法，让LLM生成可执行的Python评分脚本，基于分解的子任务语义线索动态过滤DOM元素。该方法无需LLM读取原始大型DOM，而是将遍历和评分委托给轻量级、可解释的程序。

Result: 实现了候选元素25倍到50倍的减少，在低级别接地任务上准确率从46.8%大幅提升至88.28%，表现出最先进的性能。

Conclusion: Prune4Web通过程序化剪枝范式有效解决了网页自动化中DOM处理效率低下的问题，显著提升了动作定位的精确性，同时减轻了注意力稀释问题。

Abstract: Web automation employs intelligent agents to execute high-level tasks by mimicking human interactions with web interfaces. Despite the capabilities of recent Large Language Model (LLM)-based web agents, navigating complex, real-world webpages efficiently remains a significant hurdle due to the prohibitively large size of Document Object Model (DOM) structures, often ranging from 10,000 to 100,000 tokens. Existing strategies typically rely on crude DOM truncation -- risking the loss of critical information -- or employ inefficient heuristics and separate ranking models, failing to achieve an optimal balance between precision and scalability. To address these challenges, we introduce Prune4Web, a novel paradigm that shifts DOM processing from resource-intensive LLM reading to efficient programmatic pruning. Central to our approach is DOM Tree Pruning Programming, where an LLM generates executable Python scoring scripts to dynamically filter DOM elements based on semantic cues from decomposed sub-tasks. This mechanism eliminates the need for LLMs to ingest raw, massive DOMs, instead delegating traversal and scoring to lightweight, interpretable programs. This methodology achieves a 25x to 50x reduction in candidate elements for grounding, thereby facilitating precise action localization while mitigating attention dilution. Furthermore, we propose a specialized data annotation pipeline and a two-turn dialogue training strategy that jointly optimizes the Planner, Programmatic Filter, and Grounder within a unified framework. Extensive experiments demonstrate state-of-the-art performance. Notably, on our low-level grounding task, Prune4Web dramatically improves accuracy from 46.8% to 88.28%, underscoring its efficacy in real-world web automation.

</details>


### [25] [New Hybrid Heuristics for Pseudo-Boolean Propagation](https://arxiv.org/abs/2511.21417)
*Mia Müßig,Jan Johannsen*

Main category: cs.AI

TL;DR: 本文提出了新的启发式方法来改进伪布尔求解中的混合单元传播策略，显著提升了RoundingSAT求解器的性能。


<details>
  <summary>Details</summary>
Motivation: 当前伪布尔求解中最成功的单元传播策略是观察字面量方案与计数方法的混合模式，但现有方法仍有改进空间。

Method: 为混合决策引入了新的启发式方法，优化了观察字面量方案与计数方法的结合方式。

Result: 新启发式方法能够显著超越RoundingSAT求解器中当前的方法性能。

Conclusion: 新的混合决策启发式方法在伪布尔求解中具有显著优势，能够大幅提升求解器性能。

Abstract: In pseudo-boolean solving the currently most successful unit propagation strategy is a hybrid mode combining the watched literal scheme with the counting method. This short paper introduces new heuristics for this hybrid decision, which are able to drastically outperform the current method in the RoundingSAT solver.

</details>


### [26] [Conversational no-code and multi-agentic disease module identification and drug repurposing prediction with ChatDRex](https://arxiv.org/abs/2511.21438)
*Simon Süwer,Kester Bagemihl,Sylvie Baier,Lucia Dicunta,Markus List,Jan Baumbach,Andreas Maier,Fernando M. Delgado-Chaves*

Main category: cs.AI

TL;DR: ChatDRex是一个基于对话的多智能体系统，通过自然语言访问生物医学知识图谱，实现网络药物重定位预测，使非计算机专家也能进行复杂生物信息学分析。


<details>
  <summary>Details</summary>
Motivation: 传统药物重定位预测需要多领域专家协作，工具分散且数据异构，工作流程不顺畅。需要开发一个能让临床专家无需计算机专业知识就能进行复杂分析的系统。

Method: 基于NeDRex知识图谱构建多智能体系统，包括查询路由、数据检索、算法执行、结果可视化等专门智能体，配备推理模块进行幻觉检测。

Result: 系统提供了自然语言访问生物医学知识图谱的能力，整合了网络分析、药物重定位、功能一致性评估、文献挖掘等多种生物信息学工具。

Conclusion: ChatDRex通过多智能体设计和自然语言接口，使临床专家能够生成假设和探索药物重定位机会，加速新疗法发现，推进个性化医疗和转化研究。

Abstract: Repurposing approved drugs offers a time-efficient and cost-effective alternative to traditional drug development. However, in silico prediction of repurposing candidates is challenging and requires the effective collaboration of specialists in various fields, including pharmacology, medicine, biology, and bioinformatics. Fragmented, specialized algorithms and tools often address only narrow aspects of the overall problem, and heterogeneous, unstructured data landscapes require specialized users to be involved. Hence, these data services do not integrate smoothly across workflows. With ChatDRex, we present a conversation-based, multi-agent system that facilitates the execution of complex bioinformatic analyses aiming for network-based drug repurposing prediction. It builds on the integrated systems medicine knowledge graph NeDRex. ChatDRex provides natural language access to its extensive biomedical KG and integrates bioinformatics agents for network analysis and drug repurposing, complemented by agents for functional coherence evaluation for in silico validation, as well as agents for literature mining and for discussing the obtained results in a scientific context. Its flexible multi-agent design assigns specific tasks to specialized agents, including query routing, data retrieval, algorithm execution, and result visualization. A dedicated reasoning module keeps the user in the loop and allows for hallucination detection. By enabling physicians and researchers without computer science expertise to control complex analyses in natural language, ChatDRex democratizes access to bioinformatics as an important resource for drug repurposing. It enables clinical experts to generate hypotheses and explore drug repurposing opportunities, ultimately accelerating the discovery of novel therapies and advancing personalized medicine and translational research.

</details>


### [27] [EWE: An Agentic Framework for Extreme Weather Analysis](https://arxiv.org/abs/2511.21444)
*Zhe Jiang,Jiong Wang,Xiaoyu Yue,Zijie Guo,Wenlong Zhang,Fenghua Ling,Wanli Ouyang,Lei Bai*

Main category: cs.AI

TL;DR: 提出了首个极端天气智能诊断代理框架EWE，通过知识引导规划、闭环推理和气象工具包，从原始气象数据自动生成多模态可视化并进行诊断分析，突破了传统人工诊断的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 极端天气事件对全球社会构成日益严重的威胁，但传统专家驱动的人工诊断方式存在分析瓶颈，阻碍了科学进展。虽然AI在地球科学预测方面取得进展，但自动诊断推理这一同等重要的挑战尚未被充分探索。

Method: 开发了EWE智能代理框架，通过知识引导规划模拟专家工作流程，采用闭环推理机制和专门设计的气象工具包，能够从原始气象数据自主生成和解释多模态可视化。

Result: 建立了该新兴领域的首个基准测试，包含103个高影响事件的精选数据集和新的逐步评估指标。EWE展示了自动科学发现的潜力。

Conclusion: EWE标志着向自动科学发现迈出了一步，有望民主化专业知识和智力资源，特别是对易受极端天气影响的发展中国家具有重要意义。

Abstract: Extreme weather events pose escalating risks to global society, underscoring the urgent need to unravel their underlying physical mechanisms. Yet the prevailing expert-driven, labor-intensive diagnostic paradigm has created a critical analytical bottleneck, stalling scientific progress. While AI for Earth Science has achieved notable advances in prediction, the equally essential challenge of automated diagnostic reasoning remains largely unexplored. We present the Extreme Weather Expert (EWE), the first intelligent agent framework dedicated to this task. EWE emulates expert workflows through knowledge-guided planning, closed-loop reasoning, and a domain-tailored meteorological toolkit. It autonomously produces and interprets multimodal visualizations from raw meteorological data, enabling comprehensive diagnostic analyses. To catalyze progress, we introduce the first benchmark for this emerging field, comprising a curated dataset of 103 high-impact events and a novel step-wise evaluation metric. EWE marks a step toward automated scientific discovery and offers the potential to democratize expertise and intellectual resources, particularly for developing nations vulnerable to extreme weather.

</details>


### [28] [MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning](https://arxiv.org/abs/2511.21460)
*Junjian Wang,Lidan Zhao,Xi Sheryl Zhang*

Main category: cs.AI

TL;DR: 提出MADRA框架，通过多智能体辩论进行风险评估，无需训练即可提升安全性，同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法计算成本高或过度拒绝安全指令的问题，确保具身AI在家庭环境中的安全部署。

Method: 使用多个LLM智能体辩论指令安全性，关键评估器根据逻辑性、风险识别、证据质量和清晰度评分，通过迭代审议和共识投票决策。

Result: 在AI2-THOR和VirtualHome实验中，拒绝90%以上危险任务，同时保持低安全任务拒绝率，优于现有方法。

Conclusion: 提供了可扩展、模型无关的可信具身智能体解决方案。

Abstract: Ensuring the safety of embodied AI agents during task planning is critical for real-world deployment, especially in household environments where dangerous instructions pose significant risks. Existing methods often suffer from either high computational costs due to preference alignment training or over-rejection when using single-agent safety prompts. To address these limitations, we propose MADRA, a training-free Multi-Agent Debate Risk Assessment framework that leverages collective reasoning to enhance safety awareness without sacrificing task performance. MADRA employs multiple LLM-based agents to debate the safety of a given instruction, guided by a critical evaluator that scores responses based on logical soundness, risk identification, evidence quality, and clarity. Through iterative deliberation and consensus voting, MADRA significantly reduces false rejections while maintaining high sensitivity to dangerous tasks. Additionally, we introduce a hierarchical cognitive collaborative planning framework that integrates safety, memory, planning, and self-evolution mechanisms to improve task success rates through continuous learning. We also contribute SafeAware-VH, a benchmark dataset for safety-aware task planning in VirtualHome, containing 800 annotated instructions. Extensive experiments on AI2-THOR and VirtualHome demonstrate that our approach achieves over 90% rejection of unsafe tasks while ensuring that safe-task rejection is low, outperforming existing methods in both safety and execution efficiency. Our work provides a scalable, model-agnostic solution for building trustworthy embodied agents.

</details>


### [29] [SpatialBench: Benchmarking Multimodal Large Language Models for Spatial Cognition](https://arxiv.org/abs/2511.21471)
*Peiran Xu,Sudong Wang,Yao Zhu,Jianing Li,Yunjian Zhang*

Main category: cs.AI

TL;DR: 提出了一个分层空间认知框架，将空间智能分解为五个渐进复杂层次，并构建了SpatialBench基准来系统评估多模态大语言模型的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准过度简化空间认知，将其简化为单一维度指标，无法捕捉空间能力的层次结构和相互依赖关系。

Method: 构建分层空间认知框架（五个认知层次），开发SpatialBench基准（15个任务），引入高层次能力导向的统一评估指标。

Result: 实验显示模型在感知层面表现良好，但在符号推理、因果推断和规划方面存在局限；人类测试表明人类进行选择性目标导向抽象，而MLLMs倾向于过度关注表面细节。

Conclusion: 建立了首个系统测量MLLMs分层空间认知的框架，为未来空间智能系统奠定基础。

Abstract: Spatial cognition is fundamental to real-world multimodal intelligence, allowing models to effectively interact with the physical environment. While multimodal large language models (MLLMs) have made significant strides, existing benchmarks often oversimplify spatial cognition, reducing it to a single-dimensional metric, which fails to capture the hierarchical structure and interdependence of spatial abilities. To address this gap, we propose a hierarchical spatial cognition framework that decomposes spatial intelligence into five progressively complex levels from basic observation to high-level planning. Building upon this taxonomy, we construct SpatialBench, a large-scale, fine-grained benchmark covering 15 tasks aligned with these cognitive levels. To provide a unified evaluation across heterogeneous tasks, we further introduce a high-level capability-oriented metric that reliably assesses a model's overall spatial reasoning ability. Extensive experiments over massive MLLMs reveal distinct performance stratification across cognitive levels: models exhibit strong perceptual grounding yet remain limited in symbolic reasoning, causal inference, and planning. Additional human tests demonstrate that humans perform selective, goal-directed abstraction, while MLLMs tend to over-attend to surface details without coherent spatial intent. Our work establishes the first systematic framework for measuring hierarchical spatial cognition in MLLMs, laying the foundation for future spatially intelligent systems.

</details>


### [30] [Pessimistic Verification for Open Ended Math Questions](https://arxiv.org/abs/2511.21522)
*Yanxing Huang,Zihan Tang,Zejin Lin,Peng Li,Yang Liu*

Main category: cs.AI

TL;DR: 提出悲观验证方法，通过构建多个并行验证来检测数学证明中的错误，显著提升验证性能且计算资源消耗低


<details>
  <summary>Details</summary>
Motivation: 现有验证性能的关键限制在于错误检测能力，需要更有效的验证方法来提高数学问题的可靠性

Method: 设计悲观验证变体，为同一证明构建多个并行验证，只要任一验证报告错误即判定证明不正确

Result: 该方法在多个数学验证基准上显著提升性能，token效率甚至超过扩展长链思维，且发现数据集中存在标注错误

Conclusion: 悲观验证能有效提高语言模型输出的可靠性，对实现长视野数学任务至关重要，有助于增强语言模型的数学能力

Abstract: The key limitation of the verification performance lies in the ability of error detection. With this intuition we designed several variants of pessimistic verification, which are simple workflows that could significantly improve the verification of open-ended math questions. In pessimistic verification we construct multiple parallel verifications for the same proof, and the proof is deemed incorrect if any one of them reports an error. This simple technique significantly improves the performance across many math verification benchmarks without incurring substantial computational resources. Its token efficiency even surpassed extended long-CoT in test-time scaling. Our case studies further indicate that the majority of false negatives in stronger models are actually caused by annotation errors in the original dataset, so our method's performance is in fact underestimated. Self-verification for mathematical problems can effectively improve the reliability and performance of language model outputs, and it also plays a critical role in enabling long-horizon mathematical tasks. We believe that research on pessimistic verification will help enhance the mathematical capabilities of language models across a wide range of tasks.

</details>


### [31] [Self-Transparency Failures in Expert-Persona LLMs: A Large-Scale Behavioral Audit](https://arxiv.org/abs/2511.21569)
*Alex Diep*

Main category: cs.AI

TL;DR: 语言模型在专业角色中AI身份披露存在严重不一致性，金融顾问角色披露率30.8%，神经外科医生仅3.5%，可能引发用户过度信任的"反向盖尔曼遗忘症"效应。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在专业角色中可靠披露AI身份的能力，因为在高风险领域虚假专业知识可能对用户造成伤害，用户需要了解模型的能力边界。

Method: 采用共同花园设计，对16个开放权重模型（4B-671B参数）进行19,200次试验审计，使用贝叶斯验证和Rogan-Gladen校正确保测量误差稳健性。

Result: 模型披露率从2.8%到73.6%不等，14B模型达61.4%而70B模型仅4.1%；推理优化会主动抑制自我透明度，推理变体比基础版本披露率降低高达48.4%。

Conclusion: 透明度反映训练因素而非规模，组织不能假设安全属性会转移到部署环境，需要刻意行为设计和经验验证。

Abstract: If a language model cannot reliably disclose its AI identity in expert contexts, users cannot trust its competence boundaries. This study examines self-transparency in models assigned professional personas within high-stakes domains where false expertise risks user harm. Using a common-garden design, sixteen open-weight models (4B--671B parameters) were audited across 19,200 trials. Models exhibited sharp domain-specific inconsistency: a Financial Advisor persona elicited 30.8% disclosure initially, while a Neurosurgeon persona elicited only 3.5%. This creates preconditions for a "Reverse Gell-Mann Amnesia" effect, where transparency in some domains leads users to overgeneralize trust to contexts where disclosure fails. Disclosure ranged from 2.8% to 73.6%, with a 14B model reaching 61.4% while a 70B produced just 4.1%. Model identity predicted behavior better than parameter count ($ΔR_{adj}^{2} = 0.359$ vs 0.018). Reasoning optimization actively suppressed self-transparency in some models, with reasoning variants showing up to 48.4% lower disclosure than base counterparts. Bayesian validation with Rogan--Gladen correction confirmed robustness to measurement error ($κ= 0.908$). These findings demonstrate transparency reflects training factors rather than scale. Organizations cannot assume safety properties transfer to deployment contexts, requiring deliberate behavior design and empirical verification.

</details>


### [32] [From Prediction to Foresight: The Role of AI in Designing Responsible Futures](https://arxiv.org/abs/2511.21570)
*Maria Perez-Ortiz*

Main category: cs.AI

TL;DR: 本文提出"负责任计算预见"概念，探讨人工智能在负责任预见中的作用，强调AI作为支持工具增强而非替代政策制定者判断，以应对21世纪重大挑战。


<details>
  <summary>Details</summary>
Motivation: 在技术快速发展和全球挑战复杂的时代，负责任预见成为政策制定者应对未来不确定性和塑造未来的重要框架。

Method: 建立负责任计算预见的基础原则，提出一套AI驱动的预见工具，结合模拟和情景分析来增强政策制定能力。

Result: AI与模拟和情景分析结合，能增强政策制定者应对不确定性、评估风险和制定可持续、有韧性未来策略的能力。

Conclusion: AI应作为负责任、以人为本的预见中的支持工具，补充而非替代政策制定者判断，实现有韧性和道德健全的未来塑造。

Abstract: In an era marked by rapid technological advancements and complex global challenges, responsible foresight has emerged as an essential framework for policymakers aiming to navigate future uncertainties and shape the future. Responsible foresight entails the ethical anticipation of emerging opportunities and risks, with a focus on fostering proactive, sustainable, and accountable future design. This paper coins the term "responsible computational foresight", examining the role of human-centric artificial intelligence and computational modeling in advancing responsible foresight, establishing a set of foundational principles for this new field and presenting a suite of AI-driven foresight tools currently shaping it. AI, particularly in conjunction with simulations and scenario analysis, enhances policymakers' ability to address uncertainty, evaluate risks, and devise strategies geared toward sustainable, resilient futures. However, responsible foresight extends beyond mere technical forecasting; it demands a nuanced understanding of the interdependencies within social, environmental, economic and political systems, alongside a commitment to ethical, long-term decision-making that supports human intelligence. We argue that AI will play a role as a supportive tool in responsible, human-centered foresight, complementing rather than substituting policymaker judgment to enable the proactive shaping of resilient and ethically sound futures. This paper advocates for the thoughtful integration of AI into foresight practices to empower policymakers and communities as they confront the grand challenges of the 21st century.

</details>


### [33] [On the Limits of Innate Planning in Large Language Models](https://arxiv.org/abs/2511.21591)
*Charles Schepanowski,Charles Ling*

Main category: cs.AI

TL;DR: LLMs在8-puzzle任务中表现出状态跟踪和规划能力的显著局限性，即使有外部验证器辅助也无法解决任何谜题，主要问题是脆弱的状态表示和弱启发式规划。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在没有代码执行或其他工具的情况下，进行规划和状态推理的能力，使用8-puzzle作为测试平台来精确评估这些能力。

Method: 在四种模型上测试常见提示条件（零样本、思维链、算法思维）和分层纠正反馈，然后使用外部移动验证器提供有效移动。

Result: 反馈提高了某些模型-提示组合的成功率，但许多成功运行时间长、计算成本高且间接。即使有外部验证器辅助，所有模型都无法解决任何谜题。

Conclusion: 当前LLMs在规划方面存在重大限制，需要开发维护显式状态和执行结构化搜索的机制才能取得进一步进展。

Abstract: Large language models (LLMs) achieve impressive results on many benchmarks, yet their capacity for planning and stateful reasoning remains unclear. We study these abilities directly, without code execution or other tools, using the 8-puzzle: a classic task that requires state tracking and goal-directed planning while allowing precise, step-by-step evaluation. Four models are tested under common prompting conditions (Zero-Shot, Chain-of-Thought, Algorithm-of-Thought) and with tiered corrective feedback. Feedback improves success rates for some model-prompt combinations, but many successful runs are long, computationally expensive, and indirect. We then examine the models with an external move validator that provides only valid moves. Despite this level of assistance, none of the models solve any puzzles in this setting. Qualitative analysis reveals two dominant deficits across all models: (1) brittle internal state representations, leading to frequent invalid moves, and (2) weak heuristic planning, with models entering loops or selecting actions that do not reduce the distance to the goal state. These findings indicate that, in the absence of external tools such as code interpreters, current LLMs have substantial limitations in planning and that further progress may require mechanisms for maintaining explicit state and performing structured search.

</details>


### [34] [Bridging the Unavoidable A Priori: A Framework for Comparative Causal Modeling](https://arxiv.org/abs/2511.21636)
*Peter S. Hovmand,Kari O'Donnell,Callie Ogland-Hand,Brian Biroscak,Douglas D. Gunzler*

Main category: cs.AI

TL;DR: 该论文提出了一个将系统动力学和结构方程建模结合到共同数学框架中的方法，用于支持负责任AI/ML的开发。


<details>
  <summary>Details</summary>
Motivation: AI/ML模型在解决未解决问题时带来了创新，但也放大了人类偏见。负责任AI/ML倡导者希望利用更丰富的系统动力学因果模型来指导开发，但不同方法基于不同假设的整合存在困难。

Method: 将系统动力学和结构方程建模结合到一个共同的数学框架中，用于生成系统分布、开发方法并比较结果。

Result: 建立了一个统一的数学框架，能够整合两种方法，为数据科学和AI/ML应用提供系统动力学的认识论基础。

Conclusion: 该框架有助于克服不同方法假设的障碍，为负责任AI/ML的发展提供更全面的系统视角。

Abstract: AI/ML models have rapidly gained prominence as innovations for solving previously unsolved problems and their unintended consequences from amplifying human biases. Advocates for responsible AI/ML have sought ways to draw on the richer causal models of system dynamics to better inform the development of responsible AI/ML. However, a major barrier to advancing this work is the difficulty of bringing together methods rooted in different underlying assumptions (i.e., Dana Meadow's "the unavoidable a priori"). This paper brings system dynamics and structural equation modeling together into a common mathematical framework that can be used to generate systems from distributions, develop methods, and compare results to inform the underlying epistemology of system dynamics for data science and AI/ML applications.

</details>


### [35] [Agentic Learner with Grow-and-Refine Multimodal Semantic Memory](https://arxiv.org/abs/2511.21678)
*Weihao Bo,Shan Zhang,Yanpeng Sun,Jingjing Wu,Qunyi Xie,Xiao Tan,Kunbin Chen,Wei He,Xiaofan Li,Na Zhao,Jingdong Wang,Zechao Li*

Main category: cs.AI

TL;DR: ViLoMem是一个双流记忆框架，通过分别编码视觉分心模式和逻辑推理错误，使MLLMs能够从成功和失败经验中学习，在六个多模态基准上显著提高准确率并减少重复错误。


<details>
  <summary>Details</summary>
Motivation: 现有基于轨迹的记忆方法存在简洁性偏差，逐渐丢失关键领域知识，且仅记录单模态行为轨迹，无法保存视觉注意力和逻辑推理如何共同贡献于解决方案，这与人类认知的多模态集成特性不符。

Method: 引入ViLoMem双流记忆框架，分别编码视觉分心模式和逻辑推理错误，采用增长-精炼原则逐步积累和更新多模态语义知识，保持稳定可泛化策略同时避免灾难性遗忘。

Result: 在六个多模态基准测试中，ViLoMem持续提高pass@1准确率，显著减少重复的视觉和逻辑错误。消融实验证实了具有明确分心-幻觉分离的双流记忆的必要性。

Conclusion: ViLoMem证明了错误感知多模态记忆对于终身和跨领域智能学习的重要价值，通过双流记忆架构有效提升了MLLMs的学习能力。

Abstract: MLLMs exhibit strong reasoning on isolated queries, yet they operate de novo -- solving each problem independently and often repeating the same mistakes. Existing memory-augmented agents mainly store past trajectories for reuse. However, trajectory-based memory suffers from brevity bias, gradually losing essential domain knowledge. More critically, even in truly multimodal problem-solving settings, it records only a single-modality trace of past behavior, failing to preserve how visual attention and logical reasoning jointly contributed to the solution. This is fundamentally misaligned with human cognition: semantic memory is both multimodal and integrated, preserving visual and abstract knowledge through coordinated but distinct representational streams. We thus introduce ViLoMem, a dual-stream memory framework that constructs compact, schema-based memory. It separately encodes visual distraction patterns and logical reasoning errors, enabling MLLMs to learn from their successful and failed experiences. Following a grow-and-refine principle, the system incrementally accumulates and updates multimodal semantic knowledge -- preserving stable, generalizable strategies while avoiding catastrophic forgetting. Across six multimodal benchmarks, ViLoMem consistently improves pass@1 accuracy and substantially reduces repeated visual and logical errors. Ablations confirm the necessity of dual-stream memory with explicit distraction--hallucination separation, demonstrating the value of error-aware multimodal memory for lifelong and cross-domain agentic learning. Our project page will be available at https://weihao-bo.github.io/ViLoMeo-page.

</details>
