{"id": "2510.06901", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.06901", "abs": "https://arxiv.org/abs/2510.06901", "authors": ["Fangzhou Zhao", "Yao Sun", "Jianglin Lan", "Lan Zhang", "Xuesong Liu", "Muhammad Ali Imran"], "title": "Adaptive Semantic Communication for UAV/UGV Cooperative Path Planning", "comment": null, "summary": "Effective path planning is fundamental to the coordination of unmanned aerial\nvehicles (UAVs) and unmanned ground vehicles (UGVs) systems, particularly in\napplications such as surveillance, navigation, and emergency response.\nCombining UAVs' broad field of view with UGVs' ground-level operational\ncapability greatly improve the likelihood of successfully achieving task\nobjectives such as locating victims, monitoring target areas, or navigating\nhazardous terrain. In complex environments, UAVs need to provide precise\nenvironmental perception information for UGVs to optimize their routing policy.\nHowever, due to severe interference and non-line-of-sight conditions, wireless\ncommunication is often unstable in such complex environments, making it\ndifficult to support timely and accurate path planning for UAV-UGV\ncoordination. To this end, this paper proposes a semantic communication\n(SemCom) framework to enhance UAV/UGV cooperative path planning under\nunreliable wireless conditions. Unlike traditional methods that transmit raw\ndata, SemCom transmits only the key information for path planning, reducing\ntransmission volume without sacrificing accuracy. The proposed framework is\ndeveloped by defining key semantics for path planning and designing a\ntransceiver for meeting the requirements of UAV-UGV cooperative path planning.\nSimulation results show that, compared to conventional SemCom transceivers, the\nproposed transceiver significantly reduces data transmission volume while\nmaintaining path planning accuracy, thereby enhancing system collaboration\nefficiency."}
{"id": "2510.06916", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.06916", "abs": "https://arxiv.org/abs/2510.06916", "authors": ["Fangzhou Zhao", "Yao Sun", "Jianglin Lan", "Muhammad Ali Imran"], "title": "Dynamic Control Aware Semantic Communication Enabled Image Transmission for Lunar Landing", "comment": null, "summary": "The primary challenge in autonomous lunar landing missions lies in the\nunreliable local control system, which has limited capacity to handle\nhigh-dynamic conditions, severely affecting landing precision and safety.\nRecent advancements in lunar satellite communication make it possible to\nestablish a wireless link between lunar orbit satellites and the lunar lander.\nThis enables satellites to run high-performance autonomous landing algorithms,\nimproving landing accuracy while reducing the lander's computational and\nstorage load. Nevertheless, traditional communication paradigms are not\ndirectly applicable due to significant temperature fluctuations on the lunar\nsurface, intense solar radiation, and severe interference caused by lunar dust\non hardware. The emerging technique of semantic communication (SemCom) offers\nsignificant advantages in robustness and resource efficiency, particularly\nunder harsh channel conditions. In this paper, we introduce a novel SemCom\nframework for transmitting images from the lander to satellites operating the\nremote landing control system. The proposed encoder-decoder dynamically adjusts\nthe transmission strategy based on real-time feedback from the lander's control\nalgorithm, ensuring the accurate delivery of critical image features and\nenhancing control reliability. We provide a rigorous theoretical analysis of\nthe conditions that improve the accuracy of the control algorithm and reduce\nend-to-end transmission time under the proposed framework. Simulation results\ndemonstrate that our SemCom method significantly enhances autonomous landing\nperformance compared to traditional communication methods."}
{"id": "2510.07292", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.07292", "abs": "https://arxiv.org/abs/2510.07292", "authors": ["Tiago Silva", "António Grilo"], "title": "A Genetic Algorithm Approach to Anti-Jamming UAV Swarm Behavior", "comment": "8 pages, conference paper", "summary": "In recent years, Unmanned Aerial Vehicles (UAVs) have brought a new true\nrevolution to military tactics. While UAVs already constitute an advantage when\noperating alone, multi-UAV swarms expand the available possibilities, allowing\nthe UAVs to collaborate and support each other as a team to carry out a given\ntask. This entails the capability to exchange information related with\nsituation awareness and action coordination by means of a suitable wireless\ncommunication technology. In such scenario, the adversary is expected to\ndisrupt communications by jamming the communication channel. The latter becomes\nthe Achilles heel of the swarm. While anti-jamming techniques constitute a well\ncovered topic in the literature, the use of intelligent swarm behaviors to\nleverage those techniques is still an open research issue.\n  This paper explores the use of Genetic Algorithms (GAs) to jointly optimize\nUAV swarm formation, beam-steering antennas and traffic routing in order to\nmitigate the effect of jamming in the main coordination channel, under the\nassumption that a more robust and low data rate channel is used for formation\nmanagement signaling. Simulation results show the effectiveness of proposed\napproach. However, the significant computational cost paves the way for further\nresearch."}
{"id": "2510.06342", "categories": ["cs.IT", "math-ph", "math.IT", "math.MP", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.06342", "abs": "https://arxiv.org/abs/2510.06342", "authors": ["Ludovico Lami"], "title": "A doubly composite Chernoff-Stein lemma and its applications", "comment": "50+4 pages", "summary": "Given a sequence of random variables $X^n=X_1,\\ldots, X_n$, discriminating\nbetween two hypotheses on the underlying probability distribution is a key task\nin statistics and information theory. Of interest here is the Stein exponent,\ni.e. the largest rate of decay (in $n$) of the type II error probability for a\nvanishingly small type I error probability. When the hypotheses are simple and\ni.i.d., the Chernoff-Stein lemma states that this is given by the relative\nentropy between the single-copy probability distributions. Generalisations of\nthis result exist in the case of composite hypotheses, but mostly to settings\nwhere the probability distribution of $X^n$ is not genuinely correlated, but\nrather, e.g., a convex combination of product distributions with components\ntaken from a base set. Here, we establish a general Chernoff-Stein lemma that\napplies to the setting where both hypotheses are composite and genuinely\ncorrelated, satisfying only generic assumptions such as convexity (on both\nhypotheses) and some weak form of permutational symmetry (on either\nhypothesis). Our result, which strictly subsumes most prior work, is proved\nusing a refinement of the blurring technique developed in the context of the\ngeneralised quantum Stein's lemma [Lami, IEEE Trans. Inf. Theory 2025]. In this\nrefined form, blurring is applied symbol by symbol, which makes it both\nstronger and applicable also in the absence of permutational symmetry. The\nsecond part of the work is devoted to applications: we provide a single-letter\nformula for the Stein exponent characterising the discrimination of broad\nfamilies of null hypotheses vs a composite i.i.d. or an arbitrarily varying\nalternative hypothesis, and establish a 'constrained de Finetti reduction'\nstatement that covers a wide family of convex constraints. Applications to\nquantum hypothesis testing are explored in a related paper [Lami, arXiv:today]."}
{"id": "2510.06622", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.06622", "abs": "https://arxiv.org/abs/2510.06622", "authors": ["Ni Ding", "Farhad Farokhi", "Tao Guo", "Yinfei Xu", "Xiang Zhang"], "title": "$α$-leakage Interpretation of Rényi Capacity", "comment": null, "summary": "For $\\tilde{f}(t) = \\exp(\\frac{\\alpha-1}{\\alpha}t)$, this paper shows that\nthe Sibson mutual information is an $\\alpha$-leakage averaged over the\nadversary's $\\tilde{f}$-mean relative information gain (on the secret) at\nelementary event of channel output $Y$ as well as the joint occurrence of\nelementary channel input $X$ and output $Y$. This interpretation is used to\nderive a sufficient condition that achieves a $\\delta$-approximation of\n$\\epsilon$-upper bounded $\\alpha$-leakage. A $Y$-elementary $\\alpha$-leakage is\nproposed, extending the existing pointwise maximal leakage to the overall\nR\\'{e}nyi order range $\\alpha \\in [0,\\infty)$. Maximizing this $Y$-elementary\nleakage over all attributes $U$ of channel input $X$ gives the R\\'{e}nyi\ndivergence. Further, the R\\'{e}nyi capacity is interpreted as the maximal\n$\\tilde{f}$-mean information leakage over both the adversary's malicious\ninference decision and the channel input $X$ (represents the adversary's prior\nbelief). This suggests an alternating max-max implementation of the existing\ngeneralized Blahut-Arimoto method."}
{"id": "2510.06261", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06261", "abs": "https://arxiv.org/abs/2510.06261", "authors": ["Zhanke Zhou", "Chentao Cao", "Xiao Feng", "Xuan Li", "Zongze Li", "Xiangyu Lu", "Jiangchao Yao", "Weikai Huang", "Linrui Xu", "Tian Cheng", "Guanyu Jiang", "Yiming Zheng", "Brando Miranda", "Tongliang Liu", "Sanmi Koyejo", "Masashi Sugiyama", "Bo Han"], "title": "AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning", "comment": "Ongoing project", "summary": "We present AlphaApollo, a self-evolving agentic reasoning system that aims to\naddress two bottlenecks in foundation model (FM) reasoning-limited\nmodel-intrinsic capacity and unreliable test-time iteration. AlphaApollo\norchestrates multiple models with professional tools to enable deliberate,\nverifiable reasoning. It couples (i) a computation tool (Python with numerical\nand symbolic libraries) and (ii) a retrieval tool (task-relevant external\ninformation) to execute exact calculations and ground decisions. The system\nfurther supports multi-round, multi-model solution evolution via a shared state\nmap that records candidates, executable checks, and feedback for iterative\nrefinement. In evaluations on AIME 2024/2025 across multiple models,\nAlphaApollo delivers consistent gains: +5.15% Average@32 and +23.34% Pass@32\nfor Qwen2.5-14B-Instruct, and +8.91% Average@32 with +26.67% Pass@32 for\nLlama-3.3-70B-Instruct. Tool-use analysis shows that more than 80% of tool\ncalls are successfully executed, with consistent outperformance of non-tool\nbaselines, thereby lifting the capability ceiling of FMs. More empirical\nresults and implementation details will be updated at\nhttps://github.com/tmlr-group/AlphaApollo."}
{"id": "2510.07292", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.07292", "abs": "https://arxiv.org/abs/2510.07292", "authors": ["Tiago Silva", "António Grilo"], "title": "A Genetic Algorithm Approach to Anti-Jamming UAV Swarm Behavior", "comment": "8 pages, conference paper", "summary": "In recent years, Unmanned Aerial Vehicles (UAVs) have brought a new true\nrevolution to military tactics. While UAVs already constitute an advantage when\noperating alone, multi-UAV swarms expand the available possibilities, allowing\nthe UAVs to collaborate and support each other as a team to carry out a given\ntask. This entails the capability to exchange information related with\nsituation awareness and action coordination by means of a suitable wireless\ncommunication technology. In such scenario, the adversary is expected to\ndisrupt communications by jamming the communication channel. The latter becomes\nthe Achilles heel of the swarm. While anti-jamming techniques constitute a well\ncovered topic in the literature, the use of intelligent swarm behaviors to\nleverage those techniques is still an open research issue.\n  This paper explores the use of Genetic Algorithms (GAs) to jointly optimize\nUAV swarm formation, beam-steering antennas and traffic routing in order to\nmitigate the effect of jamming in the main coordination channel, under the\nassumption that a more robust and low data rate channel is used for formation\nmanagement signaling. Simulation results show the effectiveness of proposed\napproach. However, the significant computational cost paves the way for further\nresearch."}
{"id": "2510.06734", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.06734", "abs": "https://arxiv.org/abs/2510.06734", "authors": ["Fabian Göttsch", "Max Franke", "Arash Pourdamghani", "Giuseppe Caire", "Stefan Schmid"], "title": "Optimizing Fronthaul Quantization for Flexible User Load in Cell-Free Massive MIMO", "comment": null, "summary": "We investigate the physical layer (PHY) spectral efficiency and fronthaul\nnetwork load of a scalable user-centric cell-free massive MIMO system. Each\nuser-centric cluster processor responsible for cluster-level signal processing\nis located at one of multiple decentralized units (DUs). Thus, the radio units\nin the cluster must exchange data with the corresponding DU over the fronthaul.\nBecause the fronthaul links have limited capacity, this data must be quantized\nbefore it is sent over the fronthaul. We consider a routed fronthaul network,\nwhere the cluster processor placement and fronthaul traffic routing are jointly\noptimized with a mixed-integer linear program. For different numbers of users\nin the network, we investigate the effect of fronthaul quantization rates, a\nsystem parameter computed based on rate-distortion theory. Our results show\nthat with optimized quantization rates, the fronthaul load is quite stable for\na wide range of user loads without significant PHY performance loss. This\ndemonstrates that the cell-free massive MIMO PHY and fronthaul network are\nresilient to varying user densities."}
{"id": "2510.06274", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06274", "abs": "https://arxiv.org/abs/2510.06274", "authors": ["Mohammad Mahdi Samiei Paqaleh", "Arash Marioriyad", "Arman Tahmasebi-Zadeh", "Mohamadreza Fereydooni", "Mahdi Ghaznavai", "Mahdieh Soleymani Baghshah"], "title": "Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization", "comment": null, "summary": "Recent progress has pushed AI frontiers from pattern recognition tasks toward\nproblems that require step by step, System2 style reasoning, especially with\nlarge language models. Yet, unlike learning, where generalization and out of\ndistribution (OoD) evaluation concepts are well formalized, there is no clear,\nconsistent definition or metric for reasoning ability. We propose Complexity\nOut of Distribution (Complexity OoD) generalization as a framework and problem\nsetting to define and measure reasoning. A model exhibits Complexity OoD\ngeneralization when it maintains performance on test instances whose minimal\nrequired solution complexity, either representational (richer solution\nstructure) or computational (more reasoning steps/program length), exceeds that\nof all training examples. We formalize complexity via solution description\nKolmogorov complexity and operational proxies (e.g., object/relation counts;\nreasoning step counts), clarifying how Complexity OoD differs from length and\ncompositional OoD. This lens unifies learning and reasoning: many cases\nsolvable with System1 like processing at low complexity become System2 like\nunder complexity pressure, while System2 can be viewed as generalization over\nsolution structures. We translate this perspective into practice with\nrecommendations for operationalizing Complexity OoD across the stack:\nincorporating complexity into benchmark and evaluation metric design,\nrethinking supervision to target solution traces, seeking and designing\ninductive biases for Complexity OoD generalization, addressing learning to\nreason spillovers such as spurious shortcuts, semantic robustness, catastrophic\nforgetting, and step wise calibration. Because Complexity OoD cannot be solved\nby scaling data alone, progress toward robust reasoning will require\narchitectures and training regimes that explicitly model and allocate\ncomputation with respect to complexity."}
{"id": "2510.06868", "categories": ["cs.IT", "cs.AI", "cs.CR", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.06868", "abs": "https://arxiv.org/abs/2510.06868", "authors": ["Didrik Bergström", "Deniz Gündüz", "Onur Günlü"], "title": "Multi-hop Deep Joint Source-Channel Coding with Deep Hash Distillation for Semantically Aligned Image Retrieval", "comment": null, "summary": "We consider image transmission via deep joint source-channel coding\n(DeepJSCC) over multi-hop additive white Gaussian noise (AWGN) channels by\ntraining a DeepJSCC encoder-decoder pair with a pre-trained deep hash\ndistillation (DHD) module to semantically cluster images, facilitating\nsecurity-oriented applications through enhanced semantic consistency and\nimproving the perceptual reconstruction quality. We train the DeepJSCC module\nto both reduce mean square error (MSE) and minimize cosine distance between DHD\nhashes of source and reconstructed images. Significantly improved perceptual\nquality as a result of semantic alignment is illustrated for different\nmulti-hop settings, for which classical DeepJSCC may suffer from noise\naccumulation, measured by the learned perceptual image patch similarity (LPIPS)\nmetric."}
{"id": "2510.06288", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06288", "abs": "https://arxiv.org/abs/2510.06288", "authors": ["Raj Ghugare", "Catherine Ji", "Kathryn Wantlin", "Jin Schofield", "Benjamin Eysenbach"], "title": "BuilderBench -- A benchmark for generalist agents", "comment": "Project page: https://rajghugare19.github.io/builderbench and Code:\n  https://github.com/rajghugare19/builderbench", "summary": "Today's AI models learn primarily through mimicry and sharpening, so it is\nnot surprising that they struggle to solve problems beyond the limits set by\nexisting data. To solve novel problems, agents should acquire skills for\nexploring and learning through experience. Finding a scalable learning\nmechanism for developing agents that learn through interaction remains a major\nopen problem. In this work, we introduce BuilderBench, a benchmark to\naccelerate research into agent pre-training that centers open-ended\nexploration. BuilderBench requires agents to learn how to build any structure\nusing blocks. BuilderBench is equipped with $(1)$ a hardware accelerated\nsimulator of a robotic agent interacting with various physical blocks, and\n$(2)$ a task-suite with over 42 diverse target structures that are carefully\ncurated to test an understanding of physics, mathematics, and long-horizon\nplanning. During training, agents have to explore and learn general principles\nabout the environment without any external supervision. During evaluation,\nagents have to build the unseen target structures from the task suite. Solving\nthese tasks requires a sort of \\emph{embodied reasoning} that is not reflected\nin words but rather in actions, experimenting with different strategies and\npiecing them together. Our experiments show that many of these tasks challenge\nthe current iteration of algorithms. Hence, we also provide a ``training\nwheels'' protocol, in which agents are trained and evaluated to build a single\ntarget structure from the task suite. Finally, we provide single-file\nimplementations of six different algorithms as a reference point for\nresearchers."}
{"id": "2510.06972", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.06972", "abs": "https://arxiv.org/abs/2510.06972", "authors": ["Yanshi Sun", "Zhiguo Ding", "George K. Karagiannidis"], "title": "A Stochastic Geometric Analysis on Multi-cell Pinching-antenna Systems under Blockage Effect", "comment": null, "summary": "Recently, the study on pinching-antenna technique has attracted significant\nattention. However, most relevant literature focuses on a single-cell scenario,\nwhere the effect from the interfering pinching-antennas on waveguides connected\nto spatially distributed base stations (BSs) was ignored. To fulfill this\nknowledge gap, this letter aims to provide an analytical framework on\nperformance evaluation for multi-cell pinching-antenna systems where spatially\ndistributed waveguides which are connected to different BSs are considered. In\nparticular, tools from stochastic geometry is applied for system modeling. The\nexpression for the outage probability is obtained. Simulation results are\nprovided to verify the accuracy of the analysis and demonstrate the superior\nperformance of pinching-antenna system compared to fixed-antenna systems."}
{"id": "2510.06302", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06302", "abs": "https://arxiv.org/abs/2510.06302", "authors": ["Ksenija Lace", "Marite Kirikova"], "title": "Requirements for Game-Based Learning Design Framework for Information System Integration in the Context of Post-Merger Integration", "comment": null, "summary": "Post-merger integration states unique challenges for professionals\nresponsible for information system integration aimed on alignment and\ncombination diverse system architectures of merging organizations. Although the\ntheoretical and practical guidance exists for post-merger integration on the\nbusiness level, there is a significant gap in training for information system\nintegration in this context. In prior research specific methods AMILI (Support\nmethod for informed decision identification) and AMILP (Support method for\ninformed decision-making) were introduced for the support of information system\nintegration decisions in the post-merger integration. But during the practical\napplication was reported high learning curve and low learner motivation. This\npaper explores how game-based learning design can address these limitations by\ntransforming static method training into engaging learning experience. The\nstudy analyzes foundational learning theories, cognitive load and motivation\nmodels, and serious game design frameworks to identify the essential\nrequirements for a game-based learning design framework tailored to information\nsystem integration in post-merger integration. Requirements are structured in\ntwo components: the transformation process and resulting learning experience.\nThe paper concludes with a plan for developing and evaluating the proposed\nframework through iterative design and real-world validation."}
{"id": "2510.07015", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.07015", "abs": "https://arxiv.org/abs/2510.07015", "authors": ["Jonas G. Matt", "Pengcheng Huang", "Balz Maag"], "title": "Lossless Compression of Time Series Data: A Comparative Study", "comment": null, "summary": "Our increasingly digital and connected world has led to the generation of\nunprecedented amounts of data. This data must be efficiently managed,\ntransmitted, and stored to preserve resources and allow scalability. Data\ncompression has therein been a key technology for a long time, resulting in a\nvast landscape of available techniques. This largest-to-date study analyzes and\ncompares various lossless data compression methods for time series data. We\npresent a unified framework encompassing two stages: data transformation and\nentropy encoding. We evaluate compression algorithms across both synthetic and\nreal-world datasets with varying characteristics. Through ablation studies at\neach compression stage, we isolate the impact of individual components on\noverall compression performance -- revealing the strengths and weaknesses of\ndifferent algorithms when facing diverse time series properties. Our study\nunderscores the importance of well-configured and complete compression\npipelines beyond individual components or algorithms; it offers a comprehensive\nguide for selecting and composing the most appropriate compression algorithms\ntailored to specific datasets."}
{"id": "2510.06307", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06307", "abs": "https://arxiv.org/abs/2510.06307", "authors": ["Wentao Deng", "Jiahuan Pei", "Zhiwei Xu", "Zhaochun Ren", "Zhumin Chen", "Pengjie Ren"], "title": "Belief-Calibrated Multi-Agent Consensus Seeking for Complex NLP Tasks", "comment": "This paper has been accepted by NeurIPS 2025", "summary": "A multi-agent system (MAS) enhances its capacity to solve complex natural\nlanguage processing (NLP) tasks through collaboration among multiple agents,\nwhere consensus-seeking serves as a fundamental mechanism. However, existing\nconsensus-seeking approaches typically rely on voting mechanisms to judge\nconsensus, overlooking contradictions in system-internal beliefs that\ndestabilize the consensus. Moreover, these methods often involve agents\nupdating their results through indiscriminate collaboration with every other\nagent. Such uniform interaction fails to identify the optimal collaborators for\neach agent, hindering the emergence of a stable consensus. To address these\nchallenges, we provide a theoretical framework for selecting optimal\ncollaborators that maximize consensus stability. Based on the theorems, we\npropose the Belief-Calibrated Consensus Seeking (BCCS) framework to facilitate\nstable consensus via selecting optimal collaborators and calibrating the\nconsensus judgment by system-internal beliefs. Experimental results on the MATH\nand MMLU benchmark datasets demonstrate that the proposed BCCS framework\noutperforms the best existing results by 2.23% and 3.95% of accuracy on\nchallenging tasks, respectively. Our code and data are available at\nhttps://github.com/dengwentao99/BCCS."}
{"id": "2510.07044", "categories": ["cs.IT", "math.IT", "68P20, 94A12, 62J"], "pdf": "https://arxiv.org/pdf/2510.07044", "abs": "https://arxiv.org/abs/2510.07044", "authors": ["Hendrik Bernd Zarucha", "Peter Jung", "Giuseppe Caire"], "title": "Robustness of Covariance Estimators with Application in Activity Detection", "comment": "27 pages, 1 figure, 4 subfigures", "summary": "The first part of this work considers a general class of covariance\nestimators. Each estimator of that class is generated by a real-valued function\n$g$ and a set of model covariance matrices $H$. If $\\bf{W}$ is a potentially\nperturbed observation of a searched covariance matrix, then the estimator is\nthe minimizer of the sum of $g$ applied to each eigenvalue of\n$\\bf{W}^\\frac{1}{2}\\bf{Z}^{-1}\\bf{W}^\\frac{1}{2}$ under the constraint that\n$\\bf{Z}$ is from $H$. It is shown that under mild conditions on $g$ and $H$\nsuch estimators are robust, meaning the estimation error can be made\narbitrarily small if the perturbation of $\\bf{W}$ gets small enough. \\par In\nthe second part of this work the previous results are applied to activity\ndetection in random access with multiple receive antennas. In activity\ndetection recovering the large scale fading coefficients is a sparse recovery\nproblem which can be reduced to a structured covariance estimation problem. The\nrecovery can be done with a non-negative least squares estimator or with a\nrelaxed maximum likelihood estimator. It is shown that under suitable\nassumptions on the distributions of the noise and the channel coefficients, the\nrelaxed maximum likelihood estimator is from the general class of covariance\nestimators considered in the first part of this work. Then, codebooks based\nupon a signed kernel condition are proposed. It is shown that with the proposed\ncodebooks both estimators can recover the large-scale fading coefficients if\nthe number of receive antennas is high enough and\n$S\\leq\\left\\lceil\\frac{1}{2}M^2\\right\\rceil-1$ where $S$ is the number of\nactive users and $M$ is number of pilot symbols per user."}
{"id": "2510.06410", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06410", "abs": "https://arxiv.org/abs/2510.06410", "authors": ["Aochong Oliver Li", "Tanya Goyal"], "title": "Off-Trajectory Reasoning: Can LLMs Collaborate on Reasoning Trajectory?", "comment": null, "summary": "Reasoning LLMs are trained to verbalize their reasoning process, yielding\nstrong gains on complex tasks. This transparency also opens a promising\ndirection: multiple reasoners can directly collaborate on each other's thinking\nwithin a shared trajectory, yielding better inference efficiency and\nexploration. A key prerequisite, however, is the ability to assess the\nusefulness and build on another model's partial thinking -- we call this\noff-trajectory reasoning. Our paper investigates a critical question: can\nstandard solo-reasoning training pipelines deliver desired off-trajectory\nbehaviors? We propose twin tests that capture the two extremes of the\noff-trajectory spectrum, namely Recoverability, which tests whether LLMs can\nbacktrack from \"distractions\" induced by misleading reasoning traces, and\nGuidability, which tests their ability to build upon correct reasoning from\nstronger collaborators. Our study evaluates 15 open-weight LLMs (1.5B-32B) and\nreveals a counterintuitive finding -- \"stronger\" LLMs on benchmarks are often\nmore fragile under distraction. Moreover, all models tested fail to effectively\nleverage guiding steps from collaborators on problems beyond their inherent\ncapabilities with solve rates remaining under 9.2%. Finally, we conduct control\nstudies to isolate the effects of three factors in post-training on these\nbehaviors: the choice of distillation teacher, the use of RL, and data\nselection strategy. Our results provide actionable insights for training\nnatively strong reasoning collaborators; e.g., we find that suboptimal\nrecoverability behaviors of teacher models are transferred to distilled\nstudents even if the distillation trajectories are correct. Taken together,\nthis work lays the groundwork for evaluating multi-model collaborations in\nshared reasoning trajectories and highlights the limitations of off-the-shelf\nreasoning LLMs."}
{"id": "2510.07108", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.07108", "abs": "https://arxiv.org/abs/2510.07108", "authors": ["Lingyi Wang", "Rashed Shelim", "Walid Saad", "Naren Ramakrishnan"], "title": "A Theoretically-Grounded Codebook for Digital Semantic Communications", "comment": null, "summary": "The use of a learnable codebook provides an efficient way for semantic\ncommunications to map vector-based high-dimensional semantic features onto\ndiscrete symbol representations required in digital communication systems. In\nthis paper, the problem of codebook-enabled quantization mapping for digital\nsemantic communications is studied from the perspective of information theory.\nParticularly, a novel theoretically-grounded codebook design is proposed for\njointly optimizing quantization efficiency, transmission efficiency, and robust\nperformance. First, a formal equivalence is established between the one-to-many\nsynonymous mapping defined in semantic information theory and the many-to-one\nquantization mapping based on the codebook's Voronoi partitions. Then, the\nmutual information between semantic features and their quantized indices is\nderived in order to maximize semantic information carried by discrete indices.\nTo realize the semantic maximum in practice, an entropy-regularized\nquantization loss based on empirical estimation is introduced for end-to-end\ncodebook training. Next, the physical channel-induced semantic distortion and\nthe optimal codebook size for semantic communications are characterized under\nbit-flip errors and semantic distortion. To mitigate the semantic distortion\ncaused by physical channel noise, a novel channel-aware semantic distortion\nloss is proposed. Simulation results on image reconstruction tasks demonstrate\nthe superior performance of the proposed theoretically-grounded codebook that\nachieves a 24.1% improvement in peak signal-to-noise ratio (PSNR) and a 46.5%\nimprovement in learned perceptual image patch similarity (LPIPS) compared to\nthe existing codebook designs when the signal-to-noise ratio (SNR) is 10 dB."}
{"id": "2510.06433", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06433", "abs": "https://arxiv.org/abs/2510.06433", "authors": ["Aryan Singh Dalal", "Yinglun Zhang", "Duru Doğan", "Atalay Mert İleri", "Hande Küçük McGinty"], "title": "Flavonoid Fusion: Creating a Knowledge Graph to Unveil the Interplay Between Food and Health", "comment": null, "summary": "The focus on \"food as medicine\" is gaining traction in the field of health\nand several studies conducted in the past few years discussed this aspect of\nfood in the literature. However, very little research has been done on\nrepresenting the relationship between food and health in a standardized,\nmachine-readable format using a semantic web that can help us leverage this\nknowledge effectively. To address this gap, this study aims to create a\nknowledge graph to link food and health through the knowledge graph's ability\nto combine information from various platforms focusing on flavonoid contents of\nfood found in the USDA databases and cancer connections found in the\nliterature. We looked closely at these relationships using KNARM methodology\nand represented them in machine-operable format. The proposed knowledge graph\nserves as an example for researchers, enabling them to explore the complex\ninterplay between dietary choices and disease management. Future work for this\nstudy involves expanding the scope of the knowledge graph by capturing nuances,\nadding more related data, and performing inferences on the acquired knowledge\nto uncover hidden relationships."}
{"id": "2510.07136", "categories": ["cs.IT", "cs.CR", "cs.LG", "cs.SI", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.07136", "abs": "https://arxiv.org/abs/2510.07136", "authors": ["Mohamed Seif", "Antti Koskela", "H. Vincent Poor", "Andrea J. Goldsmith"], "title": "Spectral Graph Clustering under Differential Privacy: Balancing Privacy, Accuracy, and Efficiency", "comment": null, "summary": "We study the problem of spectral graph clustering under edge differential\nprivacy (DP). Specifically, we develop three mechanisms: (i) graph perturbation\nvia randomized edge flipping combined with adjacency matrix shuffling, which\nenforces edge privacy while preserving key spectral properties of the graph.\nImportantly, shuffling considerably amplifies the guarantees: whereas flipping\nedges with a fixed probability alone provides only a constant epsilon edge DP\nguarantee as the number of nodes grows, the shuffled mechanism achieves\n(epsilon, delta) edge DP with parameters that tend to zero as the number of\nnodes increase; (ii) private graph projection with additive Gaussian noise in a\nlower-dimensional space to reduce dimensionality and computational complexity;\nand (iii) a noisy power iteration method that distributes Gaussian noise across\niterations to ensure edge DP while maintaining convergence. Our analysis\nprovides rigorous privacy guarantees and a precise characterization of the\nmisclassification error rate. Experiments on synthetic and real-world networks\nvalidate our theoretical analysis and illustrate the practical privacy-utility\ntrade-offs."}
{"id": "2510.06475", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.06475", "abs": "https://arxiv.org/abs/2510.06475", "authors": ["Yitao Long", "Yuru Jiang", "Hongjun Liu", "Yilun Zhao", "Jingchen Sun", "Yiqiu Shen", "Chen Zhao", "Arman Cohan", "Dennis Shasha"], "title": "PuzzlePlex: Benchmarking Foundation Models on Reasoning and Planning with Puzzles", "comment": null, "summary": "This work investigates the reasoning and planning capabilities of foundation\nmodels and their scalability in complex, dynamic environments. We introduce\nPuzzlePlex, a benchmark designed to assess these capabilities through a diverse\nset of puzzles. PuzzlePlex consists of 15 types of puzzles, including\ndeterministic and stochastic games of varying difficulty, as well as\nsingle-player and two-player scenarios. The PuzzlePlex framework provides a\ncomprehensive environment for each game, and supports extensibility to generate\nmore challenging instances as foundation models evolve. Additionally, we\nimplement customized game-playing strategies for comparison. Building on this\nbenchmark, we develop fine-grained metrics to measure performance and conduct\nan in-depth analysis of frontier foundation models across two settings:\ninstruction-based and code-based. Furthermore, we systematically investigate\ntheir scaling limits. Our findings show that reasoning models outperform others\nin instruction-based settings, while code-based execution presents greater\nchallenges but offers a scalable and efficient alternative. PuzzlePlex enables\ntargeted evaluation and guides future improvements in reasoning, planning, and\ngeneralization for foundation models."}
{"id": "2510.06534", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06534", "abs": "https://arxiv.org/abs/2510.06534", "authors": ["Jiahe Jin", "Abhijay Paladugu", "Chenyan Xiong"], "title": "Beneficial Reasoning Behaviors in Agentic Search and Effective Post-training to Obtain Them", "comment": null, "summary": "Agentic search leverages large language models (LLMs) to interpret complex\nuser information needs and execute a multi-step process of planning, searching,\nand synthesizing information to provide answers. This paradigm introduces\nunique challenges for LLMs' reasoning and agentic capabilities when interacting\nwith retrieval systems and the broader web. In this paper, we propose a\nreasoning-driven LLM-based pipeline to study effective reasoning behavior\npatterns in agentic search. Using this pipeline, we analyze successful agentic\nsearch trajectories and identify four beneficial reasoning behaviors:\nInformation Verification, Authority Evaluation, Adaptive Search, and Error\nRecovery. Based on these findings, we propose a technique called Behavior\nPriming to train more effective agentic search models. It synthesizes agentic\nsearch trajectories that exhibit these four behaviors and integrates them into\nthe agentic search model through supervised fine-tuning (SFT), followed by\nstandard reinforcement learning (RL). Experiments on three benchmarks (GAIA,\nWebWalker, and HLE) demonstrate that behavior priming yields over 35% gains in\nLlama3.2-3B and Qwen3-1.7B compared to directly training agentic search models\nwith RL. Crucially, we demonstrate that the desired reasoning behaviors in the\nSFT data, rather than the correctness of the final answer, is the critical\nfactor for achieving strong final performance after RL: fine-tuning on\ntrajectories with desirable reasoning behaviors but incorrect answers leads to\nbetter performance than fine-tuning on trajectories with correct answers. Our\nanalysis further reveals the underlying mechanism: the introduced reasoning\nbehaviors endow models with more effective exploration (higher pass@k and\nentropy) and test-time scaling (longer trajectories) capabilities, providing a\nstrong foundation for RL. Our code will be released as open source."}
{"id": "2510.06538", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06538", "abs": "https://arxiv.org/abs/2510.06538", "authors": ["Jiajie Li", "Huayi Zhang", "Peng Lin", "Jinjun Xiong", "Wei Xu"], "title": "Auto-Prompt Ensemble for LLM Judge", "comment": null, "summary": "We present a novel framework that improves the reliability of LLM judges by\nselectively augmenting LLM with auxiliary evaluation dimensions. Existing LLM\njudges often miss crucial evaluation dimensions because they fail to recognize\nthe implicit standards underlying human assessments. To address this challenge,\nwe propose the Auto-Prompt Ensemble (APE), an adaptive framework that\nautomatically learns evaluation dimensions from its failure cases. APE\nincorporates a confidence-based ensemble mechanism to decide when to adopt the\njudgments from additional evaluation dimensions through a novel confidence\nestimation approach called Collective Confidence. Extensive experiments\ndemonstrate that APE improves the reliability of LLM Judge across diverse\nstandard benchmarks. For instance, APE enhances GPT-4o agreement rate on Reward\nBench from 87.2% to 90.5% in the zero-shot setting. Overall, APE provides a\nprincipled approach for LLM Judge to leverage test-time computation, and bridge\nthe evaluation gap between human and LLM judges."}
{"id": "2510.06587", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06587", "abs": "https://arxiv.org/abs/2510.06587", "authors": ["Jingbo Yang", "Bairu Hou", "Wei Wei", "Shiyu Chang", "Yujia Bao"], "title": "WebDART: Dynamic Decomposition and Re-planning for Complex Web Tasks", "comment": null, "summary": "Large language model (LLM) agents are becoming competent at straightforward\nweb tasks, such as opening an item page or submitting a form, but still\nstruggle with objectives that require long horizon navigation, large scale\ninformation extraction, and reasoning under constraints. We present WebDART, a\ngeneral framework that enables a single LLM to handle such complex chores.\nWebDART (i) dynamically decomposes each objective into three focused subtasks:\nnavigation, information extraction, and execution, so the model concentrates on\none skill at a time, and (ii) continuously replans the decomposition as new\nwebpages are revealed, taking advantage of newly discovered filters or\nshortcuts and avoiding redundant exploration. Evaluated on WebChoreArena,\nWebDART lifts success rates by up to 13.7 percentage points over previous SOTA\nagents, while matching their performance on the easier WebArena suite and\ncompleting tasks with up to 14.7 fewer navigation steps."}
{"id": "2510.06600", "categories": ["cs.AI", "H.3.3; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.06600", "abs": "https://arxiv.org/abs/2510.06600", "authors": ["Zhaochun Ren", "Zhou Yang", "Chenglong Ye", "Haizhou Sun", "Chao Chen", "Xiaofei Zhu", "Xiangwen Liao"], "title": "Fine-Grained Emotion Recognition via In-Context Learning", "comment": "9 pages, 10 figures, 4 tables", "summary": "Fine-grained emotion recognition aims to identify the emotional type in\nqueries through reasoning and decision-making processes, playing a crucial role\nin various systems. Recent methods use In-Context Learning (ICL), enhancing the\nrepresentation of queries in the reasoning process through semantically similar\nexamples, while further improving emotion recognition by explaining the\nreasoning mechanisms. However, these methods enhance the reasoning process but\noverlook the decision-making process. This paper investigates decision-making\nin fine-grained emotion recognition through prototype theory. We show that ICL\nrelies on similarity matching between query representations and emotional\nprototypes within the model, where emotion-accurate representations are\ncritical. However, semantically similar examples often introduce emotional\ndiscrepancies, hindering accurate representations and causing errors. To\naddress this, we propose Emotion In-Context Learning (EICL), which introduces\nemotionally similar examples and uses a dynamic soft-label strategy to improve\nquery representations in the emotion reasoning process. A two-stage exclusion\nstrategy is then employed to assess similarity from multiple angles, further\noptimizing the decision-making process. Extensive experiments show that EICL\nsignificantly outperforms ICL on multiple datasets."}
{"id": "2510.06674", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06674", "abs": "https://arxiv.org/abs/2510.06674", "authors": ["Cen", "Zhao", "Tiantian Zhang", "Hanchen Su", "Yufeng", "Zhang", "Shaowei Su", "Mingzhi Xu", "Yu", "Liu", "Wei Han", "Jeremy Werner", "Claire Na Cheng", "Yashar Mehdad"], "title": "Agent-in-the-Loop: A Data Flywheel for Continuous Improvement in LLM-based Customer Support", "comment": "EMNLP 2025 Industry Track submission (Paper #305). Preprint. Main\n  text within the 7-page industry limit (references/appendices excluded).\n  Contains multiple figures and tables", "summary": "We introduce an Agent-in-the-Loop (AITL) framework that implements a\ncontinuous data flywheel for iteratively improving an LLM-based customer\nsupport system. Unlike standard offline approaches that rely on batch\nannotations, AITL integrates four key types of annotations directly into live\ncustomer operations: (1) pairwise response preferences, (2) agent adoption and\nrationales, (3) knowledge relevance checks, and (4) identification of missing\nknowledge. These feedback signals seamlessly feed back into models' updates,\nreducing retraining cycles from months to weeks. Our production pilot involving\nUS-based customer support agents demonstrated significant improvements in\nretrieval accuracy (+11.7% recall@75, +14.8% precision@8), generation quality\n(+8.4% helpfulness) and agent adoption rates (+4.5%). These results underscore\nthe effectiveness of embedding human feedback loops directly into operational\nworkflows to continuously refine LLM-based customer support system."}
{"id": "2510.06711", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06711", "abs": "https://arxiv.org/abs/2510.06711", "authors": ["Batu El", "Mert Yuksekgonul", "James Zou"], "title": "Inefficiencies of Meta Agents for Agent Design", "comment": null, "summary": "Recent works began to automate the design of agentic systems using\nmeta-agents that propose and iteratively refine new agent architectures. In\nthis paper, we examine three key challenges in a common class of meta-agents.\nFirst, we investigate how a meta-agent learns across iterations and find that\nsimply expanding the context with all previous agents, as proposed by previous\nworks, performs worse than ignoring prior designs entirely. We show that the\nperformance improves with an evolutionary approach. Second, although the\nmeta-agent designs multiple agents during training, it typically commits to a\nsingle agent at test time. We find that the designed agents have low behavioral\ndiversity, limiting the potential for their complementary use. Third, we assess\nwhen automated design is economically viable. We find that only in a few\ncases--specifically, two datasets--the overall cost of designing and deploying\nthe agents is lower than that of human-designed agents when deployed on over\n15,000 examples. In contrast, the performance gains for other datasets do not\njustify the design cost, regardless of scale."}
{"id": "2510.06742", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06742", "abs": "https://arxiv.org/abs/2510.06742", "authors": ["Ali Sarabadani", "Kheirolah Rahsepar Fard"], "title": "MultiCNKG: Integrating Cognitive Neuroscience, Gene, and Disease Knowledge Graphs Using Large Language Models", "comment": null, "summary": "The advent of large language models (LLMs) has revolutionized the integration\nof knowledge graphs (KGs) in biomedical and cognitive sciences, overcoming\nlimitations in traditional machine learning methods for capturing intricate\nsemantic links among genes, diseases, and cognitive processes. We introduce\nMultiCNKG, an innovative framework that merges three key knowledge sources: the\nCognitive Neuroscience Knowledge Graph (CNKG) with 2.9K nodes and 4.3K edges\nacross 9 node types and 20 edge types; Gene Ontology (GO) featuring 43K nodes\nand 75K edges in 3 node types and 4 edge types; and Disease Ontology (DO)\ncomprising 11.2K nodes and 8.8K edges with 1 node type and 2 edge types.\nLeveraging LLMs like GPT-4, we conduct entity alignment, semantic similarity\ncomputation, and graph augmentation to create a cohesive KG that interconnects\ngenetic mechanisms, neurological disorders, and cognitive functions. The\nresulting MultiCNKG encompasses 6.9K nodes across 5 types (e.g., Genes,\nDiseases, Cognitive Processes) and 11.3K edges spanning 7 types (e.g., Causes,\nAssociated with, Regulates), facilitating a multi-layered view from molecular\nto behavioral domains. Assessments using metrics such as precision (85.20%),\nrecall (87.30%), coverage (92.18%), graph consistency (82.50%), novelty\ndetection (40.28%), and expert validation (89.50%) affirm its robustness and\ncoherence. Link prediction evaluations with models like TransE (MR: 391, MRR:\n0.411) and RotatE (MR: 263, MRR: 0.395) show competitive performance against\nbenchmarks like FB15k-237 and WN18RR. This KG advances applications in\npersonalized medicine, cognitive disorder diagnostics, and hypothesis\nformulation in cognitive neuroscience."}
{"id": "2510.06756", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06756", "abs": "https://arxiv.org/abs/2510.06756", "authors": ["Dennis Gross", "Helge Spieker", "Arnaud Gotlieb"], "title": "Verifying Memoryless Sequential Decision-making of Large Language Models", "comment": null, "summary": "We introduce a tool for rigorous and automated verification of large language\nmodel (LLM)- based policies in memoryless sequential decision-making tasks.\nGiven a Markov decision process (MDP) representing the sequential\ndecision-making task, an LLM policy, and a safety requirement expressed as a\nPCTL formula, our approach incrementally constructs only the reachable portion\nof the MDP guided by the LLM's chosen actions. Each state is encoded as a\nnatural language prompt, the LLM's response is parsed into an action, and\nreachable successor states by the policy are expanded. The resulting formal\nmodel is checked with Storm to determine whether the policy satisfies the\nspecified safety property. In experiments on standard grid world benchmarks, we\nshow that open source LLMs accessed via Ollama can be verified when\ndeterministically seeded, but generally underperform deep reinforcement\nlearning baselines. Our tool natively integrates with Ollama and supports\nPRISM-specified tasks, enabling continuous benchmarking in user-specified\nsequential decision-making tasks and laying a practical foundation for formally\nverifying increasingly capable LLMs."}
{"id": "2510.06761", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.06761", "abs": "https://arxiv.org/abs/2510.06761", "authors": ["Zhi Zhang", "Yan Liu", "Zhejing Hu", "Gong Chen", "Sheng-hua Zhong", "Jiannong Cao"], "title": "Evolving and Executing Research Plans via Double-Loop Multi-Agent Collaboration", "comment": null, "summary": "Automating the end-to-end scientific research process poses a fundamental\nchallenge: it requires both evolving high-level plans that are novel and sound,\nand executing these plans correctly amidst dynamic and uncertain conditions. To\naddress this bilevel challenge, we propose a novel Double-Loop Multi-Agent\n(DLMA) framework to solve the given research problem automatically. The leader\nloop, composed of professor agents, is responsible for evolving research plans.\nIt employs an evolutionary algorithm through involvement, improvement, and\nintegration meetings to iteratively generate and refine a pool of research\nproposals, exploring the solution space effectively. The follower loop,\ncomposed of doctoral student agents, is responsible for executing the\nbest-evolved plan. It dynamically adjusts the plan during implementation via\npre-hoc and post-hoc meetings, ensuring each step (e.g., drafting, coding) is\nwell-supported by contextual and external observations. Extensive experiments\non benchmarks like ACLAward and Laboratory show that DLMA generates research\npapers that achieve state-of-the-art scores in automated evaluation,\nsignificantly outperforming strong baselines. Ablation studies confirm the\ncritical roles of both loops, with evolution driving novelty and execution\nensuring soundness."}
{"id": "2510.06857", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06857", "abs": "https://arxiv.org/abs/2510.06857", "authors": ["Qi Guo", "Jianing Wang", "Jianfei Zhang", "Deyang Kong", "Xiangzhou Huang", "Xiangyu Xi", "Wei Wang", "Jingang Wang", "Xunliang Cai", "Shikun Zhang", "Wei Ye"], "title": "Autoformalizer with Tool Feedback", "comment": null, "summary": "Autoformalization addresses the scarcity of data for Automated Theorem\nProving (ATP) by translating mathematical problems from natural language into\nformal statements. Efforts in recent work shift from directly prompting large\nlanguage models to training an end-to-end formalizer model from scratch,\nachieving remarkable advancements. However, existing formalizer still struggles\nto consistently generate valid statements that meet syntactic validity and\nsemantic consistency. To address this issue, we propose the Autoformalizer with\nTool Feedback (ATF), a novel approach that incorporates syntactic and\nconsistency information as tools into the formalization process. By integrating\nLean 4 compilers for syntax corrections and employing a multi-LLMs-as-judge\napproach for consistency validation, the model is able to adaptively refine\ngenerated statements according to the tool feedback, enhancing both syntactic\nvalidity and semantic consistency. The training of ATF involves a cold-start\nphase on synthetic tool-calling data, an expert iteration phase to improve\nformalization capabilities, and Direct Preference Optimization to alleviate\nineffective revisions. Experimental results show that ATF markedly outperforms\na range of baseline formalizer models, with its superior performance further\nvalidated by human evaluations. Subsequent analysis reveals that ATF\ndemonstrates excellent inference scaling properties. Moreover, we open-source\nNumina-ATF, a dataset containing 750K synthetic formal statements to facilitate\nadvancements in autoformalization and ATP research."}
{"id": "2510.06878", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06878", "abs": "https://arxiv.org/abs/2510.06878", "authors": ["Daria Ozerova", "Ekaterina Trofimova"], "title": "TGPR: Tree-Guided Policy Refinement for Robust Self-Debugging of LLMs", "comment": null, "summary": "Iterative refinement has been a promising paradigm to enable large language\nmodels (LLMs) to resolve difficult reasoning and problem-solving tasks. One of\nthe key challenges, however, is how to effectively search through the enormous\nsearch space of possible refinements. Existing methods typically fall back on\npredefined heuristics, which are troubled by the exploration-exploitation\ndilemma and cannot adapt based on past refinement outcomes. We introduce\nTree-Guided Policy Refinement (TGPR), a novel framework that combines GRPO with\na Thompson-Sampling-based tree search. TGPR explores both failed and successful\nrefinement paths actively, with denser training trajectories and more adaptive\npolicies. On HumanEval, MBPP, and APPS benchmarks, our method achieves up to\n+4.2 percentage points absolute improvement in pass@1 (on MBPP) and up to\n+12.51 percentage points absolute improvement in pass@10 (on APPS) compared to\na competitive GRPO baseline. Apart from debugging code, TGPR focuses on a\nprincipled approach to combining learned policies with structured search\nmethods, offering a general framework for enhancing iterative refinement and\nstateful reasoning in LLMs."}
{"id": "2510.06911", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06911", "abs": "https://arxiv.org/abs/2510.06911", "authors": ["Hacane Hechehouche", "Andre Antakli", "Matthias Klusch"], "title": "LLM-Assisted Modeling of Semantic Web-Enabled Multi-Agents Systems with AJAN", "comment": null, "summary": "There are many established semantic Web standards for implementing\nmulti-agent driven applications. The AJAN framework allows to engineer\nmulti-agent systems based on these standards. In particular, agent knowledge is\nrepresented in RDF/RDFS and OWL, while agent behavior models are defined with\nBehavior Trees and SPARQL to access and manipulate this knowledge. However, the\nappropriate definition of RDF/RDFS and SPARQL-based agent behaviors still\nremains a major hurdle not only for agent modelers in practice. For example,\ndealing with URIs is very error-prone regarding typos and dealing with complex\nSPARQL queries in large-scale environments requires a high learning curve. In\nthis paper, we present an integrated development environment to overcome such\nhurdles of modeling AJAN agents and at the same time to extend the user\ncommunity for AJAN by the possibility to leverage Large Language Models for\nagent engineering."}
{"id": "2510.06953", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.06953", "abs": "https://arxiv.org/abs/2510.06953", "authors": ["Minju Gwak", "Guijin Son", "Jaehyung Kim"], "title": "Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces", "comment": null, "summary": "The Uniform Information Density (UID) hypothesis suggests that effective\ncommunication maintains a stable flow of information. In this work, we revisit\nthis principle in the context of large language model (LLM) reasoning traces,\nasking whether step-level uniformity reflects reasoning quality. To this end,\nwe propose an entropy-based stepwise information density metric and introduce\ntwo complementary measures of uniformity, local and global uniformity scores.\nAcross the experiments on six different reasoning benchmarks, we find that\nstep-level uniformity not only provides a strong theoretical lens but also\nyields practical performance benefits; for example, selecting reasoning traces\nwith more uniform information density at the step-level improves accuracy by\n10-32\\% relative gains over baselines at AIME2025. Our analysis further reveals\nthat correct reasoning traces tend to avoid sharp information density spikes,\nwhile incorrect traces exhibit irregular information bursts. These results\ndemonstrate that UID-inspired information density measures outperform\nalternative internal signals as predictors of reasoning quality. Results\nhighlight the uniformity of the information density as a robust diagnostic and\nselection criterion for building more reliable and accurate reasoning systems."}
{"id": "2510.07038", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07038", "abs": "https://arxiv.org/abs/2510.07038", "authors": ["Wenxun Wu", "Yuanyang Li", "Guhan Chen", "Linyue Wang", "Hongyang Chen"], "title": "Tool-Augmented Policy Optimization: Synergizing Reasoning and Adaptive Tool Use with Reinforcement Learning", "comment": null, "summary": "Recent advances in large language models (LLMs) have popularized test-time\nscaling, where models generate additional reasoning tokens before producing\nfinal answers. These approaches have demonstrated significant performance\nimprovements on benchmarks involving mathematical reasoning. However, language\nmodels relying solely on direct inference still struggle with tasks demanding\nup-to-date knowledge or computational tools such as calculators and code\ninterpreters for complex arithmetic operations. To overcome these limitations,\nwe propose Tool-Augmented Policy Optimization (TAPO), a novel reinforcement\nlearning framework that systematically integrates multi-hop reasoning with\nadaptive tool-calling capabilities. Our approach employs a modified version of\nDynamic Sampling Policy Optimization (DAPO), a recently developed RL paradigm,\nwhich we adapt specifically for tool invocation scenarios, enabling models to\ndynamically interleave complex reasoning with on-demand tool usage (including\nsearch APIs and Python interpreters).\n  To support this research, we introduce two new datasets: TAPO-easy-60K and\nTAPO-hard-18K, specifically designed to train and evaluate both fact-based\nreasoning and mathematical calculation capabilities. Our experiments on\nQwen2.5-3B and Qwen2.5-7B models demonstrate the effectiveness of our approach,\nwith both models achieving state-of-the-art performance on tasks requiring\nexternal knowledge and mathematical computation among methods with comparable\nparameters. Notably, TAPO achieves more efficient tool utilization than\nbaseline methods while preventing excessive calls caused by reward hacking.\nThese results highlight the significant potential of combining advanced\nreasoning with tool usage to enhance model performance in knowledge-intensive\nand computationally demanding tasks."}
{"id": "2510.07064", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07064", "abs": "https://arxiv.org/abs/2510.07064", "authors": ["Manh Hung Nguyen", "Sebastian Tschiatschek", "Adish Singla"], "title": "Prompt Optimization Across Multiple Agents for Representing Diverse Human Populations", "comment": null, "summary": "The difficulty and expense of obtaining large-scale human responses make\nLarge Language Models (LLMs) an attractive alternative and a promising proxy\nfor human behavior. However, prior work shows that LLMs often produce\nhomogeneous outputs that fail to capture the rich diversity of human\nperspectives and behaviors. Thus, rather than trying to capture this diversity\nwith a single LLM agent, we propose a novel framework to construct a set of\nagents that collectively capture the diversity of a given human population.\nEach agent is an LLM whose behavior is steered by conditioning on a small set\nof human demonstrations (task-response pairs) through in-context learning. The\ncentral challenge is therefore to select a representative set of LLM agents\nfrom the exponentially large space of possible agents. We tackle this selection\nproblem from the lens of submodular optimization. In particular, we develop\nmethods that offer different trade-offs regarding time complexity and\nperformance guarantees. Extensive experiments in crowdsourcing and educational\ndomains demonstrate that our approach constructs agents that more effectively\nrepresent human populations compared to baselines. Moreover, behavioral\nanalyses on new tasks show that these agents reproduce the behavior patterns\nand perspectives of the students and annotators they are designed to represent."}
{"id": "2510.07069", "categories": ["cs.AI", "I.2.4"], "pdf": "https://arxiv.org/pdf/2510.07069", "abs": "https://arxiv.org/abs/2510.07069", "authors": ["Hongbo Hu", "Yisong Wang", "Yi Huang", "Kewen Wang"], "title": "Inductive Learning for Possibilistic Logic Programs Under Stable Models", "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "summary": "Possibilistic logic programs (poss-programs) under stable models are a major\nvariant of answer set programming (ASP). While its semantics (possibilistic\nstable models) and properties have been well investigated, the problem of\ninductive reasoning has not been investigated yet. This paper presents an\napproach to extracting poss-programs from a background program and examples\n(parts of intended possibilistic stable models). To this end, the notion of\ninduction tasks is first formally defined, its properties are investigated and\ntwo algorithms ilpsm and ilpsmmin for computing induction solutions are\npresented. An implementation of ilpsmmin is also provided and experimental\nresults show that when inputs are ordinary logic programs, the prototype\noutperforms a major inductive learning system for normal logic programs from\nstable models on the datasets that are randomly generated."}
{"id": "2510.07073", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07073", "abs": "https://arxiv.org/abs/2510.07073", "authors": ["André Hottung", "Federico Berto", "Chuanbo Hua", "Nayeli Gast Zepeda", "Daniel Wetzel", "Michael Römer", "Haoran Ye", "Davide Zago", "Michael Poli", "Stefano Massaroli", "Jinkyoo Park", "Kevin Tierney"], "title": "VRPAgent: LLM-Driven Discovery of Heuristic Operators for Vehicle Routing Problems", "comment": null, "summary": "Designing high-performing heuristics for vehicle routing problems (VRPs) is a\ncomplex task that requires both intuition and deep domain knowledge. Large\nlanguage model (LLM)-based code generation has recently shown promise across\nmany domains, but it still falls short of producing heuristics that rival those\ncrafted by human experts. In this paper, we propose VRPAgent, a framework that\nintegrates LLM-generated components into a metaheuristic and refines them\nthrough a novel genetic search. By using the LLM to generate problem-specific\noperators, embedded within a generic metaheuristic framework, VRPAgent keeps\ntasks manageable, guarantees correctness, and still enables the discovery of\nnovel and powerful strategies. Across multiple problems, including the\ncapacitated VRP, the VRP with time windows, and the prize-collecting VRP, our\nmethod discovers heuristic operators that outperform handcrafted methods and\nrecent learning-based approaches while requiring only a single CPU core. To our\nknowledge, \\VRPAgent is the first LLM-based paradigm to advance the\nstate-of-the-art in VRPs, highlighting a promising future for automated\nheuristics discovery."}
{"id": "2510.07091", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.07091", "abs": "https://arxiv.org/abs/2510.07091", "authors": ["Baixuan Xu", "Tianshi Zheng", "Zhaowei Wang", "Hong Ting Tsang", "Weiqi Wang", "Tianqing Fang", "Yangqiu Song"], "title": "The Cognitive Bandwidth Bottleneck: Shifting Long-Horizon Agent from Planning with Actions to Planning with Schemas", "comment": "22 pages", "summary": "Enabling LLMs to effectively operate long-horizon task which requires\nlong-term planning and multiple interactions is essential for open-world\nautonomy. Conventional methods adopt planning with actions where a executable\naction list would be provided as reference. However, this action representation\nchoice would be impractical when the environment action space is combinatorial\nexploded (e.g., open-ended real world). This naturally leads to a question: As\nenvironmental action space scales, what is the optimal action representation\nfor long-horizon agents? In this paper, we systematically study the\neffectiveness of two different action representations. The first one is\nconventional planning with actions (PwA) which is predominantly adopted for its\neffectiveness on existing benchmarks. The other one is planning with schemas\n(PwS) which instantiate an action schema into action lists (e.g., \"move [OBJ]\nto [OBJ]\" -> \"move apple to desk\") to ensure concise action space and reliable\nscalability. This alternative is motivated by its alignment with human\ncognition and its compliance with environment-imposed action format\nrestriction. We propose cognitive bandwidth perspective as a conceptual\nframework to qualitatively understand the differences between these two action\nrepresentations and empirically observe a representation-choice inflection\npoint between ALFWorld (~35 actions) and SciWorld (~500 actions), which serve\nas evidence of the need for scalable representations. We further conduct\ncontrolled experiments to study how the location of this inflection point\ninteracts with different model capacities: stronger planning proficiency shifts\nthe inflection rightward, whereas better schema instantiation shifts it\nleftward. Finally, noting the suboptimal performance of PwS agents, we provide\nan actionable guide for building more capable PwS agents for better scalable\nautonomy."}
{"id": "2510.07117", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.07117", "abs": "https://arxiv.org/abs/2510.07117", "authors": ["Leonardo Christov-Moore", "Arthur Juliani", "Alex Kiefer", "Nicco Reggente", "B. Scott Rousse", "Adam Safron", "Nicol'as Hinrichs", "Daniel Polani", "Antonio Damasio"], "title": "The Contingencies of Physical Embodiment Allow for Open-Endedness and Care", "comment": "15 pages, 1 figure", "summary": "Physical vulnerability and mortality are often seen as obstacles to be\navoided in the development of artificial agents, which struggle to adapt to\nopen-ended environments and provide aligned care. Meanwhile, biological\norganisms survive, thrive, and care for each other in an open-ended physical\nworld with relative ease and efficiency. Understanding the role of the\nconditions of life in this disparity can aid in developing more robust,\nadaptive, and caring artificial agents. Here we define two minimal conditions\nfor physical embodiment inspired by the existentialist phenomenology of Martin\nHeidegger: being-in-the-world (the agent is a part of the environment) and\nbeing-towards-death (unless counteracted, the agent drifts toward terminal\nstates due to the second law of thermodynamics). We propose that from these\nconditions we can obtain both a homeostatic drive - aimed at maintaining\nintegrity and avoiding death by expending energy to learn and act - and an\nintrinsic drive to continue to do so in as many ways as possible. Drawing\ninspiration from Friedrich Nietzsche's existentialist concept of will-to-power,\nwe examine how intrinsic drives to maximize control over future states, e.g.,\nempowerment, allow agents to increase the probability that they will be able to\nmeet their future homeostatic needs, thereby enhancing their capacity to\nmaintain physical integrity. We formalize these concepts within a reinforcement\nlearning framework, which enables us to examine how intrinsically driven\nembodied agents learning in open-ended multi-agent environments may cultivate\nthe capacities for open-endedness and care.ov"}
{"id": "2510.07161", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07161", "abs": "https://arxiv.org/abs/2510.07161", "authors": ["Ali Norouzifar", "Humam Kourani", "Marcus Dees", "Wil van der Aalst"], "title": "Integrating Domain Knowledge into Process Discovery Using Large Language Models", "comment": "This paper is currently under review for publication in a journal", "summary": "Process discovery aims to derive process models from event logs, providing\ninsights into operational behavior and forming a foundation for conformance\nchecking and process improvement. However, models derived solely from event\ndata may not accurately reflect the real process, as event logs are often\nincomplete or affected by noise, and domain knowledge, an important\ncomplementary resource, is typically disregarded. As a result, the discovered\nmodels may lack reliability for downstream tasks. We propose an interactive\nframework that incorporates domain knowledge, expressed in natural language,\ninto the process discovery pipeline using Large Language Models (LLMs). Our\napproach leverages LLMs to extract declarative rules from textual descriptions\nprovided by domain experts. These rules are used to guide the IMr discovery\nalgorithm, which recursively constructs process models by combining insights\nfrom both the event log and the extracted rules, helping to avoid problematic\nprocess structures that contradict domain knowledge. The framework coordinates\ninteractions among the LLM, domain experts, and a set of backend services. We\npresent a fully implemented tool that supports this workflow and conduct an\nextensive evaluation of multiple LLMs and prompt engineering strategies. Our\nempirical study includes a case study based on a real-life event log with the\ninvolvement of domain experts, who assessed the usability and effectiveness of\nthe framework."}
{"id": "2510.07172", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07172", "abs": "https://arxiv.org/abs/2510.07172", "authors": ["Tianshi Zheng", "Kelvin Kiu-Wai Tam", "Newt Hue-Nam K. Nguyen", "Baixuan Xu", "Zhaowei Wang", "Jiayang Cheng", "Hong Ting Tsang", "Weiqi Wang", "Jiaxin Bai", "Tianqing Fang", "Yangqiu Song", "Ginny Y. Wong", "Simon See"], "title": "NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents", "comment": "60 pages, 18 figures, 13 tables", "summary": "Large language models are emerging as powerful tools for scientific law\ndiscovery, a foundational challenge in AI-driven science. However, existing\nbenchmarks for this task suffer from a fundamental methodological trilemma,\nforcing a trade-off between scientific relevance, scalability, and resistance\nto memorization. Furthermore, they oversimplify discovery as static function\nfitting, failing to capture the authentic scientific process of uncovering\nembedded laws through the interactive exploration of complex model systems. To\naddress these critical gaps, we introduce NewtonBench, a benchmark comprising\n324 scientific law discovery tasks across 12 physics domains. Our design\nmitigates the evaluation trilemma by using metaphysical shifts - systematic\nalterations of canonical laws - to generate a vast suite of problems that are\nscalable, scientifically relevant, and memorization-resistant. Moreover, we\nelevate the evaluation from static function fitting to interactive model\ndiscovery, requiring agents to experimentally probe simulated complex systems\nto uncover hidden principles. Our extensive experiment reveals a clear but\nfragile capability for discovery in frontier LLMs: this ability degrades\nprecipitously with increasing system complexity and exhibits extreme\nsensitivity to observational noise. Notably, we uncover a paradoxical effect of\ntool assistance: providing a code interpreter can hinder more capable models by\ninducing a premature shift from exploration to exploitation, causing them to\nsatisfice on suboptimal solutions. These results demonstrate that robust,\ngeneralizable discovery in complex, interactive environments remains the core\nchallenge. By providing a scalable, robust, and scientifically authentic\ntestbed, NewtonBench offers a crucial tool for measuring true progress and\nguiding the development of next-generation AI agents capable of genuine\nscientific discovery."}
{"id": "2510.07276", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.07276", "abs": "https://arxiv.org/abs/2510.07276", "authors": ["Pulkit Rustagi", "Kyle Hollins Wray", "Sandhya Saisubramanian"], "title": "Multi-Objective Multi-Agent Path Finding with Lexicographic Cost Preferences", "comment": "8 pages, 7 figures", "summary": "Many real-world scenarios require multiple agents to coordinate in shared\nenvironments, while balancing trade-offs between multiple, potentially\ncompeting objectives. Current multi-objective multi-agent path finding\n(MO-MAPF) algorithms typically produce conflict-free plans by computing Pareto\nfrontiers. They do not explicitly optimize for user-defined preferences, even\nwhen the preferences are available, and scale poorly with the number of\nobjectives. We propose a lexicographic framework for modeling MO-MAPF, along\nwith an algorithm \\textit{Lexicographic Conflict-Based Search} (LCBS) that\ndirectly computes a single solution aligned with a lexicographic preference\nover objectives. LCBS integrates a priority-aware low-level $A^*$ search with\nconflict-based search, avoiding Pareto frontier construction and enabling\nefficient planning guided by preference over objectives. We provide insights\ninto optimality and scalability, and empirically demonstrate that LCBS computes\noptimal solutions while scaling to instances with up to ten objectives -- far\nbeyond the limits of existing MO-MAPF methods. Evaluations on standard and\nrandomized MAPF benchmarks show consistently higher success rates against\nstate-of-the-art baselines, especially with increasing number of objectives."}
{"id": "2510.07297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07297", "abs": "https://arxiv.org/abs/2510.07297", "authors": ["Henry Wang", "Md Sirajus Salekin", "Jake Lee", "Ross Claytor", "Shinan Zhang", "Michael Chi"], "title": "Agentic generative AI for media content discovery at the national football league", "comment": "13 pages, 7 figures, International Sports Analytics Conference and\n  Exhibition", "summary": "Generative AI has unlocked new possibilities in content discovery and\nmanagement. Through collaboration with the National Football League (NFL), we\ndemonstrate how a generative-AI based workflow enables media researchers and\nanalysts to query relevant historical plays using natural language rather than\ntraditional filter-and-click interfaces. The agentic workflow takes a user\nquery as input, breaks it into elements, and translates them into the\nunderlying database query language. Accuracy and latency are further improved\nthrough carefully designed semantic caching. The solution achieves over 95\npercent accuracy and reduces the average time to find relevant videos from 10\nminutes to 30 seconds, significantly increasing the NFL's operational\nefficiency and allowing users to focus on producing creative content and\nengaging storylines."}
{"id": "2510.06868", "categories": ["cs.IT", "cs.AI", "cs.CR", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.06868", "abs": "https://arxiv.org/abs/2510.06868", "authors": ["Didrik Bergström", "Deniz Gündüz", "Onur Günlü"], "title": "Multi-hop Deep Joint Source-Channel Coding with Deep Hash Distillation for Semantically Aligned Image Retrieval", "comment": null, "summary": "We consider image transmission via deep joint source-channel coding\n(DeepJSCC) over multi-hop additive white Gaussian noise (AWGN) channels by\ntraining a DeepJSCC encoder-decoder pair with a pre-trained deep hash\ndistillation (DHD) module to semantically cluster images, facilitating\nsecurity-oriented applications through enhanced semantic consistency and\nimproving the perceptual reconstruction quality. We train the DeepJSCC module\nto both reduce mean square error (MSE) and minimize cosine distance between DHD\nhashes of source and reconstructed images. Significantly improved perceptual\nquality as a result of semantic alignment is illustrated for different\nmulti-hop settings, for which classical DeepJSCC may suffer from noise\naccumulation, measured by the learned perceptual image patch similarity (LPIPS)\nmetric."}
