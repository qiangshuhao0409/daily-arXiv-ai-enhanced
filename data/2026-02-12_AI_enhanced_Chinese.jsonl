{"id": "2602.10482", "categories": ["cs.IT", "eess.IV"], "pdf": "https://arxiv.org/pdf/2602.10482", "abs": "https://arxiv.org/abs/2602.10482", "authors": ["Jijia Tian", "Junting Chen", "Pooi-Yuen Kam"], "title": "Robust Semantic Transmission for Low-Altitude UAVs: Predictive Channel-Aware Scheduling and Generative Reconstruction", "comment": null, "summary": "Unmanned aerial vehicle (UAV) downlink transmission facilitates critical time-sensitive visual applications but is fundamentally constrained by bandwidth scarcity and dynamic channel impairments. The rapid fluctuation of the air-to-ground (A2G) link creates a regime where reliable transmission slots are intermittent and future channel quality can only be predicted with uncertainty. Conventional deep joint source-channel coding (DeepJSCC) methods transmit coupled feature streams, causing global reconstruction failure when specific time slots experience deep fading. Decoupling semantic content into a deterministic structure component and a stochastic texture component enables differentiated error protection strategies aligned with channel reliability. A predictive transmission framework is developed that utilizes a split-stream variational codec and a channel-aware scheduler to prioritize the delivery of structural layout over reliable slots. Experimental evaluations indicate that this approach achieves a 5.6 dB gain in peak signal-to-noise (SNR) ratio over single-stream baselines and maintains structural fidelity under significant prediction mismatch.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u4eba\u673a\u4e0b\u884c\u89c6\u89c9\u4f20\u8f93\u6846\u67b6\uff0c\u5c06\u8bed\u4e49\u5185\u5bb9\u89e3\u8026\u4e3a\u786e\u5b9a\u6027\u7684\u7ed3\u6784\u7ec4\u4ef6\u548c\u968f\u673a\u6027\u7684\u7eb9\u7406\u7ec4\u4ef6\uff0c\u901a\u8fc7\u9884\u6d4b\u6027\u4f20\u8f93\u548c\u4fe1\u9053\u611f\u77e5\u8c03\u5ea6\u4f18\u5148\u4f20\u8f93\u7ed3\u6784\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u6297\u4fe1\u9053\u8870\u843d\u80fd\u529b\u3002", "motivation": "\u65e0\u4eba\u673a\u4e0b\u884c\u89c6\u89c9\u4f20\u8f93\u9762\u4e34\u5e26\u5bbd\u7a00\u7f3a\u548c\u52a8\u6001\u4fe1\u9053\u635f\u4f24\u7684\u6311\u6218\uff0c\u4f20\u7edf\u6df1\u5ea6\u8054\u5408\u4fe1\u6e90\u4fe1\u9053\u7f16\u7801\u65b9\u6cd5\u5728\u7279\u5b9a\u65f6\u9699\u6df1\u5ea6\u8870\u843d\u65f6\u4f1a\u5bfc\u81f4\u5168\u5c40\u91cd\u5efa\u5931\u8d25\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u4f20\u8f93\u65b9\u6848\u3002", "method": "\u5c06\u8bed\u4e49\u5185\u5bb9\u89e3\u8026\u4e3a\u786e\u5b9a\u6027\u7ed3\u6784\u7ec4\u4ef6\u548c\u968f\u673a\u6027\u7eb9\u7406\u7ec4\u4ef6\uff0c\u5f00\u53d1\u9884\u6d4b\u6027\u4f20\u8f93\u6846\u67b6\uff0c\u91c7\u7528\u5206\u6d41\u53d8\u5206\u7f16\u89e3\u7801\u5668\u548c\u4fe1\u9053\u611f\u77e5\u8c03\u5ea6\u5668\uff0c\u4f18\u5148\u5728\u53ef\u9760\u65f6\u9699\u4f20\u8f93\u7ed3\u6784\u5e03\u5c40\u4fe1\u606f\u3002", "result": "\u76f8\u6bd4\u5355\u6d41\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u5cf0\u503c\u4fe1\u566a\u6bd4\u4e0a\u83b7\u5f975.6 dB\u589e\u76ca\uff0c\u5e76\u5728\u663e\u8457\u9884\u6d4b\u5931\u914d\u60c5\u51b5\u4e0b\u4fdd\u6301\u7ed3\u6784\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u8bed\u4e49\u5185\u5bb9\u89e3\u8026\u548c\u5dee\u5f02\u5316\u9519\u8bef\u4fdd\u62a4\u7b56\u7565\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u65e0\u4eba\u673a\u4e0b\u884c\u94fe\u8def\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u663e\u8457\u63d0\u5347\u89c6\u89c9\u4f20\u8f93\u7684\u9c81\u68d2\u6027\u548c\u91cd\u5efa\u8d28\u91cf\u3002"}}
{"id": "2602.10542", "categories": ["cs.IT", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.10542", "abs": "https://arxiv.org/abs/2602.10542", "authors": ["Ozgur Ercetin", "Mohaned Chraiti"], "title": "Predictive-State Communication: Innovation Coding and Reconciliation under Delay", "comment": null, "summary": "Shannon theory models communication as the reliable transfer of symbol sequences, with performance governed by capacity and rate-distortion limits. When both endpoints possess strong predictors -- as in modern large language models and related generative priors -- literal symbol transport is no longer the only operational regime. We propose predictive-state communication (PSC), in which the transmitter and receiver maintain an explicit shared predictive state, and the physical channel is used primarily to convey innovations, i.e., corrective information that reconciles the receiver's provisional trajectory with the transmitter's realized trajectory. This viewpoint replaces entropy-rate accounting by cross-entropy accounting under model mismatch, and it introduces feasibility constraints that depend jointly on capacity, delay, and perceptual continuity requirements; the resulting operating set is typically a bounded perception-capacity band rather than a one-sided threshold. We outline the protocol and architectural implications (state identifiers, anchors, bounded rollback, and patch-based updates) and provide a stylized illustrative example to visualize the induced feasibility region and its dependence on predictive quality.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u9884\u6d4b\u72b6\u6001\u901a\u4fe1(PSC)\u6846\u67b6\uff0c\u7528\u5171\u4eab\u9884\u6d4b\u72b6\u6001\u548c\u4f20\u8f93\u521b\u65b0\u4fe1\u606f\u66ff\u4ee3\u4f20\u7edf\u7b26\u53f7\u4f20\u8f93\uff0c\u5f62\u6210\u611f\u77e5-\u5bb9\u91cf\u5e26\u800c\u975e\u5355\u8fb9\u9608\u503c", "motivation": "\u5f53\u901a\u4fe1\u4e24\u7aef\u90fd\u62e5\u6709\u5f3a\u5927\u9884\u6d4b\u5668\uff08\u5982\u5927\u8bed\u8a00\u6a21\u578b\uff09\u65f6\uff0c\u4f20\u7edf\u57fa\u4e8e\u7b26\u53f7\u53ef\u9760\u4f20\u8f93\u7684\u9999\u519c\u7406\u8bba\u4e0d\u518d\u662f\u6700\u4f73\u64cd\u4f5c\u8303\u5f0f\uff0c\u9700\u8981\u65b0\u7684\u901a\u4fe1\u6846\u67b6\u6765\u5229\u7528\u9884\u6d4b\u80fd\u529b", "method": "\u63d0\u51fa\u9884\u6d4b\u72b6\u6001\u901a\u4fe1(PSC)\uff1a\u6536\u53d1\u7aef\u7ef4\u62a4\u663e\u5f0f\u5171\u4eab\u9884\u6d4b\u72b6\u6001\uff0c\u7269\u7406\u4fe1\u9053\u4e3b\u8981\u4f20\u8f93\u521b\u65b0\u4fe1\u606f\uff08\u63a5\u6536\u7aef\u9884\u6d4b\u8f68\u8ff9\u4e0e\u53d1\u9001\u7aef\u5b9e\u9645\u8f68\u8ff9\u7684\u6821\u6b63\u4fe1\u606f\uff09\uff0c\u5f15\u5165\u72b6\u6001\u6807\u8bc6\u7b26\u3001\u951a\u70b9\u3001\u6709\u754c\u56de\u6eda\u548c\u57fa\u4e8e\u8865\u4e01\u7684\u66f4\u65b0\u7b49\u534f\u8bae\u67b6\u6784", "result": "PSC\u5c06\u71b5\u7387\u8ba1\u7b97\u66ff\u6362\u4e3a\u6a21\u578b\u5931\u914d\u4e0b\u7684\u4ea4\u53c9\u71b5\u8ba1\u7b97\uff0c\u5f15\u5165\u4f9d\u8d56\u5bb9\u91cf\u3001\u5ef6\u8fdf\u548c\u611f\u77e5\u8fde\u7eed\u6027\u8981\u6c42\u7684\u53ef\u884c\u6027\u7ea6\u675f\uff0c\u5f62\u6210\u6709\u754c\u7684\u611f\u77e5-\u5bb9\u91cf\u5e26\u800c\u975e\u5355\u8fb9\u9608\u503c\uff0c\u901a\u8fc7\u793a\u4f8b\u5c55\u793a\u4e86\u53ef\u884c\u6027\u533a\u57df\u53ca\u5176\u5bf9\u9884\u6d4b\u8d28\u91cf\u7684\u4f9d\u8d56", "conclusion": "\u9884\u6d4b\u72b6\u6001\u901a\u4fe1\u4e3a\u5229\u7528\u73b0\u4ee3\u9884\u6d4b\u5668\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6\uff0c\u6539\u53d8\u4e86\u4f20\u7edf\u901a\u4fe1\u7684\u6027\u80fd\u8fb9\u754c\u6982\u5ff5\uff0c\u4e3a\u672a\u6765\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\u548c\u67b6\u6784\u65b9\u5411"}}
{"id": "2602.10813", "categories": ["cs.IT", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10813", "abs": "https://arxiv.org/abs/2602.10813", "authors": ["Pradyumna Kumar Bishoyi", "Chia Chia Lee", "Navid Keshtiarast", "Marina Petrova"], "title": "Dynamic Interference Management for TN-NTN Coexistence in the Upper Mid-Band", "comment": "This work has been accepted for publication in the IEEE ICC 2026 Conference", "summary": "The coexistence of terrestrial networks (TN) and non-terrestrial networks (NTN) in the frequency range 3 (FR3) upper mid-band presents considerable interference concerns, as dense TN deployments can severely degrade NTN downlink performance. Existing studies rely on interference-nulling beamforming, precoding, or exclusion zones that require accurate channel state information (CSI) and static coordination, making them unsuitable for dynamic NTN scenarios. To overcome these limitations, we develop an optimization framework that jointly controls TN downlink power, uplink power, and antenna downtilt to protect NTN links while preserving terrestrial performance. The resultant non-convex coupling between TN and NTN parameters is addressed by a Proximal Policy Optimization (PPO)-based reinforcement learning method that develops adaptive power and tilt control strategies. Simulation results demonstrate a reduction up to 8 dB in the median interference-to-noise ratio (INR) while maintaining over 87% TN basestation activity, outperforming conventional baseline methods and validating the feasibility of the proposed strategy for FR3 coexistence.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u63a7\u5236\u5730\u9762\u7f51\u7edc\u7684\u4e0b\u884c\u529f\u7387\u3001\u4e0a\u884c\u529f\u7387\u548c\u5929\u7ebf\u503e\u89d2\u6765\u4fdd\u62a4\u975e\u5730\u9762\u7f51\u7edc\u94fe\u8def\uff0c\u540c\u65f6\u4fdd\u6301\u5730\u9762\u7f51\u7edc\u6027\u80fd\uff0c\u89e3\u51b3\u4e86FR3\u9891\u6bb5\u5171\u5b58\u4e2d\u7684\u5e72\u6270\u95ee\u9898\u3002", "motivation": "\u5728FR3\u9891\u6bb5\u4e0a\uff0c\u5730\u9762\u7f51\u7edc\uff08TN\uff09\u548c\u975e\u5730\u9762\u7f51\u7edc\uff08NTN\uff09\u5171\u5b58\u5b58\u5728\u4e25\u91cd\u5e72\u6270\u95ee\u9898\uff0c\u5bc6\u96c6\u7684TN\u90e8\u7f72\u4f1a\u4e25\u91cd\u964d\u4f4eNTN\u4e0b\u884c\u6027\u80fd\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5e72\u6270\u6d88\u9664\u6ce2\u675f\u6210\u5f62\u3001\u9884\u7f16\u7801\u6216\u6392\u9664\u533a\u57df\uff0c\u9700\u8981\u51c6\u786e\u7684\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u548c\u9759\u6001\u534f\u8c03\uff0c\u4e0d\u9002\u7528\u4e8e\u52a8\u6001NTN\u573a\u666f\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4f18\u5316\u6846\u67b6\uff0c\u8054\u5408\u63a7\u5236TN\u4e0b\u884c\u529f\u7387\u3001\u4e0a\u884c\u529f\u7387\u548c\u5929\u7ebf\u503e\u89d2\u6765\u4fdd\u62a4NTN\u94fe\u8def\u3002\u91c7\u7528\u57fa\u4e8e\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6765\u89e3\u51b3TN\u548cNTN\u53c2\u6570\u4e4b\u95f4\u7684\u975e\u51f8\u8026\u5408\u95ee\u9898\uff0c\u5f00\u53d1\u81ea\u9002\u5e94\u529f\u7387\u548c\u503e\u89d2\u63a7\u5236\u7b56\u7565\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u5c06\u4e2d\u503c\u5e72\u6270\u566a\u58f0\u6bd4\uff08INR\uff09\u964d\u4f4e\u9ad8\u8fbe8dB\uff0c\u540c\u65f6\u4fdd\u6301\u8d85\u8fc787%\u7684TN\u57fa\u7ad9\u6d3b\u52a8\u7387\uff0c\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u7b56\u7565\u5728FR3\u5171\u5b58\u4e2d\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u5316\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86FR3\u9891\u6bb5TN\u548cNTN\u5171\u5b58\u4e2d\u7684\u5e72\u6270\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u529f\u7387\u548c\u503e\u89d2\u63a7\u5236\u7b56\u7565\uff0c\u5728\u4fdd\u62a4NTN\u94fe\u8def\u7684\u540c\u65f6\u4fdd\u6301\u4e86TN\u6027\u80fd\uff0c\u4e3a\u52a8\u6001NTN\u573a\u666f\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.10929", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.10929", "abs": "https://arxiv.org/abs/2602.10929", "authors": ["Julien Molina"], "title": "MacWilliams identities for the generalized rank weights", "comment": null, "summary": "We study the generalized rank weight distribution of a linear code. First, we provide a MacWilliams-type identity which relates the distributions of a code and its dual. Then, we give a formula for the enumerator polynomial. Finally, we explicitly compute the distribution of an MRD code.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u7ebf\u6027\u7801\u7684\u5e7f\u4e49\u79e9\u91cd\u91cf\u5206\u5e03\uff0c\u5efa\u7acb\u4e86MacWilliams\u578b\u6052\u7b49\u5f0f\uff0c\u7ed9\u51fa\u4e86\u679a\u4e3e\u591a\u9879\u5f0f\u516c\u5f0f\uff0c\u5e76\u8ba1\u7b97\u4e86MRD\u7801\u7684\u5206\u5e03", "motivation": "\u7814\u7a76\u7ebf\u6027\u7801\u7684\u5e7f\u4e49\u79e9\u91cd\u91cf\u5206\u5e03\u5bf9\u4e8e\u7406\u89e3\u7801\u7684\u7ed3\u6784\u548c\u6027\u80fd\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u7279\u522b\u662f\u5728\u79e9\u5ea6\u91cf\u7801\u7684\u80cc\u666f\u4e0b", "method": "1. \u5efa\u7acb\u5e7f\u4e49\u79e9\u91cd\u91cf\u5206\u5e03\u7684MacWilliams\u578b\u6052\u7b49\u5f0f\uff0c\u5c06\u7801\u4e0e\u5176\u5bf9\u5076\u7801\u7684\u5206\u5e03\u8054\u7cfb\u8d77\u6765\n2. \u63a8\u5bfc\u5e7f\u4e49\u79e9\u91cd\u91cf\u5206\u5e03\u7684\u679a\u4e3e\u591a\u9879\u5f0f\u516c\u5f0f\n3. \u9488\u5bf9\u6700\u5927\u79e9\u8ddd\u79bb\u7801\uff08MRD\u7801\uff09\u8fdb\u884c\u5177\u4f53\u7684\u5206\u5e03\u8ba1\u7b97", "result": "1. \u6210\u529f\u5efa\u7acb\u4e86\u5e7f\u4e49\u79e9\u91cd\u91cf\u5206\u5e03\u7684MacWilliams\u578b\u6052\u7b49\u5f0f\n2. \u5f97\u5230\u4e86\u5e7f\u4e49\u79e9\u91cd\u91cf\u5206\u5e03\u7684\u679a\u4e3e\u591a\u9879\u5f0f\u516c\u5f0f\n3. \u660e\u786e\u8ba1\u7b97\u51fa\u4e86MRD\u7801\u7684\u5e7f\u4e49\u79e9\u91cd\u91cf\u5206\u5e03", "conclusion": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u7ebf\u6027\u7801\u7684\u5e7f\u4e49\u79e9\u91cd\u91cf\u5206\u5e03\uff0c\u5efa\u7acb\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u79e9\u5ea6\u91cf\u7801\u7684\u5206\u6790\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\uff0c\u7279\u522b\u662f\u5bf9MRD\u7801\u7684\u5206\u5e03\u8ba1\u7b97\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2602.10615", "categories": ["cs.NI", "cs.PF", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10615", "abs": "https://arxiv.org/abs/2602.10615", "authors": ["Fei Long", "Kaihui Gao", "Li Chen", "Dan Li", "Yiwei Zhang", "Fei Gui", "Yitao Xing", "Wenjia Wei", "Bingyang Liu"], "title": "Supercharging Packet-level Network Simulation of Large Model Training via Memoization and Fast-Forwarding", "comment": "13 pages body, 21 pages total", "summary": "Packet-level discrete-event simulation (PLDES) is a prevalent tool for evaluating detailed performance of large model training. Although PLDES offers high fidelity and generality, its slow performance has plagued networking practitioners. Existing optimization techniques either simplify the network model, resulting in large errors; or execute it in parallel using multiple processors, with an upper bound on speedup. This paper explores an alternative optimization direction that reduces the computational loads of PLDES while maintaining high fidelity. Our key insight is that, in distributed LLM training, packet-level traffic behaviors often exhibit repetitive contention patterns and steady-states where flow rates stabilize, ignoring these redundant discrete events speeds up the simulation considerably and the error is negligible. We realize this idea by proposing Wormhole, a user-transparent PLDES kernel capable of automatically memoization for unsteady-states and skipping for steady-states. Wormhole adopts network partitioning, state memoization and reuse, and rate-based steady-state identification to accurately determine the periods of each flow's steady-state, while maintaining simulation consistency after fast-forwarding. Experiments demonstrate that Wormhole can achieve a 744x speedup over the original ns-3 (510x for MoE workload), with a bounded error of <1%. Applying current multithreading parallel techniques and Wormhole together allows a 1012x speedup, reducing the simulation time for one GPT-13B training under 128 GPUs from 9 hours to 5 minutes.", "AI": {"tldr": "Wormhole \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684 PLDES \u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u548c\u8df3\u8fc7\u5197\u4f59\u7684\u79bb\u6563\u4e8b\u4ef6\uff08\u7279\u522b\u662f\u7a33\u6001\u6d41\u91cf\uff09\uff0c\u5728\u4fdd\u6301\u9ad8\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\u663e\u8457\u52a0\u901f\u6a21\u62df\uff0c\u5b9e\u73b0744\u500d\u52a0\u901f\uff0c\u8bef\u5dee\u5c0f\u4e8e1%\u3002", "motivation": "PLDES\uff08\u5305\u7ea7\u79bb\u6563\u4e8b\u4ef6\u6a21\u62df\uff09\u662f\u8bc4\u4f30\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u6027\u80fd\u7684\u91cd\u8981\u5de5\u5177\uff0c\u4f46\u73b0\u6709\u4f18\u5316\u65b9\u6cd5\u8981\u4e48\u7b80\u5316\u7f51\u7edc\u6a21\u578b\u5bfc\u81f4\u5927\u8bef\u5dee\uff0c\u8981\u4e48\u5e76\u884c\u6267\u884c\u4f46\u52a0\u901f\u4e0a\u9650\u6709\u9650\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u9ad8\u4fdd\u771f\u5ea6\u53c8\u80fd\u663e\u8457\u52a0\u901f\u7684\u65b0\u65b9\u6cd5\u3002", "method": "Wormhole \u91c7\u7528\u7f51\u7edc\u5206\u533a\u3001\u72b6\u6001\u8bb0\u5fc6\u5316\u548c\u91cd\u7528\u3001\u57fa\u4e8e\u901f\u7387\u7684\u7a33\u6001\u8bc6\u522b\u6280\u672f\uff0c\u81ea\u52a8\u8bb0\u5fc6\u975e\u7a33\u6001\u5e76\u8df3\u8fc7\u7a33\u6001\u671f\u95f4\u7684\u5197\u4f59\u4e8b\u4ef6\uff0c\u5728\u5feb\u901f\u8f6c\u53d1\u540e\u4fdd\u6301\u6a21\u62df\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793a Wormhole \u76f8\u6bd4\u539f\u59cb ns-3 \u5b9e\u73b0744\u500d\u52a0\u901f\uff08MoE\u5de5\u4f5c\u8d1f\u8f7d\u4e3a510\u500d\uff09\uff0c\u8bef\u5dee\u5c0f\u4e8e1%\u3002\u7ed3\u5408\u73b0\u6709\u591a\u7ebf\u7a0b\u5e76\u884c\u6280\u672f\u53ef\u5b9e\u73b01012\u500d\u52a0\u901f\uff0c\u5c06128 GPU\u4e0bGPT-13B\u8bad\u7ec3\u6a21\u62df\u65f6\u95f4\u4ece9\u5c0f\u65f6\u51cf\u5c11\u52305\u5206\u949f\u3002", "conclusion": "Wormhole \u901a\u8fc7\u8bc6\u522b\u548c\u8df3\u8fc7\u5206\u5e03\u5f0fLLM\u8bad\u7ec3\u4e2d\u7684\u5197\u4f59\u79bb\u6563\u4e8b\u4ef6\uff0c\u5728\u4fdd\u6301\u9ad8\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u6570\u91cf\u7ea7\u7684\u52a0\u901f\uff0c\u4e3a\u5927\u89c4\u6a21\u8bad\u7ec3\u6a21\u62df\u63d0\u4f9b\u4e86\u5b9e\u7528\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.10324", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10324", "abs": "https://arxiv.org/abs/2602.10324", "authors": ["Caroline Wang", "Daniel Kasenberg", "Kim Stachenfeld", "Pablo Samuel Castro"], "title": "Discovering Differences in Strategic Behavior Between Humans and LLMs", "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed in social and strategic scenarios, it becomes critical to understand where and why their behavior diverges from that of humans. While behavioral game theory (BGT) provides a framework for analyzing behavior, existing models do not fully capture the idiosyncratic behavior of humans or black-box, non-human agents like LLMs. We employ AlphaEvolve, a cutting-edge program discovery tool, to directly discover interpretable models of human and LLM behavior from data, thereby enabling open-ended discovery of structural factors driving human and LLM behavior. Our analysis on iterated rock-paper-scissors reveals that frontier LLMs can be capable of deeper strategic behavior than humans. These results provide a foundation for understanding structural differences driving differences in human and LLM behavior in strategic interactions.", "AI": {"tldr": "\u4f7f\u7528AlphaEvolve\u5de5\u5177\u53d1\u73b0\u53ef\u89e3\u91ca\u6a21\u578b\uff0c\u5206\u6790\u4eba\u7c7b\u4e0eLLM\u5728\u8fed\u4ee3\u526a\u5200\u77f3\u5934\u5e03\u6e38\u620f\u4e2d\u7684\u6218\u7565\u884c\u4e3a\u5dee\u5f02\uff0c\u53d1\u73b0\u524d\u6cbfLLM\u6bd4\u4eba\u7c7b\u8868\u73b0\u51fa\u66f4\u6df1\u5c42\u7684\u6218\u7565\u80fd\u529b\u3002", "motivation": "\u968f\u7740LLM\u5728\u793e\u4ea4\u548c\u6218\u7565\u573a\u666f\u4e2d\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u9700\u8981\u7406\u89e3\u5176\u884c\u4e3a\u4e0e\u4eba\u7c7b\u7684\u5dee\u5f02\u3002\u73b0\u6709\u884c\u4e3a\u535a\u5f08\u8bba\u6a21\u578b\u65e0\u6cd5\u5b8c\u5168\u6355\u6349\u4eba\u7c7b\u6216LLM\u7b49\u9ed1\u7bb1\u975e\u4eba\u7c7b\u4ee3\u7406\u7684\u72ec\u7279\u884c\u4e3a\u3002", "method": "\u91c7\u7528AlphaEvolve\u8fd9\u4e00\u524d\u6cbf\u7a0b\u5e8f\u53d1\u73b0\u5de5\u5177\uff0c\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u53d1\u73b0\u4eba\u7c7b\u548cLLM\u884c\u4e3a\u7684\u53ef\u89e3\u91ca\u6a21\u578b\uff0c\u5b9e\u73b0\u5bf9\u4eba\u7c7b\u548cLLM\u884c\u4e3a\u9a71\u52a8\u56e0\u7d20\u7684\u5f00\u6e90\u53d1\u73b0\u3002", "result": "\u5728\u8fed\u4ee3\u526a\u5200\u77f3\u5934\u5e03\u6e38\u620f\u4e2d\uff0c\u524d\u6cbfLLM\u5c55\u73b0\u51fa\u6bd4\u4eba\u7c7b\u66f4\u6df1\u5c42\u7684\u6218\u7565\u884c\u4e3a\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u4eba\u7c7b\u4e0eLLM\u5728\u6218\u7565\u4e92\u52a8\u4e2d\u7684\u7ed3\u6784\u6027\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u4e3a\u7406\u89e3\u4eba\u7c7b\u4e0eLLM\u5728\u6218\u7565\u4e92\u52a8\u4e2d\u884c\u4e3a\u5dee\u5f02\u7684\u7ed3\u6784\u6027\u9a71\u52a8\u56e0\u7d20\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u8868\u660e\u9700\u8981\u65b0\u7684\u5efa\u6a21\u65b9\u6cd5\u6765\u6355\u6349LLM\u7684\u6218\u7565\u884c\u4e3a\u7279\u5f81\u3002"}}
{"id": "2602.10252", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.10252", "abs": "https://arxiv.org/abs/2602.10252", "authors": ["Sanjoli Narang", "Anup Agarwal", "Venkat Arun", "Manya Ghobadi"], "title": "Bring Your Own Objective: Inter-operability of Network Objectives in Datacenters", "comment": null, "summary": "Datacenter networks are currently locked in a \"tyranny of the single objective\". While modern workloads demand diverse performance goals, ranging from coflow completion times, per-flow fairness, short-flow latencies, existing fabrics are typically hardcoded for a single metric. This rigid coupling ensures peak performance when application and network objectives align, but results in abysmal performance when they diverge.\n  We propose DMart, a decentralized scheduling framework that treats network bandwidth as a competitive marketplace. In DMart, applications independently encode the urgency and importance of their network traffic into autonomous bids, allowing diverse objectives to co-exist natively on the same fabric. To meet the extreme scale and sub-microsecond requirements of modern datacenters, DMart implements distributed, per-link, per-RTT auctions, without relying on ILPs, centralized schedulers, or complex priority queues.\n  We evaluate DMart using packet-level simulations and compare it against network schedulers designed for individual metrics, e.g., pFabric and Sincronia. DMart matches the performance of specialized schedulers on their own \"home turf\" while simultaneously optimizing secondary metrics. Compared to pFabric and Sincronia, DMart reduces deadline misses by 2x and coflow completion times by 1.6x respectively, while matching pFabric short-flow completion times.", "AI": {"tldr": "DMart\u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u8c03\u5ea6\u6846\u67b6\uff0c\u5c06\u5e26\u5bbd\u89c6\u4e3a\u7ade\u4e89\u6027\u5e02\u573a\uff0c\u901a\u8fc7\u5e94\u7528\u81ea\u4e3b\u51fa\u4ef7\u5b9e\u73b0\u591a\u79cd\u6027\u80fd\u76ee\u6807\u7684\u5171\u5b58\uff0c\u65e0\u9700\u96c6\u4e2d\u8c03\u5ea6\u5668\u6216\u590d\u6742\u4f18\u5148\u7ea7\u961f\u5217\u3002", "motivation": "\u73b0\u4ee3\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u88ab\"\u5355\u4e00\u76ee\u6807\u7684\u66b4\u653f\"\u6240\u56f0\uff0c\u73b0\u6709\u7f51\u7edc\u67b6\u6784\u901a\u5e38\u9488\u5bf9\u5355\u4e00\u6027\u80fd\u6307\u6807\u786c\u7f16\u7801\uff0c\u5f53\u5e94\u7528\u9700\u6c42\u4e0e\u7f51\u7edc\u76ee\u6807\u4e0d\u4e00\u81f4\u65f6\u6027\u80fd\u6025\u5267\u4e0b\u964d\u3002\u73b0\u4ee3\u5de5\u4f5c\u8d1f\u8f7d\u9700\u8981\u591a\u6837\u5316\u7684\u6027\u80fd\u76ee\u6807\uff08\u5982coflow\u5b8c\u6210\u65f6\u95f4\u3001\u6d41\u516c\u5e73\u6027\u3001\u77ed\u6d41\u5ef6\u8fdf\u7b49\uff09\uff0c\u4f46\u73b0\u6709\u7f51\u7edc\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u8fd9\u4e9b\u9700\u6c42\u3002", "method": "DMart\u91c7\u7528\u53bb\u4e2d\u5fc3\u5316\u7684\u8c03\u5ea6\u6846\u67b6\uff0c\u5c06\u7f51\u7edc\u5e26\u5bbd\u89c6\u4e3a\u7ade\u4e89\u6027\u5e02\u573a\u3002\u5e94\u7528\u72ec\u7acb\u5730\u5c06\u7f51\u7edc\u6d41\u91cf\u7684\u7d27\u6025\u6027\u548c\u91cd\u8981\u6027\u7f16\u7801\u4e3a\u81ea\u4e3b\u51fa\u4ef7\uff0c\u5b9e\u73b0\u591a\u79cd\u76ee\u6807\u5728\u540c\u4e00\u7f51\u7edc\u4e0a\u7684\u539f\u751f\u5171\u5b58\u3002\u4e3a\u6ee1\u8db3\u73b0\u4ee3\u6570\u636e\u4e2d\u5fc3\u7684\u6781\u7aef\u89c4\u6a21\u548c\u4e9a\u5fae\u79d2\u7ea7\u8981\u6c42\uff0cDMart\u5b9e\u73b0\u4e86\u5206\u5e03\u5f0f\u3001\u6bcf\u94fe\u8def\u3001\u6bcfRTT\u7684\u62cd\u5356\u673a\u5236\uff0c\u4e0d\u4f9d\u8d56\u6574\u6570\u7ebf\u6027\u89c4\u5212\u3001\u96c6\u4e2d\u8c03\u5ea6\u5668\u6216\u590d\u6742\u4f18\u5148\u7ea7\u961f\u5217\u3002", "result": "\u901a\u8fc7\u5305\u7ea7\u4eff\u771f\u8bc4\u4f30\uff0cDMart\u5728\u4e13\u7528\u8c03\u5ea6\u5668\u5404\u81ea\u7684\"\u4e3b\u573a\"\u4e0a\u80fd\u5339\u914d\u5176\u6027\u80fd\uff0c\u540c\u65f6\u4f18\u5316\u6b21\u8981\u6307\u6807\u3002\u76f8\u6bd4pFabric\u548cSincronia\uff0cDMart\u5c06\u622a\u6b62\u65f6\u95f4\u9519\u8fc7\u7387\u964d\u4f4e2\u500d\uff0c\u5c06coflow\u5b8c\u6210\u65f6\u95f4\u51cf\u5c111.6\u500d\uff0c\u540c\u65f6\u5339\u914dpFabric\u7684\u77ed\u6d41\u5b8c\u6210\u65f6\u95f4\u3002", "conclusion": "DMart\u901a\u8fc7\u5e02\u573a\u5316\u7684\u5e26\u5bbd\u5206\u914d\u673a\u5236\uff0c\u6253\u7834\u4e86\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u7684\"\u5355\u4e00\u76ee\u6807\u66b4\u653f\"\uff0c\u5b9e\u73b0\u4e86\u591a\u79cd\u6027\u80fd\u76ee\u6807\u7684\u548c\u8c10\u5171\u5b58\uff0c\u4e3a\u73b0\u4ee3\u591a\u6837\u5316\u5de5\u4f5c\u8d1f\u8f7d\u63d0\u4f9b\u4e86\u7075\u6d3b\u9ad8\u6548\u7684\u7f51\u7edc\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.11022", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.11022", "abs": "https://arxiv.org/abs/2602.11022", "authors": ["Haoyuan Zhu", "Haonan Hu", "Jie Zhang"], "title": "Information Abstraction for Data Transmission Networks based on Large Language Models", "comment": null, "summary": "Biological systems, particularly the human brain, achieve remarkable energy efficiency by abstracting information across multiple hierarchical levels. In contrast, modern artificial intelligence and communication systems often consume significant energy overheads in transmitting low-level data, with limited emphasis on abstraction. Despite its implicit importance, a formal and computational theory of information abstraction remains absent. In this work, we introduce the Degree of Information Abstraction (DIA), a general metric that quantifies how well a representation compresses input data while preserving task-relevant semantics. We derive a tractable information-theoretic formulation of DIA and propose a DIA-based information abstraction framework. As a case study, we apply DIA to a large language model (LLM)-guided video transmission task, where abstraction-aware encoding significantly reduces transmission volume by $99.75\\%$, while maintaining semantic fidelity. Our results suggest that DIA offers a principled tool for rebalancing energy and information in intelligent systems and opens new directions in neural network design, neuromorphic computing, semantic communication, and joint sensing-communication architectures.", "AI": {"tldr": "\u63d0\u51fa\u4fe1\u606f\u62bd\u8c61\u5ea6(DIA)\u8fd9\u4e00\u91cf\u5316\u6307\u6807\uff0c\u7528\u4e8e\u8861\u91cf\u8868\u793a\u5728\u538b\u7f29\u8f93\u5165\u6570\u636e\u7684\u540c\u65f6\u4fdd\u7559\u4efb\u52a1\u76f8\u5173\u8bed\u4e49\u7684\u80fd\u529b\uff0c\u5e76\u5728LLM\u5f15\u5bfc\u7684\u89c6\u9891\u4f20\u8f93\u4efb\u52a1\u4e2d\u5b9e\u73b099.75%\u7684\u4f20\u8f93\u91cf\u51cf\u5c11\u3002", "motivation": "\u751f\u7269\u7cfb\u7edf\uff08\u7279\u522b\u662f\u4eba\u8111\uff09\u901a\u8fc7\u591a\u5c42\u6b21\u7684\u4fe1\u606f\u62bd\u8c61\u5b9e\u73b0\u5353\u8d8a\u7684\u80fd\u6548\uff0c\u800c\u73b0\u4ee3\u4eba\u5de5\u667a\u80fd\u548c\u901a\u4fe1\u7cfb\u7edf\u5728\u4f20\u8f93\u4f4e\u5c42\u6570\u636e\u65f6\u6d88\u8017\u5927\u91cf\u80fd\u91cf\uff0c\u7f3a\u4e4f\u5bf9\u62bd\u8c61\u7684\u91cd\u89c6\u3002\u76ee\u524d\u7f3a\u4e4f\u5f62\u5f0f\u5316\u548c\u8ba1\u7b97\u5316\u7684\u4fe1\u606f\u62bd\u8c61\u7406\u8bba\u3002", "method": "\u5f15\u5165\u4fe1\u606f\u62bd\u8c61\u5ea6(DIA)\u8fd9\u4e00\u901a\u7528\u5ea6\u91cf\u6807\u51c6\uff0c\u63a8\u5bfc\u51fa\u53ef\u5904\u7406\u7684\u4fe1\u606f\u8bba\u516c\u5f0f\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8eDIA\u7684\u4fe1\u606f\u62bd\u8c61\u6846\u67b6\u3002\u4ee5LLM\u5f15\u5bfc\u7684\u89c6\u9891\u4f20\u8f93\u4efb\u52a1\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u5e94\u7528DIA\u8fdb\u884c\u62bd\u8c61\u611f\u77e5\u7f16\u7801\u3002", "result": "\u5728LLM\u5f15\u5bfc\u7684\u89c6\u9891\u4f20\u8f93\u4efb\u52a1\u4e2d\uff0c\u57fa\u4e8eDIA\u7684\u62bd\u8c61\u611f\u77e5\u7f16\u7801\u5c06\u4f20\u8f93\u91cf\u51cf\u5c11\u4e8699.75%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002", "conclusion": "DIA\u4e3a\u667a\u80fd\u7cfb\u7edf\u4e2d\u80fd\u91cf\u4e0e\u4fe1\u606f\u7684\u91cd\u65b0\u5e73\u8861\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u5de5\u5177\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u3001\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u3001\u8bed\u4e49\u901a\u4fe1\u548c\u8054\u5408\u611f\u77e5-\u901a\u4fe1\u67b6\u6784\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.10367", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10367", "abs": "https://arxiv.org/abs/2602.10367", "authors": ["Zhiling Yan", "Dingjie Song", "Zhe Fang", "Yisheng Ji", "Xiang Li", "Quanzheng Li", "Lichao Sun"], "title": "LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation", "comment": null, "summary": "The deployment of Large Language Models (LLMs) in high-stakes clinical settings demands rigorous and reliable evaluation. However, existing medical benchmarks remain static, suffering from two critical limitations: (1) data contamination, where test sets inadvertently leak into training corpora, leading to inflated performance estimates; and (2) temporal misalignment, failing to capture the rapid evolution of medical knowledge. Furthermore, current evaluation metrics for open-ended clinical reasoning often rely on either shallow lexical overlap (e.g., ROUGE) or subjective LLM-as-a-Judge scoring, both inadequate for verifying clinical correctness. To bridge these gaps, we introduce LiveMedBench, a continuously updated, contamination-free, and rubric-based benchmark that weekly harvests real-world clinical cases from online medical communities, ensuring strict temporal separation from model training data. We propose a Multi-Agent Clinical Curation Framework that filters raw data noise and validates clinical integrity against evidence-based medical principles. For evaluation, we develop an Automated Rubric-based Evaluation Framework that decomposes physician responses into granular, case-specific criteria, achieving substantially stronger alignment with expert physicians than LLM-as-a-Judge. To date, LiveMedBench comprises 2,756 real-world cases spanning 38 medical specialties and multiple languages, paired with 16,702 unique evaluation criteria. Extensive evaluation of 38 LLMs reveals that even the best-performing model achieves only 39.2%, and 84% of models exhibit performance degradation on post-cutoff cases, confirming pervasive data contamination risks. Error analysis further identifies contextual application-not factual knowledge-as the dominant bottleneck, with 35-48% of failures stemming from the inability to tailor medical knowledge to patient-specific constraints.", "AI": {"tldr": "LiveMedBench\uff1a\u4e00\u4e2a\u6301\u7eed\u66f4\u65b0\u3001\u65e0\u6570\u636e\u6c61\u67d3\u3001\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u4e34\u5e8a\u533b\u5b66\u57fa\u51c6\uff0c\u901a\u8fc7\u6bcf\u5468\u4ece\u5728\u7ebf\u533b\u7597\u793e\u533a\u6536\u96c6\u771f\u5b9e\u75c5\u4f8b\uff0c\u89e3\u51b3\u73b0\u6709\u533b\u5b66\u57fa\u51c6\u7684\u9759\u6001\u6027\u3001\u6570\u636e\u6c61\u67d3\u548c\u65f6\u95f4\u9519\u4f4d\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u533b\u5b66\u57fa\u51c6\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a1) \u6570\u636e\u6c61\u67d3\uff08\u6d4b\u8bd5\u96c6\u6cc4\u9732\u5230\u8bad\u7ec3\u6570\u636e\u4e2d\u5bfc\u81f4\u6027\u80fd\u4f30\u8ba1\u865a\u9ad8\uff09\uff1b2) \u65f6\u95f4\u9519\u4f4d\uff08\u65e0\u6cd5\u6355\u6349\u533b\u5b66\u77e5\u8bc6\u7684\u5feb\u901f\u6f14\u8fdb\uff09\u3002\u6b64\u5916\uff0c\u5f53\u524d\u5f00\u653e\u5f0f\u4e34\u5e8a\u63a8\u7406\u8bc4\u4f30\u6307\u6807\u8981\u4e48\u4f9d\u8d56\u6d45\u5c42\u8bcd\u6c47\u91cd\u53e0\uff08\u5982ROUGE\uff09\uff0c\u8981\u4e48\u4f9d\u8d56\u4e3b\u89c2\u7684LLM-as-a-Judge\u8bc4\u5206\uff0c\u90fd\u4e0d\u8db3\u4ee5\u9a8c\u8bc1\u4e34\u5e8a\u6b63\u786e\u6027\u3002", "method": "1) \u6784\u5efaLiveMedBench\u57fa\u51c6\uff1a\u6bcf\u5468\u4ece\u5728\u7ebf\u533b\u7597\u793e\u533a\u6536\u96c6\u771f\u5b9e\u4e34\u5e8a\u75c5\u4f8b\uff0c\u786e\u4fdd\u4e0e\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u7684\u4e25\u683c\u65f6\u95f4\u5206\u79bb\uff1b2) \u591a\u667a\u80fd\u4f53\u4e34\u5e8a\u7b5b\u9009\u6846\u67b6\uff1a\u8fc7\u6ee4\u539f\u59cb\u6570\u636e\u566a\u58f0\uff0c\u57fa\u4e8e\u5faa\u8bc1\u533b\u5b66\u539f\u5219\u9a8c\u8bc1\u4e34\u5e8a\u5b8c\u6574\u6027\uff1b3) \u81ea\u52a8\u5316\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u4f30\u6846\u67b6\uff1a\u5c06\u533b\u751f\u56de\u7b54\u5206\u89e3\u4e3a\u7ec6\u7c92\u5ea6\u7684\u75c5\u4f8b\u7279\u5b9a\u6807\u51c6\uff0c\u6bd4LLM-as-a-Judge\u8bc4\u5206\u4e0e\u4e13\u5bb6\u533b\u751f\u66f4\u4e00\u81f4\u3002", "result": "LiveMedBench\u5305\u542b2,756\u4e2a\u771f\u5b9e\u75c5\u4f8b\uff0c\u6db5\u76d638\u4e2a\u533b\u5b66\u4e13\u79d1\u548c\u591a\u79cd\u8bed\u8a00\uff0c\u914d\u670916,702\u4e2a\u72ec\u7279\u8bc4\u4f30\u6807\u51c6\u3002\u5bf938\u4e2aLLM\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff1a\u6700\u4f73\u6a21\u578b\u4ec5\u8fbe\u523039.2%\u7684\u51c6\u786e\u7387\uff1b84%\u7684\u6a21\u578b\u5728\u622a\u6b62\u65e5\u671f\u540e\u7684\u75c5\u4f8b\u4e0a\u8868\u73b0\u4e0b\u964d\uff0c\u8bc1\u5b9e\u4e86\u666e\u904d\u7684\u6570\u636e\u6c61\u67d3\u98ce\u9669\uff1b\u9519\u8bef\u5206\u6790\u8868\u660e35-48%\u7684\u5931\u8d25\u6e90\u4e8e\u65e0\u6cd5\u5c06\u533b\u5b66\u77e5\u8bc6\u9002\u5e94\u60a3\u8005\u7279\u5b9a\u7ea6\u675f\uff0c\u4e0a\u4e0b\u6587\u5e94\u7528\u800c\u975e\u4e8b\u5b9e\u77e5\u8bc6\u662f\u4e3b\u8981\u74f6\u9888\u3002", "conclusion": "LiveMedBench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u9760\u3001\u52a8\u6001\u7684\u4e34\u5e8a\u533b\u5b66\u8bc4\u4f30\u57fa\u51c6\uff0c\u63ed\u793a\u4e86LLM\u5728\u4e34\u5e8a\u63a8\u7406\u4e2d\u7684\u5b9e\u9645\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u6570\u636e\u6c61\u67d3\u95ee\u9898\u548c\u4e0a\u4e0b\u6587\u5e94\u7528\u80fd\u529b\u4e0d\u8db3\uff0c\u4e3a\u672a\u6765\u4e34\u5e8aAI\u7cfb\u7edf\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2602.10468", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.10468", "abs": "https://arxiv.org/abs/2602.10468", "authors": ["Anchengcheng Zhou", "Vamsi Addanki", "Maria Apostolaki"], "title": "To Reconfigure or Not to Reconfigure: Optimizing All-to-All Collectives in Circuit-Switched Photonic Interconnects", "comment": null, "summary": "All-to-all collective communication is a core primitive in distributed machine learning and high-performance computing. At the server scale, the communication demands of these workloads are increasingly outstripping the bandwidth and energy limits of electrical interconnects, driving a growing interest in photonic interconnects. However, leveraging these interconnects for all-to-all communication is nontrivial. The core challenge lies in jointly optimizing a sequence of topologies and flow schedules, reconfiguring only when the transmission savings from traversing shorter paths outweigh the reconfiguration cost. Yet the search space of this joint optimization is enormous. Existing work sidesteps this challenge by making unrealistic assumptions on reconfiguration costs so that it is never or always worthwhile to reconfigure. In this paper, we show that any candidate sequence of topologies and flow schedules can be expressed as a sum of adjacency matrices and their powers. This abstraction captures the entire solution space and yields a lower bound on all-to-all completion time. Building on this formulation, we identify a family of topology sequences with strong symmetry and high expansion that admits bandwidth-efficient schedules, which our algorithm constructs with low computational overhead. Together, these insights allow us to efficiently construct near-optimal solutions, effectively avoiding enumeration of the combinatorial design space. Evaluation shows that our approach reduces all-to-all completion time by up to 44% on average across a wide range of network parameters, message sizes and workload types.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u77e9\u9635\u5206\u89e3\u7684\u62bd\u8c61\u65b9\u6cd5\uff0c\u5c06\u5168\u5bf9\u5168\u901a\u4fe1\u4e2d\u7684\u62d3\u6251\u5e8f\u5217\u548c\u6d41\u8c03\u5ea6\u4f18\u5316\u95ee\u9898\u8868\u8fbe\u4e3a\u90bb\u63a5\u77e9\u9635\u53ca\u5176\u5e42\u6b21\u7684\u548c\uff0c\u4ece\u800c\u9ad8\u6548\u6784\u5efa\u8fd1\u4f18\u89e3\uff0c\u907f\u514d\u7ec4\u5408\u7a7a\u95f4\u679a\u4e3e\u3002", "motivation": "\u968f\u7740\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e2d\u5168\u5bf9\u5168\u901a\u4fe1\u9700\u6c42\u589e\u957f\uff0c\u7535\u4e92\u8fde\u7684\u5e26\u5bbd\u548c\u80fd\u8017\u9650\u5236\u65e5\u76ca\u7a81\u51fa\uff0c\u5149\u5b50\u4e92\u8fde\u6210\u4e3a\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u7136\u800c\uff0c\u5229\u7528\u5149\u5b50\u4e92\u8fde\u8fdb\u884c\u5168\u5bf9\u5168\u901a\u4fe1\u9762\u4e34\u6838\u5fc3\u6311\u6218\uff1a\u9700\u8981\u5728\u62d3\u6251\u5e8f\u5217\u548c\u6d41\u8c03\u5ea6\u4e4b\u95f4\u8fdb\u884c\u8054\u5408\u4f18\u5316\uff0c\u6743\u8861\u91cd\u914d\u7f6e\u6210\u672c\u4e0e\u4f20\u8f93\u8282\u7701\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u56e0\u5bf9\u91cd\u914d\u7f6e\u6210\u672c\u505a\u51fa\u4e0d\u5207\u5b9e\u9645\u7684\u5047\u8bbe\u800c\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6570\u5b66\u62bd\u8c61\u65b9\u6cd5\uff0c\u5c06\u5019\u9009\u7684\u62d3\u6251\u5e8f\u5217\u548c\u6d41\u8c03\u5ea6\u8868\u8fbe\u4e3a\u90bb\u63a5\u77e9\u9635\u53ca\u5176\u5e42\u6b21\u7684\u548c\uff0c\u8fd9\u79cd\u62bd\u8c61\u80fd\u6355\u6349\u6574\u4e2a\u89e3\u7a7a\u95f4\u5e76\u63d0\u4f9b\u5168\u5bf9\u5168\u5b8c\u6210\u65f6\u95f4\u7684\u4e0b\u754c\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u8bc6\u522b\u51fa\u4e00\u7c7b\u5177\u6709\u5f3a\u5bf9\u79f0\u6027\u548c\u9ad8\u6269\u5c55\u6027\u7684\u62d3\u6251\u5e8f\u5217\u65cf\uff0c\u8be5\u65cf\u5141\u8bb8\u5e26\u5bbd\u9ad8\u6548\u7684\u8c03\u5ea6\uff0c\u5e76\u8bbe\u8ba1\u7b97\u6cd5\u4ee5\u4f4e\u8ba1\u7b97\u5f00\u9500\u6784\u5efa\u8fd9\u4e9b\u8c03\u5ea6\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5e7f\u6cdb\u7684\u7f51\u7edc\u53c2\u6570\u3001\u6d88\u606f\u5927\u5c0f\u548c\u5de5\u4f5c\u8d1f\u8f7d\u7c7b\u578b\u4e0b\uff0c\u5e73\u5747\u51cf\u5c11\u5168\u5bf9\u5168\u5b8c\u6210\u65f6\u95f4\u8fbe44%\u3002", "conclusion": "\u901a\u8fc7\u5c06\u5168\u5bf9\u5168\u901a\u4fe1\u4f18\u5316\u95ee\u9898\u62bd\u8c61\u4e3a\u77e9\u9635\u5206\u89e3\u5f62\u5f0f\uff0c\u80fd\u591f\u9ad8\u6548\u6784\u5efa\u8fd1\u4f18\u89e3\uff0c\u907f\u514d\u7ec4\u5408\u8bbe\u8ba1\u7a7a\u95f4\u7684\u679a\u4e3e\uff0c\u663e\u8457\u63d0\u5347\u5149\u5b50\u4e92\u8fde\u7f51\u7edc\u4e2d\u7684\u901a\u4fe1\u6027\u80fd\u3002"}}
{"id": "2602.11099", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.11099", "abs": "https://arxiv.org/abs/2602.11099", "authors": ["Farshad Rostami Ghadi", "Kai-Kit Wong", "Masoud Kaveh", "Wee Kiat New", "Chan-Byoung Chae", "Lajos Hanzo"], "title": "Enormous Fluid Antenna Systems (E-FAS) for Multiuser MIMO: Channel Modeling and Analysis", "comment": null, "summary": "Enormous fluid antenna systems (E-FAS), the system concept that utilizes position reconfigurability in the large scale, have emerged as a new architectural paradigm where intelligent surfaces are repurposed from passive smart reflectors into multi-functional electromagnetic (EM) interfaces that can route guided surface waves over walls, ceilings, and building facades, as well as emit space waves to target receivers. This expanded functionality introduces a new mode of signal propagation, enabling new forms of wireless communication. In this paper, we provide an analytical performance characterization of an E-FAS-enabled wireless link. We first develop a physics-consistent end-to-end channel model that couples a surface-impedance wave formulation with small-scale fading on both the base station (BS)-surface and launcher-user segments. We illustrate that the resulting effective BS-user channel remains circularly symmetric complex Gaussian, with an enhanced average power that explicitly captures surface-wave attenuation and junction losses. For single-user cases with linear precoding, we derive the outage probability and ergodic capacity in closed forms, together with high signal-to-noise ratio (SNR) asymptotics that quantify the gain of E-FAS over purely space-wave propagation. For the multiuser case with zero-forcing (ZF) precoding, we derive the distribution of the signal-to-interference-plus-noise ratio (SINR) and obtain tractable approximations for the ergodic sum-rate, explicitly revealing how the E-FAS macro-gain interacts with the BS spatial degrees of freedom (DoF). In summary, our analysis shows that E-FAS preserves the diversity order dictated by small-scale fading while improving the coding gain enabled by cylindrical surface-wave propagation.", "AI": {"tldr": "E-FAS\u5c06\u667a\u80fd\u8868\u9762\u4ece\u88ab\u52a8\u53cd\u5c04\u5668\u8f6c\u53d8\u4e3a\u591a\u529f\u80fd\u7535\u78c1\u63a5\u53e3\uff0c\u652f\u6301\u8868\u9762\u6ce2\u548c\u7a7a\u95f4\u6ce2\u4f20\u64ad\uff0c\u672c\u6587\u5efa\u7acb\u4e86\u5176\u7aef\u5230\u7aef\u4fe1\u9053\u6a21\u578b\u5e76\u5206\u6790\u4e86\u5355\u7528\u6237\u548c\u591a\u7528\u6237\u573a\u666f\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "E-FAS\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u67b6\u6784\u8303\u5f0f\uff0c\u5c06\u667a\u80fd\u8868\u9762\u91cd\u65b0\u5b9a\u4f4d\u4e3a\u591a\u529f\u80fd\u7535\u78c1\u63a5\u53e3\uff0c\u80fd\u591f\u901a\u8fc7\u5899\u58c1\u3001\u5929\u82b1\u677f\u548c\u5efa\u7b51\u7acb\u9762\u5f15\u5bfc\u8868\u9762\u6ce2\uff0c\u540c\u65f6\u53d1\u5c04\u7a7a\u95f4\u6ce2\u5230\u76ee\u6807\u63a5\u6536\u5668\u3002\u8fd9\u79cd\u6269\u5c55\u529f\u80fd\u5f15\u5165\u4e86\u65b0\u7684\u4fe1\u53f7\u4f20\u64ad\u6a21\u5f0f\uff0c\u9700\u8981\u5bf9\u5176\u6027\u80fd\u8fdb\u884c\u7406\u8bba\u5206\u6790\u3002", "method": "\u9996\u5148\u5f00\u53d1\u4e86\u7269\u7406\u4e00\u81f4\u6027\u7684\u7aef\u5230\u7aef\u4fe1\u9053\u6a21\u578b\uff0c\u5c06\u8868\u9762\u963b\u6297\u6ce2\u516c\u5f0f\u4e0e\u5c0f\u5c3a\u5ea6\u8870\u843d\u8026\u5408\u3002\u9488\u5bf9\u5355\u7528\u6237\u573a\u666f\u63a8\u5bfc\u4e86\u4e2d\u65ad\u6982\u7387\u548c\u904d\u5386\u5bb9\u91cf\u7684\u95ed\u5f0f\u89e3\uff1b\u9488\u5bf9\u591a\u7528\u6237\u573a\u666f\u63a8\u5bfc\u4e86SINR\u5206\u5e03\u548c\u904d\u5386\u548c\u901f\u7387\u7684\u53ef\u5904\u7406\u8fd1\u4f3c\u3002", "result": "\u5206\u6790\u8868\u660eE-FAS\u4fdd\u6301\u4e86\u5c0f\u5c3a\u5ea6\u8870\u843d\u51b3\u5b9a\u7684\u591a\u6837\u6027\u9636\u6570\uff0c\u540c\u65f6\u901a\u8fc7\u5706\u67f1\u8868\u9762\u6ce2\u4f20\u64ad\u63d0\u9ad8\u4e86\u7f16\u7801\u589e\u76ca\u3002\u9ad8\u4fe1\u566a\u6bd4\u6e10\u8fd1\u5206\u6790\u91cf\u5316\u4e86E-FAS\u76f8\u5bf9\u4e8e\u7eaf\u7a7a\u95f4\u6ce2\u4f20\u64ad\u7684\u589e\u76ca\u3002", "conclusion": "E-FAS\u5728\u4fdd\u6301\u5c0f\u5c3a\u5ea6\u8870\u843d\u591a\u6837\u6027\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u8868\u9762\u6ce2\u4f20\u64ad\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u65e0\u7ebf\u901a\u4fe1\u63d0\u4f9b\u4e86\u65b0\u7684\u67b6\u6784\u8303\u5f0f\u3002"}}
{"id": "2602.10458", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10458", "abs": "https://arxiv.org/abs/2602.10458", "authors": ["Yansong Qu", "Zihao Sheng", "Zilin Huang", "Jiancong Chen", "Yuhao Luo", "Tianyi Wang", "Yiheng Feng", "Samuel Labi", "Sikai Chen"], "title": "Found-RL: foundation model-enhanced reinforcement learning for autonomous driving", "comment": "39 pages", "summary": "Reinforcement Learning (RL) has emerged as a dominant paradigm for end-to-end autonomous driving (AD). However, RL suffers from sample inefficiency and a lack of semantic interpretability in complex scenarios. Foundation Models, particularly Vision-Language Models (VLMs), can mitigate this by offering rich, context-aware knowledge, yet their high inference latency hinders deployment in high-frequency RL training loops. To bridge this gap, we present Found-RL, a platform tailored to efficiently enhance RL for AD using foundation models. A core innovation is the asynchronous batch inference framework, which decouples heavy VLM reasoning from the simulation loop, effectively resolving latency bottlenecks to support real-time learning. We introduce diverse supervision mechanisms: Value-Margin Regularization (VMR) and Advantage-Weighted Action Guidance (AWAG) to effectively distill expert-like VLM action suggestions into the RL policy. Additionally, we adopt high-throughput CLIP for dense reward shaping. We address CLIP's dynamic blindness via Conditional Contrastive Action Alignment, which conditions prompts on discretized speed/command and yields a normalized, margin-based bonus from context-specific action-anchor scoring. Found-RL provides an end-to-end pipeline for fine-tuned VLM integration and shows that a lightweight RL model can achieve near-VLM performance compared with billion-parameter VLMs while sustaining real-time inference (approx. 500 FPS). Code, data, and models will be publicly available at https://github.com/ys-qu/found-rl.", "AI": {"tldr": "Found-RL\u5e73\u53f0\u901a\u8fc7\u5f02\u6b65\u6279\u91cf\u63a8\u7406\u6846\u67b6\u89e3\u51b3VLM\u5728RL\u8bad\u7ec3\u4e2d\u7684\u5ef6\u8fdf\u95ee\u9898\uff0c\u4f7f\u7528VMR\u548cAWAG\u673a\u5236\u5c06VLM\u77e5\u8bc6\u84b8\u998f\u5230RL\u7b56\u7565\u4e2d\uff0c\u5e76\u91c7\u7528\u6539\u8fdb\u7684CLIP\u8fdb\u884c\u5956\u52b1\u5851\u9020\uff0c\u4f7f\u8f7b\u91cfRL\u6a21\u578b\u8fbe\u5230\u63a5\u8fd1VLM\u7684\u6027\u80fd\u3002", "motivation": "RL\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u5b58\u5728\u6837\u672c\u6548\u7387\u4f4e\u548c\u8bed\u4e49\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u800c\u57fa\u7840\u6a21\u578b\uff08\u7279\u522b\u662fVLM\uff09\u80fd\u63d0\u4f9b\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u77e5\u8bc6\uff0c\u4f46\u5176\u9ad8\u63a8\u7406\u5ef6\u8fdf\u963b\u788d\u4e86\u5728\u9ad8\u9891RL\u8bad\u7ec3\u5faa\u73af\u4e2d\u7684\u90e8\u7f72\u3002", "method": "1) \u5f02\u6b65\u6279\u91cf\u63a8\u7406\u6846\u67b6\u89e3\u8026VLM\u63a8\u7406\u4e0e\u4eff\u771f\u5faa\u73af\uff1b2) VMR\u548cAWAG\u673a\u5236\u5c06VLM\u52a8\u4f5c\u5efa\u8bae\u84b8\u998f\u5230RL\u7b56\u7565\uff1b3) \u91c7\u7528\u9ad8\u541e\u5410\u91cfCLIP\u8fdb\u884c\u5bc6\u96c6\u5956\u52b1\u5851\u9020\uff0c\u5e76\u901a\u8fc7\u6761\u4ef6\u5bf9\u6bd4\u52a8\u4f5c\u5bf9\u9f50\u89e3\u51b3CLIP\u7684\u52a8\u6001\u76f2\u70b9\u95ee\u9898\u3002", "result": "\u8f7b\u91cfRL\u6a21\u578b\u80fd\u8fbe\u5230\u63a5\u8fd1\u6570\u5341\u4ebf\u53c2\u6570VLM\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u65f6\u63a8\u7406\uff08\u7ea6500 FPS\uff09\uff0c\u89e3\u51b3\u4e86VLM\u5ef6\u8fdf\u74f6\u9888\u95ee\u9898\u3002", "conclusion": "Found-RL\u4e3a\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684RL\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u57fa\u7840\u6a21\u578b\u96c6\u6210\u5e73\u53f0\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u5f02\u6b65\u63a8\u7406\u548c\u77e5\u8bc6\u84b8\u998f\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u4e0e\u5b9e\u65f6\u6027\u7684\u5e73\u8861\u3002"}}
{"id": "2602.10505", "categories": ["cs.NI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2602.10505", "abs": "https://arxiv.org/abs/2602.10505", "authors": ["Isaac Keslassy", "Ilay Yavlovich", "Jose Yallouz", "Tzu-Chien Hsueh", "Yeshaiahu Fainman", "Bill Lin"], "title": "Scaling Routers with In-Package Optics and High-Bandwidth Memories", "comment": null, "summary": "This paper aims to apply two major scaling transformations from the computing packaging industry to internet routers: the heterogeneous integration of high-bandwidth memories (HBMs) and chiplets, as well as in-package optics. We propose a novel internet router architecture that employs these technologies to achieve a petabit/sec router within a single integrated package. At the top-level, we introduce a novel split-parallel switch architecture that spatially divides (without processing) the incoming fibers and distributes them across smaller independent switches without intermediate OEO conversions or fine-tuned per-packet load-balancing. This passive spatial division enables scaling at the cost of a coarser traffic load balancing. Yet, through extensive evaluations of backbone network traffic, we demonstrate that differences with fine-tuned approaches are small. In addition, we propose a novel HBM-based shared-memory architecture for the implementation of the smaller independent switches, and we introduce a novel parallel frame interleaving algorithm that packs traffic into frames so that HBM banks are accessed at peak HBM data rates in a cyclical interleaving manner. We further discuss why these new technologies represent a paradigm shift in the design of future internet routers. Finally, we emphasize that power consumption may constitute the primary bottleneck to scaling.", "AI": {"tldr": "\u5c06\u8ba1\u7b97\u5c01\u88c5\u884c\u4e1a\u7684\u4e24\u5927\u6269\u5c55\u6280\u672f\uff08HBM/\u82af\u7c92\u5f02\u6784\u96c6\u6210\u548c\u5c01\u88c5\u5185\u5149\u5b66\uff09\u5e94\u7528\u4e8e\u4e92\u8054\u7f51\u8def\u7531\u5668\uff0c\u63d0\u51fa\u5355\u5c01\u88c5\u5185\u5b9e\u73b0Petabit/s\u8def\u7531\u5668\u7684\u521b\u65b0\u67b6\u6784", "motivation": "\u4f20\u7edf\u4e92\u8054\u7f51\u8def\u7531\u5668\u9762\u4e34\u6269\u5c55\u74f6\u9888\uff0c\u9700\u8981\u5229\u7528\u5148\u8fdb\u5c01\u88c5\u6280\u672f\u5b9e\u73b0\u66f4\u9ad8\u5e26\u5bbd\u548c\u80fd\u6548\u7684\u8def\u7531\u5668\u67b6\u6784", "method": "\u63d0\u51fa\u5206\u88c2\u5e76\u884c\u4ea4\u6362\u67b6\u6784\uff08\u88ab\u52a8\u7a7a\u95f4\u5206\u5272\u5149\u7ea4\uff09+ HBM\u5171\u4eab\u5185\u5b58\u67b6\u6784 + \u5e76\u884c\u5e27\u4ea4\u9519\u7b97\u6cd5\uff0c\u5b9e\u73b0\u65e0OEO\u8f6c\u6362\u7684\u7c97\u7c92\u5ea6\u8d1f\u8f7d\u5747\u8861", "result": "\u901a\u8fc7\u9aa8\u5e72\u7f51\u6d41\u91cf\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e0e\u7cbe\u7ec6\u8d1f\u8f7d\u5747\u8861\u65b9\u6cd5\u5dee\u5f02\u5f88\u5c0f\uff0c\u80fd\u591f\u5b9e\u73b0\u5355\u5c01\u88c5\u5185Petabit/s\u8def\u7531\u5668", "conclusion": "\u8fd9\u4e9b\u65b0\u6280\u672f\u4ee3\u8868\u672a\u6765\u4e92\u8054\u7f51\u8def\u7531\u5668\u8bbe\u8ba1\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u4f46\u529f\u8017\u53ef\u80fd\u6210\u4e3a\u6269\u5c55\u7684\u4e3b\u8981\u74f6\u9888"}}
{"id": "2602.10467", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10467", "abs": "https://arxiv.org/abs/2602.10467", "authors": ["Jihwan Oh", "Murad Aghazada", "Yooju Shin", "Se-Young Yun", "Taehyeon Kim"], "title": "MERIT Feedback Elicits Better Bargaining in LLM Negotiators", "comment": "Preprint. arXiv admin note: substantial text overlap with arXiv:2505.22998", "summary": "Bargaining is often regarded as a logical arena rather than an art or a matter of intuition, yet Large Language Models (LLMs) still struggle to navigate it due to limited strategic depth and difficulty adapting to complex human factors. Current benchmarks rarely capture this limitation. To bridge this gap, we present an utility feedback centric framework. Our contributions are: (i) AgoraBench, a new benchmark spanning nine challenging settings (e.g., deception, monopoly) that supports diverse strategy modeling; (ii) human-aligned, economically grounded metrics derived from utility theory. This is operationalized via agent utility, negotiation power, and acquisition ratio that implicitly measure how well the negotiation aligns with human preference and (iii) a human preference grounded dataset with learning pipeline that strengthens LLMs' bargaining ability through both prompting and finetuning. Empirical results indicate that baseline LLM strategies often diverge from human preferences, while our mechanism substantially improves negotiation performance, yielding deeper strategic behavior and stronger opponent awareness.", "AI": {"tldr": "\u63d0\u51faAgoraBench\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u6548\u7528\u53cd\u9988\u673a\u5236\u589e\u5f3aLLM\u5728\u590d\u6742\u8c08\u5224\u573a\u666f\u4e2d\u7684\u6218\u7565\u6df1\u5ea6\u548c\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u80fd\u529b", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8c08\u5224\u573a\u666f\u4e2d\u6218\u7565\u6df1\u5ea6\u4e0d\u8db3\uff0c\u96be\u4ee5\u9002\u5e94\u590d\u6742\u7684\u4eba\u7c7b\u56e0\u7d20\uff0c\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u5145\u5206\u6355\u6349\u8fd9\u4e00\u5c40\u9650", "method": "\u63d0\u51fa\u57fa\u4e8e\u6548\u7528\u53cd\u9988\u7684\u6846\u67b6\uff1a1) AgoraBench\u57fa\u51c6\uff0c\u6db5\u76d69\u4e2a\u6311\u6218\u6027\u573a\u666f\uff1b2) \u57fa\u4e8e\u6548\u7528\u7406\u8bba\u7684\u4eba\u7c7b\u5bf9\u9f50\u7ecf\u6d4e\u6307\u6807\uff1b3) \u4eba\u7c7b\u504f\u597d\u6570\u636e\u96c6\u548c\u5b66\u4e60\u7ba1\u9053\uff0c\u901a\u8fc7\u63d0\u793a\u548c\u5fae\u8c03\u589e\u5f3aLLM\u8c08\u5224\u80fd\u529b", "result": "\u57fa\u7ebfLLM\u7b56\u7565\u5e38\u504f\u79bb\u4eba\u7c7b\u504f\u597d\uff0c\u800c\u63d0\u51fa\u7684\u673a\u5236\u663e\u8457\u63d0\u5347\u8c08\u5224\u6027\u80fd\uff0c\u4ea7\u751f\u66f4\u6df1\u5c42\u7684\u6218\u7565\u884c\u4e3a\u548c\u66f4\u5f3a\u7684\u5bf9\u624b\u610f\u8bc6", "conclusion": "\u901a\u8fc7\u6548\u7528\u53cd\u9988\u6846\u67b6\u548c\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\uff0c\u53ef\u4ee5\u663e\u8457\u589e\u5f3aLLM\u5728\u590d\u6742\u8c08\u5224\u573a\u666f\u4e2d\u7684\u6218\u7565\u80fd\u529b\u548c\u9002\u5e94\u6027"}}
{"id": "2602.10564", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.10564", "abs": "https://arxiv.org/abs/2602.10564", "authors": ["Tao Li", "Yulin Tang", "Yiyang Song", "Cong Wu", "Xihui Liu", "Pan Li", "Xianhao Chen"], "title": "SplitCom: Communication-efficient Split Federated Fine-tuning of LLMs via Temporal Compression", "comment": null, "summary": "Federated fine-tuning of on-device large language models (LLMs) mitigates privacy concerns by preventing raw data sharing. However, the intensive computational and memory demands pose significant challenges for resource-constrained edge devices. To overcome these limitations, split federated learning (SFL) emerges as a promising solution that partitions the model into lightweight client-side and compute-intensive server-side sub-models, thus offloading the primary training workload to a powerful server. Nevertheless, high-dimensional activation exchanges in SFL lead to excessive communication overhead. To overcome this, we propose SplitCom, a communication-efficient SFL framework for LLMs that exploits temporal redundancy in activations across consecutive training epochs. Inspired by video compression, the core innovation of our framework lies in selective activation uploading only when a noticeable deviation from previous epochs occurs. To balance communication efficiency and learning performance, we introduce two adaptive threshold control schemes based on 1) bang-bang control or 2) deep deterministic policy gradient (DDPG)-based reinforcement learning. Moreover, we implement dimensionality reduction techniques to alleviate client-side memory requirements. Furthermore, we extend SplitCom to the U-shape architecture, ensuring the server never accesses clients' labels. Extensive simulations and laboratory experiments demonstrate that SplitCom reduces uplink communication costs by up to 98.6\\,\\% in its standard configuration and total communication costs by up to 95.8\\,\\% in its U-shape variant without noticeably compromising model performance.", "AI": {"tldr": "SplitCom\uff1a\u4e00\u79cd\u901a\u4fe1\u9ad8\u6548\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u8fde\u7eed\u8bad\u7ec3\u5468\u671f\u4e2d\u6fc0\u6d3b\u7684\u65f6\u5e8f\u5197\u4f59\uff0c\u9009\u62e9\u6027\u4e0a\u4f20\u663e\u8457\u53d8\u5316\u7684\u6fc0\u6d3b\uff0c\u51cf\u5c11LLM\u8054\u90a6\u5fae\u8c03\u4e2d\u7684\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u5728\u8bbe\u5907\u7aef\u5927\u8bed\u8a00\u6a21\u578b\u8054\u90a6\u5fae\u8c03\u4e2d\uff0c\u867d\u7136\u907f\u514d\u4e86\u539f\u59cb\u6570\u636e\u5171\u4eab\u4fdd\u62a4\u4e86\u9690\u79c1\uff0c\u4f46\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u5bf9\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u6784\u6210\u6311\u6218\u3002\u5206\u5272\u8054\u90a6\u5b66\u4e60\u5c06\u6a21\u578b\u5212\u5206\u4e3a\u8f7b\u91cf\u7ea7\u5ba2\u6237\u7aef\u548c\u8ba1\u7b97\u5bc6\u96c6\u578b\u670d\u52a1\u5668\u7aef\u5b50\u6a21\u578b\uff0c\u4f46\u9ad8\u7ef4\u6fc0\u6d3b\u4ea4\u6362\u5bfc\u81f4\u901a\u4fe1\u5f00\u9500\u8fc7\u5927\u3002", "method": "1\uff09\u5229\u7528\u89c6\u9891\u538b\u7f29\u601d\u60f3\uff0c\u4ec5\u5f53\u6fc0\u6d3b\u4e0e\u5148\u524d\u5468\u671f\u51fa\u73b0\u663e\u8457\u504f\u5dee\u65f6\u624d\u9009\u62e9\u6027\u4e0a\u4f20\uff1b2\uff09\u5f15\u5165\u4e24\u79cd\u81ea\u9002\u5e94\u9608\u503c\u63a7\u5236\u65b9\u6848\uff08bang-bang\u63a7\u5236\u6216DDPG\u5f3a\u5316\u5b66\u4e60\uff09\u5e73\u8861\u901a\u4fe1\u6548\u7387\u548c\u5b66\u4e60\u6027\u80fd\uff1b3\uff09\u5b9e\u65bd\u964d\u7ef4\u6280\u672f\u51cf\u8f7b\u5ba2\u6237\u7aef\u5185\u5b58\u9700\u6c42\uff1b4\uff09\u6269\u5c55\u5230U\u578b\u67b6\u6784\u786e\u4fdd\u670d\u52a1\u5668\u4e0d\u8bbf\u95ee\u5ba2\u6237\u7aef\u6807\u7b7e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSplitCom\u5728\u6807\u51c6\u914d\u7f6e\u4e0b\u5c06\u4e0a\u884c\u901a\u4fe1\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe98.6%\uff0c\u5728U\u578b\u53d8\u4f53\u4e2d\u5c06\u603b\u901a\u4fe1\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe95.8%\uff0c\u4e14\u4e0d\u660e\u663e\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "SplitCom\u901a\u8fc7\u5229\u7528\u6fc0\u6d3b\u7684\u65f6\u5e8f\u5197\u4f59\u548c\u81ea\u9002\u5e94\u9608\u503c\u63a7\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5272\u8054\u90a6\u5b66\u4e60\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u901a\u4fe1\u5f00\u9500\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u901a\u4fe1\u6210\u672c\u3002"}}
{"id": "2602.10485", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10485", "abs": "https://arxiv.org/abs/2602.10485", "authors": ["Zhenhe Cui", "Huaxiang Xia", "Hangjun Shen", "Kailun Luo", "Yong He", "Wei Liang"], "title": "Abstraction Generation for Generalized Planning with Pretrained Large Language Models", "comment": null, "summary": "Qualitative Numerical Planning (QNP) serves as an important abstraction model for generalized planning (GP), which aims to compute general plans that solve multiple instances at once. Recent works show that large language models (LLMs) can function as generalized planners. This work investigates whether LLMs can serve as QNP abstraction generators for GP problems and how to fix abstractions via automated debugging. We propose a prompt protocol: input a GP domain and training tasks to LLMs, prompting them to generate abstract features and further abstract the initial state, action set, and goal into QNP problems. An automated debugging method is designed to detect abstraction errors, guiding LLMs to fix abstractions. Experiments demonstrate that under properly guided by automated debugging, some LLMs can generate useful QNP abstractions.", "AI": {"tldr": "LLMs\u53ef\u4f5c\u4e3aQNP\u62bd\u8c61\u751f\u6210\u5668\uff0c\u901a\u8fc7\u81ea\u52a8\u8c03\u8bd5\u65b9\u6cd5\u4fee\u590d\u62bd\u8c61\u9519\u8bef\uff0c\u4e3a\u5e7f\u4e49\u89c4\u5212\u95ee\u9898\u751f\u6210\u6709\u7528\u7684QNP\u62bd\u8c61", "motivation": "\u63a2\u7d22LLMs\u80fd\u5426\u4f5c\u4e3aQNP\u62bd\u8c61\u751f\u6210\u5668\u4e3a\u5e7f\u4e49\u89c4\u5212\u95ee\u9898\u670d\u52a1\uff0c\u5e76\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u81ea\u52a8\u8c03\u8bd5\u4fee\u590d\u62bd\u8c61\u9519\u8bef", "method": "\u63d0\u51fa\u63d0\u793a\u534f\u8bae\uff1a\u8f93\u5165GP\u9886\u57df\u548c\u8bad\u7ec3\u4efb\u52a1\u7ed9LLMs\uff0c\u8ba9\u5176\u751f\u6210\u62bd\u8c61\u7279\u5f81\u5e76\u8fdb\u4e00\u6b65\u62bd\u8c61\u521d\u59cb\u72b6\u6001\u3001\u52a8\u4f5c\u96c6\u548c\u76ee\u6807\u4e3aQNP\u95ee\u9898\uff1b\u8bbe\u8ba1\u81ea\u52a8\u8c03\u8bd5\u65b9\u6cd5\u68c0\u6d4b\u62bd\u8c61\u9519\u8bef\uff0c\u6307\u5bfcLLMs\u4fee\u590d\u62bd\u8c61", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u81ea\u52a8\u8c03\u8bd5\u7684\u9002\u5f53\u6307\u5bfc\u4e0b\uff0c\u67d0\u4e9bLLMs\u80fd\u591f\u751f\u6210\u6709\u7528\u7684QNP\u62bd\u8c61", "conclusion": "LLMs\u53ef\u4ee5\u4f5c\u4e3aQNP\u62bd\u8c61\u751f\u6210\u5668\uff0c\u7ed3\u5408\u81ea\u52a8\u8c03\u8bd5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u751f\u6210\u548c\u4fee\u590d\u62bd\u8c61\uff0c\u4e3a\u5e7f\u4e49\u89c4\u5212\u95ee\u9898\u63d0\u4f9b\u652f\u6301"}}
{"id": "2602.10583", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10583", "abs": "https://arxiv.org/abs/2602.10583", "authors": ["Bo Xue", "Yunchong Song", "Fanghao Shao", "Xuekai Zhu", "Lin Chen", "Luoyi Fu", "Xinbing Wang", "Zhouhan Lin"], "title": "Flow of Spans: Generalizing Language Models to Dynamic Span-Vocabulary via GFlowNets", "comment": "Published as a conference paper at ICLR 2026", "summary": "Standard autoregressive language models generate text token-by-token from a fixed vocabulary, inducing a tree-structured state space when viewing token sampling as an action, which limits flexibility and expressiveness. Recent work introduces dynamic vocabulary by sampling retrieved text spans but overlooks that the same sentence can be composed of spans of varying lengths, lacking explicit modeling of the directed acyclic graph (DAG) state space. This leads to restricted exploration of compositional paths and is biased toward the chosen path. Generative Flow Networks (GFlowNets) are powerful for efficient exploring and generalizing over state spaces, particularly those with a DAG structure. However, prior GFlowNets-based language models operate at the token level and remain confined to tree-structured spaces, limiting their potential. In this work, we propose Flow of SpanS (FOSS), a principled GFlowNets framework for span generation. FoSS constructs a dynamic span vocabulary by segmenting the retrieved text flexibly, ensuring a DAG-structured state space, which allows GFlowNets to explore diverse compositional paths and improve generalization. With specialized reward models, FoSS generates diverse, high-quality text. Empirically, FoSS improves MAUVE scores by up to 12.5% over Transformer on text generation and achieves 3.5% gains on knowledge-intensive tasks, consistently outperforming state-of-the-art methods. Scaling experiments further demonstrate FoSS benefits from larger models, more data, and richer retrieval corpora, retaining its advantage over strong baselines.", "AI": {"tldr": "FoSS\u63d0\u51fa\u57fa\u4e8e\u751f\u6210\u6d41\u7f51\u7edc\u7684\u8de8\u5ea6\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8de8\u5ea6\u8bcd\u6c47\u548cDAG\u72b6\u6001\u7a7a\u95f4\u63d0\u5347\u6587\u672c\u751f\u6210\u591a\u6837\u6027\u548c\u8d28\u91cf", "motivation": "\u4f20\u7edf\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u4f7f\u7528\u56fa\u5b9a\u8bcd\u6c47\u8868\uff0c\u5f62\u6210\u6811\u72b6\u72b6\u6001\u7a7a\u95f4\uff0c\u9650\u5236\u4e86\u751f\u6210\u7075\u6d3b\u6027\u548c\u8868\u8fbe\u80fd\u529b\u3002\u73b0\u6709\u52a8\u6001\u8bcd\u6c47\u65b9\u6cd5\u867d\u7136\u5f15\u5165\u68c0\u7d22\u6587\u672c\u8de8\u5ea6\uff0c\u4f46\u5ffd\u7565\u4e86\u540c\u4e00\u53e5\u5b50\u53ef\u7531\u4e0d\u540c\u957f\u5ea6\u8de8\u5ea6\u7ec4\u6210\uff0c\u7f3a\u4e4f\u5bf9DAG\u72b6\u6001\u7a7a\u95f4\u7684\u663e\u5f0f\u5efa\u6a21\uff0c\u5bfc\u81f4\u7ec4\u5408\u8def\u5f84\u63a2\u7d22\u53d7\u9650\u548c\u8def\u5f84\u9009\u62e9\u504f\u5dee\u3002", "method": "\u63d0\u51faFlow of SpanS (FoSS)\u6846\u67b6\uff1a1) \u901a\u8fc7\u7075\u6d3b\u5206\u5272\u68c0\u7d22\u6587\u672c\u6784\u5efa\u52a8\u6001\u8de8\u5ea6\u8bcd\u6c47\u8868\uff1b2) \u786e\u4fddDAG\u7ed3\u6784\u72b6\u6001\u7a7a\u95f4\uff0c\u4f7f\u751f\u6210\u6d41\u7f51\u7edc\u80fd\u591f\u63a2\u7d22\u591a\u6837\u7ec4\u5408\u8def\u5f84\uff1b3) \u4f7f\u7528\u4e13\u95e8\u7684\u5956\u52b1\u6a21\u578b\u6307\u5bfc\u751f\u6210\u8fc7\u7a0b\u3002", "result": "FoSS\u5728\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e0a\u6bd4Transformer\u63d0\u5347MAUVE\u5206\u6570\u8fbe12.5%\uff0c\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u83b7\u5f973.5%\u7684\u589e\u76ca\uff0c\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002\u6269\u5c55\u5b9e\u9a8c\u663e\u793aFoSS\u53d7\u76ca\u4e8e\u66f4\u5927\u6a21\u578b\u3001\u66f4\u591a\u6570\u636e\u548c\u66f4\u4e30\u5bcc\u7684\u68c0\u7d22\u8bed\u6599\u5e93\u3002", "conclusion": "FoSS\u901a\u8fc7\u5c06\u751f\u6210\u6d41\u7f51\u7edc\u5e94\u7528\u4e8e\u8de8\u5ea6\u751f\u6210\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u72b6\u6001\u7a7a\u95f4\u7ed3\u6784\u4e0a\u7684\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u66f4\u7075\u6d3b\u3001\u591a\u6837\u548c\u9ad8\u8d28\u91cf\u7684\u6587\u672c\u751f\u6210\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u751f\u6210\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.10734", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.10734", "abs": "https://arxiv.org/abs/2602.10734", "authors": ["Pawani Porambage", "Diego Lopez", "Antonio Pastor", "Bin Han", "Jos\u00e9 Mar\u00eda Jorquera Valero", "Manuel Gil P\u00e9rez", "Noelia P\u00e9rez Palma", "Antonio Skarmeta", "Prajnamaya Dass", "Stefan K\u00f6psell", "Sonika Ujjwal", "Javier Jos\u00e9 D\u00edaz Rivera", "Pol Alemany", "Raul Mu\u00f1oz", "Jafar Mohammadi", "Chaitanya Aggarwal", "Betul Guvenc Paltun", "Ferhat Karakoc"], "title": "Security, Privacy and System-Level Resillience of 6G End-to-End System: Hexa-X-II Perspective", "comment": "Presented at IEEE CAMAD 2024 WORKSHOP 2: Addressing 6G Cybersecurity and Privacy Challenges as invited paper (extended abstract)", "summary": "The sixth generation (6G) of mobile networks are being developed to overcome limitations in previous generations and meet emerging user demands. As a European project, the Smart Networks and Services Joint Undertaking (SNS JU) 6G Flagship project Hexa-X-II has a leading role for developing technologies and anchoring 6G end-to-end system. This paper summarizes the security, privacy and resilient (SPR) controls identified by Hexa-X-II project and their validation frameworks.", "AI": {"tldr": "Hexa-X-II\u9879\u76ee\u603b\u7ed3\u4e866G\u7f51\u7edc\u7684\u5b89\u5168\u3001\u9690\u79c1\u548c\u5f39\u6027\u63a7\u5236\u63aa\u65bd\u53ca\u5176\u9a8c\u8bc1\u6846\u67b6", "motivation": "6G\u7f51\u7edc\u9700\u8981\u514b\u670d\u524d\u51e0\u4ee3\u7f51\u7edc\u7684\u9650\u5236\u5e76\u6ee1\u8db3\u65b0\u5174\u7528\u6237\u9700\u6c42\uff0cHexa-X-II\u9879\u76ee\u4f5c\u4e3a\u6b27\u6d326G\u65d7\u8230\u9879\u76ee\uff0c\u5728\u5f00\u53d1\u6280\u672f\u548c\u951a\u5b9a\u7aef\u5230\u7aef\u7cfb\u7edf\u65b9\u9762\u53d1\u6325\u4e3b\u5bfc\u4f5c\u7528", "method": "\u8bc6\u522b\u5b89\u5168\u3001\u9690\u79c1\u548c\u5f39\u6027\u63a7\u5236\u63aa\u65bd\uff0c\u5e76\u5efa\u7acb\u76f8\u5e94\u7684\u9a8c\u8bc1\u6846\u67b6", "result": "\u603b\u7ed3\u4e86Hexa-X-II\u9879\u76ee\u786e\u5b9a\u7684\u5b89\u5168\u3001\u9690\u79c1\u548c\u5f39\u6027\u63a7\u5236\u63aa\u65bd\u53ca\u5176\u9a8c\u8bc1\u6846\u67b6", "conclusion": "\u8be5\u9879\u76ee\u4e3a6G\u7f51\u7edc\u7684\u5b89\u5168\u3001\u9690\u79c1\u548c\u5f39\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u63a7\u5236\u63aa\u65bd\u548c\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e6G\u7cfb\u7edf\u7684\u6574\u4f53\u53d1\u5c55"}}
{"id": "2602.10598", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10598", "abs": "https://arxiv.org/abs/2602.10598", "authors": ["Shuai Han", "Mehdi Dastani", "Shihan Wang"], "title": "Neuro-symbolic Action Masking for Deep Reinforcement Learning", "comment": null, "summary": "Deep reinforcement learning (DRL) may explore infeasible actions during training and execution. Existing approaches assume a symbol grounding function that maps high-dimensional states to consistent symbolic representations and a manually specified action masking techniques to constrain actions. In this paper, we propose Neuro-symbolic Action Masking (NSAM), a novel framework that automatically learn symbolic models, which are consistent with given domain constraints of high-dimensional states, in a minimally supervised manner during the DRL process. Based on the learned symbolic model of states, NSAM learns action masks that rules out infeasible actions. NSAM enables end-to-end integration of symbolic reasoning and deep policy optimization, where improvements in symbolic grounding and policy learning mutually reinforce each other. We evaluate NSAM on multiple domains with constraints, and experimental results demonstrate that NSAM significantly improves sample efficiency of DRL agent while substantially reducing constraint violations.", "AI": {"tldr": "\u63d0\u51faNSAM\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u5b66\u4e60\u7b26\u53f7\u6a21\u578b\u6765\u7ea6\u675fDRL\u4e2d\u7684\u4e0d\u53ef\u884c\u52a8\u4f5c\uff0c\u63d0\u9ad8\u6837\u672c\u6548\u7387\u5e76\u51cf\u5c11\u7ea6\u675f\u8fdd\u53cd", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u624b\u52a8\u6307\u5b9a\u7b26\u53f7\u57fa\u7840\u51fd\u6570\u548c\u52a8\u4f5c\u63a9\u7801\u6280\u672f\uff0c\u8fd9\u9650\u5236\u4e86DRL\u5728\u5b9e\u9645\u7ea6\u675f\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002\u9700\u8981\u4e00\u79cd\u80fd\u81ea\u52a8\u5b66\u4e60\u7b26\u53f7\u6a21\u578b\u5e76\u7ea6\u675f\u52a8\u4f5c\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7\u52a8\u4f5c\u63a9\u7801\uff08NSAM\uff09\u6846\u67b6\uff0c\u5728DRL\u8fc7\u7a0b\u4e2d\u4ee5\u6700\u5c0f\u76d1\u7763\u65b9\u5f0f\u81ea\u52a8\u5b66\u4e60\u4e0e\u9ad8\u7ef4\u72b6\u6001\u57df\u7ea6\u675f\u4e00\u81f4\u7684\u7b26\u53f7\u6a21\u578b\uff0c\u57fa\u4e8e\u5b66\u4e60\u7684\u7b26\u53f7\u6a21\u578b\u751f\u6210\u52a8\u4f5c\u63a9\u7801\u6392\u9664\u4e0d\u53ef\u884c\u52a8\u4f5c\uff0c\u5b9e\u73b0\u7b26\u53f7\u63a8\u7406\u4e0e\u6df1\u5ea6\u7b56\u7565\u4f18\u5316\u7684\u7aef\u5230\u7aef\u96c6\u6210\u3002", "result": "\u5728\u591a\u4e2a\u7ea6\u675f\u57df\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNSAM\u663e\u8457\u63d0\u9ad8\u4e86DRL\u667a\u80fd\u4f53\u7684\u6837\u672c\u6548\u7387\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86\u7ea6\u675f\u8fdd\u53cd\u3002", "conclusion": "NSAM\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u7b26\u53f7\u63a8\u7406\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u6709\u6548\u96c6\u6210\uff0c\u901a\u8fc7\u81ea\u52a8\u5b66\u4e60\u7b26\u53f7\u6a21\u578b\u548c\u52a8\u4f5c\u63a9\u7801\uff0c\u89e3\u51b3\u4e86DRL\u5728\u7ea6\u675f\u73af\u5883\u4e2d\u7684\u52a8\u4f5c\u53ef\u884c\u6027\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.10823", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.10823", "abs": "https://arxiv.org/abs/2602.10823", "authors": ["Bruno Rodrigues", "Karim Khamaisi"], "title": "Less is More: The Dilution Effect in Multi-Link Wireless Sensing", "comment": null, "summary": "Wireless sensing approaches promise to transform smart infrastructures into privacy-preserving motion detectors, yet commercial adoption remains limited. A common assumption may explain this gap: that denser sensor deployments yield better accuracy. We tested this assumption with a 12-day naturalistic study using a 9-node ESP32-C3 mesh (72 sensing links) in a residential environment. Our results show that a single well-placed link outperformed the full 72-link mesh (AUC 0.541 vs. 0.489, Cohen's $d$=0.86). Even a random link selection matched optimized selection ($p$=0.35). The benefit comes from avoiding multi-link fusion, not from choosing the right link. We attribute this to a \"dilution effect\": links whose Fresnel zones miss activity regions contribute noise that overwhelms signal from informative links. In our deployment, strategic link placement mattered 2.7$\\times$ more than classifier choice. We release 312 hours of labeled CSI data, firmware, and analysis code to enable validation across diverse environments.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u65e0\u7ebf\u4f20\u611f\u4e2d\uff0c\u5355\u4e2a\u7cbe\u5fc3\u5e03\u7f6e\u7684\u94fe\u8def\u6bd4\u5bc6\u96c6\u7684\u591a\u94fe\u8def\u7f51\u7edc\u6027\u80fd\u66f4\u597d\uff0c\u56e0\u4e3a\u591a\u94fe\u8def\u878d\u5408\u4f1a\u4ea7\u751f\"\u7a00\u91ca\u6548\u5e94\"\uff0c\u566a\u58f0\u4f1a\u6df9\u6ca1\u6709\u7528\u4fe1\u53f7\u3002", "motivation": "\u65e0\u7ebf\u4f20\u611f\u6280\u672f\u6709\u671b\u6210\u4e3a\u9690\u79c1\u4fdd\u62a4\u7684\u8fd0\u52a8\u68c0\u6d4b\u5668\uff0c\u4f46\u5546\u4e1a\u5e94\u7528\u6709\u9650\u3002\u4f20\u7edf\u5047\u8bbe\u8ba4\u4e3a\u5bc6\u96c6\u4f20\u611f\u5668\u90e8\u7f72\u80fd\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u672c\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u8fd9\u4e00\u5047\u8bbe\u3002", "method": "\u5728\u4f4f\u5b85\u73af\u5883\u4e2d\u8fdb\u884c\u4e3a\u671f12\u5929\u7684\u81ea\u7136\u7814\u7a76\uff0c\u4f7f\u75289\u8282\u70b9ESP32-C3\u7f51\u72b6\u7f51\u7edc\uff0872\u4e2a\u4f20\u611f\u94fe\u8def\uff09\uff0c\u6bd4\u8f83\u5355\u4e2a\u94fe\u8def\u4e0e\u5b8c\u6574\u7f51\u7edc\u7684\u6027\u80fd\u3002", "result": "\u5355\u4e2a\u7cbe\u5fc3\u5e03\u7f6e\u7684\u94fe\u8def\uff08AUC 0.541\uff09\u4f18\u4e8e\u5b8c\u6574\u768472\u94fe\u8def\u7f51\u7edc\uff08AUC 0.489\uff09\uff0c\u6548\u679c\u5dee\u5f02\u663e\u8457\uff08Cohen's d=0.86\uff09\u3002\u968f\u673a\u94fe\u8def\u9009\u62e9\u4e0e\u4f18\u5316\u9009\u62e9\u65e0\u663e\u8457\u5dee\u5f02\uff08p=0.35\uff09\u3002", "conclusion": "\u65e0\u7ebf\u4f20\u611f\u4e2d\u94fe\u8def\u6218\u7565\u5e03\u7f6e\u6bd4\u5206\u7c7b\u5668\u9009\u62e9\u91cd\u89812.7\u500d\uff0c\u591a\u94fe\u8def\u878d\u5408\u4f1a\u4ea7\u751f\"\u7a00\u91ca\u6548\u5e94\"\uff0c\u566a\u58f0\u4f1a\u6df9\u6ca1\u6709\u7528\u4fe1\u53f7\u3002\u7814\u7a76\u53d1\u5e03\u4e86312\u5c0f\u65f6\u6807\u8bb0\u6570\u636e\u4f9b\u9a8c\u8bc1\u3002"}}
{"id": "2602.10625", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.10625", "abs": "https://arxiv.org/abs/2602.10625", "authors": ["Nanxu Gong", "Haotian Li", "Sixun Dong", "Jianxun Lian", "Yanjie Fu", "Xing Xie"], "title": "To Think or Not To Think, That is The Question for Large Reasoning Models in Theory of Mind Tasks", "comment": null, "summary": "Theory of Mind (ToM) assesses whether models can infer hidden mental states such as beliefs, desires, and intentions, which is essential for natural social interaction. Although recent progress in Large Reasoning Models (LRMs) has boosted step-by-step inference in mathematics and coding, it is still underexplored whether this benefit transfers to socio-cognitive skills. We present a systematic study of nine advanced Large Language Models (LLMs), comparing reasoning models with non-reasoning models on three representative ToM benchmarks. The results show that reasoning models do not consistently outperform non-reasoning models and sometimes perform worse. A fine-grained analysis reveals three insights. First, slow thinking collapses: accuracy significantly drops as responses grow longer, and larger reasoning budgets hurt performance. Second, moderate and adaptive reasoning benefits performance: constraining reasoning length mitigates failure, while distinct success patterns demonstrate the necessity of dynamic adaptation. Third, option matching shortcut: when multiple choice options are removed, reasoning models improve markedly, indicating reliance on option matching rather than genuine deduction. We also design two intervention approaches: Slow-to-Fast (S2F) adaptive reasoning and Think-to-Match (T2M) shortcut prevention to further verify and mitigate the problems. With all results, our study highlights the advancement of LRMs in formal reasoning (e.g., math, code) cannot be fully transferred to ToM, a typical task in social reasoning. We conclude that achieving robust ToM requires developing unique capabilities beyond existing reasoning methods.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u6a21\u578b\u5728\u5fc3\u7406\u7406\u8bba\u4efb\u52a1\u4e0a\u5e76\u4e0d\u6bd4\u975e\u63a8\u7406\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u6709\u65f6\u751a\u81f3\u66f4\u5dee\uff0c\u63ed\u793a\u4e86\u63a8\u7406\u6a21\u578b\u5728\u793e\u4ea4\u63a8\u7406\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u7b49\u6b63\u5f0f\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8fd9\u4e9b\u4f18\u52bf\u662f\u5426\u80fd\u8f6c\u79fb\u5230\u5fc3\u7406\u7406\u8bba\u8fd9\u6837\u7684\u793e\u4ea4\u8ba4\u77e5\u6280\u80fd\u4e0a\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30\u63a8\u7406\u6a21\u578b\u5728\u5fc3\u7406\u7406\u8bba\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u5bf99\u4e2a\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u7814\u7a76\uff0c\u6bd4\u8f83\u63a8\u7406\u6a21\u578b\u4e0e\u975e\u63a8\u7406\u6a21\u578b\u5728\u4e09\u4e2a\u4ee3\u8868\u6027\u5fc3\u7406\u7406\u8bba\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\u3002\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5206\u6790\u63ed\u793a\u95ee\u9898\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e24\u79cd\u5e72\u9884\u65b9\u6cd5\uff1a\u6162\u5230\u5feb\u81ea\u9002\u5e94\u63a8\u7406\u548c\u601d\u8003\u5230\u5339\u914d\u6377\u5f84\u9884\u9632\u3002", "result": "\u63a8\u7406\u6a21\u578b\u5728\u5fc3\u7406\u7406\u8bba\u4efb\u52a1\u4e0a\u5e76\u4e0d\u4e00\u81f4\u4f18\u4e8e\u975e\u63a8\u7406\u6a21\u578b\uff0c\u6709\u65f6\u8868\u73b0\u66f4\u5dee\u3002\u5206\u6790\u53d1\u73b0\uff1a1\uff09\u6162\u601d\u8003\u5d29\u6e83\uff1a\u56de\u7b54\u8d8a\u957f\u51c6\u786e\u7387\u8d8a\u4f4e\uff1b2\uff09\u9002\u5ea6\u81ea\u9002\u5e94\u63a8\u7406\u6709\u76ca\uff1b3\uff09\u9009\u9879\u5339\u914d\u6377\u5f84\uff1a\u79fb\u9664\u9009\u9879\u540e\u63a8\u7406\u6a21\u578b\u8868\u73b0\u663e\u8457\u63d0\u5347\u3002\u5e72\u9884\u65b9\u6cd5\u9a8c\u8bc1\u5e76\u7f13\u89e3\u4e86\u8fd9\u4e9b\u95ee\u9898\u3002", "conclusion": "\u63a8\u7406\u6a21\u578b\u5728\u6b63\u5f0f\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8fdb\u6b65\u4e0d\u80fd\u5b8c\u5168\u8f6c\u79fb\u5230\u5fc3\u7406\u7406\u8bba\u8fd9\u6837\u7684\u793e\u4ea4\u63a8\u7406\u4efb\u52a1\u4e2d\u3002\u5b9e\u73b0\u7a33\u5065\u7684\u5fc3\u7406\u7406\u8bba\u9700\u8981\u5f00\u53d1\u8d85\u8d8a\u73b0\u6709\u63a8\u7406\u65b9\u6cd5\u7684\u72ec\u7279\u80fd\u529b\u3002"}}
{"id": "2602.10900", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.10900", "abs": "https://arxiv.org/abs/2602.10900", "authors": ["Sergio Cruzes"], "title": "AI Infrastructure Sovereignty", "comment": "27 pages, 7 figures", "summary": "Artificial intelligence has shifted from a software-centric discipline to an infrastructure-driven system. Large-scale training and inference increasingly depend on tightly coupled data centers, high-capacity optical networks, and energy systems operating close to physical and environmental limits. As a result, control over data and algorithms alone is no longer sufficient to achieve meaningful AI sovereignty. Practical sovereignty now depends on who can deploy, operate, and adapt AI infrastructure under constraints imposed by energy availability, sustainability targets, and network reach. This tutorial-survey introduces the concept of AI infrastructure sovereignty, defined as the ability of a region, operator, or nation to exercise operational control over AI systems within physical and environmental limits. The paper argues that sovereignty emerges from the co-design of three layers: AI-oriented data centers, optical transport networks, and automation frameworks that provide real-time visibility and control. We analyze how AI workloads reshape data center design, driving extreme power densities, advanced cooling requirements, and tighter coupling to local energy systems, with sustainability metrics such as carbon intensity and water usage acting as hard deployment boundaries. We then examine optical networks as the backbone of distributed AI, showing how latency, capacity, failure domains, and jurisdictional control define practical sovereignty limits. Building on this foundation, the paper positions telemetry, agentic AI, and digital twins as enablers of operational sovereignty through validated, closed-loop control across compute, network, and energy domains. The tutorial concludes with a reference architecture for sovereign AI infrastructure that integrates telemetry pipelines, agent-based control, and digital twins, framing sustainability as a first-order design constraint.", "AI": {"tldr": "AI\u4e3b\u6743\u5df2\u4ece\u8f6f\u4ef6\u63a7\u5236\u8f6c\u5411\u57fa\u7840\u8bbe\u65bd\u63a7\u5236\uff0c\u9700\u8981\u6570\u636e\u4e2d\u5fc3\u3001\u5149\u7f51\u7edc\u548c\u81ea\u52a8\u5316\u6846\u67b6\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u5728\u80fd\u6e90\u548c\u53ef\u6301\u7eed\u6027\u7ea6\u675f\u4e0b\u5b9e\u73b0\u53ef\u64cd\u4f5c\u7684\u4e3b\u6743\u3002", "motivation": "AI\u5df2\u4ece\u8f6f\u4ef6\u4e3a\u4e2d\u5fc3\u8f6c\u5411\u57fa\u7840\u8bbe\u65bd\u9a71\u52a8\uff0c\u4ec5\u63a7\u5236\u6570\u636e\u548c\u7b97\u6cd5\u5df2\u4e0d\u8db3\u4ee5\u5b9e\u73b0\u771f\u6b63\u7684AI\u4e3b\u6743\u3002\u5b9e\u9645\u4e3b\u6743\u53d6\u51b3\u4e8e\u5728\u80fd\u6e90\u53ef\u7528\u6027\u3001\u53ef\u6301\u7eed\u6027\u76ee\u6807\u548c\u7f51\u7edc\u8986\u76d6\u7b49\u7ea6\u675f\u4e0b\u90e8\u7f72\u3001\u8fd0\u8425\u548c\u9002\u5e94AI\u57fa\u7840\u8bbe\u65bd\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faAI\u57fa\u7840\u8bbe\u65bd\u4e3b\u6743\u6982\u5ff5\uff0c\u5206\u6790\u4e09\u4e2a\u534f\u540c\u8bbe\u8ba1\u5c42\uff1aAI\u5bfc\u5411\u7684\u6570\u636e\u4e2d\u5fc3\uff08\u8003\u8651\u529f\u7387\u5bc6\u5ea6\u3001\u51b7\u5374\u3001\u80fd\u6e90\u8026\u5408\uff09\u3001\u5149\u4f20\u8f93\u7f51\u7edc\uff08\u5ef6\u8fdf\u3001\u5bb9\u91cf\u3001\u6545\u969c\u57df\u3001\u7ba1\u8f96\u63a7\u5236\uff09\u3001\u4ee5\u53ca\u63d0\u4f9b\u5b9e\u65f6\u53ef\u89c1\u6027\u548c\u63a7\u5236\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff08\u9065\u6d4b\u3001\u667a\u80fdAI\u3001\u6570\u5b57\u5b6a\u751f\uff09\u3002", "result": "\u6784\u5efa\u4e86\u4e3b\u6743AI\u57fa\u7840\u8bbe\u65bd\u7684\u53c2\u8003\u67b6\u6784\uff0c\u6574\u5408\u9065\u6d4b\u7ba1\u9053\u3001\u57fa\u4e8e\u4ee3\u7406\u7684\u63a7\u5236\u548c\u6570\u5b57\u5b6a\u751f\uff0c\u5c06\u53ef\u6301\u7eed\u6027\u4f5c\u4e3a\u9996\u8981\u8bbe\u8ba1\u7ea6\u675f\uff0c\u5b9e\u73b0\u8de8\u8ba1\u7b97\u3001\u7f51\u7edc\u548c\u80fd\u6e90\u9886\u57df\u7684\u95ed\u73af\u63a7\u5236\u3002", "conclusion": "AI\u4e3b\u6743\u73b0\u5728\u53d6\u51b3\u4e8e\u57fa\u7840\u8bbe\u65bd\u63a7\u5236\u80fd\u529b\uff0c\u9700\u8981\u901a\u8fc7\u6570\u636e\u4e2d\u5fc3\u3001\u5149\u7f51\u7edc\u548c\u81ea\u52a8\u5316\u6846\u67b6\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u5728\u7269\u7406\u548c\u73af\u5883\u9650\u5236\u4e0b\u5b9e\u73b0\u53ef\u64cd\u4f5c\u7684\u4e3b\u6743\uff0c\u5c06\u53ef\u6301\u7eed\u6027\u4f5c\u4e3a\u6838\u5fc3\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2602.10635", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10635", "abs": "https://arxiv.org/abs/2602.10635", "authors": ["Keane Ong", "Sabri Boughorbel", "Luwei Xiao", "Chanakya Ekbote", "Wei Dai", "Ao Qu", "Jingyao Wu", "Rui Mao", "Ehsan Hoque", "Erik Cambria", "Gianmarco Mengaldo", "Paul Pu Liang"], "title": "OmniSapiens: A Foundation Model for Social Behavior Processing via Heterogeneity-Aware Relative Policy Optimization", "comment": null, "summary": "To develop socially intelligent AI, existing approaches typically model human behavioral dimensions (e.g., affective, cognitive, or social attributes) in isolation. Although useful, task-specific modeling often increases training costs and limits generalization across behavioral settings. Recent reasoning RL methods facilitate training a single unified model across multiple behavioral tasks, but do not explicitly address learning across different heterogeneous behavioral data. To address this gap, we introduce Heterogeneity-Aware Relative Policy Optimization (HARPO), an RL method that balances leaning across heterogeneous tasks and samples. This is achieved by modulating advantages to ensure that no single task or sample carries disproportionate influence during policy optimization. Using HARPO, we develop and release Omnisapiens-7B 2.0, a foundation model for social behavior processing. Relative to existing behavioral foundation models, Omnisapiens-7B 2.0 achieves the strongest performance across behavioral tasks, with gains of up to +16.85% and +9.37% on multitask and held-out settings respectively, while producing more explicit and robust reasoning traces. We also validate HARPO against recent RL methods, where it achieves the most consistently strong performance across behavioral tasks.", "AI": {"tldr": "HARPO\u662f\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c03\u8282\u4f18\u52bf\u51fd\u6570\u6765\u5e73\u8861\u5f02\u6784\u4efb\u52a1\u548c\u6837\u672c\u7684\u5b66\u4e60\uff0c\u5f00\u53d1\u4e86Omnisapiens-7B 2.0\u793e\u4ea4\u884c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u5728\u591a\u9879\u884c\u4e3a\u4efb\u52a1\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5b64\u7acb\u5730\u5efa\u6a21\u4eba\u7c7b\u884c\u4e3a\u7ef4\u5ea6\uff08\u5982\u60c5\u611f\u3001\u8ba4\u77e5\u6216\u793e\u4f1a\u5c5e\u6027\uff09\uff0c\u867d\u7136\u6709\u7528\u4f46\u4efb\u52a1\u7279\u5b9a\u5efa\u6a21\u4f1a\u589e\u52a0\u8bad\u7ec3\u6210\u672c\u5e76\u9650\u5236\u8de8\u884c\u4e3a\u8bbe\u7f6e\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6700\u8fd1\u7684\u63a8\u7406RL\u65b9\u6cd5\u867d\u7136\u80fd\u5728\u591a\u4e2a\u884c\u4e3a\u4efb\u52a1\u4e0a\u8bad\u7ec3\u7edf\u4e00\u6a21\u578b\uff0c\u4f46\u6ca1\u6709\u660e\u786e\u89e3\u51b3\u8de8\u5f02\u6784\u884c\u4e3a\u6570\u636e\u7684\u5b66\u4e60\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u5f02\u6784\u611f\u77e5\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08HARPO\uff09\uff0c\u8fd9\u662f\u4e00\u79cdRL\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c03\u8282\u4f18\u52bf\u51fd\u6570\u6765\u786e\u4fdd\u5728\u7b56\u7565\u4f18\u5316\u8fc7\u7a0b\u4e2d\u6ca1\u6709\u4efb\u4f55\u5355\u4e2a\u4efb\u52a1\u6216\u6837\u672c\u4ea7\u751f\u4e0d\u6210\u6bd4\u4f8b\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u5e73\u8861\u8de8\u5f02\u6784\u4efb\u52a1\u548c\u6837\u672c\u7684\u5b66\u4e60\u3002", "result": "\u4f7f\u7528HARPO\u5f00\u53d1\u4e86Omnisapiens-7B 2.0\u793e\u4ea4\u884c\u4e3a\u5904\u7406\u57fa\u7840\u6a21\u578b\u3002\u76f8\u5bf9\u4e8e\u73b0\u6709\u884c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u5728\u591a\u9879\u884c\u4e3a\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u5f3a\u6027\u80fd\uff0c\u591a\u4efb\u52a1\u548c\u4fdd\u7559\u8bbe\u7f6e\u5206\u522b\u63d0\u5347\u4e86+16.85%\u548c+9.37%\uff0c\u540c\u65f6\u4ea7\u751f\u66f4\u660e\u786e\u548c\u9c81\u68d2\u7684\u63a8\u7406\u8f68\u8ff9\u3002HARPO\u5728\u4e0e\u5176\u4ed6RL\u65b9\u6cd5\u7684\u6bd4\u8f83\u4e2d\u4e5f\u8868\u73b0\u51fa\u6700\u4e00\u81f4\u5f3a\u5927\u7684\u6027\u80fd\u3002", "conclusion": "HARPO\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u5f02\u6784\u884c\u4e3a\u6570\u636e\u5b66\u4e60\u7684\u6311\u6218\uff0c\u5f00\u53d1\u51fa\u7684Omnisapiens-7B 2.0\u6a21\u578b\u5728\u793e\u4ea4\u884c\u4e3a\u5904\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u5f00\u53d1\u793e\u4f1a\u667a\u80fdAI\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2602.11058", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.11058", "abs": "https://arxiv.org/abs/2602.11058", "authors": ["Mohammad Khosravi", "Setareh Maghsudi"], "title": "A Robust Optimization Approach for Regenerator Placement in Fault-Tolerant Networks Under Discrete Cost Uncertainty", "comment": null, "summary": "We focus on robust, survivable communication networks, where network links and nodes are affected by an uncertainty set. In this sense, any network links might fail. Besides, a signal can only travel a maximum distance before its quality falls below a certain threshold, necessitating its regeneration by regenerators installed at network nodes. In addition, the price of installing and maintaining regenerators belongs to a discrete uncertainty set. Robust optimization seeks a solution with guaranteed performance against all scenarios modeled in an uncertainty set. Thus, the problem is to find a subset of nodes with minimum cost for the placement of the regenerator, ensuring that all nodes can communicate even if a subset of network links fails. To solve the problem optimally, we propose two solution approaches, including one flow-based and one cut-based integer programming formulation, as well as their iterative exact method. Our theoretical and experimental results show the effectiveness of our methods.", "AI": {"tldr": "\u7814\u7a76\u9c81\u68d2\u53ef\u751f\u5b58\u901a\u4fe1\u7f51\u7edc\u4e2d\u7684\u518d\u751f\u5668\u653e\u7f6e\u95ee\u9898\uff0c\u8003\u8651\u94fe\u8def\u6545\u969c\u548c\u6210\u672c\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u51fa\u4e24\u79cd\u6574\u6570\u89c4\u5212\u65b9\u6cd5", "motivation": "\u5728\u9c81\u68d2\u53ef\u751f\u5b58\u901a\u4fe1\u7f51\u7edc\u4e2d\uff0c\u94fe\u8def\u548c\u8282\u70b9\u53ef\u80fd\u6545\u969c\uff0c\u4fe1\u53f7\u4f20\u8f93\u8ddd\u79bb\u6709\u9650\u9700\u8981\u518d\u751f\u5668\uff0c\u4e14\u5b89\u88c5\u7ef4\u62a4\u6210\u672c\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\uff0c\u9700\u8981\u627e\u5230\u6700\u5c0f\u6210\u672c\u7684\u518d\u751f\u5668\u653e\u7f6e\u65b9\u6848", "method": "\u63d0\u51fa\u4e24\u79cd\u89e3\u51b3\u65b9\u6848\uff1a\u57fa\u4e8e\u6d41\u7684\u6574\u6570\u89c4\u5212\u516c\u5f0f\u548c\u57fa\u4e8e\u5272\u7684\u6574\u6570\u89c4\u5212\u516c\u5f0f\uff0c\u4ee5\u53ca\u5b83\u4eec\u7684\u8fed\u4ee3\u7cbe\u786e\u65b9\u6cd5", "result": "\u7406\u8bba\u548c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u6210\u529f\u89e3\u51b3\u4e86\u9c81\u68d2\u901a\u4fe1\u7f51\u7edc\u4e2d\u7684\u518d\u751f\u5668\u653e\u7f6e\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u6574\u6570\u89c4\u5212\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u627e\u5230\u6700\u5c0f\u6210\u672c\u7684\u518d\u751f\u5668\u914d\u7f6e\u65b9\u6848"}}
{"id": "2602.10699", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10699", "abs": "https://arxiv.org/abs/2602.10699", "authors": ["Jie Jiang", "Yangru Huang", "Zeyu Wang", "Changping Wang", "Yuling Xiong", "Jun Zhang", "Huan Yu"], "title": "Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation", "comment": null, "summary": "Generative recommendation via autoregressive models has unified retrieval and ranking into a single conditional generation framework. However, fine-tuning these models with Reinforcement Learning (RL) often suffers from a fundamental probability-reward mismatch. Conventional likelihood-dominated decoding (e.g., beam search) exhibits a myopic bias toward locally probable prefixes, which causes two critical failures: (1) insufficient exploration, where high-reward items in low-probability branches are prematurely pruned and rarely sampled, and (2) advantage compression, where trajectories sharing high-probability prefixes receive highly correlated rewards with low within-group variance, yielding a weak comparative signal for RL. To address these challenges, we propose V-STAR, a Value-guided Sampling and Tree-structured Advantage Reinforcement framework. V-STAR forms a self-evolving loop via two synergistic components. First, a Value-Guided Efficient Decoding (VED) is developed to identify decisive nodes and selectively deepen high-potential prefixes. This improves exploration efficiency without exhaustive tree search. Second, we propose Sibling-GRPO, which exploits the induced tree topology to compute sibling-relative advantages and concentrates learning signals on decisive branching decisions. Extensive experiments on both offline and online datasets demonstrate that V-STAR outperforms state-of-the-art baselines, delivering superior accuracy and candidate-set diversity under strict latency constraints.", "AI": {"tldr": "V-STAR\u6846\u67b6\u901a\u8fc7\u4ef7\u503c\u5f15\u5bfc\u91c7\u6837\u548c\u6811\u72b6\u4f18\u52bf\u5f3a\u5316\u5b66\u4e60\uff0c\u89e3\u51b3\u751f\u6210\u5f0f\u63a8\u8350\u4e2dRL\u8bad\u7ec3\u7684\u6982\u7387-\u5956\u52b1\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u63d0\u5347\u63a2\u7d22\u6548\u7387\u548c\u591a\u6837\u6027\u3002", "motivation": "\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u5b58\u5728\u6982\u7387-\u5956\u52b1\u4e0d\u5339\u914d\u95ee\u9898\uff1a\u4f20\u7edf\u57fa\u4e8e\u4f3c\u7136\u7684\u89e3\u7801\u504f\u5411\u5c40\u90e8\u9ad8\u6982\u7387\u524d\u7f00\uff0c\u5bfc\u81f4\u63a2\u7d22\u4e0d\u8db3\u548c\u4f18\u52bf\u538b\u7f29\uff0c\u9650\u5236\u4e86\u6a21\u578b\u53d1\u73b0\u9ad8\u5956\u52b1\u4f46\u4f4e\u6982\u7387\u7269\u54c1\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faV-STAR\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u534f\u540c\u7ec4\u4ef6\uff1a1) \u4ef7\u503c\u5f15\u5bfc\u9ad8\u6548\u89e3\u7801(VED)\uff0c\u8bc6\u522b\u5173\u952e\u8282\u70b9\u5e76\u9009\u62e9\u6027\u6df1\u5316\u9ad8\u6f5c\u529b\u524d\u7f00\uff1b2) Sibling-GRPO\uff0c\u5229\u7528\u6811\u72b6\u62d3\u6251\u8ba1\u7b97\u5144\u5f1f\u76f8\u5bf9\u4f18\u52bf\uff0c\u96c6\u4e2d\u5b66\u4e60\u4fe1\u53f7\u4e8e\u5173\u952e\u5206\u652f\u51b3\u7b56\u3002", "result": "\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cV-STAR\u5728\u4e25\u683c\u5ef6\u8fdf\u7ea6\u675f\u4e0b\uff0c\u5728\u51c6\u786e\u6027\u548c\u5019\u9009\u96c6\u591a\u6837\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "V-STAR\u901a\u8fc7\u4ef7\u503c\u5f15\u5bfc\u91c7\u6837\u548c\u6811\u72b6\u4f18\u52bf\u5f3a\u5316\u5b66\u4e60\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u4e2dRL\u8bad\u7ec3\u7684\u6982\u7387-\u5956\u52b1\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u63a2\u7d22\u6548\u7387\u548c\u63a8\u8350\u8d28\u91cf\u3002"}}
{"id": "2602.11102", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.11102", "abs": "https://arxiv.org/abs/2602.11102", "authors": ["Robert Beverly", "Amreesh Phokeer", "Oliver Gasser"], "title": "WHEREIS: IP Address Registration Geo-Consistency", "comment": "arXiv admin note: text overlap with arXiv:2308.12436", "summary": "The five Regional Internet Registries (RIRs) provide the critical function of IP address resource del egation and registration. The accuracy of registration data directly impacts Internet operation, management, security, and optimization. In addition, the scarcity of IP addresses has brought into focus conflicts between RIR policy and IP registration ownership and use. The tension between a free-market based approach to address allocation versus policies to promote fairness and regional equity has resulted in court litigation that threatens the very existence of the RIR system.\n  We develop WHEREIS, a measurement-based approach to geolocate delegated IPv4 and IPv6 prefixes at an RIR-region granularity and systematically study where addresses are used post-allocation and the extent to which registration information is accurate. We define a taxonomy of registration ``geo-consistency'' that compares a prefix's measured geolocation to the allocating RIR's coverage region as well as the registered organization's location. While in aggregate over 98% of the prefixes we examine are consistent with our geolocation inferences, there is substantial variation across RIRs and we focus on AFRINIC as a case study. IPv6 registrations are no more consistent than IPv4, suggesting that structural, rather than technical, issues play an important role in allocations. We solicit additional information on inconsistent prefixes from network operators, IP leasing providers, and collaborate with three RIRs to obtain validation. We further show that the inconsistencies we discover manifest in three commercial geolocation databases. By improving the transparency around post-allocation prefix use, we hope to improve applications that use IP registration data and inform ongoing discussions over in-region address use and policy.", "AI": {"tldr": "\u5f00\u53d1WHEREIS\u7cfb\u7edf\u6d4b\u91cfIP\u524d\u7f00\u5728RIR\u533a\u57df\u7ea7\u522b\u7684\u5b9e\u9645\u4f7f\u7528\u4f4d\u7f6e\uff0c\u53d1\u73b0\u6ce8\u518c\u4fe1\u606f\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u7279\u522b\u662f\u5728AFRINIC\u533a\u57df\uff0cIPv6\u4e0eIPv4\u540c\u6837\u5b58\u5728\u95ee\u9898\uff0c\u5f71\u54cd\u5546\u4e1a\u5730\u7406\u4f4d\u7f6e\u6570\u636e\u5e93\u51c6\u786e\u6027\u3002", "motivation": "RIR\u7cfb\u7edf\u8d1f\u8d23IP\u5730\u5740\u8d44\u6e90\u5206\u914d\u548c\u6ce8\u518c\uff0c\u6ce8\u518c\u6570\u636e\u7684\u51c6\u786e\u6027\u76f4\u63a5\u5f71\u54cd\u4e92\u8054\u7f51\u8fd0\u8425\u3001\u7ba1\u7406\u3001\u5b89\u5168\u548c\u4f18\u5316\u3002IP\u5730\u5740\u7a00\u7f3a\u52a0\u5267\u4e86RIR\u653f\u7b56\u4e0eIP\u6ce8\u518c\u6240\u6709\u6743\u548c\u4f7f\u7528\u4e4b\u95f4\u7684\u51b2\u7a81\uff0c\u81ea\u7531\u5e02\u573a\u5206\u914d\u4e0e\u516c\u5e73\u533a\u57df\u653f\u7b56\u4e4b\u95f4\u7684\u7d27\u5f20\u5173\u7cfb\u5df2\u5bfc\u81f4\u6cd5\u5f8b\u8bc9\u8bbc\uff0c\u5a01\u80c1RIR\u7cfb\u7edf\u7684\u5b58\u5728\u3002", "method": "\u5f00\u53d1WHEREIS\u6d4b\u91cf\u65b9\u6cd5\uff0c\u5728RIR\u533a\u57df\u7c92\u5ea6\u4e0a\u5b9a\u4f4d\u5df2\u5206\u914d\u7684IPv4\u548cIPv6\u524d\u7f00\u3002\u5b9a\u4e49\"\u5730\u7406\u4e00\u81f4\u6027\"\u5206\u7c7b\u6cd5\uff0c\u6bd4\u8f83\u524d\u7f00\u7684\u6d4b\u91cf\u5730\u7406\u4f4d\u7f6e\u4e0e\u5206\u914dRIR\u8986\u76d6\u533a\u57df\u4ee5\u53ca\u6ce8\u518c\u7ec4\u7ec7\u4f4d\u7f6e\u3002\u6536\u96c6\u4e0d\u4e00\u81f4\u524d\u7f00\u7684\u989d\u5916\u4fe1\u606f\uff0c\u4e0e\u7f51\u7edc\u8fd0\u8425\u5546\u3001IP\u79df\u8d41\u63d0\u4f9b\u5546\u5408\u4f5c\uff0c\u5e76\u4e0e\u4e09\u4e2aRIR\u534f\u4f5c\u9a8c\u8bc1\u3002", "result": "\u603b\u4f53\u4e0a\u8d85\u8fc798%\u7684\u524d\u7f00\u4e0e\u5730\u7406\u4f4d\u7f6e\u63a8\u65ad\u4e00\u81f4\uff0c\u4f46\u5404RIR\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4ee5AFRINIC\u4e3a\u6848\u4f8b\u7814\u7a76\u3002IPv6\u6ce8\u518c\u5e76\u4e0d\u6bd4IPv4\u66f4\u4e00\u81f4\uff0c\u8868\u660e\u7ed3\u6784\u6027\u95ee\u9898\u800c\u975e\u6280\u672f\u95ee\u9898\u5728\u5206\u914d\u4e2d\u8d77\u91cd\u8981\u4f5c\u7528\u3002\u53d1\u73b0\u7684\u4e0d\u4e00\u81f4\u6027\u4e5f\u4f53\u73b0\u5728\u4e09\u4e2a\u5546\u4e1a\u5730\u7406\u4f4d\u7f6e\u6570\u636e\u5e93\u4e2d\u3002", "conclusion": "\u901a\u8fc7\u63d0\u9ad8\u5206\u914d\u540e\u524d\u7f00\u4f7f\u7528\u7684\u900f\u660e\u5ea6\uff0c\u5e0c\u671b\u6539\u8fdb\u4f7f\u7528IP\u6ce8\u518c\u6570\u636e\u7684\u5e94\u7528\u7a0b\u5e8f\uff0c\u5e76\u4e3a\u6b63\u5728\u8fdb\u884c\u7684\u533a\u57df\u5185\u5730\u5740\u4f7f\u7528\u548c\u653f\u7b56\u8ba8\u8bba\u63d0\u4f9b\u4fe1\u606f\u3002\u6d4b\u91cf\u65b9\u6cd5\u63ed\u793a\u4e86\u6ce8\u518c\u6570\u636e\u51c6\u786e\u6027\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u7ed3\u6784\u6027\u95ee\u9898\u5bf9IP\u5206\u914d\u7684\u5f71\u54cd\u3002"}}
{"id": "2602.10802", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10802", "abs": "https://arxiv.org/abs/2602.10802", "authors": ["Da-Lun Chen", "Prasasthy Balasubramanian", "Lauri Lov\u00e9n", "Susanna Pirttikangas", "Jaakko Sauvola", "Panagiotis Kostakos"], "title": "Integrating Generative AI-enhanced Cognitive Systems in Higher Education: From Stakeholder Perceptions to a Conceptual Framework considering the EU AI Act", "comment": null, "summary": "Many staff and students in higher education have adopted generative artificial intelligence (GenAI) tools in their work and study. GenAI is expected to enhance cognitive systems by enabling personalized learning and streamlining educational services. However, stakeholders perceptions of GenAI in higher education remain divided, shaped by cultural, disciplinary, and institutional contexts. In addition, the EU AI Act requires universities to ensure regulatory compliance when deploying cognitive systems. These developments highlight the need for institutions to engage stakeholders and tailor GenAI integration to their needs while addressing concerns. This study investigates how GenAI is perceived within the disciplines of Information Technology and Electrical Engineering (ITEE). Using a mixed-method approach, we surveyed 61 staff and 37 students at the Faculty of ITEE, University of Oulu. The results reveal both shared and discipline-specific themes, including strong interest in programming support from GenAI and concerns over response quality, privacy, and academic integrity. Drawing from these insights, the study identifies a set of high-level requirements and proposes a conceptual framework for responsible GenAI integration. Disciplinary-specific requirements reinforce the importance of stakeholder engagement when integrating GenAI into higher education. The high-level requirements and the framework provide practical guidance for universities aiming to harness GenAI while addressing stakeholder concerns and ensuring regulatory compliance.", "AI": {"tldr": "\u7814\u7a76\u8c03\u67e5\u4e86\u9ad8\u7b49\u6559\u80b2\u4e2d\u751f\u6210\u5f0fAI\u7684\u611f\u77e5\u60c5\u51b5\uff0c\u91cd\u70b9\u5173\u6ce8ITEE\u9886\u57df\uff0c\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u8bc6\u522b\u4e86\u5171\u540c\u548c\u5b66\u79d1\u7279\u5b9a\u7684\u4e3b\u9898\uff0c\u63d0\u51fa\u4e86\u8d1f\u8d23\u4efb\u6574\u5408\u7684\u6846\u67b6\u548c\u9ad8\u7ea7\u8981\u6c42\u3002", "motivation": "\u9ad8\u7b49\u6559\u80b2\u4e2d\u751f\u6210\u5f0fAI\u5de5\u5177\u5df2\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u5229\u76ca\u76f8\u5173\u8005\u7684\u770b\u6cd5\u5b58\u5728\u5206\u6b67\uff0c\u53d7\u6587\u5316\u3001\u5b66\u79d1\u548c\u5236\u5ea6\u80cc\u666f\u5f71\u54cd\u3002\u6b27\u76dfAI\u6cd5\u6848\u8981\u6c42\u5927\u5b66\u786e\u4fdd\u8ba4\u77e5\u7cfb\u7edf\u7684\u5408\u89c4\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e86\u89e3\u5229\u76ca\u76f8\u5173\u8005\u9700\u6c42\u5e76\u5b9a\u5236AI\u6574\u5408\u65b9\u6848\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u5bf9\u5965\u5362\u5927\u5b66ITEE\u5b66\u9662\u768461\u540d\u6559\u804c\u5458\u5de5\u548c37\u540d\u5b66\u751f\u8fdb\u884c\u8c03\u67e5\uff0c\u5206\u6790\u4ed6\u4eec\u5bf9\u751f\u6210\u5f0fAI\u7684\u611f\u77e5\u548c\u9700\u6c42\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u5171\u540c\u548c\u5b66\u79d1\u7279\u5b9a\u7684\u4e3b\u9898\uff1a\u5bf9\u7f16\u7a0b\u652f\u6301\u7684\u5f3a\u70c8\u5174\u8da3\uff0c\u4ee5\u53ca\u5bf9\u54cd\u5e94\u8d28\u91cf\u3001\u9690\u79c1\u548c\u5b66\u672f\u8bda\u4fe1\u7684\u62c5\u5fe7\u3002\u8bc6\u522b\u4e86\u9ad8\u7ea7\u8981\u6c42\u5e76\u63d0\u51fa\u4e86\u8d1f\u8d23\u4efb\u6574\u5408\u7684\u6982\u5ff5\u6846\u67b6\u3002", "conclusion": "\u5b66\u79d1\u7279\u5b9a\u8981\u6c42\u5f3a\u8c03\u4e86\u5229\u76ca\u76f8\u5173\u8005\u53c2\u4e0e\u7684\u91cd\u8981\u6027\u3002\u9ad8\u7ea7\u8981\u6c42\u548c\u6846\u67b6\u4e3a\u5927\u5b66\u5229\u7528\u751f\u6210\u5f0fAI\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u540c\u65f6\u89e3\u51b3\u5229\u76ca\u76f8\u5173\u8005\u5173\u5207\u5e76\u786e\u4fdd\u5408\u89c4\u6027\u3002"}}
{"id": "2602.10814", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10814", "abs": "https://arxiv.org/abs/2602.10814", "authors": ["Xingyi Zhang", "Yulei Ye", "Kaifeng Huang", "Wenhao Li", "Xiangfeng Wang"], "title": "See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch", "comment": null, "summary": "Block-based programming environments such as Scratch play a central role in low-code education, yet evaluating the capabilities of AI agents to construct programs through Graphical User Interfaces (GUIs) remains underexplored. We introduce ScratchWorld, a benchmark for evaluating multimodal GUI agents on program-by-construction tasks in Scratch. Grounded in the Use-Modify-Create pedagogical framework, ScratchWorld comprises 83 curated tasks spanning four distinct problem categories: Create, Debug, Extend, and Compute. To rigorously diagnose the source of agent failures, the benchmark employs two complementary interaction modes: primitive mode requires fine-grained drag-and-drop manipulation to directly assess visuomotor control, while composite mode uses high-level semantic APIs to disentangle program reasoning from GUI execution. To ensure reliable assessment, we propose an execution-based evaluation protocol that validates the functional correctness of the constructed Scratch programs through runtime tests within the browser environment. Extensive experiments across state-of-the-art multimodal language models and GUI agents reveal a substantial reasoning--acting gap, highlighting persistent challenges in fine-grained GUI manipulation despite strong planning capabilities.", "AI": {"tldr": "ScratchWorld\uff1a\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001GUI\u4ee3\u7406\u5728Scratch\u4e2d\u901a\u8fc7\u56fe\u5f62\u754c\u9762\u6784\u5efa\u7a0b\u5e8f\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b83\u4e2a\u4efb\u52a1\uff0c\u91c7\u7528\u4e24\u79cd\u4ea4\u4e92\u6a21\u5f0f\u6765\u8bca\u65ad\u4ee3\u7406\u5931\u8d25\u539f\u56e0\u3002", "motivation": "\u867d\u7136Scratch\u7b49\u57fa\u4e8e\u5757\u7684\u7f16\u7a0b\u73af\u5883\u5728\u4f4e\u4ee3\u7801\u6559\u80b2\u4e2d\u626e\u6f14\u6838\u5fc3\u89d2\u8272\uff0c\u4f46\u8bc4\u4f30AI\u4ee3\u7406\u901a\u8fc7\u56fe\u5f62\u7528\u6237\u754c\u9762\u6784\u5efa\u7a0b\u5e8f\u7684\u80fd\u529b\u4ecd\u7136\u7814\u7a76\u4e0d\u8db3\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u591a\u6a21\u6001GUI\u4ee3\u7406\u5728\u7a0b\u5e8f\u6784\u5efa\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u57fa\u4e8eUse-Modify-Create\u6559\u5b66\u6846\u67b6\u8bbe\u8ba183\u4e2a\u4efb\u52a1\uff0c\u6db5\u76d6Create\u3001Debug\u3001Extend\u3001Compute\u56db\u7c7b\u95ee\u9898\u3002\u91c7\u7528\u4e24\u79cd\u4ea4\u4e92\u6a21\u5f0f\uff1aprimitive\u6a21\u5f0f\uff08\u7ec6\u7c92\u5ea6\u62d6\u653e\u64cd\u4f5c\uff09\u8bc4\u4f30\u89c6\u89c9\u8fd0\u52a8\u63a7\u5236\uff0ccomposite\u6a21\u5f0f\uff08\u9ad8\u7ea7\u8bed\u4e49API\uff09\u5206\u79bb\u7a0b\u5e8f\u63a8\u7406\u548cGUI\u6267\u884c\u3002\u63d0\u51fa\u57fa\u4e8e\u6267\u884c\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u5728\u6d4f\u89c8\u5668\u73af\u5883\u4e2d\u901a\u8fc7\u8fd0\u884c\u65f6\u6d4b\u8bd5\u9a8c\u8bc1\u7a0b\u5e8f\u529f\u80fd\u6b63\u786e\u6027\u3002", "result": "\u5bf9\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u548cGUI\u4ee3\u7406\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u63ed\u793a\u4e86\u663e\u8457\u7684\u63a8\u7406-\u884c\u52a8\u5dee\u8ddd\uff0c\u8868\u660e\u5c3d\u7ba1\u89c4\u5212\u80fd\u529b\u5f3a\uff0c\u4f46\u5728\u7ec6\u7c92\u5ea6GUI\u64cd\u4f5c\u65b9\u9762\u4ecd\u5b58\u5728\u6301\u7eed\u6311\u6218\u3002", "conclusion": "ScratchWorld\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u8bc4\u4f30\u591a\u6a21\u6001GUI\u4ee3\u7406\u7684\u7a0b\u5e8f\u6784\u5efa\u80fd\u529b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u4ee3\u7406\u5728GUI\u64cd\u4f5c\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2602.10845", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10845", "abs": "https://arxiv.org/abs/2602.10845", "authors": ["Xuecheng Zou", "Yu Tang", "Bingbing Wang"], "title": "SynergyKGC: Reconciling Topological Heterogeneity in Knowledge Graph Completion via Topology-Aware Synergy", "comment": "10 pages, 5 tables, 7 figures. This work introduces the Active Synergy mechanism and Identity Anchoring for Knowledge Graph Completion. Code: https://github.com/XuechengZou-2001/SynergyKGC-main", "summary": "Knowledge Graph Completion (KGC) fundamentally hinges on the coherent fusion of pre-trained entity semantics with heterogeneous topological structures to facilitate robust relational reasoning. However, existing paradigms encounter a critical \"structural resolution mismatch,\" failing to reconcile divergent representational demands across varying graph densities, which precipitates structural noise interference in dense clusters and catastrophic representation collapse in sparse regions. We present SynergyKGC, an adaptive framework that advances traditional neighbor aggregation to an active Cross-Modal Synergy Expert via relation-aware cross-attention and semantic-intent-driven gating. By coupling a density-dependent Identity Anchoring strategy with a Double-tower Coherent Consistency architecture, SynergyKGC effectively reconciles topological heterogeneity while ensuring representational stability across training and inference phases. Systematic evaluations on two public benchmarks validate the superiority of our method in significantly boosting KGC hit rates, providing empirical evidence for a generalized principle of resilient information integration in non-homogeneous structured data.", "AI": {"tldr": "SynergyKGC\u901a\u8fc7\u8de8\u6a21\u6001\u534f\u540c\u4e13\u5bb6\u548c\u5bc6\u5ea6\u4f9d\u8d56\u7684\u8eab\u4efd\u951a\u5b9a\u7b56\u7565\uff0c\u89e3\u51b3\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4e2d\u7684\u7ed3\u6784\u5206\u8fa8\u7387\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u547d\u4e2d\u7387\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u65b9\u6cd5\u9762\u4e34\"\u7ed3\u6784\u5206\u8fa8\u7387\u4e0d\u5339\u914d\"\u95ee\u9898\uff1a\u65e0\u6cd5\u534f\u8c03\u4e0d\u540c\u56fe\u5bc6\u5ea6\u4e0b\u7684\u8868\u793a\u9700\u6c42\uff0c\u5bfc\u81f4\u5bc6\u96c6\u7c07\u4e2d\u7684\u7ed3\u6784\u566a\u58f0\u5e72\u6270\u548c\u7a00\u758f\u533a\u57df\u7684\u8868\u793a\u5d29\u6e83\u3002", "method": "\u63d0\u51faSynergyKGC\u6846\u67b6\uff1a1) \u5c06\u4f20\u7edf\u90bb\u5c45\u805a\u5408\u63d0\u5347\u4e3a\u4e3b\u52a8\u7684\u8de8\u6a21\u6001\u534f\u540c\u4e13\u5bb6\uff0c\u4f7f\u7528\u5173\u7cfb\u611f\u77e5\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u8bed\u4e49\u610f\u56fe\u9a71\u52a8\u7684\u95e8\u63a7\uff1b2) \u7ed3\u5408\u5bc6\u5ea6\u4f9d\u8d56\u7684\u8eab\u4efd\u951a\u5b9a\u7b56\u7565\u548c\u53cc\u5854\u4e00\u81f4\u6027\u67b6\u6784\uff0c\u534f\u8c03\u62d3\u6251\u5f02\u8d28\u6027\u5e76\u786e\u4fdd\u8868\u793a\u7a33\u5b9a\u6027\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u7cfb\u7edf\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86KGC\u547d\u4e2d\u7387\uff0c\u4e3a\u975e\u5747\u5300\u7ed3\u6784\u5316\u6570\u636e\u4e2d\u7684\u5f39\u6027\u4fe1\u606f\u6574\u5408\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u8bc1\u636e\u3002", "conclusion": "SynergyKGC\u901a\u8fc7\u81ea\u9002\u5e94\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4e2d\u7684\u7ed3\u6784\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9884\u8bad\u7ec3\u5b9e\u4f53\u8bed\u4e49\u4e0e\u5f02\u6784\u62d3\u6251\u7ed3\u6784\u7684\u534f\u540c\u878d\u5408\uff0c\u4e3a\u5173\u7cfb\u63a8\u7406\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.10885", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10885", "abs": "https://arxiv.org/abs/2602.10885", "authors": ["Leheng Sheng", "Wenchang Ma", "Ruixin Hong", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Reinforcing Chain-of-Thought Reasoning with Self-Evolving Rubrics", "comment": "21 pages", "summary": "Despite chain-of-thought (CoT) playing crucial roles in LLM reasoning, directly rewarding it is difficult: training a reward model demands heavy human labeling efforts, and static RMs struggle with evolving CoT distributions and reward hacking. These challenges motivate us to seek an autonomous CoT rewarding approach that requires no human annotation efforts and can evolve gradually. Inspired by recent self-evolving training methods, we propose \\textbf{RLCER} (\\textbf{R}einforcement \\textbf{L}earning with \\textbf{C}oT Supervision via Self-\\textbf{E}volving \\textbf{R}ubrics), which enhances the outcome-centric RLVR by rewarding CoTs with self-proposed and self-evolving rubrics. We show that self-proposed and self-evolving rubrics provide reliable CoT supervision signals even without outcome rewards, enabling RLCER to outperform outcome-centric RLVR. Moreover, when used as in-prompt hints, these self-proposed rubrics further improve inference-time performance.", "AI": {"tldr": "RLCER\uff1a\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684\u81ea\u4e3b\u5956\u52b1\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u63d0\u51fa\u548c\u81ea\u6f14\u8fdb\u7684\u8bc4\u5206\u6807\u51c6\u6765\u5956\u52b1CoT\u63a8\u7406\uff0c\u8d85\u8d8a\u57fa\u4e8e\u7ed3\u679c\u7684RLVR\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u5956\u52b1CoT\u63a8\u7406\u7684\u65b9\u6cd5\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1\uff09\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\uff1b2\uff09\u9759\u6001\u5956\u52b1\u6a21\u578b\u96be\u4ee5\u9002\u5e94\u4e0d\u65ad\u6f14\u5316\u7684CoT\u5206\u5e03\u4e14\u5bb9\u6613\u53d7\u5230\u5956\u52b1\u653b\u51fb\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u4e14\u80fd\u81ea\u4e3b\u6f14\u8fdb\u7684CoT\u5956\u52b1\u65b9\u6cd5\u3002", "method": "\u63d0\u51faRLCER\u65b9\u6cd5\uff0c\u5728\u57fa\u4e8e\u7ed3\u679c\u7684RLVR\u57fa\u7840\u4e0a\uff0c\u901a\u8fc7\u81ea\u63d0\u51fa\u548c\u81ea\u6f14\u8fdb\u7684\u8bc4\u5206\u6807\u51c6\u6765\u5956\u52b1CoT\u63a8\u7406\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u81ea\u4e3b\u751f\u6210\u8bc4\u5206\u6807\u51c6\u5e76\u968f\u65f6\u95f4\u6f14\u8fdb\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u7ed3\u679c\u5956\u52b1\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u63d0\u4f9b\u53ef\u9760\u7684CoT\u76d1\u7763\u4fe1\u53f7\u3002", "result": "RLCER\u5728\u6027\u80fd\u4e0a\u8d85\u8d8a\u4e86\u57fa\u4e8e\u7ed3\u679c\u7684RLVR\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u5f53\u5c06\u8fd9\u4e9b\u81ea\u63d0\u51fa\u7684\u8bc4\u5206\u6807\u51c6\u4f5c\u4e3a\u63d0\u793a\u4e2d\u7684\u63d0\u793a\u4fe1\u606f\u65f6\uff0c\u8fd8\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u63a8\u7406\u65f6\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "RLCER\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u81ea\u4e3b\u5956\u52b1CoT\u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u4e14\u80fd\u9002\u5e94\u6f14\u5316\uff0c\u4e3aLLM\u63a8\u7406\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.10964", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10964", "abs": "https://arxiv.org/abs/2602.10964", "authors": ["F. Carichon", "R. Rampa", "G. Farnadi"], "title": "Can LLMs Cook Jamaican Couscous? A Study of Cultural Novelty in Recipe Generation", "comment": "14 pages, 12 figures, conference", "summary": "Large Language Models (LLMs) are increasingly used to generate and shape cultural content, ranging from narrative writing to artistic production. While these models demonstrate impressive fluency and generative capacity, prior work has shown that they also exhibit systematic cultural biases, raising concerns about stereotyping, homogenization, and the erasure of culturally specific forms of expression. Understanding whether LLMs can meaningfully align with diverse cultures beyond the dominant ones remains a critical challenge. In this paper, we study cultural adaptation in LLMs through the lens of cooking recipes, a domain in which culture, tradition, and creativity are tightly intertwined. We build on the \\textit{GlobalFusion} dataset, which pairs human recipes from different countries according to established measures of cultural distance. Using the same country pairs, we generate culturally adapted recipes with multiple LLMs, enabling a direct comparison between human and LLM behavior in cross-cultural content creation. Our analysis shows that LLMs fail to produce culturally representative adaptations. Unlike humans, the divergence of their generated recipes does not correlate with cultural distance. We further provide explanations for this gap. We show that cultural information is weakly preserved in internal model representations, that models inflate novelty in their production by misunderstanding notions such as creativity and tradition, and that they fail to identify adaptation with its associated countries and to ground it in culturally salient elements such as ingredients. These findings highlight fundamental limitations of current LLMs for culturally oriented generation and have important implications for their use in culturally sensitive applications.", "AI": {"tldr": "LLMs\u5728\u6587\u5316\u9002\u5e94\u65b9\u9762\u5b58\u5728\u6839\u672c\u6027\u7f3a\u9677\uff1a\u5c3d\u7ba1\u80fd\u751f\u6210\u6d41\u7545\u5185\u5bb9\uff0c\u4f46\u65e0\u6cd5\u6839\u636e\u6587\u5316\u8ddd\u79bb\u4ea7\u751f\u6709\u610f\u4e49\u7684\u9002\u5e94\uff0c\u5728\u70f9\u996a\u98df\u8c31\u751f\u6210\u4e2d\u8868\u73b0\u51fa\u4e0e\u4eba\u7c7b\u4e0d\u540c\u7684\u6a21\u5f0f\uff0c\u6587\u5316\u4fe1\u606f\u5728\u6a21\u578b\u5185\u90e8\u8868\u5f81\u4e2d\u4fdd\u5b58\u8f83\u5f31\u3002", "motivation": "LLMs\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u751f\u6210\u548c\u5851\u9020\u6587\u5316\u5185\u5bb9\uff0c\u4f46\u5148\u524d\u7814\u7a76\u8868\u660e\u5b83\u4eec\u5b58\u5728\u7cfb\u7edf\u6027\u6587\u5316\u504f\u89c1\uff0c\u53ef\u80fd\u5f15\u53d1\u523b\u677f\u5370\u8c61\u3001\u540c\u8d28\u5316\u548c\u6587\u5316\u7279\u5b9a\u8868\u8fbe\u5f62\u5f0f\u7684\u62b9\u9664\u3002\u7406\u89e3LLMs\u662f\u5426\u80fd\u8d85\u8d8a\u4e3b\u6d41\u6587\u5316\u800c\u6709\u610f\u4e49\u5730\u9002\u5e94\u591a\u5143\u6587\u5316\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u901a\u8fc7\u70f9\u996a\u98df\u8c31\u8fd9\u4e00\u6587\u5316\u3001\u4f20\u7edf\u548c\u521b\u9020\u529b\u7d27\u5bc6\u4ea4\u7ec7\u7684\u9886\u57df\u7814\u7a76LLMs\u7684\u6587\u5316\u9002\u5e94\u80fd\u529b\u3002\u4f7f\u7528GlobalFusion\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u6839\u636e\u6587\u5316\u8ddd\u79bb\u6d4b\u91cf\u914d\u5bf9\u4e0d\u540c\u56fd\u5bb6\u7684\u4eba\u7c7b\u98df\u8c31\u3002\u4f7f\u7528\u76f8\u540c\u56fd\u5bb6\u914d\u5bf9\uff0c\u7528\u591a\u4e2aLLMs\u751f\u6210\u6587\u5316\u9002\u5e94\u98df\u8c31\uff0c\u4ece\u800c\u76f4\u63a5\u6bd4\u8f83\u4eba\u7c7b\u548cLLM\u5728\u8de8\u6587\u5316\u5185\u5bb9\u521b\u4f5c\u4e2d\u7684\u884c\u4e3a\u3002", "result": "LLMs\u65e0\u6cd5\u4ea7\u751f\u5177\u6709\u6587\u5316\u4ee3\u8868\u6027\u7684\u9002\u5e94\u3002\u4e0e\u4eba\u7c7b\u4e0d\u540c\uff0c\u5b83\u4eec\u751f\u6210\u7684\u98df\u8c31\u5dee\u5f02\u4e0e\u6587\u5316\u8ddd\u79bb\u4e0d\u76f8\u5173\u3002\u6587\u5316\u4fe1\u606f\u5728\u6a21\u578b\u5185\u90e8\u8868\u5f81\u4e2d\u4fdd\u5b58\u8f83\u5f31\uff1b\u6a21\u578b\u901a\u8fc7\u8bef\u89e3\u521b\u9020\u6027\u548c\u4f20\u7edf\u7b49\u6982\u5ff5\u6765\u5938\u5927\u65b0\u9896\u6027\uff1b\u65e0\u6cd5\u5c06\u9002\u5e94\u4e0e\u76f8\u5173\u56fd\u5bb6\u8054\u7cfb\u8d77\u6765\uff0c\u4e5f\u65e0\u6cd5\u5c06\u5176\u5efa\u7acb\u5728\u6587\u5316\u663e\u8457\u5143\u7d20\uff08\u5982\u98df\u6750\uff09\u4e0a\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u6587\u5316\u5bfc\u5411\u751f\u6210\u65b9\u9762\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\uff0c\u8fd9\u5bf9\u5b83\u4eec\u5728\u6587\u5316\u654f\u611f\u5e94\u7528\u4e2d\u7684\u4f7f\u7528\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002\u7814\u7a76\u63ed\u793a\u4e86LLMs\u5728\u6587\u5316\u9002\u5e94\u65b9\u9762\u7684\u7cfb\u7edf\u6027\u7f3a\u9677\uff0c\u9700\u8981\u66f4\u6df1\u5165\u7406\u89e3\u6a21\u578b\u5982\u4f55\u7f16\u7801\u548c\u5904\u7406\u6587\u5316\u4fe1\u606f\u3002"}}
{"id": "2602.10999", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10999", "abs": "https://arxiv.org/abs/2602.10999", "authors": ["Yusong Lin", "Haiyang Wang", "Shuzhe Wu", "Lue Fan", "Feiyang Pan", "Sanyuan Zhao", "Dandan Tu"], "title": "CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion", "comment": null, "summary": "Agentic coding requires agents to effectively interact with runtime environments, e.g., command line interfaces (CLI), so as to complete tasks like resolving dependency issues, fixing system problems, etc. But it remains underexplored how such environment-intensive tasks can be obtained at scale to enhance agents' capabilities. To address this, based on an analogy between the Dockerfile and the agentic task, we propose to employ agents to simulate and explore environment histories, guided by execution feedback. By tracing histories of a healthy environment, its state can be inverted to an earlier one with runtime failures, from which a task can be derived by packing the buggy state and the corresponding error messages. With our method, named CLI-Gym, a total of 1,655 environment-intensive tasks are derived, being the largest collection of its kind. Moreover, with curated successful trajectories, our fine-tuned model, named LiberCoder, achieves substantial absolute improvements of +21.1% (to 46.1%) on Terminal-Bench, outperforming various strong baselines. To our knowledge, this is the first public pipeline for scalable derivation of environment-intensive tasks.", "AI": {"tldr": "\u63d0\u51faCLI-Gym\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u62df\u73af\u5883\u5386\u53f2\u6765\u5927\u89c4\u6a21\u751f\u6210\u73af\u5883\u5bc6\u96c6\u578b\u4efb\u52a1\uff0c\u5e76\u8bad\u7ec3\u51faLiberCoder\u6a21\u578b\u5728\u7ec8\u7aef\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347", "motivation": "\u4ee3\u7406\u7f16\u7801\u9700\u8981\u4e0e\u73af\u5883\u6709\u6548\u4ea4\u4e92\uff0c\u4f46\u7f3a\u4e4f\u5927\u89c4\u6a21\u7684\u73af\u5883\u5bc6\u96c6\u578b\u4efb\u52a1\u6765\u589e\u5f3a\u4ee3\u7406\u80fd\u529b\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u83b7\u53d6\u8fd9\u7c7b\u4efb\u52a1", "method": "\u57fa\u4e8eDockerfile\u4e0e\u4ee3\u7406\u4efb\u52a1\u7684\u7c7b\u6bd4\uff0c\u8ba9\u4ee3\u7406\u6a21\u62df\u63a2\u7d22\u73af\u5883\u5386\u53f2\uff0c\u901a\u8fc7\u6267\u884c\u53cd\u9988\u5f15\u5bfc\u3002\u4ece\u5065\u5eb7\u73af\u5883\u7684\u5386\u53f2\u4e2d\u56de\u6eaf\u5230\u65e9\u671f\u6709\u8fd0\u884c\u65f6\u6545\u969c\u7684\u72b6\u6001\uff0c\u5c06\u9519\u8bef\u72b6\u6001\u548c\u76f8\u5e94\u9519\u8bef\u4fe1\u606f\u6253\u5305\u751f\u6210\u4efb\u52a1", "result": "\u751f\u6210\u4e861,655\u4e2a\u73af\u5883\u5bc6\u96c6\u578b\u4efb\u52a1\uff0c\u662f\u76ee\u524d\u540c\u7c7b\u4efb\u52a1\u4e2d\u6700\u5927\u7684\u96c6\u5408\u3002\u8bad\u7ec3\u51fa\u7684LiberCoder\u6a21\u578b\u5728Terminal-Bench\u4e0a\u53d6\u5f97+21.1%\u7684\u7edd\u5bf9\u63d0\u5347\uff08\u8fbe\u523046.1%\uff09\uff0c\u4f18\u4e8e\u591a\u4e2a\u5f3a\u57fa\u7ebf", "conclusion": "\u63d0\u51fa\u4e86\u9996\u4e2a\u516c\u5f00\u7684\u53ef\u6269\u5c55\u73af\u5883\u5bc6\u96c6\u578b\u4efb\u52a1\u751f\u6210\u7ba1\u9053CLI-Gym\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u4efb\u52a1\u751f\u6210\u548c\u8f68\u8ff9\u5fae\u8c03\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7406\u5728\u7ec8\u7aef\u4efb\u52a1\u4e0a\u7684\u6027\u80fd"}}
{"id": "2602.11103", "categories": ["cs.AI", "cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.11103", "abs": "https://arxiv.org/abs/2602.11103", "authors": ["Wayne Chi", "Yixiong Fang", "Arnav Yayavaram", "Siddharth Yayavaram", "Seth Karten", "Qiuhong Anna Wei", "Runkun Chen", "Alexander Wang", "Valerie Chen", "Ameet Talwalkar", "Chris Donahue"], "title": "GameDevBench: Evaluating Agentic Capabilities Through Game Development", "comment": null, "summary": "Despite rapid progress on coding agents, progress on their multimodal counterparts has lagged behind. A key challenge is the scarcity of evaluation testbeds that combine the complexity of software development with the need for deep multimodal understanding. Game development provides such a testbed as agents must navigate large, dense codebases while manipulating intrinsically multimodal assets such as shaders, sprites, and animations within a visual game scene. We present GameDevBench, the first benchmark for evaluating agents on game development tasks. GameDevBench consists of 132 tasks derived from web and video tutorials. Tasks require significant multimodal understanding and are complex -- the average solution requires over three times the amount of lines of code and file changes compared to prior software development benchmarks. Agents still struggle with game development, with the best agent solving only 54.5% of tasks. We find a strong correlation between perceived task difficulty and multimodal complexity, with success rates dropping from 46.9% on gameplay-oriented tasks to 31.6% on 2D graphics tasks. To improve multimodal capability, we introduce two simple image and video-based feedback mechanisms for agents. Despite their simplicity, these methods consistently improve performance, with the largest change being an increase in Claude Sonnet 4.5's performance from 33.3% to 47.7%. We release GameDevBench publicly to support further research into agentic game development.", "AI": {"tldr": "\u63d0\u51fa\u4e86GameDevBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001AI\u5728\u6e38\u620f\u5f00\u53d1\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u5305\u542b132\u4e2a\u590d\u6742\u4efb\u52a1\uff0c\u5f53\u524d\u6700\u4f73AI\u4ec5\u80fd\u89e3\u51b354.5%\u7684\u4efb\u52a1", "motivation": "\u5f53\u524d\u7f16\u7801\u667a\u80fd\u4f53\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u591a\u6a21\u6001\u667a\u80fd\u4f53\u8fdb\u5c55\u6ede\u540e\uff0c\u7f3a\u4e4f\u7ed3\u5408\u8f6f\u4ef6\u5f00\u53d1\u590d\u6742\u6027\u548c\u6df1\u5ea6\u591a\u6a21\u6001\u7406\u89e3\u7684\u8bc4\u4f30\u57fa\u51c6\u3002\u6e38\u620f\u5f00\u53d1\u63d0\u4f9b\u4e86\u7406\u60f3\u7684\u6d4b\u8bd5\u573a\u666f\uff0c\u9700\u8981\u5904\u7406\u5927\u578b\u4ee3\u7801\u5e93\u548c\u591a\u79cd\u591a\u6a21\u6001\u8d44\u6e90", "method": "\u4ece\u7f51\u7edc\u548c\u89c6\u9891\u6559\u7a0b\u4e2d\u63d0\u53d6132\u4e2a\u6e38\u620f\u5f00\u53d1\u4efb\u52a1\u6784\u5efaGameDevBench\u57fa\u51c6\uff0c\u5305\u542b\u6e38\u620f\u73a9\u6cd5\u30012D\u56fe\u5f62\u7b49\u4e0d\u540c\u7c7b\u578b\u4efb\u52a1\u3002\u5f15\u5165\u4e24\u79cd\u7b80\u5355\u7684\u56fe\u50cf\u548c\u89c6\u9891\u53cd\u9988\u673a\u5236\u6765\u589e\u5f3a\u667a\u80fd\u4f53\u7684\u591a\u6a21\u6001\u80fd\u529b", "result": "\u6e38\u620f\u5f00\u53d1\u4efb\u52a1\u975e\u5e38\u590d\u6742\uff0c\u5e73\u5747\u89e3\u51b3\u65b9\u6848\u9700\u8981\u6bd4\u5148\u524d\u8f6f\u4ef6\u57fa\u51c6\u591a3\u500d\u7684\u4ee3\u7801\u884c\u6570\u548c\u6587\u4ef6\u4fee\u6539\u3002\u6700\u4f73\u667a\u80fd\u4f53\u4ec5\u80fd\u89e3\u51b354.5%\u7684\u4efb\u52a1\uff0c\u4efb\u52a1\u96be\u5ea6\u4e0e\u591a\u6a21\u6001\u590d\u6742\u6027\u5f3a\u76f8\u5173\uff08\u6e38\u620f\u73a9\u6cd5\u4efb\u52a146.9%\u6210\u529f\u7387 vs 2D\u56fe\u5f62\u4efb\u52a131.6%\uff09\u3002\u53cd\u9988\u673a\u5236\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0cClaude Sonnet 4.5\u4ece33.3%\u63d0\u5347\u523047.7%", "conclusion": "\u6e38\u620f\u5f00\u53d1\u662f\u591a\u6a21\u6001\u667a\u80fd\u4f53\u8bc4\u4f30\u7684\u91cd\u8981\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5f53\u524dAI\u4ecd\u9762\u4e34\u6311\u6218\u3002\u7b80\u5355\u7684\u591a\u6a21\u6001\u53cd\u9988\u673a\u5236\u80fd\u6709\u6548\u63d0\u5347\u6027\u80fd\uff0cGameDevBench\u7684\u53d1\u5e03\u5c06\u652f\u6301\u667a\u80fd\u4f53\u6e38\u620f\u5f00\u53d1\u7684\u8fdb\u4e00\u6b65\u7814\u7a76"}}
{"id": "2602.11136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11136", "abs": "https://arxiv.org/abs/2602.11136", "authors": ["Jiayi Zhou", "Yang Sheng", "Hantao Lou", "Yaodong Yang", "Jie Fu"], "title": "FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight", "comment": "27 pages", "summary": "As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces a fundamental dilemma: how can probabilistic systems reliably supervise other probabilistic systems without inheriting their failure modes? We argue that formal verification offers a principled escape from this dilemma, yet its adoption has been hindered by a critical bottleneck: the translation from natural language requirements to formal specifications. This paper bridges this gap by proposing , a neuro-symbolic framework that employs a bidirectional Formal-of-Thought architecture: LLMs serve as specification compilers that top-down decompose high-level human intent into atomic, verifiable constraints, then bottom-up prove compliance using Dafny specifications and Z3 Satisfiability modulo theories solving, which produces mathematical guarantees rather than probabilistic scores. We validate across three benchmarks spanning behavioral safety, multi-domain constraint adherence, and agentic upward deception detection. Experiments on 7 agent models demonstrate that achieves an average improvement of 16.6% over LLM-as-a-Judge baselines, enables weak-to-strong generalization where a 7B judge achieves over 90% accuracy detecting deception from 72B agents, and provides near-linear safety improvement through iterative refinement.", "AI": {"tldr": "\u63d0\u51faFoT\u6846\u67b6\uff0c\u4f7f\u7528\u53cc\u5411\u5f62\u5f0f\u601d\u7ef4\u67b6\u6784\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u8f6c\u5316\u4e3a\u53ef\u9a8c\u8bc1\u7684\u5f62\u5f0f\u5316\u89c4\u8303\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u63d0\u4f9b\u6570\u5b66\u4fdd\u8bc1\u800c\u975e\u6982\u7387\u8bc4\u5206", "motivation": "\u968f\u7740LLM\u667a\u80fd\u4f53\u5728\u73b0\u5b9e\u4e16\u754c\u9ad8\u98ce\u9669\u9886\u57df\u5e94\u7528\u589e\u591a\uff0c\u786e\u4fdd\u5176\u884c\u4e3a\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524d\u4e3b\u6d41\u7684LLM-as-a-Judge\u76d1\u7763\u8303\u5f0f\u9762\u4e34\u6839\u672c\u56f0\u5883\uff1a\u6982\u7387\u7cfb\u7edf\u5982\u4f55\u53ef\u9760\u76d1\u7763\u5176\u4ed6\u6982\u7387\u7cfb\u7edf\u800c\u4e0d\u7ee7\u627f\u5176\u5931\u8d25\u6a21\u5f0f\uff1f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u5230\u5f62\u5f0f\u5316\u89c4\u8303\u7684\u8f6c\u6362\u6210\u4e3a\u5173\u952e\u74f6\u9888\u3002", "method": "\u63d0\u51faFoT\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u5411\u5f62\u5f0f\u601d\u7ef4\u67b6\u6784\uff1aLLM\u4f5c\u4e3a\u89c4\u8303\u7f16\u8bd1\u5668\uff0c\u81ea\u4e0a\u800c\u4e0b\u5c06\u9ad8\u5c42\u4eba\u7c7b\u610f\u56fe\u5206\u89e3\u4e3a\u539f\u5b50\u5316\u3001\u53ef\u9a8c\u8bc1\u7684\u7ea6\u675f\uff0c\u7136\u540e\u81ea\u4e0b\u800c\u4e0a\u4f7f\u7528Dafny\u89c4\u8303\u548cZ3\u53ef\u6ee1\u8db3\u6027\u6a21\u7406\u8bba\u6c42\u89e3\u5668\u8bc1\u660e\u5408\u89c4\u6027\uff0c\u4ea7\u751f\u6570\u5b66\u4fdd\u8bc1\u800c\u975e\u6982\u7387\u8bc4\u5206\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08\u884c\u4e3a\u5b89\u5168\u3001\u591a\u9886\u57df\u7ea6\u675f\u9075\u5b88\u3001\u667a\u80fd\u4f53\u5411\u4e0a\u6b3a\u9a97\u68c0\u6d4b\uff09\u4e0a\u9a8c\u8bc1\uff0c\u5b9e\u9a8c\u6d89\u53ca7\u4e2a\u667a\u80fd\u4f53\u6a21\u578b\u3002FoT\u76f8\u6bd4LLM-as-a-Judge\u57fa\u7ebf\u5e73\u5747\u63d0\u534716.6%\uff0c\u5b9e\u73b0\u5f31\u5230\u5f3a\u6cdb\u5316\uff087B\u6a21\u578b\u68c0\u6d4b72B\u667a\u80fd\u4f53\u6b3a\u9a97\u51c6\u786e\u7387\u8d8590%\uff09\uff0c\u901a\u8fc7\u8fed\u4ee3\u7ec6\u5316\u63d0\u4f9b\u63a5\u8fd1\u7ebf\u6027\u7684\u5b89\u5168\u6539\u8fdb\u3002", "conclusion": "FoT\u6846\u67b6\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u89e3\u51b3\u4e86LLM\u667a\u80fd\u4f53\u76d1\u7763\u7684\u6839\u672c\u56f0\u5883\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u8f6c\u5316\u4e3a\u53ef\u9a8c\u8bc1\u7684\u5f62\u5f0f\u5316\u89c4\u8303\uff0c\u4e3a\u667a\u80fd\u4f53\u884c\u4e3a\u5b89\u5168\u63d0\u4f9b\u6570\u5b66\u4fdd\u8bc1\uff0c\u663e\u8457\u4f18\u4e8e\u6982\u7387\u8bc4\u5206\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5f31\u5230\u5f3a\u6cdb\u5316\u7684\u6f5c\u529b\u3002"}}
