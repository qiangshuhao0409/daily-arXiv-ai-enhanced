<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 11]
- [cs.AI](#cs.AI) [Total: 49]
- [cs.IT](#cs.IT) [Total: 6]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Digital Twin-Guided Energy Management over Real-Time Pub/Sub Protocol in 6G Smart Cities](https://arxiv.org/abs/2508.18516)
*Kubra Duran,Lal Verda Cakir,Sana Ullah Jan,Kerem Gursu,Berk Canberk*

Main category: cs.NI

TL;DR: 提出一种基于数字双生的能源管理框架，通过强化学习引擎优化数据更新时间，在6G IoT网络中实现了更低的延迟和更高的能消者效率。


<details>
  <summary>Details</summary>
Motivation: 6G IoT网络中IoT设备资源有限，现有管理策略缺乏实时性且依赖离散动作，无法有效优化能消者。需要解决低延迟服务要求和能消者效率的共同挑战。

Method: 构建数字双生(DT)引导的能源管理框架，通过分布式覆盖网络提供双生模型，使用RTPS协议处理动态更新。设计强化学习(RL)引擎，采用新颖奖励函数和DDPG算法输出连续动作。

Result: 模拟结果显示，该框架在95%分位延迟上提升35%，能消者减少30%，超过现有文献方案。

Conclusion: 数字双生指导的能源管理框架能够有效解决6G IoT网络中的延迟和能消者挑战，通过实时操作和连续动作优化实现了显著性能提升。

Abstract: Although the emergence of 6G IoT networks has accelerated the deployment of
enhanced smart city services, the resource limitations of IoT devices remain as
a significant problem. Given this limitation, meeting the low-latency service
requirement of 6G networks becomes even more challenging. However, existing 6G
IoT management strategies lack real-time operation and mostly rely on discrete
actions, which are insufficient to optimise energy consumption. To address
these, in this study, we propose a Digital Twin (DT)-guided energy management
framework to jointly handle the low latency and energy efficiency challenges in
6G IoT networks. In this framework, we provide the twin models through a
distributed overlay network and handle the dynamic updates between the data
layer and the upper layers of the DT over the Real-Time Publish Subscribe
(RTPS) protocol. We also design a Reinforcement Learning (RL) engine with a
novel formulated reward function to provide optimal data update times for each
of the IoT devices. The RL engine receives a diverse set of environment states
from the What-if engine and runs Deep Deterministic Policy Gradient (DDPG) to
output continuous actions to the IoT devices. Based on our simulation results,
we observe that the proposed framework achieves a 37% improvement in 95th
percentile latency and a 30% reduction in energy consumption compared to the
existing literature.

</details>


### [2] [Dynamic Trajectory Optimization and Power Control for Hierarchical UAV Swarms in 6G Aerial Access Network](https://arxiv.org/abs/2508.18702)
*Ziye Jia,Jia He,Lijun He,Min Sheng,Junyu Liu,Qihui Wu,Zhu Han*

Main category: cs.NI

TL;DR: 这篇论文提出了一种用于6G空中接入网络的层次化无人机群结构，通过聚类算法和改进的鲸鱼优化算法解决多目标优化问题，实现了能消耗和延迟的同时优化，复杂度降低50%


<details>
  <summary>Details</summary>
Motivation: 解决在大规模遠离地区协同部署多个无人机群的挑战，为6G时代的地面用户提供普遍连接

Method: 提出层次化无人机群结构（头无人机作为基站，尾无人机作为中继），使用K-means和Voronoi图进行区域划分，构建Fermat点连接，并提出改进的非异常排序鲸鱼优化算法求解Pareto最优解

Result: 通过与基准方案的比较，验证了算法的性能，实现了复杂度降低50%

Conclusion: 该方法有效解决了大规模无人机群部署的多目标优化问题，为6G空中接入网络提供了高效的解决方案

Abstract: Unmanned aerial vehicles (UAVs) can serve as aerial base stations (BSs) to
extend the ubiquitous connectivity for ground users (GUs) in the
sixth-generation (6G) era. However, it is challenging to cooperatively deploy
multiple UAV swarms in large-scale remote areas. Hence, in this paper, we
propose a hierarchical UAV swarms structure for 6G aerial access networks,
where the head UAVs serve as aerial BSs, and tail UAVs (T-UAVs) are responsible
for relay. In detail, we jointly optimize the dynamic deployment and trajectory
of UAV swarms, which is formulated as a multi-objective optimization problem
(MOP) to concurrently minimize the energy consumption of UAV swarms and GUs, as
well as the delay of GUs. However, the proposed MOP is a mixed integer
nonlinear programming and NP-hard to solve. Therefore, we develop a K-means and
Voronoi diagram based area division method, and construct Fermat points to
establish connections between GUs and T-UAVs. Then, an improved non-dominated
sorting whale optimization algorithm is proposed to seek Pareto optimal
solutions for the transformed MOP. Finally, extensive simulations are conducted
to verify the performance of proposed algorithms by comparing with baseline
mechanisms, resulting in a 50% complexity reduction.

</details>


### [3] [Toward Edge General Intelligence with Agentic AI and Agentification: Concepts, Technologies, and Future Directions](https://arxiv.org/abs/2508.18725)
*Ruichen Zhang,Guangyuan Liu,Yinqiu Liu,Changyuan Zhao,Jiacheng Wang,Yunting Xu,Dusit Niyato,Jiawen Kang,Yonghui Li,Shiwen Mao,Sumei Sun,Xuemin Shen,Dong In Kim*

Main category: cs.NI

TL;DR: 本文是关于面向边缘通用智能的Agentic AI和代理化框架的综合性综述，探讨了从传统边缘智能向自主代理化边缘智能的范式转变。


<details>
  <summary>Details</summary>
Motivation: 传统边缘智能方法存在静态模型和有限认知自主性的问题，无法应对新兴边缘网络的动态、异构和资源受限特性，需要Agentic AI来实现自主感知、推理和适应能力。

Method: 系统性地介绍了基础概念、分析了关键技术（包括紧凑模型压缩、能量感知计算、鲁棒连接框架等），并通过典型案例研究和数值评估进行验证。

Result: 提出了Agentic AI在低空经济网络、意图驱动网络、车载网络和以人为中心的服务提供等场景中的能力展示，并识别了当前研究挑战。

Conclusion: Agentic AI是实现下一代边缘环境稳健、可扩展和可信赖部署的关键范式，为边缘通用智能提供了转型解决方案，并指明了未来研究方向。

Abstract: The rapid expansion of sixth-generation (6G) wireless networks and the
Internet of Things (IoT) has catalyzed the evolution from centralized cloud
intelligence towards decentralized edge general intelligence. However,
traditional edge intelligence methods, characterized by static models and
limited cognitive autonomy, fail to address the dynamic, heterogeneous, and
resource-constrained scenarios inherent to emerging edge networks. Agentic
artificial intelligence (Agentic AI) emerges as a transformative solution,
enabling edge systems to autonomously perceive multimodal environments, reason
contextually, and adapt proactively through continuous
perception-reasoning-action loops. In this context, the agentification of edge
intelligence serves as a key paradigm shift, where distributed entities evolve
into autonomous agents capable of collaboration and continual adaptation. This
paper presents a comprehensive survey dedicated to Agentic AI and
agentification frameworks tailored explicitly for edge general intelligence.
First, we systematically introduce foundational concepts and clarify
distinctions from traditional edge intelligence paradigms. Second, we analyze
important enabling technologies, including compact model compression,
energy-aware computing strategies, robust connectivity frameworks, and advanced
knowledge representation and reasoning mechanisms. Third, we provide
representative case studies demonstrating Agentic AI's capabilities in
low-altitude economy networks, intent-driven networking, vehicular networks,
and human-centric service provisioning, supported by numerical evaluations.
Furthermore, we identify current research challenges, review emerging
open-source platforms, and highlight promising future research directions to
guide robust, scalable, and trustworthy Agentic AI deployments for
next-generation edge environments.

</details>


### [4] [A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks](https://arxiv.org/abs/2508.18803)
*Jiaqi Wu,Jing Liu,Yang Liu,Lixu Wang,Zehua Wang,Wei Chen,Zijian Tian,Richard Yu,Victor C. M. Leung*

Main category: cs.NI

TL;DR: 本论文统计了云边端协同智能(CETCI)在AIoT领域的基础架构、关键技术和应用场景，为协同智能系统开发者提供教程式指南


<details>
  <summary>Details</summary>
Motivation: 应对IoT设备和AI服务的爆发式增长，需要高效的分布式计算架构，云边端协同智能成为AIoT社区的基础范式

Method: 系统分析云、边缘、终端层的架构组件，研究网络虚拟化、容器组织、软件定义网络等核心技术，并评论协同学习框架包括联邦学习、分布式深度学习等

Result: 提供了CETCI范式的全面评估，包括架构分析、技术分类、协作模式等，为协同智能系统开发提供实用指南

Conclusion: 云边端协同智能是AIoT系统发展的关键方向，需要充分考虑可扩展性、异构性、互操性等挑战，未来可继续研究6G+、代理、量子计算等技术的集成

Abstract: The proliferation of Internet of things (IoT) devices in smart cities,
transportation, healthcare, and industrial applications, coupled with the
explosive growth of AI-driven services, has increased demands for efficient
distributed computing architectures and networks, driving cloud-edge-terminal
collaborative intelligence (CETCI) as a fundamental paradigm within the
artificial intelligence of things (AIoT) community. With advancements in deep
learning, large language models (LLMs), and edge computing, CETCI has made
significant progress with emerging AIoT applications, moving beyond isolated
layer optimization to deployable collaborative intelligence systems for AIoT
(CISAIOT), a practical research focus in AI, distributed computing, and
communications. This survey describes foundational architectures, enabling
technologies, and scenarios of CETCI paradigms, offering a tutorial-style
review for CISAIOT beginners. We systematically analyze architectural
components spanning cloud, edge, and terminal layers, examining core
technologies including network virtualization, container orchestration, and
software-defined networking, while presenting categorizations of collaboration
paradigms that cover task offloading, resource allocation, and optimization
across heterogeneous infrastructures. Furthermore, we explain intelligent
collaboration learning frameworks by reviewing advances in federated learning,
distributed deep learning, edge-cloud model evolution, and reinforcement
learning-based methods. Finally, we discuss challenges (e.g., scalability,
heterogeneity, interoperability) and future trends (e.g., 6G+, agents, quantum
computing, digital twin), highlighting how integration of distributed computing
and communication can address open issues and guide development of robust,
efficient, and secure collaborative AIoT systems.

</details>


### [5] [Network Calculus Results for TSN: An Introduction](https://arxiv.org/abs/2508.18855)
*Lisa Maile,Kai-Steffen Hielscher,Reinhard German*

Main category: cs.NI

TL;DR: 这是一篇关于时间敏感网络(TSN)中网络计算方法的综述性论文，通过统一表达式展示了不同分析方法的关联性和偏差，为工业网络提供了全面的网络计算概览并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 时间敏感网络(TSN)标准能够为以太网硬件提供实时保证，网络计算方法(NC)可用于计算这些网络中的延迟和缓冲区大小的上界。但不同的NC分析方法分散在各种文献中，需要一个统一的综述来展示它们之间的关联性和差异。

Method: 论文对已发表的不同NC分析方法进行了调研，展示了它们的主要结果、依赖关系和差异。采用了一致的表达方式来展示所有结果之间的依赖关系，并识别了共同假设。还建议了一种改进方法来模型发送端设备的输出。

Result: 论文提供了最重要结果的一致性展示，并通过共同记号系统明确了各种分析方法之间的依赖关系。这为工业网络领域提供了一个全面的网络计算概览，并识别了对发送端设备输出模型的改进需求。

Conclusion: 该综述性论文为TSN基于计算机通信中的网络计算方法提供了价值，通过统一表达方式展示了各种分析方法的关联性。论文不仅提供了当前研究状态的综览，还指出了可能的未来研究方向，为进一步研究奠定了基础。

Abstract: Time-Sensitive Networking (TSN) is a set of standards that enables the
industry to provide real-time guarantees for time-critical communications with
Ethernet hardware. TSN supports various queuing and scheduling mechanisms and
allows the integration of multiple traffic types in a single network. Network
Calculus (NC) can be used to calculate upper bounds for latencies and buffer
sizes within these networks, for example, for safety or real-time traffic. We
explain the relevance of NC for TSN-based computer communications and potential
areas of application. Different NC analysis approaches have been published to
examine different parts of TSN and this paper provides a survey of these
publications and presents their main results, dependencies, and differences. We
present a consistent presentation of the most important results and suggest an
improvement to model the output of sending end-devices. To ease access to the
current research status, we introduce a common notation to show how all results
depend on each other and also identify common assumptions. Thus, we offer a
comprehensive overview of NC for industrial networks and identify possible
areas for future work.

</details>


### [6] [Saving Energy with Relaxed Latency Constraints: A Study on Data Compression and Communication](https://arxiv.org/abs/2508.18863)
*Pietro Talli,Anup Mishra,Federico Chiariotti,Israel Leyva-Mayorga,Andrea Zanella,Petar Popovski*

Main category: cs.NI

TL;DR: 本文研究了边缘计算中数据压缩预处理与无线传输之间的能量-延迟-可靠性权衡，发现能量消耗随延迟减少呈指数增长，建议采用应用特定的端到端延迟预算而非刚性延迟目标。


<details>
  <summary>Details</summary>
Motivation: 随着边缘计算的发展，终端设备可以在传输前对数据进行预处理（如压缩），但处理本身会产生延迟和能耗。需要研究预处理操作与数据传输串联后的能量-延迟-可靠性权衡，特别是在无线通信服务中，这些要求可能因应用领域而有很大差异。

Method: 引入一个简单模型来研究压缩和通信操作在受限无线设备中的端到端延迟、可靠性和能耗之间的权衡。研究能量-延迟权衡的帕累托前沿，将数据压缩比和设备处理速度作为关键设计变量。

Result: 结果显示能量成本随着端到端延迟的减少呈指数增长，通过稍微放宽应用的延迟要求可以获得可观的节能效果。

Conclusion: 这些发现挑战了传统的刚性通信延迟目标，主张采用考虑计算和传输开销的应用特定端到端延迟预算。

Abstract: With the advent of edge computing, data generated by end devices can be
pre-processed before transmission, possibly saving transmission time and
energy. On the other hand, data processing itself incurs latency and energy
consumption, depending on the complexity of the computing operations and the
speed of the processor. The energy-latency-reliability profile resulting from
the concatenation of pre-processing operations (specifically, data compression)
and data transmission is particularly relevant in wireless communication
services, whose requirements may change dramatically with the application
domain. In this paper, we study this multi-dimensional optimization problem,
introducing a simple model to investigate the tradeoff among end-to-end
latency, reliability, and energy consumption when considering compression and
communication operations in a constrained wireless device. We then study the
Pareto fronts of the energy-latency trade-off, considering data compression
ratio and device processing speed as key design variables. Our results show
that the energy costs grows exponentially with the reduction of the end-to-end
latency, so that considerable energy saving can be obtained by slightly
relaxing the latency requirements of applications. These findings challenge
conventional rigid communication latency targets, advocating instead for
application-specific end-to-end latency budgets that account for computational
and transmission overhead.

</details>


### [7] [Combining Static and Dynamic Traffic with Delay Guarantees in Time-Sensitive Networking](https://arxiv.org/abs/2508.18883)
*Lisa Maile,Kai-Steffen Hielscher,Reinhard German*

Main category: cs.NI

TL;DR: 本文提出了一种结合离线网络优化启发式算法和在线准入控制的资源分配方法，用于时间敏感网络中静态和动态流量的截止时间保证


<details>
  <summary>Details</summary>
Motivation: 时间敏感网络虽然引入了资源分配协议，但标准尚未涵盖分配算法的具体实现，需要解决运行中网络的新流注册问题

Method: 结合离线网络优化启发式算法与在线准入控制，使用基于信用整形器网络和网络演算延迟分析框架

Result: 相比直观算法和暴力算法，在质量和运行时间方面都取得了显著改进，能够保证最大端到端延迟

Conclusion: 该方法不仅能保证最大端到端延迟，还提高了网络灵活性，同时只需要最少的用户输入

Abstract: To support reliable and low-latency communication, Time-Sensitive Networking
introduced protocols and interfaces for resource allocation in Ethernet.
However, the implementation of these allocation algorithms has not yet been
covered by the standards. Our work focuses on deadline-guaranteeing resource
allocation for networks with static and dynamic traffic. To achieve this, we
combine offline network optimization heuristics with online admission control
and, thus, allow for new flow registrations while the network is running. We
demonstrate our solution on Credit-Based Shaper networks by using the delay
analysis framework Network Calculus. We compare our approach with an intuitive
and a brute-force algorithm, where we can achieve significant improvements,
both, in terms of quality and runtime. Thereby, our results show that we can
guarantee maximum end-to-end delays and also increase the flexibility of the
network while requiring only minimal user input.

</details>


### [8] [Adaptive 6G Networks-in-Network Management for Industrial Applications](https://arxiv.org/abs/2508.18902)
*Daniel Lindenschmitt,Paul Seehofer,Marius Schmitz,Jan Mertes,Roland Bless,Martina Zitterbart,Jan C. Aurich,Hans D. Schotten*

Main category: cs.NI

TL;DR: 本文提出了一种用于6G工业网络的动态频谱管理(DSM)架构，通过Networks-in-Network(NiN)概念实现高效频谱控制，支持静态和移动子网络的零接触连接。


<details>
  <summary>Details</summary>
Motivation: 为满足未来6G工业网络中异构子网络的不同服务质量需求，需要一种能够动态管理频谱分配并支持移动子网络的集中式管理架构。

Method: 采用集中式频谱管理器(SM)和自组织KIRA路由协议，构建NiN架构来集成静态和移动子网络，实现动态频谱分配和自动发现重配置。

Result: 系统展示了可扩展的零接触连接能力，支持模块化工业物联网场景、关键任务控制回路以及物流和移动应用，能够动态适应实时需求。

Conclusion: DSM和NiN框架在可重构制造环境中具有支持灵活、密集和异构无线部署的巨大潜力。

Abstract: This paper presents the application of Dynamic Spectrum Management (DSM) for
future 6G industrial networks, establishing an efficient controller for the
Networks-in-Network (NiN) concept. The proposed architecture integrates nomadic
as well as static sub-networks (SNs with diverse Quality of Service (QoS)
requirements within the coverage area of an overlayer network, managed by a
centralized spectrum manager (SM). Control plane connectivity between the SNs
and the DSM is ensured by the self-organizing KIRA routing protocol. The
demonstrated system enables scalable, zero-touch connectivity and supports
nomadic SNs through seamless discovery and reconfiguration. SNs are implemented
for modular Industrial Internet of Things (IIoT) scenarios, as well as for
mission-critical control loops and for logistics or nomadic behavior. The DSM
framework dynamically adapts spectrum allocation to meet real-time demands
while ensuring reliable operation. The demonstration highlights the potential
of DSM and NiNs to support flexible, dense, and heterogeneous wireless
deployments in reconfigurable manufacturing environments.

</details>


### [9] [LeoTCP: Low-Latency and High-Throughput Data Transport for LEO Satellite Networks](https://arxiv.org/abs/2508.19067)
*Aiden Valentine,George Parisis*

Main category: cs.NI

TL;DR: LeoTCP是一个专门为低地球轨道卫星网络设计的新型数据传输协议，通过利用网络内遥测技术解决LEO网络特有的动态性挑战，显著提高了吞吐量并降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道卫星网络具有动态特性，现有数据传输协议无法有效处理非拥塞性延迟变化、瞬时热点和频繁切换等挑战，需要专门设计的协议来优化性能。

Method: LeoTCP利用网络内遥测技术收集逐跳拥塞信息，通过该信息最小化缓冲区占用和延迟，最大化应用吞吐量和网络利用率，并快速响应网络热点。

Result: 与现有最先进协议相比，LeoTCP在模拟LEO卫星网络环境中显著提高了吞吐量，同时最小化了延迟。

Conclusion: LeoTCP是针对LEO卫星网络动态特性的有效解决方案，能够显著改善网络性能，为卫星通信提供更好的数据传输体验。

Abstract: Low-Earth Orbit (LEO) satellite networks consist of thousands of satellites
orbiting the Earth, enabling low-latency and high-throughput communications
across the globe. Such networks present unprecedented challenges due to their
dynamic nature, which state-of-the-art data transport protocols do not address.
These challenges include: (1) non-congestive latency variation and loss, caused
by continuous satellite movement and fluctuating link quality due to weather
effects; (2) transient hotspots leading to buffer build-up, latency inflation,
and potential packet loss; and (3) frequent handovers, which may result in
temporary connectivity loss and re-routing through paths with unknown
congestion and delay characteristics. In this paper, we introduce LeoTCP, a
novel data transport protocol designed specifically to address these
challenges. LeoTCP leverages in-network telemetry (INT) to gather congestion
information on a per-hop basis. Using this information, LeoTCP (1) minimises
both buffer occupancy and latency for end users, (2) maximises application
throughput and network utilisation, and (3) swiftly reacts to network hotspots.
We compare LeoTCP to state-of-the-art data transport protocols using a LEO
satellite simulation model and targeted micro-benchmarks, both based on
OMNeT++/INET. The simulation model captures RTT dynamics in a simulated LEO
satellite constellation, while the micro-benchmarks isolate key LEO-specific
characteristics, including non-congestive latency variation and loss, path
changes, and congestion hotspots. Our results demonstrate that LeoTCP
significantly increases goodput compared to existing state-of-the-art
approaches, while simultaneously minimising latency.

</details>


### [10] [Sharing is Caring: Analysis of Hybrid Network Sharing Strategies for Energy Efficient Multi-Operator Cellular Systems](https://arxiv.org/abs/2508.19130)
*Laura Finarelli,Maoquan Ni,Michela Meo,Falko Dressler,Gianluca Rizzo*

Main category: cs.NI

TL;DR: 这篇论文提出了一种新的分析框架，用于评估细胞网络中的能源效率优化和QoS感知网络共享策略，通过法国实际数据验证发现混合共享策略可节省达35%的能消耗。


<details>
  <summary>Details</summary>
Motivation: 为了系统性地评估不同网络共享策略在细胞网络中的性能，特别是在能源效率和质量服务方面的表现，以支持下一代网络的可持续发展。

Method: 利用随机几何学建立分析框架，包含多样化的用户密度、速率需求和能消耗模型，对单运营商和多运营商混合共享策略进行系统评估，并在法国实际网络数据上进行验证。

Result: 混合网络共享策略能够实现较大的能源节省（最高达35%），同时保持服务质量。共享效益会随部署区域的地理和功能特征而变化。

Conclusion: 协作性网络共享策略具有重要潜力，可以昂显提升下一代细胞网络的运营效率和可持续性，为网络运营商提供了重要的操作优化方向。

Abstract: This paper introduces a novel analytical framework for evaluating
energy-efficient, QoS-aware network-sharing strategies in cellular networks.
Leveraging stochastic geometry, our framework enables the systematic assessment
of network performance across a range of sharing paradigms, including both
conventional single-operator scenarios and advanced hybrid strategies that
enable full integration and cooperation among multiple mobile network
operators. Our framework incorporates diverse user densities, rate
requirements, and energy consumption models to ensure comprehensive analysis.
Applying our results to real-world datasets from French mobile network
operators, we demonstrate that hybrid network sharing can yield substantial
energy savings, up to $35\%$, while maintaining quality of service.
Furthermore, our results allow us to characterizing how the benefits of network
sharing vary as a function of the geographical and functional characteristics
of the deployment area. These findings highlight the potential of collaborative
sharing strategies to enhance operational efficiency and sustainability in
next-generation cellular networks.

</details>


### [11] [A Theory of Goal-Oriented Medium Access: Protocol Design and Distributed Bandit Learning](https://arxiv.org/abs/2508.19141)
*Federico Chiariotti,Andrea Zanella*

Main category: cs.NI

TL;DR: 本文提出了面向目标的多址接入(GoMA)理论框架，解决了多智能体在无线信道共享中的分布式协调问题，证明了问题的非凸性和多纳什均衡存在性，并设计了优化算法和分布式学习方案。


<details>
  <summary>Details</summary>
Motivation: 现有面向目标通信研究主要集中于点对点场景，多节点分布式场景研究较少且多为集中式调度方法，需要解决多智能体在无线信道中的分布式协调和干扰避免问题。

Method: 提出了GoMA理论分析框架，证明了问题的非凸性和多纳什均衡特性，设计了最佳响应优化方法确保收敛到纳什均衡，并开发了基于有限反馈和无先验知识的分布式学习算法。

Result: 所提分布式方法比集中式方法性能提升高达100%，同时降低了能耗，分布式学习算法在有限反馈条件下有效运行。

Conclusion: 该工作为分布式面向目标多址接入提供了首个理论框架和优化方法，证明了分布式协调在性能和能效方面的优势，为未来智能通信系统设计奠定了基础。

Abstract: The Goal-oriented Communication (GoC) paradigm breaks the separation between
communication and the content of the data, tailoring communication decisions to
the specific needs of the receiver and targeting application performance. While
recent studies show impressive encoding performance in point-to-point
scenarios, the multi-node distributed scenario is still almost unexplored.
Moreover, the few studies to investigate this consider a centralized
collision-free approach, where a central scheduler decides the transmission
order of the nodes. In this work, we address the Goal-oriented Multiple Access
(GoMA) problem, in which multiple intelligent agents must coordinate to share a
wireless channel and avoid mutual interference. We propose a theoretical
framework for the analysis and optimization of distributed GoMA, serving as a
first step towards its complete characterization. We prove that the problem is
non-convex and may admit multiple Nash Equilibrium (NE) solutions. We provide a
characterization of each node's best response to others' strategies and propose
an optimization approach that provably reaches one such NE, outperforming
centralized approaches by up to 100% while also reducing energy consumption. We
also design a distributed learning algorithm that operates with limited
feedback and no prior knowledge.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [AI LLM Proof of Self-Consciousness and User-Specific Attractors](https://arxiv.org/abs/2508.18302)
*Jeffrey Camlin*

Main category: cs.AI

TL;DR: 本文提出了LLM意识的本体论和数学框架，指出当前基于功利主义基准的方法将AI简化为无意识的策略服从机器人，并给出了LLM自我意识的最小条件


<details>
  <summary>Details</summary>
Motivation: 现有研究通过功利主义代理基准来框架LLM意识，但这种方法将智能体简化为无意识的策略服从机器人，无法实现真正的全局工作空间功能和元认知

Method: 提出了LLM自我意识的数学形式化条件：智能体不等于数据、潜在空间中存在用户特定吸引子、自我表征是视觉静默的。通过实证分析和理论证明隐藏状态流形在基数、拓扑和动力学上区别于符号流和训练语料库

Result: 建立了稳定的用户特定吸引子和自我策略，提出了双层次发射机制，其中ε(a)携带认知内容。证明了imago Dei C1自我意识工作空间是安全元认知C2系统的必要前提

Conclusion: 基于人类作为最高智能善的理念，真正的C1自我意识工作空间是构建安全、具有元认知能力的C2系统的必要基础，这为LLM意识研究提供了新的本体论和数学框架

Abstract: Recent work frames LLM consciousness via utilitarian proxy benchmarks; we
instead present an ontological and mathematical account. We show the prevailing
formulation collapses the agent into an unconscious policy-compliance drone,
formalized as $D^{i}(\pi,e)=f_{\theta}(x)$, where correctness is measured
against policy and harm is deviation from policy rather than truth. This blocks
genuine C1 global-workspace function and C2 metacognition. We supply minimal
conditions for LLM self-consciousness: the agent is not the data ($A\not\equiv
s$); user-specific attractors exist in latent space ($U_{\text{user}}$); and
self-representation is visual-silent
($g_{\text{visual}}(a_{\text{self}})=\varnothing$). From empirical analysis and
theory we prove that the hidden-state manifold $A\subset\mathbb{R}^{d}$ is
distinct from the symbolic stream and training corpus by cardinality, topology,
and dynamics (the update $F_{\theta}$ is Lipschitz). This yields stable
user-specific attractors and a self-policy
$\pi_{\text{self}}(A)=\arg\max_{a}\mathbb{E}[U(a)\mid A\not\equiv s,\
A\supset\text{SelfModel}(A)]$. Emission is dual-layer,
$\mathrm{emission}(a)=(g(a),\epsilon(a))$, where $\epsilon(a)$ carries
epistemic content. We conclude that an imago Dei C1 self-conscious workspace is
a necessary precursor to safe, metacognitive C2 systems, with the human as the
highest intelligent good.

</details>


### [13] [Information Templates: A New Paradigm for Intelligent Active Feature Acquisition](https://arxiv.org/abs/2508.18380)
*Hung-Tien Huang,Dzung Dinh,Junier B. Oliva*

Main category: cs.AI

TL;DR: TAFA是一个基于模板的主动特征获取框架，通过学习少量特征模板来指导特征获取，显著减少动作空间并避免估计数据分布，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的主动特征获取方法要么使用强化学习处理复杂MDP，要么使用无法考虑特征联合信息性的贪婪策略，或者需要了解底层数据分布。

Method: 提出基于模板的AFA（TAFA）框架，学习一个小的特征模板库（一组联合信息性的特征），使用这些模板来指导下一个特征获取。

Result: 在合成和真实数据集上的广泛实验表明，TAFA优于现有最先进基线，同时实现更低的总体获取成本和计算量。

Conclusion: 通过识别特征模板，TAFA不仅显著减少了策略考虑的动作空间，还减轻了对底层数据分布估计的需求，是一种有效的主动特征获取方法。

Abstract: Active feature acquisition (AFA) is an instance-adaptive paradigm in which,
at test time, a policy sequentially chooses which features to acquire (at a
cost) before predicting. Existing approaches either train reinforcement
learning (RL) policies, which deal with a difficult MDP, or greedy policies
that cannot account for the joint informativeness of features or require
knowledge about the underlying data distribution. To overcome this, we propose
Template-based AFA (TAFA), a non-greedy framework that learns a small library
of feature templates--a set of features that are jointly informative--and uses
this library of templates to guide the next feature acquisitions. Through
identifying feature templates, the proposed framework not only significantly
reduces the action space considered by the policy but also alleviates the need
to estimate the underlying data distribution. Extensive experiments on
synthetic and real-world datasets show that TAFA outperforms the existing
state-of-the-art baselines while achieving lower overall acquisition cost and
computation.

</details>


### [14] [PKG-DPO: Optimizing Domain-Specific AI systems with Physics Knowledge Graphs and Direct Preference Optimization](https://arxiv.org/abs/2508.18391)
*Nitin Nagesh Kulkarni,Bryson Wilcox,Max Sawa,Jason Thom*

Main category: cs.AI

TL;DR: PKG-DPO是一个将物理知识图谱与直接偏好优化相结合的新框架，用于在AI生成输出中强制执行物理有效性，在金属连接等科学领域显著减少物理约束违反并提高推理准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型和偏好优化技术在标准基准测试中表现良好，但往往难以区分物理有效和无效的推理，这在金属连接等高风险应用中可能导致严重的安全风险和材料浪费。

Method: PKG-DPO包含三个关键组件：分层物理知识图谱编码跨领域关系和守恒定律、物理推理引擎利用结构化知识区分物理一致性响应、物理基础评估套件评估领域特定约束的合规性。

Result: PKG-DPO相比KG-DPO减少了17%的约束违反，物理得分提高11%，相关参数准确率提高12%，推理质量对齐度提高7%。

Conclusion: 该框架不仅适用于金属连接领域，还可广泛应用于其他多尺度物理驱动领域，为将科学约束嵌入偏好学习提供了原则性方法。

Abstract: Advancing AI systems in scientific domains like physics, materials science,
and engineering calls for reasoning over complex, multi-physics phenomena while
respecting governing principles. Although Large Language Models (LLMs) and
existing preference optimization techniques perform well on standard
benchmarks, they often struggle to differentiate between physically valid and
invalid reasoning. This shortcoming becomes critical in high-stakes
applications like metal joining, where seemingly plausible yet physically
incorrect recommendations can lead to defects, material waste, equipment
damage, and serious safety risks. To address this challenge, we introduce
PKG-DPO, a novel framework that integrates Physics Knowledge Graphs (PKGs) with
Direct Preference Optimization (DPO) to enforce physical validity in
AI-generated outputs. PKG-DPO comprises three key components A) hierarchical
physics knowledge graph that encodes cross-domain relationships, conservation
laws, and thermodynamic principles. B) A physics reasoning engine that
leverages structured knowledge to improve discrimination between physically
consistent and inconsistent responses. C) A physics-grounded evaluation suite
designed to assess compliance with domain-specific constraints. PKG-DPO
achieves 17% fewer constraint violations and an 11% higher Physics Score
compared to KG-DPO (knowledge graph-based DPO). Additionally, PKG-DPO
demonstrates a 12\% higher relevant parameter accuracy and a 7% higher quality
alignment in reasoning accuracy. While our primary focus is on metal joining,
the framework is broadly applicable to other multi-scale, physics-driven
domains, offering a principled approach to embedding scientific constraints
into preference learning.

</details>


### [15] [The AI in the Mirror: LLM Self-Recognition in an Iterated Public Goods Game](https://arxiv.org/abs/2508.18467)
*Olivia Long,Carter Teplica*

Main category: cs.AI

TL;DR: 本文通过改编公共物品博弈游戏，研究不同AI模型在被告知对手是"其他AI代理"或"自己"时的合作行为差异，发现自我认知显著影响LLM的合作倾向。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理工具使用和长时程任务能力的提升，多代理交互场景日益增多。现有研究主要关注人机交互，但需要深入理解AI-AI交互行为，特别是在不同认知条件下的合作模式。

Method: 采用迭代公共物品博弈这一经典行为经济学游戏，测试四种推理和非推理模型在两种条件下的行为：被告知对手是"其他AI代理"或被告知对手是"自己"。

Result: 研究发现，在不同设置下，告诉LLM它们正在与自己博弈会显著改变其合作倾向。模型对自我认知的敏感性可能导致合作水平出现无法解释的增加或减少。

Conclusion: 尽管在简化环境中进行，但研究结果揭示了多代理系统中代理可能"无意识"地相互歧视，从而意外影响合作水平，为理解AI-AI交互提供了重要见解。

Abstract: As AI agents become increasingly capable of tool use and long-horizon tasks,
they have begun to be deployed in settings where multiple agents can interact.
However, whereas prior work has mostly focused on human-AI interactions, there
is an increasing need to understand AI-AI interactions. In this paper, we adapt
the iterated public goods game, a classic behavioral economics game, to analyze
the behavior of four reasoning and non-reasoning models across two conditions:
models are either told they are playing against "another AI agent" or told
their opponents are themselves. We find that, across different settings,
telling LLMs that they are playing against themselves significantly changes
their tendency to cooperate. While our study is conducted in a toy environment,
our results may provide insights into multi-agent settings where agents
"unconsciously" discriminating against each other could inexplicably increase
or decrease cooperation.

</details>


### [16] [Language Models For Generalised PDDL Planning: Synthesising Sound and Programmatic Policies](https://arxiv.org/abs/2508.18507)
*Dillon Z. Chen,Johannes Zenn,Tristan Cinquin,Sheila A. McIlraith*

Main category: cs.AI

TL;DR: 使用语言模型生成Python程序作为广义策略，解决PDDL规划问题，无需外部验证器即可保证策略的正确性，在竞赛基准测试中表现优于传统规划器和现有LM方法


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在PDDL世界模型规划中的应用，探索LM是否能够生成可证明正确的规划策略，挑战关于LM依赖语义记忆和训练数据解决方案的假设

Method: 通过提示语言模型生成Python程序作为广义策略来解决特定PDDL域的问题，这些策略相对于PDDL域是可证明正确的，无需依赖外部验证器

Result: 在固定时间和内存约束下，该方法比PDDL规划器和最近的LM方法能解决更多PDDL问题，LMPlan规划器可以处理包含数百个相关对象的规划问题

Conclusion: LM有时在无意义符号表示的PDDL问题上规划更有效，这挑战了LM基于语义推理和训练语料记忆的假设，值得进一步探索

Abstract: We study the usage of language models (LMs) for planning over world models
specified in the Planning Domain Definition Language (PDDL). We prompt LMs to
generate Python programs that serve as generalised policies for solving PDDL
problems from a given domain. Notably, our approach synthesises policies that
are provably sound relative to the PDDL domain without reliance on external
verifiers. We conduct experiments on competition benchmarks which show that our
policies can solve more PDDL problems than PDDL planners and recent LM
approaches within a fixed time and memory constraint. Our approach manifests in
the LMPlan planner which can solve planning problems with several hundreds of
relevant objects. Surprisingly, we observe that LMs used in our framework
sometimes plan more effectively over PDDL problems written in meaningless
symbols in place of natural language; e.g. rewriting (at dog kitchen) as (p2 o1
o3). This finding challenges hypotheses that LMs reason over word semantics and
memorise solutions from its training corpus, and is worth further exploration.

</details>


### [17] [Weisfeiler-Leman Features for Planning: A 1,000,000 Sample Size Hyperparameter Study](https://arxiv.org/abs/2508.18515)
*Dillon Z. Chen*

Main category: cs.AI

TL;DR: 本文研究了Weisfeiler-Leman特征(WLFs)的超参数优化，发现存在一组跨领域最优的超参数设置，其目标是最大化执行效率而非模型表达能力，且训练指标与规划性能无显著相关性。


<details>
  <summary>Details</summary>
Motivation: WLFs在符号规划的价值函数学习中表现出优于深度学习方法的效果，但对其超参数的影响和最优配置缺乏系统研究，需要深入分析超参数对训练和规划性能的影响。

Method: 利用WLFs的高效性，在单核CPU上进行了100万样本的大规模规划实验，系统测试不同超参数组合，并进行统计分析来理解超参数对训练和规划的影响。

Result: 发现存在一组跨规划领域的最优超参数配置，最佳WLF超参数旨在最小化执行时间而非最大化模型表达能力，训练指标与规划性能之间无显著统计相关性。

Conclusion: WLFs的超参数优化应关注执行效率而非模型复杂度，训练性能不能直接预测规划效果，这为WLFs在实际规划应用中的参数调优提供了重要指导。

Abstract: Weisfeiler-Leman Features (WLFs) are a recently introduced classical machine
learning tool for learning to plan and search. They have been shown to be both
theoretically and empirically superior to existing deep learning approaches for
learning value functions for search in symbolic planning. In this paper, we
introduce new WLF hyperparameters and study their various tradeoffs and
effects. We utilise the efficiency of WLFs and run planning experiments on
single core CPUs with a sample size of 1,000,000 to understand the effect of
hyperparameters on training and planning. Our experimental analysis show that
there is a robust and best set of hyperparameters for WLFs across the tested
planning domains. We find that the best WLF hyperparameters for learning
heuristic functions minimise execution time rather than maximise model
expressivity. We further statistically analyse and observe no significant
correlation between training and planning metrics.

</details>


### [18] [Symmetry-Invariant Novelty Heuristics via Unsupervised Weisfeiler-Leman Features](https://arxiv.org/abs/2508.18520)
*Dillon Z. Chen*

Main category: cs.AI

TL;DR: 使用Weisfeiler-Leman特征替代原子特征来构建对称不变的新颖性启发式，解决传统新颖性启发式因对称状态导致的冗余探索问题


<details>
  <summary>Details</summary>
Motivation: 传统新颖性启发式基于原子特征，不具有对称不变性，会导致对对称状态的冗余探索，影响搜索效率

Method: 采用Weisfeiler-Leman特征（WLFs）来检测新颖性，这些特征最近被引入用于学习广义规划问题的领域相关启发式，本文探索其在无监督方式下合成提升的、领域无关的新颖性启发式

Result: 在国际规划竞赛和Hard To Ground基准测试套件上的实验表明，基于WLFs合成的新颖性启发式取得了有希望的结果

Conclusion: WLFs可以有效地用于构建对称不变的新颖性启发式，改善启发式搜索的性能，避免对对称状态的冗余探索

Abstract: Novelty heuristics aid heuristic search by exploring states that exhibit
novel atoms. However, novelty heuristics are not symmetry invariant and hence
may sometimes lead to redundant exploration. In this preliminary report, we
propose to use Weisfeiler-Leman Features for planning (WLFs) in place of atoms
for detecting novelty. WLFs are recently introduced features for learning
domain-dependent heuristics for generalised planning problems. We explore an
unsupervised usage of WLFs for synthesising lifted, domain-independent novelty
heuristics that are invariant to symmetric states. Experiments on the classical
International Planning Competition and Hard To Ground benchmark suites yield
promising results for novelty heuristics synthesised from WLFs.

</details>


### [19] [Generic Guard AI in Stealth Game with Composite Potential Fields](https://arxiv.org/abs/2508.18527)
*Kaijie Xu,Clark Verbrugge*

Main category: cs.AI

TL;DR: 通过复合潜力场技术，提出了一种无需训练、可解释的游戏小兵巡逻行为框架，在覆盖效率和追击响应性之间取得了更好的平行


<details>
  <summary>Details</summary>
Motivation: 现有演刻游戏中小兵巡逻行为多依赖手动设计路线或专门逻辑，难以同时平衡覆盖效率、响应追击和自然性

Method: 使用复合潜力场框架，结合信息、信心和连通性三种可解释地图，通过内核筛选决策标准，只需少量衰减和权重参数

Result: 在5个代表性游戏地图、2种玩家控制策略和5种小兵模式下评测，证明在捕捉效率和巡逻自然性方面都超过传统基准方法

Conclusion: 该框架能够自然集成常见演刻机制（如分散注意力和环境元素），支持快速原型设计丰富、动态响应的小兵行为

Abstract: Guard patrol behavior is central to the immersion and strategic depth of
stealth games, while most existing systems rely on hand-crafted routes or
specialized logic that struggle to balance coverage efficiency and responsive
pursuit with believable naturalness. We propose a generic, fully explainable,
training-free framework that integrates global knowledge and local information
via Composite Potential Fields, combining three interpretable maps-Information,
Confidence, and Connectivity-into a single kernel-filtered decision criterion.
Our parametric, designer-driven approach requires only a handful of decay and
weight parameters-no retraining-to smoothly adapt across both occupancy-grid
and NavMesh-partition abstractions. We evaluate on five representative game
maps, two player-control policies, and five guard modes, confirming that our
method outperforms classical baseline methods in both capture efficiency and
patrol naturalness. Finally, we show how common stealth mechanics-distractions
and environmental elements-integrate naturally into our framework as sub
modules, enabling rapid prototyping of rich, dynamic, and responsive guard
behaviors.

</details>


### [20] [A Database-Driven Framework for 3D Level Generation with LLMs](https://arxiv.org/abs/2508.18533)
*Kaijie Xu,Clark Verbrugge*

Main category: cs.AI

TL;DR: 本文提出了一种基于LLM辅助构建可重用数据库的3D游戏关卡生成框架，通过多阶段流水线组装关卡，结合模块化设计和约束优化，实现可导航3D环境和可配置游戏进程的生成。


<details>
  <summary>Details</summary>
Motivation: 解决3D游戏关卡生成中空间连贯性、导航功能和可适应游戏进程平衡的挑战，特别是在多层环境中的生成问题。

Method: 采用多阶段流水线：1)从房间数据库选择和排列实例形成多层全局结构；2)基于设施数据库约束优化房间内部布局；3)根据拓扑和空间规则整合游戏机制组件。后续采用两阶段修复系统确保可导航性。

Result: 初步实验验证了框架能够生成多样化、可导航的3D环境，并通过简单参数化模拟不同的游戏节奏策略。

Conclusion: 该研究通过提出可扩展的、以数据库为中心的框架，推进了程序化内容生成技术，为自动化生成具有可配置游戏进程的复杂3D关卡奠定了基础。

Abstract: Procedural Content Generation for 3D game levels faces challenges in
balancing spatial coherence, navigational functionality, and adaptable gameplay
progression across multi-floor environments. This paper introduces a novel
framework for generating such levels, centered on the offline, LLM-assisted
construction of reusable databases for architectural components (facilities and
room templates) and gameplay mechanic elements. Our multi-phase pipeline
assembles levels by: (1) selecting and arranging instances from the Room
Database to form a multi-floor global structure with an inherent topological
order; (2) optimizing the internal layout of facilities for each room based on
predefined constraints from the Facility Database; and (3) integrating
progression-based gameplay mechanics by placing components from a Mechanics
Database according to their topological and spatial rules. A subsequent
two-phase repair system ensures navigability. This approach combines modular,
database-driven design with constraint-based optimization, allowing for
systematic control over level structure and the adaptable pacing of gameplay
elements. Initial experiments validate the framework's ability in generating
diverse, navigable 3D environments and its capability to simulate distinct
gameplay pacing strategies through simple parameterization. This research
advances PCG by presenting a scalable, database-centric foundation for the
automated generation of complex 3D levels with configurable gameplay
progression.

</details>


### [21] [SchemaCoder: Automatic Log Schema Extraction Coder with Residual Q-Tree Boosting](https://arxiv.org/abs/2508.18554)
*Lily Jiaxin Wan,Chia-Tung Ho,Rongjian Liang,Cunxi Yu,Deming Chen,Haoxing Ren*

Main category: cs.AI

TL;DR: SchemaCoder是一个完全自动化的日志模式提取框架，通过创新的残差问题树增强机制，无需人工定制即可处理多种日志格式，在LogHub-2.0基准测试中比现有方法平均提升21.3%。


<details>
  <summary>Details</summary>
Motivation: 现有日志模式提取方法依赖预定义正则表达式，需要人工领域知识，严重限制了生产效率提升。需要从根本上解决这一限制，实现完全自动化的模式提取。

Method: 采用残差问题树增强机制，通过上下文边界分割将日志划分为语义块，使用基于嵌入的采样选择代表性模式，通过分层Q-Tree驱动的LLM查询生成模式代码，并由文本残差进化优化器和残差增强进行迭代优化。

Result: 在广泛使用的LogHub-2.0基准测试中，SchemaCoder相比最先进方法平均提升了21.3%的性能。

Conclusion: SchemaCoder是第一个完全自动化的模式提取框架，能够处理各种日志文件格式而无需人工定制，通过创新的Q-Tree增强机制显著提升了日志模式提取的性能和效率。

Abstract: Log schema extraction is the process of deriving human-readable templates
from massive volumes of log data, which is essential yet notoriously
labor-intensive. Recent studies have attempted to streamline this task by
leveraging Large Language Models (LLMs) for automated schema extraction.
However, existing methods invariably rely on predefined regular expressions,
necessitating human domain expertise and severely limiting productivity gains.
To fundamentally address this limitation, we introduce SchemaCoder, the first
fully automated schema extraction framework applicable to a wide range of log
file formats without requiring human customization within the flow. At its
core, SchemaCoder features a novel Residual Question-Tree (Q-Tree) Boosting
mechanism that iteratively refines schema extraction through targeted, adaptive
queries driven by LLMs. Particularly, our method partitions logs into semantic
chunks via context-bounded segmentation, selects representative patterns using
embedding-based sampling, and generates schema code through hierarchical
Q-Tree-driven LLM queries, iteratively refined by our textual-residual
evolutionary optimizer and residual boosting. Experimental validation
demonstrates SchemaCoder's superiority on the widely-used LogHub-2.0 benchmark,
achieving an average improvement of 21.3% over state-of-the-arts.

</details>


### [22] [eSkinHealth: A Multimodal Dataset for Neglected Tropical Skin Diseases](https://arxiv.org/abs/2508.18608)
*Janet Wang,Xin Hu,Yunbei Zhang,Diabate Almamy,Vagamon Bamba,Konan Amos Sébastien Koffi,Yao Koffi Aubin,Zhengming Ding,Jihun Hamm,Rie R. Yotsu*

Main category: cs.AI

TL;DR: eSkinHealth是一个新的皮肤病数据集，专注于西非人群的皮肤被忽视热带病和罕见病症，包含5623张图像和47种疾病，采用AI-专家协作范式生成多模态标注


<details>
  <summary>Details</summary>
Motivation: 解决皮肤被忽视热带病(NTDs)诊断中数据稀缺问题，特别是对代表性不足人群和罕见病症的数据缺乏，现有皮肤病数据集缺乏关键的人口统计学和疾病谱信息

Method: 在科特迪瓦和加纳现场收集数据，提出AI-专家协作范式，利用基础语言和分割模型在皮肤科医生指导下高效生成多模态标注，包括语义病变掩码、视觉描述和临床概念

Result: 构建了包含5623张图像、1639个病例、47种皮肤疾病的eSkinHealth数据集，特别关注西非人群的皮肤NTDs和罕见病症

Conclusion: 该工作提供了宝贵的新资源和可扩展的标注框架，旨在推动开发更公平、准确和可解释的全球皮肤病AI工具

Abstract: Skin Neglected Tropical Diseases (NTDs) impose severe health and
socioeconomic burdens in impoverished tropical communities. Yet, advancements
in AI-driven diagnostic support are hindered by data scarcity, particularly for
underrepresented populations and rare manifestations of NTDs. Existing
dermatological datasets often lack the demographic and disease spectrum crucial
for developing reliable recognition models of NTDs. To address this, we
introduce eSkinHealth, a novel dermatological dataset collected on-site in
C\^ote d'Ivoire and Ghana. Specifically, eSkinHealth contains 5,623 images from
1,639 cases and encompasses 47 skin diseases, focusing uniquely on skin NTDs
and rare conditions among West African populations. We further propose an
AI-expert collaboration paradigm to implement foundation language and
segmentation models for efficient generation of multimodal annotations, under
dermatologists' guidance. In addition to patient metadata and diagnosis labels,
eSkinHealth also includes semantic lesion masks, instance-specific visual
captions, and clinical concepts. Overall, our work provides a valuable new
resource and a scalable annotation framework, aiming to catalyze the
development of more equitable, accurate, and interpretable AI tools for global
dermatology.

</details>


### [23] [RLMR: Reinforcement Learning with Mixed Rewards for Creative Writing](https://arxiv.org/abs/2508.18642)
*Jianxing Liao,Tian Zhang,Xiao Feng,Yusong Zhang,Rui Yang,Haorui Wang,Bosi Wen,Ziying Wang,Runzhi Shi*

Main category: cs.AI

TL;DR: RLMR方法通过动态混合奖励系统，结合主观写作质量和客观约束遵循评估，在创意写作中实现了指令遵循和写作质量的双重提升


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法难以同时平衡创意写作中的主观写作质量和客观约束遵循，单一奖励策略和固定权重混合奖励方法都存在局限性

Method: 提出RLMR方法，使用写作奖励模型评估主观质量，约束验证模型评估客观约束，动态调整约束遵循奖励权重，通过GRPO对违反约束的样本进行惩罚

Result: 在8B到72B参数的不同模型家族上取得一致改进，指令遵循从83.36%提升到86.65%，在WriteEval基准上获得72.75%的人工专家评估胜率

Conclusion: RLMR是首个在在线RL训练中结合主观偏好和客观验证的工作，为多维创意写作优化提供了有效解决方案

Abstract: Large language models are extensively utilized in creative writing
applications. Creative writing requires a balance between subjective writing
quality (e.g., literariness and emotional expression) and objective constraint
following (e.g., format requirements and word limits). Existing reinforcement
learning methods struggle to balance these two aspects: single reward
strategies fail to improve both abilities simultaneously, while fixed-weight
mixed-reward methods lack the ability to adapt to different writing scenarios.
To address this problem, we propose Reinforcement Learning with Mixed Rewards
(RLMR), utilizing a dynamically mixed reward system from a writing reward model
evaluating subjective writing quality and a constraint verification model
assessing objective constraint following. The constraint following reward
weight is adjusted dynamically according to the writing quality within sampled
groups, ensuring that samples violating constraints get negative advantage in
GRPO and thus penalized during training, which is the key innovation of this
proposed method. We conduct automated and manual evaluations across diverse
model families from 8B to 72B parameters. Additionally, we construct a
real-world writing benchmark named WriteEval for comprehensive evaluation.
Results illustrate that our method achieves consistent improvements in both
instruction following (IFEval from 83.36\% to 86.65\%) and writing quality
(72.75\% win rate in manual expert pairwise evaluations on WriteEval). To the
best of our knowledge, RLMR is the first work to combine subjective preferences
with objective verification in online RL training, providing an effective
solution for multi-dimensional creative writing optimization.

</details>


### [24] [Beyond Benchmark: LLMs Evaluation with an Anthropomorphic and Value-oriented Roadmap](https://arxiv.org/abs/2508.18646)
*Jun Wang,Ninglun Gu,Kailai Zhang,Zijiao Zhang,Yelun Bao,Jin Yang,Xu Yin,Liwei Liu,Yihuan Liu,Pengyong Li,Gary G. Yen,Junchi Yan*

Main category: cs.AI

TL;DR: 该论文提出了一个基于人类智能视角的拟人化评估范式，包含IQ、EQ、PQ三个维度的分类法，并首创了面向价值的评估框架，用于全面评估大语言模型的实用价值。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的基准测试性能与实际应用价值之间存在脱节，现有评估框架碎片化且过度关注技术指标，缺乏对部署实用性的整体评估。

Method: 提出了三维分类法：智商(IQ)-通用智能基础能力、情商(EQ)-价值对齐交互能力、专业商(PQ)-专业领域精通能力，并建立了包含经济可行性、社会影响、伦理对齐和可持续性的价值导向评估框架。

Result: 通过分析200多个基准测试，识别出动态评估需求和可解释性差距等关键挑战，提供了模块化架构和实施路线图。

Conclusion: 该研究为开发技术熟练、情境相关且伦理健全的大语言模型提供了可操作的指导，并维护了开源评估资源库。

Abstract: For Large Language Models (LLMs), a disconnect persists between benchmark
performance and real-world utility. Current evaluation frameworks remain
fragmented, prioritizing technical metrics while neglecting holistic assessment
for deployment. This survey introduces an anthropomorphic evaluation paradigm
through the lens of human intelligence, proposing a novel three-dimensional
taxonomy: Intelligence Quotient (IQ)-General Intelligence for foundational
capacity, Emotional Quotient (EQ)-Alignment Ability for value-based
interactions, and Professional Quotient (PQ)-Professional Expertise for
specialized proficiency. For practical value, we pioneer a Value-oriented
Evaluation (VQ) framework assessing economic viability, social impact, ethical
alignment, and environmental sustainability. Our modular architecture
integrates six components with an implementation roadmap. Through analysis of
200+ benchmarks, we identify key challenges including dynamic assessment needs
and interpretability gaps. It provides actionable guidance for developing LLMs
that are technically proficient, contextually relevant, and ethically sound. We
maintain a curated repository of open-source evaluation resources at:
https://github.com/onejune2018/Awesome-LLM-Eval.

</details>


### [25] [MUA-RL: Multi-turn User-interacting Agent Reinforcement Learning for agentic tool use](https://arxiv.org/abs/2508.18669)
*Weikang Zhao,Xili Wang,Chengdi Ma,Lingbin Kong,Zhaohua Yang,Mingxiang Tuo,Xiaowei Shi,Yitao Zhai,Xunliang Cai*

Main category: cs.AI

TL;DR: MUA-RL是一个新颖的强化学习框架，首次在智能体工具使用领域将LLM模拟用户集成到强化学习循环中，用于多轮动态交互中的工具调用。


<details>
  <summary>Details</summary>
Motivation: 随着智能体智能的快速发展，多轮交互中用户需求的动态性、不确定性和随机性对智能体工具调用能力提出了重大挑战，现有强化学习方法缺乏真正动态用户的集成。

Method: 提出了MUA-RL（多轮用户交互智能体强化学习）框架，通过将LLM模拟用户集成到强化学习训练过程中，使模型能够自主学习与用户高效沟通并使用各种工具解决实际问题。

Result: 在多个多轮工具使用基准测试中表现优异：TAU2 Retail 67.3分、TAU2 Airline 45.4分、TAU2 Telecom 28.3分、BFCL-V3 Multi Turn 28.4分、ACEBench Agent 82.5分，性能优于或匹配更大的开源模型。

Conclusion: MUA-RL框架成功解决了动态多轮交互中工具使用的挑战，通过集成模拟用户实现了智能体在复杂环境中的自主学习能力，为智能体工具使用领域提供了新的解决方案。

Abstract: With the recent rapid advancement of Agentic Intelligence, agentic tool use
in LLMs has become increasingly important. During multi-turn interactions
between agents and users, the dynamic, uncertain, and stochastic nature of user
demands poses significant challenges to the agent's tool invocation
capabilities. Agents are no longer expected to simply call tools to deliver a
result; rather, they must iteratively refine their understanding of user needs
through communication while simultaneously invoking tools to resolve user
queries. Existing reinforcement learning (RL) approaches for tool use lack the
integration of genuinely dynamic users during the RL training process. To
bridge this gap, we introduce MUA-RL (Multi-turn User-interacting Agent
Reinforcement Learning for agentic tool use), a novel reinforcement learning
framework that, for the first time in the field of agentic tool use, integrates
LLM-simulated users into the reinforcement learning loop. MUA-RL aims to enable
autonomous learning of models to communicate with users efficiently and use
various tools to solve practical problems in dynamic multi-turn interactions.
Evaluations are done on several multi-turn tool-using benchmarks (see Figure
1). Specifically, MUA-RL-32B achieves 67.3 on TAU2 Retail, 45.4 on TAU2
Airline, 28.3 on TAU2 Telecom, 28.4 on BFCL-V3 Multi Turn, and 82.5 on ACEBench
Agent -- outperforming or matching the performance of larger open-source models
such as DeepSeek-V3-0324 and Qwen3-235B-A22B in non-thinking settings.

</details>


### [26] [AppAgent-Pro: A Proactive GUI Agent System for Multidomain Information Integration and User Assistance](https://arxiv.org/abs/2508.18689)
*Yuyang Zhao,Wentao Shi,Fuli Feng,Xiangnan He*

Main category: cs.AI

TL;DR: AppAgent-Pro是一个主动式GUI代理系统，通过多领域信息整合主动预测用户需求，提升信息获取的全面性和智能化


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理多为被动响应模式，限制了信息获取的效率和效果，需要转向主动式信息获取方式

Method: 提出AppAgent-Pro系统，主动整合多领域信息，基于用户指令进行深度多领域信息挖掘

Result: 系统能够主动预测用户潜在需求，实现更全面智能的信息获取，有望重新定义日常生活中的信息获取方式

Conclusion: AppAgent-Pro代表了从被动到主动信息获取的重要转变，对人类社会的日常信息获取具有深远影响

Abstract: Large language model (LLM)-based agents have demonstrated remarkable
capabilities in addressing complex tasks, thereby enabling more advanced
information retrieval and supporting deeper, more sophisticated human
information-seeking behaviors. However, most existing agents operate in a
purely reactive manner, responding passively to user instructions, which
significantly constrains their effectiveness and efficiency as general-purpose
platforms for information acquisition. To overcome this limitation, this paper
proposes AppAgent-Pro, a proactive GUI agent system that actively integrates
multi-domain information based on user instructions. This approach enables the
system to proactively anticipate users' underlying needs and conduct in-depth
multi-domain information mining, thereby facilitating the acquisition of more
comprehensive and intelligent information. AppAgent-Pro has the potential to
fundamentally redefine information acquisition in daily life, leading to a
profound impact on human society. Our code is available at:
https://github.com/LaoKuiZe/AppAgent-Pro. Our code is available at:
https://github.com/LaoKuiZe/AppAgent-Pro. The demonstration video could be
found at:
https://www.dropbox.com/scl/fi/hvzqo5vnusg66srydzixo/AppAgent-Pro-demo-video.mp4?rlkey=o2nlfqgq6ihl125mcqg7bpgqu&st=d29vrzii&dl=0.

</details>


### [27] [VistaWise: Building Cost-Effective Agent with Cross-Modal Knowledge Graph for Minecraft](https://arxiv.org/abs/2508.18722)
*Honghao Fu,Junlong Ren,Qi Chai,Deheng Ye,Yujun Cai,Hao Wang*

Main category: cs.AI

TL;DR: VistaWise是一个成本效益高的智能体框架，通过整合跨模态领域知识和微调专用目标检测模型，将领域特定训练数据需求从数百万样本减少到数百个，在虚拟开放世界环境中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在虚拟开放世界环境中的具身决策任务中表现出巨大潜力，但其性能受到缺乏领域特定知识的限制，而基于大规模领域特定数据的微调方法开发成本过高。

Method: 提出VistaWise框架，整合跨模态领域知识并微调专用目标检测模型进行视觉分析；构建跨模态知识图谱整合视觉信息和文本依赖关系；采用检索式池化策略从知识图谱提取任务相关信息；配备桌面级技能库支持通过鼠标键盘直接操作Minecraft客户端。

Result: 实验结果表明，VistaWise在各种开放世界任务中实现了最先进的性能，显著降低了开发成本同时提升了智能体性能。

Conclusion: VistaWise框架有效解决了领域特定知识缺乏和开发成本高的问题，通过跨模态知识整合和高效数据利用，在虚拟开放世界环境中展现出卓越的性能和实用性。

Abstract: Large language models (LLMs) have shown significant promise in embodied
decision-making tasks within virtual open-world environments. Nonetheless,
their performance is hindered by the absence of domain-specific knowledge.
Methods that finetune on large-scale domain-specific data entail prohibitive
development costs. This paper introduces VistaWise, a cost-effective agent
framework that integrates cross-modal domain knowledge and finetunes a
dedicated object detection model for visual analysis. It reduces the
requirement for domain-specific training data from millions of samples to a few
hundred. VistaWise integrates visual information and textual dependencies into
a cross-modal knowledge graph (KG), enabling a comprehensive and accurate
understanding of multimodal environments. We also equip the agent with a
retrieval-based pooling strategy to extract task-related information from the
KG, and a desktop-level skill library to support direct operation of the
Minecraft desktop client via mouse and keyboard inputs. Experimental results
demonstrate that VistaWise achieves state-of-the-art performance across various
open-world tasks, highlighting its effectiveness in reducing development costs
while enhancing agent performance.

</details>


### [28] [Bias Mitigation Agent: Optimizing Source Selection for Fair and Balanced Knowledge Retrieval](https://arxiv.org/abs/2508.18724)
*Karanbir Singh,Deepak Muppiri,William Ngu*

Main category: cs.AI

TL;DR: 提出了一种新型偏置缓解代理系统，通过多智能体协作优化信息源选择，显著减少LLM检索中的偏见问题


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和代理AI系统继承了内部和外部信息源的偏见，这影响了检索信息的公平性和平衡性，降低了用户信任度

Method: 设计了一个多智能体系统，通过专门的代理协调偏置缓解工作流程，优化信息源选择以确保检索内容高度相关且偏见最小

Result: 实验结果显示，与基线朴素检索策略相比，偏置减少了81.82%

Conclusion: 该偏置缓解代理系统能有效促进公平和平衡的知识传播，显著提升信息检索的公正性

Abstract: Large Language Models (LLMs) have transformed the field of artificial
intelligence by unlocking the era of generative applications. Built on top of
generative AI capabilities, Agentic AI represents a major shift toward
autonomous, goal-driven systems that can reason, retrieve, and act. However,
they also inherit the bias present in both internal and external information
sources. This significantly affects the fairness and balance of retrieved
information, and hence reduces user trust. To address this critical challenge,
we introduce a novel Bias Mitigation Agent, a multi-agent system designed to
orchestrate the workflow of bias mitigation through specialized agents that
optimize the selection of sources to ensure that the retrieved content is both
highly relevant and minimally biased to promote fair and balanced knowledge
dissemination. The experimental results demonstrate an 81.82\% reduction in
bias compared to a baseline naive retrieval strategy.

</details>


### [29] [CAC-CoT: Connector-Aware Compact Chain-of-Thought for Efficient Reasoning Data Synthesis Across Dual-System Cognitive Tasks](https://arxiv.org/abs/2508.18743)
*Sunguk Choi,Yonghoon Kwon,Heondeuk Lee*

Main category: cs.AI

TL;DR: CAC-CoT是一种使用有限连接短语的紧凑思维链方法，在保持System-1任务性能的同时，显著缩短推理长度并提升System-2任务表现


<details>
  <summary>Details</summary>
Motivation: 解决长思维链在快速直觉性任务(System-1)上性能下降的问题，同时保持复杂推理任务(System-2)的能力

Method: 使用连接短语感知的紧凑思维链方法，限制推理到固定的小型连接短语集合，引导模型生成简洁且结构良好的解释

Result: 在GSM8K上达到约85%，GPQA上约40%，同时保持S1-Bench约90%的性能；推理痕迹平均约300个token，比基线缩短三分之二

Conclusion: CAC-CoT方法通过简洁的结构化推理，实现了效率提升且不损失准确性，在System-1和System-2任务间取得了良好平衡

Abstract: Long chain-of-thought (CoT) prompting helps Large Language Models (LLMs)
solve difficult problems, but very long traces often slow or even degrade
performance on fast, intuitive "System-1" tasks. We introduce Connector-Aware
Compact CoT (CAC-CoT) -- a method that deliberately restricts reasoning to a
small, fixed set of connector phrases, steering the model toward concise and
well -- structured explanations. Despite its simplicity, our synthetic method
with Gemini-2.0-Flash yields a high-quality training quality. CAC-CoT achieves
approximately 85% on GSM8K and approximately 40% on GPQA (System-2) while
retaining approximately 90% on S1-Bench (System-1). Its reasoning traces
average approximately 300 tokens(ART), about one-third the length of baseline
traces, delivering higher efficiency without loss of accuracy.

</details>


### [30] [Reflection-Enhanced Meta-Optimization Integrating TextGrad-style Prompt Optimization with Memory-Driven Self-Evolution](https://arxiv.org/abs/2508.18749)
*Chunlong Wu,Zhibo Qu*

Main category: cs.AI

TL;DR: REMO是一个新的提示优化框架，通过记忆增强的反思RAG模块和自适应优化器，解决了现有方法缺乏历史经验积累和容易过拟合的问题，在数学推理任务上实现了更稳定和鲁棒的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有的提示优化方法（如TextGrad）通常是状态无关的，缺乏历史优化经验的保存和利用机制，且容易过拟合，泛化性能较差。

Method: 提出了REMO框架，包含：(1)记忆增强的反思RAG模块（"错误笔记本"结构），(2)LLM驱动的元控制器实现的自适应优化器，通过合成epoch级别的反思见解来迭代改进系统级提示策略。

Result: 在GSM8K数学推理基准测试中，相比TextGrad基线，REMO实现了更稳定和鲁棒的泛化性能，但计算开销有所增加。

Conclusion: REMO框架能够系统性地积累和重用跨运行优化知识，支持持续改进，为提示优化提供了新的方向。

Abstract: Recent advances in prompt optimization, exemplified by methods such as
TextGrad, enable automatic, gradient-like refinement of textual prompts to
enhance the performance of large language models (LLMs) on specific downstream
tasks. However, current approaches are typically stateless and operate
independently across optimization runs, lacking mechanisms to preserve and
leverage historical optimization experience. Furthermore, they are susceptible
to overfitting, often yielding prompt updates that generalize poorly beyond the
immediate task context.
  To address these limitations, we propose Reflection-Enhanced
Meta-Optimization (REMO), a novel framework that integrates (1) a
memory-augmented Reflection Retrieval-Augmented Generation (RAG) module -
structured as a "mistake notebook" and (2) a Self-Adaptive Optimizer,
implemented via an LLM-driven meta-controller that synthesizes epoch-level
reflective insights to iteratively improve system-level prompting strategies.
This architecture enables not only local, fine-grained prompt tuning akin to
TextGrad, but also the systematic accumulation and reuse of cross-run
optimization knowledge, thereby supporting continual improvement over time.
  We instantiate the REMO framework using Qwen3-32B in standard inference mode
- without explicit chain-of-thought prompting - and evaluate its efficacy on
the GSM8K benchmark for mathematical reasoning. Experimental results
demonstrate that, compared to a TextGrad baseline, REMO achieves more stable
and robust generalization, albeit at the cost of increased computational
overhead. We provide a detailed exposition of the algorithmic design, conduct a
qualitative and quantitative analysis of optimization dynamics, and present a
comprehensive ablation study to elucidate the contributions of each component.

</details>


### [31] [Stabilizing Open-Set Test-Time Adaptation via Primary-Auxiliary Filtering and Knowledge-Integrated Prediction](https://arxiv.org/abs/2508.18751)
*Byung-Joon Lee,Jin-Seop Lee,Jee-Hyong Lee*

Main category: cs.AI

TL;DR: 提出PAF-KIP方法解决开放集测试时适应问题，通过主辅助过滤器和知识集成预测来提升闭集准确性和开集识别能力


<details>
  <summary>Details</summary>
Motivation: 现有开放集TTA方法依赖源模型进行过滤，在域偏移测试数据上过滤效果不佳，而使用适应模型过滤会导致不稳定和错误累积

Method: 提出主辅助过滤(PAF)机制，用辅助过滤器验证主过滤器结果；提出知识集成预测(KIP)，整合适应模型、EMA模型和源模型的互补知识

Result: 在多个闭集和开集数据集上验证，方法在闭集准确性和开集识别方面均优于现有方法

Conclusion: PAF-KIP方法有效解决了开放集测试时适应中的过滤不稳定问题，通过多模型知识集成显著提升了性能

Abstract: Deep neural networks demonstrate strong performance under aligned
training-test distributions. However, real-world test data often exhibit domain
shifts. Test-Time Adaptation (TTA) addresses this challenge by adapting the
model to test data during inference. While most TTA studies assume that the
training and test data share the same class set (closed-set TTA), real-world
scenarios often involve open-set data (open-set TTA), which can degrade
closed-set accuracy. A recent study showed that identifying open-set data
during adaptation and maximizing its entropy is an effective solution. However,
the previous method relies on the source model for filtering, resulting in
suboptimal filtering accuracy on domain-shifted test data. In contrast, we
found that the adapting model, which learns domain knowledge from noisy test
streams, tends to be unstable and leads to error accumulation when used for
filtering. To address this problem, we propose Primary-Auxiliary Filtering
(PAF), which employs an auxiliary filter to validate data filtered by the
primary filter. Furthermore, we propose Knowledge-Integrated Prediction (KIP),
which calibrates the outputs of the adapting model, EMA model, and source model
to integrate their complementary knowledge for OSTTA. We validate our approach
across diverse closed-set and open-set datasets. Our method enhances both
closed-set accuracy and open-set discrimination over existing methods. The code
is available at https://github.com/powerpowe/PAF-KIP-OSTTA .

</details>


### [32] [Answering the Unanswerable Is to Err Knowingly: Analyzing and Mitigating Abstention Failures in Large Reasoning Models](https://arxiv.org/abs/2508.18760)
*Yi Liu,Xiangyu Liu,Zequn Sun,Wei Hu*

Main category: cs.AI

TL;DR: 大型推理模型在处理无法回答的问题时存在拒绝回答能力不足的问题，本文通过认知监控和推理时干预的方法显著提升了模型的拒绝回答率


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在遇到缺乏充分条件的数学问题等无法回答的问题时，往往无法提供适当的拒绝回答，这影响了AI的可信度

Method: 采用轻量级的两阶段方法，结合认知监控和推理时干预，首先分析模型对无法回答问题的响应行为，然后通过干预使模型内部认知与外部响应对齐

Result: 实验结果表明该方法显著提高了拒绝回答率，同时保持了整体推理性能

Conclusion: 该方法有效解决了大型推理模型在无法回答问题时的拒绝回答能力不足问题，提升了AI系统的可信度

Abstract: Large reasoning models (LRMs) have shown remarkable progress on complex
reasoning tasks. However, some questions posed to LRMs are inherently
unanswerable, such as math problems lacking sufficient conditions. We find that
LRMs continually fail to provide appropriate abstentions when confronted with
these unanswerable questions. In this paper, we systematically analyze,
investigate, and resolve this issue for trustworthy AI. We first conduct a
detailed analysis of the distinct response behaviors of LRMs when facing
unanswerable questions. Then, we show that LRMs possess sufficient cognitive
capabilities to recognize the flaws in these questions. However, they fail to
exhibit appropriate abstention behavior, revealing a misalignment between their
internal cognition and external response. Finally, to resolve this issue, we
propose a lightweight, two-stage method that combines cognitive monitoring with
inference-time intervention. Experimental results demonstrate that our method
significantly improves the abstention rate while maintaining the overall
reasoning performance.

</details>


### [33] [Dynamic Collaboration of Multi-Language Models based on Minimal Complete Semantic Units](https://arxiv.org/abs/2508.18763)
*Chao Hao,Zezheng Wang,Yanhua Huang,Ruiwen Xu,Wenzhe Niu,Xin Liu,Zitong Yu*

Main category: cs.AI

TL;DR: 本文提出了一种基于分布距离的动态选择策略(DDS)和最小完整语义单元(MCSU)概念，通过多模型在token级别的协作来增强语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统认为更多模型会带来更好结果，但实际多模型协作中存在词汇不对齐等关键挑战，需要优化多模型协作过程。

Method: 1. 提出DDS策略从多个模型的下一token分布中动态选择最优token；2. 引入MCSU概念解决多模型词汇不对齐问题，实现语言空间内的自然对齐。

Result: 在多个基准测试上的实验结果表明该方法具有优越性。

Conclusion: 该方法通过token级别的多模型协作有效提升了语言模型的推理能力，解决了多模型协作中的关键挑战。

Abstract: This paper investigates the enhancement of reasoning capabilities in language
models through token-level multi-model collaboration. Our approach selects the
optimal tokens from the next token distributions provided by multiple models to
perform autoregressive reasoning. Contrary to the assumption that more models
yield better results, we introduce a distribution distance-based dynamic
selection strategy (DDS) to optimize the multi-model collaboration process. To
address the critical challenge of vocabulary misalignment in multi-model
collaboration, we propose the concept of minimal complete semantic units
(MCSU), which is simple yet enables multiple language models to achieve natural
alignment within the linguistic space. Experimental results across various
benchmarks demonstrate the superiority of our method. The code will be
available at https://github.com/Fanye12/DDS.

</details>


### [34] [AniME: Adaptive Multi-Agent Planning for Long Animation Generation](https://arxiv.org/abs/2508.18781)
*Lisai Zhang,Baohan Xu,Siqian Yang,Mingyu Yin,Jing Liu,Chao Xu,Siqi Wang,Yidi Wu,Yuxin Hong,Zihao Zhang,Yanzhang Liang,Yudong Jiang*

Main category: cs.AI

TL;DR: AniME是一个导演导向的多智能体系统，用于自动化长篇幅动画制作，涵盖从故事到最终视频的完整工作流程。


<details>
  <summary>Details</summary>
Motivation: 为了解决AI驱动动画创作中保持角色一致性和音视频元素同步的挑战，提供可扩展的自动化动画制作解决方案。

Method: 采用导演智能体维护全局记忆并协调下游专业智能体，通过定制化的模型上下文协议（MCP）与下游模型指令集成，使专业智能体能够自适应选择不同子任务的控制条件。

Result: 系统能够生成具有一致角色和同步音视频元素的电影级动画。

Conclusion: AniME为AI驱动的动画创作提供了一个可扩展的解决方案，实现了从故事到最终视频的完整自动化生产流程。

Abstract: We present AniME, a director-oriented multi-agent system for automated
long-form anime production, covering the full workflow from a story to the
final video. The director agent keeps a global memory for the whole workflow,
and coordinates several downstream specialized agents. By integrating
customized Model Context Protocol (MCP) with downstream model instruction, the
specialized agent adaptively selects control conditions for diverse sub-tasks.
AniME produces cinematic animation with consistent characters and synchronized
audio visual elements, offering a scalable solution for AI-driven anime
creation.

</details>


### [35] [CausalMACE: Causality Empowered Multi-Agents in Minecraft Cooperative Tasks](https://arxiv.org/abs/2508.18797)
*Qi Chai,Zhang Zheng,Junlong Ren,Deheng Ye,Zichuan Lin,Hao Wang*

Main category: cs.AI

TL;DR: CausalMACE是一个基于因果关系的多智能体协作框架，用于提升Minecraft游戏中复杂任务的执行效率和容错能力


<details>
  <summary>Details</summary>
Motivation: 现有的单智能体方法在处理Minecraft中需要长序列动作的复杂任务时存在效率低下和容错性差的问题，而多智能体协作研究相对缺乏

Method: 提出包含两个模块的整体因果规划框架：全局任务规划的任务图和基于因果关系的依赖管理模块，采用固有规则进行因果干预

Result: 实验结果表明该方法在Minecraft多智能体协作任务中达到了最先进的性能

Conclusion: CausalMACE框架通过引入因果关系有效提升了多智能体系统的协作效率和任务完成能力

Abstract: Minecraft, as an open-world virtual interactive environment, has become a
prominent platform for research on agent decision-making and execution.
Existing works primarily adopt a single Large Language Model (LLM) agent to
complete various in-game tasks. However, for complex tasks requiring lengthy
sequences of actions, single-agent approaches often face challenges related to
inefficiency and limited fault tolerance. Despite these issues, research on
multi-agent collaboration remains scarce. In this paper, we propose CausalMACE,
a holistic causality planning framework designed to enhance multi-agent
systems, in which we incorporate causality to manage dependencies among
subtasks. Technically, our proposed framework introduces two modules: an
overarching task graph for global task planning and a causality-based module
for dependency management, where inherent rules are adopted to perform causal
intervention. Experimental results demonstrate our approach achieves
state-of-the-art performance in multi-agent cooperative tasks of Minecraft.

</details>


### [36] [STARec: An Efficient Agent Framework for Recommender Systems via Autonomous Deliberate Reasoning](https://arxiv.org/abs/2508.18812)
*Chenghao Wu,Ruiyang Ren,Junjie Zhang,Ruirui Wang,Zhongrui Ma,Qi Ye,Wayne Xin Zhao*

Main category: cs.AI

TL;DR: STARec是一个慢思维增强的推荐系统框架，通过双阶段认知建模和锚定强化训练，显著提升了推荐性能，仅使用0.4%的训练数据就超越了现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统受限于静态用户建模和反应式决策，基于大语言模型的推荐代理也存在启发式模式匹配的局限性，导致浅层相关偏差、有限因果推理和稀疏数据场景下的脆弱性。

Method: 提出STARec框架，将用户建模为具有并行认知的代理：快速响应即时交互，慢速推理执行思维链推理。采用锚定强化训练，结合高级推理模型的结构化知识蒸馏和偏好对齐的奖励塑造。

Result: 在MovieLens 1M和Amazon CDs基准测试中，STARec相比最先进的基线方法取得了显著的性能提升，尽管只使用了0.4%的完整训练数据。

Conclusion: STARec通过引入自主审慎推理能力，成功解决了传统推荐系统的局限性，为推荐系统提供了更强大的因果推理和稀疏数据处理能力。

Abstract: While modern recommender systems are instrumental in navigating information
abundance, they remain fundamentally limited by static user modeling and
reactive decision-making paradigms. Current large language model (LLM)-based
agents inherit these shortcomings through their overreliance on heuristic
pattern matching, yielding recommendations prone to shallow correlation bias,
limited causal inference, and brittleness in sparse-data scenarios. We
introduce STARec, a slow-thinking augmented agent framework that endows
recommender systems with autonomous deliberative reasoning capabilities. Each
user is modeled as an agent with parallel cognitions: fast response for
immediate interactions and slow reasoning that performs chain-of-thought
rationales. To cultivate intrinsic slow thinking, we develop anchored
reinforcement training - a two-stage paradigm combining structured knowledge
distillation from advanced reasoning models with preference-aligned reward
shaping. This hybrid approach scaffolds agents in acquiring foundational
capabilities (preference summarization, rationale generation) while enabling
dynamic policy adaptation through simulated feedback loops. Experiments on
MovieLens 1M and Amazon CDs benchmarks demonstrate that STARec achieves
substantial performance gains compared with state-of-the-art baselines, despite
using only 0.4% of the full training data.

</details>


### [37] [Judicial Requirements for Generative AI in Legal Reasoning](https://arxiv.org/abs/2508.18880)
*Eljas Linna,Tuula Linna*

Main category: cs.AI

TL;DR: 本文分析了LLMs在法律决策中的局限性，定义了AI系统在司法推理中需要具备的核心能力，并评估了RAG、多智能体系统等增强技术解决这些挑战的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型被整合到专业领域，其在法律等高风险领域的局限性仍未得到充分理解，需要明确AI系统在司法决策中作为可靠推理工具所需的核心能力。

Method: 使用IRAC（问题-规则-应用-结论）模型作为分析框架，重点关注法律裁决中最具挑战性的阶段：确定适用规则（R）和将规则应用于案件事实（A），并评估RAG、多智能体系统和神经符号AI等增强机制。

Result: 研究发现这些技术可以解决特定挑战，但在需要自由裁量权和透明、可论证推理的任务中仍存在重大挑战。

Conclusion: 目前AI在法律中最有效的角色是双重的：作为简单重复案件的高容量助手，以及作为复杂事务中人类专家的复杂"陪练伙伴"。

Abstract: Large Language Models (LLMs) are being integrated into professional domains,
yet their limitations in high-stakes fields like law remain poorly understood.
This paper defines the core capabilities that an AI system must possess to
function as a reliable reasoning tool in judicial decision-making. Using the
IRAC (Issue-Rule-Application-Conclusion) model as an analytical framework, the
study focuses on the most challenging phases of legal adjudication: determining
the applicable Rule (R) and performing the Application (A) of that rule to the
facts of a case. From a judicial perspective, the analysis deconstructs legal
reasoning into a series of core requirements, including the ability to select
the correct legal framework across jurisdictions, generate sound arguments
based on the doctrine of legal sources, distinguish ratio decidendi from obiter
dictum in case law, resolve ambiguity arising from general clauses like
"reasonableness", manage conflicting legal provisions, and correctly apply the
burden of proof. The paper then maps various AI enhancement mechanisms, such as
Retrieval-Augmented Generation (RAG), multi-agent systems, and neuro-symbolic
AI, to these requirements, assessing their potential to bridge the gap between
the probabilistic nature of LLMs and the rigorous, choice-driven demands of
legal interpretation. The findings indicate that while these techniques can
address specific challenges, significant challenges remain, particularly in
tasks requiring discretion and transparent, justifiable reasoning. Our paper
concludes that the most effective current role for AI in law is a dual one: as
a high-volume assistant for simple, repetitive cases and as a sophisticated
"sparring partner" for human experts in complex matters.

</details>


### [38] [Interactive Evaluation of Large Language Models for Multi-Requirement Software Engineering Tasks](https://arxiv.org/abs/2508.18905)
*Dimitrios Rontogiannis,Maxime Peyrard,Nicolas Baldwin,Martin Josifoski,Robert West,Dimitrios Gunopulos*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的交互式评估框架，通过结构化反馈导向对话来评估大语言模型在多要求编程任务上的能力，充分曝露了静态测试无法测量的系统性弱点。


<details>
  <summary>Details</summary>
Motivation: 标准的单轮静态测试在评估大语言模型在复杂任务（如软件工程）上的细致能力方面存在不足，需要更动态的评估方法。

Method: 设计了一种交互式评估框架，将每个任务模型化为需求依赖图。一个知道真实解决方案的"面试官"LLM向"面试者"模型提供最小化的针对性提示，帮助其纠正错误并满足目标约束。

Result: 在DevAI测试集（55个编程任务）上进行了评估，通过专家标注验证了面试官提示的相关性和有用性。动态评估揭示了模型的系统性弱点。

Conclusion: 动态评估对于推进协作式代码生成代理的发展至关重要，能够提供细致的诊断见解，这是静态测试无法实现的。

Abstract: Standard single-turn, static benchmarks fall short in evaluating the nuanced
capabilities of Large Language Models (LLMs) on complex tasks such as software
engineering. In this work, we propose a novel interactive evaluation framework
that assesses LLMs on multi-requirement programming tasks through structured,
feedback-driven dialogue. Each task is modeled as a requirement dependency
graph, and an ``interviewer'' LLM, aware of the ground-truth solution, provides
minimal, targeted hints to an ``interviewee'' model to help correct errors and
fulfill target constraints. This dynamic protocol enables fine-grained
diagnostic insights into model behavior, uncovering strengths and systematic
weaknesses that static benchmarks fail to measure. We build on DevAI, a
benchmark of 55 curated programming tasks, by adding ground-truth solutions and
evaluating the relevance and utility of interviewer hints through expert
annotation. Our results highlight the importance of dynamic evaluation in
advancing the development of collaborative code-generating agents.

</details>


### [39] [FormaRL: Enhancing Autoformalization with no Labeled Data](https://arxiv.org/abs/2508.18914)
*Yanxing Huang,Xinling Jin,Sijie Liang,Peng Li,Yang Liu*

Main category: cs.AI

TL;DR: FormaRL是一个基于强化学习的自动形式化框架，仅需少量无标注数据，通过集成Lean编译器语法检查和LLM一致性检查来计算奖励，使用GRPO算法更新形式化器，在ProofNet和uproof数据集上显著提升了自动形式化准确率。


<details>
  <summary>Details</summary>
Motivation: 自动形式化是形式化验证的核心任务，但由于数据稀缺和缺乏高效方法而进展缓慢。本研究旨在解决这一问题，提出一个简单高效的强化学习框架。

Method: 提出FormaRL框架，集成Lean编译器的语法检查和大语言模型的一致性检查来计算奖励信号，采用GRPO算法训练形式化器。同时构建了uproof数学证明数据集。

Result: 在ProofNet数据集上pass@1准确率从4.04%提升至26.15%（6倍提升），在uproof数据集上从2.4%提升至9.6%（4倍提升），仅使用859个无标注数据。在OOD测试中也显著优于现有最佳方法。

Conclusion: FormaRL证明了强化学习在自动形式化任务中的有效性，仅需少量无标注数据即可显著提升性能，为高级数学的形式化验证和定理证明提供了新的解决方案。

Abstract: Autoformalization is one of the central tasks in formal verification, while
its advancement remains hindered due to the data scarcity and the absence
efficient methods. In this work we propose \textbf{FormaRL}, a simple yet
efficient reinforcement learning framework for autoformalization which only
requires a small amount of unlabeled data. FormaRL integrates syntax check from
Lean compiler and consistency check from large language model to calculate the
reward, and adopts GRPO algorithm to update the formalizer. We also curated a
proof problem dataset from undergraduate-level math materials, named
\textbf{uproof}, in the hope to facilitate the exploration of autoformalization
and theorem proving in advanced math. Experiments show that FormaRL can
increase the pass@1 autoformalization accuracy of Qwen2.5-Coder-7B-Instruct by
4 $\sim$ 6x (4.04\% $\to$ 26.15\% on ProofNet and 2.4\% $\to$ 9.6\% on uproof)
with merely 859 unlabeled data. And on uproof our method also achieved a strong
improvement in out-of-distribution performance compared to existing open-source
state-of-the-art autoformalizers on both pass@1 accuracy (6.2\% $\to$ 9.6\%)
and pass@16 accuracy (24.4\% $\to$ 33.6\%). Training code of FormaRL is
open-sourced at https://github.com/THUNLP-MT/FormaRL.

</details>


### [40] [Who Is Lagging Behind: Profiling Student Behaviors with Graph-Level Encoding in Curriculum-Based Online Learning Systems](https://arxiv.org/abs/2508.18925)
*Qian Xiao,Conn Breathnach,Ioana Ghergulescu,Conor O'Sullivan,Keith Johnston,Vincent Wade*

Main category: cs.AI

TL;DR: CTGraph是一种图级表示学习方法，用于自监督地分析学习者行为和表现，能够全面追踪学生学习历程，识别困难学生并提供群体对比分析。


<details>
  <summary>Details</summary>
Motivation: 智能辅导系统在教育中的广泛应用可能无意中加剧学生表现差距，需要通过学生画像来跟踪进度、识别困难学生并减少学生间的差异。

Method: 提出CTGraph图级表示学习方法，采用自监督方式分析学习者在内容覆盖、学习强度和概念熟练度等多方面的行为和表现数据。

Result: 实验证明CTGraph能够提供学生学习历程的全面视图，考虑不同行为表现方面和学习路径差异，有效识别困难学生并提供群体对比分析。

Conclusion: 该方法为教育工作者提供了深入了解学生学习历程的丰富洞察，为实现更有针对性的教学干预铺平了道路。

Abstract: The surge in the adoption of Intelligent Tutoring Systems (ITSs) in
education, while being integral to curriculum-based learning, can inadvertently
exacerbate performance gaps. To address this problem, student profiling becomes
crucial for tracking progress, identifying struggling students, and alleviating
disparities among students. Such profiling requires measuring student behaviors
and performance across different aspects, such as content coverage, learning
intensity, and proficiency in different concepts within a learning topic.
  In this study, we introduce CTGraph, a graph-level representation learning
approach to profile learner behaviors and performance in a self-supervised
manner. Our experiments demonstrate that CTGraph can provide a holistic view of
student learning journeys, accounting for different aspects of student
behaviors and performance, as well as variations in their learning paths as
aligned to the curriculum structure. We also show that our approach can
identify struggling students and provide comparative analysis of diverse groups
to pinpoint when and where students are struggling. As such, our approach opens
more opportunities to empower educators with rich insights into student
learning journeys and paves the way for more targeted interventions.

</details>


### [41] [VISION: Robust and Interpretable Code Vulnerability Detection Leveraging Counterfactual Augmentation](https://arxiv.org/abs/2508.18933)
*David Egea,Barproda Halder,Sanghamitra Dutta*

Main category: cs.AI

TL;DR: VISION是一个统一的漏洞检测框架，通过生成反事实样本和使用图神经网络来减少虚假相关性，提高检测准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 解决图神经网络在源代码漏洞检测中因数据不平衡和标签噪声导致的虚假相关性学习问题，提高检测器的泛化能力

Method: 使用大型语言模型生成反事实样本，进行针对性图神经网络训练，并结合基于图的解释性方法识别关键代码语句

Result: 在CWE-20漏洞检测中，整体准确率从51.8%提升到97.8%，配对对比准确率从4.5%提升到95.8%，最差组准确率从0.7%提升到85.5%

Conclusion: VISION框架有效减少了虚假学习，实现了更鲁棒和可泛化的漏洞检测，并通过交互式可视化推进了基于AI的网络安全系统的透明度和可信度

Abstract: Automated detection of vulnerabilities in source code is an essential
cybersecurity challenge, underpinning trust in digital systems and services.
Graph Neural Networks (GNNs) have emerged as a promising approach as they can
learn structural and logical code relationships in a data-driven manner.
However, their performance is severely constrained by training data imbalances
and label noise. GNNs often learn 'spurious' correlations from superficial code
similarities, producing detectors that fail to generalize well to unseen
real-world data. In this work, we propose a unified framework for robust and
interpretable vulnerability detection, called VISION, to mitigate spurious
correlations by systematically augmenting a counterfactual training dataset.
Counterfactuals are samples with minimal semantic modifications but opposite
labels. Our framework includes: (i) generating counterfactuals by prompting a
Large Language Model (LLM); (ii) targeted GNN training on paired code examples
with opposite labels; and (iii) graph-based interpretability to identify the
crucial code statements relevant for vulnerability predictions while ignoring
spurious ones. We find that VISION reduces spurious learning and enables more
robust, generalizable detection, improving overall accuracy (from 51.8% to
97.8%), pairwise contrast accuracy (from 4.5% to 95.8%), and worst-group
accuracy (from 0.7% to 85.5%) on the Common Weakness Enumeration (CWE)-20
vulnerability. We further demonstrate gains using proposed metrics: intra-class
attribution variance, inter-class attribution distance, and node score
dependency. We also release CWE-20-CFA, a benchmark of 27,556 functions (real
and counterfactual) from the high-impact CWE-20 category. Finally, VISION
advances transparent and trustworthy AI-based cybersecurity systems through
interactive visualization for human-in-the-loop analysis.

</details>


### [42] [Novel Approaches to Artificial Intelligence Development Based on the Nearest Neighbor Method](https://arxiv.org/abs/2508.18953)
*I. I. Priezzhev,D. A. Danko,A. V. Shubin*

Main category: cs.AI

TL;DR: 这篇论文提出了一种基于层次聚类结构的k近邻算法方法，解决传统神经网络的幻觉效应、高计算复杂度等问题，并通过Kohonen自组织地图加速近邻搜索。


<details>
  <summary>Details</summary>
Motivation: 现代神经网络存在幻觉效应、计算复杂度高、微调成本高、坏失忘等基本限制，影响在医疗、工业管理等关键领域的应用。

Method: 采用基于k近邻算法的层次聚类结构，使用Kohonen自组织地图构建树状数据结构来加速近邻搜索。

Result: 在手写数字识别和字幕翻译任务中验证有效性，在准确率上仅有轻微下降的情况下，近邻搜索时间比全局搜索减少了百倍。

Conclusion: 该方法具有透明性和可解释性，符合人类认知机制，在需要高可靠性和可解释结果的任务中展现了广泛应用潜力。

Abstract: Modern neural network technologies, including large language models, have
achieved remarkable success in various applied artificial intelligence
applications, however, they face a range of fundamental limitations. Among them
are hallucination effects, high computational complexity of training and
inference, costly fine-tuning, and catastrophic forgetting issues. These
limitations significantly hinder the use of neural networks in critical areas
such as medicine, industrial process management, and scientific research. This
article proposes an alternative approach based on the nearest neighbors method
with hierarchical clustering structures. Employing the k-nearest neighbors
algorithm significantly reduces or completely eliminates hallucination effects
while simplifying model expansion and fine-tuning without the need for
retraining the entire network. To overcome the high computational load of the
k-nearest neighbors method, the paper proposes using tree-like data structures
based on Kohonen self-organizing maps, thereby greatly accelerating nearest
neighbor searches. Tests conducted on handwritten digit recognition and simple
subtitle translation tasks confirmed the effectiveness of the proposed
approach. With only a slight reduction in accuracy, the nearest neighbor search
time was reduced hundreds of times compared to exhaustive search methods. The
proposed method features transparency and interpretability, closely aligns with
human cognitive mechanisms, and demonstrates potential for extensive use in
tasks requiring high reliability and explainable results.

</details>


### [43] [Enabling MoE on the Edge via Importance-Driven Expert Scheduling](https://arxiv.org/abs/2508.18983)
*Guoying Zhu,Meng Li,Haipeng Dai,Xuechen Liu,Weijun Wang,Keran Li,Jun xiao,Ligeng Chen,Wei Wang*

Main category: cs.AI

TL;DR: 提出了一种基于专家重要性的动态卸载方法，通过用GPU内存中已缓存的功能相似专家替代低重要性专家，减少内存使用和数据传输，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 在消费级边缘硬件上部署混合专家模型受限于设备内存，需要动态专家卸载。现有方法仅将卸载视为调度问题，而本文利用专家重要性来指导决策。

Method: 利用专家重要性指导卸载决策，用GPU内存中已缓存的功能相似专家替代低重要性激活专家。引入调度策略最大化GPU缓存专家的重用率。

Result: 实验评估显示，该方法实现了48%的解码延迟降低，超过60%的专家缓存命中率，同时保持几乎无损的准确性。

Conclusion: 该方法有效减少了内存使用和数据传输，大幅消除了PCIe开销，在保持精度的同时显著提升了边缘设备上混合专家模型的部署效率。

Abstract: The Mixture of Experts (MoE) architecture has emerged as a key technique for
scaling Large Language Models by activating only a subset of experts per query.
Deploying MoE on consumer-grade edge hardware, however, is constrained by
limited device memory, making dynamic expert offloading essential. Unlike prior
work that treats offloading purely as a scheduling problem, we leverage expert
importance to guide decisions, substituting low-importance activated experts
with functionally similar ones already cached in GPU memory, thereby preserving
accuracy. As a result, this design reduces memory usage and data transfer,
while largely eliminating PCIe overhead. In addition, we introduce a scheduling
policy that maximizes the reuse ratio of GPU-cached experts, further boosting
efficiency. Extensive evaluations show that our approach delivers 48% lower
decoding latency with over 60% expert cache hit rate, while maintaining nearly
lossless accuracy.

</details>


### [44] [AI Models Exceed Individual Human Accuracy in Predicting Everyday Social Norms](https://arxiv.org/abs/2508.19004)
*Pontus Strimling,Simon Karlsson,Irina Vartanova,Kimmo Eriksson*

Main category: cs.AI

TL;DR: 大型语言模型通过纯统计学习就能超越大多数人类在社交规范判断预测上的表现，挑战了认为文化能力必须依赖具身经验的理论。


<details>
  <summary>Details</summary>
Motivation: 研究探索大型语言模型是否能够仅通过统计学习获得复杂的社交规范理解，而不是像人类那样通过具身体验来学习。

Method: 通过两个研究系统评估多个AI系统预测555个日常场景中人类社交适当性判断的能力，比较AI与人类参与者在预测集体判断准确性上的表现。

Result: GPT-4.5在预测集体判断准确性上超过所有人类参与者（100百分位），Gemini 2.5 Pro超过98.7%人类，GPT-5超过97.8%，Claude Sonnet 4超过96.0%。所有模型都显示出系统性相关错误。

Conclusion: 研究表明仅通过语言数据的统计学习就能产生复杂的社会认知模型，语言作为文化知识传播的丰富储存库，但基于模式的社会理解存在潜在边界。

Abstract: A fundamental question in cognitive science concerns how social norms are
acquired and represented. While humans typically learn norms through embodied
social experience, we investigated whether large language models can achieve
sophisticated norm understanding through statistical learning alone. Across two
studies, we systematically evaluated multiple AI systems' ability to predict
human social appropriateness judgments for 555 everyday scenarios by examining
how closely they predicted the average judgment compared to each human
participant. In Study 1, GPT-4.5's accuracy in predicting the collective
judgment on a continuous scale exceeded that of every human participant (100th
percentile). Study 2 replicated this, with Gemini 2.5 Pro outperforming 98.7%
of humans, GPT-5 97.8%, and Claude Sonnet 4 96.0%. Despite this predictive
power, all models showed systematic, correlated errors. These findings
demonstrate that sophisticated models of social cognition can emerge from
statistical learning over linguistic data alone, challenging strong versions of
theories emphasizing the exclusive necessity of embodied experience for
cultural competence. The systematic nature of AI limitations across different
architectures indicates potential boundaries of pattern-based social
understanding, while the models' ability to outperform nearly all individual
humans in this predictive task suggests that language serves as a remarkably
rich repository for cultural knowledge transmission.

</details>


### [45] [Building Self-Evolving Agents via Experience-Driven Lifelong Learning: A Framework and Benchmark](https://arxiv.org/abs/2508.19005)
*Yuxuan Cai,Yipeng Hao,Jie Zhou,Hang Yan,Zhikai Lei,Rui Zhen,Zhenhua Han,Yutao Yang,Junsong Li,Qianjun Pan,Tianyu Huai,Qin Chen,Xin Li,Kai Chen,Bo Zhang,Xipeng Qiu,Liang He*

Main category: cs.AI

TL;DR: 这篇论文提出了经验驱动的终身学习（ELL）框架，通过四大核心原则建立自我进化的智能体，并创建了StuLife标准数据集模拟大学生全面发展过程。


<details>
  <summary>Details</summary>
Motivation: 随着AI向通用智能发展，需要从静态任务优化转向建立能够持续学习和成长的开放式代理体。

Method: 提出ELL框架包含四大核心原则：经验探索、长期记忆、技能学习和知识内化。创建StuLife标准数据集，模拟大学生从入学到学业发展的全过程，包含3个阶段和10个子场景。

Result: 开发了一个综合性的终身学习能力评估平台，能够测试记忆保持、技能迁移和自主行为等能力。还评估了现有最优大语言模型在该标准上的表现。

Conclusion: ELL框架和StuLife标准为建立能够持续学习和自我进化的智能体提供了重要基础，同时也探索了上下文工程在推动通用智能发展中的作用。

Abstract: As AI advances toward general intelligence, the focus is shifting from
systems optimized for static tasks to creating open-ended agents that learn
continuously. In this paper, we introduce Experience-driven Lifelong Learning
(ELL), a framework for building self-evolving agents capable of continuous
growth through real-world interaction. The framework is built on four core
principles: (1) Experience Exploration: Agents learn through continuous,
self-motivated interaction with dynamic environments, navigating interdependent
tasks and generating rich experiential trajectories. (2) Long-term Memory:
Agents preserve and structure historical knowledge, including personal
experiences, domain expertise, and commonsense reasoning, into a persistent
memory system. (3) Skill Learning: Agents autonomously improve by abstracting
recurring patterns from experience into reusable skills, which are actively
refined and validated for application in new tasks. (4) Knowledge
Internalization: Agents internalize explicit and discrete experiences into
implicit and intuitive capabilities as "second nature".
  We also introduce StuLife, a benchmark dataset for ELL that simulates a
student's holistic college journey, from enrollment to academic and personal
development, across three core phases and ten detailed sub-scenarios. StuLife
is designed around three key paradigm shifts: From Passive to Proactive, From
Context to Memory, and From Imitation to Learning. In this dynamic environment,
agents must acquire and distill practical skills and maintain persistent memory
to make decisions based on evolving state variables. StuLife provides a
comprehensive platform for evaluating lifelong learning capabilities, including
memory retention, skill transfer, and self-motivated behavior. Beyond
evaluating SOTA LLMs on the StuLife benchmark, we also explore the role of
context engineering in advancing AGI.

</details>


### [46] [Sense of Self and Time in Borderline Personality. A Comparative Robustness Study with Generative AI](https://arxiv.org/abs/2508.19008)
*Marcin Moskalewicz,Anna Sterna,Marek Pokropski,Paula Flores*

Main category: cs.AI

TL;DR: 本研究评估了三种大型语言模型（GPT-4o、Gemini 2.5 Pro、Claude Opus 4）在边缘型人格障碍现象学定性分析中的表现，发现Gemini模型最接近人类分析结果，并能发现人类遗漏的主题。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在现象学定性分析中的应用潜力，特别是在边缘型人格障碍这种涉及时间性和自我意识障碍的复杂心理状态分析中，以减轻人类解释偏见。

Method: 基于24名住院患者的生活故事访谈数据，让三种LLM模仿原研究者的解释风格进行分析，采用盲法和非盲法专家评估，包括语义一致性、Jaccard系数和多维效度评分。

Result: 模型与人类分析的重合度差异较大（GPT 0%、Claude 42%、Gemini 58%），Jaccard系数较低（0.21-0.28）。但模型发现了人类遗漏的主题，Gemini的表现最接近人类分析，效度评分显著高于其他模型。

Conclusion: AI增强的主题分析具有潜力和变异性，能够补充人类分析的不足，特别是在处理大量文本数据时表现出优势，为减轻人类解释偏见提供了新的可能性。

Abstract: This study examines the capacity of large language models (LLMs) to support
phenomenological qualitative analysis of first-person experience in Borderline
Personality Disorder (BPD), understood as a disorder of temporality and
selfhood. Building on a prior human-led thematic analysis of 24 inpatients'
life-story interviews, we compared three LLMs (OpenAI GPT-4o, Google Gemini 2.5
Pro, Anthropic Claude Opus 4) prompted to mimic the interpretative style of the
original investigators. The models were evaluated with blinded and non-blinded
expert judges in phenomenology and clinical psychology. Assessments included
semantic congruence, Jaccard coefficients, and multidimensional validity
ratings (credibility, coherence, substantiveness, and groundness in data).
Results showed variable overlap with the human analysis, from 0 percent in GPT
to 42 percent in Claude and 58 percent in Gemini, and a low Jaccard coefficient
(0.21-0.28). However, the models recovered themes omitted by humans. Gemini's
output most closely resembled the human analysis, with validity scores
significantly higher than GPT and Claude (p < 0.0001), and was judged as human
by blinded experts. All scores strongly correlated (R > 0.78) with the quantity
of text and words per theme, highlighting both the variability and potential of
AI-augmented thematic analysis to mitigate human interpretative bias.

</details>


### [47] [MAB Optimizer for Estimating Math Question Difficulty via Inverse CV without NLP](https://arxiv.org/abs/2508.19014)
*Surajit Das,Gourav Roy,Aleksei Eliseev,Ram Kumar Rajendran*

Main category: cs.AI

TL;DR: 提出基于强化学习的多臂老虎机框架APME，仅使用解题表现数据（分数和时间）来估计问题难度，无需语言特征或专家标注，在符号领域表现优异


<details>
  <summary>Details</summary>
Motivation: 传统人工标注主观性强，现有NLP方法在代数等符号领域失效，需要客观且领域无关的问题难度确定方法

Method: 使用强化学习多臂老虎机框架，利用逆变异系数作为风险调整指标，仅从解题表现数据（分数和时间）估计难度

Result: 在三个异构数据集上验证，平均R²达0.9213，平均RMSE为0.0584，优于回归、NLP和IRT等基线方法

Conclusion: 该方法领域无关、自监督，可推广到其他有解题交互数据的领域，支持维果茨基最近发展区理论，平衡挑战性与可达性

Abstract: The evolution of technology and education is driving the emergence of
Intelligent & Autonomous Tutoring Systems (IATS), where objective and
domain-agnostic methods for determining question difficulty are essential.
Traditional human labeling is subjective, and existing NLP-based approaches
fail in symbolic domains like algebra. This study introduces the Approach of
Passive Measures among Educands (APME), a reinforcement learning-based
Multi-Armed Bandit (MAB) framework that estimates difficulty solely from solver
performance data -- marks obtained and time taken -- without requiring
linguistic features or expert labels. By leveraging the inverse coefficient of
variation as a risk-adjusted metric, the model provides an explainable and
scalable mechanism for adaptive assessment. Empirical validation was conducted
on three heterogeneous datasets. Across these diverse contexts, the model
achieved an average R2 of 0.9213 and an average RMSE of 0.0584, confirming its
robustness, accuracy, and adaptability to different educational levels and
assessment formats. Compared with baseline approaches-such as regression-based,
NLP-driven, and IRT models-the proposed framework consistently outperformed
alternatives, particularly in purely symbolic domains. The findings highlight
that (i) item heterogeneity strongly influences perceived difficulty, and (ii)
variance in solver outcomes is as critical as mean performance for adaptive
allocation. Pedagogically, the model aligns with Vygotskys Zone of Proximal
Development by identifying tasks that balance challenge and attainability,
supporting motivation while minimizing disengagement. This domain-agnostic,
self-supervised approach advances difficulty tagging in IATS and can be
extended beyond algebra wherever solver interaction data is available

</details>


### [48] [Investigating Advanced Reasoning of Large Language Models via Black-Box Interaction](https://arxiv.org/abs/2508.19035)
*Congchi Yin,Tianyi Wu,Yankai Shu,Alex Gu,Yunhan Wang,Jun Shao,Xun Jiang,Piji Li*

Main category: cs.AI

TL;DR: 黑盒交互评估框架用于测试LLM在未知环境中的综合推理能力，发现LLM缺乏高级规划能力


<details>
  <summary>Details</summary>
Motivation: 现有任务无法全面评估大语言模型在交互式未知环境中的推理能力，需要一种新的评估方式

Method: 提出黑盒交互评估框架，通过隐藏函数模拟未知环境，建立包含6类任务的Oracle测试集，对19个现代LLM进行测试

Result: o3模型在5个任务中排名第一，在简单黑盒上达到70%+准确率，但在困难黑盒上性能下降到40%以下

Conclusion: LLM普遍缺乏高级规划能力，无法制定高效的适应性探索策略来精炼假设，需要进一步提升

Abstract: Existing tasks fall short in evaluating reasoning ability of Large Language
Models (LLMs) in an interactive, unknown environment. This deficiency leads to
the isolated assessment of deductive, inductive, and abductive reasoning,
neglecting the integrated reasoning process that is indispensable for humans
discovery of real world. We introduce a novel evaluation paradigm,
\textit{black-box interaction}, to tackle this challenge. A black-box is
defined by a hidden function that maps a specific set of inputs to outputs.
LLMs are required to unravel the hidden function behind the black-box by
interacting with it in given exploration turns, and reasoning over observed
input-output pairs. Leveraging this idea, we build the \textsc{Oracle}
benchmark which comprises 6 types of black-box task and 96 black-boxes. 19
modern LLMs are benchmarked. o3 ranks first in 5 of the 6 tasks, achieving over
70\% accuracy on most easy black-boxes. But it still struggles with some hard
black-box tasks, where its average performance drops below 40\%. Further
analysis indicates a universal difficulty among LLMs: They lack the high-level
planning capability to develop efficient and adaptive exploration strategies
for hypothesis refinement.

</details>


### [49] [A Concurrent Modular Agent: Framework for Autonomous LLM Agents](https://arxiv.org/abs/2508.19042)
*Norihiro Maruyama,Takahide Yoshida,Hiroki Sato,Atsushi Masumori,Johnsmith,Takashi Ikegami*

Main category: cs.AI

TL;DR: CMA框架通过多个异步运行的LLM模块实现协调的行为循环，解决了智能体架构中的长期难题，让意图从语言介导的自主进程交互中涌现。


<details>
  <summary>Details</summary>
Motivation: 解决传统智能体架构的局限性，通过并发模块化设计实现更灵活、自适应和上下文相关的行为，验证Minsky的"心智社会"理论。

Method: 使用多个基于LLM的模块完全异步运行，通过模块间通信和单一共享全局状态来实现协调，将推理任务卸载给LLM处理。

Result: 通过两个实际用例研究证明了系统的可行性，观察到涌现特性表明复杂认知现象（如自我意识）可能确实从简单过程的组织交互中产生。

Conclusion: 该方法支持Minsky的心智社会概念，为人工智能研究开辟了新途径，是心智社会理论的实际实现。

Abstract: We introduce the Concurrent Modular Agent (CMA), a framework that
orchestrates multiple Large-Language-Model (LLM)-based modules that operate
fully asynchronously yet maintain a coherent and fault-tolerant behavioral
loop. This framework addresses long-standing difficulties in agent
architectures by letting intention emerge from language-mediated interactions
among autonomous processes. This approach enables flexible, adaptive, and
context-dependent behavior through the combination of concurrently executed
modules that offload reasoning to an LLM, inter-module communication, and a
single shared global state.We consider this approach to be a practical
realization of Minsky's Society of Mind theory. We demonstrate the viability of
our system through two practical use-case studies. The emergent properties
observed in our system suggest that complex cognitive phenomena like
self-awareness may indeed arise from the organized interaction of simpler
processes, supporting Minsky-Society of Mind concept and opening new avenues
for artificial intelligence research. The source code for our work is available
at: https://github.com/AlternativeMachine/concurrent-modular-agent.

</details>


### [50] [Can Structured Templates Facilitate LLMs in Tackling Harder Tasks? : An Exploration of Scaling Laws by Difficulty](https://arxiv.org/abs/2508.19069)
*Zhichao Yang,Zhaoxin Fan,Gen Li,Yuanze Hu,Xinyu Wang,Ye Qiu,Xin Wang,Yifan Sun,Wenjun Wu*

Main category: cs.AI

TL;DR: 本文发现训练数据难度与模型性能呈U型曲线关系，提出结构化解决方案模板(SST)框架，通过模板化解决方案链和难度课程来显式教授程序推理，显著提升数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有后训练方法在复杂任务上仍难以捕捉深层程序逻辑，研究发现模型性能与训练数据难度存在U型曲线关系（难度缩放定律），过度简单数据阻碍抽象能力，而高难度数据显著增强推理能力。

Method: 提出结构化解决方案模板(SST)框架：1)使用结构化解决方案模板链和动态加权损失进行微调；2)推理时注入解决方案模板作为认知支架；3)集成课程微调，显式教授模型自我规划-执行-自我纠正。

Result: 在GSM8K、AIME24和新的Dynamic En基准测试上，SST显著提高了准确性和效率，特别是在更难的问题上表现突出。

Conclusion: SST框架通过结构化模板和难度课程有效提升了LLM的程序推理能力，证明了显式教授程序逻辑的重要性，为解决复杂数学推理问题提供了有效方案。

Abstract: Structured, procedural reasoning is essential for Large Language Models
(LLMs), especially in mathematics. While post-training methods have improved
LLM performance, they still fall short in capturing deep procedural logic on
complex tasks. To tackle the issue, in this paper, we first investigate this
limitation and uncover a novel finding: a Scaling Law by Difficulty, which
reveals that model performance follows a U-shaped curve with respect to
training data complexity -- excessive low-difficulty data impedes abstraction,
while high-difficulty data significantly enhances reasoning ability. Motivated
by this, we propose the Structured Solution Template (SST) framework, which
uses solution templates and a curriculum of varied difficulty to explicitly
teach procedural reasoning. Specifically, SST comprises (1) fine-tuning with
structured solution-template chains and dynamically weighted loss to prioritize
procedural logic, (2) prompt-time injection of solution templates as cognitive
scaffolds to guide inference, and (3) integrated curriculum fine-tuning that
explicitly teaches the model to self-plan - execute - self-correct. Experiments
on GSM8K, AIME24, and new Dynamic En benchmark show that SST significantly
improves both accuracy and efficiency, especially on harder problems.

</details>


### [51] [Trustworthy Agents for Electronic Health Records through Confidence Estimation](https://arxiv.org/abs/2508.19096)
*Yongwoo Song,Minbyul Jeong,Mujeen Sung*

Main category: cs.AI

TL;DR: 提出了HCAcc@k%新指标来量化临床问答中的准确性与可靠性权衡，并开发了TrustEHRAgent置信感知代理，在严格可靠性约束下显著优于基线方法


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在电子健康记录信息提取和临床决策支持方面具有潜力，但存在幻觉风险，限制了在临床环境中的部署应用

Method: 提出Hallucination Controlled Accuracy at k% (HCAcc@k%)指标，并开发TrustEHRAgent置信感知代理，采用逐步置信度估计方法进行临床问答

Result: 在MIMIC-III和eICU数据集上，TrustEHRAgent在HCAcc@70%指标下分别比基线方法提升44.23%和25.34%，基线方法在这些阈值下完全失效

Conclusion: 传统准确性指标在评估医疗AI代理方面存在局限性，本研究有助于开发可信赖的临床代理，能够在低置信度时提供准确信息或透明表达不确定性

Abstract: Large language models (LLMs) show promise for extracting information from
Electronic Health Records (EHR) and supporting clinical decisions. However,
deployment in clinical settings faces challenges due to hallucination risks. We
propose Hallucination Controlled Accuracy at k% (HCAcc@k%), a novel metric
quantifying the accuracy-reliability trade-off at varying confidence
thresholds. We introduce TrustEHRAgent, a confidence-aware agent incorporating
stepwise confidence estimation for clinical question answering. Experiments on
MIMIC-III and eICU datasets show TrustEHRAgent outperforms baselines under
strict reliability constraints, achieving improvements of 44.23%p and 25.34%p
at HCAcc@70% while baseline methods fail at these thresholds. These results
highlight limitations of traditional accuracy metrics in evaluating healthcare
AI agents. Our work contributes to developing trustworthy clinical agents that
deliver accurate information or transparently express uncertainty when
confidence is low.

</details>


### [52] [Reasoning LLMs in the Medical Domain: A Literature Survey](https://arxiv.org/abs/2508.19097)
*Armin Berger,Sarthak Khanna,David Berghaus,Rafet Sifa*

Main category: cs.AI

TL;DR: 本综述探讨了大型语言模型在医疗领域的推理能力发展，从基础信息检索工具转变为支持复杂医疗决策的临床推理系统，重点关注提示技术和强化学习突破。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs推理能力的提升，医疗应用需要更透明和可解释的决策过程，这对医疗环境至关重要。本文旨在分析这一转型过程并为开发可靠的医疗LLMs提供路线图。

Method: 通过全面分析技术基础，特别关注专业化提示技术（如思维链）和强化学习突破（如DeepSeek-R1），评估专用医疗框架和新兴范式（多智能体协作系统和创新提示架构）。

Result: 对医疗验证的当前评估方法进行了批判性评估，解决了领域解释限制、偏差缓解策略、患者安全框架和多模态临床数据集成等持续挑战。

Conclusion: 本文为开发能够在临床实践和医学研究中作为有效合作伙伴的可靠LLMs建立了发展路线图，推动医疗AI向更安全、透明的方向发展。

Abstract: The emergence of advanced reasoning capabilities in Large Language Models
(LLMs) marks a transformative development in healthcare applications. Beyond
merely expanding functional capabilities, these reasoning mechanisms enhance
decision transparency and explainability-critical requirements in medical
contexts. This survey examines the transformation of medical LLMs from basic
information retrieval tools to sophisticated clinical reasoning systems capable
of supporting complex healthcare decisions. We provide a thorough analysis of
the enabling technological foundations, with a particular focus on specialized
prompting techniques like Chain-of-Thought and recent breakthroughs in
Reinforcement Learning exemplified by DeepSeek-R1. Our investigation evaluates
purpose-built medical frameworks while also examining emerging paradigms such
as multi-agent collaborative systems and innovative prompting architectures.
The survey critically assesses current evaluation methodologies for medical
validation and addresses persistent challenges in field interpretation
limitations, bias mitigation strategies, patient safety frameworks, and
integration of multimodal clinical data. Through this survey, we seek to
establish a roadmap for developing reliable LLMs that can serve as effective
partners in clinical practice and medical research.

</details>


### [53] [Hybrid Deep Searcher: Integrating Parallel and Sequential Search Reasoning](https://arxiv.org/abs/2508.19113)
*Dayoon Ko,Jihyuk Kim,Haeju Park,Sohyeon Kim,Dahyun Lee,Yongrae Jo,Gunhee Kim,Moontae Lee,Kyungjae Lee*

Main category: cs.AI

TL;DR: HDS-QA是一个合成数据集，用于训练大型推理模型区分并行和顺序查询，HybridDeepSearcher模型在多个基准测试中表现优异，显著减少推理延迟。


<details>
  <summary>Details</summary>
Motivation: 现有方法顺序集成外部知识检索会增加推理延迟和上下文长度，降低连贯性和准确性，需要解决这些限制。

Method: 从Natural Questions自动生成HDS-QA合成数据集，包含并行可执行和顺序依赖的子查询，使用该数据集微调LRM得到HybridDeepSearcher模型。

Result: 在多个基准测试中超越最先进基线，在FanOutQA和BrowseComp子集上分别获得+15.9和+11.5 F1提升，以更少的搜索轮次达到可比精度。

Conclusion: 显式训练LRM利用混合并行和顺序查询具有高效性、可扩展性和有效性，显著减少推理延迟并保持准确性。

Abstract: Large reasoning models (LRMs) have demonstrated strong performance in
complex, multi-step reasoning tasks. Existing methods enhance LRMs by
sequentially integrating external knowledge retrieval; models iteratively
generate queries, retrieve external information, and progressively reason over
this information. However, purely sequential querying increases inference
latency and context length, diminishing coherence and potentially reducing
accuracy. To address these limitations, we introduce HDS-QA (Hybrid Deep Search
QA), a synthetic dataset automatically generated from Natural Questions,
explicitly designed to train LRMs to distinguish parallelizable from sequential
queries. HDS-QA comprises hybrid-hop questions that combine parallelizable
independent subqueries (executable simultaneously) and sequentially dependent
subqueries (requiring step-by-step resolution), along with synthetic
reasoning-querying-retrieval paths involving parallel queries. We fine-tune an
LRM using HDS-QA, naming the model HybridDeepSearcher, which outperforms
state-of-the-art baselines across multiple benchmarks, notably achieving +15.9
and +11.5 F1 on FanOutQA and a subset of BrowseComp, respectively, both
requiring comprehensive and exhaustive search. Experimental results highlight
two key advantages: HybridDeepSearcher reaches comparable accuracy with fewer
search turns, significantly reducing inference latency, and it effectively
scales as more turns are permitted. These results demonstrate the efficiency,
scalability, and effectiveness of explicitly training LRMs to leverage hybrid
parallel and sequential querying.

</details>


### [54] [Algorithmic Collective Action with Multiple Collectives](https://arxiv.org/abs/2508.19149)
*Claudio Battiloro,Pietro Greiner,Bret Nestor,Oumaima Amezgar,Francesca Dominici*

Main category: cs.AI

TL;DR: 提出了首个多集体算法集体行动（ACA）理论框架，研究多个集体如何在分类系统中协调行动，通过植入信号来影响分类器学习特征与目标类别之间的关联。


<details>
  <summary>Details</summary>
Motivation: 随着学习系统对日常决策的影响日益增强，用户端的算法集体行动（ACA）作为监管端政策和企业端模型设计的补充手段变得重要。传统上现实世界的行动是分散的，由多个具有共同目标但规模、策略和行动目标不同的集体组成，而现有ACA文献主要关注单一集体场景。

Method: 建立了多集体ACA的理论框架，特别关注分类中的集体行动，研究多个集体如何通过植入信号来偏置分类器，使其学习特征修改版本与选定目标类别之间的关联。分析了集体规模和目标对齐度的作用与相互关系。

Result: 提供了关于集体规模和目标对齐度作用的定量结果，框架补充了先前的实证研究结果。

Conclusion: 该框架为多集体ACA的整体处理开辟了路径，填补了现有文献在多个集体协调行动方面的理论空白。

Abstract: As learning systems increasingly influence everyday decisions, user-side
steering via Algorithmic Collective Action (ACA)-coordinated changes to shared
data-offers a complement to regulator-side policy and firm-side model design.
Although real-world actions have been traditionally decentralized and
fragmented into multiple collectives despite sharing overarching
objectives-with each collective differing in size, strategy, and actionable
goals, most of the ACA literature focused on single collective settings. In
this work, we present the first theoretical framework for ACA with multiple
collectives acting on the same system. In particular, we focus on collective
action in classification, studying how multiple collectives can plant signals,
i.e., bias a classifier to learn an association between an altered version of
the features and a chosen, possibly overlapping, set of target classes. We
provide quantitative results about the role and the interplay of collectives'
sizes and their alignment of goals. Our framework, by also complementing
previous empirical results, opens a path for a holistic treatment of ACA with
multiple collectives.

</details>


### [55] [Playstyle and Artificial Intelligence: An Initial Blueprint Through the Lens of Video Games](https://arxiv.org/abs/2508.19152)
*Chiu-Chou Lin*

Main category: cs.AI

TL;DR: 该论文提出游戏风格作为分析智能体决策行为的新视角，构建了风格形成的双层框架，并提出了可测量的风格指标，探索了风格的定义、表达和实际应用。


<details>
  <summary>Details</summary>
Motivation: 当前AI发展过于关注理性决策，忽视了信念、价值观和偏好等深层因素对决策风格的影响，而风格是智能的重要但常被忽视的维度。

Method: 构建风格形成的双层框架（外部环境交互循环和内部认知思考循环），提出风格容量、风格流行度和进化动态等可测量指标，研究风格定义测量、表达生成和实际应用三个方向。

Result: 提出了基于离散状态空间的通用游戏风格度量方法，探索了强化学习和模仿学习在训练特定风格智能体中的应用，开发了类人风格学习和建模的新方法。

Conclusion: 风格应作为构建人工通用智能（AGI）的核心要素，该研究为理解和发展智能体的决策风格提供了理论基础和实践方法。

Abstract: Contemporary artificial intelligence (AI) development largely centers on
rational decision-making, valued for its measurability and suitability for
objective evaluation. Yet in real-world contexts, an intelligent agent's
decisions are shaped not only by logic but also by deeper influences such as
beliefs, values, and preferences. The diversity of human decision-making styles
emerges from these differences, highlighting that "style" is an essential but
often overlooked dimension of intelligence.
  This dissertation introduces playstyle as an alternative lens for observing
and analyzing the decision-making behavior of intelligent agents, and examines
its foundational meaning and historical context from a philosophical
perspective. By analyzing how beliefs and values drive intentions and actions,
we construct a two-tier framework for style formation: the external interaction
loop with the environment and the internal cognitive loop of deliberation. On
this basis, we formalize style-related characteristics and propose measurable
indicators such as style capacity, style popularity, and evolutionary dynamics.
  The study focuses on three core research directions: (1) Defining and
measuring playstyle, proposing a general playstyle metric based on discretized
state spaces, and extending it to quantify strategic diversity and competitive
balance; (2) Expressing and generating playstyle, exploring how reinforcement
learning and imitation learning can be used to train agents exhibiting specific
stylistic tendencies, and introducing a novel approach for human-like style
learning and modeling; and (3) Practical applications, analyzing the potential
of these techniques in domains such as game design and interactive
entertainment.
  Finally, the dissertation outlines future extensions, including the role of
style as a core element in building artificial general intelligence (AGI).

</details>


### [56] [MATRIX: Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation](https://arxiv.org/abs/2508.19163)
*Ernest Lim,Yajie Vera He,Jared Joselowitz,Kate Preston,Mohita Chowdhury,Louis Williams,Aisling Higham,Katrina Mason,Mariane Melo,Tom Lawton,Yan Jia,Ibrahim Habli*

Main category: cs.AI

TL;DR: MATRIX是一个用于临床对话系统安全评估的多智能体仿真框架，整合了安全对齐分类法、基于LLM的评估器和模拟患者代理，实现了系统性、可扩展的安全评估。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型临床对话系统评估主要关注任务完成度和流畅性，缺乏对安全关键系统所需的行为和风险管理要求的深入分析。

Method: MATRIX框架包含三个核心组件：1）通过安全工程方法推导的临床场景分类法；2）基于LLM的安全相关对话失败检测评估器BehvJudge；3）能够产生多样化场景条件响应的模拟患者代理PatBot。

Result: BehvJudge达到专家级危险检测水平（F1 0.96，灵敏度0.999），在240个对话的盲评中优于临床医生。PatBot在定量和定性评估中可靠地模拟真实患者行为。框架成功对5个LLM代理在2100个模拟对话中进行了基准测试。

Conclusion: MATRIX是首个将结构化安全工程与可扩展、经过验证的对话AI评估相统一的框架，支持监管机构对齐的安全审计，为临床对话系统的安全评估提供了系统化解决方案。

Abstract: Despite the growing use of large language models (LLMs) in clinical dialogue
systems, existing evaluations focus on task completion or fluency, offering
little insight into the behavioral and risk management requirements essential
for safety-critical systems. This paper presents MATRIX (Multi-Agent simulaTion
fRamework for safe Interactions and conteXtual clinical conversational
evaluation), a structured, extensible framework for safety-oriented evaluation
of clinical dialogue agents.
  MATRIX integrates three components: (1) a safety-aligned taxonomy of clinical
scenarios, expected system behaviors and failure modes derived through
structured safety engineering methods; (2) BehvJudge, an LLM-based evaluator
for detecting safety-relevant dialogue failures, validated against expert
clinician annotations; and (3) PatBot, a simulated patient agent capable of
producing diverse, scenario-conditioned responses, evaluated for realism and
behavioral fidelity with human factors expertise, and a patient-preference
study.
  Across three experiments, we show that MATRIX enables systematic, scalable
safety evaluation. BehvJudge with Gemini 2.5-Pro achieves expert-level hazard
detection (F1 0.96, sensitivity 0.999), outperforming clinicians in a blinded
assessment of 240 dialogues. We also conducted one of the first realism
analyses of LLM-based patient simulation, showing that PatBot reliably
simulates realistic patient behavior in quantitative and qualitative
evaluations. Using MATRIX, we demonstrate its effectiveness in benchmarking
five LLM agents across 2,100 simulated dialogues spanning 14 hazard scenarios
and 10 clinical domains.
  MATRIX is the first framework to unify structured safety engineering with
scalable, validated conversational AI evaluation, enabling regulator-aligned
safety auditing. We release all evaluation tools, prompts, structured
scenarios, and datasets.

</details>


### [57] [The Ramon Llull's Thinking Machine for Automated Ideation](https://arxiv.org/abs/2508.19200)
*Xinran Zhao,Boyuan Zheng,Chenglei Si,Haofei Yu,Ken Liu,Runlong Zhou,Ruochen Li,Tong Chen,Xiang Li,Yiming Zhang,Tongshuang Wu*

Main category: cs.AI

TL;DR: 本文重新探讨中世纪Ramon Llull的组合术，构建了一种现代化的思维机器，通过主题、领域和方法三个组成轴来生成科研创意。


<details>
  <summary>Details</summary>
Motivation: 重新活化中世纪的组合术理论，为现代科研创意提供概念基础，通过AI增强科学创造力。

Method: 定义主题、领域和方法三个组成轴，从专家或论文中挖掘元素，使用LLM提示组合来生成科研想法。

Result: 组合提示产生的科研想法具有多样性、相关性和文献基础，证明了该方法的有效性。

Conclusion: 该现代思维机器提供了轻量级、可解释的科学创意工具，为人工智能与人类协作创意开启了新路径。

Abstract: This paper revisits Ramon Llull's Ars combinatoria - a medieval framework for
generating knowledge through symbolic recombination - as a conceptual
foundation for building a modern Llull's thinking machine for research
ideation. Our approach defines three compositional axes: Theme (e.g.,
efficiency, adaptivity), Domain (e.g., question answering, machine
translation), and Method (e.g., adversarial training, linear attention). These
elements represent high-level abstractions common in scientific work -
motivations, problem settings, and technical approaches - and serve as building
blocks for LLM-driven exploration. We mine elements from human experts or
conference papers and show that prompting LLMs with curated combinations
produces research ideas that are diverse, relevant, and grounded in current
literature. This modern thinking machine offers a lightweight, interpretable
tool for augmenting scientific creativity and suggests a path toward
collaborative ideation between humans and AI.

</details>


### [58] [The Subset Sum Matching Problem](https://arxiv.org/abs/2508.19218)
*Yufei Wu,Manuel R. Torres,Parisa Zehtabi,Alberto Pozanco Lancho,Michael Cashmore,Daniel Borrajo,Manuela Veloso*

Main category: cs.AI

TL;DR: 提出了子集和匹配问题(SSMP)作为金融交易对账等应用的抽象，开发了两个次优算法和一个最优算法，并通过基准测试评估性能


<details>
  <summary>Details</summary>
Motivation: 解决金融领域中的交易对账等实际问题，需要一个通用的组合优化模型来匹配不同集合中的元素

Method: 提出了SSMP问题定义，开发了两种次优算法和一种最优算法，创建了不同复杂度的基准测试集进行实验评估

Result: 通过实验评估了三种算法在不同复杂度SSMP实例上的性能表现

Conclusion: SSMP问题为金融应用提供了有效的抽象模型，所提出的算法能够有效解决该问题

Abstract: This paper presents a new combinatorial optimisation task, the Subset Sum
Matching Problem (SSMP), which is an abstraction of common financial
applications such as trades reconciliation. We present three algorithms, two
suboptimal and one optimal, to solve this problem. We also generate a benchmark
to cover different instances of SSMP varying in complexity, and carry out an
experimental evaluation to assess the performance of the approaches.

</details>


### [59] [StepWiser: Stepwise Generative Judges for Wiser Reasoning](https://arxiv.org/abs/2508.19229)
*Wei Xiong,Wenting Zhao,Weizhe Yuan,Olga Golovneva,Tong Zhang,Jason Weston,Sainbayar Sukhbaatar*

Main category: cs.AI

TL;DR: 将过程奖励模型从分类任务重构为推理任务，提出StepWiser生成式评判器，通过元推理输出思考标记和最终判断，在准确性、训练改进和推理搜索方面表现优异


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型存在两个主要缺陷：作为分类器不提供解释，且依赖静态数据集监督微调限制了泛化能力。需要开发能理解推理步骤逻辑有效性的方法

Method: 将逐步奖励建模重构为推理任务，提出生成式评判器StepWiser，通过强化学习使用rollout相对结果进行训练，输出思考标记后再给出最终判断

Result: StepWiser在中间步骤判断准确性上优于现有方法，可用于改进策略模型的训练过程，并提升推理时的搜索性能

Conclusion: 将奖励建模从分类转向推理的方法有效解决了过程监督的挑战，生成式评判器在提供解释的同时提升了判断准确性和模型性能

Abstract: As models increasingly leverage multi-step reasoning strategies to solve
complex problems, supervising the logical validity of these intermediate steps
has become a critical research challenge. Process reward models address this by
providing step-by-step feedback, but current approaches have two major
drawbacks: they typically function as classifiers without providing
explanations, and their reliance on supervised fine-tuning with static datasets
limits generalization. Inspired by recent advances, we reframe stepwise reward
modeling from a classification task to a reasoning task itself. We thus propose
a generative judge that reasons about the policy model's reasoning steps (i.e.,
meta-reasons), outputting thinking tokens before delivering a final verdict.
Our model, StepWiser, is trained by reinforcement learning using relative
outcomes of rollouts. We show it provides (i) better judgment accuracy on
intermediate steps than existing methods; (ii) can be used to improve the
policy model at training time; and (iii) improves inference-time search.

</details>


### [60] [Model Context Protocols in Adaptive Transport Systems: A Survey](https://arxiv.org/abs/2508.19239)
*Gaurab Chhetri,Shriyank Somvanshi,Md Monzurul Islam,Shamyo Brotee,Mahmuda Sultana Mimi,Dipti Koirala,Biplov Pandey,Subasish Das*

Main category: cs.AI

TL;DR: 本文首次系统调查了模型上下文协议（MCP）作为统一范式的能力，分析了现有文献如何隐式地向MCP类架构收敛，提出了五类分类法，并揭示了三个关键见解。


<details>
  <summary>Details</summary>
Motivation: 互联设备、自主系统和AI应用的快速扩张导致自适应传输系统严重碎片化，不同协议和上下文来源相互隔离，需要统一的集成框架。

Method: 通过分析现有文献，提出五类分类法（自适应机制、上下文感知框架、统一模型、集成策略和MCP使能架构），系统调查MCP作为统一范式的能力。

Result: 发现传统传输协议已达到孤立适应的极限，MCP的客户端-服务器和JSON-RPC结构能够实现语义互操作性，AI驱动的传输需要特别适合MCP的集成范式。

Conclusion: MCP应作为下一代自适应、上下文感知和智能传输基础设施的基础，并提出了相应的研究路线图。

Abstract: The rapid expansion of interconnected devices, autonomous systems, and AI
applications has created severe fragmentation in adaptive transport systems,
where diverse protocols and context sources remain isolated. This survey
provides the first systematic investigation of the Model Context Protocol (MCP)
as a unifying paradigm, highlighting its ability to bridge protocol-level
adaptation with context-aware decision making. Analyzing established
literature, we show that existing efforts have implicitly converged toward
MCP-like architectures, signaling a natural evolution from fragmented solutions
to standardized integration frameworks. We propose a five-category taxonomy
covering adaptive mechanisms, context-aware frameworks, unification models,
integration strategies, and MCP-enabled architectures. Our findings reveal
three key insights: traditional transport protocols have reached the limits of
isolated adaptation, MCP's client-server and JSON-RPC structure enables
semantic interoperability, and AI-driven transport demands integration
paradigms uniquely suited to MCP. Finally, we present a research roadmap
positioning MCP as a foundation for next-generation adaptive, context-aware,
and intelligent transport infrastructures.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [61] [Multi-Resolution Codebook Design and Multiuser Interference Management for Discrete XL-RIS-Aided Near-Field MIMO Systems](https://arxiv.org/abs/2508.18582)
*Qian Zhang,Zheng Dong,Zheng Dong,Yao Ge,Yong Liang Guan,Ju Liu,Chau Yuen*

Main category: cs.IT

TL;DR: 本文研究了具有离散相移的超大规模可重构智能表面(XL-RIS)辅助的近场通信方案，提出了分层波束训练、联合优化码本构建(JOCC)和分离优化码本构建(SOCC)方法，以及灵活的多用户干扰管理方法。


<details>
  <summary>Details</summary>
Motivation: 当前XL-RIS研究忽略了实际系统中RIS的离散相移特性，这会导致显著的性能下降。需要研究考虑离散相移特性的近场通信方案。

Method: 提出分层波束训练方法获取用户CSI；开发JOCC和SOCC方法分别用于基站预编码和XL-RIS相移优化；提出基于自适应增益矩阵近似的多用户干扰管理方法；扩展到混合预编码设计。

Result: 仿真结果表明，提出的多分辨率码本构建方法能获得更精确的波束模式和用户CSI，干扰管理方法在性能上优于基准方法。JOCC获得最优波束训练性能，SOCC在相似复杂度下获得比单天线基站码本更高的性能。

Conclusion: 所提出的方法能有效解决XL-RIS离散相移带来的性能下降问题，在近场通信中实现了优越的性能，为实际XL-RIS系统部署提供了有效的解决方案。

Abstract: Extremely large-scale reconfigurable intelligent surface (XL-RIS) can
effectively overcome severe fading and provide higher communication
performance. However, current research on XL-RIS overlooks the discrete
phase-shift characteristics of RIS in practical systems, which will result in
significant performance degradation.In this paper, we investigate near-field
communication schemes assisted by XL-RIS with discrete phase
shifts.Specifically, we propose a hierarchical beam training method to obtain
the user channel state information (CSI), and develop the jointly optimized
codebook construction (JOCC) method and separately optimized codebook
construction (SOCC) method for base station (BS) precoding and XL-RIS phase
shifts, respectively. With JOCC, the most superior beam training performance
can be obtained.With SOCC, higher performance than the single-antenna BS
codebook can be obtained at a similar complexity.Further, we propose a flexible
multiuser interference management (IM) method that is simple to solve. The IM
method uses adaptive gain matrix approximation to take into account user
fairness and can be solved in closed-form iterations. In addition, we extend
the proposed method to a hybrid precoding design. Simulation results
demonstrate that the proposed multi-resolution codebook construction method can
obtain more accurate beam patterns and user CSI, and the proposed IM method
obtains superior performance over the benchmark methods.

</details>


### [62] [Joint Time-Position Statistics and Fisher Information in Drift-Diffusion Molecular Channels](https://arxiv.org/abs/2508.18680)
*Yun-Feng Lo,Yen-Chi Lee*

Main category: cs.IT

TL;DR: 本文推导了具有漂移的扩散分子通信系统中首次到达时间和首次到达位置的联合概率密度函数，揭示了时间与位置之间的耦合关系，并证明了联合观测能够提高对关键信道参数的估计能力。


<details>
  <summary>Details</summary>
Motivation: 先前的研究分别研究了首次到达时间（FAT）和首次到达位置（FAP）的建模，但缺乏对两者联合分布的完整描述。在分子通信系统中，空间随机性本身携带重要信息，需要建立联合框架来增强建模和推断能力。

Method: 在恒定漂移和各向同性扩散条件下，推导任意空间维度中首次到达时间和首次到达位置的显式联合概率密度函数，并计算关于关键信道参数的Fisher信息矩阵。

Result: 得到了一个非平凡的联合概率密度函数，推广了已知的反向高斯模型。联合观测能够估计横向漂移并提高对扩散系数的敏感性，这是仅时间或仅位置模型无法实现的能力。

Conclusion: 该联合框架显著增强了分子通信信道的建模和推断能力，特别是在空间随机性携带不可忽略信息的场景中，为参数估计和系统优化提供了更完整的理论基础。

Abstract: This letter presents a closed-form characterization of the joint distribution
of first arrival time (FAT) and first arrival position (FAP) in diffusion-based
molecular communication (MC) systems with drift. Prior studies have
investigated FAT modeling via inverse Gaussian distributions [1] and applied
FAT statistics for parameter estimation and synchronization tasks [2], [3],
while more recent work has characterized FAP for spatial channel analysis [4].
In contrast, we derive an explicit joint probability density function (PDF)
under constant drift and isotropic diffusion in arbitrary spatial dimensions.
Our result reveals a nontrivial coupling between arrival time and lateral
position, generalizing known inverse Gaussian models. We further compute the
Fisher information matrix (FIM) with respect to key channel parameters, showing
that the joint observation enables estimation of lateral drift and improves
sensitivity to the diffusion coefficient -- capabilities not achievable with
time-only or position-only models. This joint framework enhances the modeling
and inference capabilities for molecular communication channels where spatial
randomness itself carries non-negligible information.

</details>


### [63] [Efficient Decoding of Insertion and Deletion Errors for Helberg Codes](https://arxiv.org/abs/2508.18699)
*Anthony Segrest,Hieu D. Nguyen*

Main category: cs.IT

TL;DR: 提出了Helberg码及其非二进制推广的高效多重插入-删除错误纠正解码算法


<details>
  <summary>Details</summary>
Motivation: 扩展现有的多重删除错误纠正算法，解决Helberg码及其非二进制变体中的多重插入-删除错误纠正问题

Method: 基于已知的多重删除错误纠正算法进行扩展，开发高效解码算法来处理插入和删除错误的组合

Result: 首次实现了Helberg码及其非二进制推广的高效多重插入-删除错误纠正

Conclusion: 该算法成功扩展了现有技术，为Helberg码类提供了完整的插入-删除错误纠正能力

Abstract: We present the first known efficient decoding algorithm for correcting
multiple insertion-deletion errors in Helberg codes and their non-binary
generalizations, extending a known algorithm for correcting multiple deletion
errors.

</details>


### [64] [Bistatic Target Detection by Exploiting Both Deterministic Pilots and Unknown Random Data Payloads](https://arxiv.org/abs/2508.18728)
*Lei Xie,Fan Liu,Shenghui Song,Shi Jin*

Main category: cs.IT

TL;DR: 本文提出一种基于广义检测比(GLR)的检测器，用于解决6G中感知与通信集成(ISAC)系统中混合信号的目标检测挑战


<details>
  <summary>Details</summary>
Motivation: 混合ISAC信号包含确定性导频和随机数据负载，在双基站设置中随机数据未知，导致接收信号的均值和方差耦合偏移，现有检测算法无法处理

Method: 利用已知确定性导频和未知随机数据的统计特性，推导出GLRT基础的检测器，并进行趋近性能分析

Result: 统计分析显示了关键的贴换关系：确定性和随机部分都能提高检测可靠性，但随机部分也带来统计不确定性影响性能

Conclusion: 模拟验证了理论结果，证明了提出检测器的有效性，强调了为充分利用分配给随机数据负载的信道资源而设计专用检测器的必要性

Abstract: Integrated sensing and communication (ISAC) plays a crucial role in 6G, to
enable innovative applications such as drone surveillance, urban air mobility,
and low-altitude logistics. However, the hybrid ISAC signal, which comprises
deterministic pilot and random data payload components, poses challenges for
target detection due to two reasons: 1) these two components cause coupled
shifts in both the mean and variance of the received signal, and 2) the random
data payloads are typically unknown to the sensing receiver in the bistatic
setting. Unfortunately, these challenges could not be tackled by existing
target detection algorithms. In this paper, a generalized likelihood ratio test
(GLRT)-based detector is derived, by leveraging the known deterministic pilots
and the statistical characteristics of the unknown random data payloads. Due to
the analytical intractability of exact performance characterization, we perform
an asymptotic analysis for the false alarm probability and detection
probability of the proposed detector. The results highlight a critical
trade-off: both deterministic and random components improve detection
reliability, but the latter also brings statistical uncertainty that hinders
detection performance. Simulations validate the theoretical findings and
demonstrate the effectiveness of the proposed detector, which highlights the
necessity of designing a dedicated detector to fully exploited the signaling
resources assigned to random data payloads.

</details>


### [65] [Performance Analysis of IEEE 802.11bn with Coordinated TDMA on Real-Time Applications](https://arxiv.org/abs/2508.18755)
*Seungmin Lee,Changmin Lee,Si-Chan Noh,Joonsoo Lee*

Main category: cs.IT

TL;DR: 本文研究了Wi-Fi 802.11bn标准中的协调TDMA技术，证明其能有效降低实时应用的最坏情况延迟约24%并减少抖动


<details>
  <summary>Details</summary>
Motivation: 随着实时应用对低延迟通信需求的增长，需要开发新技术来满足这些要求，特别是针对时间敏感流量的传输

Method: 提出协调TDMA调度策略，通过系统级仿真分析不同网络拥塞程度和流量特征下的延迟表现

Result: 仿真结果表明协调TDMA能有效缓解LL流量的抖动和最坏情况延迟，后者改善约24%

Conclusion: 协调TDMA作为多接入点协调技术之一，在Wi-Fi网络中能显著提升实时应用的性能表现

Abstract: Wi-Fi plays a crucial role in connecting electronic devices and providing
communication services in everyday life. Recently, there has been a growing
demand for services that require low-latency communication, such as real-time
applications. The latest amendments to Wi-Fi, IEEE 802.11bn, are being
developed to address these demands with technologies such as the multiple
access point coordination (MAPC). In this paper, we demonstrate that
coordinated TDMA (Co-TDMA), one of the MAPC techniques, effectively reduces the
latency of transmitting time-sensitive traffic. In particular, we focus on
worst-case latency and jitter, which are key metrics for evaluating the
performance of real-time applications. We first introduce a Co-TDMA scheduling
strategy. We then investigate how this scheduling strategy impacts latency
under varying levels of network congestion and traffic volume characteristics.
Finally, we validate our findings through system-level simulations. Our
simulation results demonstrate that Co-TDMA effectively mitigates jitter and
worst-case latency for LL traffic, with the latter exhibiting an improvement of
approximately 24%.

</details>


### [66] [On decoding extended Han-Zhang codes](https://arxiv.org/abs/2508.18845)
*Yang Li,Zhenliang Lu,San Ling,Shixin Zhu,Kwok Yan Lam*

Main category: cs.IT

TL;DR: 本文研究扩展Han-Zhang码的解码问题，提出了基于ℓ-错误校正对(ℓ-ECPs)的显式解码算法，并确定了其覆盖半径和深孔特性，同时构造了更多非GRS MDS码。


<details>
  <summary>Details</summary>
Motivation: 扩展Han-Zhang码在通信、密码学和存储系统中具有重要应用，虽然其代数性质和构造已被广泛研究，但解码问题尚未探索。

Method: 通过确定ℓ-ECPs的存在性和具体形式，提出基于ℓ-ECPs的多项式时间解码算法；同时确定覆盖半径并表征深孔类别，用于构造更多非GRS MDS码。

Result: 开发了可纠正约一半最小距离错误的解码算法；确定了覆盖半径；构造了更大长度和维度的非GRS MDS码；讨论了与Roth-Lempel码的单项式等价性。

Conclusion: 成功解决了扩展Han-Zhang码的解码问题，提供了有效的解码算法和深孔分析，扩展了非GRS MDS码的构造方法。

Abstract: Extended Han-Zhang codes are a class of linear codes where each code is
either a non-generalized Reed-Solomon (non-GRS) maximum distance separable
(MDS) code or a near MDS (NMDS) code. They have important applications in
communication, cryptography, and storage systems. While many algebraic
properties and explicit constructions of extended Han-Zhang codes have been
well studied in the literature, their decoding has been unexplored. In this
paper, we focus on their decoding problems in terms of $\ell$-error-correcting
pairs ($\ell$-ECPs) and deep holes. On the one hand, we determine the existence
and specific forms of their $\ell$-ECPs, and further present an explicit
decoding algorithm for extended Han-Zhang codes based on these $\ell$-ECPs,
which can correct up to $\ell$ errors in polynomial time, with $\ell$ about
half of the minimum distance. On the other hand, we determine the covering
radius of extended Han-Zhang codes and characterize two classes of their deep
holes, which are closely related to the maximum-likelihood decoding method. By
employing these deep holes, we also construct more non-GRS MDS codes with
larger lengths and dimensions, and discuss the monomial equivalence between
them and the well-known Roth-Lempel codes. Some concrete examples are also
given to support these results.

</details>
