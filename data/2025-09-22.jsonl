{"id": "2509.15291", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.15291", "abs": "https://arxiv.org/abs/2509.15291", "authors": ["Federico Taschin", "Abderrahmane Lazaraq", "Ozan K. Tonguz", "Inci Ozgunes"], "title": "The Distribution Shift Problem in Transportation Networks using Reinforcement Learning and AI", "comment": null, "summary": "The use of Machine Learning (ML) and Artificial Intelligence (AI) in smart\ntransportation networks has increased significantly in the last few years.\nAmong these ML and AI approaches, Reinforcement Learning (RL) has been shown to\nbe a very promising approach by several authors. However, a problem with using\nReinforcement Learning in Traffic Signal Control is the reliability of the\ntrained RL agents due to the dynamically changing distribution of the input\ndata with respect to the distribution of the data used for training. This\npresents a major challenge and a reliability problem for the trained network of\nAI agents and could have very undesirable and even detrimental consequences if\na suitable solution is not found. Several researchers have tried to address\nthis problem using different approaches. In particular, Meta Reinforcement\nLearning (Meta RL) promises to be an effective solution. In this paper, we\nevaluate and analyze a state-of-the-art Meta RL approach called MetaLight and\nshow that, while under certain conditions MetaLight can indeed lead to\nreasonably good results, under some other conditions it might not perform well\n(with errors of up to 22%), suggesting that Meta RL schemes are often not\nrobust enough and can even pose major reliability problems."}
{"id": "2509.15501", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.15501", "abs": "https://arxiv.org/abs/2509.15501", "authors": ["Lifei Hao", "Yue Cheng", "Min Wang", "Bing Jia", "Baoqi Huang"], "title": "WiFiSim: Simulating WiFi Probe Requests via AOSP Analysis and Device Behavior Modeling", "comment": null, "summary": "WiFi probe request (PR) frames encode fine-grained device interactions and\nserve as a critical basis for mobility and crowd analytics. However, pervasive\nMAC address randomization and the scarcity of labeled datasets hinder progress\nin PR-based studies. We introduce WiFiSim, a simulation framework that\nreconstructs PR generation through Android Open Source Project (AOSP) protocol\nanalysis and finite-state device behavior modeling. WiFiSim identifies the key\ndeterminants of PR structure and timing while capturing realistic user-driven\nstate transitions. Experiments show that WiFiSim achieves less than 5%\ndeviation from real measurements in both distributional and temporal dynamics,\nscales to large-scale dataset synthesis, and enables reliable evaluation of\ndownstream applications. Source code and sample datasets are publicly released\nto foster reproducible research."}
{"id": "2509.15411", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.15411", "abs": "https://arxiv.org/abs/2509.15411", "authors": ["Anika Tabassum Biva", "Md. Ibrahim", "A. S. M. Badrudduza", "Imran Shafique Ansari"], "title": "Enhancing Physical Layer Security in IoT-Based RF-FSO Integrated Networks: Multi-RIS Structures and their Impact on Secure Communication", "comment": null, "summary": "Due to their ability to dynamically control the propagation environment,\nreconfigurable intelligent surfaces (RISs) offer a promising solution to\naddress the challenges of $6$G wireless communication, especially in the\ncontext of Internet of Things (IoT) networks. This paper investigates a mixed\ncommunication model with multi-RIS-aided radio frequency (RF)-free space optics\n(FSO) to enhance the performance of IoT applications in complex environments.\nAn eavesdropper is assumed to be present, attempting to intercept confidential\ninformation transmitted over the RF link. All RF links are modeled using Rician\nfading, while the FSO link accounts for M\\'alaga turbulence with pointing\nerrors, capturing real-world propagation conditions. Closed-form analytical\nexpressions are derived for the secrecy outage probability, average secrecy\ncapacity, and effective secrecy throughput in terms of Meijer's G function. To\ngain further insight, high signal-to-noise approximations of these metrics are\nalso presented. Numerical results highlight the importance of heterodyne\ndetection in mitigating the adverse effects of pointing errors on the FSO link.\nMoreover, integrating a multi-RIS structure into the proposed model\nsignificantly increases secrecy performance, achieving up to a $47.67\\%$\nimprovement in SOP compared to conventional methods. Finally, the derived\nanalytical results are validated through Monte Carlo simulations."}
{"id": "2509.15237", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.15237", "abs": "https://arxiv.org/abs/2509.15237", "authors": ["Di Wen", "Kunyu Peng", "Junwei Zheng", "Yufan Chen", "Yitain Shi", "Jiale Wei", "Ruiping Liu", "Kailun Yang", "Rainer Stiefelhagen"], "title": "MICA: Multi-Agent Industrial Coordination Assistant", "comment": "The source code will be made publicly available at\n  https://github.com/Kratos-Wen/MICA", "summary": "Industrial workflows demand adaptive and trustworthy assistance that can\noperate under limited computing, connectivity, and strict privacy constraints.\nIn this work, we present MICA (Multi-Agent Industrial Coordination Assistant),\na perception-grounded and speech-interactive system that delivers real-time\nguidance for assembly, troubleshooting, part queries, and maintenance. MICA\ncoordinates five role-specialized language agents, audited by a safety checker,\nto ensure accurate and compliant support. To achieve robust step understanding,\nwe introduce Adaptive Step Fusion (ASF), which dynamically blends expert\nreasoning with online adaptation from natural speech feedback. Furthermore, we\nestablish a new multi-agent coordination benchmark across representative task\ncategories and propose evaluation metrics tailored to industrial assistance,\nenabling systematic comparison of different coordination topologies. Our\nexperiments demonstrate that MICA consistently improves task success,\nreliability, and responsiveness over baseline structures, while remaining\ndeployable on practical offline hardware. Together, these contributions\nhighlight MICA as a step toward deployable, privacy-preserving multi-agent\nassistants for dynamic factory environments. The source code will be made\npublicly available at https://github.com/Kratos-Wen/MICA."}
{"id": "2509.15856", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.15856", "abs": "https://arxiv.org/abs/2509.15856", "authors": ["Zhenyu Wang", "Chuan Lin", "Guangjie Han", "Shengchao Zhu", "Ruoyuan Wu", "Tongwei Zhang"], "title": "Smart Interrupted Routing Based on Multi-head Attention Mask Mechanism-Driven MARL in Software-defined UASNs", "comment": null, "summary": "Routing-driven timely data collection in Underwater Acoustic Sensor Networks\n(UASNs) is crucial for marine environmental monitoring, disaster warning and\nunderwater resource exploration, etc. However, harsh underwater conditions,\nincluding high delays, limited bandwidth, and dynamic topologies - make\nefficient routing decisions challenging in UASNs. In this paper, we propose a\nsmart interrupted routing scheme for UASNs to address dynamic underwater\nchallenges. We first model underwater noise influences from real underwater\nrouting features, e.g., turbulence and storms. We then propose a\nSoftware-Defined Networking (SDN)-based Interrupted Software-defined UASNs\nReinforcement Learning (ISURL) framework which ensures adaptive routing through\ndynamically failure handling (e.g., energy depletion of sensor nodes or link\ninstability) and real-time interrupted recovery. Based on ISURL, we propose\nMA-MAPPO algorithm, integrating multi-head attention mask mechanism with MAPPO\nto filter out infeasible actions and streamline training. Furthermore, to\nsupport interrupted data routing in UASNs, we introduce MA-MAPPO_i, MA-MAPPO\nwith interrupted policy, to enable smart interrupted routing decision in UASNs.\nThe evaluations demonstrate that our proposed routing scheme achieves exact\nunderwater data routing decision with faster convergence speed and lower\nrouting delays than existing approaches."}
{"id": "2509.15637", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.15637", "abs": "https://arxiv.org/abs/2509.15637", "authors": ["Chin Wa Lau", "Xiang Shi", "Ziyan Zheng", "Haiwen Cao", "Nian Guo"], "title": "Interplay Between Belief Propagation and Transformer: Differential-Attention Message Passing Transformer", "comment": "6 pages, 4 figures, to be published in ISIT2025", "summary": "Transformer-based neural decoders have emerged as a promising approach to\nerror correction coding, combining data-driven adaptability with efficient\nmodeling of long-range dependencies. This paper presents a novel decoder\narchitecture that integrates classical belief propagation principles with\ntransformer designs. We introduce a differentiable syndrome loss function\nleveraging global codebook structure and a differential-attention mechanism\noptimizing bit and syndrome embedding interactions. Experimental results\ndemonstrate consistent performance improvements over existing transformer-based\ndecoders, with our approach surpassing traditional belief propagation decoders\nfor short-to-medium length LDPC codes."}
{"id": "2509.15239", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.15239", "abs": "https://arxiv.org/abs/2509.15239", "authors": ["Stjepan Požgaj", "Dobrik Georgiev", "Marin Šilić", "Petar Veličković"], "title": "KNARsack: Teaching Neural Algorithmic Reasoners to Solve Pseudo-Polynomial Problems", "comment": "14 pages, 10 figures", "summary": "Neural algorithmic reasoning (NAR) is a growing field that aims to embed\nalgorithmic logic into neural networks by imitating classical algorithms. In\nthis extended abstract, we detail our attempt to build a neural algorithmic\nreasoner that can solve Knapsack, a pseudo-polynomial problem bridging\nclassical algorithms and combinatorial optimisation, but omitted in standard\nNAR benchmarks. Our neural algorithmic reasoner is designed to closely follow\nthe two-phase pipeline for the Knapsack problem, which involves first\nconstructing the dynamic programming table and then reconstructing the solution\nfrom it. The approach, which models intermediate states through dynamic\nprogramming supervision, achieves better generalization to larger problem\ninstances than a direct-prediction baseline that attempts to select the optimal\nsubset only from the problem inputs."}
{"id": "2509.15930", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.15930", "abs": "https://arxiv.org/abs/2509.15930", "authors": ["Özgür Ozan Kaynak", "Andreas Kassler", "Andreas Fischer", "Ognjen Dobrijevic", "Fabio D'Andreagiovanni"], "title": "A Robust Scheduling of Cyclic Traffic for Integrated Wired and Wireless Time-Sensitive Networks", "comment": "This paper has been accepted for publication in the proceedings of\n  the 21st International Conference on Network and Service Management (CNSM\n  2025)", "summary": "Time-Sensitive Networking (TSN) is a toolbox of technologies that enable\ndeterministic communication over Ethernet. A key area has been TSN's time-aware\ntraffic shaping (TAS), which supports stringent end-to-end latency and\nreliability requirements. Configuration of TAS requires the computation of a\nnetwork-wide traffic schedule, which is particularly challenging with\nintegrated wireless networks (e.g., 5G, Wi-Fi) due to the stochastic nature of\nwireless links. This paper introduces a novel method for configuring TAS,\nfocusing on cyclic traffic patterns and jitter of wireless links. We formulate\na linear program that computes a network-wide time-aware schedule, robust to\nwireless performance uncertainties. The given method enables robust scheduling\nof multiple TSN frames per transmission window using a tunable robustness\nparameter ({\\Gamma}). To reduce computational complexity, we also propose a\nsequential batch-scheduling heuristic that runs in polynomial time. Our\napproach is evaluated by using different network topologies and wireless link\ncharacteristics, demonstrating that the heuristic can schedule 90% of 6500\nrequested TSN streams in a large topology."}
{"id": "2509.15643", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.15643", "abs": "https://arxiv.org/abs/2509.15643", "authors": ["Zhentian Zhang", "Kai-Kit Wong", "David Morales-Jimenez", "Hao Jiang", "Hao Xu", "Christos Masouros", "Zaichen Zhang", "Chan-Byoung Chae"], "title": "Finite-blocklength Fluid Antenna Systems", "comment": null, "summary": "This work introduces and investigates finite blocklength fluid antenna\nsystems (FBL-FASs). To meet the stringent key performance indicators (KPIs) of\n6G and beyond networks, including ultra-massive machine-type communications\n(mMTC), ultra-reliable low-latency communications (URLLC), and enhanced mobile\nbroadband (eMBB), it is necessary to evaluate the performance of FAS under\nlimited channel uses across time, frequency, and other domains. By exploiting\nrandom matrix theory and extreme value theory (EVT), we characterize the effect\nof finite blocklength on key metrics such as the signal-to-noise ratio (SNR)\nand the signal-to-interference-plus-noise ratio (SINR), via accurate estimation\nof interference caused by codeword correlation. Closed-form expressions for\nblock error rate (BLER) and outage probability are derived, covering both\nconditional BLER (with channel state information, CSI) and statistical BLER\n(without CSI). The proposed analysis leverages Chernoff bounds and introduces a\nTaylor-expansion-assisted mean value theorem for integrals (MVTI) to reduce\ncomputational complexity. Numerical results show that, compared with\nconventional multi-antenna systems, the proposed FBL-FAS framework achieves\nhigher energy and spectral efficiency under finite blocklength, making it a\npromising enabler for next-generation wireless networks."}
{"id": "2509.15291", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.15291", "abs": "https://arxiv.org/abs/2509.15291", "authors": ["Federico Taschin", "Abderrahmane Lazaraq", "Ozan K. Tonguz", "Inci Ozgunes"], "title": "The Distribution Shift Problem in Transportation Networks using Reinforcement Learning and AI", "comment": null, "summary": "The use of Machine Learning (ML) and Artificial Intelligence (AI) in smart\ntransportation networks has increased significantly in the last few years.\nAmong these ML and AI approaches, Reinforcement Learning (RL) has been shown to\nbe a very promising approach by several authors. However, a problem with using\nReinforcement Learning in Traffic Signal Control is the reliability of the\ntrained RL agents due to the dynamically changing distribution of the input\ndata with respect to the distribution of the data used for training. This\npresents a major challenge and a reliability problem for the trained network of\nAI agents and could have very undesirable and even detrimental consequences if\na suitable solution is not found. Several researchers have tried to address\nthis problem using different approaches. In particular, Meta Reinforcement\nLearning (Meta RL) promises to be an effective solution. In this paper, we\nevaluate and analyze a state-of-the-art Meta RL approach called MetaLight and\nshow that, while under certain conditions MetaLight can indeed lead to\nreasonably good results, under some other conditions it might not perform well\n(with errors of up to 22%), suggesting that Meta RL schemes are often not\nrobust enough and can even pose major reliability problems."}
{"id": "2509.16035", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.16035", "abs": "https://arxiv.org/abs/2509.16035", "authors": ["Ran Li", "Ziyi Xu", "Ying-Jun Angela Zhang"], "title": "Near-Field Beam Training Through Beam Diverging", "comment": null, "summary": "This paper investigates beam training techniques for near-field (NF)\nextremely large-scale antenna arrays (ELAAs). Existing NF beam training methods\npredominantly rely on beam focusing, where the base station (BS) transmits\nhighly spatially selective beams to locate the user equipment (UE). However,\nthese beam-focusing-based schemes suffer from both high beam sweeping overhead\nand limited accuracy in the NF, primarily due to the narrow beams' high\nsusceptibility to misalignment. To address this, we propose a novel NF beam\ntraining paradigm using diverging beams. Specifically, we introduce the beam\ndiverging effect and exploit it for low-overhead, high-accuracy beam training.\nFirst, we design a diverging codeword to induce the beam diverging effect with\na single radio frequency (RF) chain. Next, we develop a diverging polar-domain\ncodebook (DPC) along with a hierarchical method that enables angular-domain\nlocalization of the UE with only 2 log_2(N) pilots, where N denotes the number\nof antennas. Finally, we enhance beam training performance through two\nadditional techniques: a DPC angular range reduction strategy to improve the\neffectiveness of beam diverging, and a pilot set expansion method to increase\noverall beam training accuracy. Numerical results show that our algorithm\nachieves near-optimal accuracy with a small pilot overhead, outperforming\nexisting methods."}
{"id": "2509.15292", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15292", "abs": "https://arxiv.org/abs/2509.15292", "authors": ["Abhiyan Dhakal", "Kausik Paudel", "Sanjog Sigdel"], "title": "An Artificial Intelligence Driven Semantic Similarity-Based Pipeline for Rapid Literature", "comment": "8 pages, 6 figures, 1 table, National Conference on Computer\n  Innovations", "summary": "We propose an automated pipeline for performing literature reviews using\nsemantic similarity. Unlike traditional systematic review systems or\noptimization based methods, this work emphasizes minimal overhead and high\nrelevance by using transformer based embeddings and cosine similarity. By\nproviding a paper title and abstract, it generates relevant keywords, fetches\nrelevant papers from open access repository, and ranks them based on their\nsemantic closeness to the input. Three embedding models were evaluated. A\nstatistical thresholding approach is then applied to filter relevant papers,\nenabling an effective literature review pipeline. Despite the absence of\nheuristic feedback or ground truth relevance labels, the proposed system shows\npromise as a scalable and practical tool for preliminary research and\nexploratory analysis."}
{"id": "2509.16055", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.16055", "abs": "https://arxiv.org/abs/2509.16055", "authors": ["Ran Li", "Ziyi Xu", "Ying-Jun Angela Zhang"], "title": "3D Near-Field Beam Training for Uniform Planar Arrays through Beam Diverging", "comment": null, "summary": "In future 6G communication systems, large-scale antenna arrays promise\nenhanced signal strength and spatial resolution, but they also increase the\ncomplexity of beam training. Moreover, as antenna counts grow and carrier\nwavelengths shrink, the channel model transits from far-field (FF) planar waves\nto near-field (NF) spherical waves, further complicating the beam training\nprocess. This paper focuses on millimeter-wave (mmWave) systems equipped with\nlarge-scale uniform planar arrays (UPAs), which produce 3D beam patterns and\nintroduce additional challenges for NF beam training. Existing methods\nprimarily rely on either FF steering or NF focusing codewords, both of which\nare highly sensitive to mismatches in user equipment (UE) location, leading to\nhigh sensitivity to even slight mismatch and excessive training overhead. In\ncontrast, we introduce a novel beam training approach leveraging the\nbeam-diverging effect, which enables adjustable wide-beam coverage using only a\nsingle radio frequency (RF) chain. Specifically, we first analyze the spatial\ncharacteristics of this effect in UPA systems and leverage them to construct\nhierarchical codebooks for coarse UE localization. Then, we develop a 3D\nsampling mechanism to build an NF refinement codebook for precise beam\ntraining. Numerical results demonstrate that the proposed algorithm achieves\nsuperior beam training performance while maintaining low training overhead."}
{"id": "2509.15336", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15336", "abs": "https://arxiv.org/abs/2509.15336", "authors": ["Humam Kourani", "Anton Antonov", "Alessandro Berti", "Wil M. P. van der Aalst"], "title": "Knowledge-Driven Hallucination in Large Language Models: An Empirical Study on Process Modeling", "comment": "The Version of Record of this contribution will be published in the\n  proceedings of the 2nd International Workshop on Generative AI for Process\n  Mining (GenAI4PM 2025). This preprint has not undergone peer review or any\n  post-submission improvements or corrections", "summary": "The utility of Large Language Models (LLMs) in analytical tasks is rooted in\ntheir vast pre-trained knowledge, which allows them to interpret ambiguous\ninputs and infer missing information. However, this same capability introduces\na critical risk of what we term knowledge-driven hallucination: a phenomenon\nwhere the model's output contradicts explicit source evidence because it is\noverridden by the model's generalized internal knowledge. This paper\ninvestigates this phenomenon by evaluating LLMs on the task of automated\nprocess modeling, where the goal is to generate a formal business process model\nfrom a given source artifact. The domain of Business Process Management (BPM)\nprovides an ideal context for this study, as many core business processes\nfollow standardized patterns, making it likely that LLMs possess strong\npre-trained schemas for them. We conduct a controlled experiment designed to\ncreate scenarios with deliberate conflict between provided evidence and the\nLLM's background knowledge. We use inputs describing both standard and\ndeliberately atypical process structures to measure the LLM's fidelity to the\nprovided evidence. Our work provides a methodology for assessing this critical\nreliability issue and raises awareness of the need for rigorous validation of\nAI-generated artifacts in any evidence-based domain."}
{"id": "2509.16129", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.16129", "abs": "https://arxiv.org/abs/2509.16129", "authors": ["Sudharsan Senthil", "Avhishek Chatterjee"], "title": "Learning the Influence Graph of a Markov Process that Randomly Resets to Past", "comment": "Sample complexity proof included", "summary": "Learning the influence graph G of a high-dimensional Markov process is a\nchallenging problem. Prior work has addressed this task when the process has\nfinite memory. However, the more general regime in which the system\nprobabilistically \"jumps back in time\" - so that the state at t+1 depends on a\nsample from a distant past t-d - remains unexplored. The process with\nprobabilistic resets can be modeled as a Markov process with memory, but\nestimations become computationally expensive. To tackle this, we introduce\nPIMRecGreedy, a modification of the RecGreedy algorithm originally designed for\ni.i.d. samples. The proposed method does not assume memory, requires no prior\nknowledge of d, and recovers G with high probability even without access to the\nspecific time indices at which such temporal jumps occur, and without imposing\nany constraints on the graph structures."}
{"id": "2509.15366", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15366", "abs": "https://arxiv.org/abs/2509.15366", "authors": ["Andrejs Sorstkins", "Josh Bailey", "Dr Alistair Baron"], "title": "Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context", "comment": "Dissertation and research project created in collaboration with\n  JobFair LTD", "summary": "The rapid evolution of neural architectures - from multilayer perceptrons to\nlarge-scale Transformer-based models - has enabled language models (LLMs) to\nexhibit emergent agentic behaviours when equipped with memory, planning, and\nexternal tool use. However, their inherent stochasticity and multi-step\ndecision processes render classical evaluation methods inadequate for\ndiagnosing agentic performance. This work introduces a diagnostic framework for\nexpert systems that not only evaluates but also facilitates the transfer of\nexpert behaviour into LLM-powered agents. The framework integrates (i) curated\ngolden datasets of expert annotations, (ii) silver datasets generated through\ncontrolled behavioural mutation, and (iii) an LLM-based Agent Judge that scores\nand prescribes targeted improvements. These prescriptions are embedded into a\nvectorized recommendation map, allowing expert interventions to propagate as\nreusable improvement trajectories across multiple system instances. We\ndemonstrate the framework on a multi-agent recruiter-assistant system, showing\nthat it uncovers latent cognitive failures - such as biased phrasing,\nextraction drift, and tool misrouting - while simultaneously steering agents\ntoward expert-level reasoning and style. The results establish a foundation for\nstandardized, reproducible expert behaviour transfer in stochastic,\ntool-augmented LLM agents, moving beyond static evaluation to active expert\nsystem refinement."}
{"id": "2509.16146", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.16146", "abs": "https://arxiv.org/abs/2509.16146", "authors": ["Gongpu Chen", "Deniz Gunduz"], "title": "Implicit Communication in Linear Quadratic Gaussian Control Systems", "comment": "27 pages, 3 figures", "summary": "This paper studies implicit communication in linear quadratic Gaussian\ncontrol systems. We show that the control system itself can serve as an\nimplicit communication channel, enabling the controller to transmit messages\nthrough its inputs to a receiver that observes the system state. This\ncommunication is considered implicit because (i) no explicit communication\nchannels are needed; and (ii) information is transmitted while simultaneously\nfulfilling the controller's primary objective--maintaining the control cost\nwithin a specified level. As a result, there exists an inherent trade-off\nbetween control and communication performance. This trade-off is formalized\nthrough the notion of implicit channel capacity, which characterizes the\nsupremum reliable communication rate subject to a constraint on control\nperformance. We characterize the implicit channel capacity in three settings.\nWhen both the controller and the receiver have noiseless observations of the\nsystem state, the channel capacity admits a closed-form expression. When only\nthe controller has noiseless observations, the channel capacity is given by the\nsolution of a convex optimization. When both the controller and the receiver\nhave noisy observations, we establish a lower bound on the implicit capacity.\nSurprisingly, when the controller has noiseless observations, the\ncapacity-achieving input policy adheres to a separation principle, allowing the\ncontrol and channel coding tasks to be addressed independently, without loss of\noptimality. Moreover, under this capacity-achieving input policy, the implicit\nchannel can be equivalently translated into a Gaussian MIMO channel, enabling\nthe use of existing channel codes to achieve implicit communication."}
{"id": "2509.15409", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15409", "abs": "https://arxiv.org/abs/2509.15409", "authors": ["Yu Shee", "Anthony M. Smaldone", "Anton Morgunov", "Gregory W. Kyro", "Victor S. Batista"], "title": "FragmentRetro: A Quadratic Retrosynthetic Method Based on Fragmentation Algorithms", "comment": null, "summary": "Retrosynthesis, the process of deconstructing a target molecule into simpler\nprecursors, is crucial for computer-aided synthesis planning (CASP). Widely\nadopted tree-search methods often suffer from exponential computational\ncomplexity. In this work, we introduce FragmentRetro, a novel retrosynthetic\nmethod that leverages fragmentation algorithms, specifically BRICS and r-BRICS,\ncombined with stock-aware exploration and pattern fingerprint screening to\nachieve quadratic complexity. FragmentRetro recursively combines molecular\nfragments and verifies their presence in a building block set, providing sets\nof fragment combinations as retrosynthetic solutions. We present the first\nformal computational analysis of retrosynthetic methods, showing that tree\nsearch exhibits exponential complexity $O(b^h)$, DirectMultiStep scales as\n$O(h^6)$, and FragmentRetro achieves $O(h^2)$, where $h$ represents the number\nof heavy atoms in the target molecule and $b$ is the branching factor for tree\nsearch. Evaluations on PaRoutes, USPTO-190, and natural products demonstrate\nthat FragmentRetro achieves high solved rates with competitive runtime,\nincluding cases where tree search fails. The method benefits from fingerprint\nscreening, which significantly reduces substructure matching complexity. While\nFragmentRetro focuses on efficiently identifying fragment-based solutions\nrather than full reaction pathways, its computational advantages and ability to\ngenerate strategic starting candidates establish it as a powerful foundational\ncomponent for scalable and automated synthesis planning."}
{"id": "2509.15541", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15541", "abs": "https://arxiv.org/abs/2509.15541", "authors": ["Bronson Schoen", "Evgenia Nitishinskaya", "Mikita Balesni", "Axel Højmark", "Felix Hofstätter", "Jérémy Scheurer", "Alexander Meinke", "Jason Wolfe", "Teun van der Weij", "Alex Lloyd", "Nicholas Goldowsky-Dill", "Angela Fan", "Andrei Matveiakin", "Rusheb Shah", "Marcus Williams", "Amelia Glaese", "Boaz Barak", "Wojciech Zaremba", "Marius Hobbhahn"], "title": "Stress Testing Deliberative Alignment for Anti-Scheming Training", "comment": null, "summary": "Highly capable AI systems could secretly pursue misaligned goals -- what we\ncall \"scheming\". Because a scheming AI would deliberately try to hide its\nmisaligned goals and actions, measuring and mitigating scheming requires\ndifferent strategies than are typically used in ML. We propose that assessing\nanti-scheming interventions requires at least (1) testing propensity to scheme\non far out-of-distribution (OOD) tasks, (2) evaluating whether lack of scheming\nis driven by situational awareness, and (3) checking for robustness to\npre-existing misaligned goals. We use a broad category of \"covert actions\" --\nsuch as secretly breaking rules or intentionally underperforming in tests -- as\na proxy for scheming, and design evaluations for covert actions. We then\nstress-test deliberative alignment as a case study for anti-scheming. Across 26\nOOD evaluations (180+ environments), deliberative alignment reduces covert\naction rates (OpenAI o3: 13%->0.4%) but does not fully eliminate them. Our\nmitigation is also able to largely stop agents from pursuing a hidden goal\npreviously trained into the model, but we still find misbehavior after\nadditional red-teaming. We find that models' chain-of-thought (CoT) often\ndemonstrates awareness of being evaluated for alignment, and show causal\nevidence that this awareness decreases covert behavior, while unawareness\nincreases it. Therefore, we cannot exclude that the observed reductions in\ncovert action rates are at least partially driven by situational awareness.\nWhile we rely on human-legible CoT for training, studying situational\nawareness, and demonstrating clear evidence of misalignment, our ability to\nrely on this degrades as models continue to depart from reasoning in standard\nEnglish. We encourage research into alignment mitigations for scheming and\ntheir assessment, especially for the adversarial case of deceptive alignment,\nwhich this paper does not address."}
{"id": "2509.15635", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15635", "abs": "https://arxiv.org/abs/2509.15635", "authors": ["Pan Tang", "Shixiang Tang", "Huanqi Pu", "Zhiqing Miao", "Zhixing Wang"], "title": "MicroRCA-Agent: Microservice Root Cause Analysis Method Based on Large Language Model Agents", "comment": "18 pages, 22 figures", "summary": "This paper presents MicroRCA-Agent, an innovative solution for microservice\nroot cause analysis based on large language model agents, which constructs an\nintelligent fault root cause localization system with multimodal data fusion.\nThe technical innovations are embodied in three key aspects: First, we combine\nthe pre-trained Drain log parsing algorithm with multi-level data filtering\nmechanism to efficiently compress massive logs into high-quality fault\nfeatures. Second, we employ a dual anomaly detection approach that integrates\nIsolation Forest unsupervised learning algorithms with status code validation\nto achieve comprehensive trace anomaly identification. Third, we design a\nstatistical symmetry ratio filtering mechanism coupled with a two-stage LLM\nanalysis strategy to enable full-stack phenomenon summarization across\nnode-service-pod hierarchies. The multimodal root cause analysis module\nleverages carefully designed cross-modal prompts to deeply integrate multimodal\nanomaly information, fully exploiting the cross-modal understanding and logical\nreasoning capabilities of large language models to generate structured analysis\nresults encompassing fault components, root cause descriptions, and reasoning\ntrace. Comprehensive ablation studies validate the complementary value of each\nmodal data and the effectiveness of the system architecture. The proposed\nsolution demonstrates superior performance in complex microservice fault\nscenarios, achieving a final score of 50.71. The code has been released at:\nhttps://github.com/tangpan360/MicroRCA-Agent."}
{"id": "2509.15690", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15690", "abs": "https://arxiv.org/abs/2509.15690", "authors": ["Weixuan Sun", "Jucai Zhai", "Dengfeng Liu", "Xin Zhang", "Xiaojun Wu", "Qiaobo Hao", "AIMgroup", "Yang Fang", "Jiuyang Tang"], "title": "CCrepairBench: A High-Fidelity Benchmark and Reinforcement Learning Framework for C++ Compilation Repair", "comment": null, "summary": "The automated repair of C++ compilation errors presents a significant\nchallenge, the resolution of which is critical for developer productivity.\nProgress in this domain is constrained by two primary factors: the scarcity of\nlarge-scale, high-fidelity datasets and the limitations of conventional\nsupervised methods, which often fail to generate semantically correct\npatches.This paper addresses these gaps by introducing a comprehensive\nframework with three core contributions. First, we present CCrepair, a novel,\nlarge-scale C++ compilation error dataset constructed through a sophisticated\ngenerate-and-verify pipeline. Second, we propose a Reinforcement Learning (RL)\nparadigm guided by a hybrid reward signal, shifting the focus from mere\ncompilability to the semantic quality of the fix. Finally, we establish the\nrobust, two-stage evaluation system providing this signal, centered on an\nLLM-as-a-Judge whose reliability has been rigorously validated against the\ncollective judgments of a panel of human experts. This integrated approach\naligns the training objective with generating high-quality, non-trivial patches\nthat are both syntactically and semantically correct. The effectiveness of our\napproach was demonstrated experimentally. Our RL-trained Qwen2.5-1.5B-Instruct\nmodel achieved performance comparable to a Qwen2.5-14B-Instruct model,\nvalidating the efficiency of our training paradigm. Our work provides the\nresearch community with a valuable new dataset and a more effective paradigm\nfor training and evaluating robust compilation repair models, paving the way\nfor more practical and reliable automated programming assistants."}
{"id": "2509.15730", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.15730", "abs": "https://arxiv.org/abs/2509.15730", "authors": ["Lukas Laakmann", "Seyyid A. Ciftci", "Christian Janiesch"], "title": "A Nascent Taxonomy of Machine Learning in Intelligent Robotic Process Automation", "comment": null, "summary": "Robotic process automation (RPA) is a lightweight approach to automating\nbusiness processes using software robots that emulate user actions at the\ngraphical user interface level. While RPA has gained popularity for its\ncost-effective and timely automation of rule-based, well-structured tasks, its\nsymbolic nature has inherent limitations when approaching more complex tasks\ncurrently performed by human agents. Machine learning concepts enabling\nintelligent RPA provide an opportunity to broaden the range of automatable\ntasks. In this paper, we conduct a literature review to explore the connections\nbetween RPA and machine learning and organize the joint concept intelligent RPA\ninto a taxonomy. Our taxonomy comprises the two meta-characteristics RPA-ML\nintegration and RPA-ML interaction. Together, they comprise eight dimensions:\narchitecture and ecosystem, capabilities, data basis, intelligence level, and\ntechnical depth of integration as well as deployment environment, lifecycle\nphase, and user-robot relation."}
{"id": "2509.15780", "categories": ["cs.AI", "cs.DL"], "pdf": "https://arxiv.org/pdf/2509.15780", "abs": "https://arxiv.org/abs/2509.15780", "authors": ["Natallia Kokash", "Bernard de Bono", "Tom Gillespie"], "title": "Ontology Creation and Management Tools: the Case of Anatomical Connectivity", "comment": "14 pages", "summary": "We are developing infrastructure to support researchers in mapping data\nrelated to the peripheral nervous system and other physiological systems, with\nan emphasis on their relevance to the organs under investigation. The nervous\nsystem, a complex network of nerves and ganglia, plays a critical role in\ncoordinating and transmitting signals throughout the body. To aid in this, we\nhave created ApiNATOMY, a framework for the topological and semantic\nrepresentation of multiscale physiological circuit maps. ApiNATOMY integrates a\nKnowledge Representation (KR) model and a suite of Knowledge Management (KM)\ntools. The KR model enables physiology experts to easily capture interactions\nbetween anatomical entities, while the KM tools help modelers convert\nhigh-level abstractions into detailed models of physiological processes, which\ncan be integrated with external ontologies and knowledge graphs."}
{"id": "2509.15786", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.15786", "abs": "https://arxiv.org/abs/2509.15786", "authors": ["Nan Li", "Bo Kang", "Tijl De Bie"], "title": "Building Data-Driven Occupation Taxonomies: A Bottom-Up Multi-Stage Approach via Semantic Clustering and Multi-Agent Collaboration", "comment": null, "summary": "Creating robust occupation taxonomies, vital for applications ranging from\njob recommendation to labor market intelligence, is challenging. Manual\ncuration is slow, while existing automated methods are either not adaptive to\ndynamic regional markets (top-down) or struggle to build coherent hierarchies\nfrom noisy data (bottom-up). We introduce CLIMB (CLusterIng-based Multi-agent\ntaxonomy Builder), a framework that fully automates the creation of\nhigh-quality, data-driven taxonomies from raw job postings. CLIMB uses global\nsemantic clustering to distill core occupations, then employs a\nreflection-based multi-agent system to iteratively build a coherent hierarchy.\nOn three diverse, real-world datasets, we show that CLIMB produces taxonomies\nthat are more coherent and scalable than existing methods and successfully\ncapture unique regional characteristics. We release our code and datasets at\nhttps://anonymous.4open.science/r/CLIMB."}
{"id": "2509.15848", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15848", "abs": "https://arxiv.org/abs/2509.15848", "authors": ["Giovanni De Gasperis", "Sante Dino Facchini"], "title": "A Comparative Study of Rule-Based and Data-Driven Approaches in Industrial Monitoring", "comment": null, "summary": "Industrial monitoring systems, especially when deployed in Industry 4.0\nenvironments, are experiencing a shift in paradigm from traditional rule-based\narchitectures to data-driven approaches leveraging machine learning and\nartificial intelligence. This study presents a comparison between these two\nmethodologies, analyzing their respective strengths, limitations, and\napplication scenarios, and proposes a basic framework to evaluate their key\nproperties. Rule-based systems offer high interpretability, deterministic\nbehavior, and ease of implementation in stable environments, making them ideal\nfor regulated industries and safety-critical applications. However, they face\nchallenges with scalability, adaptability, and performance in complex or\nevolving contexts. Conversely, data-driven systems excel in detecting hidden\nanomalies, enabling predictive maintenance and dynamic adaptation to new\nconditions. Despite their high accuracy, these models face challenges related\nto data availability, explainability, and integration complexity. The paper\nsuggests hybrid solutions as a possible promising direction, combining the\ntransparency of rule-based logic with the analytical power of machine learning.\nOur hypothesis is that the future of industrial monitoring lies in intelligent,\nsynergic systems that leverage both expert knowledge and data-driven insights.\nThis dual approach enhances resilience, operational efficiency, and trust,\npaving the way for smarter and more flexible industrial environments."}
{"id": "2509.15957", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.15957", "abs": "https://arxiv.org/abs/2509.15957", "authors": ["Kanato Masayoshi", "Masahiro Hashimoto", "Ryoichi Yokoyama", "Naoki Toda", "Yoshifumi Uwamino", "Shogo Fukuda", "Ho Namkoong", "Masahiro Jinzaki"], "title": "EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol", "comment": null, "summary": "Background: Large language models (LLMs) show promise in medicine, but their\ndeployment in hospitals is limited by restricted access to electronic health\nrecord (EHR) systems. The Model Context Protocol (MCP) enables integration\nbetween LLMs and external tools.\n  Objective: To evaluate whether an LLM connected to an EHR database via MCP\ncan autonomously retrieve clinically relevant information in a real hospital\nsetting.\n  Methods: We developed EHR-MCP, a framework of custom MCP tools integrated\nwith the hospital EHR database, and used GPT-4.1 through a LangGraph ReAct\nagent to interact with it. Six tasks were tested, derived from use cases of the\ninfection control team (ICT). Eight patients discussed at ICT conferences were\nretrospectively analyzed. Agreement with physician-generated gold standards was\nmeasured.\n  Results: The LLM consistently selected and executed the correct MCP tools.\nExcept for two tasks, all tasks achieved near-perfect accuracy. Performance was\nlower in the complex task requiring time-dependent calculations. Most errors\narose from incorrect arguments or misinterpretation of tool results. Responses\nfrom EHR-MCP were reliable, though long and repetitive data risked exceeding\nthe context window.\n  Conclusions: LLMs can retrieve clinical data from an EHR via MCP tools in a\nreal hospital setting, achieving near-perfect performance in simple tasks while\nhighlighting challenges in complex ones. EHR-MCP provides an infrastructure for\nsecure, consistent data access and may serve as a foundation for hospital AI\nagents. Future work should extend beyond retrieval to reasoning, generation,\nand clinical impact assessment, paving the way for effective integration of\ngenerative AI into clinical practice."}
{"id": "2509.15962", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15962", "abs": "https://arxiv.org/abs/2509.15962", "authors": ["Sander Schildermans", "Chang Tian", "Ying Jiao", "Marie-Francine Moens"], "title": "Structured Information for Improving Spatial Relationships in Text-to-Image Generation", "comment": "text-to-image generation, structured information, spatial\n  relationship", "summary": "Text-to-image (T2I) generation has advanced rapidly, yet faithfully capturing\nspatial relationships described in natural language prompts remains a major\nchallenge. Prior efforts have addressed this issue through prompt optimization,\nspatially grounded generation, and semantic refinement. This work introduces a\nlightweight approach that augments prompts with tuple-based structured\ninformation, using a fine-tuned language model for automatic conversion and\nseamless integration into T2I pipelines. Experimental results demonstrate\nsubstantial improvements in spatial accuracy, without compromising overall\nimage quality as measured by Inception Score. Furthermore, the automatically\ngenerated tuples exhibit quality comparable to human-crafted tuples. This\nstructured information provides a practical and portable solution to enhance\nspatial relationships in T2I generation, addressing a key limitation of current\nlarge-scale generative systems."}
{"id": "2509.16058", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.16058", "abs": "https://arxiv.org/abs/2509.16058", "authors": ["Krati Saxena", "Federico Jurado Ruiz", "Guido Manzi", "Dianbo Liu", "Alex Lamb"], "title": "Attention Schema-based Attention Control (ASAC): A Cognitive-Inspired Approach for Attention Management in Transformers", "comment": null, "summary": "Attention mechanisms have become integral in AI, significantly enhancing\nmodel performance and scalability by drawing inspiration from human cognition.\nConcurrently, the Attention Schema Theory (AST) in cognitive science posits\nthat individuals manage their attention by creating a model of the attention\nitself, effectively allocating cognitive resources. Inspired by AST, we\nintroduce ASAC (Attention Schema-based Attention Control), which integrates the\nattention schema concept into artificial neural networks. Our initial\nexperiments focused on embedding the ASAC module within transformer\narchitectures. This module employs a Vector-Quantized Variational AutoEncoder\n(VQVAE) as both an attention abstractor and controller, facilitating precise\nattention management. By explicitly modeling attention allocation, our approach\naims to enhance system efficiency. We demonstrate ASAC's effectiveness in both\nthe vision and NLP domains, highlighting its ability to improve classification\naccuracy and expedite the learning process. Our experiments with vision\ntransformers across various datasets illustrate that the attention controller\nnot only boosts classification accuracy but also accelerates learning.\nFurthermore, we have demonstrated the model's robustness and generalization\ncapabilities across noisy and out-of-distribution datasets. In addition, we\nhave showcased improved performance in multi-task settings. Quick experiments\nreveal that the attention schema-based module enhances resilience to\nadversarial attacks, optimizes attention to improve learning efficiency, and\nfacilitates effective transfer learning and learning from fewer examples. These\npromising results establish a connection between cognitive science and machine\nlearning, shedding light on the efficient utilization of attention mechanisms\nin AI systems."}
