{"id": "2507.22865", "categories": ["cs.IT", "cs.SY", "eess.SY", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.22865", "abs": "https://arxiv.org/abs/2507.22865", "authors": ["Sahan Liyanaarachchi", "Sennur Ulukus"], "title": "Age of Estimates: When to Submit Jobs to a Markov Machine to Maximize Revenue", "comment": null, "summary": "With the dawn of AI factories ushering a new era of computing supremacy,\ndevelopment of strategies to effectively track and utilize the available\ncomputing resources is garnering utmost importance. These computing resources\nare often modeled as Markov sources, which oscillate between free and busy\nstates, depending on their internal load and external utilization, and are\ncommonly referred to as Markov machines (MMs). Most of the prior work solely\nfocuses on the problem of tracking these MMs, while often assuming a\nrudimentary decision process that governs their utilization. Our key\nobservation is that the ultimate goal of tracking a MM is to properly utilize\nit. In this work, we consider the problem of maximizing the utility of a MM,\nwhere the utility is defined as the average revenue generated by the MM.\nAssuming a Poisson job arrival process and a query-based sampling procedure to\nsample the state of the MM, we find the optimal times to submit the available\njobs to the MM so as to maximize the average revenue generated per unit job. We\nshow that, depending on the parameters of the MM, the optimal policy is in the\nform of either a \\emph{threshold policy} or a \\emph{switching policy} based on\nthe \\emph{age of our estimate} of the state of the MM."}
{"id": "2507.22131", "categories": ["cs.NI", "cs.DC", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.22131", "abs": "https://arxiv.org/abs/2507.22131", "authors": ["Theviyanthan Krishnamohan", "Paul Harvey"], "title": "OpenRASE: Service Function Chain Emulation", "comment": "Accepted to IEEE SoftCom 2025", "summary": "Service Function Chains (SFCs) are one of the key enablers in providing\nprogrammable computer networks, paving the way for network autonomy. However,\nthis also introduces new challenges, such as resource allocation and\noptimisation related to their operation, requiring new algorithms to address\nthese challenges. Various tools have been used in the literature to evaluate\nthese algorithms. However, these tools suffer from inaccuracy, low fidelity,\nunscalability, inflexibility, or additional code requirements. This paper\nintroduces an emulator based on Mininet and Docker for SFCs called OpenRASE.\nThe goal of OpenRASE is to enable the exploration of resource allocation\nalgorithms for SFCs in a dynamic setting, allowing real CPU usage and latency\nto be measured. We describe the design and implementation of OpenRASE and\ndiscuss its characteristics. We also experimentally evaluate two different\nalgorithms to address the SFC resource allocation challenge, including an\nonline Genetic Algorithm, using OpenRASE to show its effectiveness and\npracticality for dynamic network conditions."}
{"id": "2507.22732", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.22732", "abs": "https://arxiv.org/abs/2507.22732", "authors": ["Wittawat Kositwattanarerk"], "title": "Dynamic Exponent Market Maker: Personalized Portfolio Manager and One Pool to Trade Them All", "comment": "This is a preprint of the article with the same title in Blockchain:\n  Research and Applications", "summary": "Decentralized exchange platforms such as Uniswap and Balancer operate on\nseveral pools where each pool contains two or more cryptocurrencies and\nconstitutes direct trading pairs. The drawbacks here are that liquidity\nproviding requires contribution of tokens in a specific proportion, and trading\nmay require hopping between pools, hence increasing transaction fee and gas\nfee. We propose an automated market maker (AMM) protocol where liquidity\nproviders can deposit any amount of tokens into the pool. The protocol will\npreserve the proportion of tokens by total value at the time of deposit and can\nbe seen as a personalized self-balancing portfolio manager. In addition, since\nthe invariant function is dynamic, all exchange pairs are executed from a\nsingle composite pool. Nevertheless, the scheme is vulnerable to flash loan\nattacks and must be used in conjunction with preventive measures."}
{"id": "2507.22149", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22149", "abs": "https://arxiv.org/abs/2507.22149", "authors": ["Xianxuan Long", "Yao Fu", "Runchao Li", "Mu Sheng", "Haotian Yu", "Xiaotian Han", "Pan Li"], "title": "When Truthful Representations Flip Under Deceptive Instructions?", "comment": null, "summary": "Large language models (LLMs) tend to follow maliciously crafted instructions\nto generate deceptive responses, posing safety challenges. How deceptive\ninstructions alter the internal representations of LLM compared to truthful\nones remains poorly understood beyond output analysis. To bridge this gap, we\ninvestigate when and how these representations ``flip'', such as from truthful\nto deceptive, under deceptive versus truthful/neutral instructions. Analyzing\nthe internal representations of Llama-3.1-8B-Instruct and Gemma-2-9B-Instruct\non a factual verification task, we find the model's instructed True/False\noutput is predictable via linear probes across all conditions based on the\ninternal representation. Further, we use Sparse Autoencoders (SAEs) to show\nthat the Deceptive instructions induce significant representational shifts\ncompared to Truthful/Neutral representations (which are similar), concentrated\nin early-to-mid layers and detectable even on complex datasets. We also\nidentify specific SAE features highly sensitive to deceptive instruction and\nuse targeted visualizations to confirm distinct truthful/deceptive\nrepresentational subspaces. % Our analysis pinpoints layer-wise and\nfeature-level correlates of instructed dishonesty, offering insights for LLM\ndetection and control. Our findings expose feature- and layer-level signatures\nof deception, offering new insights for detecting and mitigating instructed\ndishonesty in LLMs."}
{"id": "2507.22317", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22317", "abs": "https://arxiv.org/abs/2507.22317", "authors": ["Ze Zhang", "Qian Dong", "Wenhan Wang"], "title": "AdapSCA-PSO: An Adaptive Localization Algorithm with AI-Based Hybrid SCA-PSO for IoT WSNs", "comment": null, "summary": "The accurate localization of sensor nodes is a fundamental requirement for\nthe practical application of the Internet of Things (IoT). To enable robust\nlocalization across diverse environments, this paper proposes a hybrid\nmeta-heuristic localization algorithm. Specifically, the algorithm integrates\nthe Sine Cosine Algorithm (SCA), which is effective in global search, with\nParticle Swarm Optimization (PSO), which excels at local search. An adaptive\nswitching module is introduced to dynamically select between the two\nalgorithms. Furthermore, the initialization, fitness evaluation, and parameter\nsettings of the algorithm have been specifically redesigned and optimized to\naddress the characteristics of the node localization problem. Simulation\nresults across varying numbers of sensor nodes demonstrate that, compared to\nstandalone PSO and the unoptimized SCAPSO algorithm, the proposed method\nsignificantly reduces the number of required iterations and achieves an average\nlocalization error reduction of 84.97%."}
{"id": "2507.22865", "categories": ["cs.IT", "cs.SY", "eess.SY", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.22865", "abs": "https://arxiv.org/abs/2507.22865", "authors": ["Sahan Liyanaarachchi", "Sennur Ulukus"], "title": "Age of Estimates: When to Submit Jobs to a Markov Machine to Maximize Revenue", "comment": null, "summary": "With the dawn of AI factories ushering a new era of computing supremacy,\ndevelopment of strategies to effectively track and utilize the available\ncomputing resources is garnering utmost importance. These computing resources\nare often modeled as Markov sources, which oscillate between free and busy\nstates, depending on their internal load and external utilization, and are\ncommonly referred to as Markov machines (MMs). Most of the prior work solely\nfocuses on the problem of tracking these MMs, while often assuming a\nrudimentary decision process that governs their utilization. Our key\nobservation is that the ultimate goal of tracking a MM is to properly utilize\nit. In this work, we consider the problem of maximizing the utility of a MM,\nwhere the utility is defined as the average revenue generated by the MM.\nAssuming a Poisson job arrival process and a query-based sampling procedure to\nsample the state of the MM, we find the optimal times to submit the available\njobs to the MM so as to maximize the average revenue generated per unit job. We\nshow that, depending on the parameters of the MM, the optimal policy is in the\nform of either a \\emph{threshold policy} or a \\emph{switching policy} based on\nthe \\emph{age of our estimate} of the state of the MM."}
{"id": "2507.22197", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.22197", "abs": "https://arxiv.org/abs/2507.22197", "authors": ["Matthieu Queloz"], "title": "Explainability Through Systematicity: The Hard Systematicity Challenge for Artificial Intelligence", "comment": "39 pages; final, published version", "summary": "This paper argues that explainability is only one facet of a broader ideal\nthat shapes our expectations towards artificial intelligence (AI).\nFundamentally, the issue is to what extent AI exhibits systematicity--not\nmerely in being sensitive to how thoughts are composed of recombinable\nconstituents, but in striving towards an integrated body of thought that is\nconsistent, coherent, comprehensive, and parsimoniously principled. This richer\nconception of systematicity has been obscured by the long shadow of the\n\"systematicity challenge\" to connectionism, according to which network\narchitectures are fundamentally at odds with what Fodor and colleagues termed\n\"the systematicity of thought.\" I offer a conceptual framework for thinking\nabout \"the systematicity of thought\" that distinguishes four senses of the\nphrase. I use these distinctions to defuse the perceived tension between\nsystematicity and connectionism and show that the conception of systematicity\nthat historically shaped our sense of what makes thought rational,\nauthoritative, and scientific is more demanding than the Fodorian notion. To\ndetermine whether we have reason to hold AI models to this ideal of\nsystematicity, I then argue, we must look to the rationales for systematization\nand explore to what extent they transfer to AI models. I identify five such\nrationales and apply them to AI. This brings into view the \"hard systematicity\nchallenge.\" However, the demand for systematization itself needs to be\nregulated by the rationales for systematization. This yields a dynamic\nunderstanding of the need to systematize thought, which tells us how systematic\nwe need AI models to be and when."}
{"id": "2507.22591", "categories": ["cs.NI", "eess.SP", "14J60 (Primary) 14F05, 14J26 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.22591", "abs": "https://arxiv.org/abs/2507.22591", "authors": ["Pablo Picazo-Martinez", "Carlos Barroso-Fernández", "Alejandro Calvillo-Fernandez", "Milan Groshev", "Carlos J. Bernardos", "Antonio de la Oliva", "Alain Mourad"], "title": "802.11bf Multiband Passive Sensing: Reusing Wi-Fi Signaling for Sensing", "comment": "16 pages, 16 figures, 4 tables", "summary": "This paper presents a novel multiband passive sensing system that leverages\nIEEE 802.11bf Wi-Fi signals for environmental sensing, focusing on both sub-7\nGHz and millimeter-wave (mmWave) bands. By combining Channel State Information\n(CSI) from multiple bands, the system enhances accuracy and reliability in\ndetecting human presence, movement, and activities in indoor environments.\nUtilizing a novel model, called MILAGRO, the system demonstrates robust\nperformance across different scenarios, including monitoring human presence in\nworkspaces and tracking movement in corridors. Experimental results show high\naccuracy (95-100%), with improved performance by integrating multiband data.\nThe system also addresses key security concerns associated with passive\nsensing, proposing measures to mitigate potential risks. This work advances the\nuse of Wi-Fi for passive sensing by reducing reliance on active sensing\ninfrastructure and extending the capabilities of low-cost, non-intrusive\nenvironmental monitoring."}
{"id": "2507.22281", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.22281", "abs": "https://arxiv.org/abs/2507.22281", "authors": ["Minsoo Kim", "Seung-won Hwang"], "title": "CoEx -- Co-evolving World-model and Exploration", "comment": null, "summary": "Planning in modern LLM agents relies on the utilization of LLM as an internal\nworld model, acquired during pretraining. However, existing agent designs fail\nto effectively assimilate new observations into dynamic updates of the world\nmodel. This reliance on the LLM's static internal world model is progressively\nprone to misalignment with the underlying true state of the world, leading to\nthe generation of divergent and erroneous plans. We introduce a hierarchical\nagent architecture, CoEx, in which hierarchical state abstraction allows LLM\nplanning to co-evolve with a dynamically updated model of the world. CoEx plans\nand interacts with the world by using LLM reasoning to orchestrate dynamic\nplans consisting of subgoals, and its learning mechanism continuously\nincorporates these subgoal experiences into a persistent world model in the\nform of a neurosymbolic belief state, comprising textual inferences and\ncode-based symbolic memory. We evaluate our agent across a diverse set of agent\nscenarios involving rich environments and complex tasks including ALFWorld,\nPDDL, and Jericho. Our experiments show that CoEx outperforms existing agent\nparadigms in planning and exploration."}
{"id": "2507.22687", "categories": ["cs.NI", "cs.AI", "cs.LO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.22687", "abs": "https://arxiv.org/abs/2507.22687", "authors": ["Josh Millar", "Ryan Gibb", "Roy Ang", "Anil Madhavapeddy", "Hamed Haddadi"], "title": "Bifröst: Spatial Networking with Bigraphs", "comment": "Submitted to HotNets 2025", "summary": "Modern networked environments increasingly rely on spatial reasoning, but\nlack a coherent representation for coordinating physical space. Consequently,\ntasks such as enforcing spatial access policies remain fragile and manual. We\nfirst propose a unifying representation based on bigraphs, capturing spatial,\nsocial, and communication relationships within a single formalism, with\nuser-facing tools to generate bigraphs from physical environments. Second, we\npresent a hierarchical agent architecture for distributed spatial reasoning,\nwith runtimes for agentic processes to interact the spatial representation, and\na context-aware execution model that scopes reasoning to the smallest viable\nsubspace. Together, these enable private, reliable, and low-latency spatial\nnetworking that can safely interact with agentic workflows."}
{"id": "2507.22326", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22326", "abs": "https://arxiv.org/abs/2507.22326", "authors": ["Qun Ma", "Xiao Xue", "Ming Zhang", "Yifan Shen", "Zihan Zhao"], "title": "An Explainable Emotion Alignment Framework for LLM-Empowered Agent in Metaverse Service Ecosystem", "comment": null, "summary": "Metaverse service is a product of the convergence between Metaverse and\nservice systems, designed to address service-related challenges concerning\ndigital avatars, digital twins, and digital natives within Metaverse. With the\nrise of large language models (LLMs), agents now play a pivotal role in\nMetaverse service ecosystem, serving dual functions: as digital avatars\nrepresenting users in the virtual realm and as service assistants (or NPCs)\nproviding personalized support. However, during the modeling of Metaverse\nservice ecosystems, existing LLM-based agents face significant challenges in\nbridging virtual-world services with real-world services, particularly\nregarding issues such as character data fusion, character knowledge\nassociation, and ethical safety concerns. This paper proposes an explainable\nemotion alignment framework for LLM-based agents in Metaverse Service\nEcosystem. It aims to integrate factual factors into the decision-making loop\nof LLM-based agents, systematically demonstrating how to achieve more\nrelational fact alignment for these agents. Finally, a simulation experiment in\nthe Offline-to-Offline food delivery scenario is conducted to evaluate the\neffectiveness of this framework, obtaining more realistic social emergence."}
{"id": "2507.22711", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22711", "abs": "https://arxiv.org/abs/2507.22711", "authors": ["Hong-Jun Yoon", "Mariam Kiran", "Danial Ebling", "Joe Breen"], "title": "OFCnetLLM: Large Language Model for Network Monitoring and Alertness", "comment": null, "summary": "The rapid evolution of network infrastructure is bringing new challenges and\nopportunities for efficient network management, optimization, and security.\nWith very large monitoring databases becoming expensive to explore, the use of\nAI and Generative AI can help reduce costs of managing these datasets. This\npaper explores the use of Large Language Models (LLMs) to revolutionize network\nmonitoring management by addressing the limitations of query finding and\npattern analysis. We leverage LLMs to enhance anomaly detection, automate\nroot-cause analysis, and automate incident analysis to build a well-monitored\nnetwork management team using AI. Through a real-world example of developing\nour own OFCNetLLM, based on the open-source LLM model, we demonstrate practical\napplications of OFCnetLLM in the OFC conference network. Our model is developed\nas a multi-agent approach and is still evolving, and we present early results\nhere."}
{"id": "2507.22358", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.22358", "abs": "https://arxiv.org/abs/2507.22358", "authors": ["Hussein Mozannar", "Gagan Bansal", "Cheng Tan", "Adam Fourney", "Victor Dibia", "Jingya Chen", "Jack Gerrits", "Tyler Payne", "Matheus Kunzler Maldaner", "Madeleine Grunde-McLaughlin", "Eric Zhu", "Griffin Bassman", "Jacob Alber", "Peter Chang", "Ricky Loynd", "Friederike Niedtner", "Ece Kamar", "Maya Murad", "Rafah Hosn", "Saleema Amershi"], "title": "Magentic-UI: Towards Human-in-the-loop Agentic Systems", "comment": null, "summary": "AI agents powered by large language models are increasingly capable of\nautonomously completing complex, multi-step tasks using external tools. Yet,\nthey still fall short of human-level performance in most domains including\ncomputer use, software development, and research. Their growing autonomy and\nability to interact with the outside world, also introduces safety and security\nrisks including potentially misaligned actions and adversarial manipulation. We\nargue that human-in-the-loop agentic systems offer a promising path forward,\ncombining human oversight and control with AI efficiency to unlock productivity\nfrom imperfect systems. We introduce Magentic-UI, an open-source web interface\nfor developing and studying human-agent interaction. Built on a flexible\nmulti-agent architecture, Magentic-UI supports web browsing, code execution,\nand file manipulation, and can be extended with diverse tools via Model Context\nProtocol (MCP). Moreover, Magentic-UI presents six interaction mechanisms for\nenabling effective, low-cost human involvement: co-planning, co-tasking,\nmulti-tasking, action guards, and long-term memory. We evaluate Magentic-UI\nacross four dimensions: autonomous task completion on agentic benchmarks,\nsimulated user testing of its interaction capabilities, qualitative studies\nwith real users, and targeted safety assessments. Our findings highlight\nMagentic-UI's potential to advance safe and efficient human-agent\ncollaboration."}
{"id": "2507.22851", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.22851", "abs": "https://arxiv.org/abs/2507.22851", "authors": ["Yidong Ren", "Maolin Gan", "Chenning Li", "Shakhrul Iman Siam", "Mi Zhang", "Shigang Chen", "Zhichao Cao"], "title": "Morph: ChirpTransformer-based Encoder-decoder Co-design for Reliable LoRa Communication", "comment": null, "summary": "In this paper, we propose Morph, a LoRa encoder-decoder co-design to enhance\ncommunication reliability while improving its computation efficiency in\nextremely-low signal-to-noise ratio (SNR) situations. The standard LoRa encoder\ncontrols 6 Spreading Factors (SFs) to tradeoff SNR tolerance with data rate.\nSF-12 is the maximum SF providing the lowest SNR tolerance on commercial\noff-the-shelf (COTS) LoRa nodes. In Morph, we develop an SF-configuration based\nencoder to mimic the larger SFs beyond SF-12 while it is compatible with COTS\nLoRa nodes. Specifically, we manipulate four SF configurations of a Morph\nsymbol to encode 2-bit data. Accordingly, we recognize the used SF\nconfiguration of the symbol for data decoding. We leverage a Deep Neural\nNetwork (DNN) decoder to fully capture multi-dimensional features among diverse\nSF configurations to maximize the SNR gain. Moreover, we customize the input\nsize, neural network structure, and training method of the DNN decoder to\nimprove its efficiency, reliability, and generalizability. We implement Morph\nwith COTS LoRa nodes and a USRP N210, then evaluate its performance on indoor\nand campus-scale testbeds. Results show that we can reliably decode data at\n-28.8~dB SNR, which is 6.4~dB lower than the standard LoRa with SF-12 chirps.\nIn addition, the computation efficiency of our DNN decoder is about 3x higher\nthan state-of-the-art."}
{"id": "2507.22359", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.22359", "abs": "https://arxiv.org/abs/2507.22359", "authors": ["Qianhong Guo", "Wei Xie", "Xiaofang Cai", "Enze Wang", "Shuoyoucheng Ma", "Kai Chen", "Xiaofeng Wang", "Baosheng Wang"], "title": "LLM-Crowdsourced: A Benchmark-Free Paradigm for Mutual Evaluation of Large Language Models", "comment": null, "summary": "Although large language models (LLMs) demonstrate remarkable capabilities\nacross various tasks, evaluating their capabilities remains a challenging task.\nExisting evaluation methods suffer from issues such as data contamination,\nblack-box operation, and subjective preference. These issues make it difficult\nto evaluate the LLMs' true capabilities comprehensively. To tackle these\nchallenges, we propose a novel benchmark-free evaluation paradigm,\nLLM-Crowdsourced. It utilizes LLMs to generate questions, answer independently,\nand evaluate mutually. This method integrates four key evaluation criteria:\ndynamic, transparent, objective, and professional, which existing evaluation\nmethods cannot satisfy simultaneously. Experiments on eight mainstream LLMs\nacross mathematics and programming verify the advantages of our method in\ndistinguishing LLM performance. Furthermore, our study reveals several novel\nfindings that are difficult for traditional methods to detect, including but\nnot limited to: (1) Gemini demonstrates the highest original and professional\nquestion-design capabilities among others; (2) Some LLMs exhibit\n''memorization-based answering'' by misrecognizing questions as familiar ones\nwith a similar structure; (3) LLM evaluation results demonstrate high\nconsistency (robustness)."}
{"id": "2507.22365", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.22365", "abs": "https://arxiv.org/abs/2507.22365", "authors": ["ZhaoBin Li", "Mark Steyvers"], "title": "Beyond Accuracy: How AI Metacognitive Sensitivity improves AI-assisted Decision Making", "comment": "26 pages, 5 figures, submitted to Decision Analysis", "summary": "In settings where human decision-making relies on AI input, both the\npredictive accuracy of the AI system and the reliability of its confidence\nestimates influence decision quality. We highlight the role of AI metacognitive\nsensitivity -- its ability to assign confidence scores that accurately\ndistinguish correct from incorrect predictions -- and introduce a theoretical\nframework for assessing the joint impact of AI's predictive accuracy and\nmetacognitive sensitivity in hybrid decision-making settings. Our analysis\nidentifies conditions under which an AI with lower predictive accuracy but\nhigher metacognitive sensitivity can enhance the overall accuracy of human\ndecision making. Finally, a behavioral experiment confirms that greater AI\nmetacognitive sensitivity improves human decision performance. Together, these\nfindings underscore the importance of evaluating AI assistance not only by\naccuracy but also by metacognitive sensitivity, and of optimizing both to\nachieve superior decision outcomes."}
{"id": "2507.22423", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22423", "abs": "https://arxiv.org/abs/2507.22423", "authors": ["Kei-Sing Ng"], "title": "On the Definition of Intelligence", "comment": "Accepted at AGI-25", "summary": "To engineer AGI, we should first capture the essence of intelligence in a\nspecies-agnostic form that can be evaluated, while being sufficiently general\nto encompass diverse paradigms of intelligent behavior, including reinforcement\nlearning, generative models, classification, analogical reasoning, and\ngoal-directed decision-making. We propose a general criterion based on sample\nfidelity: intelligence is the ability, given sample(s) from a category, to\ngenerate sample(s) from the same category. We formalise this intuition as\n{\\epsilon}-category intelligence: it is {\\epsilon}-intelligent with respect to\na category if no chosen admissible distinguisher can separate generated from\noriginal samples beyond tolerance {\\epsilon}. We present the formal framework,\noutline empirical protocols, and discuss implications for evaluation, safety,\nand generalization."}
{"id": "2507.22432", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22432", "abs": "https://arxiv.org/abs/2507.22432", "authors": ["Zhe Yu", "Yiwei Lu", "Burkhard Schafer", "Zhe Lin"], "title": "Cross-Border Legal Adaptation of Autonomous Vehicle Design based on Logic and Non-monotonic Reasoning", "comment": "Accepted to appear in Proceedings of the 20th International\n  Conference on Artificial Intelligence and Law (ICAIL 2025)", "summary": "This paper focuses on the legal compliance challenges of autonomous vehicles\nin a transnational context. We choose the perspective of designers and try to\nprovide supporting legal reasoning in the design process. Based on\nargumentation theory, we introduce a logic to represent the basic properties of\nargument-based practical (normative) reasoning, combined with partial order\nsets of natural numbers to express priority. Finally, through case analysis of\nlegal texts, we show how the reasoning system we provide can help designers to\nadapt their design solutions more flexibly in the cross-border application of\nautonomous vehicles and to more easily understand the legal implications of\ntheir decisions."}
{"id": "2507.22440", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.22440", "abs": "https://arxiv.org/abs/2507.22440", "authors": ["Yiya Diao", "Changhe Li", "Sanyou Zeng", "Xinye Cai", "Wenjian Luo", "Shengxiang Yang", "Carlos A. Coello Coello"], "title": "Nearest-Better Network for Visualizing and Analyzing Combinatorial Optimization Problems: A Unified Tool", "comment": null, "summary": "The Nearest-Better Network (NBN) is a powerful method to visualize sampled\ndata for continuous optimization problems while preserving multiple landscape\nfeatures. However, the calculation of NBN is very time-consuming, and the\nextension of the method to combinatorial optimization problems is challenging\nbut very important for analyzing the algorithm's behavior. This paper provides\na straightforward theoretical derivation showing that the NBN network\nessentially functions as the maximum probability transition network for\nalgorithms. This paper also presents an efficient NBN computation method with\nlogarithmic linear time complexity to address the time-consuming issue. By\napplying this efficient NBN algorithm to the OneMax problem and the Traveling\nSalesman Problem (TSP), we have made several remarkable discoveries for the\nfirst time: The fitness landscape of OneMax exhibits neutrality, ruggedness,\nand modality features. The primary challenges of TSP problems are ruggedness,\nmodality, and deception. Two state-of-the-art TSP algorithms (i.e., EAX and\nLKH) have limitations when addressing challenges related to modality and\ndeception, respectively. LKH, based on local search operators, fails when there\nare deceptive solutions near global optima. EAX, which is based on a single\npopulation, can efficiently maintain diversity. However, when multiple\nattraction basins exist, EAX retains individuals within multiple basins\nsimultaneously, reducing inter-basin interaction efficiency and leading to\nalgorithm's stagnation."}
{"id": "2507.22504", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22504", "abs": "https://arxiv.org/abs/2507.22504", "authors": ["Hongyan Cheng", "Chengzhang Yu", "Yanshu Shi", "Chiyue Wang", "Cong Liu", "Zhanpeng Jin"], "title": "Collaborative Medical Triage under Uncertainty: A Multi-Agent Dynamic Matching Approach", "comment": "10 pages, 8 figures, 2 table", "summary": "The post-pandemic surge in healthcare demand, coupled with critical nursing\nshortages, has placed unprecedented pressure on emergency department triage\nsystems, necessitating innovative AI-driven solutions. We present a multi-agent\ninteractive intelligent system for medical triage that addresses three\nfundamental challenges in current AI-based triage systems: insufficient medical\nspecialization leading to hallucination-induced misclassifications,\nheterogeneous department structures across healthcare institutions, and\ninefficient detail-oriented questioning that impedes rapid triage decisions.\nOur system employs three specialized agents - RecipientAgent, InquirerAgent,\nand DepartmentAgent - that collaborate through structured inquiry mechanisms\nand department-specific guidance rules to transform unstructured patient\nsymptoms into accurate department recommendations. To ensure robust evaluation,\nwe constructed a comprehensive Chinese medical triage dataset from a medical\nwebsite, comprising 3,360 real-world cases spanning 9 primary departments and\n62 secondary departments. Through systematic data imputation using large\nlanguage models, we address the prevalent issue of incomplete medical records\nin real-world data. Experimental results demonstrate that our multi-agent\nsystem achieves 89.2% accuracy in primary department classification and 73.9%\naccuracy in secondary department classification after four rounds of patient\ninteraction. The system's pattern-matching-based guidance mechanisms enable\nefficient adaptation to diverse hospital configurations while maintaining high\ntriage accuracy. Our work provides a scalable framework for deploying\nAI-assisted triage systems that can accommodate the organizational\nheterogeneity of healthcare institutions while ensuring clinically sound\ndecision-making."}
{"id": "2507.22606", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22606", "abs": "https://arxiv.org/abs/2507.22606", "authors": ["Yaolun Zhang", "Xiaogeng Liu", "Chaowei Xiao"], "title": "MetaAgent: Automatically Constructing Multi-Agent Systems Based on Finite State Machines", "comment": "ICML 2025", "summary": "Large Language Models (LLMs) have demonstrated the ability to solve a wide\nrange of practical tasks within multi-agent systems. However, existing\nhuman-designed multi-agent frameworks are typically limited to a small set of\npre-defined scenarios, while current automated design methods suffer from\nseveral limitations, such as the lack of tool integration, dependence on\nexternal training data, and rigid communication structures. In this paper, we\npropose MetaAgent, a finite state machine based framework that can\nautomatically generate a multi-agent system. Given a task description,\nMetaAgent will design a multi-agent system and polish it through an\noptimization algorithm. When the multi-agent system is deployed, the finite\nstate machine will control the agent's actions and the state transitions. To\nevaluate our framework, we conduct experiments on both text-based tasks and\npractical tasks. The results indicate that the generated multi-agent system\nsurpasses other auto-designed methods and can achieve a comparable performance\nwith the human-designed multi-agent system, which is optimized for those\nspecific tasks."}
{"id": "2507.22619", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22619", "abs": "https://arxiv.org/abs/2507.22619", "authors": ["Sebastian Monka", "Irlan Grangel-González", "Stefan Schmid", "Lavdim Halilaj", "Marc Rickart", "Oliver Rudolph", "Rui Dias"], "title": "Enhancing Manufacturing Knowledge Access with LLMs and Context-aware Prompting", "comment": "European Conference on Artificial Intelligence (ECAI) 2024", "summary": "Knowledge graphs (KGs) have transformed data management within the\nmanufacturing industry, offering effective means for integrating disparate data\nsources through shared and structured conceptual schemas. However, harnessing\nthe power of KGs can be daunting for non-experts, as it often requires\nformulating complex SPARQL queries to retrieve specific information. With the\nadvent of Large Language Models (LLMs), there is a growing potential to\nautomatically translate natural language queries into the SPARQL format, thus\nbridging the gap between user-friendly interfaces and the sophisticated\narchitecture of KGs. The challenge remains in adequately informing LLMs about\nthe relevant context and structure of domain-specific KGs, e.g., in\nmanufacturing, to improve the accuracy of generated queries. In this paper, we\nevaluate multiple strategies that use LLMs as mediators to facilitate\ninformation retrieval from KGs. We focus on the manufacturing domain,\nparticularly on the Bosch Line Information System KG and the I40 Core\nInformation Model. In our evaluation, we compare various approaches for feeding\nrelevant context from the KG to the LLM and analyze their proficiency in\ntransforming real-world questions into SPARQL queries. Our findings show that\nLLMs can significantly improve their performance on generating correct and\ncomplete queries when provided only the adequate context of the KG schema. Such\ncontext-aware prompting techniques help LLMs to focus on the relevant parts of\nthe ontology and reduce the risk of hallucination. We anticipate that the\nproposed techniques help LLMs to democratize access to complex data\nrepositories and empower informed decision-making in manufacturing settings."}
{"id": "2507.22774", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22774", "abs": "https://arxiv.org/abs/2507.22774", "authors": ["Thomas Eiter", "Tobias Geibinger", "Tobias Kaminski", "Nysret Musliu", "Johannes Oetsch"], "title": "ASP-FZN: A Translation-based Constraint Answer Set Solver", "comment": "Presented at the 41st International Conference on Logic Programming\n  (ICLP 2025)", "summary": "We present the solver asp-fzn for Constraint Answer Set Programming (CASP),\nwhich extends ASP with linear constraints. Our approach is based on translating\nCASP programs into the solver-independent FlatZinc language that supports\nseveral Constraint Programming and Integer Programming backend solvers. Our\nsolver supports a rich language of linear constraints, including some common\nglobal constraints. As for evaluation, we show that asp-fzn is competitive with\nstate-of-the-art ASP solvers on benchmarks taken from past ASP competitions.\nFurthermore, we evaluate it on several CASP problems from the literature and\ncompare its performance with clingcon, which is a prominent CASP solver that\nsupports most of the asp-fzn language. The performance of asp-fzn is very\npromising as it is already competitive on plain ASP and even outperforms\nclingcon on some CASP benchmarks."}
{"id": "2507.22782", "categories": ["cs.AI", "cs.LG", "I.2.0; I.2.8"], "pdf": "https://arxiv.org/pdf/2507.22782", "abs": "https://arxiv.org/abs/2507.22782", "authors": ["Hugo Garrido-Lestache", "Jeremy Kedziora"], "title": "Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic Policies", "comment": "8 pages", "summary": "This paper introduces Team-Attention-Actor-Critic (TAAC), a reinforcement\nlearning algorithm designed to enhance multi-agent collaboration in cooperative\nenvironments. TAAC employs a Centralized Training/Centralized Execution scheme\nincorporating multi-headed attention mechanisms in both the actor and critic.\nThis design facilitates dynamic, inter-agent communication, allowing agents to\nexplicitly query teammates, thereby efficiently managing the exponential growth\nof joint-action spaces while ensuring a high degree of collaboration. We\nfurther introduce a penalized loss function which promotes diverse yet\ncomplementary roles among agents. We evaluate TAAC in a simulated soccer\nenvironment against benchmark algorithms representing other multi-agent\nparadigms, including Proximal Policy Optimization and Multi-Agent\nActor-Attention-Critic. We find that TAAC exhibits superior performance and\nenhanced collaborative behaviors across a variety of metrics (win rates, goal\ndifferentials, Elo ratings, inter-agent connectivity, balanced spatial\ndistributions, and frequent tactical interactions such as ball possession\nswaps)."}
{"id": "2507.22847", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.22847", "abs": "https://arxiv.org/abs/2507.22847", "authors": ["Han Jiang", "Pengda Wang", "Xiaoyuan Yi", "Xing Xie", "Ziang Xiao"], "title": "The Incomplete Bridge: How AI Research (Mis)Engages with Psychology", "comment": null, "summary": "Social sciences have accumulated a rich body of theories and methodologies\nfor investigating the human mind and behaviors, while offering valuable\ninsights into the design and understanding of Artificial Intelligence (AI)\nsystems. Focusing on psychology as a prominent case, this study explores the\ninterdisciplinary synergy between AI and the field by analyzing 1,006\nLLM-related papers published in premier AI venues between 2023 and 2025, along\nwith the 2,544 psychology publications they cite. Through our analysis, we\nidentify key patterns of interdisciplinary integration, locate the psychology\ndomains most frequently referenced, and highlight areas that remain\nunderexplored. We further examine how psychology theories/frameworks are\noperationalized and interpreted, identify common types of misapplication, and\noffer guidance for more effective incorporation. Our work provides a\ncomprehensive map of interdisciplinary engagement between AI and psychology,\nthereby facilitating deeper collaboration and advancing AI systems."}
{"id": "2507.22876", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.22876", "abs": "https://arxiv.org/abs/2507.22876", "authors": ["Yiwen Sun", "Furong Ye", "Zhihan Chen", "Ke Wei", "Shaowei Cai"], "title": "Automatically discovering heuristics in a complex SAT solver with large language models", "comment": null, "summary": "Satisfiability problem (SAT) is a cornerstone of computational complexity\nwith broad industrial applications, and it remains challenging to optimize\nmodern SAT solvers in real-world settings due to their intricate architectures.\nWhile automatic configuration frameworks have been developed, they rely on\nmanually constrained search spaces and yield limited performance gains. This\nwork introduces a novel paradigm which effectively optimizes complex SAT\nsolvers via Large Language Models (LLMs), and a tool called AutoModSAT is\ndeveloped. Three fundamental challenges are addressed in order to achieve\nsuperior performance: (1) LLM-friendly solver: Systematic guidelines are\nproposed for developing a modularized solver to meet LLMs' compatibility,\nemphasizing code simplification, information share and bug reduction; (2)\nAutomatic prompt optimization: An unsupervised automatic prompt optimization\nmethod is introduced to advance the diversity of LLMs' output; (3) Efficient\nsearch strategy: We design a presearch strategy and an EA evolutionary\nalgorithm for the final efficient and effective discovery of heuristics.\nExtensive experiments across a wide range of datasets demonstrate that\nAutoModSAT achieves 50% performance improvement over the baseline solver and\nachieves 30% superiority against the state-of-the-art (SOTA) solvers. Moreover,\nAutoModSAT attains a 20% speedup on average compared to parameter-tuned\nalternatives of the SOTA solvers, showcasing the enhanced capability in\nhandling complex problem instances. This work bridges the gap between AI-driven\nheuristics discovery and mission-critical system optimization, and provides\nboth methodological advancements and empirically validated results for\nnext-generation complex solver development."}
{"id": "2507.22317", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22317", "abs": "https://arxiv.org/abs/2507.22317", "authors": ["Ze Zhang", "Qian Dong", "Wenhan Wang"], "title": "AdapSCA-PSO: An Adaptive Localization Algorithm with AI-Based Hybrid SCA-PSO for IoT WSNs", "comment": null, "summary": "The accurate localization of sensor nodes is a fundamental requirement for\nthe practical application of the Internet of Things (IoT). To enable robust\nlocalization across diverse environments, this paper proposes a hybrid\nmeta-heuristic localization algorithm. Specifically, the algorithm integrates\nthe Sine Cosine Algorithm (SCA), which is effective in global search, with\nParticle Swarm Optimization (PSO), which excels at local search. An adaptive\nswitching module is introduced to dynamically select between the two\nalgorithms. Furthermore, the initialization, fitness evaluation, and parameter\nsettings of the algorithm have been specifically redesigned and optimized to\naddress the characteristics of the node localization problem. Simulation\nresults across varying numbers of sensor nodes demonstrate that, compared to\nstandalone PSO and the unoptimized SCAPSO algorithm, the proposed method\nsignificantly reduces the number of required iterations and achieves an average\nlocalization error reduction of 84.97%."}
{"id": "2507.22687", "categories": ["cs.NI", "cs.AI", "cs.LO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.22687", "abs": "https://arxiv.org/abs/2507.22687", "authors": ["Josh Millar", "Ryan Gibb", "Roy Ang", "Anil Madhavapeddy", "Hamed Haddadi"], "title": "Bifröst: Spatial Networking with Bigraphs", "comment": "Submitted to HotNets 2025", "summary": "Modern networked environments increasingly rely on spatial reasoning, but\nlack a coherent representation for coordinating physical space. Consequently,\ntasks such as enforcing spatial access policies remain fragile and manual. We\nfirst propose a unifying representation based on bigraphs, capturing spatial,\nsocial, and communication relationships within a single formalism, with\nuser-facing tools to generate bigraphs from physical environments. Second, we\npresent a hierarchical agent architecture for distributed spatial reasoning,\nwith runtimes for agentic processes to interact the spatial representation, and\na context-aware execution model that scopes reasoning to the smallest viable\nsubspace. Together, these enable private, reliable, and low-latency spatial\nnetworking that can safely interact with agentic workflows."}
{"id": "2507.22711", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22711", "abs": "https://arxiv.org/abs/2507.22711", "authors": ["Hong-Jun Yoon", "Mariam Kiran", "Danial Ebling", "Joe Breen"], "title": "OFCnetLLM: Large Language Model for Network Monitoring and Alertness", "comment": null, "summary": "The rapid evolution of network infrastructure is bringing new challenges and\nopportunities for efficient network management, optimization, and security.\nWith very large monitoring databases becoming expensive to explore, the use of\nAI and Generative AI can help reduce costs of managing these datasets. This\npaper explores the use of Large Language Models (LLMs) to revolutionize network\nmonitoring management by addressing the limitations of query finding and\npattern analysis. We leverage LLMs to enhance anomaly detection, automate\nroot-cause analysis, and automate incident analysis to build a well-monitored\nnetwork management team using AI. Through a real-world example of developing\nour own OFCNetLLM, based on the open-source LLM model, we demonstrate practical\napplications of OFCnetLLM in the OFC conference network. Our model is developed\nas a multi-agent approach and is still evolving, and we present early results\nhere."}
