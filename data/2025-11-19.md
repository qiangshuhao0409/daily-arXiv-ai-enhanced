<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 4]
- [cs.AI](#cs.AI) [Total: 31]
- [cs.IT](#cs.IT) [Total: 5]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Benchmarking OpenWiFiSync on ESP32: Towards Cost-Effective Wireless Time Synchronization](https://arxiv.org/abs/2511.14457)
*Michael Gundall,Jan Herbst,Robin Müller,Hans D. Schotten*

Main category: cs.NI

TL;DR: 该论文提出了一种基于Wi-Fi广播的无线时间同步协议，在低成本ESP32硬件上实现了±30微秒的同步精度，并开源了实现代码。


<details>
  <summary>Details</summary>
Motivation: 无线移动设备的时间同步是工业4.0应用的关键需求，但传统有线时钟同步协议在无线环境中性能不佳，需要新的解决方案。

Method: 采用参考广播基础设施同步协议，利用无线通信的广播特性，在ESP32模块和商用Wi-Fi接入点上实现非侵入式、标准兼容的同步方案。

Result: 实验结果显示，使用节能且经济实惠的硬件可以实现±30微秒的同步精度。

Conclusion: 该方法适用于广泛的应用场景，并通过OpenWifiSync项目开源了实现代码，支持进一步的研究和开发。

Abstract: Wireless time synchronization of mobile devices is a key enabler for numerous Industry 4.0 applications, such as coordinated and synchronized tasks or the generation of high-precision timestamps for machine learning or artificial intelligence algorithms. Traditional wireline clock synchronization protocols, however, cannot achieve the performance in wireless environments without significant modifications. To address this challenge, we make use of the Reference Broadcast Infrastructure Synchronization protocol, which leverages the broadcast nature of wireless communications and remains both non-invasive and standard-compliant. We implement and validate this protocol on a low-cost testbed using ESP32 modules and a commercial Wi-Fi access point. To support further research and development, we release our implementation as open-source software under the GNU General Public License Version 3 license via the OpenWifiSync project on GitHub.
  Our results demonstrate that synchronization accuracies within +/-30 microseconds are achievable using energy-efficient and affordable hardware, making this approach suitable for a wide range of use cases.

</details>


### [2] [Cracking the Microsecond: An Efficient and Precise Time Synchronization Scheme for Hybrid 5G-TSN Networks](https://arxiv.org/abs/2511.14462)
*Michael Gundall,Hans D. Schotten*

Main category: cs.NI

TL;DR: 提出了一种利用现有基础设施实现无线设备时间同步的方案，其中一个用户设备作为主时钟，可为工厂网络提供边界时钟功能，在实验室环境中实现了±50纳秒的同步精度。


<details>
  <summary>Details</summary>
Motivation: 工业物联网市场相对于消费电子市场较小，导致IIoT增强功能尚未在芯片中实现，需要探索替代解决方案来实现无线系统的精确时间同步。

Method: 使用协议利用现有基础设施同步用户设备，其中一个UE作为主时钟；如果主UE通过有线连接到工厂网络，可充当边界时钟；使用OpenAirInterface和软件定义无线电在硬件测试平台上实现和评估。

Result: 使用窗口大小为1024的移动平均滤波器可获得最佳偏移预测精度；在受控实验室环境中，同步精度始终保持在±50纳秒范围内。

Conclusion: 所提出的协议在严格的工业用例中具有可行性和高性能，为实际部署提供了足够的同步误差余量，同时保持亚微秒级精度。

Abstract: Achieving precise time synchronization in wireless systems is essential for both industrial applications and 5G, where sub-microsecond accuracy is required. However, since the Industrial Internet of Things (IIoT) market is negligible compared to the consumer electronics market, the so-called IIoT enhancements have not yet been implemented in silicon. Moreover, there is no guarantee that this situation will change soon. Thus, alternative solutions must be explored. This paper addresses this challenge by introducing a scheme that uses a protocol capable of leveraging existing infrastructure to synchronize User Equipments (UEs), with one of the UEs serving as the master. If this master is connected via a wired link to the factory network, it can also function as a boundary clock for the factory network, including any Time-Sensitive Networking (TSN) network. Furthermore, the 5G Core Network (5GC) and 5G Base Station (gNB) can also be synchronized if they are connected either to the factory network or to the master UE. The proposed solution is implemented and evaluated on a hardware testbed using OpenAirInterface (OAI) and Software Defined Radios (SDRs). Time offset and clock skew are analyzed using a moving average filter with various window sizes. Results show that a filter size of 1024 provides the best accuracy for offset prediction between UEs. In a controlled lab environment, the approach consistently achieves synchronization within +/-50 ns, leaving sufficient margin for synchronization errors in real deployments while still maintaining sub-microsecond accuracy. These findings demonstrate the feasibility and high performance of the proposed protocol for stringent industrial use cases.

</details>


### [3] [From Topology to Behavioral Semantics: Enhancing BGP Security by Understanding BGP's Language with LLMs](https://arxiv.org/abs/2511.14467)
*Heng Zhao,Ruoyu Wang,Tianhang Zheng,Qi Li,Bo Lv,Yuyi Wang,Wenliang Du*

Main category: cs.NI

TL;DR: BGPShield是一个基于LLM嵌入的BGP异常检测框架，通过捕捉AS的行为画像和路由策略原理来检测前缀劫持和配置错误，相比传统方法具有更好的泛化性和效率。


<details>
  <summary>Details</summary>
Motivation: BGP的信任机制使其容易受到前缀劫持和配置错误的威胁，传统检测方法依赖人工检查且扩展性有限，而现有的机器学习方法存在精度不足、泛化性差和重训练成本高的问题。

Method: 提出BGPShield框架，使用LLM嵌入捕捉AS的行为画像和路由策略原理；采用分段聚合方案将AS描述转换为LLM表示；使用轻量级对比压缩网络生成语义一致版本；通过AR-DTW算法对齐和累积语义距离来检测行为不一致性。

Result: 在16个真实数据集上评估，BGPShield检测到100%的已验证异常，误报率低于5%；对未见过的AS能在1秒内构建表示，显著优于BEAM方法（平均需要65小时重训练）。

Conclusion: BGPShield通过超越拓扑的语义特征分析，有效解决了BGP异常检测中的精度、泛化性和效率问题，验证了LLM在路由安全领域的应用潜力。

Abstract: The trust-based nature of Border Gateway Protocol (BGP) makes it vulnerable to disruptions like prefix hijacking and misconfigurations, threatening routing stability. Traditional detection relies on manual inspection with limited scalability. Machine/Deep Learning (M/DL) approaches automate detection but suffer from suboptimal precision, limited generalizability, and high retraining costs. This is because existing methods focus on topological structures rather than comprehensive semantic characteristics of Autonomous Systems (ASes), often misinterpreting functionally similar but topologically distant ASes.
  To address this, we propose BGPShield, an anomaly detection framework built on LLM embeddings that captures the Behavior Portrait and Routing Policy Rationale of each AS beyond topology, such as operational scale and global role. We propose a segment-wise aggregation scheme to transform AS descriptions into LLM representations without information loss, and a lightweight contrastive reduction network to compress them into a semantic-consistent version. Using these representations, our AR-DTW algorithm aligns and accumulates semantic distances to reveal behavioral inconsistencies. Evaluated on 16 real-world datasets, BGPShield detects 100% of verified anomalies with a false discovery rate below 5%. Notably, the employed LLMs were released prior to evaluation events, verifying generalizability. Furthermore, BGPShield constructs representations for unseen ASes within one second, significantly outperforming BEAM which demands costly retraining (averaging 65 hours).

</details>


### [4] [Evaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over Heterogeneous Networks](https://arxiv.org/abs/2511.14550)
*Dimitrios Dimopoulos,Apostolis K. Salkintzis,Dimitris Tsolkas,Nikos Passas,Lazaros Merakos*

Main category: cs.NI

TL;DR: MPTCP协议在异构网络路径下的性能分析，包括包调度和拥塞控制算法的组合影响


<details>
  <summary>Details</summary>
Motivation: 现代设备配备多网络接口，MPTCP旨在同时利用多条网络路径，但在路径异构性增加时性能面临挑战

Method: 分析MPTCP协议操作，研究现有包调度和拥塞控制算法，通过广泛实验评估不同路径异构条件下的性能

Result: 不同算法组合在路径异构条件下对MPTCP性能产生显著影响

Conclusion: MPTCP性能受路径异构性影响，需要针对不同网络条件优化算法组合

Abstract: Modern mobile and stationary devices are equipped with multiple network interfaces aiming to provide wireless and wireline connectivity either in a local LAN or the Internet. Multipath TCP (MPTCP) protocol has been developed on top of legacy TCP to allow the simultaneous use of multiple network paths in the communication route between two end-systems. Although the combination of multiple paths is beneficial in case of links with similar network characteristics, MPTCP performance is challenged as heterogeneity among the used paths increases. This work provides an overview of the MPTCP protocol operation, analyzes the state-of-art packet scheduling and congestion control algorithms available in literature, and examines the impact of the various algorithm combinations on MPTCP performance, by conducting an extensive experimental evaluation under diverse path-heterogeneity conditions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [5] [Collaborative QA using Interacting LLMs. Impact of Network Structure, Node Capability and Distributed Data](https://arxiv.org/abs/2511.14098)
*Adit Jain,Vikram Krishnamurthy,Yiming Zhang*

Main category: cs.AI

TL;DR: 本文研究了LLM网络中的协作问答问题，分析了幻觉在LLM网络中的传播机制，并提出了基于平均场动力学和随机效用模型的生成模型来建模这一过程。


<details>
  <summary>Details</summary>
Motivation: LLM在缺乏直接证据时容易产生幻觉，而在交互的LLM网络中，这种幻觉效应会扩散，导致原本准确的LLM也开始产生幻觉。

Method: 结合网络科学中的平均场动力学和经济学中的随机效用模型，构建生成模型。将LLM建模为具有潜在状态（真实或幻觉）的节点，分析有向网络中信息扩散的动态过程。

Result: 为具有两种潜在状态的LLM网络建立了固定点存在性和唯一性的充分条件，并分析了激励对固定点行为的影响。在100个开源LLM网络上进行了实验研究。

Conclusion: 通过平均场动力学和随机效用模型可以有效地建模LLM网络中的幻觉传播，为理解和管理LLM协作系统中的信息可靠性提供了理论框架。

Abstract: In this paper, we model and analyze how a network of interacting LLMs performs collaborative question-answering (CQA) in order to estimate a ground truth given a distributed set of documents. This problem is interesting because LLMs often hallucinate when direct evidence to answer a question is lacking, and these effects become more pronounced in a network of interacting LLMs. The hallucination spreads, causing previously accurate LLMs to hallucinate. We study interacting LLMs and their hallucination by combining novel ideas of mean-field dynamics (MFD) from network science and the randomized utility model from economics to construct a useful generative model. We model the LLM with a latent state that indicates if it is truthful or not with respect to the ground truth, and extend a tractable analytical model considering an MFD to model the diffusion of information in a directed network of LLMs. To specify the probabilities that govern the dynamics of the MFD, we propose a randomized utility model. For a network of LLMs, where each LLM has two possible latent states, we posit sufficient conditions for the existence and uniqueness of a fixed point and analyze the behavior of the fixed point in terms of the incentive (e.g., test-time compute) given to individual LLMs. We experimentally study and analyze the behavior of a network of $100$ open-source LLMs with respect to data heterogeneity, node capability, network structure, and sensitivity to framing on multiple semi-synthetic datasets.

</details>


### [6] [Imagine in Space: Exploring the Frontier of Spatial Intelligence and Reasoning Efficiency in Vision Language Models](https://arxiv.org/abs/2511.13782)
*Xiaoxing Lian,Aidong Yang,Jun Zhu,Peng Wang,Yue Zhang*

Main category: cs.AI

TL;DR: SpatiaLite是一个合成基准测试，用于评估视觉语言模型的空间推理能力。研究发现当前先进VLM主要依赖语言表示进行空间推理，在视觉中心任务上表现不佳，且推理效率低下。作者提出了IDF框架来改进VLM的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型和视觉语言模型在逻辑推理、问题解决和决策方面表现出色，但空间推理（包括心理旋转、导航和空间关系理解）仍然是当前先进VLM的重大挑战。作者假设想象力是空间世界模型中的主导推理机制。

Method: 引入SpatiaLite合成基准测试，联合测量空间推理准确性和效率。通过全面实验分析VLM的空间推理机制，并提出Imagery Driven Framework（IDF）用于数据合成和训练。

Result: 发现三个关键结果：1）先进VLM主要依赖语言表示，在视觉中心任务上表现不佳；2）VLM空间推理效率严重低下，token使用随转换复杂度快速增加；3）IDF框架可以隐式构建内部世界模型。

Conclusion: 这项工作描绘了先进VLM的空间推理限制和模式，识别了关键缺陷，并为未来改进提供了信息。IDF框架为构建具有更好空间推理能力的VLM提供了方向。

Abstract: Large language models (LLMs) and vision language models (VLMs), such as DeepSeek R1,OpenAI o3, and Gemini 2.5 Pro, have demonstrated remarkable reasoning capabilities across logical inference, problem solving, and decision making. However, spatial reasoning:a fundamental component of human cognition that includes mental rotation, navigation, and spatial relationship comprehension remains a significant challenge for current advanced VLMs. We hypothesize that imagination, the internal simulation of spatial states, is the dominant reasoning mechanism within a spatial world model. To test this hypothesis and systematically probe current VLM spatial reasoning mechanisms, we introduce SpatiaLite, a fully synthetic benchmark that jointly measures spatial reasoning accuracy and reasoning efficiency. Comprehensive experiments reveal three key findings. First, advanced VLMs predominantly rely on linguistic representations for reasoning and imagination, resulting in significant deficiencies on visual centric tasks that demand perceptual spatial relations and 3D geometry transformations such as mental rotation or projection prediction. Second, advanced VLMs exhibit severe inefficiency in their current spatial reasoning mechanisms, with token usage growing rapidly as transformation complexity increases. Third, we propose an Imagery Driven Framework (IDF) for data synthesis and training, which can implicitly construct an internal world model that is critical for spatial reasoning in VLMs. Building on SpatiaLite, this work delineates the spatial reasoning limits and patterns of advanced VLMs, identifies key shortcomings, and informs future advances

</details>


### [7] [KANGURA: Kolmogorov-Arnold Network-Based Geometry-Aware Learning with Unified Representation Attention for 3D Modeling of Complex Structures](https://arxiv.org/abs/2511.13798)
*Mohammad Reza Shafie,Morteza Hajiabadi,Hamed Khosravi,Mobina Noori,Imtiaz Ahmed*

Main category: cs.AI

TL;DR: 提出了KANGURA框架，使用Kolmogorov-Arnold网络进行3D几何建模，在MFC阳极结构优化中表现出色，在ModelNet40数据集上达到92.7%准确率。


<details>
  <summary>Details</summary>
Motivation: 微生物燃料电池阳极结构的几何复杂性使得现有预测模型难以捕捉关键几何依赖关系，需要新的3D机器学习方法来优化这些结构。

Method: KANGURA采用Kolmogorov-Arnold网络进行函数分解，通过几何解耦表示学习分离结构变化，并使用统一注意力机制增强关键几何区域。

Result: 在ModelNet40基准数据集上超越15个SOTA模型，达到92.7%准确率；在真实MFC阳极结构问题上达到97%准确率。

Conclusion: KANGURA为3D几何建模提供了强大框架，为先进制造和质量驱动工程应用中的复杂结构优化开辟了新可能性。

Abstract: Microbial Fuel Cells (MFCs) offer a promising pathway for sustainable energy generation by converting organic matter into electricity through microbial processes. A key factor influencing MFC performance is the anode structure, where design and material properties play a crucial role. Existing predictive models struggle to capture the complex geometric dependencies necessary to optimize these structures. To solve this problem, we propose KANGURA: Kolmogorov-Arnold Network-Based Geometry-Aware Learning with Unified Representation Attention. KANGURA introduces a new approach to three-dimensional (3D) machine learning modeling. It formulates prediction as a function decomposition problem, where Kolmogorov-Arnold Network (KAN)- based representation learning reconstructs geometric relationships without a conventional multi- layer perceptron (MLP). To refine spatial understanding, geometry-disentangled representation learning separates structural variations into interpretable components, while unified attention mechanisms dynamically enhance critical geometric regions. Experimental results demonstrate that KANGURA outperforms over 15 state-of-the-art (SOTA) models on the ModelNet40 benchmark dataset, achieving 92.7% accuracy, and excels in a real-world MFC anode structure problem with 97% accuracy. This establishes KANGURA as a robust framework for 3D geometric modeling, unlocking new possibilities for optimizing complex structures in advanced manufacturing and quality-driven engineering applications.

</details>


### [8] [Rate-Distortion Guided Knowledge Graph Construction from Lecture Notes Using Gromov-Wasserstein Optimal Transport](https://arxiv.org/abs/2511.14595)
*Yuan An,Ruhma Hashmi,Michelle Rogers,Jane Greenberg,Brian K. Smith*

Main category: cs.AI

TL;DR: 提出基于率失真理论和最优传输几何的知识图谱构建与优化框架，通过FGW耦合量化语义失真，使用精炼操作最小化率失真拉格朗日函数，生成紧凑且保留信息的知识图谱。


<details>
  <summary>Details</summary>
Motivation: 将非结构化教育材料（如讲义和幻灯片）转换为捕捉关键教学内容的知识图谱仍然很困难，需要一种原则性的方法来构建和优化任务导向的知识图谱。

Method: 将讲义内容建模为度量-测度空间，使用Fused Gromov-Wasserstein耦合对齐候选知识图谱以量化语义失真，通过添加、合并、拆分、移除和重连等精炼操作最小化率失真拉格朗日函数。

Result: 在数据科学讲义上的原型应用显示，从优化后的知识图谱生成的多选题在15个质量标准上始终优于从原始笔记生成的多选题。

Conclusion: 本研究为个性化教育和AI辅助教育中的信息论知识图谱优化建立了原则性基础。

Abstract: Task-oriented knowledge graphs (KGs) enable AI-powered learning assistant systems to automatically generate high-quality multiple-choice questions (MCQs). Yet converting unstructured educational materials, such as lecture notes and slides, into KGs that capture key pedagogical content remains difficult. We propose a framework for knowledge graph construction and refinement grounded in rate-distortion (RD) theory and optimal transport geometry. In the framework, lecture content is modeled as a metric-measure space, capturing semantic and relational structure, while candidate KGs are aligned using Fused Gromov-Wasserstein (FGW) couplings to quantify semantic distortion. The rate term, expressed via the size of KG, reflects complexity and compactness. Refinement operators (add, merge, split, remove, rewire) minimize the rate-distortion Lagrangian, yielding compact, information-preserving KGs. Our prototype applied to data science lectures yields interpretable RD curves and shows that MCQs generated from refined KGs consistently surpass those from raw notes on fifteen quality criteria. This study establishes a principled foundation for information-theoretic KG optimization in personalized and AI-assisted education.

</details>


### [9] [When AI Does Science: Evaluating the Autonomous AI Scientist KOSMOS in Radiation Biology](https://arxiv.org/abs/2511.13825)
*Humza Nusrat,Omar Nusrat*

Main category: cs.AI

TL;DR: 评估KOSMOS自主AI科学家在辐射生物学中的表现，发现其产生了一个明确发现、一个不确定结果和一个错误假设，表明AI科学家能生成有用想法但需要严格验证。


<details>
  <summary>Details</summary>
Motivation: 评估自主AI科学家KOSMOS在辐射生物学问题上的表现，检验其生成假设和发现的能力。

Method: 使用简单随机基因零基准测试KOSMOS在三个辐射生物学问题上的表现：DNA损伤响应与p53转录响应关系、OGT和CDO1基因表达与辐射响应模块关系、12基因特征预测前列腺癌放疗后生存。

Result: 假设1不支持（DDR评分与p53响应弱负相关）；OGT弱相关，CDO1是明显异常值；12基因特征一致性指数0.61但效应大小不唯一。

Conclusion: AI科学家能生成有用想法，但需要针对适当零模型进行严格审计，以避免虚假发现。

Abstract: Agentic AI "scientists" now use language models to search the literature, run analyses, and generate hypotheses. We evaluate KOSMOS, an autonomous AI scientist, on three problems in radiation biology using simple random-gene null benchmarks. Hypothesis 1: baseline DNA damage response (DDR) capacity across cell lines predicts the p53 transcriptional response after irradiation (GSE30240). Hypothesis 2: baseline expression of OGT and CDO1 predicts the strength of repressed and induced radiation-response modules in breast cancer cells (GSE59732). Hypothesis 3: a 12-gene expression signature predicts biochemical recurrence-free survival after prostate radiotherapy plus androgen deprivation therapy (GSE116918). The DDR-p53 hypothesis was not supported: DDR score and p53 response were weakly negatively correlated (Spearman rho = -0.40, p = 0.76), indistinguishable from random five-gene scores. OGT showed only a weak association (r = 0.23, p = 0.34), whereas CDO1 was a clear outlier (r = 0.70, empirical p = 0.0039). The 12-gene signature achieved a concordance index of 0.61 (p = 0.017) but a non-unique effect size. Overall, KOSMOS produced one well-supported discovery, one plausible but uncertain result, and one false hypothesis, illustrating that AI scientists can generate useful ideas but require rigorous auditing against appropriate null models.

</details>


### [10] [Causal computations in Semi Markovian Structural Causal Models using divide and conquer](https://arxiv.org/abs/2511.13852)
*Anna Rodum Bjøru,Rafael Cabañas,Helge Langseth,Antonio Salmerón*

Main category: cs.AI

TL;DR: 本文扩展了Bjøru等人的分治算法，从马尔可夫因果模型推广到半马尔可夫因果模型，以处理更复杂的混淆关系。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅适用于马尔可夫因果模型，其中外生变量仅影响单个内生变量。但在实际应用中，外生变量可能影响多个内生变量，形成混淆关系，需要扩展到半马尔可夫模型。

Method: 使用分治策略将高基数外生变量的因果模型分解为多个低基数子模型，这些子模型具有精确的外生变量边际分布，允许高效精确推理。通过聚合结果来界定原始模型中的反事实概率。

Result: 通过最小示例说明了扩展的挑战，并提出并评估了替代解决方案策略。进行了理论分析和计算研究来验证方法。

Conclusion: 成功将分治算法扩展到半马尔可夫因果模型，能够处理更复杂的混淆关系，为反事实概率的界定提供了更通用的方法。

Abstract: Recently, Bjøru et al. proposed a novel divide-and-conquer algorithm for bounding counterfactual probabilities in structural causal models (SCMs). They assumed that the SCMs were learned from purely observational data, leading to an imprecise characterization of the marginal distributions of exogenous variables. Their method leveraged the canonical representation of structural equations to decompose a general SCM with high-cardinality exogenous variables into a set of sub-models with low-cardinality exogenous variables. These sub-models had precise marginals over the exogenous variables and therefore admitted efficient exact inference. The aggregated results were used to bound counterfactual probabilities in the original model. The approach was developed for Markovian models, where each exogenous variable affects only a single endogenous variable. In this paper, we investigate extending the methodology to \textit{semi-Markovian} SCMs, where exogenous variables may influence multiple endogenous variables. Such models are capable of representing confounding relationships that Markovian models cannot. We illustrate the challenges of this extension using a minimal example, which motivates a set of alternative solution strategies. These strategies are evaluated both theoretically and through a computational study.

</details>


### [11] [Jailbreaking Large Vision Language Models in Intelligent Transportation Systems](https://arxiv.org/abs/2511.13892)
*Badhan Chandra Das,Md Tasnim Jawad,Md Jueal Mia,M. Hadi Amini,Yanzhao Wu*

Main category: cs.AI

TL;DR: 本文系统分析了智能交通系统中大型视觉语言模型在精心设计的越狱攻击下的脆弱性，提出了基于图像排版操纵和多轮提示的新型越狱攻击方法，并设计了多层响应过滤防御技术。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在多模态推理和实际应用中表现出强大能力，但极易受到越狱攻击。特别是在智能交通系统等关键应用中，这种安全漏洞可能带来严重后果。

Method: 1) 构建与交通相关的有害查询数据集；2) 提出利用图像排版操纵和多轮提示的新型越狱攻击方法；3) 设计多层响应过滤防御技术来阻止模型生成不当响应。

Result: 在最先进的大型视觉语言模型上进行了广泛实验，使用GPT-4判断和人工验证评估攻击方法和防御技术的效果。与现有越狱技术相比，图像排版操纵和多轮提示攻击在智能交通系统中带来了更严重的安全风险。

Conclusion: 大型视觉语言模型在智能交通系统中存在严重的安全漏洞，需要有效的防御机制来防止越狱攻击。提出的多层响应过滤防御技术能够有效减轻这些安全风险。

Abstract: Large Vision Language Models (LVLMs) demonstrate strong capabilities in multimodal reasoning and many real-world applications, such as visual question answering. However, LVLMs are highly vulnerable to jailbreaking attacks. This paper systematically analyzes the vulnerabilities of LVLMs integrated in Intelligent Transportation Systems (ITS) under carefully crafted jailbreaking attacks. First, we carefully construct a dataset with harmful queries relevant to transportation, following OpenAI's prohibited categories to which the LVLMs should not respond. Second, we introduce a novel jailbreaking attack that exploits the vulnerabilities of LVLMs through image typography manipulation and multi-turn prompting. Third, we propose a multi-layered response filtering defense technique to prevent the model from generating inappropriate responses. We perform extensive experiments with the proposed attack and defense on the state-of-the-art LVLMs (both open-source and closed-source). To evaluate the attack method and defense technique, we use GPT-4's judgment to determine the toxicity score of the generated responses, as well as manual verification. Further, we compare our proposed jailbreaking method with existing jailbreaking techniques and highlight severe security risks involved with jailbreaking attacks with image typography manipulation and multi-turn prompting in the LVLMs integrated in ITS.

</details>


### [12] [CORGI: Efficient Pattern Matching With Quadratic Guarantees](https://arxiv.org/abs/2511.13942)
*Daniel Weitekamp*

Main category: cs.AI

TL;DR: CORGI是一种新的模式匹配算法，为实时AI系统和数据库查询提供二次时间和空间保证，避免传统RETE算法在复杂匹配时的指数级内存消耗问题。


<details>
  <summary>Details</summary>
Motivation: 基于规则的系统在实时应用中面临指数级时间和空间消耗的问题，特别是在处理具有多个未约束变量的规则时。自动生成的规则容易产生最坏情况匹配模式，导致系统变慢或内存溢出。

Method: CORGI采用两步法：正向构建/维护关系图，反向通过迭代器按需生成匹配。与传统RETE不同，它没有β-内存来收集部分匹配，而是流式生成后续匹配。

Result: 性能评估显示，在简单组合匹配任务上，CORGI显著优于SOAR和OPS5中的RETE实现，消除了高延迟延迟和内存溢出问题。

Conclusion: CORGI算法通过提供可预测的性能保证，使基于规则的系统在实际应用中更加可靠，特别适用于从示例学习自动生成规则的认知系统。

Abstract: Rule-based systems must solve complex matching problems within tight time constraints to be effective in real-time applications, such as planning and reactive control for AI agents, as well as low-latency relational database querying. Pattern-matching systems can encounter issues where exponential time and space are required to find matches for rules with many underconstrained variables, or which produce combinatorial intermediate partial matches (but are otherwise well-constrained). When online AI systems automatically generate rules from example-driven induction or code synthesis, they can easily produce worst-case matching patterns that slow or halt program execution by exceeding available memory. In our own work with cognitive systems that learn from example, we've found that aggressive forms of anti-unification-based generalization can easily produce these circumstances. To make these systems practical without hand-engineering constraints or succumbing to unpredictable failure modes, we introduce a new matching algorithm called CORGI (Collection-Oriented Relational Graph Iteration). Unlike RETE-based approaches, CORGI offers quadratic time and space guarantees for finding single satisficing matches, and the ability to iteratively stream subsequent matches without committing entire conflict sets to memory. CORGI differs from RETE in that it does not have a traditional $β$-memory for collecting partial matches. Instead, CORGI takes a two-step approach: a graph of grounded relations is built/maintained in a forward pass, and an iterator generates matches as needed by working backward through the graph. This approach eliminates the high-latency delays and memory overflows that can result from populating full conflict sets. In a performance evaluation, we demonstrate that CORGI significantly outperforms RETE implementations from SOAR and OPS5 on a simple combinatorial matching task.

</details>


### [13] [Scene Graph-Guided Generative AI Framework for Synthesizing and Evaluating Industrial Hazard Scenarios](https://arxiv.org/abs/2511.13970)
*Sanjay Acharjee,Abir Khan Ratul,Diego Patino,Md Nazmus Sakib*

Main category: cs.AI

TL;DR: 提出了一种基于场景图引导的生成AI框架，利用OSHA事故报告生成逼真的工作场所危险场景图像，并通过VQA框架评估生成数据的真实性和语义保真度。


<details>
  <summary>Details</summary>
Motivation: 获取真实的工作场所危险场景图像数据集很困难，因为捕捉实际发生的事故触发场景几乎不可能。

Method: 使用GPT-4o分析OSHA叙述提取结构化危险推理，转换为对象级场景图，然后指导文本到图像扩散模型生成构图准确的危险场景，并通过VQA框架评估生成质量。

Result: 提出的VQA图评分在四个最先进的生成模型中，基于熵验证优于CLIP和BLIP指标，证实了其更高的判别敏感性。

Conclusion: 该框架能够有效生成逼真的工作场所危险场景图像，为安全培训提供有价值的视觉数据资源。

Abstract: Training vision models to detect workplace hazards accurately requires realistic images of unsafe conditions that could lead to accidents. However, acquiring such datasets is difficult because capturing accident-triggering scenarios as they occur is nearly impossible. To overcome this limitation, this study presents a novel scene graph-guided generative AI framework that synthesizes photorealistic images of hazardous scenarios grounded in historical Occupational Safety and Health Administration (OSHA) accident reports. OSHA narratives are analyzed using GPT-4o to extract structured hazard reasoning, which is converted into object-level scene graphs capturing spatial and contextual relationships essential for understanding risk. These graphs guide a text-to-image diffusion model to generate compositionally accurate hazard scenes. To evaluate the realism and semantic fidelity of the generated data, a visual question answering (VQA) framework is introduced. Across four state-of-the-art generative models, the proposed VQA Graph Score outperforms CLIP and BLIP metrics based on entropy-based validation, confirming its higher discriminative sensitivity.

</details>


### [14] [Artificial Intelligence Agents in Music Analysis: An Integrative Perspective Based on Two Use Cases](https://arxiv.org/abs/2511.13987)
*Antonio Manuel Martínez-Heredia,Dolores Godrid Rodríguez,Andrés Ortiz García*

Main category: cs.AI

TL;DR: 本文综述了AI代理在音乐分析和教育中的应用，从基于规则的模型发展到深度学习、多代理架构和RAG框架，并通过双案例实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 探索AI代理在音乐分析和教育中的潜力，解决传统方法在可解释性和适应性方面的局限性，并关注教育环境中的伦理问题。

Method: 采用双案例方法：(1)在中学教育中使用生成式AI平台培养分析创造能力；(2)设计用于符号音乐分析的多代理系统，实现模块化、可扩展和可解释的工作流程。

Result: 实验结果显示AI代理在音乐模式识别、作曲参数化和教育反馈方面优于传统自动化方法，具有更好的可解释性和适应性。

Conclusion: 研究提出了一个统一框架，连接技术、教学和伦理考量，为计算音乐学和音乐教育中智能代理的设计应用提供基于证据的指导。

Abstract: This paper presents an integrative review and experimental validation of artificial intelligence (AI) agents applied to music analysis and education. We synthesize the historical evolution from rule-based models to contemporary approaches involving deep learning, multi-agent architectures, and retrieval-augmented generation (RAG) frameworks. The pedagogical implications are evaluated through a dual-case methodology: (1) the use of generative AI platforms in secondary education to foster analytical and creative skills; (2) the design of a multiagent system for symbolic music analysis, enabling modular, scalable, and explainable workflows.
  Experimental results demonstrate that AI agents effectively enhance musical pattern recognition, compositional parameterization, and educational feedback, outperforming traditional automated methods in terms of interpretability and adaptability. The findings highlight key challenges concerning transparency, cultural bias, and the definition of hybrid evaluation metrics, emphasizing the need for responsible deployment of AI in educational environments.
  This research contributes to a unified framework that bridges technical, pedagogical, and ethical considerations, offering evidence-based guidance for the design and application of intelligent agents in computational musicology and music education.

</details>


### [15] [ALEX:A Light Editing-knowledge Extractor](https://arxiv.org/abs/2511.14018)
*Minghu Wang,Shuliang Zhao,Yuanyuan Zhao,Hongxia Xu*

Main category: cs.AI

TL;DR: ALEX是一个轻量级知识编辑框架，通过分层内存架构将知识更新组织成语义簇，将检索复杂度从O(N)降低到O(K+N/C)，显著提高了多跳问答的准确性和推理路径可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型中的知识是静态的，难以适应不断变化的信息，现有方法在处理需要多步推理的复杂多跳问题时面临可扩展性和检索效率的挑战。

Method: ALEX采用分层内存架构组织知识更新，包含推理查询合成模块来弥合查询与事实之间的语义差距，以及动态证据裁决引擎执行高效的两阶段检索过程。

Result: 在MQUAKE基准测试中，ALEX显著提高了多跳答案的准确性和推理路径的可靠性，同时将所需搜索空间减少了80%以上。

Conclusion: ALEX为构建可扩展、高效且准确的知识编辑系统提供了一条有前景的路径。

Abstract: The static nature of knowledge within Large Language Models (LLMs) makes it difficult for them to adapt to evolving information, rendering knowledge editing a critical task. However, existing methods struggle with challenges of scalability and retrieval efficiency, particularly when handling complex, multi-hop questions that require multi-step reasoning. To address these challenges, this paper introduces ALEX (A Light Editing-knowledge Extractor), a lightweight knowledge editing framework. The core innovation of ALEX is its hierarchical memory architecture, which organizes knowledge updates (edits) into semantic clusters. This design fundamentally reduces retrieval complexity from a linear O(N) to a highly scalable O(K+N/C). Furthermore, the framework integrates an Inferential Query Synthesis (IQS) module to bridge the semantic gap between queries and facts , and a Dynamic Evidence Adjudication (DEA) engine that executes an efficient two-stage retrieval process. Experiments on the MQUAKE benchmark demonstrate that ALEX significantly improves both the accuracy of multi-hop answers (MultiHop-ACC) and the reliability of reasoning paths (HopWise-ACC). It also reduces the required search space by over 80% , presenting a promising path toward building scalable, efficient, and accurate knowledge editing systems.

</details>


### [16] [Syn-STARTS: Synthesized START Triage Scenario Generation Framework for Scalable LLM Evaluation](https://arxiv.org/abs/2511.14023)
*Chiharu Hagiwara,Naoki Nonaka,Yuhta Hashimoto,Ryu Uchimido,Jun Seita*

Main category: cs.AI

TL;DR: 开发了Syn-STARTS框架，使用LLM生成大规模分类案例，解决了真实世界大规模伤亡事件数据稀缺的问题，验证了合成数据在医疗AI开发中的可行性。


<details>
  <summary>Details</summary>
Motivation: 大规模伤亡事件中的分类决策至关重要，但真实数据难以收集，阻碍了AI模型的开发和评估。

Method: 使用LLM生成分类案例的Syn-STARTS框架，并与手动整理的TRIAGE开放数据集进行定性比较。

Result: Syn-STARTS生成的案例在质量上与人工整理的数据集无法区分，且在不同分类类别（绿、黄、红、黑）的评估中表现稳定。

Conclusion: 合成数据在开发高性能医疗AI模型方面具有巨大潜力，特别是在严重和危急医疗情况下。

Abstract: Triage is a critically important decision-making process in mass casualty incidents (MCIs) to maximize victim survival rates. While the role of AI in such situations is gaining attention for making optimal decisions within limited resources and time, its development and performance evaluation require benchmark datasets of sufficient quantity and quality. However, MCIs occur infrequently, and sufficient records are difficult to accumulate at the scene, making it challenging to collect large-scale realworld data for research use. Therefore, we developed Syn-STARTS, a framework that uses LLMs to generate triage cases, and verified its effectiveness. The results showed that the triage cases generated by Syn-STARTS were qualitatively indistinguishable from the TRIAGE open dataset generated by manual curation from training materials. Furthermore, when evaluating the LLM accuracy using hundreds of cases each from the green, yellow, red, and black categories defined by the standard triage method START, the results were found to be highly stable. This strongly indicates the possibility of synthetic data in developing high-performance AI models for severe and critical medical situations.

</details>


### [17] [AISAC: An Integrated multi-agent System for Transparent, Retrieval-Grounded Scientific Assistance](https://arxiv.org/abs/2511.14043)
*Chandrachur Bhattacharya,Sibendu Som*

Main category: cs.AI

TL;DR: AISAC是阿贡国家实验室开发的多智能体科学助手系统，集成了LangGraph、FAISS和SQLite技术，专注于科学工作流的透明性、溯源跟踪和适应性。


<details>
  <summary>Details</summary>
Motivation: 开发一个集成化的科学工作流系统，解决科学计算中的透明性、溯源跟踪和跨领域适应性问题。

Method: 采用Router-Planner-Coordinator工作流和可选Evaluator角色，使用提示工程智能体协调，结合FAISS向量搜索和SQLite持久化的混合内存方法，支持增量索引和配置驱动的项目引导。

Result: 系统已应用于阿贡实验室的多个研究领域，包括废物转化产品和能源过程安全等专业部署，以及通用科学辅助，展示了跨领域适用性。

Conclusion: AISAC成功构建了一个透明、可追踪且适应性强的科学工作流系统，通过模块化设计和配置驱动方法实现了跨领域应用。

Abstract: AI Scientific Assistant Core (AISAC) is an integrated multi-agent system developed at Argonne National Laboratory for scientific and engineering workflows. AISAC builds on established technologies - LangGraph for orchestration, FAISS for vector search, and SQLite for persistence - and integrates them into a unified system prototype focused on transparency, provenance tracking, and scientific adaptability.
  The system implements a Router-Planner-Coordinator workflow and an optional Evaluator role, using prompt-engineered agents coordinated via LangGraph's StateGraph and supported by helper agents such as a Researcher. Each role is defined through custom system prompts that enforce structured JSON outputs. A hybrid memory approach (FAISS + SQLite) enables both semantic retrieval and structured conversation history. An incremental indexing strategy based on file hashing minimizes redundant re-embedding when scientific corpora evolve. A configuration-driven project bootstrap layer allows research teams to customize tools, prompts, and data sources without modifying core code.
  All agent decisions, tool invocations, and retrievals are logged and visualized through a custom Gradio interface, providing step-by-step transparency for each reasoning episode. The authors have applied AISAC to multiple research areas at Argonne, including specialized deployments for waste-to-products research and energy process safety, as well as general-purpose scientific assistance, demonstrating its cross-domain applicability.

</details>


### [18] [Making Evidence Actionable in Adaptive Learning](https://arxiv.org/abs/2511.14052)
*Amirreza Mehrabi,Jason W. Morphew,Breejha Quezada,N. Sanjay Rebello*

Main category: cs.AI

TL;DR: 提出了一个由教师主导的反馈循环系统，将概念级评估证据转化为经过验证的微干预措施，通过二元整数规划方法实现个性化学习路径的优化分配。


<details>
  <summary>Details</summary>
Motivation: 传统自适应学习系统诊断准确但干预薄弱，导致帮助时机不当或内容不匹配。需要建立诊断与教学之间的闭环，实现公平且负载感知的个性化教学。

Method: 采用二元整数规划方法，包含三个保障机制：充分性保证知识差距闭合、注意力作为时间和冗余的预算约束、多样性防止对单一资源的过拟合。使用贪婪选择、梯度松弛和混合方法三种求解器。

Result: 在1204名学生的物理课程部署中，两种求解器都能在有限观看时间内为几乎所有学习者实现完整的技能覆盖。梯度方法比贪婪方法减少约12%的冗余覆盖，并在难度上更均衡。

Conclusion: 该系统构建了一个可追踪且可审计的控制器，闭合了诊断-教学循环，在课堂规模上实现了公平且负载感知的个性化教学。

Abstract: Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage, time, difficulty windows informed by ability estimates, prerequisites encoded by a concept matrix, and anti-redundancy enforced through diversity. Greedy selection serves low-richness and tight-latency regimes, gradient-based relaxation serves rich repositories, and a hybrid method transitions along a richness-latency frontier. In simulation and in an introductory physics deployment with one thousand two hundred four students, both solvers achieved full skill coverage for essentially all learners within bounded watch time. The gradient-based method reduced redundant coverage by approximately twelve percentage points relative to greedy and harmonized difficulty across slates, while greedy delivered comparable adequacy with lower computational cost in scarce settings. Slack variables localized missing content and supported targeted curation, sustaining sufficiency across subgroups. The result is a tractable and auditable controller that closes the diagnostic-pedagogical loop and delivers equitable, load-aware personalization at classroom scale.

</details>


### [19] [APD-Agents: A Large Language Model-Driven Multi-Agents Collaborative Framework for Automated Page Design](https://arxiv.org/abs/2511.14101)
*Xinpeng Chen,Xiaofeng Han,Kaihao Zhang,Guochao Ren,Yujie Wang,Wenhao Cao,Yang Zhou,Jianfeng Lu,Zhenbo Song*

Main category: cs.AI

TL;DR: APD-agents是一个基于大语言模型的多智能体框架，用于自动化移动应用页面设计，通过多个智能体协作将用户描述转换为结构化布局设计。


<details>
  <summary>Details</summary>
Motivation: 移动应用页面布局设计耗时且需要专业技能，现有设计软件需要大量培训，跨页面协作设计还需要额外时间统一标准。

Method: 使用多智能体框架：OrchestratorAgent协调任务，SemanticParserAgent解析用户描述，PrimaryLayoutAgent生成初始布局，TemplateRetrievalAgent检索相关示例，RecursiveComponentAgent递归生成细粒度子元素。

Result: 在RICO数据集上的实验结果显示，APD-agents达到了最先进的性能。

Conclusion: 该工作充分利用了大模型驱动的多智能体系统的自动协作能力，实现了高效的自动化页面设计。

Abstract: Layout design is a crucial step in developing mobile app pages. However, crafting satisfactory designs is time-intensive for designers: they need to consider which controls and content to present on the page, and then repeatedly adjust their size, position, and style for better aesthetics and structure. Although many design software can now help to perform these repetitive tasks, extensive training is needed to use them effectively. Moreover, collaborative design across app pages demands extra time to align standards and ensure consistent styling. In this work, we propose APD-agents, a large language model (LLM) driven multi-agent framework for automated page design in mobile applications. Our framework contains OrchestratorAgent, SemanticParserAgent, PrimaryLayoutAgent, TemplateRetrievalAgent, and RecursiveComponentAgent. Upon receiving the user's description of the page, the OrchestratorAgent can dynamically can direct other agents to accomplish users' design task. To be specific, the SemanticParserAgent is responsible for converting users' descriptions of page content into structured data. The PrimaryLayoutAgent can generate an initial coarse-grained layout of this page. The TemplateRetrievalAgent can fetch semantically relevant few-shot examples and enhance the quality of layout generation. Besides, a RecursiveComponentAgent can be used to decide how to recursively generate all the fine-grained sub-elements it contains for each element in the layout. Our work fully leverages the automatic collaboration capabilities of large-model-driven multi-agent systems. Experimental results on the RICO dataset show that our APD-agents achieve state-of-the-art performance.

</details>


### [20] [PRISM: Prompt-Refined In-Context System Modelling for Financial Retrieval](https://arxiv.org/abs/2511.14130)
*Chun Chet Ng,Jia Yu Lim,Wei Zeng Low*

Main category: cs.AI

TL;DR: 提出了PRISM框架，一种无需训练的方法，通过系统提示、上下文学习和轻量级多代理系统来解决金融信息检索问题，在FinAgentBench数据集上取得了0.71818的NDCG@5分数。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，金融信息检索成为关键工业应用。从冗长的财务文件中提取任务相关信息对于运营和分析决策至关重要。

Method: PRISM框架整合了精炼的系统提示、上下文学习和轻量级多代理系统。提示工程提供精确任务指令，上下文学习提供语义相关的少样本示例，多代理系统模拟协调评分行为。

Result: 最佳配置在受限验证集上实现了0.71818的NDCG@5分数，证明PRISM在生产规模金融检索中可行且稳健。

Conclusion: PRISM的模块化、仅推理设计使其适用于实际应用场景，为金融信息检索提供了实用的解决方案。

Abstract: With the rapid progress of large language models (LLMs), financial information retrieval has become a critical industrial application. Extracting task-relevant information from lengthy financial filings is essential for both operational and analytical decision-making. The FinAgentBench dataset formalizes this problem through two tasks: document ranking and chunk ranking. We present PRISM, a training-free framework that integrates refined system prompting, in-context learning (ICL), and a lightweight multi-agent system. Each component is examined extensively to reveal their synergies: prompt engineering provides precise task instructions, ICL supplies semantically relevant few-shot examples, and the multi-agent system models coordinated scoring behaviour. Our best configuration achieves an NDCG@5 of 0.71818 on the restricted validation split. We further demonstrate that PRISM is feasible and robust for production-scale financial retrieval. Its modular, inference-only design makes it practical for real-world use cases. The source code is released at https://bit.ly/prism-ailens.

</details>


### [21] [Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation](https://arxiv.org/abs/2511.14131)
*Yu Zhong,Zihao Zhang,Rui Zhang,Lingdong Huang,Haihan Gao,Shuo Wang,Da Li,Ruijian Han,Jiaming Guo,Shaohui Peng,Di Huang,Yunji Chen*

Main category: cs.AI

TL;DR: R3是一个用于视觉语言导航的双过程思考框架，结合了轻量级专家模型和大语言模型，通过三个核心模块实现高效导航和复杂推理的协调。


<details>
  <summary>Details</summary>
Motivation: 解决VLN任务中LLM方法在空间理解、计算成本和推理延迟方面的不足，同时保持LLM的泛化能力。

Method: 提出R3框架，包含Runner（轻量级专家模型）、Ruminator（多模态LLM推理模块）和Regulator（模式切换控制器），在零样本设置下协调运行。

Result: 在REVERIE基准测试中，SPL和RGSPL分别超过现有最佳方法3.28%和3.30%。

Conclusion: R3框架有效解决了VLN任务的挑战，通过双过程思考机制实现了导航性能和效率的显著提升。

Abstract: Vision-and-Language Navigation (VLN) requires an agent to dynamically explore complex 3D environments following human instructions. Recent research underscores the potential of harnessing large language models (LLMs) for VLN, given their commonsense knowledge and general reasoning capabilities. Despite their strengths, a substantial gap in task completion performance persists between LLM-based approaches and domain experts, as LLMs inherently struggle to comprehend real-world spatial correlations precisely. Additionally, introducing LLMs is accompanied with substantial computational cost and inference latency. To address these issues, we propose a novel dual-process thinking framework dubbed R3, integrating LLMs' generalization capabilities with VLN-specific expertise in a zero-shot manner. The framework comprises three core modules: Runner, Ruminator, and Regulator. The Runner is a lightweight transformer-based expert model that ensures efficient and accurate navigation under regular circumstances. The Ruminator employs a powerful multimodal LLM as the backbone and adopts chain-of-thought (CoT) prompting to elicit structured reasoning. The Regulator monitors the navigation progress and controls the appropriate thinking mode according to three criteria, integrating Runner and Ruminator harmoniously. Experimental results illustrate that R3 significantly outperforms other state-of-the-art methods, exceeding 3.28% and 3.30% in SPL and RGSPL respectively on the REVERIE benchmark. This pronounced enhancement highlights the effectiveness of our method in handling challenging VLN tasks.

</details>


### [22] [Beyond Accuracy: A Multi-Dimensional Framework for Evaluating Enterprise Agentic AI Systems](https://arxiv.org/abs/2511.14136)
*Sushant Mehta*

Main category: cs.AI

TL;DR: 提出了CLEAR评估框架，针对企业AI代理的全面评估，涵盖成本、延迟、效能、保障和可靠性五个维度，解决了现有基准只关注准确性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理基准主要评估任务完成准确性，但忽视了企业部署所需的关键要求，如成本效率、可靠性和操作稳定性。

Method: 通过系统分析12个主要基准和实证评估最先进代理，识别出三个根本限制，并提出CLEAR评估框架进行多维评估。

Result: 在300个企业任务上评估六个领先代理，发现仅优化准确性的代理比成本感知替代方案贵4.4-10.8倍；专家评估确认CLEAR能更好预测生产成功（ρ=0.83 vs 0.41）。

Conclusion: CLEAR框架为企业AI代理提供了更全面的评估标准，显著优于仅关注准确性的传统评估方法。

Abstract: Current agentic AI benchmarks predominantly evaluate task completion accuracy, while overlooking critical enterprise requirements such as cost-efficiency, reliability, and operational stability. Through systematic analysis of 12 main benchmarks and empirical evaluation of state-of-the-art agents, we identify three fundamental limitations: (1) absence of cost-controlled evaluation leading to 50x cost variations for similar precision, (2) inadequate reliability assessment where agent performance drops from 60\% (single run) to 25\% (8-run consistency), and (3) missing multidimensional metrics for security, latency, and policy compliance. We propose \textbf{CLEAR} (Cost, Latency, Efficacy, Assurance, Reliability), a holistic evaluation framework specifically designed for enterprise deployment. Evaluation of six leading agents on 300 enterprise tasks demonstrates that optimizing for accuracy alone yields agents 4.4-10.8x more expensive than cost-aware alternatives with comparable performance. Expert evaluation (N=15) confirms that CLEAR better predicts production success (correlation $ρ=0.83$) compared to accuracy-only evaluation ($ρ=0.41$).

</details>


### [23] [HFL-FlowLLM: Large Language Models for Network Traffic Flow Classification in Heterogeneous Federated Learning](https://arxiv.org/abs/2511.14199)
*Jiazhuo Tian,Yachao Yuan*

Main category: cs.AI

TL;DR: HFL-FlowLLM是首个将大语言模型应用于异构联邦学习中网络流量分类的框架，相比现有方法平均F1分数提升约13%，训练成本降低约87%。


<details>
  <summary>Details</summary>
Motivation: 解决5G和物联网环境中传统集中式机器学习面临的数据分布和隐私问题，以及现有联邦学习方法成本高、泛化能力差的问题。

Method: 提出HFL-FlowLLM框架，将大语言模型应用于异构联邦学习中的网络流量分类任务。

Result: 相比最先进的异构联邦学习方法，平均F1分数提升约13%；相比现有大语言模型联邦学习框架，随着客户端数量增加，平均F1分数提升达5%，同时训练成本降低约87%。

Conclusion: HFL-FlowLLM在现代通信网络安全中展现出巨大潜力和实用价值。

Abstract: In modern communication networks driven by 5G and the Internet of Things (IoT), effective network traffic flow classification is crucial for Quality of Service (QoS) management and security. Traditional centralized machine learning struggles with the distributed data and privacy concerns in these heterogeneous environments, while existing federated learning approaches suffer from high costs and poor generalization. To address these challenges, we propose HFL-FlowLLM, which to our knowledge is the first framework to apply large language models to network traffic flow classification in heterogeneous federated learning. Compared to state-of-the-art heterogeneous federated learning methods for network traffic flow classification, the proposed approach improves the average F1 score by approximately 13%, demonstrating compelling performance and strong robustness. When compared to existing large language models federated learning frameworks, as the number of clients participating in each training round increases, the proposed method achieves up to a 5% improvement in average F1 score while reducing the training costs by about 87%. These findings prove the potential and practical value of HFL-FlowLLM in modern communication networks security.

</details>


### [24] [Do Large Language Models (LLMs) Understand Chronology?](https://arxiv.org/abs/2511.14214)
*Pattaraphon Kenny Wongchamcharoen,Paul Glasserman*

Main category: cs.AI

TL;DR: 测试LLMs对时间顺序的理解能力，发现在复杂时序任务中表现有限，但增加推理预算能显著提升GPT-5和Claude-3.7 Sonnet的表现。


<details>
  <summary>Details</summary>
Motivation: 验证LLMs是否真正理解时间顺序，这对金融经济应用中避免前瞻性偏差至关重要。

Method: 设计三种时序任务：时间排序、条件排序（先筛选后排序）和时代错置检测，在多种推理设置下测试GPT-4.1、Claude-3.7 Sonnet和GPT-5。

Result: 随着序列变长，准确率急剧下降；条件排序失败主要来自筛选步骤；时代错置检测相对容易但性能仍会下降；增加推理预算能显著改善表现。

Conclusion: 当前LLMs在时序任务上存在局限，但明确分配推理预算能帮助改善表现，这对LLMs在金融领域的实时应用具有重要意义。

Abstract: Large language models (LLMs) are increasingly used in finance and economics, where prompt-based attempts against look-ahead bias implicitly assume that models understand chronology. We test this fundamental question with a series of chronological ordering tasks with increasing complexities over facts the model already knows from pre-training. Our tasks cover (1) chronological ordering, (2) conditional sorting (filter, then order), and (3) anachronism detection. We evaluate GPT-4.1, Claude-3.7 Sonnet, with and without Extended Thinking (ET), and GPT-5 across multiple reasoning-effort settings. Across models, Exact match rate drops sharply as sequences lengthen even while rank correlations stay high as LLMs largely preserve local order but struggle to maintain a single globally consistent timeline. In conditional sorting, most failures stem from the filtering step rather than the ordering step, but GPT-5 and Claude-3.7 Sonnet with Extended Thinking outshine normal models significantly. Lastly, anachronism detection is found to be the easiest task for the LLMs but performance still declines with increasingly overlapping timelines or entities. Overall, our main contribution is showing that allocating explicit reasoning budget helps with chronological ordering with GPT-5 at medium/high reasoning effort achieving flawless ordering at all lengths and perfect conditional sorting (both self-filtered and given-subset), whereas low/minimal effort degrades with longer lists, mirroring earlier models. Our findings delineate limits of current LLMs on chronological tasks, providing insights into task complexity, and demonstrate scenarios in which reasoning helps. These patterns are important for the real-time application of LLMs in finance. We release all code and evaluation templates to support full reproducibility.

</details>


### [25] [Listen Like a Teacher: Mitigating Whisper Hallucinations using Adaptive Layer Attention and Knowledge Distillation](https://arxiv.org/abs/2511.14219)
*Kumud Tripathi,Aditya Srinivas Menon,Aman Gaurav,Raj Prakash Gohil,Pankaj Wasnik*

Main category: cs.AI

TL;DR: 提出两阶段架构来减少Whisper模型的幻觉错误：第一阶段通过自适应层注意力增强编码器鲁棒性，第二阶段使用多目标知识蒸馏抑制幻觉。


<details>
  <summary>Details</summary>
Motivation: Whisper模型在噪声条件下经常产生幻觉错误，现有方法主要关注音频预处理或转录后处理，对模型本身的修改探索不足。

Method: 1. 自适应层注意力(ALA)：通过层间相关性分析将编码器层分组为语义连贯块，使用可学习多头注意力融合块表示；2. 多目标知识蒸馏(KD)：在噪声音频上训练学生模型，使其语义和注意力分布与处理干净输入的教师模型对齐。

Result: 在噪声语音基准测试中显著减少了幻觉和词错误率，同时保持了在干净语音上的性能。

Conclusion: ALA和KD为在真实世界噪声条件下提高Whisper可靠性提供了原则性策略。

Abstract: The Whisper model, an open-source automatic speech recognition system, is widely adopted for its strong performance across multilingual and zero-shot settings. However, it frequently suffers from hallucination errors, especially under noisy acoustic conditions. Previous works to reduce hallucinations in Whisper-style ASR systems have primarily focused on audio preprocessing or post-processing of transcriptions to filter out erroneous content. However, modifications to the Whisper model itself remain largely unexplored to mitigate hallucinations directly. To address this challenge, we present a two-stage architecture that first enhances encoder robustness through Adaptive Layer Attention (ALA) and further suppresses hallucinations using a multi-objective knowledge distillation (KD) framework. In the first stage, ALA groups encoder layers into semantically coherent blocks via inter-layer correlation analysis. A learnable multi-head attention module then fuses these block representations, enabling the model to jointly exploit low- and high-level features for more robust encoding. In the second stage, our KD framework trains the student model on noisy audio to align its semantic and attention distributions with a teacher model processing clean inputs. Our experiments on noisy speech benchmarks show notable reductions in hallucinations and word error rates, while preserving performance on clean speech. Together, ALA and KD offer a principled strategy to improve Whisper's reliability under real-world noisy conditions.

</details>


### [26] [DevPiolt: Operation Recommendation for IoT Devices at Xiaomi Home](https://arxiv.org/abs/2511.14227)
*Yuxiang Wang,Siwen Wang,Haowei Han,Ao Wang,Boya Liu,Yong Zhao,Chengbo Wu,Bin Zhu,Bin Qin,Xiaokai Zhou,Xiao Yan,Jiawei Jiang,Bo Du*

Main category: cs.AI

TL;DR: DevPiolt是一个基于大语言模型的物联网设备操作推荐系统，通过持续预训练、多任务微调、偏好优化和置信度控制机制，显著提升了推荐性能，并在小米家庭应用中成功部署。


<details>
  <summary>Details</summary>
Motivation: 现有的推荐模型在处理物联网设备操作时面临复杂操作逻辑、多样化用户偏好和对次优建议敏感等问题，限制了其在物联网设备操作推荐中的适用性。

Method: 1) 通过持续预训练和多任务微调为LLM注入物联网操作领域知识；2) 使用直接偏好优化将微调后的LLM与特定用户偏好对齐；3) 设计基于置信度的曝光控制机制避免低质量推荐带来的负面用户体验。

Result: 在所有数据集上显著超越基线模型，所有指标平均提升69.5%。在小米家庭应用中部署一个季度，服务25.5万用户，在线实验显示唯一访客设备覆盖率提升21.6%，页面浏览接受率提升29.1%。

Conclusion: DevPiolt成功解决了物联网设备操作推荐的挑战，通过LLM技术和精心设计的优化策略实现了显著的性能提升和实际应用价值。

Abstract: Operation recommendation for IoT devices refers to generating personalized device operations for users based on their context, such as historical operations, environment information, and device status. This task is crucial for enhancing user satisfaction and corporate profits. Existing recommendation models struggle with complex operation logic, diverse user preferences, and sensitive to suboptimal suggestions, limiting their applicability to IoT device operations. To address these issues, we propose DevPiolt, a LLM-based recommendation model for IoT device operations. Specifically, we first equip the LLM with fundamental domain knowledge of IoT operations via continual pre-training and multi-task fine-tuning. Then, we employ direct preference optimization to align the fine-tuned LLM with specific user preferences. Finally, we design a confidence-based exposure control mechanism to avoid negative user experiences from low-quality recommendations. Extensive experiments show that DevPiolt significantly outperforms baselines on all datasets, with an average improvement of 69.5% across all metrics. DevPiolt has been practically deployed in Xiaomi Home app for one quarter, providing daily operation recommendations to 255,000 users. Online experiment results indicate a 21.6% increase in unique visitor device coverage and a 29.1% increase in page view acceptance rates.

</details>


### [27] [Enhancing Regional Airbnb Trend Forecasting Using LLM-Based Embeddings of Accessibility and Human Mobility](https://arxiv.org/abs/2511.14248)
*Hongju Lee,Youngjun Park,Jisun An,Dongman Lee*

Main category: cs.AI

TL;DR: 提出基于LLM的区域Airbnb市场预测框架，通过整合房源特征和外部因素构建区域表示，相比传统方法将RMSE和MAE降低约48%。


<details>
  <summary>Details</summary>
Motivation: Airbnb等短租平台的扩张扰乱了当地住房市场，导致租金上涨和住房可负担性问题。准确预测区域Airbnb市场趋势可为政策制定者提供关键洞察。

Method: 使用滑动窗口方法预测1-3个月趋势，将结构化表格数据转换为基于提示的LLM输入生成区域嵌入，再输入到时序模型（RNN、LSTM、Transformer）中捕捉复杂时空动态。

Result: 在首尔Airbnb数据集上的实验表明，该方法相比传统统计和机器学习模型，平均RMSE和MAE降低了约48%。

Conclusion: 该框架不仅提高了预测准确性，还为检测供应过剩区域和支持数据驱动的城市政策决策提供了实用见解。

Abstract: The expansion of short-term rental platforms, such as Airbnb, has significantly disrupted local housing markets, often leading to increased rental prices and housing affordability issues. Accurately forecasting regional Airbnb market trends can thus offer critical insights for policymakers and urban planners aiming to mitigate these impacts. This study proposes a novel time-series forecasting framework to predict three key Airbnb indicators -- Revenue, Reservation Days, and Number of Reservations -- at the regional level. Using a sliding-window approach, the model forecasts trends 1 to 3 months ahead. Unlike prior studies that focus on individual listings at fixed time points, our approach constructs regional representations by integrating listing features with external contextual factors such as urban accessibility and human mobility. We convert structured tabular data into prompt-based inputs for a Large Language Model (LLM), producing comprehensive regional embeddings. These embeddings are then fed into advanced time-series models (RNN, LSTM, Transformer) to better capture complex spatio-temporal dynamics. Experiments on Seoul's Airbnb dataset show that our method reduces both average RMSE and MAE by approximately 48% compared to conventional baselines, including traditional statistical and machine learning models. Our framework not only improves forecasting accuracy but also offers practical insights for detecting oversupplied regions and supporting data-driven urban policy decisions.

</details>


### [28] [PathMind: A Retrieve-Prioritize-Reason Framework for Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2511.14256)
*Yu Liu,Xixun Lin,Yanmin Shang,Yangxi Li,Shi Wang,Yanan Cao*

Main category: cs.AI

TL;DR: PathMind是一个新颖的知识图谱推理框架，通过选择性引导LLM使用重要推理路径来增强忠实和可解释的推理，采用“检索-优先排序-推理”范式，在复杂推理任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM-based知识图谱推理方法的两个关键限制：1) 无差别提取推理路径可能引入无关噪声误导LLM；2) 动态探索推理路径需要高检索需求和频繁LLM调用。

Method: 采用“检索-优先排序-推理”范式：首先通过检索模块从KG中检索查询子图；然后引入路径优先排序机制，使用语义感知的路径优先级函数识别重要推理路径；最后通过双阶段训练策略生成准确响应。

Result: 在基准数据集上的广泛实验表明，PathMind持续优于竞争基线，特别是在复杂推理任务上，通过识别关键推理路径以更少的输入token实现更好性能。

Conclusion: PathMind通过选择性路径引导和双阶段训练，有效提升了知识图谱推理的准确性和效率，为LLM在复杂推理任务中的应用提供了可靠解决方案。

Abstract: Knowledge graph reasoning (KGR) is the task of inferring new knowledge by performing logical deductions on knowledge graphs. Recently, large language models (LLMs) have demonstrated remarkable performance in complex reasoning tasks. Despite promising success, current LLM-based KGR methods still face two critical limitations. First, existing methods often extract reasoning paths indiscriminately, without assessing their different importance, which may introduce irrelevant noise that misleads LLMs. Second, while many methods leverage LLMs to dynamically explore potential reasoning paths, they require high retrieval demands and frequent LLM calls. To address these limitations, we propose PathMind, a novel framework designed to enhance faithful and interpretable reasoning by selectively guiding LLMs with important reasoning paths. Specifically, PathMind follows a "Retrieve-Prioritize-Reason" paradigm. First, it retrieves a query subgraph from KG through the retrieval module. Next, it introduces a path prioritization mechanism that identifies important reasoning paths using a semantic-aware path priority function, which simultaneously considers the accumulative cost and the estimated future cost for reaching the target. Finally, PathMind generates accurate and logically consistent responses via a dual-phase training strategy, including task-specific instruction tuning and path-wise preference alignment. Extensive experiments on benchmark datasets demonstrate that PathMind consistently outperforms competitive baselines, particularly on complex reasoning tasks with fewer input tokens, by identifying essential reasoning paths.

</details>


### [29] [DataSage: Multi-agent Collaboration for Insight Discovery with External Knowledge Retrieval, Multi-role Debating, and Multi-path Reasoning](https://arxiv.org/abs/2511.14299)
*Xiaochuan Liu,Yuanfeng Song,Xiaoming Yin,Xing Chen*

Main category: cs.AI

TL;DR: DataSage是一个多智能体框架，通过外部知识检索、多角色辩论机制和多路径推理来解决现有数据洞察代理在领域知识利用、分析深度和代码生成准确性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 在数据驱动时代，全自动端到端数据分析对于发现可操作的洞察至关重要。现有数据洞察代理存在领域知识利用不足、分析深度浅、代码生成易出错等问题。

Method: 提出DataSage多智能体框架，包含三个创新特性：外部知识检索丰富分析上下文、多角色辩论机制模拟多样化分析视角、多路径推理提高代码和洞察生成准确性。

Result: 在InsightBench上的广泛实验表明，DataSage在所有难度级别上都持续优于现有数据洞察代理。

Conclusion: DataSage为自动化数据洞察发现提供了一个有效的解决方案。

Abstract: In today's data-driven era, fully automated end-to-end data analytics, particularly insight discovery, is critical for discovering actionable insights that assist organizations in making effective decisions. With the rapid advancement of large language models (LLMs), LLM-driven agents have emerged as a promising paradigm for automating data analysis and insight discovery. However, existing data insight agents remain limited in several key aspects, often failing to deliver satisfactory results due to: (1) insufficient utilization of domain knowledge, (2) shallow analytical depth, and (3) error-prone code generation during insight generation. To address these issues, we propose DataSage, a novel multi-agent framework that incorporates three innovative features including external knowledge retrieval to enrich the analytical context, a multi-role debating mechanism to simulate diverse analytical perspectives and deepen analytical depth, and multi-path reasoning to improve the accuracy of the generated code and insights. Extensive experiments on InsightBench demonstrate that DataSage consistently outperforms existing data insight agents across all difficulty levels, offering an effective solution for automated data insight discovery.

</details>


### [30] [When Words Change the Model: Sensitivity of LLMs for Constraint Programming Modelling](https://arxiv.org/abs/2511.14334)
*Alessio Pellegrino,Jacopo Mauro*

Main category: cs.AI

TL;DR: LLMs在自动生成优化和约束编程模型方面表现良好，但在面对重新表述和扰动的经典问题时性能显著下降，表明其成功可能源于训练数据污染而非真正的推理能力。


<details>
  <summary>Details</summary>
Motivation: 检验LLMs自动生成优化模型的能力是否真正基于推理，还是仅仅因为训练数据中包含了经典问题而表现良好。

Method: 系统性地重新表述和扰动CSPLib中的经典问题，保持结构不变但修改上下文并引入误导元素，然后比较三个代表性LLM在原始和修改描述下的模型生成表现。

Result: LLMs能够生成语法有效且语义合理的模型，但在上下文和语言变化下性能急剧下降，显示出浅层理解和对措辞的敏感性。

Conclusion: LLMs在自动生成优化模型方面的成功可能主要源于数据污染而非真正的推理能力，其理解深度有限且对表述变化敏感。

Abstract: One of the long-standing goals in optimisation and constraint programming is to describe a problem in natural language and automatically obtain an executable, efficient model. Large language models appear to bring this vision closer, showing impressive results in automatically generating models for classical benchmarks. However, much of this apparent success may derive from data contamination rather than genuine reasoning: many standard CP problems are likely included in the training data of these models. To examine this hypothesis, we systematically rephrased and perturbed a set of well-known CSPLib problems to preserve their structure while modifying their context and introducing misleading elements. We then compared the models produced by three representative LLMs across original and modified descriptions. Our qualitative analysis shows that while LLMs can produce syntactically valid and semantically plausible models, their performance drops sharply under contextual and linguistic variation, revealing shallow understanding and sensitivity to wording.

</details>


### [31] [Operationalizing Pluralistic Values in Large Language Model Alignment Reveals Trade-offs in Safety, Inclusivity, and Model Behavior](https://arxiv.org/abs/2511.14476)
*Dalia Ali,Dora Zhao,Allison Koenecke,Orestis Papakyriakopoulos*

Main category: cs.AI

TL;DR: 本研究探讨了在LLM对齐过程中纳入多元化价值观的影响，通过系统评估人口统计差异和设计参数，发现不同社会群体的偏好会导致模型行为差异，技术设计选择对毒性降低效果显著。


<details>
  <summary>Details</summary>
Motivation: 当前LLM对齐决策往往忽视人类社会的多样性，需要研究如何将多元化价值观纳入对齐过程，以平衡安全性和公平代表性。

Method: 收集美国和德国参与者的对齐数据，在五个维度上评估LLM响应，使用不同社会群体的偏好微调多个大语言模型和大推理模型，并改变评分尺度、分歧处理方法和优化技术。

Result: 发现系统性人口统计效应：男性参与者对毒性的评分比女性低18%；保守派和黑人参与者对情感意识的评分分别比自由派和白人参与者高27.9%和44%。技术设计选择显示强烈效果：保留评分者分歧比多数投票实现约53%更大的毒性降低；5点量表比二元格式产生约22%更多降低；DPO在多值优化中始终优于GRPO。

Conclusion: 这些发现为回答关键问题提供了初步步骤：对齐应如何平衡专家驱动和用户驱动信号，以确保安全性和公平代表性。

Abstract: Although large language models (LLMs) are increasingly trained using human feedback for safety and alignment with human values, alignment decisions often overlook human social diversity. This study examines how incorporating pluralistic values affects LLM behavior by systematically evaluating demographic variation and design parameters in the alignment pipeline. We collected alignment data from US and German participants (N = 1,095, 27,375 ratings) who rated LLM responses across five dimensions: Toxicity, Emotional Awareness (EA), Sensitivity, Stereotypical Bias, and Helpfulness. We fine-tuned multiple Large Language Models and Large Reasoning Models using preferences from different social groups while varying rating scales, disagreement handling methods, and optimization techniques. The results revealed systematic demographic effects: male participants rated responses 18% less toxic than female participants; conservative and Black participants rated responses 27.9% and 44% more emotionally aware than liberal and White participants, respectively. Models fine-tuned on group-specific preferences exhibited distinct behaviors. Technical design choices showed strong effects: the preservation of rater disagreement achieved roughly 53% greater toxicity reduction than majority voting, and 5-point scales yielded about 22% more reduction than binary formats; and Direct Preference Optimization (DPO) consistently outperformed Group Relative Policy Optimization (GRPO) in multi-value optimization. These findings represent a preliminary step in answering a critical question: How should alignment balance expert-driven and user-driven signals to ensure both safety and fair representation?

</details>


### [32] [A Neuro-Symbolic Framework for Reasoning under Perceptual Uncertainty: Bridging Continuous Perception and Discrete Symbolic Planning](https://arxiv.org/abs/2511.14533)
*Jiahao Wu,Shengwen Yu*

Main category: cs.AI

TL;DR: 提出了一种神经符号框架，通过显式建模和传播从感知到规划的不确定性，连接连续感知信号和离散符号推理。在桌面机器人操作任务中验证了有效性，在多个基准测试中达到90.7%平均成功率，比最强POMDP基线提高10-14个百分点。


<details>
  <summary>Details</summary>
Motivation: 解决连续感知信号与离散符号推理之间的桥梁问题，特别是在不确定性环境下运行的AI系统需要建立这两个抽象层次之间的原则性连接。

Method: 结合基于transformer的感知前端和图神经网络关系推理，从视觉观察中提取概率符号状态，并使用不确定性感知的符号规划器在置信度低时主动收集信息。

Result: 在10,047个PyBullet生成的场景（3-10个物体）上处理，输出具有校准置信度的概率谓词（总体F1=0.68）。在规划器中嵌入后，在Simple Stack、Deep Stack和Clear+Stack基准测试中分别达到94%/90%/88%成功率（平均90.7%），比最强POMDP基线提高10-14个百分点，规划时间在15毫秒内。

Conclusion: 该框架建立了校准不确定性与规划收敛之间的定量联系，提供了理论保证并经验验证。该框架是通用的，可应用于任何需要从感知输入到符号规划的不确定性感知推理的领域。

Abstract: Bridging continuous perceptual signals and discrete symbolic reasoning is a fundamental challenge in AI systems that must operate under uncertainty. We present a neuro-symbolic framework that explicitly models and propagates uncertainty from perception to planning, providing a principled connection between these two abstraction levels. Our approach couples a transformer-based perceptual front-end with graph neural network (GNN) relational reasoning to extract probabilistic symbolic states from visual observations, and an uncertainty-aware symbolic planner that actively gathers information when confidence is low. We demonstrate the framework's effectiveness on tabletop robotic manipulation as a concrete application: the translator processes 10,047 PyBullet-generated scenes (3--10 objects) and outputs probabilistic predicates with calibrated confidences (overall F1=0.68). When embedded in the planner, the system achieves 94\%/90\%/88\% success on Simple Stack, Deep Stack, and Clear+Stack benchmarks (90.7\% average), exceeding the strongest POMDP baseline by 10--14 points while planning within 15\,ms. A probabilistic graphical-model analysis establishes a quantitative link between calibrated uncertainty and planning convergence, providing theoretical guarantees that are validated empirically. The framework is general-purpose and can be applied to any domain requiring uncertainty-aware reasoning from perceptual input to symbolic planning.

</details>


### [33] [AutoTool: Efficient Tool Selection for Large Language Model Agents](https://arxiv.org/abs/2511.14650)
*Jingyi Jia,Qinbin Li*

Main category: cs.AI

TL;DR: AutoTool是一个基于图的框架，通过利用工具使用惯性来减少LLM代理中的推理成本，无需重复调用LLM进行工具选择


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理框架在工具选择时存在高推理成本问题，特别是像ReAct这样需要反复调用LLM确定每个步骤使用什么工具的方法

Method: 构建基于历史代理轨迹的有向图，节点代表工具，边捕捉转移概率，建模工具选择惯性，并集成参数级信息来优化工具输入生成

Result: 在多样化代理任务上的实验表明，AutoTool将推理成本降低高达30%，同时保持竞争力的任务完成率

Conclusion: 这项工作展示了将统计结构整合到LLM代理设计中的前景，可以在不牺牲性能的情况下实现更高的效率

Abstract: Large Language Model (LLM) agents have emerged as powerful tools for automating complex tasks by leveraging the reasoning and decision-making abilities of LLMs. However, a major bottleneck in current agent frameworks lies in the high inference cost of tool selection, especially in approaches like ReAct that repeatedly invoke the LLM to determine which tool to use at each step. In this work, we propose AutoTool, a novel graph-based framework that bypasses repeated LLM inference by exploiting a key empirical observation: tool usage inertia - the tendency of tool invocations to follow predictable sequential patterns. AutoTool constructs a directed graph from historical agent trajectories, where nodes represent tools and edges capture transition probabilities, effectively modeling the inertia in tool selection. It further integrates parameter-level information to refine tool input generation. By traversing this structured representation, AutoTool efficiently selects tools and their parameters with minimal reliance on LLM inference. Extensive experiments across diverse agent tasks demonstrate that AutoTool reduces inference costs by up to 30% while maintaining competitive task completion rates, offering a practical and scalable enhancement for inference-heavy frameworks. Our work highlights the promise of integrating statistical structure into LLM agent design for greater efficiency without sacrificing performance.

</details>


### [34] [SkillGen: Learning Domain Skills for In-Context Sequential Decision Making](https://arxiv.org/abs/2511.14670)
*Ruomeng Ding,Wei Cheng,Minglai Shao,Chen Zhao*

Main category: cs.AI

TL;DR: SkillGen是一个基于技能的上下文学习框架，通过构建动作中心图、识别高效用动作和检索步骤技能，为顺序决策任务生成细粒度的提示，在多个环境中显著提升LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 现有上下文学习方法在提示质量上存在不足，无法同时满足关注决策关键信息、提供步骤级粒度和减少专家标注依赖这三个原则。

Method: SkillGen构建动作中心的领域级图，通过时间差分信用分配识别高效用动作，并检索步骤级技能来生成细粒度的上下文感知提示。

Result: 在ALFWorld、BabyAI和ScienceWorld上的实验表明，SkillGen平均提升进度率5.9%-16.5%，在开源和专有LLM上均取得一致增益。

Conclusion: 关注高效用片段支持任务可识别性，并为更有效的上下文学习提示设计提供信息，SkillGen框架在顺序推理任务中表现出色。

Abstract: Large language models (LLMs) are increasingly applied to sequential decision-making through in-context learning (ICL), yet their effectiveness is highly sensitive to prompt quality. Effective prompts should meet three principles: focus on decision-critical information, provide step-level granularity, and minimize reliance on expert annotations through label efficiency. However, existing ICL methods often fail to satisfy all three criteria simultaneously. Motivated by these challenges, we introduce SkillGen, a skill-based ICL framework for structured sequential reasoning. It constructs an action-centric, domain-level graph from sampled trajectories, identifies high-utility actions via temporal-difference credit assignment, and retrieves step-wise skills to generate fine-grained, context-aware prompts. We further present a theoretical analysis showing that focusing on high-utility segments supports task identifiability and informs more effective ICL prompt design. Experiments on ALFWorld, BabyAI, and ScienceWorld, using both open-source and proprietary LLMs, show that SkillGen achieves consistent gains, improving progress rate by 5.9%-16.5% on average across models.

</details>


### [35] [Heterogeneous Multi-Agent Proximal Policy Optimization for Power Distribution System Restoration](https://arxiv.org/abs/2511.14730)
*Parya Dolatyabi,Mahdi Khodayar*

Main category: cs.AI

TL;DR: 本文应用异构智能体强化学习框架解决电力配电网大规模停电后的恢复问题，通过HAPPO算法实现互联微电网的协调恢复，在IEEE测试系统上表现出优于多种基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法和基于价值的强化学习方法在处理配电网恢复问题时计算效率低且难以扩展，需要解决非线性约束下的顺序开关操作和分布式能源资源协调问题。

Method: 采用异构智能体强化学习框架，通过异构智能体近端策略优化算法训练去中心化的执行器策略，配合集中式评论家计算优势值进行稳定的策略更新，使用物理信息化的OpenDSS环境提供完整潮流反馈。

Result: 在IEEE 123总线和IEEE 8500节点系统上的实验表明，HAPPO相比DQN、PPO、MAES、MAGDPG、MADQN、Mean-Field RL和QMIX等方法，具有更快的收敛速度、更高的恢复功率和更平滑的多种子训练过程。

Conclusion: 将微电网级别的异构性纳入HARL框架，为复杂配电网恢复问题提供了可扩展、稳定且约束感知的解决方案。

Abstract: Restoring power distribution systems (PDS) after large-scale outages requires sequential switching operations that reconfigure feeder topology and coordinate distributed energy resources (DERs) under nonlinear constraints such as power balance, voltage limits, and thermal ratings. These challenges make conventional optimization and value-based RL approaches computationally inefficient and difficult to scale. This paper applies a Heterogeneous-Agent Reinforcement Learning (HARL) framework, instantiated through Heterogeneous-Agent Proximal Policy Optimization (HAPPO), to enable coordinated restoration across interconnected microgrids. Each agent controls a distinct microgrid with different loads, DER capacities, and switch counts, introducing practical structural heterogeneity. Decentralized actor policies are trained with a centralized critic to compute advantage values for stable on-policy updates. A physics-informed OpenDSS environment provides full power flow feedback and enforces operational limits via differentiable penalty signals rather than invalid action masking. The total DER generation is capped at 2400 kW, and each microgrid must satisfy local supply-demand feasibility. Experiments on the IEEE 123-bus and IEEE 8500-node systems show that HAPPO achieves faster convergence, higher restored power, and smoother multi-seed training than DQN, PPO, MAES, MAGDPG, MADQN, Mean-Field RL, and QMIX. Results demonstrate that incorporating microgrid-level heterogeneity within the HARL framework yields a scalable, stable, and constraint-aware solution for complex PDS restoration.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [36] [DNA Storage in the Short Molecule Regime](https://arxiv.org/abs/2511.14284)
*Ran Tamir,Nir Weinberger,Albert Guillén i Fàbregas*

Main category: cs.IT

TL;DR: 本文完成了DNA存储系统中短DNA分子可存储信息量的猜想证明，提出了两种编码方案，其中随机编码方案实现了与已有下界匹配的可达性界，第二种方案计算复杂度更低但在极短分子范围内未达最优。


<details>
  <summary>Details</summary>
Motivation: 研究DNA存储系统中短DNA分子能够可靠存储的信息量，验证Shomorony和 Heckel (2022)提出的关于信息位数缩放规律的猜想。

Method: 分析了随机编码方案，其中码字通过量化从概率单纯形中随机生成的概率质量函数获得，并分析了最优最大似然解码器；还提出了第二种计算复杂度显著降低的编码方案。

Result: 推导出了与最近建立的下界在整个短分子范围内匹配的可达性界；第二种方案在除特定极短分子范围外实现了最优缩放。

Conclusion: 完成了DNA存储系统短分子信息容量猜想的证明，提供了两种编码方案，其中随机编码方案完全匹配理论界限，而低复杂度方案在大多数情况下也能达到最优性能。

Abstract: We study the amount of reliable information that can be stored in a DNA-based storage system composed of short DNA molecules. In this regime, Shomorony and Heckel (2022) put forward a conjecture on the scaling of the number of information bits that can be reliably stored. In this paper, we complete the proof of this conjecture. We analyze a random-coding scheme in which each codeword is obtained by quantizing a randomly generated probability mass function drawn from the probability simplex. By analyzing the optimal maximum-likelihood decoder, we derive an achievability bound that matches a recently established converse bound across the entire short-molecule regime. We also propose a second coding scheme, which operates with significantly lower computational complexity but achieves the optimal scaling, except for a specific range of very short molecules.

</details>


### [37] [The Capacity of Collusion-Resilient Decentralized Secure Aggregation with Groupwise Keys](https://arxiv.org/abs/2511.14444)
*Zhou Li,Xiang Zhang,Yizhou Zhao,Haiqiang Chen,Jihao Fan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 本文研究了在实用分组密钥和抗串谋条件下的去中心化安全聚合问题，确定了最优的通信速率和密钥速率区域。


<details>
  <summary>Details</summary>
Motivation: 受高效分组密钥生成协议的启发，研究在对称分组密钥设置下的安全聚合问题，其中每组G个用户共享独立的分组密钥，旨在为去中心化学习系统提供通信和密钥高效的安全聚合设计思路。

Method: 考虑K个用户通过无差错广播信道互连，每个用户持有私有输入，使用分组密钥来掩盖输入，同时满足恢复和安全约束。分析在分组密钥结构约束下的最优速率区域。

Result: 当G=1或G≥K-T时，分组密钥DSA不可行；当2≤G<K-T时，为安全计算一个期望和符号，每个用户必须广播至少一个符号，每个分组密钥必须包含至少(K-T-2)/C(K-T-1,G)个独立符号。

Conclusion: 建立了分组密钥DSA的基本极限，为去中心化学习系统中的通信和密钥高效安全聚合提供了设计见解。

Abstract: This paper investigates the information-theoretic decentralized secure aggregation (DSA) problem under practical groupwise secret keys and collusion resilience. In DSA, $K$ users are interconnected through error-free broadcast channels. Each user holds a private input and aims to compute the sum of all other users' inputs, while satisfying the security constraint that no user, even when colluding with up to $T$ other users, can infer any information about the inputs beyond the recovered sum. To ensure security, users are equipped with secret keys to mask their inputs. Motivated by recent advances in efficient group-based key generation protocols, we consider the symmetric groupwise key setting, where every subset of $G$ users shares a group key that is independent of all other group keys. The problem is challenging because the recovery and security constraints must hold simultaneously for all users, and the structural constraints on the secret keys limit the flexibility of key correlations. We characterize the optimal rate region consisting of all achievable pairs of per-user broadcast communication rate and groupwise key rate. In particular, we show that DSA with groupwise keys is infeasible when $G=1$ or $G\ge K-T$. Otherwise, when $2\le G<K-T$, to securely compute one symbol of the desired sum, each user must broadcast at least one symbol, and each group key must contain at least $(K-T-2)/\binom{K-T-1}{G}$ independent symbols. Our results establish the fundamental limits of DSA with groupwise keys and provide design insights for communication- and key-efficient secure aggregation in decentralized learning systems.

</details>


### [38] [Monimial Matrix Analogue of Yoshida's theorem](https://arxiv.org/abs/2511.14480)
*Ananda Chakraborty*

Main category: cs.IT

TL;DR: 本文研究了有限域上线性码的权重枚举器变体，推广了平均完全联合权重枚举器的概念，建立了MacWilliams型恒等式和Yoshida定理的单项式类似物。


<details>
  <summary>Details</summary>
Motivation: 研究有限域上线性码的权重枚举器变体，特别是推广平均完全联合权重枚举器的概念，以深化对编码理论中权重分布性质的理解。

Method: 推广平均完全联合权重枚举器概念，建立MacWilliams型恒等式，并发展Yoshida定理的单项式矩阵类似物。

Result: 提出了平均完全联合权重枚举器的广义表示，并建立了相应的Yoshida定理单项式类似物。

Conclusion: 成功推广了平均完全联合权重枚举器理论，建立了相关恒等式和定理，为编码理论中的权重分布分析提供了新的工具。

Abstract: In this paper, we study variants of weight enumerators of linear codes over $\mathbb{F}_q$. We generalize the concept of average complete joint weight enumerators of two linear codes over $\mathbb{F}_q$. We also give its MacWilliams type identities. Then we establish a monomial analogue of Yoshida's theorem for this average complete joint weight enumerators. Finally, we present the generalized representation for average of $g$-fold complete joint weight enumerators for $\mathbb{F}_q$-linear codes and establish a monomial matrix analogue of Yoshida's theorem for average $g$-fold complete joint weight enumerators.

</details>


### [39] [Neural Networks-Enabled Channel Reconstruction for Fluid Antenna Systems: A Data-Driven Approach](https://arxiv.org/abs/2511.14520)
*Haoyu Liang,Zhentian Zhang,Jian Dang,Hao Jiang,Zaichen Zhang*

Main category: cs.IT

TL;DR: 提出了一种基于神经网络的数据驱动信道重建方法，用于流体天线系统，在提高重建精度的同时显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 流体天线系统利用紧凑阵列空间内的电磁端口相关性提供空间分集，但需要准确的信道状态信息。现有信道重建方法缺乏同时适用于模型驱动和无模型场景的高精度、高效率解决方案。

Method: 采用神经网络驱动的数据驱动信道重建框架，结合模型驱动和无模型方法的优势。

Result: 数值结果表明，所提方案在重建精度和计算效率方面均优于现有最先进技术，具有快速收敛和鲁棒的重建能力。

Conclusion: 该神经网络驱动的信道重建方法为流体天线系统提供了一种高效、精确的信道状态信息获取解决方案，优于现有方法。

Abstract: Fluid antenna systems (FASs) offer substantial spatial diversity by exploiting the electromagnetic port correlation within compact array spaces, thereby generating favorable small-scale fading conditions with beneficial channel gain envelope fluctuations. This unique capability opens new opportunities for a wide range of communication applications and emerging technologies. However, accurate channel state information (CSI) must be acquired before a fluid antenna can be effectively utilized. Although several efforts have been made toward channel reconstruction in FASs, a generally applicable solution to both model-based or model-free scenario with both high precision and efficient computational flow remains lacking. In this work, we propose a data-driven channel reconstruction approach enabled by neural networks. The proposed framework not only achieves significantly enhanced reconstruction accuracy but also requires substantially lower computational complexity compared with existing model-free methods. Numerical results further demonstrate the rapid convergence and robust reconstruction capability of the proposed scheme, outperforming current state-of-the-art techniques.

</details>


### [40] [Compression with Privacy-Preserving Random Access](https://arxiv.org/abs/2511.14524)
*Venkat Chandar,Aslan Tchamkerten,Shashank Vatedka*

Main category: cs.IT

TL;DR: 论文证明了一个i.i.d.二进制源序列可以在任意高于熵率的速率下进行无损压缩，使得对任何单个比特的解码不会泄露其他比特的信息。


<details>
  <summary>Details</summary>
Motivation: 研究如何在压缩数据的同时保护单个比特的隐私，防止在解码某个比特时泄露其他比特的信息。

Method: 使用信息论方法分析i.i.d.二进制源序列的压缩，确保在无损压缩条件下实现单个比特解码的隐私保护。

Result: 成功证明了存在这样的压缩方案，可以在任意高于熵率的压缩速率下实现，使得解码单个比特不会泄露其他比特的任何信息。

Conclusion: 这项工作展示了在无损压缩中实现强隐私保护的可能性，为安全数据压缩提供了理论基础。

Abstract: It is shown that an i.i.d. binary source sequence $X_1, \ldots, X_n$ can be losslessly compressed at any rate above entropy such that the individual decoding of any $X_i$ reveals \emph{no} information about the other bits $\{X_j : j \neq i\}$.

</details>
