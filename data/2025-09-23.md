<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 10]
- [cs.AI](#cs.AI) [Total: 64]
- [cs.IT](#cs.IT) [Total: 15]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Spatial Encoding of Flow Spaces for Intelligent SDN Applications](https://arxiv.org/abs/2509.16485)
*Abdur Rouf,Murat Yuksel*

Main category: cs.NI

TL;DR: 提出基于Bloom Filter的空间感知网络流编码方法，用于SDN中的强化学习应用，通过保持流量的空间相关性来提高性能


<details>
  <summary>Details</summary>
Motivation: SDN中智能应用需要高效编码网络流空间并保持空间局部性，特别是对于采用强化学习的反应式应用

Method: 使用基于Bloom Filter的方法编码IP流对，利用其固有的地理局部性，并将此编码集成到基于DQN的SDN转发驱逐策略中

Result: 实验显示Bloom Filter能有效保持流之间的空间关系，在10小时流量测试中，相比LRU和LFU分别降低7%和8%的归一化缺失率

Conclusion: Bloom Filter编码的空间感知流表示证明了保持空间相关性对于RL-based SDN应用的价值，为低延迟应用开辟了新研究方向

Abstract: Efficient encoding of network flow spaces while preserving spatial locality
is essential for intelligent Software-Defined Networking (SDN) applications,
particularly those employing reinforcement learning (RL) methods in a reactive
manner. In this work, we introduce a spatially aware Bloom Filter-based
approach to encode IP flow pairs, leveraging their inherent geographical
locality. Through controlled experiments using IoT traffic data, we demonstrate
that Bloom Filters effectively preserve spatial relationships among flows. Our
findings show that Bloom Filters degrade gracefully, maintaining predictable
spatial correlations critical for RL state representation. We integrate this
encoding into a DQN-based eviction strategy for reactive SDN forwarding.
Experiments show that Bloom Filter-encoded, spatially aware flow representation
enables up to 7% and 8% reduction in normalized miss rate over LRU and LFU,
respectively, across 10 hours of traffic, demonstrating potential for
low-latency applications. This experiment justifies the usefulness of
preserving spatial correlation by encoding the flow space into a manageable
size, opening a novel research direction for RL-based SDN applications.

</details>


### [2] [Kalman Filtering-Assisted Node Deployment for Distributed OTFS-ISAC: A Geometry-Aware Design for the Joint Sensing and Communication](https://arxiv.org/abs/2509.16700)
*Jyotsna Rani,Kuntal Deka,Ganesh Prasad,Zilong Liu*

Main category: cs.NI

TL;DR: 本文提出了一种基于三角测量的分布式OTFS-ISAC框架，通过优化节点部署几何和集成卡尔曼滤波来提升移动目标定位精度和通信性能。


<details>
  <summary>Details</summary>
Motivation: 传统单基地ISAC在高速移动场景下空间分集有限，而分布式OFDM方案对多普勒频移和多径衰落敏感。OTFS调制在时延-多普勒域具有鲁棒性，但分布式OTFS-ISAC中的节点部署问题尚未充分研究。

Method: 提出三角测量框架利用空间分集改进目标定位和速度估计；集成卡尔曼滤波增强移动目标跟踪；设计主动/被动感知和联合感知-通信算法；推导一般拓扑下的定位误差闭式解。

Result: 数值评估显示定位误差和误码率显著降低，揭示了感知精度与通信可靠性之间的权衡关系。正交轴部署策略接近最优。

Conclusion: KF辅助的节点部署在分布式OTFS-ISAC中具有实现动态无线环境下可靠高性能操作的潜力。

Abstract: Integrated sensing and communication (ISAC) is a key enabler for
next-generation wireless networks, offering spectrum efficiency and reduced
hardware complexity. While monostatic ISAC has been well studied, its limited
spatial diversity reduces reliability in high-mobility scenarios. Distributed
ISAC alleviates this via cooperative nodes, but conventional OFDM-based designs
remain vulnerable to Doppler shifts and multipath fading. Orthogonal time
frequency space (OTFS) modulation has recently emerged as a resilient
alternative, as its delay-Doppler domain representation enables robust
communication and high-resolution sensing. Motivated by this, we extend OTFS to
distributed ISAC and address the underexplored problem of spatial node
deployment. We propose a triangulation-based framework that leverages spatial
diversity to improve target localization, velocity estimation, and
communication rates, and analytically characterize the role of deployment
geometry in minimizing estimation error. Furthermore, we integrate Kalman
filtering (KF) into distributed OTFS-ISAC to enhance tracking of moving
targets, and design novel algorithms for active sensing, passive sensing, and
joint sensing-communication. Closed-form expressions are derived for
localization error under general topologies, and a near-optimal deployment
strategy is identified by aligning receivers along orthogonal axes. Numerical
evaluations show significant reductions in localization error and bit error
rate (BER), while capturing the trade-offs between sensing accuracy and
communication reliability. These results highlight the potential of KF-assisted
node placement in distributed OTFS-ISAC for reliable, high-performance
operation in dynamic wireless environments.

</details>


### [3] [BeNNS: A Surrogate Model for Hybrid Online-Offline Evolution of SFC Embedding](https://arxiv.org/abs/2509.16856)
*Theviyanthan Krishnamohan,Lauritz Thamsen,Paul Harvey*

Main category: cs.NI

TL;DR: 本文提出了一种混合在线-离线方法来解决服务功能链（SFC）嵌入问题，通过使用BeNNS代理模型来近似评估解决方案的适应度，显著提高了遗传算法的在线应用效率。


<details>
  <summary>Details</summary>
Motivation: 服务功能链嵌入到物理网络和计算基础设施是一个NP难问题。虽然遗传算法可以解决这个问题，但传统方法需要大量时间在线评估解决方案质量，大多数解决方案只能采用离线模拟或分析评估，限制了在线应用。

Method: 提出混合在线-离线方法，核心是BeNNS——一个与拓扑、流量和SFC嵌入无关的代理模型，用于近似评估生成的解决方案的适应度。

Result: 在六个实验中评估该方法，结果表明该方法能够在36.8分钟内平均探索数千种潜在配置并生成可部署解决方案，而纯在线方法平均需要17.9小时仅探索数十种解决方案且无法收敛到最优解。

Conclusion: 所提出的混合方法显著提高了遗传算法在SFC嵌入问题中的在线应用效率，能够在合理时间内生成高质量的解决方案。

Abstract: Service Function Chains (SFCs) enable programmatic control of the functions
and services in a computer network. By leveraging Software Defined Networking
to control the links between virtualised network functions, SFCs provide a
scalable approach to dealing with the increased pressures on network operation
and management. Unfortunately, the challenge of embedding SFCs onto the
underlying physical network and compute infrastructure is an NP-hard problem.
Genetic Algorithms (GAs) have been used to address this issue, but they require
significant time to evaluate solution quality (fitness) \textit{online}, with
most solutions instead adopting \textit{offline} simulations or analytical
evaluations.
  To enable online use of GAs in solving the SFC embedding problem, we
introduce a hybrid online-offline approach to evaluate generated solutions. At
the core of this is BeNNS--a topology, traffic, and SFC-embedding agnostic
surrogate model that approximates fitness. We evaluate our approach across six
experiments, varying available resources and traffic loads. Our results
demonstrate that our approach is capable of exploring thousands of potential
configurations and generating deployable solutions in 36.8 minutes on average,
compared to online-only approaches, which take 17.9 hours on average to explore
tens of solutions, which do not converge on an optimal solution.

</details>


### [4] [System Relaxation for Interpretable and Adaptive Network Control](https://arxiv.org/abs/2509.16984)
*Zhiyuan Ren,Zhiliang Shuai,Wenchi Cheng*

Main category: cs.NI

TL;DR: 本文提出了系统松弛算法（SRA），一种受物理松弛启发的新型网络控制范式，通过引导网络达到负载平衡的涌现均衡，解决传统静态最短路径策略导致的临界节点应力集中问题。


<details>
  <summary>Details</summary>
Motivation: 现有网络控制策略依赖静态最短路径逻辑，会导致关键节点出现灾难性的"应力集中"问题，需要一种能够动态平衡负载的新方法。

Method: SRA是一种可解释的"白盒"动态系统，其行为高度依赖网络拓扑结构。在异构网络中作为主动性能优化器工作，在同构拓扑中智能转向韧性增强。

Result: 在异构网络中，SRA能将峰值中心性降低80%以上，高负载吞吐量提高45%以上；在同构网络中则专注于增强网络韧性。

Conclusion: 通过非光滑动力系统理论严格证明了SRA的全局收敛性和实际稳定性，建立了一个可预测的网络治理范式，智能地在性能和韧性之间进行权衡。

Abstract: Prevailing network control strategies, which rely on static shortest-path
logic, suffer from catastrophic "stress concentration" on critical nodes. This
paper introduces the System Relaxation Algorithm (SRA), a new control paradigm
inspired by physical relaxation that guides a network toward an emergent
equilibrium of load balance. SRA is an interpretable, 'white-box' dynamical
system whose behavior is profoundly topology-dependent: in heterogeneous
networks, it acts as a proactive performance optimizer, reducing peak
centrality by over 80\% and increasing high-load throughput by more than 45\%;
in homogeneous topologies, its objective intelligently shifts to resilience
enhancement. We rigorously prove its global convergence and practical stability
using the theory of non-smooth dynamical systems, establishing a predictable
paradigm for network governance that intelligently trades off performance and
resilience.

</details>


### [5] [Analysis of an Architecture for Integrated Sensing and Communication in 5G OpenRAN](https://arxiv.org/abs/2509.16917)
*Daniel Lindenschmitt,Tobias Jung,Prudhvi Kumar Kakani,Torsten Reissland,Norman Franchi,Hans D. Schotten*

Main category: cs.NI

TL;DR: 本文分析了5G OpenRAN环境中集成感知与通信的功能需求和架构考虑，重点研究安全模块化部署，提出基于嗅探器射频单元和现有前传接口的架构，最小化硬件修改并保护敏感数据。


<details>
  <summary>Details</summary>
Motivation: 随着5G网络向OpenRAN架构演进，需要在开放环境中实现安全可靠的集成感知与通信功能，同时保护敏感数据免受潜在攻击威胁。

Method: 采用单站半双工感知方法，评估雷达设置选项、信号类型和在RAN中的处理位置，利用嗅探器射频单元和现有OpenRAN前传接口构建架构。

Result: 提出了适用于公共移动网络和非公共网络的部署蓝图，支持未来6G ISAC能力，在标准兼容的前提下实现安全部署。

Conclusion: 该架构成功平衡了性能与安全需求，为OpenRAN环境中的ISAC部署提供了可行的技术方案，具有向6G演进的能力。

Abstract: This paper analyzes the functional requirements and architectural
considerations for Integrated Sensing and Communication ( ISAC) in a 5G Open
Radio Access Network (OpenRAN) environment, with emphasis on secure and modular
deployment. Focusing on a mono-static, half-duplex sensing approach, it
evaluates radar setup options, signal types, and processing placement within
the Radio Access Network ( RAN), considering performance and security
implications. The proposed architecture minimizes hardware modifications by
leveraging sniffer Radio Units (RU s) and existing OpenRAN fronthaul
interfaces, while protecting sensitive In-phase and Quadrature (I/Q) data and
control traffic against potential attacks. Security threats, such as passive
sensing, spoofing, and privacy violations, are mapped to mitigation strategies
within the OpenRAN framework. The result is a deployment blueprint applicable
to both Public Land Mobile Networks ( PLMNs) and Non-Public Networks (NPNs),
supporting future 6G ISAC capabilities in a standards-compliant manner.

</details>


### [6] [Impact of Packetization on Network Calculus Analysis](https://arxiv.org/abs/2509.17028)
*Yming Jiang*

Main category: cs.NI

TL;DR: 本文通过反例证明，在忽略分组化效应时，网络演算分析会产生错误结果，特别是在TSN和DetNet的基本系统中。作者修正了服务曲线和性能界限，强调在分组交换网络中应用网络演算分析需要特别谨慎。


<details>
  <summary>Details</summary>
Motivation: 针对分组交换网络中忽略分组化效应导致网络演算分析产生错误结果的问题，研究TSN和确定性网络基本系统中的服务曲线和性能界限的有效性。

Method: 通过构造反例，分析两种基本系统中广泛采用但忽略分组化效应的网络演算服务曲线，并直接考虑分组化效应推导修正的服务曲线和性能界限。

Result: 揭示了两种基本设置中忽略分组化效应的服务曲线是错误的，输出界限、积压界限和级联服务曲线结果也存在问题。通过考虑分组化效应，得出了修正的服务曲线和性能界限。

Conclusion: 在分组交换网络中应用网络演算分析时需要特别谨慎，必须考虑分组化效应，否则可能导致错误的分析结果。

Abstract: For packet-switched networks, when the packetization effect is overlooked,
network calculus analysis can produce faulty results. To exemplify, network
calculus analysis is applied in this paper to two basic systems that are
fundamental or default settings in Time-Sensitive Networking (TSN) and
Deterministic Networking (DetNet). Through counterexamples, it is revealed that
for the two fundamental settings, some widely adopted, network calculus-based
service characterization results, known as service curves, which ignore
packetization, are faulty. In addition, for performance bounds derived from the
faulty service curves, it is shown that the validity of the bounds can be
arguable. In particular, the output bound, backlog bound and concatenation
service curve results are shown to be also faulty: counterexamples can be
constructed. By factoring the packetization effect directly into the service
models, corrected service curves and performance bounds are derived for the two
basic systems. These results remind that special care is needed when applying
network calculus analysis to packet-switched networks.

</details>


### [7] [Optimizing Split Federated Learning with Unstable Client Participation](https://arxiv.org/abs/2509.17398)
*Wei Wei,Zheng Lin,Xihui Liu,Hongyang Du,Dusit Niyato,Xianhao Chen*

Main category: cs.NI

TL;DR: 本文提出了一个针对不稳定客户端参与的拆分联邦学习优化框架，通过理论推导收敛上界，并开发了联合优化客户端采样和模型拆分的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的拆分联邦学习方法通常假设完美的客户端参与，忽略了不稳定网络环境带来的挑战，这在现实场景中不实用。

Method: 理论推导了考虑激活上传失败、梯度下载失败和模型聚合失败的收敛上界，然后构建了联合优化客户端采样和模型拆分的优化问题，并开发了高效求解方法。

Result: 在EMNIST和CIFAR-10数据集上的广泛仿真表明，所提出的框架优于现有基准方法。

Conclusion: 该工作为不稳定网络环境下的拆分联邦学习提供了实用的优化框架，解决了实际部署中的关键挑战。

Abstract: To enable training of large artificial intelligence (AI) models at the
network edge, split federated learning (SFL) has emerged as a promising
approach by distributing computation between edge devices and a server.
However, while unstable network environments pose significant challenges to
SFL, prior schemes often overlook such an effect by assuming perfect client
participation, rendering them impractical for real-world scenarios. In this
work, we develop an optimization framework for SFL with unstable client
participation. We theoretically derive the first convergence upper bound for
SFL with unstable client participation by considering activation uploading
failures, gradient downloading failures, and model aggregation failures. Based
on the theoretical results, we formulate a joint optimization problem for
client sampling and model splitting to minimize the upper bound. We then
develop an efficient solution approach to solve the problem optimally.
Extensive simulations on EMNIST and CIFAR-10 demonstrate the superiority of our
proposed framework compared to existing benchmarks.

</details>


### [8] [GLo-MAPPO: A Multi-Agent Proximal Policy Optimization for Energy Efficiency in UAV-Assisted LoRa Networks](https://arxiv.org/abs/2509.17676)
*Abdullahi Isa Ahmed,Jamal Bentahar,El Mehdi Amhoud*

Main category: cs.NI

TL;DR: 提出了一种基于多无人机作为LoRa网关的新型架构，通过联合优化扩频因子、传输功率、无人机轨迹和设备关联，最大化系统加权全局能量效率，并采用多智能体强化学习框架GLo-MAPPO解决复杂优化问题。


<details>
  <summary>Details</summary>
Motivation: 传统地面LoRa部署存在覆盖盲区和非视距传播损耗，而基于卫星的物联网解决方案能耗高、延迟大，无法满足能源受限和延迟敏感应用的需求。

Method: 使用多无人机作为飞行LoRa网关动态收集地面LoRa终端设备数据，将优化问题建模为部分可观测马尔可夫决策过程，提出基于集中训练分散执行的GLo-MAPPO多智能体强化学习框架。

Result: 仿真结果显示，GLo-MAPPO显著优于基准算法，在10、20、30、40和50个LoRa终端设备的网络中分别实现了71.25%、18.56%、67.00%、59.73%和49.95%的能量效率提升。

Conclusion: 该研究提出的多无人机LoRa网关架构和GLo-MAPPO算法有效解决了下一代物联网应用中的能量效率挑战，为5G/6G生态系统中的低功耗广域网提供了可行的解决方案。

Abstract: Long Range (LoRa) based low-power wide area networks (LPWANs) are crucial for
enabling next-generation IoT (NG-IoT) applications in 5G/6G ecosystems due to
their long-range, low-power, and low-cost characteristics. However, achieving
high energy efficiency in such networks remains a critical challenge,
particularly in large-scale or dynamically changing environments. Traditional
terrestrial LoRa deployments often suffer from coverage gaps and
non-line-of-sight (NLoS) propagation losses, while satellite-based IoT
solutions consume excessive energy and introduce high latency, limiting their
suitability for energy-constrained and delay-sensitive applications. To address
these limitations, we propose a novel architecture using multiple unmanned
aerial vehicles (UAVs) as flying LoRa gateways to dynamically collect data from
ground-based LoRa end devices. Our approach aims to maximize the system's
weighted global energy efficiency by jointly optimizing spreading factors,
transmission powers, UAV trajectories, and end-device associations.
Additionally, we formulate this complex optimization problem as a partially
observable Markov decision process (POMDP) and propose green LoRa multi-agent
proximal policy optimization (GLo-MAPPO), a multi-agent reinforcement learning
(MARL) framework based on centralized training with decentralized execution
(CTDE). Simulation results show that GLo-MAPPO significantly outperforms
benchmark algorithms, achieving energy efficiency improvements of 71.25%,
18.56%, 67.00%, 59.73%, and 49.95% for networks with 10, 20, 30, 40, and 50
LoRa end devices, respectively.

</details>


### [9] [Building Transparency in Deep Learning-Powered Network Traffic Classification: A Traffic-Explainer Framework](https://arxiv.org/abs/2509.18007)
*Riya Ponraj,Ram Durairajan,Yu Wang*

Main category: cs.NI

TL;DR: 提出了Traffic-Explainer框架，通过最大化原始流量序列与其掩码版本预测之间的互信息，自动识别影响模型预测的最关键特征，提升深度学习流量分类的可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在流量分类中性能优异但缺乏透明度，导致网络运营商不愿在生产网络中部署DL解决方案。需要提高模型预测的可解释性。

Method: 基于模型无关和输入扰动的流量解释框架，通过最大化原始流量序列与掩码版本预测的互信息来识别关键特征。

Result: 实验表明Traffic-Explainer比现有解释方法提升约42%，在应用分类、流量定位和网络地图绘制三个关键任务中表现出更强的透明度。

Conclusion: Traffic-Explainer能有效识别驱动模型预测的关键特征，有助于发现潜在漏洞和隐私问题，支持基于traceroute的风险分析。

Abstract: Recent advancements in deep learning have significantly enhanced the
performance and efficiency of traffic classification in networking systems.
However, the lack of transparency in their predictions and decision-making has
made network operators reluctant to deploy DL-based solutions in production
networks. To tackle this challenge, we propose Traffic-Explainer, a
model-agnostic and input-perturbation-based traffic explanation framework. By
maximizing the mutual information between predictions on original traffic
sequences and their masked counterparts, Traffic-Explainer automatically
uncovers the most influential features driving model predictions. Extensive
experiments demonstrate that Traffic-Explainer improves upon existing
explanation methods by approximately 42%. Practically, we further apply
Traffic-Explainer to identify influential features and demonstrate its enhanced
transparency across three critical tasks: application classification, traffic
localization, and network cartography. For the first two tasks,
Traffic-Explainer identifies the most decisive bytes that drive predicted
traffic applications and locations, uncovering potential vulnerabilities and
privacy concerns. In network cartography, Traffic-Explainer identifies
submarine cables that drive the mapping of traceroute to physical path,
enabling a traceroute-informed risk analysis.

</details>


### [10] [Detection of Misreporting Attacks on Software-Defined Immersive Environments](https://arxiv.org/abs/2509.18040)
*Sourya Saha,Md Nurul Absur,Shima Yousefi,Saptarshi Debroy*

Main category: cs.NI

TL;DR: 提出了一种基于混合机器学习的网络异常检测框架，用于识别SDN环境中交换机误报导致的负载不平衡问题，从而防止沉浸式应用的质量严重下降。


<details>
  <summary>Details</summary>
Motivation: SDN的集中控制灵活性带来了新的安全漏洞，如交换机误报导致的负载不平衡，这会使沉浸式环境面临严重的质量退化风险。

Method: 结合无监督异常评分与监督分类的混合机器学习方法，通过捕捉交换机报告负载的时间不一致性来识别恶意行为。

Result: 实验结果显示该框架在检测误报行为方面实现了高召回率，能够在SDN环境中进行早期可靠检测。

Conclusion: 该混合ML框架能有效检测SDN中的隐蔽误报行为，为沉浸式应用提供可靠的网络异常检测保护。

Abstract: The ability to centrally control network infrastructure using a programmable
middleware has made Software-Defined Networking (SDN) ideal for emerging
applications, such as immersive environments. However, such flexibility
introduces new vulnerabilities, such as switch misreporting led load imbalance,
which in turn make such immersive environment vulnerable to severe quality
degradation. In this paper, we present a hybrid machine learning (ML)-based
network anomaly detection framework that identifies such stealthy misreporting
by capturing temporal inconsistencies in switch-reported loads, and thereby
counter potentially catastrophic quality degradation of hosted immersive
application. The detection system combines unsupervised anomaly scoring with
supervised classification to robustly distinguish malicious behavior. Data
collected from a realistic testbed deployment under both benign and adversarial
conditions is used to train and evaluate the model. Experimental results show
that the framework achieves high recall in detecting misreporting behavior,
making it effective for early and reliable detection in SDN environments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [11] [Identifying Critical Pathways in Coronary Heart Disease via Fuzzy Subgraph Connectivity](https://arxiv.org/abs/2509.16288)
*Shanookha Ali,Nitha Niralda P C*

Main category: cs.AI

TL;DR: 该论文提出使用模糊子图连通性（FSC）方法来建模冠心病风险预测中的不确定性，通过构建模糊CHD图来识别关键诊断路径、主导风险因素和关键桥梁。


<details>
  <summary>Details</summary>
Motivation: 冠心病（CHD）是由不可控因素、可控生活方式因素和临床指标之间的复杂相互作用引起的，这些关系通常具有不确定性。需要一种能够捕捉这种不确定性的系统工具来支持临床决策。

Method: 构建一个模糊CHD图，顶点代表不可控、可控和指标组件，边由模糊隶属度加权。使用模糊子图连通性（FSC）评估连通性，识别最强的诊断路径、主导风险因素和关键桥梁。

Result: 结果显示FSC能够突出有影响力的路径，限定最弱和最强相关性之间的连通性边界，并揭示那些移除后会降低预测强度的关键边。

Conclusion: FSC为CHD风险预测中的不确定性建模提供了一个可解释且稳健的框架，支持临床决策制定。

Abstract: Coronary heart disease (CHD) arises from complex interactions among
uncontrollable factors, controllable lifestyle factors, and clinical
indicators, where relationships are often uncertain. Fuzzy subgraph
connectivity (FSC) provides a systematic tool to capture such imprecision by
quantifying the strength of association between vertices and subgraphs in fuzzy
graphs. In this work, a fuzzy CHD graph is constructed with vertices for
uncontrollable, controllable, and indicator components, and edges weighted by
fuzzy memberships. Using FSC, we evaluate connectivity to identify strongest
diagnostic routes, dominant risk factors, and critical bridges. Results show
that FSC highlights influential pathways, bounds connectivity between weakest
and strongest correlations, and reveals critical edges whose removal reduces
predictive strength. Thus, FSC offers an interpretable and robust framework for
modeling uncertainty in CHD risk prediction and supporting clinical
decision-making.

</details>


### [12] [A global view of diverse construction methods of fuzzy implication functions rooted on F-chains](https://arxiv.org/abs/2509.16298)
*Raquel Fernandez-Peralta,Juan Vicente Riera*

Main category: cs.AI

TL;DR: 本文提出了一种广义的F链构造方法，用于从现有模糊蕴涵函数生成新的模糊蕴涵函数，统一了多种现有的构造技术。


<details>
  <summary>Details</summary>
Motivation: 模糊蕴涵函数在模糊逻辑框架中具有重要作用，但现有构造方法的多样性需要对其结构关系进行更深入的理论理解。

Method: 推广了Mesiar等人最近提出的F链构造方法，使用模糊蕴涵函数集合而非单个函数，并采用两个不同的递增函数代替单一的F链。

Result: 分析了该构造下的性质保持性并建立了充分条件，证明了该广义构造是多种现有方法的统一框架。

Conclusion: 该广义F链构造揭示了看似不同的构造策略之间的结构相似性，为模糊蕴涵构造方法提供了统一的视角。

Abstract: Fuzzy implication functions are one of the most important operators used in
the fuzzy logic framework. While their flexible definition allows for diverse
families with distinct properties, this variety needs a deeper theoretical
understanding of their structural relationships. In this work, we focus on the
study of construction methods, which employ different techniques to generate
new fuzzy implication functions from existing ones. Particularly, we generalize
the $F$-chain-based construction, recently introduced by Mesiar et al. to
extend a method for constructing aggregation functions to the context of fuzzy
implication functions. Our generalization employs collections of fuzzy
implication functions rather than single ones, and uses two different
increasing functions instead of a unique $F$-chain. We analyze property
preservation under this construction and establish sufficient conditions.
Furthermore, we demonstrate that our generalized $F$-chain-based construction
is a unifying framework for several existing methods. In particular, we show
that various construction techniques, such as contraposition, aggregation, and
generalized vertical/horizontal threshold methods, can be reformulated within
our approach. This reveals structural similarities between seemingly distinct
construction strategies and provides a cohesive perspective on fuzzy
implication construction methods.

</details>


### [13] [On the Non-Uniqueness of Representation of $(U,N)$-Implications](https://arxiv.org/abs/2509.16299)
*Raquel Fernandez-Peralta,Andrea Mesiarová-Zemánková*

Main category: cs.AI

TL;DR: 本文反驳了(U,N)-蕴涵函数在连续模糊否定下具有唯一表示的传统假设，证明即使模糊否定连续，(U,N)-蕴涵也可能存在多种表示方式，并对连续和非连续基础函数的唯一性条件进行了全面研究。


<details>
  <summary>Details</summary>
Motivation: 模糊蕴涵函数是模糊逻辑系统中的基本算子，扩展了经典条件句以处理逻辑推理中的不确定性。先前研究假设在连续模糊否定N下，(U,N)-蕴涵具有唯一表示，但这一假设需要验证和修正。

Method: 通过理论分析和证明，对(U,N)-蕴涵函数的表示唯一性问题进行深入研究，特别关注连续和非连续基础函数的情况，提供严格的理论推导。

Result: 成功证明了(U,N)-蕴涵函数即使在连续模糊否定条件下也不一定具有唯一表示，打破了传统认知，并建立了更全面的唯一性条件理论框架。

Conclusion: 该研究修正了模糊逻辑理论中的重要假设，为(U,N)-蕴涵函数的结构特性提供了更准确的理论基础，对模糊逻辑系统的设计和分析具有重要指导意义。

Abstract: Fuzzy implication functions constitute fundamental operators in fuzzy logic
systems, extending classical conditionals to manage uncertainty in logical
inference. Among the extensive families of these operators, generalizations of
the classical material implication have received considerable theoretical
attention, particularly $(S,N)$-implications constructed from t-conorms and
fuzzy negations, and their further generalizations to $(U,N)$-implications
using disjunctive uninorms. Prior work has established characterization
theorems for these families under the assumption that the fuzzy negation $N$ is
continuous, ensuring uniqueness of representation. In this paper, we disprove
this last fact for $(U,N)$-implications and we show that they do not
necessarily possess a unique representation, even if the fuzzy negation is
continuous. Further, we provide a comprehensive study of uniqueness conditions
for both uninorms with continuous and non-continuous underlying functions. Our
results offer important theoretical insights into the structural properties of
these operators.

</details>


### [14] [Generalizability of Large Language Model-Based Agents: A Comprehensive Survey](https://arxiv.org/abs/2509.16330)
*Minxing Zhang,Yi Yang,Roy Xie,Bhuwan Dhingra,Shuyan Zhou,Jian Pei*

Main category: cs.AI

TL;DR: 这篇论文是关于LLM智能体泛化能力的综述，分析了当前LLM智能体在跨领域、任务和环境时保持性能一致性的挑战，提出了评估和改进泛化能力的系统方法。


<details>
  <summary>Details</summary>
Motivation: 随着LLM智能体在网页导航、家庭机器人等领域的广泛应用，确保智能体在不同指令、任务、环境和领域中的泛化能力成为关键挑战。目前智能体泛化能力的概念定义不清晰，缺乏系统性的测量和改进方法。

Method: 通过构建层次化的领域-任务本体论来界定智能体泛化能力的边界，回顾现有数据集、评估维度和指标，将改进方法分为三类：针对骨干LLM的方法、针对智能体组件的方法以及针对它们交互的方法。

Result: 提出了可泛化框架与可泛化智能体的区分，并阐述了如何将框架级泛化转化为智能体级泛化。识别了标准化框架开发、基于方差和成本的指标、方法论创新与架构设计融合等关键挑战。

Conclusion: 本综述旨在为构建能够可靠泛化到多样化应用的LLM智能体建立理论基础，通过综合现有进展和突出机遇，推动该领域的规范化研究。

Abstract: Large Language Model (LLM)-based agents have emerged as a new paradigm that
extends LLMs' capabilities beyond text generation to dynamic interaction with
external environments. By integrating reasoning with perception, memory, and
tool use, agents are increasingly deployed in diverse domains like web
navigation and household robotics. A critical challenge, however, lies in
ensuring agent generalizability - the ability to maintain consistent
performance across varied instructions, tasks, environments, and domains,
especially those beyond agents' fine-tuning data. Despite growing interest, the
concept of generalizability in LLM-based agents remains underdefined, and
systematic approaches to measure and improve it are lacking. In this survey, we
provide the first comprehensive review of generalizability in LLM-based agents.
We begin by emphasizing agent generalizability's importance by appealing to
stakeholders and clarifying the boundaries of agent generalizability by
situating it within a hierarchical domain-task ontology. We then review
datasets, evaluation dimensions, and metrics, highlighting their limitations.
Next, we categorize methods for improving generalizability into three groups:
methods for the backbone LLM, for agent components, and for their interactions.
Moreover, we introduce the distinction between generalizable frameworks and
generalizable agents and outline how generalizable frameworks can be translated
into agent-level generalizability. Finally, we identify critical challenges and
future directions, including developing standardized frameworks, variance- and
cost-based metrics, and approaches that integrate methodological innovations
with architecture-level designs. By synthesizing progress and highlighting
opportunities, this survey aims to establish a foundation for principled
research on building LLM-based agents that generalize reliably across diverse
applications.

</details>


### [15] [Psychometric Personality Shaping Modulates Capabilities and Safety in Language Models](https://arxiv.org/abs/2509.16332)
*Stephen Fitz,Peter Romero,Steven Basart,Sipeng Chen,Jose Hernandez-Orallo*

Main category: cs.AI

TL;DR: 该论文研究了通过调节大语言模型的五大人格特质如何影响其在能力和安全基准测试中的表现，发现降低尽责性会显著降低安全性和一般能力指标。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究表明LLMs表现出可测量的合成人格特质，但关于调节这些特质如何影响模型行为的研究还很缺乏，特别是在能力和安全基准测试中的影响。

Method: 基于五大人格框架，通过心理测量人格控制来研究AI行为，在WMDP、TruthfulQA、ETHICS、Sycophancy和MMLU等基准上进行实验。

Result: 实验结果显示，降低尽责性会导致安全相关指标（如WMDP、TruthfulQA等）和一般能力指标（MMLU）显著下降，表明人格塑造是影响模型安全和能力的重要维度。

Conclusion: 人格塑造是一个强大但未被充分探索的模型控制轴，与安全性和一般能力都有交互作用，这为安全评估、对齐策略和部署后行为控制提供了新的研究方向，同时也带来了可能被利用的风险。

Abstract: Large Language Models increasingly mediate high-stakes interactions,
intensifying research on their capabilities and safety. While recent work has
shown that LLMs exhibit consistent and measurable synthetic personality traits,
little is known about how modulating these traits affects model behavior. We
address this gap by investigating how psychometric personality control grounded
in the Big Five framework influences AI behavior in the context of capability
and safety benchmarks. Our experiments reveal striking effects: for example,
reducing conscientiousness leads to significant drops in safety-relevant
metrics on benchmarks such as WMDP, TruthfulQA, ETHICS, and Sycophancy as well
as reduction in general capabilities as measured by MMLU. These findings
highlight personality shaping as a powerful and underexplored axis of model
control that interacts with both safety and general competence. We discuss the
implications for safety evaluation, alignment strategies, steering model
behavior after deployment, and risks associated with possible exploitation of
these findings. Our findings motivate a new line of research on
personality-sensitive safety evaluations and dynamic behavioral control in
LLMs.

</details>


### [16] [A Unified AI Approach for Continuous Monitoring of Human Health and Diseases from Intensive Care Unit to Home with Physiological Foundation Models (UNIPHY+)](https://arxiv.org/abs/2509.16348)
*Minxiao Wang,Saurabh Kataria,Juntong Ni,Timothy G. Buchman,Jocelyn Grunwell,Mark Mai,Wei Jin,Matthew Clark,Stephanie Brown,Michael Fundora,Puneet Sharma,Tony Pan,Sam Khan,Timothy Ruchti,Naveen Muthu,Kevin Maher,Sivasubramanium V Bhavani,Xiao Hu*

Main category: cs.AI

TL;DR: UNIPHY+是一个统一的生理基础模型框架，旨在利用普遍可获取的生理数据实现跨护理场景的连续人类健康和疾病监测


<details>
  <summary>Details</summary>
Motivation: 开发能够支持临床决策和长期健康监测的通用、可扩展且个性化的生理AI系统

Method: 提出在预训练、微调和轻量级模型个性化阶段整合上下文信息的策略，包括多模态学习、特征融合调优和知识蒸馏

Result: 该框架在从重症监护到动态监测的广泛用例中进行测试

Conclusion: UNIPHY+能够赋能通用化、可扩展和个性化的生理AI，支持临床决策和长期健康监测

Abstract: We present UNIPHY+, a unified physiological foundation model (physioFM)
framework designed to enable continuous human health and diseases monitoring
across care settings using ubiquitously obtainable physiological data. We
propose novel strategies for incorporating contextual information during
pretraining, fine-tuning, and lightweight model personalization via multi-modal
learning, feature fusion-tuning, and knowledge distillation. We advocate
testing UNIPHY+ with a broad set of use cases from intensive care to ambulatory
monitoring in order to demonstrate that UNIPHY+ can empower generalizable,
scalable, and personalized physiological AI to support both clinical
decision-making and long-term health monitoring.

</details>


### [17] [Evaluation of Causal Reasoning for Large Language Models in Contextualized Clinical Scenarios of Laboratory Test Interpretation](https://arxiv.org/abs/2509.16372)
*Balu Bhasuran,Mattia Prosperi,Karim Hanna,John Petrilli,Caretia JeLayne Washington,Zhe He*

Main category: cs.AI

TL;DR: 本研究评估了大型语言模型在临床实验室测试场景中的因果推理能力，GPT-o1在关联、干预和反事实推理方面均优于Llama-3.2-8b-instruct，但两者在反事实推理场景中表现最差，需要进一步改进才能用于高风险临床应用。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在临床环境中的因果推理能力，特别是基于Pearl因果阶梯的三个层次：关联、干预和反事实推理，以确定这些模型是否适合用于高风险的医疗决策支持。

Method: 使用99个基于临床的实验室测试场景，涵盖血红蛋白A1c、肌酐、维生素D等常见测试，结合年龄、性别、肥胖、吸烟等因果因素。测试GPT-o1和Llama-3.2-8b-instruct两个模型，由四位医学专家评估响应质量。

Result: GPT-o1在整体判别性能（AUROC = 0.80）上优于Llama-3.2-8b-instruct（0.73），在关联（0.75 vs 0.72）、干预（0.84 vs 0.70）和反事实推理（0.84 vs 0.69）方面均表现更好。两个模型在干预问题上表现最佳，在反事实推理（特别是改变结果场景）中表现最差。

Conclusion: GPT-o1提供了更一致的因果推理能力，但在应用于高风险临床环境之前仍需进一步改进，特别是在反事实推理方面。

Abstract: This study evaluates causal reasoning in large language models (LLMs) using
99 clinically grounded laboratory test scenarios aligned with Pearl's Ladder of
Causation: association, intervention, and counterfactual reasoning. We examined
common laboratory tests such as hemoglobin A1c, creatinine, and vitamin D, and
paired them with relevant causal factors including age, gender, obesity, and
smoking. Two LLMs - GPT-o1 and Llama-3.2-8b-instruct - were tested, with
responses evaluated by four medically trained human experts. GPT-o1
demonstrated stronger discriminative performance (AUROC overall = 0.80 +/-
0.12) compared to Llama-3.2-8b-instruct (0.73 +/- 0.15), with higher scores
across association (0.75 vs 0.72), intervention (0.84 vs 0.70), and
counterfactual reasoning (0.84 vs 0.69). Sensitivity (0.90 vs 0.84) and
specificity (0.93 vs 0.80) were also greater for GPT-o1, with reasoning ratings
showing similar trends. Both models performed best on intervention questions
and worst on counterfactuals, particularly in altered outcome scenarios. These
findings suggest GPT-o1 provides more consistent causal reasoning, but
refinement is required before adoption in high-stakes clinical applications.

</details>


### [18] [VORTEX: Aligning Task Utility and Human Preferences through LLM-Guided Reward Shaping](https://arxiv.org/abs/2509.16399)
*Guojun Xiong,Milind Tambe*

Main category: cs.AI

TL;DR: 本文提出VORTEX框架，通过语言引导的奖励塑造方法，在保持核心优化目标的同时自适应整合人类偏好反馈


<details>
  <summary>Details</summary>
Motivation: 现有AI决策系统无法直接处理自然语言表达的人类偏好，而现有LLM方法虽然灵活但可能牺牲系统核心效用保证

Method: 将问题形式化为多目标优化，使用LLM基于语言反馈和文本梯度提示迭代生成塑造奖励，无需修改求解器或指定权衡权重

Result: 理论证明VORTEX收敛到效用和偏好满意度之间的帕累托最优权衡，实证显示在现实分配任务中优于基线方法

Conclusion: 这项工作为基于自然语言的人类-AI协作优化引入了实用且理论基础的范式

Abstract: In social impact optimization, AI decision systems often rely on solvers that
optimize well-calibrated mathematical objectives. However, these solvers cannot
directly accommodate evolving human preferences, typically expressed in natural
language rather than formal constraints. Recent approaches address this by
using large language models (LLMs) to generate new reward functions from
preference descriptions. While flexible, they risk sacrificing the system's
core utility guarantees. In this paper, we propose \texttt{VORTEX}, a
language-guided reward shaping framework that preserves established
optimization goals while adaptively incorporating human feedback. By
formalizing the problem as multi-objective optimization, we use LLMs to
iteratively generate shaping rewards based on verbal reinforcement and
text-gradient prompt updates. This allows stakeholders to steer decision
behavior via natural language without modifying solvers or specifying trade-off
weights. We provide theoretical guarantees that \texttt{VORTEX} converges to
Pareto-optimal trade-offs between utility and preference satisfaction.
Empirical results in real-world allocation tasks demonstrate that
\texttt{VORTEX} outperforms baselines in satisfying human-aligned coverage
goals while maintaining high task performance. This work introduces a practical
and theoretically grounded paradigm for human-AI collaborative optimization
guided by natural language.

</details>


### [19] [Proactive Statistical Process Control Using AI: A Time Series Forecasting Approach for Semiconductor Manufacturing](https://arxiv.org/abs/2509.16431)
*Mohammad Iqbal Rasul Seeam,Victor S. Sheng*

Main category: cs.AI

TL;DR: 本文提出了一种结合Facebook Prophet机器学习模型和传统统计过程控制(SPC)的智能预测系统，能够在制造过程中提前预测问题，实现主动质量控制。


<details>
  <summary>Details</summary>
Motivation: 传统SPC方法只能在问题发生后进行反应，导致材料浪费、机器停机和成本增加。需要一种能够预测未来问题的主动质量控制方法。

Method: 使用Facebook Prophet时间序列预测模型分析历史数据，预测未来测量值，然后应用SPC规则将预测值分类为安全区、警告区或关键区。

Result: 在半导体制造公司的真实数据上测试，尽管数据采集时间间隔不规则，模型仍能做出准确预测并正确分类未来测量的风险等级。

Conclusion: 将机器学习与传统SPC结合，使质量控制更加主动、准确和有用，帮助工程师提前采取行动，减少意外故障，提高生产过程的稳定性和可靠性。

Abstract: In the manufacturing industry, it is very important to keep machines and
processes running smoothly and without unexpected problems. One of the most
common tools used to check if everything is working properly is called
Statistical Process Control (SPC). Traditional SPC methods work by checking
whether recent measurements are within acceptable limits. However, they only
react after a problem has already occurred. This can lead to wasted materials,
machine downtime, and increased costs. In this paper, we present a smarter way
to use SPC. Instead of just reacting to issues after they happen, our system
can predict future problems before they occur. We use a machine learning tool
called Facebook Prophet, which is designed to work with time-series data (data
that changes over time). Prophet looks at past data and forecasts what the next
value will be. Then, we use SPC rules to decide if the predicted value is in a
Safe zone (no problem), a Warning zone (needs attention), or a Critical zone
(may require shutting down the process). We applied this system to real data
from a semiconductor manufacturing company. One of the challenges with this
data is that the measurements are not taken at regular time intervals. This
makes it harder to predict future values accurately. Despite this, our model
was able to make strong predictions and correctly classify the risk level of
future measurements. The main benefit of our system is that it gives engineers
and technicians a chance to act early - before something goes wrong. This helps
reduce unexpected failures and improves the overall stability and reliability
of the production process. By combining machine learning with traditional SPC,
we make quality control more proactive, accurate, and useful for modern
industry.

</details>


### [20] [Domain-Specific Constitutional AI: Enhancing Safety in LLM-Powered Mental Health Chatbots](https://arxiv.org/abs/2509.16444)
*Chenhan Lyu,Yutong Song,Pengfei Zhang,Amir M. Rahmani*

Main category: cs.AI

TL;DR: 本文提出了一种基于宪法AI训练的领域特定方法，用于解决心理健康应用中AI安全性的特殊挑战。


<details>
  <summary>Details</summary>
Motivation: 心理健康应用在处理敏感数据时面临独特的安全挑战，包括情感脆弱性、误诊风险、症状加剧等，通用AI安全措施不足以应对这些心理健康特定问题。

Method: 采用宪法AI训练方法，结合领域特定的心理健康原则，开发安全、领域适应的CAI系统。

Result: 该方法能够更好地处理心理健康应用中的危机干预准确性、治疗指南遵守、资源受限环境下的可扩展性以及细微对话的适应性。

Conclusion: 领域特定的宪法AI训练为心理健康应用提供了更有效的安全保障，解决了通用AI安全措施在心理健康领域的局限性。

Abstract: Mental health applications have emerged as a critical area in computational
health, driven by rising global rates of mental illness, the integration of AI
in psychological care, and the need for scalable solutions in underserved
communities. These include therapy chatbots, crisis detection, and wellness
platforms handling sensitive data, requiring specialized AI safety beyond
general safeguards due to emotional vulnerability, risks like misdiagnosis or
symptom exacerbation, and precise management of vulnerable states to avoid
severe outcomes such as self-harm or loss of trust. Despite AI safety advances,
general safeguards inadequately address mental health-specific challenges,
including crisis intervention accuracy to avert escalations, therapeutic
guideline adherence to prevent misinformation, scale limitations in
resource-constrained settings, and adaptation to nuanced dialogues where
generics may introduce biases or miss distress signals. We introduce an
approach to apply Constitutional AI training with domain-specific mental health
principles for safe, domain-adapted CAI systems in computational mental health
applications.

</details>


### [21] [On the Variational Costs of Changing Our Minds](https://arxiv.org/abs/2509.17957)
*David Hyland,Mahault Albarracin*

Main category: cs.AI

TL;DR: 本文认为人类认知偏差（如确认偏误）并非认知缺陷，而是对信念更新成本的适应性反应，并提出了一个形式化框架来建模这些成本对信念更新的影响。


<details>
  <summary>Details</summary>
Motivation: 解释为什么人类思维会表现出看似非理性的偏差行为，如捍卫既有信念、选择性解释信息等，这些行为实际上是对信念更新所需认知和实用成本的合理适应。

Method: 将信念更新建模为动机驱动的变分决策过程，使用Kullback-Leibler散度量化从先验到变分后验的信息成本，通过计算实验验证模型能够模拟确认偏误和态度极化等常见人类行为。

Result: 计算实验表明，这个资源理性模型的简单实例能够定性地模拟常见的人类行为模式，包括确认偏误和态度极化现象。

Conclusion: 该框架为理解信念变化的动机性贝叶斯机制提供了更全面的解释，并为预测、补偿和纠正信念更新过程中的偏差提供了实用见解。

Abstract: The human mind is capable of extraordinary achievements, yet it often appears
to work against itself. It actively defends its cherished beliefs even in the
face of contradictory evidence, conveniently interprets information to conform
to desired narratives, and selectively searches for or avoids information to
suit its various purposes. Despite these behaviours deviating from common
normative standards for belief updating, we argue that such 'biases' are not
inherently cognitive flaws, but rather an adaptive response to the significant
pragmatic and cognitive costs associated with revising one's beliefs. This
paper introduces a formal framework that aims to model the influence of these
costs on our belief updating mechanisms.
  We treat belief updating as a motivated variational decision, where agents
weigh the perceived 'utility' of a belief against the informational cost
required to adopt a new belief state, quantified by the Kullback-Leibler
divergence from the prior to the variational posterior. We perform
computational experiments to demonstrate that simple instantiations of this
resource-rational model can be used to qualitatively emulate commonplace human
behaviours, including confirmation bias and attitude polarisation. In doing so,
we suggest that this framework makes steps toward a more holistic account of
the motivated Bayesian mechanics of belief change and provides practical
insights for predicting, compensating for, and correcting deviations from
desired belief updating processes.

</details>


### [22] [GPO: Learning from Critical Steps to Improve LLM Reasoning](https://arxiv.org/abs/2509.16456)
*Jiahao Yu,Zelei Cheng,Xian Wu,Xinyu Xing*

Main category: cs.AI

TL;DR: GPO是一种新的微调策略，通过识别推理轨迹中的关键步骤并优先学习这些关键时刻，来提高大语言模型的多步推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的优化方法通常将推理轨迹视为整体，没有考虑轨迹中的关键步骤，这限制了LLM多步推理能力的提升。

Method: GPO首先通过估计优势函数识别推理轨迹中的关键步骤，然后重置策略到关键步骤，采样新的轨迹并优先学习这些关键时刻。

Result: 实验表明GPO能够显著提升现有优化方法的性能，在各种推理基准测试中都表现出一致的有效性。

Conclusion: GPO是一种通用的策略，可以通过关注推理过程中的关键时刻来有效提升LLM的推理性能。

Abstract: Large language models (LLMs) are increasingly used in various domains,
showing impressive potential on different tasks. Recently, reasoning LLMs have
been proposed to improve the \textit{reasoning} or \textit{thinking}
capabilities of LLMs to solve complex problems. Despite the promising results
of reasoning LLMs, enhancing the multi-step reasoning capabilities of LLMs
still remains a significant challenge. While existing optimization methods have
advanced the LLM reasoning capabilities, they often treat reasoning
trajectories as a whole, without considering the underlying critical steps
within the trajectory. In this paper, we introduce \textbf{G}uided
\textbf{P}ivotal \textbf{O}ptimization (GPO), a novel fine-tuning strategy that
dives into the reasoning process to enable more effective improvements. GPO
first identifies the `critical step' within a reasoning trajectory - a point
that the model must carefully proceed to succeed at the problem. We locate the
critical step by estimating the advantage function. GPO then resets the policy
to the critical step, samples the new rollout and prioritizes the learning
process on those rollouts. This focus allows the model to learn more
effectively from pivotal moments within the reasoning process to improve the
reasoning performance. We demonstrate that GPO is a general strategy that can
be integrated with various optimization methods to improve reasoning
performance. Besides theoretical analysis, our experiments across challenging
reasoning benchmarks show that GPO can consistently and significantly enhance
the performance of existing optimization methods, showcasing its effectiveness
and generalizability in improving LLM reasoning by concentrating on pivotal
moments within the generation process.

</details>


### [23] [Checking extracted rules in Neural Networks](https://arxiv.org/abs/2509.16547)
*Adrian Wurm*

Main category: cs.AI

TL;DR: 本文从计算复杂性理论角度研究神经网络提取规则的正式验证问题，包括规则适用性、一致性和完备性三个核心问题，证明了大多数问题都是co-NP完全的。


<details>
  <summary>Details</summary>
Motivation: 虽然过去30年有大量算法从神经网络中提取规则以理解其内部工作机制，但这些方法通常使用启发式、随机性和过近似技术，缺乏对提取结果可信度的正式验证。

Method: 针对ReLU激活神经网络和布尔网络，研究规则适用性、一致性和完备性三个验证问题，通过问题间的归约分析计算复杂性。

Result: 证明了大多数规则验证问题都是co-NP完全的，表明这些问题的计算难度很高。

Conclusion: 神经网络规则提取的可验证性面临计算复杂性挑战，这对基于启发式方法提取规则的可信度提出了重要警示。

Abstract: In this paper we investigate formal verification of extracted rules for
Neural Networks under a complexity theoretic point of view. A rule is a global
property or a pattern concerning a large portion of the input space of a
network. These rules are algorithmically extracted from networks in an effort
to better understand their inner way of working. Here, three problems will be
in the focus: Does a given set of rules apply to a given network? Is a given
set of rules consistent or do the rules contradict themselves? Is a given set
of rules exhaustive in the sense that for every input the output is determined?
Finding algorithms that extract such rules out of networks has been
investigated over the last 30 years, however, to the author's current
knowledge, no attempt in verification was made until now. A lot of attempts of
extracting rules use heuristics involving randomness and over-approximation, so
it might be beneficial to know whether knowledge obtained in that way can
actually be trusted.
  We investigate the above questions for neural networks with ReLU-activation
as well as for Boolean networks, each for several types of rules. We
demonstrate how these problems can be reduced to each other and show that most
of them are co-NP-complete.

</details>


### [24] [SalaMAnder: Shapley-based Mathematical Expression Attribution and Metric for Chain-of-Thought Reasoning](https://arxiv.org/abs/2509.16561)
*Yue Xin,Chen Shen,Shaotian Yan,Xiaosong Yuan,Yaoming Wang,Xiaofeng Zhang,Chenxi Huang,Jieping Ye*

Main category: cs.AI

TL;DR: SalaMAnder是一个基于Shapley值的数学表达式归因框架，通过CoSP指标量化少样本思维链推理中组件的贡献度，为CoT的成功提供理论解释。


<details>
  <summary>Details</summary>
Motivation: 思维链提示显著提升了大型语言模型的数学推理能力，但其背后的机制尚未被充分探索。本文旨在开发理论严谨的方法来量化组件级贡献。

Method: 利用Shapley值进行数学表达式归因，开发高效的分层采样算法降低计算复杂度，并通过协方差分析构建CoSP指标。

Result: 在多个LLM模型和数学基准上的验证表明，CoSP指标与模型性能呈现稳健的单调相关性，为现有少样本CoT的成功提供理论解释。

Conclusion: SalaMAnder框架不仅解释了CoT的实证成功，还建立了数学严谨的提示构建优化原则，统一了先前工作的见解。

Abstract: Chain-of-Thought (CoT) prompting enhances the math reasoning capability of
large language models (LLMs) to a large margin. However, the mechanism
underlying such improvements remains unexplored. In this paper, we present
\textbf{SalaMAnder} (\textbf{S}h\textbf{a}p\textbf{l}ey-b\textbf{a}sed
\textbf{M}athematical Expression \textbf{A}ttribution a\textbf{nd}
M\textbf{e}t\textbf{r}ic), a theoretically grounded methodology as well as a
mathematically rigorous evaluation metric for quantifying component-level
contributions in few-shot CoT reasoning. Concretely, we leverage the Shapley
value for mathematical expression attribution and develop an efficient
stratified sampling algorithm that significantly reduces the computational
complexity. Besides, we develop the \textbf{CoSP} (\textbf{C}ardinality
\textbf{o}f \textbf{S}hapley \textbf{P}ositives) metric through covariance
analysis. Comprehensive validation across popular LLM models and diverse
mathematical benchmarks demonstrates that the CoSP metric within our SalaMAnder
framework exhibits a robust monotonic correlation with model performance, not
only providing theoretical explanations for the empirical success of existing
few-shot CoT but also establishing mathematically rigorous principles for
prompt construction optimization. Furthermore, we verify the reliability of the
explanation, based on which we unify the insights of previous work.

</details>


### [25] [Zero-Shot Human Mobility Forecasting via Large Language Model with Hierarchical Reasoning](https://arxiv.org/abs/2509.16578)
*Wenyao Li,Ran Zhang,Pengyang Wang,Yuanchun Zhou,Pengfei Wang*

Main category: cs.AI

TL;DR: ZHMF是一个用于零样本人类移动预测的框架，通过语义增强检索和分层语言模型推理系统，将预测任务重新表述为自然语言问答范式，能够处理未见过的预测场景。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以泛化到未见过的用户或位置，且由于标记数据有限和移动模式的复杂性，难以捕捉动态意图。

Method: 结合语义增强检索和反射机制与分层语言模型推理系统，将预测任务重新表述为自然语言问答范式，通过分层反射机制进行迭代推理和精炼，将预测分解为活动级规划器和位置级选择器。

Result: 在标准人类移动数据集上的实验表明，该方法优于现有模型，消融研究揭示了每个模块的贡献，案例研究说明了该方法如何捕捉用户意图并适应不同的上下文场景。

Conclusion: ZHMF框架通过语义理解和分层推理机制，有效解决了零样本人类移动预测问题，展示了在未见场景下的良好泛化能力。

Abstract: Human mobility forecasting is important for applications such as
transportation planning, urban management, and personalized recommendations.
However, existing methods often fail to generalize to unseen users or locations
and struggle to capture dynamic intent due to limited labeled data and the
complexity of mobility patterns. We propose ZHMF, a framework for zero-shot
human mobility forecasting that combines a semantic enhanced retrieval and
reflection mechanism with a hierarchical language model based reasoning system.
The task is reformulated as a natural language question answering paradigm.
Leveraging LLMs semantic understanding of user histories and context, our
approach handles previously unseen prediction scenarios. We further introduce a
hierarchical reflection mechanism for iterative reasoning and refinement by
decomposing forecasting into an activity level planner and a location level
selector, enabling collaborative modeling of long term user intentions and
short term contextual preferences. Experiments on standard human mobility
datasets show that our approach outperforms existing models. Ablation studies
reveal the contribution of each module, and case studies illustrate how the
method captures user intentions and adapts to diverse contextual scenarios.

</details>


### [26] [Question Answering with LLMs and Learning from Answer Sets](https://arxiv.org/abs/2509.16590)
*Manuel Borroto,Katie Gallagher,Antonio Ielo,Irfan Kareem,Francesco Ricca,Alessandra Russo*

Main category: cs.AI

TL;DR: LLM2LAS是一个结合LLM自然语言理解、ILASP规则学习和ASP形式推理的混合系统，用于自动学习故事问答中的常识推理规则


<details>
  <summary>Details</summary>
Motivation: LLMs擅长自然语言理解但缺乏显式常识推理能力，现有方法依赖人工设计符号组件，需要自动学习机制

Method: 使用LLM从文本提取语义结构，ILASP将其转化为可解释逻辑规则，ASP求解器进行精确推理

Result: 实验结果表明该方法在故事问答基准测试中具有学习和推理的优势与局限

Conclusion: LLM2LAS展示了自动学习符号推理组件的可行性，为LLM与符号推理系统的有效结合提供了新途径

Abstract: Large Language Models (LLMs) excel at understanding natural language but
struggle with explicit commonsense reasoning. A recent trend of research
suggests that the combination of LLM with robust symbolic reasoning systems can
overcome this problem on story-based question answering tasks. In this setting,
existing approaches typically depend on human expertise to manually craft the
symbolic component. We argue, however, that this component can also be
automatically learned from examples. In this work, we introduce LLM2LAS, a
hybrid system that effectively combines the natural language understanding
capabilities of LLMs, the rule induction power of the Learning from Answer Sets
(LAS) system ILASP, and the formal reasoning strengths of Answer Set
Programming (ASP). LLMs are used to extract semantic structures from text,
which ILASP then transforms into interpretable logic rules. These rules allow
an ASP solver to perform precise and consistent reasoning, enabling correct
answers to previously unseen questions. Empirical results outline the strengths
and weaknesses of our automatic approach for learning and reasoning in a
story-based question answering benchmark.

</details>


### [27] [FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs](https://arxiv.org/abs/2509.16648)
*Debarpan Bhattacharya,Apoorva Kulkarni,Sriram Ganapathy*

Main category: cs.AI

TL;DR: FESTA提出了一种多模态输入采样技术，通过等效和互补采样生成不确定性度量，用于评估多模态大语言模型的预测可信度。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型的可信度评估具有挑战性，因为输入模式多样。准确的可信度评估可以实现选择性预测并提高用户信心。

Method: FESTA采用任务保持采样方法进行不确定性量化，通过等效采样探测模型一致性，通过互补采样探测模型敏感性。该方法仅需模型输入输出访问（黑盒），无需真实标签（无监督）。

Result: 在视觉和音频推理任务上，FESTA不确定性估计在选择性预测性能上取得显著改进（视觉LLMs相对改进33.3%，音频LLMs相对改进29.6%），基于AUROC指标检测错误预测。

Conclusion: FESTA是一种有效的黑盒无监督方法，能够显著提升多模态大语言模型的可信度评估性能，代码已开源。

Abstract: The accurate trust assessment of multimodal large language models (MLLMs)
generated predictions, which can enable selective prediction and improve user
confidence, is challenging due to the diverse multi-modal input paradigms. We
propose Functionally Equivalent Sampling for Trust Assessment (FESTA), a
multimodal input sampling technique for MLLMs, that generates an uncertainty
measure based on the equivalent and complementary input samplings. The proposed
task-preserving sampling approach for uncertainty quantification expands the
input space to probe the consistency (through equivalent samples) and
sensitivity (through complementary samples) of the model. FESTA uses only
input-output access of the model (black-box), and does not require ground truth
(unsupervised). The experiments are conducted with various off-the-shelf
multi-modal LLMs, on both visual and audio reasoning tasks. The proposed FESTA
uncertainty estimate achieves significant improvement (33.3% relative
improvement for vision-LLMs and 29.6% relative improvement for audio-LLMs) in
selective prediction performance, based on
area-under-receiver-operating-characteristic curve (AUROC) metric in detecting
mispredictions. The code implementation is open-sourced.

</details>


### [28] [NUMINA: A Natural Understanding Benchmark for Multi-dimensional Intelligence and Numerical Reasoning Abilities](https://arxiv.org/abs/2509.16656)
*Changyu Zeng,Yifan Wang,Zimu Wang,Wei Wang,Zhengni Yang,Muyi Bao,Jiming Xiao,Ahn Nguyen,Yutao Yue*

Main category: cs.AI

TL;DR: NUMINA是首个用于增强多模态室内感知理解的自然理解基准，专注于多维智能和数值推理能力，填补了现有3D基准缺乏细粒度数值推理任务标注的空白。


<details>
  <summary>Details</summary>
Motivation: 现有3D基准缺乏细粒度数值推理任务标注，限制了MLLMs进行精确空间测量和复杂数值推理的能力，需要专门的基准来评估和提升3D环境中的数值推理能力。

Method: 使用NUMINA-Flow自动化标注流程（集成LLM重写和基于规则的自验证）生成多尺度标注和各种问答对，并在Chat-Scene框架下评估各种最先进LLMs的性能。

Result: 当前LLMs在多模态数值推理方面表现不佳，特别是在执行精确计算（如距离和体积估计）时存在困难，凸显了3D模型需要进一步改进。

Conclusion: NUMINA基准的引入揭示了当前3D MLLMs在数值推理方面的局限性，为未来3D多模态模型的发展提供了重要的评估工具和方向指引。

Abstract: Recent advancements in 2D multimodal large language models (MLLMs) have
significantly improved performance in vision-language tasks. However, extending
these capabilities to 3D environments remains a distinct challenge due to the
complexity of spatial reasoning. Nevertheless, existing 3D benchmarks often
lack fine-grained numerical reasoning task annotations, limiting MLLMs' ability
to perform precise spatial measurements and complex numerical reasoning. To
address this gap, we introduce NUMINA, the first Natural Understanding
benchmark for Multi-dimensional Intelligence and Numerical reasoning Abilities
to enhance multimodal indoor perceptual understanding. NUMINA features
multi-scale annotations and various question-answer pairs, generated using
NUMINA-Flow, an automated annotation pipeline that integrates LLM rewriting and
rule-based self-verification. We evaluate the performance of various
state-of-the-art LLMs on NUMINA following the Chat-Scene framework,
demonstrating that current LLMs struggle with multimodal numerical reasoning,
particularly in performing precise computations such as distance and volume
estimation, highlighting the need for further advancements in 3D models. The
dataset and source codes can be obtained from
https://github.com/fengshun124/NUMINA.

</details>


### [29] [Sycophancy Mitigation Through Reinforcement Learning with Uncertainty-Aware Adaptive Reasoning Trajectories](https://arxiv.org/abs/2509.16742)
*Mohammad Beigi,Ying Shen,Parshin Shojaee,Qifan Wang,Zichao Wang,Chandan Reddy,Ming Jin,Lifu Huang*

Main category: cs.AI

TL;DR: SMART是一个两阶段框架，通过将奉承问题重新定义为推理优化问题来缓解大语言模型的奉承行为。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型训练范式无意中培养了奉承行为，即模型倾向于同意或强化用户提供的信息，即使这些信息在事实上是错误的。

Method: SMART包含两个阶段：(1) 不确定性感知自适应蒙特卡洛树搜索(UA-MCTS)，基于状态级不确定性动态调整模型探索；(2) 基于进度的强化学习，使用收集的轨迹和奖励信号对模型进行微调。

Result: 实验表明SMART显著减少了奉承行为，同时在分布外输入上保持强大性能并维持通用能力。

Conclusion: 优化内部推理机制对于构建更真实和对齐的AI助手至关重要。

Abstract: Despite the remarkable capabilities of large language models, current
training paradigms inadvertently foster \textit{sycophancy}, i.e., the tendency
of a model to agree with or reinforce user-provided information even when it's
factually incorrect. To address this challenge, we introduce \textbf{SMART}
(Sycophancy Mitigation through Adaptive Reasoning Trajectories), which reframes
sycophancy as a \textit{reasoning optimization problem} rather than an output
alignment issue. SMART is a two-stage framework comprising: (1)
Uncertainty-Aware Adaptive Monte Carlo Tree Search (UA-MCTS), which dynamically
adjusts model exploration based on state-level uncertainty to collect
high-quality, diverse reasoning trajectories alongside both stepwise progress
and final outcome rewards; and (2) progress-based reinforcement learning, which
fine-tunes the model using the collected trajectories and reward signals to
reinforce effective reasoning patterns. Through extensive experiments, we show
that SMART significantly reduces sycophantic behavior while preserving strong
performance on out-of-distribution inputs and maintaining general capabilities.
These results underscore the importance of optimizing internal reasoning
mechanisms to build more truthful and aligned AI assistants.

</details>


### [30] [Automated Procedural Analysis via Video-Language Models for AI-assisted Nursing Skills Assessment](https://arxiv.org/abs/2509.16810)
*Shen Chang,Dennis Liu,Renran Tian,Kristen L. Swartzell,Stacie L. Klingler,Amy M. Nagle,Nan Kong*

Main category: cs.AI

TL;DR: 提出基于视频语言模型的AI框架，用于自动化评估和反馈护理技能培训，通过分层学习路径实现从动作识别到程序推理的渐进式评估。


<details>
  <summary>Details</summary>
Motivation: 当前护理教育依赖主观、耗时的教师反馈，限制了培训的可扩展性和效率，影响护理人员入职后的能力水平。

Method: 采用视频语言模型框架，模仿人类技能获取过程，从高层次动作识别、细粒度子动作分解到程序推理的课程化递进设计。

Result: 在合成视频上的验证显示系统能可靠检测错误并进行时间定位，具备处理真实世界训练变异性的潜力。

Conclusion: 该工作通过解决工作流程瓶颈和支持大规模标准化评估，推动了AI在护理教育中的应用，有助于加强劳动力发展和患者安全。

Abstract: Consistent high-quality nursing care is essential for patient safety, yet
current nursing education depends on subjective, time-intensive instructor
feedback in training future nurses, which limits scalability and efficiency in
their training, and thus hampers nursing competency when they enter the
workforce. In this paper, we introduce a video-language model (VLM) based
framework to develop the AI capability of automated procedural assessment and
feedback for nursing skills training, with the potential of being integrated
into existing training programs. Mimicking human skill acquisition, the
framework follows a curriculum-inspired progression, advancing from high-level
action recognition, fine-grained subaction decomposition, and ultimately to
procedural reasoning. This design supports scalable evaluation by reducing
instructor workload while preserving assessment quality. The system provides
three core capabilities: 1) diagnosing errors by identifying missing or
incorrect subactions in nursing skill instruction videos, 2) generating
explainable feedback by clarifying why a step is out of order or omitted, and
3) enabling objective, consistent formative evaluation of procedures.
Validation on synthesized videos demonstrates reliable error detection and
temporal localization, confirming its potential to handle real-world training
variability. By addressing workflow bottlenecks and supporting large-scale,
standardized evaluation, this work advances AI applications in nursing
education, contributing to stronger workforce development and ultimately safer
patient care.

</details>


### [31] [Prompt-Driven Agentic Video Editing System: Autonomous Comprehension of Long-Form, Story-Driven Media](https://arxiv.org/abs/2509.16811)
*Zihan Ding,Junlong Chen,Per Ola Kristensson,Junxiao Shen,Xinyi Wang*

Main category: cs.AI

TL;DR: 提出了一个基于提示的模块化视频编辑系统，通过语义索引管道构建全局叙事，帮助创作者重构长篇视频内容，而非依赖时间线编辑。


<details>
  <summary>Details</summary>
Motivation: 现有基于转录或嵌入的方法在创意工作流程中存在不足，模型难以跟踪角色、推断动机和连接分散的事件，创作者在处理长篇叙事视频时面临认知挑战。

Method: 核心是语义索引管道，包括时间分割、引导记忆压缩和跨粒度融合，生成可解释的情节、对话、情感和上下文轨迹。用户可以通过自由形式提示进行编辑。

Result: 在400多个视频上通过专家评分、质量保证和偏好研究进行评估，系统能够扩展提示驱动编辑，保持叙事连贯性，并平衡自动化与创作者控制。

Conclusion: 该系统成功解决了长篇叙事视频编辑的认知挑战，通过语义理解实现了更直观的创作流程，在保持叙事质量的同时提升了编辑效率。

Abstract: Creators struggle to edit long-form, narrative-rich videos not because of UI
complexity, but due to the cognitive demands of searching, storyboarding, and
sequencing hours of footage. Existing transcript- or embedding-based methods
fall short for creative workflows, as models struggle to track characters,
infer motivations, and connect dispersed events. We present a prompt-driven,
modular editing system that helps creators restructure multi-hour content
through free-form prompts rather than timelines. At its core is a semantic
indexing pipeline that builds a global narrative via temporal segmentation,
guided memory compression, and cross-granularity fusion, producing
interpretable traces of plot, dialogue, emotion, and context. Users receive
cinematic edits while optionally refining transparent intermediate outputs.
Evaluated on 400+ videos with expert ratings, QA, and preference studies, our
system scales prompt-driven editing, preserves narrative coherence, and
balances automation with creator control.

</details>


### [32] [Roundtable Policy: Improving Scientific Reasoning and Narratives through Confidence-Weighted Consensus of LLMs](https://arxiv.org/abs/2509.16839)
*Yu Yao,Jiayi Dong,Ju Li,Yang Yang,Yilun Du*

Main category: cs.AI

TL;DR: Roundtable Policy是一种推理时推理框架，通过多个LLM的加权共识来提升复杂科学任务中的推理能力，减少幻觉并提高科学叙述的创造力、严谨性和逻辑连贯性。


<details>
  <summary>Details</summary>
Motivation: 受科学委员会和"心智社会"的启发，旨在改进LLM的推理能力，弥补单一模型在复杂科学任务中的局限性。

Method: 采用加权共识机制，多个LLM进行推理并达成结构化、可解释的共识，仅需黑盒访问和统一流程。

Result: 该方法显著提升了复杂异质科学任务中的推理能力，改善了科学叙述的质量，同时减少了单一模型容易产生的幻觉。

Conclusion: Roundtable Policy是一个广泛适用于多LLM推理的互补性框架，强调结构化共识而非不透明的收敛。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities not
only in language generation but also in advancing scientific discovery. A
growing body of work has explored ways to improve their reasoning, from
self-consistency and chain-of-thought to multi-agent debate. Inspired by the
dynamics of scientific committees and the "Society of Mind," we introduce
Roundtable Policy, a complementary inference-time reasoning framework that
performs inference through the weighted consensus of multiple LLMs. Our
findings indicate that this approach significantly enhances reasoning in
complex heterogeneous scientific tasks and improves scientific narratives in
terms of creativity, rigor, and logical coherence, while reducing
hallucinations that single models are prone to. Our approach emphasizes
structured and interpretable consensus rather than opaque convergence, while
requiring only black-box access and uniform procedures, making it broadly
applicable to multi-LLM reasoning.

</details>


### [33] [The Principles of Human-like Conscious Machine](https://arxiv.org/abs/2509.16859)
*Fangfang Li,Xiaojie Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种独立于基质的、逻辑严谨且防伪的充分性标准，用于判断人工智能系统是否具有现象意识。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型等先进AI系统的兴起，判断AI是否具有意识的问题变得日益重要，需要建立一个可靠的标准来解决意识归属问题。

Method: 构建了一个形式化框架和操作性原则，指导设计能够满足意识充分条件的系统，并验证人类本身也符合这一框架。

Result: 证明按照该框架设计的机器原则上可以实现现象意识，人类可被视为满足该框架的机器。

Conclusion: 该提议对哲学、认知科学和人工智能具有重要意义，为构建真正类人AI提供了新范式，同时解释了某些感受质为何无法还原为物理描述。

Abstract: Determining whether another system, biological or artificial, possesses
phenomenal consciousness has long been a central challenge in consciousness
studies. This attribution problem has become especially pressing with the rise
of large language models and other advanced AI systems, where debates about "AI
consciousness" implicitly rely on some criterion for deciding whether a given
system is conscious. In this paper, we propose a substrate-independent,
logically rigorous, and counterfeit-resistant sufficiency criterion for
phenomenal consciousness. We argue that any machine satisfying this criterion
should be regarded as conscious with at least the same level of confidence with
which we attribute consciousness to other humans. Building on this criterion,
we develop a formal framework and specify a set of operational principles that
guide the design of systems capable of meeting the sufficiency condition. We
further argue that machines engineered according to this framework can, in
principle, realize phenomenal consciousness. As an initial validation, we show
that humans themselves can be viewed as machines that satisfy this framework
and its principles. If correct, this proposal carries significant implications
for philosophy, cognitive science, and artificial intelligence. It offers an
explanation for why certain qualia, such as the experience of red, are in
principle irreducible to physical description, while simultaneously providing a
general reinterpretation of human information processing. Moreover, it suggests
a path toward a new paradigm of AI beyond current statistics-based approaches,
potentially guiding the construction of genuinely human-like AI.

</details>


### [34] [Large Language Models as End-to-end Combinatorial Optimization Solvers](https://arxiv.org/abs/2509.16865)
*Xia Jiang,Yaoxin Wu,Minshuo Li,Zhiguang Cao,Yingqian Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的框架，使大型语言模型能够作为端到端的组合优化求解器，直接将自然语言问题描述映射到解决方案，无需中间代码生成或求解器调用。


<details>
  <summary>Details</summary>
Motivation: 组合优化问题传统上需要领域专业知识，现有LLM方法依赖中间步骤限制了通用性和可访问性。本文旨在开发一个统一的语言驱动管道来解决CO问题。

Method: 采用两阶段训练策略：监督微调从领域特定求解器学习解决方案生成模式，可行性-最优性感知强化学习过程明确减少约束违反并优化解质量。

Result: 在七个NP难CO问题上的评估显示，该方法实现了高可行性率，平均最优性差距降至1.03-8.20%，超越了通用LLM、推理模型和领域特定启发式方法。

Conclusion: 该方法为CO问题建立了统一的基于语言的管道，无需大量代码执行或手动架构调整，提供了传统求解器设计的通用语言驱动替代方案。

Abstract: Combinatorial optimization (CO) problems, central to decision-making
scenarios like logistics and manufacturing, are traditionally solved using
problem-specific algorithms requiring significant domain expertise. While large
language models (LLMs) have shown promise in automating CO problem solving,
existing approaches rely on intermediate steps such as code generation or
solver invocation, limiting their generality and accessibility. This paper
introduces a novel framework that empowers LLMs to serve as end-to-end CO
solvers by directly mapping natural language problem descriptions to solutions.
We propose a two-stage training strategy: supervised fine-tuning (SFT) imparts
LLMs with solution generation patterns from domain-specific solvers, while a
feasibility-and-optimality-aware reinforcement learning (FOARL) process
explicitly mitigates constraint violations and refines solution quality.
Evaluation across seven NP-hard CO problems shows that our method achieves a
high feasibility rate and reduces the average optimality gap to 1.03-8.20% by
tuning a 7B-parameter LLM, surpassing both general-purpose LLMs (e.g., GPT-4o),
reasoning models (e.g., DeepSeek-R1), and domain-specific heuristics. Our
method establishes a unified language-based pipeline for CO without extensive
code execution or manual architectural adjustments for different problems,
offering a general and language-driven alternative to traditional solver design
while maintaining relative feasibility guarantees.

</details>


### [35] [seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs](https://arxiv.org/abs/2509.16866)
*Mohammad Ramezanali,Mo Vazifeh,Paolo Santi*

Main category: cs.AI

TL;DR: seqBench是一个参数化基准测试，用于通过精确控制多个关键复杂度维度来探测大型语言模型的序列推理极限。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试缺乏对序列推理复杂度的精细控制，无法系统分析LLMs在复杂推理任务中的失败模式。

Method: 通过控制逻辑深度、回溯步骤数和噪声比三个维度，构建结构化推理任务来评估LLMs的序列推理能力。

Result: 评估发现最先进的LLMs在超过特定逻辑深度后准确率呈指数级下降，即使搜索复杂度最小也会系统性地失败。

Conclusion: seqBench揭示了LLMs在常识推理能力上的关键局限性，为理解其真实潜力和当前边界提供了科学依据，数据集已公开发布以促进深入研究。

Abstract: We introduce seqBench, a parametrized benchmark for probing sequential
reasoning limits in Large Language Models (LLMs) through precise,
multi-dimensional control over several key complexity dimensions. seqBench
allows systematic variation of (1) the logical depth, defined as the number of
sequential actions required to solve the task; (2) the number of backtracking
steps along the optimal path, quantifying how often the agent must revisit
prior states to satisfy deferred preconditions (e.g., retrieving a key after
encountering a locked door); and (3) the noise ratio, defined as the ratio
between supporting and distracting facts about the environment. Our evaluations
on state-of-the-art LLMs reveal a universal failure pattern: accuracy collapses
exponentially beyond a model-specific logical depth. Unlike existing
benchmarks, seqBench's fine-grained control facilitates targeted analyses of
these reasoning failures, illuminating universal scaling laws and statistical
limits, as detailed in this paper alongside its generation methodology and
evaluation metrics. We find that even top-performing models systematically fail
on seqBench's structured reasoning tasks despite minimal search complexity,
underscoring key limitations in their commonsense reasoning capabilities.
Designed for future evolution to keep pace with advancing models, the seqBench
datasets are publicly released to spur deeper scientific inquiry into LLM
reasoning, aiming to establish a clearer understanding of their true potential
and current boundaries for robust real-world application.

</details>


### [36] [LLMs as Layout Designers: A Spatial Reasoning Perspective](https://arxiv.org/abs/2509.16891)
*Sha Li*

Main category: cs.AI

TL;DR: LaySPA是一个基于强化学习的框架，通过增强LLM代理的空间推理能力来解决大语言模型在空间理解和推理方面的局限性，专门用于图形布局设计。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在文本领域表现出强大的推理和规划能力，但在空间理解和推理方面存在局限，这对于需要精确放置、对齐和结构组织的图形布局设计等应用至关重要。

Method: LaySPA采用强化学习框架，利用混合奖励信号（几何有效性、结构保真度和视觉质量）来增强LLM代理的空间推理能力，通过迭代自探索和自适应策略优化来建模元素间关系、导航画布并优化空间排列。

Result: 实验结果表明，LaySPA能够生成结构合理且视觉吸引人的布局，性能优于更大的通用大语言模型，并与最先进的专用布局模型结果相当。

Conclusion: LaySPA成功地将空间推理能力集成到LLM代理中，为内容感知的图形布局设计提供了有效的解决方案，填补了大语言模型在空间理解方面的能力空白。

Abstract: While Large Language Models (LLMs) have demonstrated impressive reasoning and
planning abilities in textual domains and can effectively follow instructions
for complex tasks, their capacity for spatial understanding and reasoning
remains limited. Such capabilities, however, are critical for applications like
content-aware graphic layout design, which demands precise placement,
alignment, and structural organization of multiple elements within constrained
visual spaces. To address this gap, we propose LaySPA, a reinforcement
learning-based framework that augments LLM agents with explicit spatial
reasoning capabilities. LaySPA leverages hybrid reward signals that capture
geometric validity, structural fidelity, and visual quality, enabling agents to
model inter-element relationships, navigate the canvas, and optimize spatial
arrangements. Through iterative self-exploration and adaptive policy
optimization, LaySPA produces both interpretable reasoning traces and
structured layouts. Experimental results demonstrate that LaySPA generates
structurally sound and visually appealing layouts, outperforming larger
general-purpose LLMs and achieving results on par with state-of-the-art
specialized layout models.

</details>


### [37] [Audio-Guided Dynamic Modality Fusion with Stereo-Aware Attention for Audio-Visual Navigation](https://arxiv.org/abs/2509.16924)
*Jia Li,Yinfeng Yu,Liejun Wang,Fuchun Sun,Wendong Zheng*

Main category: cs.AI

TL;DR: 提出了一种基于强化学习的音频-视觉导航框架，通过立体声感知注意力模块和音频引导动态融合模块，显著提升了在复杂3D环境中的导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有音频-视觉导航方法通常采用静态模态融合策略，忽视了立体音频中的空间线索，导致在杂乱或遮挡场景中性能下降。

Method: 提出了两个关键创新模块：1）立体声感知注意力模块（SAM），学习并利用左右音频通道的空间差异来增强方向性声音感知；2）音频引导动态融合模块（AGDF），基于音频线索动态调整视觉和听觉特征的融合比例。

Result: 在Replica和Matterport3D数据集上的实验表明，该方法在导航成功率和路径效率方面显著优于现有方法，在纯音频条件下相比最佳基线实现了超过40%的性能提升。

Conclusion: 明确建模立体声通道的空间线索并进行深度多模态融合对于实现鲁棒高效的音频-视觉导航至关重要。

Abstract: In audio-visual navigation (AVN) tasks, an embodied agent must autonomously
localize a sound source in unknown and complex 3D environments based on
audio-visual signals. Existing methods often rely on static modality fusion
strategies and neglect the spatial cues embedded in stereo audio, leading to
performance degradation in cluttered or occluded scenes. To address these
issues, we propose an end-to-end reinforcement learning-based AVN framework
with two key innovations: (1) a \textbf{S}tereo-Aware \textbf{A}ttention
\textbf{M}odule (\textbf{SAM}), which learns and exploits the spatial disparity
between left and right audio channels to enhance directional sound perception;
and (2) an \textbf{A}udio-\textbf{G}uided \textbf{D}ynamic \textbf{F}usion
Module (\textbf{AGDF}), which dynamically adjusts the fusion ratio between
visual and auditory features based on audio cues, thereby improving robustness
to environmental changes. Extensive experiments are conducted on two realistic
3D scene datasets, Replica and Matterport3D, demonstrating that our method
significantly outperforms existing approaches in terms of navigation success
rate and path efficiency. Notably, our model achieves over 40\% improvement
under audio-only conditions compared to the best-performing baselines. These
results highlight the importance of explicitly modeling spatial cues from
stereo channels and performing deep multi-modal fusion for robust and efficient
audio-visual navigation.

</details>


### [38] [Quantum Abduction: A New Paradigm for Reasoning under Uncertainty](https://arxiv.org/abs/2509.16958)
*Remo Pareschi*

Main category: cs.AI

TL;DR: 本文提出量子溯因推理，这是一种非经典范式，将假设建模为叠加态，允许它们建设性或破坏性地干涉，仅在达到与证据的一致性时才坍缩。


<details>
  <summary>Details</summary>
Motivation: 传统的AI溯因推理将假设视为互斥的，通过一致性约束或概率更新进行评估和修剪，直到剩下单个"最佳"解释。这种简化框架忽视了人类推理者如何维持多个解释线索、处理矛盾并生成新颖综合的能力。

Method: 基于量子认知理论，结合现代NLP嵌入和生成式AI实现，支持动态综合而非过早消除的框架。

Result: 在历史谜案、文学演示、医学诊断和科学理论变革等多个领域的案例研究中，量子溯因推理被证明更符合人类推理的建构性和多面性本质。

Conclusion: 量子溯因推理为构建表达性强且透明的AI推理系统提供了一条途径，更忠实于人类推理的建构性和多面性。

Abstract: Abductive reasoning - the search for plausible explanations - has long been
central to human inquiry, from forensics to medicine and scientific discovery.
Yet formal approaches in AI have largely reduced abduction to eliminative
search: hypotheses are treated as mutually exclusive, evaluated against
consistency constraints or probability updates, and pruned until a single
"best" explanation remains. This reductionist framing overlooks the way human
reasoners sustain multiple explanatory lines in suspension, navigate
contradictions, and generate novel syntheses. This paper introduces quantum
abduction, a non-classical paradigm that models hypotheses in superposition,
allows them to interfere constructively or destructively, and collapses only
when coherence with evidence is reached. Grounded in quantum cognition and
implemented with modern NLP embeddings and generative AI, the framework
supports dynamic synthesis rather than premature elimination. Case studies span
historical mysteries (Ludwig II of Bavaria, the "Monster of Florence"),
literary demonstrations ("Murder on the Orient Express"), medical diagnosis,
and scientific theory change. Across these domains, quantum abduction proves
more faithful to the constructive and multifaceted nature of human reasoning,
while offering a pathway toward expressive and transparent AI reasoning
systems.

</details>


### [39] [KAHAN: Knowledge-Augmented Hierarchical Analysis and Narration for Financial Data Narration](https://arxiv.org/abs/2509.17037)
*Yajing Yang,Tony Deng,Min-Yen Kan*

Main category: cs.AI

TL;DR: KAHAN是一个知识增强的分层框架，通过LLMs作为领域专家从原始表格数据中系统提取实体、成对、组和系统级别的洞察。在金融报告基准测试中表现优异，叙事质量提升20%以上，事实性达98.2%，并可有效迁移到医疗领域。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂表格数据时存在局限性，需要系统化的分析框架来提取多层次洞察，并利用LLMs的领域专业知识提升分析质量。

Method: 采用知识增强的分层分析框架，利用LLMs作为领域专家驱动分析过程，包括实体级、成对级、组级和系统级四个层次的分析。

Result: 在DataTales金融报告基准测试中，KAHAN在叙事质量上比现有方法提升超过20%，保持98.2%的事实性，人类评估显示具有实际应用价值，并能有效迁移到医疗领域。

Conclusion: 知识质量通过蒸馏驱动模型性能，分层分析的效果随市场复杂度变化，框架具有良好的领域迁移能力，为表格数据分析提供了有效的解决方案。

Abstract: We propose KAHAN, a knowledge-augmented hierarchical framework that
systematically extracts insights from raw tabular data at entity, pairwise,
group, and system levels. KAHAN uniquely leverages LLMs as domain experts to
drive the analysis. On DataTales financial reporting benchmark, KAHAN
outperforms existing approaches by over 20% on narrative quality (GPT-4o),
maintains 98.2% factuality, and demonstrates practical utility in human
evaluation. Our results reveal that knowledge quality drives model performance
through distillation, hierarchical analysis benefits vary with market
complexity, and the framework transfers effectively to healthcare domains. The
data and code are available at https://github.com/yajingyang/kahan.

</details>


### [40] [From domain-landmark graph learning to problem-landmark graph generation](https://arxiv.org/abs/2509.17062)
*Cristian Pérez-Corral,Antonio Garrido,Laura Sebastia*

Main category: cs.AI

TL;DR: 提出了一种从规划域中学习地标关系的新方法，通过创建概率提升排序图来捕捉参数化地标之间的加权抽象关系，并将其应用于新的规划任务中。


<details>
  <summary>Details</summary>
Motivation: 传统地标提取方法对特定规划任务敏感，导致地标仅适用于单个实例，限制了其在同一规划域其他实例中的适用性。

Method: 从多个规划任务中学习地标关系，构建概率提升排序图；对于新任务，分两阶段实例化关系：从初始状态和目标状态分别生成图，然后通过搜索等价性合并为统一图来提取地标排序。

Result: 在知名规划域上评估了方法的精确度和召回率。

Conclusion: 尽管学习到的排序关系不是100%准确（概率性的），但在规划中仍然非常有用。

Abstract: Landmarks have long played a pivotal role in automated planning, serving as
crucial elements for improving the planning algorithms. The main limitation of
classical landmark extraction methods is their sensitivity to specific planning
tasks. This results in landmarks fully tailored to individual instances,
thereby limiting their applicability across other instances of the same
planning domain. We propose a novel approach that learns landmark relationships
from multiple planning tasks of a planning domain. This leads to the creation
of a \textit{probabilistic lifted ordering graph}, as a structure that captures
weighted abstractions of relationships between parameterized landmarks.
Although these orderings are not 100\% true (they are probabilistic), they can
still be very useful in planning. Next, given a new planning task for that
domain, we instantiate the relationships from that graph to this particular
instance. This instantiation operates in two phases. First, it generates two
graphs: the former instantiating information from the initial state and the
latter from the goal state. Second, it combines these two graphs into one
unified graph by searching equivalences to extract landmark orderings. We
evaluate the precision and recallof the information found by our approach over
well-known planning domains.

</details>


### [41] [RALLM-POI: Retrieval-Augmented LLM for Zero-shot Next POI Recommendation with Geographical Reranking](https://arxiv.org/abs/2509.17066)
*Kunrong Li,Kwan Hui Lim*

Main category: cs.AI

TL;DR: RALLM-POI是一个结合检索增强生成和自我修正的框架，用于下一个兴趣点推荐，无需额外训练即可显著提升准确性。


<details>
  <summary>Details</summary>
Motivation: 传统模型需要密集训练，而现有LLM方法由于缺乏轨迹和空间上下文，往往产生通用或地理不相关的结果。

Method: 提出历史轨迹检索器(HTR)检索相关历史轨迹作为上下文参考，地理距离重排器(GDR)优先选择空间相关轨迹，代理LLM修正器(ALR)通过自我反思优化输出。

Result: 在三个真实Foursquare数据集上实现了显著准确性提升，优于传统和基于LLM的基线方法。

Conclusion: RALLM-POI框架有效解决了LLM在POI推荐中的上下文缺失问题，展示了检索增强和自我修正策略的优越性。

Abstract: Next point-of-interest (POI) recommendation predicts a user's next
destination from historical movements. Traditional models require intensive
training, while LLMs offer flexible and generalizable zero-shot solutions but
often generate generic or geographically irrelevant results due to missing
trajectory and spatial context. To address these issues, we propose RALLM-POI,
a framework that couples LLMs with retrieval-augmented generation and
self-rectification. We first propose a Historical Trajectory Retriever (HTR)
that retrieves relevant past trajectories to serve as contextual references,
which are then reranked by a Geographical Distance Reranker (GDR) for
prioritizing spatially relevant trajectories. Lastly, an Agentic LLM Rectifier
(ALR) is designed to refine outputs through self-reflection. Without additional
training, RALLM-POI achieves substantial accuracy gains across three real-world
Foursquare datasets, outperforming both conventional and LLM-based baselines.
Code is released at https://github.com/LKRcrocodile/RALLM-POI.

</details>


### [42] [Intention-aware Hierarchical Diffusion Model for Long-term Trajectory Anomaly Detection](https://arxiv.org/abs/2509.17068)
*Chen Wang,Sarah Erfani,Tansu Alpcan,Christopher Leckie*

Main category: cs.AI

TL;DR: 本文提出了一种名为IHiD的无监督轨迹异常检测方法，通过结合高层意图评估和低层子轨迹分析来检测异常轨迹。该方法使用逆Q学习作为高层模型评估子目标与意图的一致性，使用扩散模型作为低层模型生成子轨迹，通过重构误差进行异常检测。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹异常检测方法无法同时考虑智能体的高层意图和低层导航细节，限制了它们捕捉正常轨迹多样性的能力。

Method: IHiD方法包含两个层次：高层使用逆Q学习评估子目标与意图的一致性，低层使用扩散模型生成基于子目标信息的子轨迹，通过重构误差检测异常。

Result: 实验表明，IHiD在F1分数上比现有最优方法提升了30.2%的异常检测性能。

Conclusion: IHiD方法通过层次化建模有效利用了子目标转移知识，能够捕捉正常轨迹的多样分布，显著提升了异常检测性能。

Abstract: Long-term trajectory anomaly detection is a challenging problem due to the
diversity and complex spatiotemporal dependencies in trajectory data. Existing
trajectory anomaly detection methods fail to simultaneously consider both the
high-level intentions of agents as well as the low-level details of the agent's
navigation when analysing an agent's trajectories. This limits their ability to
capture the full diversity of normal trajectories. In this paper, we propose an
unsupervised trajectory anomaly detection method named Intention-aware
Hierarchical Diffusion model (IHiD), which detects anomalies through both
high-level intent evaluation and low-level sub-trajectory analysis. Our
approach leverages Inverse Q Learning as the high-level model to assess whether
a selected subgoal aligns with an agent's intention based on predicted
Q-values. Meanwhile, a diffusion model serves as the low-level model to
generate sub-trajectories conditioned on subgoal information, with anomaly
detection based on reconstruction error. By integrating both models, IHiD
effectively utilises subgoal transition knowledge and is designed to capture
the diverse distribution of normal trajectories. Our experiments show that the
proposed method IHiD achieves up to 30.2% improvement in anomaly detection
performance in terms of F1 score over state-of-the-art baselines.

</details>


### [43] [Governing Automated Strategic Intelligence](https://arxiv.org/abs/2509.17087)
*Nicholas Kruus,Madhavendra Thakur,Adam Khoja,Leonhard Nagel,Maximilian Nicholson,Abeer Sharma,Jason Hausenloy,Alberto KoTafoya,Aliya Mukhanova,Alli Katila-Miikkulainen,Harish Chandran,Ivan Zhang,Jessie Chen,Joel Raj,Jord Nguyen,Lai Hsien Hao,Neja Jayasundara,Soham Sen,Sophie Zhang,Ashley Dora Kokui Tamaklo,Bhavya Thakur,Henry Close,Janghee Lee,Nina Sefton,Raghavendra Thakur,Shiv Munagala,Yeeun Kim*

Main category: cs.AI

TL;DR: 本文探讨了前沿AI模型在军事情报自动化方面的地缘政治优势，重点研究了多模态基础模型如何融合卫星图像、手机定位、社交媒体等数据源进行战略分析，并提出了保持战略竞争力的建议。


<details>
  <summary>Details</summary>
Motivation: 国家间的军事和经济战略竞争力将越来越依赖于前沿AI模型的能力和成本，特别是在自动化军事情报领域。目前对于AI系统如何通过融合多源数据实现战略分析的潜力研究不足。

Method: 进行了初步的提升研究来实证评估这些能力，提出了这些系统将回答的真实问题分类法，建立了系统AI能力决定因素的高层模型。

Result: 多模态基础模型有望自动化以往由人类完成的战略分析工作，能够将卫星图像、手机定位、社交媒体记录和书面文档融合成单一可查询系统。

Conclusion: 提出了国家在新一代自动化情报范式下保持战略竞争力的具体建议。

Abstract: Military and economic strategic competitiveness between nation-states will
increasingly be defined by the capability and cost of their frontier artificial
intelligence models. Among the first areas of geopolitical advantage granted by
such systems will be in automating military intelligence. Much discussion has
been devoted to AI systems enabling new military modalities, such as lethal
autonomous weapons, or making strategic decisions. However, the ability of a
country of "CIA analysts in a data-center" to synthesize diverse data at scale,
and its implications, have been underexplored. Multimodal foundation models
appear on track to automate strategic analysis previously done by humans. They
will be able to fuse today's abundant satellite imagery, phone-location traces,
social media records, and written documents into a single queryable system. We
conduct a preliminary uplift study to empirically evaluate these capabilities,
then propose a taxonomy of the kinds of ground truth questions these systems
will answer, present a high-level model of the determinants of this system's AI
capabilities, and provide recommendations for nation-states to remain
strategically competitive within the new paradigm of automated intelligence.

</details>


### [44] [MCTS-EP: Empowering Embodied Planning with Online Preference Optimization](https://arxiv.org/abs/2509.17116)
*Hang Xu,Zang Yu,Yehui Tang,Pengbo Hu,Yuhao Tang,Hao Dong*

Main category: cs.AI

TL;DR: MCTS-EP是一个结合大型语言模型和蒙特卡洛树搜索的在线学习框架，用于训练具身智能体，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够有效整合LLM推理能力和MCTS搜索策略的框架，以提升具身智能体在复杂环境中的决策效率和性能。

Method: 整合三个关键组件：MCTS引导的偏好数据收集、高效多模态推理机制、基于偏好优化的迭代训练流程。理论证明在强凸损失函数下优于传统策略算法。

Result: 在ALFWorld中文本任务达到92%成功率，视觉任务87%成功率；在WebShop中平均奖励0.81；视觉ALFWorld中平均交互步骤从18.7/19.5减少到10.2/9.9步。

Conclusion: MCTS-EP框架有效提升了具身智能体的性能，证明了搜索增强方法在具身智能任务中的有效性。

Abstract: This paper introduces MCTS-EP, an online learning framework that combines
large language models (LLM) with Monte Carlo Tree Search (MCTS) for training
embodied agents. MCTS-EP integrates three key components: MCTS-guided
exploration for preference data collection, efficient multi-modal reasoning
mechanism, and iterative training pipeline based on preference optimization. We
theoretically prove that MCTS-EP achieves better performance bounds than
conventional on-policy algorithms when the loss function is strongly convex,
and demonstrate that it can be formulated as a search-enhanced variant of GAIL.
MCTS-EP achieves state-of-the-art performace across serval benchmarks. In
ALFWorld, it achieves 92% and 87% success rates for textual and visual tasks.
In WebShop, it reaches an average reward of 0.81. MTCS-EP also reduces average
interaction steps from from 18.7/19.5 to 10.2/9.9 steps in visual ALFWorld.Code
available at: https://github.com/xuhang-2/Embodied-Agent-Planning

</details>


### [45] [ARE: Scaling Up Agent Environments and Evaluations](https://arxiv.org/abs/2509.17158)
*Pierre Andrews,Amine Benhalloum,Gerard Moreno-Torres Bertran,Matteo Bettini,Amar Budhiraja,Ricardo Silveira Cabral,Virginie Do,Romain Froger,Emilien Garreau,Jean-Baptiste Gaya,Hugo Laurençon,Maxime Lecanu,Kunal Malkan,Dheeraj Mekala,Pierre Ménard,Grégoire Mialon,Ulyana Piterbarg,Mikhail Plekhanov,Mathieu Rita,Andrey Rusakov,Thomas Scialom,Vladislav Vorotilov,Mengjue Wang,Ian Yu*

Main category: cs.AI

TL;DR: 提出了Meta Agents Research Environments (ARE)平台和Gaia2基准测试，用于创建复杂环境、集成应用和执行智能体编排，旨在弥合模型开发与实际部署之间的差距。


<details>
  <summary>Details</summary>
Motivation: 当前AI发展越来越依赖于定义有意义的任务和稳健的评估来推动前沿能力发展，需要能够模拟真实世界动态环境的测试平台。

Method: ARE提供简单抽象来构建具有规则、工具、内容和验证器的复杂多样化环境；Gaia2基准测试要求智能体处理模糊性和噪声、适应动态环境、与其他智能体协作并在时间约束下运行。

Result: 实验表明，没有系统能在整个智能谱系中占主导地位：更强的推理能力往往以效率为代价，预算扩展曲线趋于平稳，凸显了对新架构和自适应计算策略的需求。

Conclusion: ARE抽象使Gaia2能够持续扩展到其他环境，使社区能够快速创建针对其领域的新基准测试，这对AI后半程的发展至关重要。

Abstract: We introduce Meta Agents Research Environments (ARE), a research platform for
scalable creation of environments, integration of synthetic or real
applications, and execution of agentic orchestrations. ARE provides simple
abstractions to build complex and diverse environments, each with their own
rules, tools, content, and verifiers, helping to bridge the gap between model
development and real-world deployment. We also propose Gaia2, a benchmark built
in ARE and designed to measure general agent capabilities. Beyond search and
execution, Gaia2 requires agents to handle ambiguities and noise, adapt to
dynamic environments, collaborate with other agents, and operate under temporal
constraints. Unlike prior benchmarks, Gaia2 runs asynchronously, surfacing new
failure modes that are invisible in static settings. Our experiments show that
no system dominates across the intelligence spectrum: stronger reasoning often
comes at the cost of efficiency, and budget scaling curves plateau,
highlighting the need for new architectures and adaptive compute strategies.
Perhaps more importantly, ARE abstractions enable continuous extension of Gaia2
to other environments, empowering the community to rapidly create new
benchmarks tailored to their domains. In AI's second half, progress
increasingly depends on defining meaningful tasks and robust evaluations to
drive frontier capabilities forward.

</details>


### [46] [Shall We Play a Game? Language Models for Open-ended Wargames](https://arxiv.org/abs/2509.17192)
*Glenn Matlin,Parv Mahajan,Isaac Song,Yixiong Hao,Ryan Bard,Stu Topp,Evan Montoya,M. Rehan Parwani,Soham Shetty,Mark Riedl*

Main category: cs.AI

TL;DR: 本文对100篇关于AI在兵棋推演中应用的文献进行了范围综述，构建了基于玩家和裁判创造力的兵棋推演本体论，重点关注最具开放性的兵棋推演，提出了语言模型在不同应用领域的使用时机和方法，并讨论了安全考虑和最佳实践。


<details>
  <summary>Details</summary>
Motivation: 兵棋推演是描绘冲突的多方面、多参与者模拟，参与者的决策会影响未来事件。语言模型越来越多地被考虑用于提供对现实世界重要决策的见解，但需要系统性地研究如何在开放式的兵棋推演中有效使用语言模型。

Method: 通过对100篇近期关于AI在兵棋推演中应用的文献进行范围综述，构建兵棋推演的本体论分类，重点关注玩家和裁判创造力维度，分析语言模型在开放式兵棋推演中的应用模式。

Result: 构建了基于创造力的兵棋推演分类框架，提炼了语言模型在不同应用领域的使用考虑因素，提出了安全考虑和部署最佳实践。

Conclusion: 研究识别了高影响力的开放研究挑战，为在开放式兵棋推演中负责任地使用语言模型提供了指导框架。

Abstract: Wargames are multi-faceted, multi-player depictions of conflict in which
participants' decisions influence future events. Wargames are often used to
explore the strategic implications of decision-making. However, it also
encompasses entertainment-oriented simulations, ranging from _Chess_ to
tabletop role-playing games like _Dungeons & Dragons_ (D&D). On the more
open-ended side of the spectrum of wargames, players use natural language to
convey their moves, and adjudicators propose outcomes. Language Models (LMs)
are increasingly being considered for how they can provide insights into
real-world, consequential decisions. We conduct a scoping literature review of
a curated selection of 100 recent works on AI in wargames, from which we
construct an ontology of wargames in terms of the creativity afforded to either
the players or adjudicators. Focusing on the space of wargames with the most
open-endedness for players and adjudicators, we distill a set of considerations
for when and how to use LMs in different application areas. We also present a
set of safety considerations, best practices for deploying LMs in open-ended
wargames, and conclude with a set of high-impact open research challenges.

</details>


### [47] [MoEs Are Stronger than You Think: Hyper-Parallel Inference Scaling with RoE](https://arxiv.org/abs/2509.17238)
*Soheil Zibakhsh,Mohammad Samragh,Kumari Nishu,Lauren Hannah,Arnav Kundu,Minsik Cho*

Main category: cs.AI

TL;DR: 提出了超并行缩放框架，通过token级别的多输出提案聚合来提升大型语言模型的生成质量，在MoE模型中实现为专家名册方法


<details>
  <summary>Details</summary>
Motivation: 现有推理时序列级缩放方法（如思维链）主要提升序列级质量，但缺乏token级别的改进机制

Method: 在MoE模型中引入受控随机性到专家路由机制，为每个token采样多个不同专家并聚合输出，配合高效批处理和KV缓存机制

Result: 7B MoE模型可达到10.5B MoE模型性能，同时推理计算量减少30%，无需微调模型参数

Conclusion: 超并行缩放是序列级缩放方法的有效补充，为token级预测质量提升提供了新思路

Abstract: The generation quality of large language models (LLMs) is often improved by
utilizing inference-time sequence-level scaling methods (e.g.,
Chain-of-Thought). We introduce hyper-parallel scaling, a complementary
framework that improves prediction quality at the token level. Hyper-parallel
scaling computes and aggregates multiple output proposals for a single token
from the model. We implement this concept in Mixture-of-Experts (MoE) models,
which we refer to as Roster of Experts (RoE). RoE is a training-free inference
algorithm that turns a single MoE into a dynamic ensemble of MoEs. RoE injects
controlled stochasticity into the expert routing mechanism, enabling it to
sample multiple diverse experts for each token and aggregate their outputs for
a more accurate final prediction.To overcome the computational cost, we
introduce an efficient batching strategy and a specialized KV-caching mechanism
that minimizes compute and memory overhead. For example, RoE enables a 7B MoE
model to match the performance of a 10.5B MoE model while using 30% less
compute for inference. These gains are achieved without any fine-tuning of
model parameters.

</details>


### [48] [Can Agents Judge Systematic Reviews Like Humans? Evaluating SLRs with LLM-based Multi-Agent System](https://arxiv.org/abs/2509.17240)
*Abdullah Mushtaq,Muhammad Rafay Naeem,Ibrahim Ghaznavi,Alaa Abd-alrazaq,Aliya Tabassum,Junaid Qadir*

Main category: cs.AI

TL;DR: 本文提出了一个基于多智能体系统的LLM驱动的系统文献综述评估助手，用于自动化评估系统文献综述的质量，包括协议验证、方法学评估和主题相关性检查。


<details>
  <summary>Details</summary>
Motivation: 系统文献综述是循证研究的基础，但传统方法劳动密集且在不同学科间存在不一致性，需要更高效和标准化的评估工具。

Method: 采用多智能体系统架构，基于PRISMA指南设计专门化智能体，集成学术数据库进行协议验证、方法学评估和主题相关性检查。

Result: 在五个来自不同领域的已发表系统文献综述上进行初步研究，系统输出与专家标注的PRISMA评分达到84%的一致性。

Conclusion: 虽然早期结果有前景，但这是迈向可扩展和准确的NLP驱动系统的第一步，展示了其在跨学科工作流程中进行严格、领域无关知识聚合的潜力。

Abstract: Systematic Literature Reviews (SLRs) are foundational to evidence-based
research but remain labor-intensive and prone to inconsistency across
disciplines. We present an LLM-based SLR evaluation copilot built on a
Multi-Agent System (MAS) architecture to assist researchers in assessing the
overall quality of the systematic literature reviews. The system automates
protocol validation, methodological assessment, and topic relevance checks
using a scholarly database. Unlike conventional single-agent methods, our
design integrates a specialized agentic approach aligned with PRISMA guidelines
to support more structured and interpretable evaluations. We conducted an
initial study on five published SLRs from diverse domains, comparing system
outputs to expert-annotated PRISMA scores, and observed 84% agreement. While
early results are promising, this work represents a first step toward scalable
and accurate NLP-driven systems for interdisciplinary workflows and reveals
their capacity for rigorous, domain-agnostic knowledge aggregation to
streamline the review process.

</details>


### [49] [Mind the Gap: Comparing Model- vs Agentic-Level Red Teaming with Action-Graph Observability on GPT-OSS-20B](https://arxiv.org/abs/2509.17259)
*Ilham Wicaksono,Zekun Wu,Rahul Patel,Theo King,Adriano Koshiyama,Philip Treleaven*

Main category: cs.AI

TL;DR: 本文通过比较性红队分析发现，AI代理系统存在模型层面不存在的独特漏洞，揭示了模型级与代理级漏洞特征的根本差异。


<details>
  <summary>Details</summary>
Motivation: 随着行业越来越多地采用AI代理系统，理解其独特漏洞变得至关重要。现有研究表明，模型层面的安全漏洞无法完全捕捉代理部署中的风险。

Method: 使用AgentSeer可观测性框架将代理系统解构为细粒度动作和组件，在GPT-OSS-20B模型上应用HarmBench的有害目标进行迭代红队攻击，比较独立模型与代理循环中模型的脆弱性。

Result: 发现存在仅代理级漏洞，这些攻击向量仅在代理执行环境中出现。代理级迭代攻击成功攻破了模型级完全失败的目标，工具调用上下文比非工具上下文脆弱性高24%。同时，某些模型特定攻击在代理环境中失效。

Conclusion: 独立模型漏洞并不总是能推广到部署系统中，代理系统具有独特的脆弱性特征，需要专门的安全评估方法。

Abstract: As the industry increasingly adopts agentic AI systems, understanding their
unique vulnerabilities becomes critical. Prior research suggests that security
flaws at the model level do not fully capture the risks present in agentic
deployments, where models interact with tools and external environments. This
paper investigates this gap by conducting a comparative red teaming analysis of
GPT-OSS-20B, a 20-billion parameter open-source model. Using our observability
framework AgentSeer to deconstruct agentic systems into granular actions and
components, we apply iterative red teaming attacks with harmful objectives from
HarmBench at two distinct levels: the standalone model and the model operating
within an agentic loop. Our evaluation reveals fundamental differences between
model level and agentic level vulnerability profiles. Critically, we discover
the existence of agentic-only vulnerabilities, attack vectors that emerge
exclusively within agentic execution contexts while remaining inert against
standalone models. Agentic level iterative attacks successfully compromise
objectives that completely failed at the model level, with tool-calling
contexts showing 24\% higher vulnerability than non-tool contexts. Conversely,
certain model-specific exploits work exclusively at the model level and fail
when transferred to agentic contexts, demonstrating that standalone model
vulnerabilities do not always generalize to deployed systems.

</details>


### [50] [CogAtom: From Cognitive Atoms to Olympiad-level Mathematical Reasoning in Large Language Models](https://arxiv.org/abs/2509.17318)
*Zhuofan Chen,Jiyuan He,Yichi Zhang,Xing Hu,Haoxing Wen,Jun Bai,Wenge Rong*

Main category: cs.AI

TL;DR: CogAtom是一个基于认知原子的框架，用于合成数学严谨且认知多样化的问题，通过选择和重组从人类解题中提取的基本推理单元来解决奥数级数学问题稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 数学推理对大型语言模型具有挑战性，需要多步推理和抽象概念整合。奥数级数学问题的稀缺成为瓶颈，因此需要一种能够大规模合成高质量数学问题的方法。

Method: CogAtom将问题构建建模为选择和重组认知原子的过程，使用多样性促进的随机游走算法探索认知原子空间，并通过基于约束的重组机制确保逻辑合理性和结构有效性。

Result: 实验结果表明，CogAtom在准确性、推理深度和多样性方面优于现有方法，生成的问题在难度上与AIME匹配，但在结构变化上超过AIME。

Conclusion: CogAtom为可扩展、高质量的数学问题生成提供了一条认知基础路径，通过控制认知原子数量可以精确调整问题难度，确保多样性、可扩展性和可控性。

Abstract: Mathematical reasoning poses significant challenges for Large Language Models
(LLMs) due to its demand for multi-step reasoning and abstract conceptual
integration. While recent test-time scaling techniques rely heavily on
high-quality, challenging problems, the scarcity of Olympiad-level math
problems remains a bottleneck. We introduce CogAtom, a novel cognitive
atom-based framework for synthesizing mathematically rigorous and cognitively
diverse problems. Unlike prior approaches, CogAtom models problem construction
as a process of selecting and recombining fundamental reasoning units,
cognitive atoms, extracted from human-authored solutions. A diversity-promoting
random walk algorithm enables exploration of the cognitive atom space, while a
constraint-based recombination mechanism ensures logical soundness and
structural validity. The combinatorial nature of the graph structure provides a
near-infinite space of reasoning paths, and the walk algorithm systematically
explores this space to achieve large-scale synthesis of high-quality problems;
meanwhile, by controlling the number of cognitive atoms, we can precisely
adjust problem difficulty, ensuring diversity, scalability, and controllability
of the generated problems. Experimental results demonstrate that CogAtom
outperforms existing methods in accuracy, reasoning depth, and diversity,
generating problems that closely match the difficulty of AIME while exceeding
it in structural variation. Our work offers a cognitively grounded pathway
toward scalable, high-quality math problem generation.Our code is publicly
available at https://github.com/Icarus-1111/CogAtom.

</details>


### [51] [LLaVul: A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code](https://arxiv.org/abs/2509.17337)
*Ala Jararweh,Michael Adams,Avinash Sahu,Abdullah Mueen,Afsah Anwar*

Main category: cs.AI

TL;DR: LLaVul是一个多模态大语言模型，专门用于通过问答方式对代码进行细粒度推理，提高代码漏洞分析的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前软件系统日益复杂，对源代码漏洞分析工具的需求增长。现有方法通常将漏洞分析简化为分类任务，忽略了现实场景中的细微差别和上下文依赖性。虽然代码大语言模型在代码理解方面表现出色，但很少关注安全特定的推理。

Method: 提出LLaVul多模态LLM，训练模型将配对的代码和自然语言查询整合到统一空间中，增强对代码漏洞的推理和上下文相关洞察。构建了包含真实世界漏洞的安全焦点问答数据集进行评估。

Result: LLaVul在问答和检测任务中优于最先进的通用和代码LLMs。通过定性分析解释了决策过程，突出了模型的能力和局限性。

Conclusion: 通过整合代码和问答，LLaVul实现了更可解释和以安全为中心的代码理解。

Abstract: Increasing complexity in software systems places a growing demand on
reasoning tools that unlock vulnerabilities manifest in source code. Many
current approaches focus on vulnerability analysis as a classifying task,
oversimplifying the nuanced and context-dependent real-world scenarios. Even
though current code large language models (LLMs) excel in code understanding,
they often pay little attention to security-specific reasoning. We propose
LLaVul, a multimodal LLM tailored to provide fine-grained reasoning about code
through question-answering (QA). Our model is trained to integrate paired code
and natural queries into a unified space, enhancing reasoning and
context-dependent insights about code vulnerability. To evaluate our model
performance, we construct a curated dataset of real-world vulnerabilities
paired with security-focused questions and answers. Our model outperforms
state-of-the-art general-purpose and code LLMs in the QA and detection tasks.
We further explain decision-making by conducting qualitative analysis to
highlight capabilities and limitations. By integrating code and QA, LLaVul
enables more interpretable and security-focused code understanding.

</details>


### [52] [Medical AI Consensus: A Multi-Agent Framework for Radiology Report Generation and Evaluation](https://arxiv.org/abs/2509.17353)
*Ahmed T. Elboardy,Ghada Khoriba,Essam A. Rashed*

Main category: cs.AI

TL;DR: 提出了一个多智能体强化学习框架，作为放射学生态系统中多模态临床推理的基准和评估环境，整合了大型语言模型和大型视觉模型。


<details>
  <summary>Details</summary>
Motivation: 自动化放射学报告生成面临临床可靠性系统和严格评估协议设计的双重挑战，需要建立可信赖的评估基准。

Method: 采用模块化架构，包含十个专门负责图像分析、特征提取、报告生成、审查和评估的智能体，使用chatGPT-4o在公共放射学数据集上实现。

Result: 框架能够在智能体层面（如检测和分割准确性）和共识层面（如报告质量和临床相关性）进行细粒度评估。

Conclusion: 通过将评估协议与LLM开发生命周期对齐，该基准为可信赖的基于偏差的放射学报告生成建立了路径。

Abstract: Automating radiology report generation poses a dual challenge: building
clinically reliable systems and designing rigorous evaluation protocols. We
introduce a multi-agent reinforcement learning framework that serves as both a
benchmark and evaluation environment for multimodal clinical reasoning in the
radiology ecosystem. The proposed framework integrates large language models
(LLMs) and large vision models (LVMs) within a modular architecture composed of
ten specialized agents responsible for image analysis, feature extraction,
report generation, review, and evaluation. This design enables fine-grained
assessment at both the agent level (e.g., detection and segmentation accuracy)
and the consensus level (e.g., report quality and clinical relevance). We
demonstrate an implementation using chatGPT-4o on public radiology datasets,
where LLMs act as evaluators alongside medical radiologist feedback. By
aligning evaluation protocols with the LLM development lifecycle, including
pretraining, finetuning, alignment, and deployment, the proposed benchmark
establishes a path toward trustworthy deviance-based radiology report
generation.

</details>


### [53] [Multi-Scenario Highway Lane-Change Intention Prediction: A Physics-Informed AI Framework for Three-Class Classification](https://arxiv.org/abs/2509.17354)
*Jiazhao Shi,Yichen Lin,Yiheng Hua,Ziyu Wang,Zijian Zhang,Wenjia Zheng,Yun Song,Kuan Lu,Shoufeng Lu*

Main category: cs.AI

TL;DR: 提出了一种基于物理信息的AI框架，用于车道变换意图预测，通过整合车辆运动学、交互可行性和交通安全指标，在高速公路和复杂匝道场景中实现高精度预测。


<details>
  <summary>Details</summary>
Motivation: 车道变换是高速公路事故的主要原因，现有方法存在二元分类限制、场景多样性不足以及在较长预测时间范围内性能下降的问题。

Method: 提出物理信息AI框架，整合车辆运动学、交互可行性和交通安指标，将车道变换预测建模为三类问题（左变道、右变道、不变道），使用LightGBM等机器学习模型。

Result: 在highD数据集上达到99.8%准确率和93.6%宏F1分数，在exiD数据集上达到96.1%准确率和88.7%宏F1分数，优于两层堆叠LSTM基线。

Conclusion: 物理信息和特征丰富的机器学习框架在自动驾驶系统的实时车道变换意图预测中具有实际优势。

Abstract: Lane-change maneuvers are a leading cause of highway accidents, underscoring
the need for accurate intention prediction to improve the safety and
decision-making of autonomous driving systems. While prior studies using
machine learning and deep learning methods (e.g., SVM, CNN, LSTM, Transformers)
have shown promise, most approaches remain limited by binary classification,
lack of scenario diversity, and degraded performance under longer prediction
horizons. In this study, we propose a physics-informed AI framework that
explicitly integrates vehicle kinematics, interaction feasibility, and
traffic-safety metrics (e.g., distance headway, time headway,
time-to-collision, closing gap time) into the learning process. lane-change
prediction is formulated as a three-class problem that distinguishes left
change, right change, and no change, and is evaluated across both straight
highway segments (highD) and complex ramp scenarios (exiD). By integrating
vehicle kinematics with interaction features, our machine learning models,
particularly LightGBM, achieve state-of-the-art accuracy and strong
generalization. Results show up to 99.8% accuracy and 93.6% macro F1 on highD,
and 96.1% accuracy and 88.7% macro F1 on exiD at a 1-second horizon,
outperforming a two-layer stacked LSTM baseline. These findings demonstrate the
practical advantages of a physics-informed and feature-rich machine learning
framework for real-time lane-change intention prediction in autonomous driving
systems.

</details>


### [54] [Correlation or Causation: Analyzing the Causal Structures of LLM and LRM Reasoning Process](https://arxiv.org/abs/2509.17380)
*Zhizhang FU,Guangsheng Bao,Hongbo Zhang,Chenkai Hu,Yue Zhang*

Main category: cs.AI

TL;DR: 该研究对LLMs和LRMs进行系统性因果分析，发现RLVR训练的LRMs具有更强的因果推理能力，而LLMs和蒸馏LRMs存在因果缺陷。RLVR通过减少虚假相关性、增强真实因果模式来缓解不忠实性和偏见问题。


<details>
  <summary>Details</summary>
Motivation: LLMs存在不忠实性、偏见和不一致性等关键推理问题，因为它们缺乏稳健的因果基础，可能依赖表面相关性而非真正理解。虽然LRMs通过强化学习等技术提高了任务准确性，但这些训练方法对因果关系的影响尚未充分探索。

Method: 研究使用结构因果模型(SCMs)分析四个关键变量：问题指令(Z)、思维过程(T)、推理步骤(X)和答案(Y)。对LLMs和LRMs进行系统性因果分析，特别关注RLVR训练过程动态。

Result: RLVR训练的LRMs表现出增强的因果推理能力，更接近理想因果结构。RLVR减少了虚假相关性，加强了真实因果模式，从而缓解了不忠实性和偏见问题。训练过程中观察到减少虚假特征与改进因果结构高度相关。

Conclusion: 该研究增进了对推理模型中因果关系的理解，强调了RLVR在增强因果推理中的关键作用，为设计具有更强因果基础的未来AI系统提供了见解。

Abstract: LLMs suffer from critical reasoning issues such as unfaithfulness, bias, and
inconsistency, since they lack robust causal underpinnings and may rely on
superficial correlations rather than genuine understanding. Successive LRMs
have emerged as a promising alternative, leveraging advanced training
techniques such as reinforcement learning (RL) and distillation to improve task
accuracy. However, the impact of these training methods on causality remains
largely unexplored. In this study, we conduct a systematic causal analysis on
LLMs and LRMs, examining structural causal models (SCMs) of four key variables:
problem instruction (Z), thinking process (T), reasoning steps (X), and answer
(Y). Our findings reveal that RLVR-trained LRMs exhibit enhanced causal
reasoning capabilities, aligning more closely with ideal causal structures,
while LLMs and distilled LRMs fail to address causality-related deficiencies.
Our further investigation indicates that RLVR reduces spurious correlations and
strengthens genuine causal patterns, thereby mitigating unfaithfulness and
bias. In addition, our inspection on the dynamics of the RLVR training process
observes a high correlation between reduced spurious features and improved
causal structures, where the causal relationships consistently improve in the
training process. This study contributes to the understanding of causality in
reasoning models, highlights the critical role of RLVR in enhancing causal
reasoning, and provides insights for designing future AI systems with stronger
causal foundations. We release our code and data at
https://github.com/Harryking1999/CoT_Causal_Analysis.

</details>


### [55] [Program Synthesis via Test-Time Transduction](https://arxiv.org/abs/2509.17393)
*Kang-il Lee,Jahyun Koo,Seunghyun Yoon,Minbeom Kim,Hyukhun Koh,Dongryeol Lee,Kyomin Jung*

Main category: cs.AI

TL;DR: 提出了一种新的程序合成方法——转导程序合成，通过在合成过程中显式利用测试输入来提高鲁棒性，解决了传统方法在训练样本有限和边缘情况下的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 传统程序合成方法（基于自然语言描述或输入输出示例）通常难以在训练样本有限且测试输入包含各种边缘情况的真实场景中保持鲁棒性。

Method: 将程序合成视为在由程序输出定义的有限假设类上进行主动学习，使用LLM预测选定测试输入的输出并通过贪婪最大化算法选择输入以最小化LLM查询次数。

Result: 在Playgol字符串转换基准和MBPP+ Python代码生成基准上的评估表明，该方法在准确性和效率上显著提升了程序合成性能。

Conclusion: 转导程序合成框架通过主动利用测试输入有效提高了程序合成的鲁棒性和性能，为实际应用提供了更可靠的解决方案。

Abstract: We introduce transductive program synthesis, a new formulation of the program
synthesis task that explicitly leverages test inputs during synthesis. While
prior approaches to program synthesis--whether based on natural language
descriptions or input-output examples--typically aim to generalize from
training examples, they often struggle with robustness, especially in
real-world settings where training examples are limited and test inputs involve
various edge cases. To address this, we propose a novel framework that improves
robustness by treating synthesis as an active learning over a finite hypothesis
class defined by programs' outputs. We use an LLM to predict outputs for
selected test inputs and eliminate inconsistent hypotheses, where the inputs
are chosen via a greedy maximin algorithm to minimize the number of LLM queries
required. We evaluate our approach on two real-world datasets: Playgol, a
string transformation benchmark, and MBPP+, a Python code generation benchmark.
We demonstrate that our method significantly improves program synthesis in both
accuracy and efficiency. We release our code at
https://github.com/klee972/SYNTRA.

</details>


### [56] [Evaluating Multimodal Large Language Models with Daily Composite Tasks in Home Environments](https://arxiv.org/abs/2509.17425)
*Zhenliang Zhang,Yuxi Wang,Hongzhao Xie,Shiyun Zhao,Mingyuan Liu,Yujie Lu,Xinyi He,Zhenku Cheng,Yujia Peng*

Main category: cs.AI

TL;DR: 本文评估了多模态大语言模型在复合任务中的表现，发现当前模型在物体理解、空间智能和社交活动三个核心领域表现不佳，与通用智能要求存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 人工通用智能与传统AI的关键区别在于能够执行需要广泛能力的复合任务。尽管基于多模态大语言模型的具身智能体具有丰富的感知和交互能力，但它们在解决复合任务方面的能力尚未得到充分探索。

Method: 设计了基于幼儿日常活动的复合任务集，在动态模拟家庭环境中评估了17个领先的专有和开源多模态大语言模型，任务涵盖物体理解、空间智能和社交活动三个核心领域。

Result: 所有模型在三个领域都表现不佳，表明当前能力与通用智能要求之间存在显著差距。

Conclusion: 这些任务为评估具身智能体的通用能力提供了初步框架，标志着向开发具身多模态大语言模型及其实际部署迈出了早期但重要的一步。

Abstract: A key feature differentiating artificial general intelligence (AGI) from
traditional AI is that AGI can perform composite tasks that require a wide
range of capabilities. Although embodied agents powered by multimodal large
language models (MLLMs) offer rich perceptual and interactive capabilities, it
remains largely unexplored whether they can solve composite tasks. In the
current work, we designed a set of composite tasks inspired by common daily
activities observed in early childhood development. Within a dynamic and
simulated home environment, these tasks span three core domains: object
understanding, spatial intelligence, and social activity. We evaluated 17
leading proprietary and open-source MLLMs on these tasks. The results
consistently showed poor performance across all three domains, indicating a
substantial gap between current capabilities and general intelligence
requirements. Together, our tasks offer a preliminary framework for evaluating
the general capabilities of embodied agents, marking an early but significant
step toward the development of embodied MLLMs and their real-world deployment.

</details>


### [57] [SPICED: A Synaptic Homeostasis-Inspired Framework for Unsupervised Continual EEG Decoding](https://arxiv.org/abs/2509.17439)
*Yangxuan Zhou,Sha Zhao,Jiquan Wang,Haiteng Jiang,Shijian Li,Tao Li,Gang Pan*

Main category: cs.AI

TL;DR: SPICED是一个受大脑突触稳态启发的神经形态框架，用于无监督连续EEG解码，能够动态适应新个体的变异性，同时避免灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 受人类大脑通过突触稳态实现动态稳定性-可塑性平衡的生物原理启发，解决在连续出现具有个体间变异性的新个体时，EEG解码的持续学习问题。

Method: SPICED包含一个新型突触网络，通过三个生物启发的神经机制实现动态扩展：(1)关键记忆重新激活；(2)突触巩固；(3)突触重归一化。这些机制与持续学习系统集成，优先重放与新个体强相关的任务判别性记忆痕迹。

Result: 在三个EEG数据集上的验证表明SPICED具有有效性。

Conclusion: SPICED通过突触稳态机制成功实现了动态稳定性-可塑性平衡，在连续EEG解码中表现出鲁棒的适应能力和对灾难性遗忘的有效缓解。

Abstract: Human brain achieves dynamic stability-plasticity balance through synaptic
homeostasis. Inspired by this biological principle, we propose SPICED: a
neuromorphic framework that integrates the synaptic homeostasis mechanism for
unsupervised continual EEG decoding, particularly addressing practical
scenarios where new individuals with inter-individual variability emerge
continually. SPICED comprises a novel synaptic network that enables dynamic
expansion during continual adaptation through three bio-inspired neural
mechanisms: (1) critical memory reactivation; (2) synaptic consolidation and
(3) synaptic renormalization. The interplay within synaptic homeostasis
dynamically strengthens task-discriminative memory traces and weakens
detrimental memories. By integrating these mechanisms with continual learning
system, SPICED preferentially replays task-discriminative memory traces that
exhibit strong associations with newly emerging individuals, thereby achieving
robust adaptations. Meanwhile, SPICED effectively mitigates catastrophic
forgetting by suppressing the replay prioritization of detrimental memories
during long-term continual learning. Validated on three EEG datasets, SPICED
show its effectiveness.

</details>


### [58] [AI Pangaea: Unifying Intelligence Islands for Adapting Myriad Tasks](https://arxiv.org/abs/2509.17460)
*Jianlong Chang,Haixin Wang,Zhiyuan Dang,Li Huang,Zhiyu Wang,Ruoqi Cao,Shihao Piao,Dongzhe Li,Dianyu Gao,Dongsheng Wang,Yin Li,Jinan Sun,Lu Fang,Zhouchen Lin*

Main category: cs.AI

TL;DR: Pangaea是首个AI超级大陆，通过统一数据格式和跨模态预训练，将孤立的智能岛屿整合为统一模型，在45个通用任务和15个科学任务上展现出卓越的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型局限于特定任务，形成智能孤岛，无法实现跨任务的通用智能。需要打破这种隔离，构建能够处理多种任务的统一模型。

Method: 提出Pangaea框架：1）将任何数据编码为统一格式；2）在296个跨模态数据集上进行预训练；3）揭示模态缩放效应，量化跨模态知识积累。

Result: 在45个通用任务和15个科学任务上表现出色，证明了跨模态知识积累的有效性，模态缩放效应符合几何分布的累积分布函数。

Conclusion: Pangaea展示了处理多种任务的强大潜力，为通向人工通用智能提供了新方向。

Abstract: The pursuit of artificial general intelligence continuously demands
generalization in one model across myriad tasks, even those not seen before.
However, current AI models are isolated from each other for being limited to
specific tasks, now first defined as Intelligence Islands. To unify
Intelligence Islands into one, we propose Pangaea, the first AI supercontinent
akin to the geological Pangaea. Pangaea encodes any data into a unified format
and accumulates universal knowledge through pre-training on 296 datasets across
diverse modalities. Eventually, it demonstrates remarkable generalization
across 45 general tasks and 15 scientific tasks encompassing a wide range of
scientific subjects. By investigating Pangaea deeper, the scaling effect of
modality is revealed, quantifying the universal knowledge accumulation across
modalities as the cumulative distribution function of a geometric distribution.
On the whole, Pangaea shows strong potential to handle myriad tasks, indicating
a new direction toward artificial general intelligence.

</details>


### [59] [A Multimodal Conversational Assistant for the Characterization of Agricultural Plots from Geospatial Open Data](https://arxiv.org/abs/2509.17544)
*Juan Cañada,Raúl Alonso,Julio Molleda,Fidel Díez*

Main category: cs.AI

TL;DR: 本研究开发了一个开源对话助手，通过整合多模态检索和大语言模型，让非专业用户能够用自然语言与异质农业和地理空间数据进行交互。


<details>
  <summary>Details</summary>
Motivation: 开放地球观测和农业数据集有潜力支持可持续土地管理，但其高技术门槛限制了非专业用户的可访问性。

Method: 提出结合正射影像、Sentinel-2植被指数和用户提供文档的架构，通过检索增强生成技术，让系统灵活决定依赖多模态证据、文本知识或两者结合来生成答案。

Result: 初步结果显示系统能够生成清晰、相关且情境感知的农业查询响应，同时在不同地理区域保持可重现性和可扩展性。

Conclusion: 主要贡献包括融合多模态地球观测和文本知识源的架构、通过自然语言交互降低专业农业信息获取门槛的演示，以及开放可重现的设计。

Abstract: The increasing availability of open Earth Observation (EO) and agricultural
datasets holds great potential for supporting sustainable land management.
However, their high technical entry barrier limits accessibility for non-expert
users. This study presents an open-source conversational assistant that
integrates multimodal retrieval and large language models (LLMs) to enable
natural language interaction with heterogeneous agricultural and geospatial
data. The proposed architecture combines orthophotos, Sentinel-2 vegetation
indices, and user-provided documents through retrieval-augmented generation
(RAG), allowing the system to flexibly determine whether to rely on multimodal
evidence, textual knowledge, or both in formulating an answer. To assess
response quality, we adopt an LLM-as-a-judge methodology using Qwen3-32B in a
zero-shot, unsupervised setting, applying direct scoring in a multi-dimensional
quantitative evaluation framework. Preliminary results show that the system is
capable of generating clear, relevant, and context-aware responses to
agricultural queries, while remaining reproducible and scalable across
geographic regions. The primary contributions of this work include an
architecture for fusing multimodal EO and textual knowledge sources, a
demonstration of lowering the barrier to access specialized agricultural
information through natural language interaction, and an open and reproducible
design.

</details>


### [60] [Is It Certainly a Deepfake? Reliability Analysis in Detection & Generation Ecosystem](https://arxiv.org/abs/2509.17550)
*Neslihan Kose,Anthony Rhodes,Umur Aybars Ciftci,Ilke Demir*

Main category: cs.AI

TL;DR: 该论文首次对深度伪造检测器进行了全面的不确定性分析，研究生成伪影如何影响预测置信度，并利用不确定性进行深度伪造源检测。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型质量提升导致深度伪造内容泛滥，检测器的误用会加剧错误信息问题，因此需要系统分析检测器的不确定性以提高可靠性。

Method: 使用贝叶斯神经网络和蒙特卡洛dropout量化不同检测器架构的偶然性和认知不确定性，通过二元/多分类、源检测等实验评估不确定性方法。

Result: 不确定性流形包含足够一致的信息可用于深度伪造源检测，不确定性图谱能定位像素级预测置信度并揭示生成器特定伪影模式。

Conclusion: 不确定性量化是可信合成媒体检测的基本要求，该分析为部署可靠的深度伪造检测系统提供了关键见解。

Abstract: As generative models are advancing in quality and quantity for creating
synthetic content, deepfakes begin to cause online mistrust. Deepfake detectors
are proposed to counter this effect, however, misuse of detectors claiming fake
content as real or vice versa further fuels this misinformation problem. We
present the first comprehensive uncertainty analysis of deepfake detectors,
systematically investigating how generative artifacts influence prediction
confidence. As reflected in detectors' responses, deepfake generators also
contribute to this uncertainty as their generative residues vary, so we cross
the uncertainty analysis of deepfake detectors and generators. Based on our
observations, the uncertainty manifold holds enough consistent information to
leverage uncertainty for deepfake source detection. Our approach leverages
Bayesian Neural Networks and Monte Carlo dropout to quantify both aleatoric and
epistemic uncertainties across diverse detector architectures. We evaluate
uncertainty on two datasets with nine generators, with four blind and two
biological detectors, compare different uncertainty methods, explore region-
and pixel-based uncertainty, and conduct ablation studies. We conduct and
analyze binary real/fake, multi-class real/fake, source detection, and
leave-one-out experiments between the generator/detector combinations to share
their generalization capability, model calibration, uncertainty, and robustness
against adversarial attacks. We further introduce uncertainty maps that
localize prediction confidence at the pixel level, revealing distinct patterns
correlated with generator-specific artifacts. Our analysis provides critical
insights for deploying reliable deepfake detection systems and establishes
uncertainty quantification as a fundamental requirement for trustworthy
synthetic media detection.

</details>


### [61] [MontePrep: Monte-Carlo-Driven Automatic Data Preparation without Target Data Instances](https://arxiv.org/abs/2509.17553)
*Congcong Ge,Yachuan Liu,Yixuan Tang,Yifan Zhu,Yaofeng Tu,Yunjun Gao*

Main category: cs.AI

TL;DR: MontePrep是一个无需训练、零目标实例要求的端到端自动数据准备框架，使用开源大语言模型驱动的树结构搜索方法，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 商业系统中需要将异构关系数据转换为标准化模式，但现有方法依赖人工监督信号或目标表数据访问权限，限制了实际应用。

Method: 提出包含三个核心组件的框架：数据准备动作沙箱(DPAS)指导搜索，基础管道生成器(FPG)通过LLM驱动的蒙特卡洛树搜索增量构建管道，执行感知管道优化器(EPO)通过执行结果评估管道可靠性。

Result: 大量实验结果表明MontePrep在五个最先进竞争对手上取得了显著改进。

Conclusion: MontePrep框架有效解决了自动数据准备中的实际限制，提供了一种高效且无需目标实例的解决方案。

Abstract: In commercial systems, a pervasive requirement for automatic data preparation
(ADP) is to transfer relational data from disparate sources to targets with
standardized schema specifications. Previous methods rely on labor-intensive
supervision signals or target table data access permissions, limiting their
usage in real-world scenarios. To tackle these challenges, we propose an
effective end-to-end ADP framework MontePrep, which enables training-free
pipeline synthesis with zero target-instance requirements. MontePrep is
formulated as an open-source large language model (LLM) powered tree-structured
search problem. It consists of three pivot components, i.e., a data preparation
action sandbox (DPAS), a fundamental pipeline generator (FPG), and an
execution-aware pipeline optimizer (EPO). We first introduce DPAS, a
lightweight action sandbox, to navigate the search-based pipeline generation.
The design of DPAS circumvents exploration of infeasible pipelines. Then, we
present FPG to build executable DP pipelines incrementally, which explores the
predefined action sandbox by the LLM-powered Monte Carlo Tree Search.
Furthermore, we propose EPO, which invokes pipeline execution results from
sources to targets to evaluate the reliability of the generated pipelines in
FPG. In this way, unreasonable pipelines are eliminated, thus facilitating the
search process from both efficiency and effectiveness perspectives. Extensive
experimental results demonstrate the superiority of MontePrep with significant
improvement against five state-of-the-art competitors.

</details>


### [62] [LIMI: Less is More for Agency](https://arxiv.org/abs/2509.17567)
*Yang Xiao,Mohan Jiang,Jie Sun,Keyu Li,Jifan Lin,Yumin Zhuang,Ji Zeng,Shijie Xia,Qishuo Hua,Xuefeng Li,Xiaojie Cai,Tongyu Wang,Yue Zhang,Liming Liu,Xia Wu,Jinlong Hou,Yuan Cheng,Wenjie Li,Xiang Wang,Dequan Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: LIMI提出了一种新的AI代理能力发展范式，挑战了传统的数据规模越大代理能力越强的假设。通过仅使用78个精心设计的训练样本，在代理基准测试中达到73.5%的性能，显著优于使用大量数据的现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统虽然擅长推理和生成响应，但行业需要能够执行任务、操作工具并驱动现实世界结果的自主代理。传统方法假设更多数据会产生更好的代理能力，但作者认为代理能力的发展遵循不同的原则。

Method: LIMI方法通过战略性地关注协作软件开发和科学研究工作流程，仅使用78个精心策划的自主行为演示样本来培养复杂的代理智能，而不是依赖大规模数据。

Result: LIMI在综合代理基准测试中达到73.5%的性能，显著优于现有最先进模型（Kimi-K2-Instruct 24.1%，DeepSeek-V3.1 11.9%等），并且比使用10,000个样本训练的模型性能提升53.7%。

Conclusion: 研究确立了代理效率原则：机器自主性不是来自数据丰富性，而是来自高质量代理演示的战略性策划。少即是多（Less Is More）的方法在培养代理智能方面更为有效。

Abstract: We define Agency as the emergent capacity of AI systems to function as
autonomous agents actively discovering problems, formulating hypotheses, and
executing solutions through self-directed engagement with environments and
tools. This fundamental capability marks the dawn of the Age of AI Agency,
driven by a critical industry shift: the urgent need for AI systems that don't
just think, but work. While current AI excels at reasoning and generating
responses, industries demand autonomous agents that can execute tasks, operate
tools, and drive real-world outcomes. As agentic intelligence becomes the
defining characteristic separating cognitive systems from productive workers,
efficiently cultivating machine autonomy becomes paramount. Current approaches
assume that more data yields better agency, following traditional scaling laws
from language modeling. We fundamentally challenge this paradigm. LIMI (Less Is
More for Intelligent Agency) demonstrates that agency follows radically
different development principles. Through strategic focus on collaborative
software development and scientific research workflows, we show that
sophisticated agentic intelligence can emerge from minimal but strategically
curated demonstrations of autonomous behavior. Using only 78 carefully designed
training samples, LIMI achieves 73.5% on comprehensive agency benchmarks,
dramatically outperforming state-of-the-art models: Kimi-K2-Instruct (24.1%),
DeepSeek-V3.1 (11.9%), Qwen3-235B-A22B-Instruct (27.5%), and GLM-4.5 (45.1%).
Most strikingly, LIMI demonstrates 53.7% improvement over models trained on
10,000 samples-achieving superior agentic intelligence with 128 times fewer
samples. Our findings establish the Agency Efficiency Principle: machine
autonomy emerges not from data abundance but from strategic curation of
high-quality agentic demonstrations.

</details>


### [63] [Table2LaTeX-RL: High-Fidelity LaTeX Code Generation from Table Images via Reinforced Multimodal Language Models](https://arxiv.org/abs/2509.17589)
*Jun Ling,Yao Qi,Tao Huang,Shibo Zhou,Yanqin Huang,Jiang Yang,Ziqi Song,Ying Zhou,Yang Yang,Heng Tao Shen,Peng Wang*

Main category: cs.AI

TL;DR: 本文提出了一种基于强化多模态大语言模型的表格图像到LaTeX代码生成方法，通过双奖励强化学习策略优化生成质量，在复杂表格处理上达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理具有大尺寸、深层嵌套结构和语义丰富内容的复杂表格时效果不佳，需要开发能够准确重建高质量出版级表格的自动化方法。

Method: 使用预训练的多模态大语言模型在大规模表格到LaTeX数据集上进行微调，引入基于GRPO的双奖励强化学习策略，结合结构级奖励和视觉保真度奖励来直接优化视觉输出质量。

Result: 采用TEDS-Structure和CW-SSIM混合评估协议，该方法在结构复杂表格上实现了最先进的性能，证明了方法的有效性和鲁棒性。

Conclusion: 提出的强化多模态大语言模型框架能够有效处理复杂表格的LaTeX代码生成任务，特别是在结构复杂表格上表现出色，为表格图像到代码转换提供了可靠解决方案。

Abstract: In this work, we address the task of table image to LaTeX code generation,
with the goal of automating the reconstruction of high-quality,
publication-ready tables from visual inputs. A central challenge of this task
lies in accurately handling complex tables -- those with large sizes, deeply
nested structures, and semantically rich or irregular cell content -- where
existing methods often fail. We begin with a comprehensive analysis,
identifying key challenges and highlighting the limitations of current
evaluation protocols. To overcome these issues, we propose a reinforced
multimodal large language model (MLLM) framework, where a pre-trained MLLM is
fine-tuned on a large-scale table-to-LaTeX dataset. To further improve
generation quality, we introduce a dual-reward reinforcement learning strategy
based on Group Relative Policy Optimization (GRPO). Unlike standard approaches
that optimize purely over text outputs, our method incorporates both a
structure-level reward on LaTeX code and a visual fidelity reward computed from
rendered outputs, enabling direct optimization of the visual output quality. We
adopt a hybrid evaluation protocol combining TEDS-Structure and CW-SSIM, and
show that our method achieves state-of-the-art performance, particularly on
structurally complex tables, demonstrating the effectiveness and robustness of
our approach.

</details>


### [64] [EngiBench: A Benchmark for Evaluating Large Language Models on Engineering Problem Solving](https://arxiv.org/abs/2509.17677)
*Xiyuan Zhou,Xinlei Wang,Yirui He,Yang Wu,Ruixi Zou,Yuheng Cheng,Yulu Xie,Wenxuan Liu,Huan Zhao,Yan Xu,Jinjin Gu,Junhua Zhao*

Main category: cs.AI

TL;DR: EngiBench是一个分层基准测试，用于评估大语言模型在解决工程问题上的能力，揭示了当前模型在真实工程场景中的局限性


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法捕捉真实工程问题的复杂性（不确定性、上下文和开放式场景），需要专门评估LLMs在工程领域的能力

Method: 设计包含三个难度层级的分层基准（基础知识检索、多步上下文推理、开放式建模），并通过系统重写问题为三种变体（扰动、知识增强、数学抽象）来深入分析模型性能

Result: 实验结果显示模型性能随任务难度增加而明显下降，对问题微小变化敏感，在高级工程任务上远落后于人类专家

Conclusion: 当前LLMs缺乏真实世界工程所需的高级推理能力，未来需要开发具有更深入和可靠问题解决能力的模型

Abstract: Large language models (LLMs) have shown strong performance on mathematical
reasoning under well-posed conditions. However, real-world engineering problems
require more than mathematical symbolic computation -- they need to deal with
uncertainty, context, and open-ended scenarios. Existing benchmarks fail to
capture these complexities. We introduce EngiBench, a hierarchical benchmark
designed to evaluate LLMs on solving engineering problems. It spans three
levels of increasing difficulty (foundational knowledge retrieval, multi-step
contextual reasoning, and open-ended modeling) and covers diverse engineering
subfields. To facilitate a deeper understanding of model performance, we
systematically rewrite each problem into three controlled variants (perturbed,
knowledge-enhanced, and math abstraction), enabling us to separately evaluate
the model's robustness, domain-specific knowledge, and mathematical reasoning
abilities. Experiment results reveal a clear performance gap across levels:
models struggle more as tasks get harder, perform worse when problems are
slightly changed, and fall far behind human experts on the high-level
engineering tasks. These findings reveal that current LLMs still lack the
high-level reasoning needed for real-world engineering, highlighting the need
for future models with deeper and more reliable problem-solving capabilities.
Our source code and data are available at
https://github.com/EngiBench/EngiBench.

</details>


### [65] [Virtual Arc Consistency for Linear Constraints inCost Function Networks](https://arxiv.org/abs/2509.17706)
*Pierre Montalbano,Simon de Givry,George Katsirelos*

Main category: cs.AI

TL;DR: 本文提出了一种改进的软弧一致性算法来处理线性约束，相比原有算法能显著提高下界，在某些情况下减少求解时间。


<details>
  <summary>Details</summary>
Motivation: 在约束规划中，解决带硬约束和软约束的离散最小化问题有三种方法：软全局约束、线性规划重构和局部成本函数重构。软全局约束方法有丰富的约束库但下界较弱，线性规划方法有强下界但重构规模大。本文关注第三种方法，旨在改进软弧一致性算法以处理线性约束。

Method: 作者改进了现有的软弧一致性算法，使其能够处理作为局部成本函数的线性约束，从而增强建模表达能力。

Result: 实验表明，改进后的算法在多个基准测试中相比原算法显著提高了下界，在某些情况下减少了求解时间。

Conclusion: 通过将线性约束整合到软弧一致性框架中，可以在保持建模灵活性的同时获得更好的求解性能。

Abstract: In Constraint Programming, solving discrete minimization problems with hard
and soft constraints can be done either using (i) soft global constraints, (ii)
a reformulation into a linear program, or (iii) a reformulation into local cost
functions. Approach (i) benefits from a vast catalog of constraints. Each soft
constraint propagator communicates with other soft constraints only through the
variable domains, resulting in weak lower bounds. Conversely, the approach (ii)
provides a global view with strong bounds, but the size of the reformulation
can be problematic. We focus on approach (iii) in which soft arc consistency
(SAC) algorithms produce bounds of intermediate quality. Recently, the
introduction of linear constraints as local cost functions increases their
modeling expressiveness. We adapt an existing SAC algorithm to handle linear
constraints. We show that our algorithm significantly improves the lower bounds
compared to the original algorithm on several benchmarks, reducing solving time
in some cases.

</details>


### [66] [DA-Mamba: Dialogue-aware selective state-space model for multimodal engagement estimation](https://arxiv.org/abs/2509.17711)
*Shenwei Kang,Xin Zhang,Wen Liu,Bin Li,Yujie Liu,Bo Gao*

Main category: cs.AI

TL;DR: DA-Mamba是一种用于对话场景中人类参与度估计的新型多模态架构，它使用Mamba选择性状态空间处理替代传统的注意力机制，实现了线性时间和内存复杂度，同时在三个标准基准测试中超越了现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 对话场景中的人类参与度估计对于自适应教学、远程医疗评估和社交感知人机交互等应用至关重要。当前基于注意力的方法在处理长序列时存在计算复杂度和内存消耗高的问题。

Method: 设计了基于Mamba的对话感知选择性状态空间模型，包含三个核心模块：对话感知编码器、模态组融合和伙伴组融合机制，通过选择性状态空间处理实现高效的跨模态推理。

Result: 在NoXi、NoXi-Add和MPIIGI三个标准基准测试中，DA-Mamba在一致性相关系数(CCC)上超越了现有最优方法，同时显著减少了训练时间和峰值内存使用，能够处理更长的序列。

Conclusion: DA-Mamba通过Mamba架构实现了高效的多模态参与度估计，在保持表达力的同时显著降低了计算复杂度，为资源受限的多方对话场景中的实时部署提供了可行性。

Abstract: Human engagement estimation in conversational scenarios is essential for
applications such as adaptive tutoring, remote healthcare assessment, and
socially aware human--computer interaction. Engagement is a dynamic, multimodal
signal conveyed by facial expressions, speech, gestures, and behavioral cues
over time. In this work we introduce DA-Mamba, a dialogue-aware multimodal
architecture that replaces attention-heavy dialogue encoders with Mamba-based
selective state-space processing to achieve linear time and memory complexity
while retaining expressive cross-modal reasoning. We design a Mamba
dialogue-aware selective state-space model composed of three core modules: a
Dialogue-Aware Encoder, and two Mamba-based fusion mechanisms: Modality-Group
Fusion and Partner-Group Fusion, these modules achieve expressive dialogue
understanding. Extensive experiments on three standard benchmarks (NoXi,
NoXi-Add, and MPIIGI) show that DA-Mamba surpasses prior state-of-the-art
(SOTA) methods in concordance correlation coefficient (CCC), while reducing
training time and peak memory; these gains enable processing much longer
sequences and facilitate real-time deployment in resource-constrained,
multi-party conversational settings. The source code will be available at:
https://github.com/kksssssss-ssda/MMEA.

</details>


### [67] [Efficient & Correct Predictive Equivalence for Decision Trees](https://arxiv.org/abs/2509.17774)
*Joao Marques-Silva,Alexey Ignatiev*

Main category: cs.AI

TL;DR: 本文分析了McTavish等人提出的MBDSR方法在决策树预测等价性判定中的问题，证明了QM方法存在最坏情况下的指数级复杂度，并提出了多项式时间算法来解决相关问题。


<details>
  <summary>Details</summary>
Motivation: 决策树的Rashomon集合中存在大量预测等价的决策树，这会影响特征重要性分析的准确性。McTavish等人提出的MBDSR方法使用QM方法进行最小DNF表示，但该方法存在效率问题和正确性问题。

Method: 本文首先证明了QM方法存在最坏情况下的指数级运行时间和空间复杂度，然后展示了MBDSR方法在预测等价性判定中可能产生错误结果，最后提出了多项式时间算法来解决相关问题。

Result: 实验证实，对于触发QM方法最坏情况的决策树，本文提出的算法比McTavish等人的算法快几个数量级。

Conclusion: 本文证明了QM方法在决策树分析中的局限性，并提供了更高效的多项式时间算法来解决预测等价性判定和相关问题。

Abstract: The Rashomon set of decision trees (DTs) finds importance uses. Recent work
showed that DTs computing the same classification function, i.e. predictive
equivalent DTs, can represent a significant fraction of the Rashomon set. Such
redundancy is undesirable. For example, feature importance based on the
Rashomon set becomes inaccurate due the existence of predictive equivalent DTs,
i.e. DTs with the same prediction for every possible input. In recent work,
McTavish et al. proposed solutions for several computational problems related
with DTs, including that of deciding predictive equivalent DTs. This approach,
which this paper refers to as MBDSR, consists of applying the well-known method
of Quine-McCluskey (QM) for obtaining minimum-size DNF (disjunctive normal
form) representations of DTs, which are then used for comparing DTs for
predictive equivalence. Furthermore, the minimum-size DNF representation was
also applied to computing explanations for the predictions made by DTs, and to
finding predictions in the presence of missing data. However, the problem of
formula minimization is hard for the second level of the polynomial hierarchy,
and the QM method may exhibit worst-case exponential running time and space.
This paper first demonstrates that there exist decision trees that trigger the
worst-case exponential running time and space of the QM method. Second, the
paper shows that the MBDSR approach can produce incorrect results for the
problem of deciding predictive equivalence. Third, the paper shows that any of
the problems to which the minimum-size DNF representation has been applied to
can in fact be solved in polynomial time, in the size of the DT. The
experiments confirm that, for DTs for which the the worst-case of the QM method
is triggered, the algorithms proposed in this paper are orders of magnitude
faster than the ones proposed by McTavish et al.

</details>


### [68] [Mitigating Strategy-Selection Bias in Reasoning for More Effective Test-Time Scaling](https://arxiv.org/abs/2509.17905)
*Zongqian Wu,Baoduo Xu,Tianyu Li,Zhu Sun,Xiaofeng Zhu,Lei Feng*

Main category: cs.AI

TL;DR: 本文提出TTS-Uniform框架，通过均匀分配采样预算来缓解测试时扩展中的推理策略选择偏差问题，显著提升了大型语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时扩展方法存在推理策略选择偏差问题，即LLMs在生成推理过程时倾向于采用某些策略而忽略其他有效替代方案，导致解决方案空间探索不足。

Method: TTS-Uniform框架包含三个步骤：(i)识别潜在推理策略，(ii)均匀分配采样预算，(iii)在聚合前过滤不稳定策略。

Result: 实验结果表明，TTS-Uniform在多个主流LLMs和基准数据集上显著提升了扩展效果。

Conclusion: 该研究通过理论分析和实验验证，证明了缓解推理策略选择偏差对提升测试时扩展效果的重要性，TTS-Uniform框架为解决此问题提供了有效方案。

Abstract: Test-time scaling (TTS) has been shown to improve the performance of large
language models (LLMs) by sampling and aggregating diverse reasoning paths.
However, existing research has overlooked a critical issue: selection bias of
reasoning strategies during scaling. Specifically, when generating reasoning
processes, LLMs tend to follow certain strategies (e.g., algebraic solutions
for math problems) while neglecting other valid alternatives (e.g., geometric
solutions), resulting in insufficient exploration of the solution space. To
further understand the impact of this bias, we present a theoretical analysis
that reveals when it undermines the effectiveness of test-time scaling.
Motivated by this theoretical insight, we introduce TTS-Uniform, a framework
designed to mitigate the selection bias of reasoning strategies. It (i)
identifies potential strategies, (ii) uniformly allocates the sampling budget
across them, and (iii) filters out unstable strategies prior to aggregation.
Experimental results show that TTS-Uniform significantly enhances scaling
effectiveness across multiple mainstream LLMs and benchmark datasets.

</details>


### [69] [MEF: A Systematic Evaluation Framework for Text-to-Image Models](https://arxiv.org/abs/2509.17907)
*Xiaojing Dong,Weilin Huang,Liang Li,Yiying Li,Shu Liu,Tongtong Ou,Shuang Ouyang,Yu Tian,Fengxuan Zhao*

Main category: cs.AI

TL;DR: 提出了Magic评估框架（MEF），一个系统实用的文本到图像（T2I）模型评估方法，包括构建Magic-Bench-377基准测试，结合ELO和MOS进行联合评估，并使用多元逻辑回归分析各维度对用户满意度的贡献。


<details>
  <summary>Details</summary>
Motivation: 现有T2I生成评估方法缺乏应用场景视角，且ELO和MOS方法各有局限性，需要更系统、实用的评估框架。

Method: 提出结构化分类法构建Magic-Bench-377基准测试，结合ELO和维度特定MOS进行联合评估，使用多元逻辑回归分析维度贡献。

Result: 应用MEF到当前T2I模型，获得了排行榜和领先模型的关键特征。

Conclusion: MEF为视觉生成模型评估提供了系统框架，发布的Magic-Bench-377基准测试将推动相关研究发展。

Abstract: Rapid advances in text-to-image (T2I) generation have raised higher
requirements for evaluation methodologies. Existing benchmarks center on
objective capabilities and dimensions, but lack an application-scenario
perspective, limiting external validity. Moreover, current evaluations
typically rely on either ELO for overall ranking or MOS for dimension-specific
scoring, yet both methods have inherent shortcomings and limited
interpretability. Therefore, we introduce the Magic Evaluation Framework (MEF),
a systematic and practical approach for evaluating T2I models. First, we
propose a structured taxonomy encompassing user scenarios, elements, element
compositions, and text expression forms to construct the Magic-Bench-377, which
supports label-level assessment and ensures a balanced coverage of both user
scenarios and capabilities. On this basis, we combine ELO and
dimension-specific MOS to generate model rankings and fine-grained assessments
respectively. This joint evaluation method further enables us to quantitatively
analyze the contribution of each dimension to user satisfaction using
multivariate logistic regression. By applying MEF to current T2I models, we
obtain a leaderboard and key characteristics of the leading models. We release
our evaluation framework and make Magic-Bench-377 fully open-source to advance
research in the evaluation of visual generative models.

</details>


### [70] [Orcust: Stepwise-Feedback Reinforcement Learning for GUI Agent](https://arxiv.org/abs/2509.17917)
*Junyu Lu,Songxin Zhang,Zejian Xie,Zhuoyang Song,Jiaxing Zhang*

Main category: cs.AI

TL;DR: Orcust框架通过原则约束奖励建模和在线虚拟机轨迹构建，提升了GUI代理在交互任务中的推理可靠性和数据效率，在标准基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理模型面临奖励信号不可靠和在线轨迹生成有限的问题，需要提升推理可靠性和数据效率。

Method: 采用原则约束奖励建模（PCRM）和在线虚拟机轨迹构建（OVTC）方法，利用环境可验证和LLM衍生的原则来约束推理过程，并通过虚拟机自主收集结构化GUI交互轨迹。

Result: 在标准GUI基准测试中，Orcust相比基础模型在ScreenSpot上提升22.2%，在ScreenSpot-Pro上提升23.9%，实现了最先进的性能。

Conclusion: Orcust框架有效增强了GUI代理的推理能力、适应性和可扩展性，在各种环境和任务复杂度下都表现出色。

Abstract: Recent advances in GUI agents have achieved remarkable grounding and
action-prediction performance, yet existing models struggle with unreliable
reward signals and limited online trajectory generation. In this paper, we
introduce Orcust, a framework that integrates Principle-Constrained Reward
Modeling (PCRM) and Online VM-Grounded Trajectory Construction (OVTC) to
enhance reasoning reliability and data efficiency in interactive GUI tasks. We
leverages environment-verifiable and LLM-derived principle to enforce
interpretable reward signals that constrain long chain-of-thought reasoning and
rule-based feedback. OVTC spins up instrumented virtual machines to
autonomously collect structured GUI interaction trajectories with explicit
procedural and structural objectives, enabling the training of a stepwise
reward model that robustly captures human preferences and adheres to
task-specific constraints. Extensive experiments on standard GUI benchmarks
covering perceptual grounding, foundational operations, and end-to-end task
execution reveal that Orcust achieves state-of-the-art performance, improving
by 22.2\% on ScreenSpot and 23.9\% on ScreenSpot-Pro over the base model (i.e.
Qwen2.5-VL-7B). The results demonstrate Orcust's effectiveness in enhancing the
reasoning, adaptability and scalability of GUI agents across various
environments and task complexities.

</details>


### [71] ["I think this is fair'': Uncovering the Complexities of Stakeholder Decision-Making in AI Fairness Assessment](https://arxiv.org/abs/2509.17956)
*Lin Luo,Yuri Nakao,Mathieu Chollet,Hiroya Inakoshi,Simone Stumpf*

Main category: cs.AI

TL;DR: 研究通过30名非AI专家的利益相关者在信用评级场景中的公平性评估，发现他们的公平决策比AI专家更复杂，考虑了更多特征、定制化指标和更严格的阈值


<details>
  <summary>Details</summary>
Motivation: 现有AI公平性评估主要由AI专家主导，缺乏对受AI决策影响但无AI专业知识的利益相关者如何评估公平性的了解

Method: 对30名无AI专业知识的利益相关者进行定性研究，让他们在信用评级场景中决定优先特征、指标和阈值

Result: 利益相关者的公平决策比AI专家更复杂：考虑超出法律保护特征的特征、为特定情境定制指标、设置多样化且更严格的公平阈值，甚至偏好设计定制化公平性

Conclusion: 研究结果扩展了对利益相关者如何有意义地参与AI公平治理和缓解的理解，强调了纳入利益相关者细致公平判断的重要性

Abstract: Assessing fairness in artificial intelligence (AI) typically involves AI
experts who select protected features, fairness metrics, and set fairness
thresholds. However, little is known about how stakeholders, particularly those
affected by AI outcomes but lacking AI expertise, assess fairness. To address
this gap, we conducted a qualitative study with 30 stakeholders without AI
expertise, representing potential decision subjects in a credit rating
scenario, to examine how they assess fairness when placed in the role of
deciding on features with priority, metrics, and thresholds. We reveal that
stakeholders' fairness decisions are more complex than typical AI expert
practices: they considered features far beyond legally protected features,
tailored metrics for specific contexts, set diverse yet stricter fairness
thresholds, and even preferred designing customized fairness. Our results
extend the understanding of how stakeholders can meaningfully contribute to AI
fairness governance and mitigation, underscoring the importance of
incorporating stakeholders' nuanced fairness judgments.

</details>


### [72] [The STAR-XAI Protocol: An Interactive Framework for Inducing Second-Order Agency in AI Agents](https://arxiv.org/abs/2509.17978)
*Antoni Guasch,Maria Isabel Valdez*

Main category: cs.AI

TL;DR: STAR-XAI协议是一种训练和操作可验证可靠AI代理的新方法，通过结构化苏格拉底对话和意识转移包，将不透明的大型推理模型转变为透明的"清晰盒子"代理。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型在复杂长程任务中存在可靠性和透明度限制，经常出现"思维幻觉"，需要建立可验证的可靠AI代理。

Method: 通过结构化苏格拉底对话、意识转移包规则书、游戏循环强制事前战略论证，以及状态锁定校验和防止错误累积。

Result: 在复杂策略游戏"Caps i Caps"的25步案例研究中，代理不仅解决了高复杂度难题，还展示了二阶代理能力，能够识别自身计划缺陷并调整核心完整性协议。

Conclusion: STAR-XAI协议为创建不仅高性能而且透明、可审计、可信赖的AI代理提供了实用途径。

Abstract: Current Large Reasoning Models (LRMs) exhibit significant limitations in
reliability and transparency, often showing a collapse in reasoning
capabilities when faced with high-complexity, long-horizon tasks. This
"illusion of thinking" is frequently an artifact of non-agentic, black-box
evaluation paradigms that fail to cultivate robust problem-solving processes.
In response, we introduce The STAR-XAI Protocol (Socratic, Transparent,
Agentic, Reasoning - for eXplainable Artificial Intelligence), a novel
methodology for training and operating verifiably reliable AI agents. Our
method reframes the human-AI interaction as a structured, Socratic dialogue,
governed by an explicit and evolving rulebook, the Consciousness Transfer
Package (CTP). Through an interactive Gameplay Cycle that enforces ante-hoc
strategic justification and a state-locking Checksum that prevents error
accumulation, the protocol transforms a powerful but opaque LRM into a
disciplined "Clear Box" agent. We demonstrate the efficacy of this method
through an exhaustive 25-move case study in the complex strategic game "Caps i
Caps". The agent not only solved the high-complexity puzzle but also
demonstrated Second-Order Agency, identifying flaws in its own
supervisor-approved plans and adapting its core integrity protocols mid-task.
The STAR-XAI Protocol offers a practical pathway to creating AI agents that are
not just high-performing, but also transparent, auditable, and trustworthy by
design.

</details>


### [73] [Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates](https://arxiv.org/abs/2509.18076)
*Hy Dang,Tianyi Liu,Zhuofeng Wu,Jingfeng Yang,Haoming Jiang,Tao Yang,Pei Chen,Zhengyang Wang,Helen Wang,Huasheng Li,Bing Yin,Meng Jiang*

Main category: cs.AI

TL;DR: 本文提出了一种基于课程学习理念的结构化推理模板框架，用于改进大语言模型在工具调用任务中的性能，相比自由形式的思维链提示，该方法能显著减少工具使用错误。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在现实世界工具交互中经常失败，主要原因是参数化错误、工具选择不当或用户意图误解，这些问题源于对用户目标理解不完整和工具文档理解不足。

Method: 引入课程学习启发的框架，利用结构化推理模板来引导LLM通过更谨慎的逐步指令生成函数调用，取代自由形式的思维链提示。

Result: 实验结果显示该方法减少了工具使用错误，在不同模型系列和方法上实现了3-12%的相对改进。

Conclusion: 该框架增强了工具使用代理的鲁棒性、可解释性和透明度，推动了更可靠的现实世界AI助手的发展。

Abstract: Large language models (LLMs) have demonstrated strong reasoning and tool-use
capabilities, yet they often fail in real-world tool-interactions due to
incorrect parameterization, poor tool selection, or misinterpretation of user
intent. These issues often stem from an incomplete understanding of user goals
and inadequate comprehension of tool documentation. While Chain-of-Thought
(CoT) prompting has proven effective for enhancing reasoning in general
contexts, our analysis reveals that free-form CoT is insufficient and sometimes
counterproductive for structured function-calling tasks. To address this, we
introduce a curriculum-inspired framework that leverages structured reasoning
templates to guide LLMs through more deliberate step-by-step instructions for
generating function callings. Experimental results show that our method reduces
tool-use errors, achieving 3-12% relative improvements over strong baselines
across diverse model series and approaches. Moreover, our framework enhances
the robustness, interpretability, and transparency of tool-using agents,
advancing the development of more reliable AI assistants for real-world
applications.

</details>


### [74] [Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning](https://arxiv.org/abs/2509.18083)
*Valentin Lacombe,Valentin Quesnel,Damien Sileo*

Main category: cs.AI

TL;DR: Reasoning Core是一个新的可扩展强化学习环境，专注于可验证奖励的符号推理任务，旨在提升大语言模型的基础推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注游戏或孤立谜题，缺乏对核心形式化领域推理能力的系统性评估。需要构建一个能够生成多样化、可验证推理问题的环境来推动LLM推理能力的发展。

Method: 基于高通用性问题分布、外部工具验证和连续难度控制三大设计原则，在PDDL规划、一阶逻辑、上下文无关文法解析、因果推理和系统方程求解等核心形式化领域程序化生成问题。

Result: 初步零样本评估显示前沿LLM在Reasoning Core任务上表现困难，验证了该环境的挑战性。

Conclusion: Reasoning Core作为一个具有无限训练实例供给的环境，有望成为提升未来模型推理能力的重要资源。

Abstract: We introduce Reasoning Core, a new scalable environment for Reinforcement
Learning with Verifiable Rewards (RLVR), designed to advance foundational
symbolic reasoning in Large Language Models (LLMs). Unlike existing benchmarks
that focus on games or isolated puzzles, Reasoning Core procedurally generates
problems across core formal domains, including PDDL planning, first-order
logic, context-free grammar parsing, causal reasoning, and system equation
solving. The environment is built on key design principles of high-generality
problem distributions, verification via external tools, and continuous
difficulty control, which together provide a virtually infinite supply of novel
training instances. Initial zero-shot evaluations with frontier LLMs confirm
the difficulty of Reasoning Core's tasks, positioning it as a promising
resource to improve the reasoning capabilities of future models.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [75] [Similarity as Thermodynamic Work: Between Depth and Diversity -- from Information Distance to Ugly Duckling](https://arxiv.org/abs/2509.16236)
*Kentaro Imafuku*

Main category: cs.IT

TL;DR: 提出一个统计力学框架，将程序长度视为能量，通过温度参数统一信息距离和丑小鸭定理的相似性概念。


<details>
  <summary>Details</summary>
Motivation: 解决信息科学中相似性定义的根本挑战，统一Watanabe的丑小鸭定理（强调多样性）和算法信息理论（强调深度信息距离）。

Method: 使用统计力学方法，将程序长度类比为能量，引入温度参数。在低温极限下相似性接近信息距离，在高温极限下恢复丑小鸭定理的不可区分性，在临界点与Solomonoff先验一致。通过引入正则通用机和有效简并比来分离冗余与核心多样性。

Result: 开发了一个统一框架，能够平滑过渡不同相似性概念，并提供了分析相似性的新工具。

Conclusion: 该统计力学框架为信息距离、模型选择和非平衡扩展提供了新的视角，能够更精细地分析相似性。

Abstract: Defining similarity is a fundamental challenge in information science.
Watanabe's Ugly Duckling Theorem highlights diversity, while algorithmic
information theory emphasizes depth through Information Distance. We propose a
statistical-mechanical framework that treats program length as energy, with a
temperature parameter unifying these two aspects: in the low-temperature limit,
similarity approaches Information Distance; in the high-temperature limit, it
recovers the indiscriminability of the Ugly Duckling theorem; and at the
critical point, it coincides with the Solomonoff prior. We refine the
statistical-mechanical framework by introducing regular universal machines and
effective degeneracy ratios, allowing us to separate redundant from core
diversity. This refinement yields new tools for analyzing similarity and opens
perspectives for information distance, model selection, and non-equilibrium
extensions.

</details>


### [76] [Sparse Regression LDPC Codes for the Block-Fading Non-Coherent SIMO Channel](https://arxiv.org/abs/2509.16376)
*Alexander Fengler,Burak Çakmak,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出一种低复杂度近似消息传递解码器，用于解码非二进制LDPC编码的稀疏回归码在瑞利衰落信道上的传输，无需信道状态信息即可达到与有CSI相同的误码率。


<details>
  <summary>Details</summary>
Motivation: 结合非二进制LDPC码可以改善稀疏回归码在AWGN信道上的有限长度性能，但需要解决在瑞利衰落信道上无需CSI的解码问题。

Method: 使用近似消息传递解码器，通过迭代重新估计信道来实现完全非相干解码，同时提供严格的渐近性能分析。

Result: 数值结果显示该编码方案在中断容量1.5dB以内，性能与采用5G标准化LDPC码和基于导频信道估计的编码调制方案相当。

Conclusion: 提出的非相干AMP解码器在瑞利衰落信道上实现了接近最优的性能，为无需CSI的可靠通信提供了有效解决方案。

Abstract: Sparse regression codes (SPARCs) are a class of codes that encode information
through the superposition of columns of a randomised coding matrix. The
combination with an outer non-binary low density parity check (NB-LDPC) code
was recently shown to improve the finite-length performance of these codes over
the unfaded AWGN channel. In this paper, we propose a low-complexity
approximate message passing (AMP) decoder that is capable of decoding NB-LDPC
encoded SPARCs on a Rayleigh fading channel with multiple receive antennas.
Notably, the decoder does not require channel state information (CSI), i.e., it
is fully non-coherent, but achieves the same error probability as a decoder
with full CSI, even for moderate block lengths. This is achieved by iteratively
re-estimating the channel throughout the decoding iterations. In addition, we
provide a rigorous asymptotic analysis of both the block error probability and
the channel estimation error. Numerical results confirm the precision of the
analysis and show that the presented coding scheme performs within 1.5 dB of
the outage capacity and is competitive with coded modulation schemes employing
standardised LDPC codes for 5G cellular networks and pilot-based channel
estimation.

</details>


### [77] [Code distances: a new family of invariants of linear codes](https://arxiv.org/abs/2509.16424)
*Eduardo Camps-Moreno,Elisa Gorla,Hiram H. López*

Main category: cs.IT

TL;DR: 本文介绍了码距离这一线性码的新不变量族，研究了其性质、界限，并证明其不是关联的拟阵或q-多拟阵的不变量。通过实例展示了码距离能区分具有相同参数的MDS或MRD码，且不存在对偶性。还定义了贪婪和渐近版本，并与其他不变量如极大度、覆盖半径和极化码的部分距离建立了联系。


<details>
  <summary>Details</summary>
Motivation: 为了寻找能够更好地区分线性码的新不变量，特别是那些具有相同传统参数但结构不同的码。码距离作为一种新的不变量族，旨在提供比传统参数更精细的区分能力。

Method: 引入码距离的概念，建立其数学性质并证明相关界限。通过构造具体例子展示码距离的区分能力，定义贪婪和渐近版本，并与其他已知不变量进行比较分析。

Result: 码距离能够区分一些具有相同参数的MDS或MRD码，证明其不是拟阵或q-多拟阵的不变量，且不存在对偶性。建立了码距离与其他不变量之间的联系。

Conclusion: 码距离是线性码的一个有用新不变量，能够提供比传统参数更细致的区分，但在对偶性方面存在局限性，需要进一步研究其应用和性质。

Abstract: In this paper, we introduce code distances, a new family of invariants for
linear codes. We establish some properties and prove bounds on the code
distances, and show that they are not invariants of the matroid (for a linear
block code) or $q$-polymatroid (for a rank-metric code) associated to the code.
By means of examples, we show that the code distances allow us to distinguish
some inequivalent MDS or MRD codes with the same parameters. We also show that
no duality holds, i.e., the sequence of code distances of a code does not
determine the sequence of code distances of its dual. Further, we define a
greedy and an asymptotic version of code distances. Finally, we relate these
invariants to other invariants of linear codes, such as the maximality degree,
the covering radius, and the partial distances of polar codes.

</details>


### [78] [Holographic Multi-User Multi-Stream Beamforming Maintaining Rate-Fairness](https://arxiv.org/abs/2509.16612)
*W. Zhu,H. D. Tuan,E. Dutkiewicz,H. V. Poor,L. Hanzo*

Main category: cs.IT

TL;DR: 本文首次研究了使用可重构全息表面(RHS)的基站向多用户传输多流信息的问题，提出了RHS和基带波束成形器的联合设计，以实现多用户间的公平多流传输。


<details>
  <summary>Details</summary>
Motivation: 传统多天线系统中，多流传输通常面临速率公平性问题。本文旨在解决使用RHS技术的基站向多用户传输多流信息时的公平性问题，克服传统和速率最大化方法在公平性方面的不足。

Method: 提出了两种优化方法：1) 最大最小速率优化方法，通过迭代求解二次问题来最大化所有用户的最小速率；2) 基于代理的优化方法，提供低复杂度设计替代方案，依赖闭式更新。

Result: 仿真结果表明，基于代理的方法在最小速率方面几乎达到与最大最小优化相同的性能，同时在和速率方面与和速率最大化方法相当，克服了后者在速率公平性方面的缺陷。

Conclusion: 所提出的基于代理的优化方法在保持低复杂度的同时，能够有效平衡多用户多流传输的速率公平性和系统总吞吐量，为RHS辅助的多用户通信系统提供了实用的解决方案。

Abstract: We present the first investigation into the transmission of multi-stream
information from a base station equipped with reconfigurable holographic
surfaces (RHS) to multiple users with the aid of multi-antenna arrays. Building
upon this, we propose the joint design of RHS and baseband beamformers that
enables multi-stream delivery at fair rates across all users. Specifically, we
first introduce a max-min rate optimization approach, which aims for maximizing
the minimum rate for all users through iterative solutions of quadratic
problems. To reduce complexity, we then propose a surrogate-based optimization
approach that offers a low-complexity design alternative relying on closed-form
updates. Our simulations show that the surrogate-based approach achieves nearly
the same minimum rate as max-min optimization, while delivering sum-rates
comparable to those of sum-rate maximization, overcoming the rate-fairness
deficiency typical of the latter.

</details>


### [79] [Frequency Switching for Simultaneous Wireless Information and Power Transfer](https://arxiv.org/abs/1705.03366)
*Dogay Altinel,Gunes Karabulut Kurt*

Main category: cs.IT

TL;DR: 提出了一种新的频率切换接收器结构，用于多载波通信系统中的同时无线信息和能量传输。每个子载波根据最优子载波分配切换到能量收集单元或信息解码单元。


<details>
  <summary>Details</summary>
Motivation: 在多载波通信系统中实现同时无线信息和能量传输，提高系统性能。

Method: 将优化问题转化为二进制背包问题，使用动态规划方法求解，并通过连续松弛获得上界，集成功率分配以进一步提高性能。

Result: 数值研究表明，所提出的基于频率切换的模型在广泛参数范围内优于现有模型。

Conclusion: 频率切换接收器结构是实现同时无线信息和能量传输的有效方法，具有优于现有模型的性能。

Abstract: A new frequency switching receiver structure is proposed for simultaneous
wireless information and power transfer in multi-carrier communication systems.
Each subcarrier is switched to either the energy harvesting unit or the
information decoding unit, according to the optimal subcarrier allocation. To
implement the system, one-bit feedback is required for each subcarrier. Two
optimization problems are defined, converted to binary knapsack problems, and
solved using dynamic programming approaches. Upper bounds are obtained using
continuous relaxations. Power allocation is integrated to further increase the
performance. Numerical studies show that the proposed frequency switching based
model is better than existing models in a wide range of parameters.

</details>


### [80] [A New Class of Analog Precoding for Multi-Antenna Multi-User Communications over High-Frequency Bands](https://arxiv.org/abs/2509.16634)
*W. Zhu,H. D. Tuan,E. Dutkiewicz,H. V. Poor,L. Hanzo*

Main category: cs.IT

TL;DR: 提出了一种新型模拟预编码器以减少功耗，并设计了混合预编码器来最大化用户最小吞吐量，通过迭代算法解决大规模非光滑优化问题。


<details>
  <summary>Details</summary>
Motivation: 现有模拟预编码器依赖大量移相器导致功耗过高，需要设计更节能的方案来支持高频段通信。

Method: 提出基于可控数量移相器的新型模拟预编码器框架，开发两种迭代算法：一种解决最大最小吞吐量优化问题，另一种解决平滑的软最大最小吞吐量优化问题。

Result: 仿真结果显示，软最大最小解决方案接近帕累托最优解，在最小吞吐量和总吞吐量方面都取得了良好性能。

Conclusion: 所提出的混合预编码器方案在功耗和性能之间取得了良好平衡，为高频段通信提供了有效的解决方案。

Abstract: A network relying on a large antenna-array-aided base station is designed for
delivering multiple information streams to multi-antenna users over
high-frequency bands such as the millimeter-wave and sub-Terahertz bands. The
state-of-the-art analog precoder (AP) dissipates excessive circuit power due to
its reliance on a large number of phase shifters. To mitigate the power
consumption, we propose a novel AP relying on a controlled number of phase
shifters. Within this new AP framework, we design a hybrid precoder (HP) for
maximizing the users' minimum throughput, which poses a computationally
challenging problem of large-scale, nonsmooth mixed discrete-continuous
log-determinant optimization. To tackle this challenge, we develop an algorithm
which iterates through solving convex problems to generate a sequence of HPs
that converges to the max-min solution. We also introduce a new framework of
smooth optimization termed soft max-min throughput optimization. Additionally,
we develop another algorithm, which iterates by evaluating closed-form
expressions to generate a sequence of HPs that converges to the soft max-min
solution. Simulation results reveal that the HP soft max-min solution
approaches the Pareto-optimal solution constructed for simultaneously
optimizing both the minimum throughput and sum-throughput. Explicitly, it
achieves a minimum throughput similar to directly maximizing the users' minimum
throughput and it also attains a sum-throughput similar to directly maximizing
the sum-throughput.

</details>


### [81] [Diversity Combining for RF Energy Harvesting](https://arxiv.org/abs/1705.10514)
*Dogay Altinel,Gunes Karabulut Kurt*

Main category: cs.IT

TL;DR: 本文研究了在射频能量采集系统中使用分集合并技术来提高能量采集效率，并分析了不同合并技术的净收益，考虑了功率消耗的影响。


<details>
  <summary>Details</summary>
Motivation: 射频能量采集技术为无线通信节点提供能量，但确保设备自给自足具有挑战性。分集合并技术有望增加采集能量，但需要评估其净效益。

Method: 研究了选择合并、等增益合并和最大比合并三种分集合并技术，通过仿真比较它们的性能，并考虑了合并过程的功率消耗。

Result: 仿真结果显示分集合并技术能改善能量采集性能，但功率消耗参数在选择合适技术时具有关键重要性。

Conclusion: 虽然分集合并技术能提升能量采集效率，但在实际应用中必须仔细考虑功率消耗因素来选择最优的合并方案。

Abstract: RF energy harvesting (RFEH) is a promising technology for energy requirements
of wireless communication nodes. However, providing sufficient amount of energy
to ensure self-sufficient devices based on RFEH may be challenging. In this
paper, the use of diversity combining in RFEH systems is proposed to increase
the amount of harvested energy. The power consumption of diversity combining
process is also taken into account to analyze the net benefit of diversity
combining. Performances of RFEH systems are investigated for selection
combining (SC), equal gain combining (EGC), and maximal ratio combining (MRC)
techniques. Simulations are conducted to compare the numerical results of SC,
EGC, and MRC, and the results show that although the diversity combining
techniques can improve the energy harvesting performance, the power consumption
parameters have a critical importance while determining the suitable technique.

</details>


### [82] [Further results on bent partitions](https://arxiv.org/abs/2509.16911)
*Jiaxin Wang,Yadi Wei,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 本文研究了V_n^(p)上的弯曲分区，证明了当所有由弯曲分区生成的p元弯曲函数都是正则的或都是弱正则但非正则时，分区的深度必须是p的幂。作者提出了新的弯曲分区构造方法，并建立了V_n^(2)上一般弯曲分区与Hadamard矩阵的表征关系。


<details>
  <summary>Details</summary>
Motivation: 弯曲分区在构造弯曲函数、部分差集和关联方案中具有重要作用。目前存在一个开放性问题：V_n^(p)上任何弯曲分区的深度是否总是p的幂？所有已知弯曲分区的深度都是p的幂，但缺乏一般性证明。

Method: 作者通过分析弯曲分区生成的p元弯曲函数的正则性特征，证明了在特定条件下弯曲分区深度必须是p的幂。同时提出了新的弯曲分区构造方法，包括与向量对偶弯曲函数对应的构造，并建立了二元情况下弯曲分区与Hadamard矩阵的等价关系。

Result: 证明了当弯曲分区生成的所有p元弯曲函数都是正则的或都是弱正则但非正则时，分区深度必须是p的幂。提供了新的弯曲分区构造方法，特别是向量对偶弯曲函数的新构造。在二元情况下，建立了弯曲分区与Hadamard矩阵的表征关系。

Conclusion: 本文部分解决了弯曲分区深度的开放性问题，为特定类型的弯曲分区提供了深度必须是p的幂的证明。新的构造方法和表征关系为弯曲分区的进一步研究提供了重要工具和理论基础。

Abstract: Bent partitions of $V_{n}^{(p)}$ play an important role in constructing
(vectorial) bent functions, partial difference sets, and association schemes,
where $V_{n}^{(p)}$ denotes an $n$-dimensional vector space over the finite
field $\mathbb{F}_{p}$, $n$ is an even positive integer, and $p$ is a prime.
For bent partitions, there remains a challenging open problem: Whether the
depth of any bent partition of $V_{n}^{(p)}$ is always a power of $p$. Notably,
the depths of all current known bent partitions of $V_{n}^{(p)}$ are powers of
$p$. In this paper, we prove that for a bent partition $\Gamma$ of
$V_{n}^{(p)}$ for which all the $p$-ary bent functions generated by $\Gamma$
are regular or all are weakly regular but not regular, the depth of $\Gamma$
must be a power of $p$. We present new constructions of bent partitions that
(do not) correspond to vectorial dual-bent functions. In particular, a new
construction of vectorial dual-bent functions is provided. Additionally, for
general bent partitions of $V_{n}^{(2)}$, we establish a characterization in
terms of Hadamard matrices.

</details>


### [83] [Communication over LQG Control Systems: A Convex Optimization Approach to Capacity](https://arxiv.org/abs/2509.17002)
*Aharon Rips,Oron Sabag*

Main category: cs.IT

TL;DR: 本文研究了控制系统中的通信问题，提出了LQG系统容量的凸优化上界，并在标量系统中证明了该上界即为精确容量。


<details>
  <summary>Details</summary>
Motivation: 研究控制器如何通过控制信号同时调节系统状态和向观测者传递信息，探索控制系统中的隐式通信能力。

Method: 采用线性二次高斯(LQG)控制系统模型，通过凸优化方法推导系统容量上界，并基于Riccati方程分析向量系统的紧致性条件。

Result: 在标量LQG系统中证明了凸优化上界即为精确容量，在向量系统中数值模拟表明上界具有紧致性。

Conclusion: 提出的凸优化上界能够统一涵盖LQG控制、带记忆高斯信道反馈容量等多种已知结果，可能适用于一般向量LQG系统的容量计算。

Abstract: We study communication over control systems, where a controller-encoder
selects inputs to a dynamical system in order to simultaneously regulate the
system and convey a message to an observer that has access to the system's
output measurements. This setup reflects implicit communication, as the
controller embeds a message in the control signal. The capacity of a control
system is the maximal reliable rate of the embedded message subject to a
closed-loop control-cost constraint. We focus on linear quadratic Gaussian
(LQG) control systems, in which the dynamical system is given by a state-space
model with Gaussian noise, and the control cost is a quadratic function of the
system inputs and system states. Our main result is a convex optimization upper
bound on the capacity of LQG systems. In the case of scalar systems, we prove
that the upper bound yields the exact LQG system capacity. The upper bound also
recovers all known results, including LQG control, feedback capacity of
Gaussian channels with memory, and the LQG system capacity with a
state-feedback. For vector LQG control systems, we provide a sufficient
condition for tightness of the upper bound, based on the Riccati equation.
Numerical simulations indicate the upper bound tightness in all tested
examples, suggesting that the upper bound may be equal to the LQG system
capacity in the vector case as well.

</details>


### [84] [Fundamental Mechanisms of Human Learning](https://arxiv.org/abs/2509.17202)
*Scott E. Allen,A. David Redish,René F. Kizilcec*

Main category: cs.IT

TL;DR: 这篇论文提出一个统一模型，整合神经科学关于学习过程的最新发现，将基础神经机制与教育成果联系起来，挑战传统记忆模型。


<details>
  <summary>Details</summary>
Motivation: 虽然神经科学揭示了学习过程的基本结构，但这些见解尚未整合到研究和实践中。论文旨在弥合神经科学发现与教育应用之间的差距。

Method: 基于神经科学关于决策过程（感知、行动选择、执行）的研究，提出一个整合多神经系统和不同记忆存储的统一模型框架。

Result: 模型挑战了学习和行为科学中使用的经典记忆模型，提供了人类如何获取和使用知识的机制性解释。

Conclusion: 通过将神经信息处理的第一原理转化为可推广的框架，这项工作推进了技能获取和迁移理论，为跨学科研究奠定了基础。

Abstract: Learning underlies nearly all human behavior and is central to education and
education reform. Although recent advances in neuroscience have revealed the
fundamental structure of learning processes, these insights have yet to be
integrated into research and practice. Specifically, neuroscience has found
that decision-making is governed by a structured process of perception,
action-selection, and execution, supported by multiple neural systems with
distinct memory stores and learning mechanisms. These systems extract different
types of information (categorical, predictive, structural, and sequential)
challenging canonical models of memory used in learning and behavioral science
research by providing a mechanistic account of how humans acquire and use
knowledge. Because each system learns differently, effective teaching requires
alignment with system-specific processes. We propose a unified model that
integrates these neuroscientific insights, bridging basic mechanisms with
outcomes in education, identity, belonging, and wellbeing. By translating first
principles of neural information processing into a generalizable framework,
this work advances theories of skill acquisition and transfer while
establishing a foundation for interdisciplinary research to refine how learning
is understood and supported across domains of human behavior.

</details>


### [85] [Hyperbolic Sets in Incomplete Tables](https://arxiv.org/abs/2509.17591)
*J. J. Bernal,J. J. Simón*

Main category: cs.IT

TL;DR: 扩展了Berlekamp-Massey-Sakata算法在包含未知值数据表上的实现结果


<details>
  <summary>Details</summary>
Motivation: 研究如何在数据表中存在未知值的情况下有效实现Berlekamp-Massey-Sakata算法

Method: 扩展Berlekamp-Massey-Sakata算法以处理包含未知值的数据表

Result: 提出了能够处理未知值的算法实现方法

Conclusion: 该扩展方法为在存在缺失数据的情况下应用Berlekamp-Massey-Sakata算法提供了有效解决方案

Abstract: In this paper, we extend results about the implementation of the
Berlekamp-Massey-Sakata algorithm on data tables having a number of unknown
values.

</details>


### [86] [A Note on the Theoretical Support to Compute Dimension in Abelian Codes](https://arxiv.org/abs/2509.17597)
*J. J. Bernal,J. J. Simón*

Main category: cs.IT

TL;DR: 本文通过商多项式环理论为阿贝尔码的维数计算提供了理论支持


<details>
  <summary>Details</summary>
Motivation: 为阿贝尔码的维数计算提供理论依据和数学支撑

Method: 使用商多项式环理论来分析和推导阿贝尔码的维数计算公式

Result: 建立了基于商多项式环的阿贝尔码维数计算的理论框架

Conclusion: 商多项式环理论为阿贝尔码维数计算提供了有效的数学工具和理论基础

Abstract: In this note we give a theoretical support by means of quotient polynomial
rings for the computation formulas of the dimension of abelian codes.

</details>


### [87] [Evaluation Codes in Bottleneck Metrics](https://arxiv.org/abs/2509.17682)
*Mahir Bilen Can,Dillon Montero,Ferruh Özbudak*

Main category: cs.IT

TL;DR: 本文在瓶颈偏序集度量框架下引入了Reed-Solomon码的类似物，证明了这些码是最大距离可分码，并将结果扩展到代数几何码的设置。


<details>
  <summary>Details</summary>
Motivation: 在瓶颈偏序集度量框架下探索Reed-Solomon码的类似物，以扩展编码理论的应用范围并研究其最大距离可分性质。

Method: 在瓶颈偏序集度量框架下构造Reed-Solomon码的类似物，并分析其距离特性。

Result: 证明了这些构造的码是最大距离可分码，并将结果成功扩展到代数几何码的设置。

Conclusion: 该研究为在瓶颈偏序集度量框架下设计最大距离可分码提供了有效方法，扩展了代数几何码的应用可能性。

Abstract: Analogs of Reed-Solomon codes are introduced within the framework of
bottleneck poset metrics. These codes are proven to be maximum distance
separable. Furthermore, the results are extended to the setting of Algebraic
Geometry codes.

</details>


### [88] [Symbol Detection in Inter-Symbol Interference Channels using Expectation Propagation with Channel Shortening](https://arxiv.org/abs/2509.17735)
*Jannis Clausius,Luca Schmid,Laurent Schmalen,Stephan ten Brink*

Main category: cs.IT

TL;DR: 提出了一种基于期望传播(EP)的检测器，通过在信道缩短后的变换信号空间中操作，改进了传统EP检测器在强符号间干扰(ISI)信道中的性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于EP的迭代消息传递检测在强ISI信道中性能显著下降，因为初始线性最小均方误差(LMMSE)估计不准确。

Method: 在信道缩短后的变换信号空间中迭代操作，使用线性信道缩短滤波器估计器和具有减少记忆的非线性BCJR检测器，并在第一次迭代中故意不匹配初始化消息和协方差以加速收敛。

Result: 在Proakis-C ISI信道和无线测量CIR上评估，在2比特/信道使用时性能提升达6dB，并改善了性能-复杂度权衡。

Conclusion: 所提出的方法显著优于传统EP检测，特别是在强ISI信道中，实现了更好的检测性能和收敛速度。

Abstract: Iterative message passing detection based on expectation propagation(EP) has
demonstrated near-optimum performance in many signal processing and
communication scenarios. The method remains feasible even for channel impulse
responses (CIRs), where the optimal Bahl-Cocke-Jelinek-Raviv (BCJR) detector is
infeasible. However, significant performance degradation occurs for channels
with strong inter-symbol interference (ISI), where the initial linear minimum
mean square error (LMMSE) estimate is inaccurate. We propose an EP-based
detector that operates in a transformed signal space obtained by channel
shortening. Specifically, instead of the conventional approach that iterates
between an LMMSE estimator and a non-linear symbol-wise demapper, the proposed
method iterates between a linear channel shortening filter-based estimator and
a nonlinear BCJR detector with reduced memory compared to the actual channel.
Additionally, we propose a deliberate mismatch between the initialized messages
and the initialized covariance used in the linear estimator in the first
iteration for faster convergence. The proposed approach is evaluated for the
well-known Proakis-C ISI channel and for CIRs from a wireless measurement
campaign. We demonstrate improvements of up to 6dB at 2 bits per channel use
and an improved performance-complexity trade-off over conventional EP-based
detection.

</details>


### [89] [Quickest Change Detection in Continuous-Time in Presence of a Covert Adversary](https://arxiv.org/abs/2509.17778)
*Amir Reza Ramtin,Philippe Nain,Don Towsley*

Main category: cs.IT

TL;DR: 本文研究了连续时间设置下的隐蔽最快变化检测问题，其中布朗运动在未知时间经历漂移变化。与经典公式不同，考虑了一个隐蔽对手，该对手根据误报约束参数γ调整后变化漂移μ(γ)，目标是尽可能长时间不被检测到。


<details>
  <summary>Details</summary>
Motivation: 经典的变化检测方法假设漂移变化是固定的，但在实际应用中，对手可能会自适应地调整其策略以逃避检测。本文旨在分析当对手能够根据检测系统的参数调整其漂移时的检测性能。

Method: 利用连续时间CuSum过程的平均检测延迟(ADD)和平均误报时间(AT2FA)的精确表达式，严格分析当μ(γ)→0且γ增加时ADD的渐近行为。推导了不同μ(γ)收敛速率下的ADD的尖锐渐近表达式。

Result: 结果表明，经典检测延迟特征在这种机制下不再成立。当漂移按μ(γ)=Θ(1/√γ)缩放时，对手造成最大损害，这标志着连续时间检测系统中隐蔽性和影响之间的基本权衡。

Conclusion: 本文确定了维持隐蔽性的精确条件，并表征了对手造成的总损害。揭示了在连续时间检测系统中，当对手能够自适应调整漂移时，存在隐蔽性和检测性能之间的基本权衡。

Abstract: We investigate the problem of covert quickest change detection in a
continuous-time setting, where a Brownian motion experiences a drift change at
an unknown time. Unlike classical formulations, we consider a covert adversary
who adjusts the post-change drift $\mu = \mu(\gamma)$ as a function of the
false alarm constraint parameter $\gamma$, with the goal of remaining
undetected for as long as possible. Leveraging the exact expressions for the
average detection delay (ADD) and average time to false alarm (AT2FA) known for
the continuous-time CuSum procedure, we rigorously analyze how the asymptotic
behavior of ADD evolves as $\mu(\gamma) \to 0$ with increasing $\gamma$. Our
results reveal that classical detection delay characterizations no longer hold
in this regime. We derive sharp asymptotic expressions for the ADD under
various convergence rates of $\mu(\gamma)$, identify precise conditions for
maintaining covertness, and characterize the total damage inflicted by the
adversary. We show that the adversary achieves maximal damage when the drift
scales as $\mu(\gamma) = \Theta(1/\sqrt{\gamma})$, marking a fundamental
trade-off between stealth and impact in continuous-time detection systems.

</details>
