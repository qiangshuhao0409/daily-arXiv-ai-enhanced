{"id": "2509.10462", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.10462", "abs": "https://arxiv.org/abs/2509.10462", "authors": ["Rabab Khan Rongon", "Krishna Das"], "title": "Energy-Aware Data Center Management: A Sustainable Approach to Reducing Carbon Footprint", "comment": null, "summary": "The rapid expansion of cloud computing and data center infrastructure has led\nto significant energy consumption, posing environmental challenges due to the\ngrowing carbon footprint. This research explores energy-aware management\nstrategies aimed at creating sustainable data center operations. By integrating\nadvanced energy-efficient technologies and optimizing resource utilization,\nthis study proposes a framework to minimize power usage while maintaining high\nperformance. Key elements include dynamic workload allocation, renewable energy\nintegration, and intelligent cooling systems, all of which contribute to\nreducing overall energy consumption. The study also examines the impact of\nthese strategies on operational costs and performance efficiency, demonstrating\nhow sustainable practices can be both environmentally and economically\nbeneficial. Through simulations and case studies, the research offers practical\ninsights into reducing carbon emissions in data centers, supporting the\ntransition towards greener cloud infrastructure. The findings highlight the\npotential for scalable, energy-aware data center designs that significantly\nlower environmental impact while ensuring optimal functionality, contributing\nto the global effort of mitigating climate change."}
{"id": "2509.10475", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.10475", "abs": "https://arxiv.org/abs/2509.10475", "authors": ["Peiyan Yuan", "Ming Li", "Chenyang Wang", "Ledong An", "Xiaoyan Zhao", "Junna Zhang", "Xiangyang Li", "Huadong Ma"], "title": "A Dynamic Service Offloading Algorithm Based on Lyapunov Optimization in Edge Computing", "comment": "This is the full version with the full proofs of theorems in the\n  version of ECAI 2025", "summary": "This study investigates the trade-off between system stability and offloading\ncost in collaborative edge computing. While collaborative offloading among\nmultiple edge servers enhances resource utilization, existing methods often\noverlook the role of queue stability in overall system performance. To address\nthis, a multi-hop data transmission model is developed, along with a cost model\nthat captures both energy consumption and delay. A time-varying queue model is\nthen introduced to maintain system stability. Based on Lyapunov optimization, a\ndynamic offloading algorithm (LDSO) is proposed to minimize offloading cost\nwhile ensuring long-term stability. Theoretical analysis and experimental\nresults verify that the proposed LDSO achieves significant improvements in both\ncost efficiency and system stability compared to the state-of-the-art."}
{"id": "2509.10478", "categories": ["cs.NI", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.10478", "abs": "https://arxiv.org/abs/2509.10478", "authors": ["Oluwaseyi Giwa", "Michael Adewole", "Tobi Awodumila", "Pelumi Aderinto"], "title": "The LLM as a Network Operator: A Vision for Generative AI in the 6G Radio Access Network", "comment": "Submitted to Workshop on AI and ML for Next-Generation Wireless\n  Communications and Networking, NeurIPS 2025", "summary": "The management of future AI-native Next-Generation (NextG) Radio Access\nNetworks (RANs), including 6G and beyond, presents a challenge of immense\ncomplexity that exceeds the capabilities of traditional automation. In\nresponse, we introduce the concept of the LLM-RAN Operator. In this paradigm, a\nLarge Language Model (LLM) is embedded into the RAN control loop to translate\nhigh-level human intents into optimal network actions. Unlike prior empirical\nstudies, we present a formal framework for an LLM-RAN operator that builds on\nearlier work by making guarantees checkable through an adapter aligned with the\nOpen RAN (O-RAN) standard, separating strategic LLM-driven guidance in the\nNon-Real-Time (RT) RAN intelligent controller (RIC) from reactive execution in\nthe Near-RT RIC, including a proposition on policy expressiveness and a theorem\non convergence to stable fixed points. By framing the problem with mathematical\nrigor, our work provides the analytical tools to reason about the feasibility\nand stability of AI-native RAN control. It identifies critical research\nchallenges in safety, real-time performance, and physical-world grounding. This\npaper aims to bridge the gap between AI theory and wireless systems engineering\nin the NextG era, aligning with the AI4NextG vision to develop knowledgeable,\nintent-driven wireless networks that integrate generative AI into the heart of\nthe RAN."}
{"id": "2509.10479", "categories": ["cs.NI", "cs.OS"], "pdf": "https://arxiv.org/pdf/2509.10479", "abs": "https://arxiv.org/abs/2509.10479", "authors": ["Junyi Liu", "Xu Jiang", "Yuanzhen Mu", "Wang Yi", "Nan Guan"], "title": "Exploring Busy Period for Worst-Case Deadline Failure Probability Analysis", "comment": null, "summary": "Busy period is a fundamental concept in classical deterministic real-time\nscheduling analysis. In this deterministic context, only one busy period -\nwhich starts at the critical instant - needs to be considered, which identifies\nthe worst-case scenario and thus paves the way for the development of efficient\nand safe analysis techniques. However, a recent work has revealed that, in the\ncontext of \\textit{probabilistic} real-time scheduling analysis, only\nconsidering critical instant is not safe. In this paper, we address this gap by\nsystematically analyzing deadline miss probabilities across varying busy period\nstarting points. We propose a novel method of Worst-Case Deadline Failure\nProbability (WCDFP) for probabilistic fixed-priority preemptive scheduling.\nExperimental results demonstrate significant improvements over state-of-the-art\nmethods achieved by our proposed method."}
{"id": "2509.10487", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.10487", "abs": "https://arxiv.org/abs/2509.10487", "authors": ["Ruizhi Zhang", "Yuchen Zhang", "Lipeng Zhu", "Ying Zhang", "Rui Zhang"], "title": "A Deep Learning Framework for Joint Channel Acquisition and Communication Optimization in Movable Antenna Systems", "comment": null, "summary": "This paper presents an end-to-end deep learning framework in a movable\nantenna (MA)-enabled multiuser communication system. In contrast to the\nconventional works assuming perfect channel state information (CSI), we address\nthe practical CSI acquisition issue through the design of pilot signals and\nquantized CSI feedback, and further incorporate the joint optimization of\nchannel estimation, MA placement, and precoding design. The proposed mechanism\nenables the system to learn an optimized transmission strategy from imperfect\nchannel data, overcoming the limitations of conventional methods that conduct\nchannel estimation and antenna position optimization separately. To balance the\nperformance and overhead, we further extend the proposed framework to optimize\nthe antenna placement based on the statistical CSI. Simulation results\ndemonstrate that the proposed approach consistently outperforms traditional\nbenchmarks in terms of achievable sum-rate of users, especially under limited\nfeedback and sparse channel environments. Notably, it achieves a performance\ncomparable to the widely-adopted gradient-based methods with perfect CSI, while\nmaintaining significantly lower CSI feedback overhead. These results highlight\nthe effectiveness and adaptability of learning-based MA system design for\nfuture wireless systems."}
{"id": "2509.10478", "categories": ["cs.NI", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.10478", "abs": "https://arxiv.org/abs/2509.10478", "authors": ["Oluwaseyi Giwa", "Michael Adewole", "Tobi Awodumila", "Pelumi Aderinto"], "title": "The LLM as a Network Operator: A Vision for Generative AI in the 6G Radio Access Network", "comment": "Submitted to Workshop on AI and ML for Next-Generation Wireless\n  Communications and Networking, NeurIPS 2025", "summary": "The management of future AI-native Next-Generation (NextG) Radio Access\nNetworks (RANs), including 6G and beyond, presents a challenge of immense\ncomplexity that exceeds the capabilities of traditional automation. In\nresponse, we introduce the concept of the LLM-RAN Operator. In this paradigm, a\nLarge Language Model (LLM) is embedded into the RAN control loop to translate\nhigh-level human intents into optimal network actions. Unlike prior empirical\nstudies, we present a formal framework for an LLM-RAN operator that builds on\nearlier work by making guarantees checkable through an adapter aligned with the\nOpen RAN (O-RAN) standard, separating strategic LLM-driven guidance in the\nNon-Real-Time (RT) RAN intelligent controller (RIC) from reactive execution in\nthe Near-RT RIC, including a proposition on policy expressiveness and a theorem\non convergence to stable fixed points. By framing the problem with mathematical\nrigor, our work provides the analytical tools to reason about the feasibility\nand stability of AI-native RAN control. It identifies critical research\nchallenges in safety, real-time performance, and physical-world grounding. This\npaper aims to bridge the gap between AI theory and wireless systems engineering\nin the NextG era, aligning with the AI4NextG vision to develop knowledgeable,\nintent-driven wireless networks that integrate generative AI into the heart of\nthe RAN."}
{"id": "2509.10481", "categories": ["cs.NI", "cs.RO", "cs.SY", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.10481", "abs": "https://arxiv.org/abs/2509.10481", "authors": ["Hongtao Liang", "Yihe Diao", "YuHang Wu", "Fuhui Zhou", "Qihui Wu"], "title": "Synergetic Empowerment: Wireless Communications Meets Embodied Intelligence", "comment": "8 pages, 5 figures", "summary": "Wireless communication is evolving into an agent era, where large-scale\nagents with inherent embodied intelligence are not just users but active\nparticipants. The perfect combination of wireless communication and embodied\nintelligence can achieve a synergetic empowerment and greatly facilitate the\ndevelopment of agent communication. An overview of this synergetic empowerment\nis presented, framing it as a co-evolutionary process that transforms wireless\ncommunication from a simple utility into the digital nervous system of a\ncollective intelligence, while simultaneously elevating isolated agents into a\nunified superorganism with emergent capabilities far exceeding individual\ncontributions. Moreover, we elaborate how embodied intelligence and wireless\ncommunication mutually benefit each other through the lens of the\nperception-cognition-execution (PCE) loop, revealing a fundamental duality\nwhere each PCE stage both challenges network capacity and creates unprecedented\nopportunities for system-wide optimization. Furthermore, critical open issues\nand future research directions are identified."}
{"id": "2509.10587", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.10587", "abs": "https://arxiv.org/abs/2509.10587", "authors": ["Ibne Farabi Shihab"], "title": "MAGNET-KG: Maximum-Entropy Geometric Networks for Temporal Knowledge Graphs: Theoretical Foundations and Mathematical Framework", "comment": null, "summary": "We present a unified theoretical framework for temporal knowledge graphs\ngrounded in maximum-entropy principles, differential geometry, and information\ntheory. We prove a unique characterization of scoring functions via the\nmaximum-entropy principle and establish necessity theorems for specific\ngeometric choices. We further provide rigorous derivations of generalization\nbounds with explicit constants and outline conditions under which consistency\nguarantees hold under temporal dependence. The framework establishes principled\nfoundations for temporal knowledge graph modeling with formal connections to\ndifferential geometric methods."}
{"id": "2509.10481", "categories": ["cs.NI", "cs.RO", "cs.SY", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.10481", "abs": "https://arxiv.org/abs/2509.10481", "authors": ["Hongtao Liang", "Yihe Diao", "YuHang Wu", "Fuhui Zhou", "Qihui Wu"], "title": "Synergetic Empowerment: Wireless Communications Meets Embodied Intelligence", "comment": "8 pages, 5 figures", "summary": "Wireless communication is evolving into an agent era, where large-scale\nagents with inherent embodied intelligence are not just users but active\nparticipants. The perfect combination of wireless communication and embodied\nintelligence can achieve a synergetic empowerment and greatly facilitate the\ndevelopment of agent communication. An overview of this synergetic empowerment\nis presented, framing it as a co-evolutionary process that transforms wireless\ncommunication from a simple utility into the digital nervous system of a\ncollective intelligence, while simultaneously elevating isolated agents into a\nunified superorganism with emergent capabilities far exceeding individual\ncontributions. Moreover, we elaborate how embodied intelligence and wireless\ncommunication mutually benefit each other through the lens of the\nperception-cognition-execution (PCE) loop, revealing a fundamental duality\nwhere each PCE stage both challenges network capacity and creates unprecedented\nopportunities for system-wide optimization. Furthermore, critical open issues\nand future research directions are identified."}
{"id": "2509.10486", "categories": ["cs.NI", "cs.AI", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.10486", "abs": "https://arxiv.org/abs/2509.10486", "authors": ["Pengcheng Luo", "Yunyang Zhao", "Bowen Zhang", "Genke Yang", "Boon-Hee Soong", "Chau Yuen"], "title": "SABR: A Stable Adaptive Bitrate Framework Using Behavior Cloning Pretraining and Reinforcement Learning Fine-Tuning", "comment": null, "summary": "With the advent of 5G, the internet has entered a new video-centric era. From\nshort-video platforms like TikTok to long-video platforms like Bilibili, online\nvideo services are reshaping user consumption habits. Adaptive Bitrate (ABR)\ncontrol is widely recognized as a critical factor influencing Quality of\nExperience (QoE). Recent learning-based ABR methods have attracted increasing\nattention. However, most of them rely on limited network trace sets during\ntraining and overlook the wide-distribution characteristics of real-world\nnetwork conditions, resulting in poor generalization in out-of-distribution\n(OOD) scenarios. To address this limitation, we propose SABR, a training\nframework that combines behavior cloning (BC) pretraining with reinforcement\nlearning (RL) fine-tuning. We also introduce benchmarks, ABRBench-3G and\nABRBench-4G+, which provide wide-coverage training traces and dedicated OOD\ntest sets for assessing robustness to unseen network conditions. Experimental\nresults demonstrate that SABR achieves the best average rank compared with\nPensieve, Comyco, and NetLLM across the proposed benchmarks. These results\nindicate that SABR enables more stable learning across wide distributions and\nimproves generalization to unseen network conditions."}
{"id": "2509.10775", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.10775", "abs": "https://arxiv.org/abs/2509.10775", "authors": ["Xuan Guang", "Jihang Yang", "Ruze Zhang"], "title": "Uniquely-Decodable Coding for Zero-Error Network Function Computation", "comment": "49 pages, 3 figures", "summary": "We consider uniquely-decodable coding for zero-error network function\ncomputation, where in a directed acyclic graph, the single sink node is\nrequired to compute with zero error a target function multiple times, whose\narguments are the information sources generated at a set of source nodes. We\nare interested in the computing capacity from the information theoretic point\nof view, which is defined as the infimum of the maximum expected number of bits\ntransmitted on all the edges for computing the target function once on average.\nWe first prove some new results on clique entropy, in particular, the\nsubstitution lemma of clique entropy for probabilistic graphs with a certain\ncondition. With them, we prove a lower bound on the computing capacity\nassociated with clique entropies of the induced characteristic graphs, where\nthe obtained lower bound is applicable to arbitrary network topologies,\narbitrary information sources, and arbitrary target functions. By refining the\nprobability distribution of information sources, we further strictly improve\nthe obtained lower bound. In addition, we compare uniquely-decodable network\nfunction-computing coding and fixed-length network function-computing coding,\nand show that the former indeed outperforms the latter in terms of the\ncomputing capacity. Therein, we provide a novel graph-theoretic explanation of\nthe key parameter in the best known bound on the computing capacity for\nfixed-length network function-computing codes, which would be helpful to\nimprove the existing results."}
{"id": "2509.10493", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10493", "abs": "https://arxiv.org/abs/2509.10493", "authors": ["Ruiqi Wang", "Jing Ren", "Tongyu Song", "Wenjun Li", "Xiong Wang", "Sheng Wang", "Shizhong Xu"], "title": "Online Learning Based Efficient Resource Allocation for LoRaWAN Network", "comment": null, "summary": "The deployment of large-scale LoRaWAN networks requires jointly optimizing\nconflicting metrics like Packet Delivery Ratio (PDR) and Energy Efficiency (EE)\nby dynamically allocating transmission parameters, including Carrier Frequency,\nSpreading Factor, and Transmission Power. Existing methods often oversimplify\nthis challenge, focusing on a single metric or lacking the adaptability needed\nfor dynamic channel environments, leading to suboptimal performance. To address\nthis, we propose two online learning-based resource allocation frameworks that\nintelligently navigate the PDR-EE trade-off. Our foundational proposal, D-LoRa,\nis a fully distributed framework that models the problem as a Combinatorial\nMulti-Armed Bandit. By decomposing the joint parameter selection and employing\nspecialized, disaggregated reward functions, D-LoRa dramatically reduces\nlearning complexity and enables nodes to autonomously adapt to network\ndynamics. To further enhance performance in LoRaWAN networks, we introduce\nCD-LoRa, a hybrid framework that integrates a lightweight, centralized\ninitialization phase to perform a one-time, quasi-optimal channel assignment\nand action space pruning, thereby accelerating subsequent distributed learning.\nExtensive simulations and real-world field experiments demonstrate the\nsuperiority of our frameworks, showing that D-LoRa excels in non-stationary\nenvironments while CD-LoRa achieves the fastest convergence in stationary\nconditions. In physical deployments, our methods outperform state-of-the-art\nbaselines, improving PDR by up to 10.8% and EE by 26.1%, confirming their\npractical effectiveness for scalable and efficient LoRaWAN networks."}
{"id": "2509.10878", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.10878", "abs": "https://arxiv.org/abs/2509.10878", "authors": ["Homa Nikbakht", "Husheng Li", "Zhu Han", "H. Vincent Poor"], "title": "A Broadcast Channel Framework for MIMO-OFDM Integrated Sensing and Communication", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Integrated sensing and communication (ISAC) is expected to be one of the\nmajor features of 6G wireless networks. In an ISAC system, communications and\nsensing functionalities are jointly performed using the same waveform,\nfrequency band and hardware, thereby enabling various use cases such as in\ncyber physical systems, digital twin and smart cities. A major challenge to the\ndesign and analysis of ISAC is a unified framework that incorporates the two\ndistinct functions. By viewing ISAC as a type of broadcast channel, in this\npaper, we propose a unified ISAC framework in which communication and sensing\nsignals are broadcast to the actual communication users and virtual sensing\nusers. This framework allows the application of existing multiplexing schemes,\nsuch as dirty paper coding (DPC) and frequency division multiplexing (FDM) that\nhave been intensively studied in data communications and information theory.\nWithin this framework, we propose different superposition coding schemes, for\ncases when the sensing waveform is known or unknown to the communication\nreceiver. We propose the waveform optimization algorithms in a multiple-input\nmultiple-output (MIMO) setting accounting for the effects of clutter and\nDoppler shift. The proposed framework is numerically evaluated for different\nschemes under various sensing and communications performance metrics."}
{"id": "2509.10499", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10499", "abs": "https://arxiv.org/abs/2509.10499", "authors": ["Duc-Thinh Ngo", "Kandaraj Piamrat", "Ons Aouedi", "Thomas Hassan", "Philippe Raipin-Parvédy"], "title": "Towards Scalable O-RAN Resource Management: Graph-Augmented Proximal Policy Optimization", "comment": null, "summary": "Open Radio Access Network (O-RAN) architectures enable flexible, scalable,\nand cost-efficient mobile networks by disaggregating and virtualizing baseband\nfunctions. However, this flexibility introduces significant challenges for\nresource management, requiring joint optimization of functional split selection\nand virtualized unit placement under dynamic demands and complex topologies.\nExisting solutions often address these aspects separately or lack scalability\nin large and real-world scenarios. In this work, we propose a novel\nGraph-Augmented Proximal Policy Optimization (GPPO) framework that leverages\nGraph Neural Networks (GNNs) for topology-aware feature extraction and\nintegrates action masking to efficiently navigate the combinatorial decision\nspace. Our approach jointly optimizes functional split and placement decisions,\ncapturing the full complexity of O-RAN resource allocation. Extensive\nexperiments on both small-and large-scale O-RAN scenarios demonstrate that GPPO\nconsistently outperforms state-of-the-art baselines, achieving up to 18% lower\ndeployment cost and 25% higher reward in generalization tests, while\nmaintaining perfect reliability. These results highlight the effectiveness and\nscalability of GPPO for practical O-RAN deployments."}
{"id": "2509.10925", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.10925", "abs": "https://arxiv.org/abs/2509.10925", "authors": ["Abdulkader Hajjouz", "Elena Avksentieva"], "title": "Detectability Thresholds for Network Attacks on Static Graphs and Temporal Networks: Information-Theoretic Limits and Nearly-Optimal Tests", "comment": null, "summary": "We develop a consolidated theory for the detectability of network-borne\nattacks under two canonical observation models: (i) a static graph drawn from\nan Erdos-Renyi background with a planted anomalous community, and (ii) a\ntemporal interaction network modeled by multivariate point processes (Poisson\nor Hawkes). Our main contribution is to match, up to universal constants,\ninformation-theoretic lower and upper bounds that govern when reliable testing\nis possible. In the static case, the core quantity is the accumulated edgewise\nsignal k^2 * chi^2(Bern(p+Delta) || Bern(p)), where chi^2 ~ Delta^2 / [p(1-p)]\nfor small Delta; detection is impossible when this falls below c * log n, and a\nnon-backtracking spectral statistic succeeds above C * log n. In the temporal\ncase, detectability is controlled by the KL information rate I contributed by\ninternal edges over a window of length T, yielding a threshold T I >= log n; a\nlikelihood-based cumulative-sum (CUSUM) test achieves first-order optimal delay\napproximately abs(log alpha) / I at false-alarm level alpha. We also quantify\nrobustness to bounded edge perturbations and outline conditional\nstatistical-computational separations. A brief case study shows how to turn\nthese bounds into concrete design choices."}
{"id": "2509.10507", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10507", "abs": "https://arxiv.org/abs/2509.10507", "authors": ["Vadim Allayev", "Mahbubur Rahman"], "title": "An Internet of Intelligent Things Framework for Decentralized Heterogeneous Platforms", "comment": "11 pages", "summary": "Internet of Intelligent Things (IoIT), an emerging field, combines the\nutility of Internet of Things (IoT) devices with the innovation of embedded AI\nalgorithms. However, it does not come without challenges, and struggles\nregarding available computing resources, energy supply, and storage\nlimitations. In particular, many impediments to IoIT are linked to the\nenergy-efficient deployment of machine learning (ML)/deep learning (DL) models\nin embedded devices. Research has been conducted to design energy-efficient\nIoIT platforms, but these papers often focus on centralized systems, in which\nsome central entity processes all the data and coordinates actions. This can be\nproblematic, e.g., serve as bottleneck or lead to security concerns. In a\ndecentralized system, nodes/devices would self-organize and make their own\ndecisions. Therefore, to address such issues, we propose a heterogeneous,\ndecentralized sensing and monitoring IoIT peer-to-peer mesh network system\nmodel. Nodes in the network will coordinate towards several optimization goals:\nreliability, energy efficiency, and latency. The system employs federated\nlearning to train nodes in a distributed manner, metaheuristics to optimize\ntask allocation and routing paths, and multi-objective optimization to balance\nconflicting performance goals."}
{"id": "2509.11054", "categories": ["cs.IT", "cs.CV", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.11054", "abs": "https://arxiv.org/abs/2509.11054", "authors": ["Thomas Y. Chen"], "title": "Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees", "comment": "ICCV MRR 2025", "summary": "We establish the first information-theoretic limits for multimodal retrieval.\nCasting ranking as lossy source coding, we derive a single-letter\nrate-distortion function $R(D)$ for reciprocal-rank distortion and prove a\nconverse bound that splits into a modality-balanced term plus a skew penalty\n$\\kappa\\,\\Delta H$ capturing entropy imbalance and cross-modal redundancy. We\nthen construct an explicit entropy-weighted stochastic quantizer with an\nadaptive, per-modality temperature decoder; a Blahut-Arimoto argument shows\nthis scheme achieves distortion within $O(n^{-1})$ of $R(D)$ using $n$ training\ntriples. A VC-type analysis yields the first finite-sample excess-risk bound\nwhose complexity scales sub-linearly in both the number of modalities and the\nentropy gap. Experiments on controlled Gaussian mixtures and Flickr30k confirm\nthat our adaptive codes sit within two percentage points of the theoretical\nfrontier, while fixed-temperature and naive CLIP baselines lag significantly.\nTaken together, our results give a principled answer to \"how many bits per\nquery are necessary\" for high-quality multimodal retrieval and provide design\nguidance for entropy-aware contrastive objectives, continual-learning\nretrievers, and retrieval-augmented generators."}
{"id": "2509.10508", "categories": ["cs.NI", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.10508", "abs": "https://arxiv.org/abs/2509.10508", "authors": ["Aathira G Menon", "Prabu Krishnan", "Shyam Lal"], "title": "CAR-BRAINet: Sub-6GHz Aided Spatial Adaptive Beam Prediction with Multi Head Attention for Heterogeneous Vehicular Networks", "comment": "10 pages, 10 figures, 6 tables, (to be published)", "summary": "Heterogeneous Vehicular Networks (HetVNets) play a key role by stacking\ndifferent communication technologies such as sub-6GHz, mm-wave and DSRC to meet\ndiverse connectivity needs of 5G/B5G vehicular networks. HetVNet helps address\nthe humongous user demands-but maintaining a steady connection in a highly\nmobile, real-world conditions remain a challenge. Though there has been ample\nof studies on beam prediction models a dedicated solution for HetVNets is\nsparsely explored. Hence, it is the need of the hour to develop a reliable beam\nprediction solution, specifically for HetVNets. This paper introduces a\nlightweight deep learning-based solution termed-\"CAR-BRAINet\" which consists of\nconvolutional neural networks with a powerful multi-head attention (MHA)\nmechanism. Existing literature on beam prediction is largely studied under a\nlimited, idealised vehicular scenario, often overlooking the real-time\ncomplexities and intricacies of vehicular networks. Therefore, this study aims\nto mimic the complexities of a real-time driving scenario by incorporating key\nfactors such as prominent MAC protocols-3GPP-C-V2X and IEEE 802.11BD, the\neffect of Doppler shifts under high velocity and varying distance and SNR\nlevels into three high-quality dynamic datasets pertaining to urban, rural and\nhighway vehicular networks. CAR-BRAINet performs effectively across all the\nvehicular scenarios, demonstrating precise beam prediction with minimal beam\noverhead and a steady improvement of 17.9422% on the spectral efficiency over\nthe existing methods. Thus, this study justifies the effectiveness of\nCAR-BRAINet in complex HetVNets, offering promising performance without relying\non the location angle and antenna dimensions of the mobile users, and thereby\nreducing the redundant sensor-latency."}
{"id": "2509.11632", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.11632", "abs": "https://arxiv.org/abs/2509.11632", "authors": ["George Vershinin", "Asaf Cohen", "Omer Gurewitz"], "title": "Active Sequential Hypothesis Testing with Non-Homogeneous Costs", "comment": "5 pages, 2 figures", "summary": "We study the Non-Homogeneous Sequential Hypothesis Testing (NHSHT), where a\nsingle active Decision-Maker (DM) selects actions with heterogeneous positive\ncosts to identify the true hypothesis under an average error constraint\n\\(\\delta\\), while minimizing expected total cost paid. Under standard\narguments, we show that the objective decomposes into the product of the mean\nnumber of samples and the mean per-action cost induced by the policy. This\nleads to a key design principle: one should optimize the ratio of expectations\n(expected information gain per expected cost) rather than the expectation of\nper-step information-per-cost (\"bit-per-buck\"), which can be suboptimal. We\nadapt the Chernoff scheme to NHSHT, preserving its classical \\(\\log 1/\\delta\\)\nscaling. In simulations, the adapted scheme reduces mean cost by up to 50\\%\nrelative to the classic Chernoff policy and by up to 90\\% relative to the naive\nbit-per-buck heuristic."}
{"id": "2509.10533", "categories": ["cs.NI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2509.10533", "abs": "https://arxiv.org/abs/2509.10533", "authors": ["Mengyao Li", "Sebastian Troia", "Yingqian Zhang", "Guido Maier"], "title": "Pair-Bid Auction Model for Optimized Network Slicing in 5G RAN", "comment": "accepted by IEEE Symposium on Computers and Communications (ISCC)\n  2025 Next-Generation Multimedia Services at the Edge: Leveraging 5G and\n  Beyond", "summary": "Network slicing is a key 5G technology that enables multiple virtual networks\nto share physical infrastructure, optimizing flexibility and resource\nallocation. This involves Mobile Network Operators (MNO), Mobile Virtual\nNetwork Operators (MVNOs), and end users, where MNO leases network slices to\nMVNOs, and then provides customized services. This work considers end-to-end\nnetwork slicing with a focus on fair sharing and financial-related power\nefficiency, modeled as a two level hierarchical combinatorial auction. At the\nupper level, an MNO auctions slices to competing MVNOs, while at the lower\nlevel, MVNOs allocate resources to end users through their own auctions.\nDynamic user requests add complexity to the process. Our model optimizes\nresource allocation and revenue generation using a pair-bid mechanism and\nVickrey-Clarke-Groves (VCG) pricing. The pair-bid approach enhances competition\nand efficiency, while VCG ensures truthful bidding based on marginal system\nimpact. Simulations validate the model's effectiveness in resource distribution\nand financial performance, showing a 12.5% revenue improvement over the\nbaseline."}
{"id": "2509.11636", "categories": ["cs.IT", "cs.AI", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.11636", "abs": "https://arxiv.org/abs/2509.11636", "authors": ["Shiyao Jiang", "Jian Jiao", "Xingjian Zhang", "Ye Wang", "Dusit Niyato", "Qinyu Zhang"], "title": "Task-Agnostic Learnable Weighted-Knowledge Base Scheme for Robust Semantic Communications", "comment": null, "summary": "With the emergence of diverse and massive data in the upcoming\nsixth-generation (6G) networks, the task-agnostic semantic communication system\nis regarded to provide robust intelligent services. In this paper, we propose a\ntask-agnostic learnable weighted-knowledge base semantic communication (TALSC)\nframework for robust image transmission to address the real-world heterogeneous\ndata bias in KB, including label flipping noise and class imbalance. The TALSC\nframework incorporates a sample confidence module (SCM) as meta-learner and the\nsemantic coding networks as learners. The learners are updated based on the\nempirical knowledge provided by the learnable weighted-KB (LW-KB). Meanwhile,\nthe meta-learner evaluates the significance of samples according to the task\nloss feedback, and adjusts the update strategy of learners to enhance the\nrobustness in semantic recovery for unknown tasks. To strike a balance between\nSCM parameters and precision of significance evaluation, we design an SCM-grid\nextension (SCM-GE) approach by embedding the Kolmogorov-Arnold networks (KAN)\nwithin SCM, which leverages the concept of spline refinement in KAN and enables\nscalable SCM with customizable granularity without retraining. Simulations\ndemonstrate that the TALSC framework effectively mitigates the effects of\nflipping noise and class imbalance in task-agnostic image semantic\ncommunication, achieving at least 12% higher semantic recovery accuracy (SRA)\nand multi-scale structural similarity (MS-SSIM) compared to state-of-the-art\nmethods."}
{"id": "2509.10544", "categories": ["cs.NI", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.10544", "abs": "https://arxiv.org/abs/2509.10544", "authors": ["Alireza Mohammadhosseini", "Jacob Chakareski", "Nicholas Mastronarde"], "title": "ASL360: AI-Enabled Adaptive Streaming of Layered 360° Video over UAV-assisted Wireless Networks", "comment": "This paper has been accepted for presentation at the IEEE Global\n  Communications Conference (GLOBECOM) 2025", "summary": "We propose ASL360, an adaptive deep reinforcement learning-based scheduler\nfor on-demand 360{\\deg} video streaming to mobile VR users in next generation\nwireless networks. We aim to maximize the overall Quality of Experience (QoE)\nof the users served over a UAV-assisted 5G wireless network. Our system model\ncomprises a macro base station (MBS) and a UAV-mounted base station which both\ndeploy mm-Wave transmission to the users. The 360{\\deg} video is encoded into\ndependent layers and segmented tiles, allowing a user to schedule downloads of\neach layer's segments. Furthermore, each user utilizes multiple buffers to\nstore the corresponding video layer's segments. We model the scheduling\ndecision as a Constrained Markov Decision Process (CMDP), where the agent\nselects Base or Enhancement layers to maximize the QoE and use a policy\ngradient-based method (PPO) to find the optimal policy. Additionally, we\nimplement a dynamic adjustment mechanism for cost components, allowing the\nsystem to adaptively balance and prioritize the video quality, buffer\noccupancy, and quality change based on real-time network and streaming session\nconditions. We demonstrate that ASL360 significantly improves the QoE,\nachieving approximately 2 dB higher average video quality, 80% lower average\nrebuffering time, and 57% lower video quality variation, relative to\ncompetitive baseline methods. Our results show the effectiveness of our layered\nand adaptive approach in enhancing the QoE in immersive videostreaming\napplications, particularly in dynamic and challenging network environments."}
{"id": "2509.11681", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.11681", "abs": "https://arxiv.org/abs/2509.11681", "authors": ["Yang Xu", "Haibin Kan", "Guangyue Han"], "title": "Reflexive Partitions Induced by Rank Support and Non-Reflexive Partitions Induced by Rank Weight", "comment": null, "summary": "In this paper, we study partitions of finite modules induced by rank support\nand rank weight. First, we show that partitions induced by rank support are\nmutually dual with respect to suitable non-degenerate pairings, and hence are\nreflexive; moreover, we compute the associated generalized Krawtchouk matrices.\nSimilar results are established for partitions induced by isomorphic relation\nof rank support. These results generalize counterpart results established for\nrow space partitions and rank partitions of matrix spaces over finite fields.\nNext, we show that partitions of free modules over a finite chain ring $R$\ninduced by rank weight are non-reflexive provided that $R$ is not a field;\nmoreover, we characterize the dual partitions explicitly. As a corollary, we\nshow that rank partitions of matrix spaces over $R$ are reflexive if and only\nif $R$ is a field; moreover, two matrices belong to the same member of the dual\npartition if and only if their transposes are equivalent. In particular, we\nshow that opposite to matrices over finite fields, rank metric does not induce\nan association scheme provided that $R$ is not a field, which further settles\nan open question proposed by Blanco-Chac\\'{o}n, Boix, Greferath and Hieta-Aho\nin \\cite{2}."}
{"id": "2509.10559", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.10559", "abs": "https://arxiv.org/abs/2509.10559", "authors": ["Shaba Shaon", "Md Raihan Uddin", "Dinh C. Nguyen", "Seyyedali Hosseinalipour", "Dusit Niyato", "Octavia A. Dobre"], "title": "Empowering AI-Native 6G Wireless Networks with Quantum Federated Learning", "comment": "Under revision at IEEE Wireless Communications Magazine", "summary": "AI-native 6G networks are envisioned to tightly embed artificial intelligence\n(AI) into the wireless ecosystem, enabling real-time, personalized, and\nprivacy-preserving intelligence at the edge. A foundational pillar of this\nvision is federated learning (FL), which allows distributed model training\nacross devices without sharing raw data. However, implementing classical FL\nmethods faces several bottlenecks in heterogeneous dynamic wireless networks,\nincluding limited device compute capacity, unreliable connectivity,\nintermittent communications, and vulnerability to model security and data\nprivacy breaches. This article investigates the integration of quantum\nfederated learning (QFL) into AI-native 6G networks, forming a transformative\nparadigm capable of overcoming these challenges. By leveraging quantum\ntechniques across computing, communication, and cryptography within FL\nworkflows, QFL offers new capabilities along three key dimensions: (i) edge\nintelligence, (ii) network optimization, and (iii) security and privacy, which\nare studied in this work. We further present a case study demonstrating that a\nQFL framework employing the quantum approximate optimization algorithm\noutperforms classical methods in model convergence. We conclude the paper by\nidentifying practical challenges facing QFL deployment, such as quantum state\nfragility, incompatibility with classical protocols, and hardware constraints,\nand then outline key research directions toward its scalable real-world\nadoption."}
{"id": "2509.11757", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.11757", "abs": "https://arxiv.org/abs/2509.11757", "authors": ["José Joaquín Bernal", "Juan Jacobo Simón"], "title": "Permutation decoding of first-order Generalized Reed-Muller codes", "comment": null, "summary": "In [4] we describe a variation of the classical permutation decoding\nalgorithm that can be applied to any binary affine-invariant code; in\nparticular, it can be applied to first-order Reed-Muller codes successfully. In\nthis paper we study how to implement it for the family of first-order\nGeneralized Reed-Muller codes. Then, we give examples which show that we\nimprove the number of errors we can correct in comparison with the known\nresults for this family of codes. Finally, we deal, from a probabilistic point\nof view, with the problem of determining when the algorithm only needs to use a\nsmaller PD-like set."}
{"id": "2509.10617", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.10617", "abs": "https://arxiv.org/abs/2509.10617", "authors": ["Rajendra Paudyal", "Rajendra Upadhyay", "Al Nahian Bin Emran", "Duminda Wijesekera"], "title": "gNB-based Local Breakout for URLLC in industrial 5G", "comment": null, "summary": "Industrial URLLC workloads-coordinated robotics, automated guided vehicles,\nmachine-vision collaboration require sub-5 ms latency and five-nines\nreliability. In standardized 5G Multicast/Broadcast Services, intra-cell group\ntraffic remains anchored in the core using MB-SMF/MB-UPF, and the Application\nFunction. This incurs a core network path and packet delay that is avoidable\nwhen data transmitters and receivers share a cell. We propose a gNB-local\nmulticast breakout that pivots eligible uplink flows to a downlink\npoint-to-multipoint bearer within the gNB, while maintaining authorization,\nmembership, and policy in the 5G core. The design specifies an eligibility\npolicy, configured-grant uplink. 3GPP security and compliance are preserved via\nunchanged control-plane anchors. A latency budget and simulation indicate that\nremoving the backhaul/UPF/AF segment reduces end-to-end latency from\napproximate 6.5-11.5 ms (anchored to the core) to 1.5-4.0 ms (local breakout),\nproducing sub-2 ms averages and a stable gap approximate 10 ms between group\nsizes. The approach offers a practical, standards-aligned path to deterministic\nintra-cell group dissemination in private 5G. We outline multi-cell and\nprototype validation as future work."}
{"id": "2509.12036", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.12036", "abs": "https://arxiv.org/abs/2509.12036", "authors": ["Xintai Chen", "Biqian Feng", "Yongpeng Wu", "Xiang-Gen Xia", "Chengshan Xiao"], "title": "Energy Efficiency Maximization for Movable Antenna-Enhanced MIMO Downlink System Based on S-CSI", "comment": "Accepted by IEEE Transactions on Wireless Communications", "summary": "This paper presents an innovative movable antenna (MA)-enhanced multi-user\nmultiple-input multiple-output (MIMO) downlink system. We aim to maximize the\nenergy efficiency (EE) under statistical channel state information (S-CSI)\nthrough a joint optimization of the precoding matrix and the antenna position\nvectors (APVs). To solve the resulting stochastic problem, we first resort to\ndeterministic equivalent (DE) tecnology to formulate the deterministic\nminorizing function of the system EE and the deterministic function of each\nuser terminal (UT)'s average achievable rate w.r.t. the transmit variables\n(i.e., the precoding matrix and the transmit APV) and the corresponding receive\nAPV, respectively. Then, we propose an alternating optimization (AO) algorithm\nto alternatively optimize the transmit variables and the receive APVs to\nmaximize the formulated deterministic objective functions, respectively.\nFinally, the above AO algorithm is tailored for the single-user scenario. Our\nnumerical results reveal that, the proposed MA-enhanced system can\nsignificantly improve the system EE compared to several benchmark schemes based\non the S-CSI and the optimal performance can be achieved with a finite size of\nmovement regions for MAs."}
{"id": "2509.10914", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.10914", "abs": "https://arxiv.org/abs/2509.10914", "authors": ["Somayeh Kianpisheh", "Tarik Taleb", "Jari Iinatti", "JaeSeung Song"], "title": "Deep Learning based Moving Target Defence for Federated Learning against Poisoning Attack in MEC Systems with a 6G Wireless Model", "comment": null, "summary": "Collaboration opportunities for devices are facilitated with Federated\nLearning (FL). Edge computing facilitates aggregation at edge and reduces\nlatency. To deal with model poisoning attacks, model-based outlier detection\nmechanisms may not operate efficiently with hetereogenous models or in\nrecognition of complex attacks. This paper fosters the defense line against\nmodel poisoning attack by exploiting device-level traffic analysis to\nanticipate the reliability of participants. FL is empowered with a topology\nmutation strategy, as a Moving Target Defence (MTD) strategy to dynamically\nchange the participants in learning. Based on the adoption of recurrent neural\nnetworks for time-series analysis of traffic and a 6G wireless model,\noptimization framework for MTD strategy is given. A deep reinforcement\nmechanism is provided to optimize topology mutation in adaption with the\nanticipated Byzantine status of devices and the communication channel\ncapabilities at devices. For a DDoS attack detection application and under\nBotnet attack at devices level, results illustrate acceptable malicious models\nexclusion and improvement in recognition time and accuracy."}
{"id": "2509.12142", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.12142", "abs": "https://arxiv.org/abs/2509.12142", "authors": ["Denis Kozlov", "Mahtab Mirmohseni", "Rahim Tafazolli"], "title": "Secure Semantic Communication over Wiretap Channels: Rate-Distortion-Equivocation Tradeoff", "comment": null, "summary": "This paper investigates an information-theoretic model of secure\nsemantic-aware communication. For this purpose, we consider the lossy joint\nsource-channel coding (JSCC) of a memoryless semantic source transmitted over a\nmemoryless wiretap channel. The source consists of two correlated parts that\nrepresent semantic and observed aspects of the information. Our model assumes\nseparate fidelity and secrecy constraints on each source component and, in\naddition, encompasses two cases for the source output, in order to evaluate the\nperformance gains if the encoder has an extended access to the source.\nSpecifically, in Case 1, the encoder has direct access only to the samples from\na single (observed) source component, while in Case 2 it has additional direct\naccess to the samples of the underlaying semantic information. We derive\nsingle-letter converse and achievability bounds on the\nrate-distortion-equivocation region. The converse bound explicitly contains\nrate-distortion functions, making it easy to evaluate, especially for some\ncommon distributions. The proposed achievability coding scheme involves novel\nstochastic superposition coding with two private parts to enable analysis of\nthe equivocation for each source component, separately. Our results generalise\nsome of the previously established source and source-channel coding problems.\nThe general results are further specialised to Gaussian and Bernoulli sources\ntransmitted over Gaussian and binary wiretap channels, respectively. The\nnumerical evaluations illustrate the derived bounds for these distributions."}
{"id": "2509.10978", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.10978", "abs": "https://arxiv.org/abs/2509.10978", "authors": ["Abdul Wadud", "Nima Afraz"], "title": "RU Energy Modeling for O-RAN in ns3-oran", "comment": null, "summary": "This paper presents a detailed and flexible power consumption model for Radio\nUnits (RUs) in O-RAN using the ns3-oran simulator. This is the first ns3-oran\nmodel supporting xApp control to perform the RU power modeling. In contrast to\nexisting frameworks like EARTH or VBS-DRX, the proposed framework is RU-centric\nand is parameterized by hardware-level features, such as the number of\ntransceivers, the efficiency of the power amplifier, mmWave overheads, and\nstandby behavior. It enables simulation-driven assessment of energy efficiency\nat various transmit power levels and seamlessly integrates with ns-3's energy\ntracking system. To help upcoming xApp-driven energy management strategies in\nO-RAN installations, numerical research validates the model's capacity to\nrepresent realistic nonlinear power scaling. It identifies ideal operating\npoints for effective RU behavior."}
{"id": "2509.11112", "categories": ["cs.NI", "cs.AI", "cs.ET", "cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.11112", "abs": "https://arxiv.org/abs/2509.11112", "authors": ["Muhammad Baqer Mollah", "Honggang Wang", "Hua Fang"], "title": "Multi-Modal Sensing Aided mmWave Beamforming for V2V Communications with Transformers", "comment": "6 Pages, Accepted to present at 2025 IEEE Global Communications\n  Conference (GLOBECOM), Taipei, Taiwan", "summary": "Beamforming techniques are utilized in millimeter wave (mmWave) communication\nto address the inherent path loss limitation, thereby establishing and\nmaintaining reliable connections. However, adopting standard defined\nbeamforming approach in highly dynamic vehicular environments often incurs high\nbeam training overheads and reduces the available airtime for communications,\nwhich is mainly due to exchanging pilot signals and exhaustive beam\nmeasurements. To this end, we present a multi-modal sensing and fusion learning\nframework as a potential alternative solution to reduce such overheads. In this\nframework, we first extract the features individually from the visual and GPS\ncoordinates sensing modalities by modality specific encoders, and subsequently\nfuse the multimodal features to obtain predicted top-k beams so that the best\nline-of-sight links can be proactively established. To show the\ngeneralizability of the proposed framework, we perform a comprehensive\nexperiment in four different vehicle-to-vehicle (V2V) scenarios from real-world\nmulti-modal sensing and communication dataset. From the experiment, we observe\nthat the proposed framework achieves up to 77.58% accuracy on predicting top-15\nbeams correctly, outperforms single modalities, incurs roughly as low as 2.32\ndB average power loss, and considerably reduces the beam searching space\noverheads by 76.56% for top-15 beams with respect to standard defined approach."}
{"id": "2509.11112", "categories": ["cs.NI", "cs.AI", "cs.ET", "cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.11112", "abs": "https://arxiv.org/abs/2509.11112", "authors": ["Muhammad Baqer Mollah", "Honggang Wang", "Hua Fang"], "title": "Multi-Modal Sensing Aided mmWave Beamforming for V2V Communications with Transformers", "comment": "6 Pages, Accepted to present at 2025 IEEE Global Communications\n  Conference (GLOBECOM), Taipei, Taiwan", "summary": "Beamforming techniques are utilized in millimeter wave (mmWave) communication\nto address the inherent path loss limitation, thereby establishing and\nmaintaining reliable connections. However, adopting standard defined\nbeamforming approach in highly dynamic vehicular environments often incurs high\nbeam training overheads and reduces the available airtime for communications,\nwhich is mainly due to exchanging pilot signals and exhaustive beam\nmeasurements. To this end, we present a multi-modal sensing and fusion learning\nframework as a potential alternative solution to reduce such overheads. In this\nframework, we first extract the features individually from the visual and GPS\ncoordinates sensing modalities by modality specific encoders, and subsequently\nfuse the multimodal features to obtain predicted top-k beams so that the best\nline-of-sight links can be proactively established. To show the\ngeneralizability of the proposed framework, we perform a comprehensive\nexperiment in four different vehicle-to-vehicle (V2V) scenarios from real-world\nmulti-modal sensing and communication dataset. From the experiment, we observe\nthat the proposed framework achieves up to 77.58% accuracy on predicting top-15\nbeams correctly, outperforms single modalities, incurs roughly as low as 2.32\ndB average power loss, and considerably reduces the beam searching space\noverheads by 76.56% for top-15 beams with respect to standard defined approach."}
{"id": "2509.11140", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.11140", "abs": "https://arxiv.org/abs/2509.11140", "authors": ["Balint Bicski", "Adrian Pekar"], "title": "On the Feasibility of Inter-Flow Service Degradation Detection", "comment": "Accepted for presentation at AnServApp 2025 (CNSM 2025)", "summary": "Hardware acceleration in modern networks creates monitoring blind spots by\noffloading flows to a non-observable state, hindering real-time service\ndegradation (SD) detection. To address this, we propose and formalize a novel\ninter-flow correlation framework, built on the hypothesis that observable flows\ncan act as environmental sensors for concurrent, non-observable flows. We\nconduct a comprehensive statistical analysis of this inter-flow landscape,\nrevealing a fundamental trade-off: while the potential for correlation is vast,\nthe most explicit signals (i.e., co-occurring SD events) are sparse and rarely\nperfectly align. Critically, however, our analysis shows these signals\nfrequently precede degradation in the target flow, validating the potential for\ntimely detection. We then evaluate the framework using a standard machine\nlearning model. While the model achieves high classification accuracy, a\nfeature-importance analysis reveals it relies primarily on simpler intra-flow\nfeatures. This key finding demonstrates that harnessing the complex contextual\ninformation requires more than simple models. Our work thus provides not only a\nfoundational analysis of the inter-flow problem but also a clear outline for\nfuture research into the structure-aware models needed to solve it."}
{"id": "2509.11157", "categories": ["cs.NI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11157", "abs": "https://arxiv.org/abs/2509.11157", "authors": ["Youquan Xian", "Xueying Zeng", "Mei Huang", "Aoxiang Zhou", "Xiaoyu Cui", "Peng Liu", "Lei Cui"], "title": "UDFS: Lightweight Representation-Driven Robust Network Traffic Classification", "comment": "Code and Dataset are available at https://github.com/kid1999/UDFS", "summary": "In recent years, sequence features such as packet length have received\nconsiderable attention due to their central role in encrypted traffic analysis.\nExisting sequence modeling approaches can be broadly categorized into\nflow-level and trace-level methods: the former suffer from high feature\nredundancy, limiting their discriminative power, whereas the latter preserve\ncomplete information but incur substantial computational and storage overhead.\nTo address these limitations, we propose the \\textbf{U}p-\\textbf{D}own\n\\textbf{F}low \\textbf{S}equence (\\textbf{UDFS}) representation, which\ncompresses an entire trace into a two-dimensional sequence and characterizes\neach flow by the aggregate of its upstream and downstream traffic, reducing\ncomplexity while maintaining high discriminability. Furthermore, to address the\nchallenge of class-specific discriminability differences, we propose an\nadaptive threshold mechanism that dynamically adjusts training weights and\nrejection boundaries, enhancing the model's classification performance.\nExperimental results demonstrate that the proposed method achieves superior\nclassification performance and robustness on both coarse-grained and\nfine-grained datasets, as well as under concept drift and open-world scenarios.\nCode and Dataset are available at https://github.com/kid1999/UDFS."}
{"id": "2509.11239", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.11239", "abs": "https://arxiv.org/abs/2509.11239", "authors": ["Zhekun Huang", "Milena Radenkovic"], "title": "Multi-Layer Perceptron-Based Relay Node Selection for Next-Generation Intelligent Delay-Tolerant Networks", "comment": null, "summary": "Delay Tolerant Networks (DTNs) are critical for emergency communication in\nhighly dynamic and challenging scenarios characterized by intermittent\nconnectivity, frequent disruptions, and unpredictable node mobility. While some\nprotocols are widely adopted for simplicity and low overhead, their static\nreplication strategy lacks the ability to adaptively distinguish high-quality\nrelay nodes, often leading to inefficient and suboptimal message dissemination.\nTo address this challenge, we propose a novel intelligent routing enhancement\nthat integrates machine learning-based node evaluation into the Spray and Wait\nframework. Several dynamic, core features are extracted from simulation logs\nand are used to train multiple classifiers - Multi-Layer Perceptron (MLP),\nSupport Vector Machine (SVM), and Random Forest (RF) - to predict whether a\nnode is suitable as a relay under dynamic conditions. The trained models are\ndeployed via a lightweight Flask-based RESTful API, enabling real-time,\nadaptive predictions. We implement the enhanced router MLPBasedSprayRouter,\nwhich selectively forwards messages based on the predicted relay quality. A\ncaching mechanism is incorporated to reduce computational overhead and ensure\nstable, low-latency inference. Extensive experiments under realistic emergency\nmobility scenarios demonstrate that the proposed framework significantly\nimproves delivery ratio while reducing average latency compared to the baseline\nprotocols. Among all evaluated classifiers, MLP achieved the most robust\nperformance, consistently outperforming both SVM and RF in terms of accuracy,\nadaptability, and inference speed. These results confirm the novelty and\npracticality of integrating machine learning into DTN routing, paving the way\nfor resilient and intelligent communication systems in smart cities, disaster\nrecovery, and other dynamic environments."}
{"id": "2509.11289", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11289", "abs": "https://arxiv.org/abs/2509.11289", "authors": ["Rashmi Kamran", "Mahesh Ganesh Bhat", "Pranav Jha", "Shana Moothedath", "Manjesh Hanawal", "Prasanna Chaporkar"], "title": "Energy-Aware 6G Network Design: A Survey", "comment": null, "summary": "6th Generation (6G) mobile networks are envisioned to support several new\ncapabilities and data-centric applications for unprecedented number of users,\npotentially raising significant energy efficiency and sustainability concerns.\nThis brings focus on sustainability as one of the key objectives in the their\ndesign. To move towards sustainable solution, research and standardization\ncommunity is focusing on several key issues like energy information monitoring\nand exposure, use of renewable energy, and use of Artificial\nIntelligence/Machine Learning (AI/ML) for improving the energy efficiency in 6G\nnetworks. The goal is to build energy-aware solutions that takes into account\nthe energy information resulting in energy efficient networks. Design of\nenergy-aware 6G networks brings in new challenges like increased overheads in\ngathering and exposing of energy related information, and the associated user\nconsent management. The aim of this paper is to provide a comprehensive survey\nof methods used for design of energy efficient 6G networks, like energy\nharvesting, energy models and parameters, classification of energy-aware\nservices, and AI/ML-based solutions. The survey also includes few use cases\nthat demonstrate the benefits of incorporating energy awareness into network\ndecisions. Several ongoing standardization efforts in 3GPP, ITU, and IEEE are\nincluded to provide insights into the ongoing work and highlight the\nopportunities for new contributions. We conclude this survey with open research\nproblems and challenges that can be explored to make energy-aware design\nfeasible and ensure optimality regarding performance and energy goals for 6G\nnetworks."}
{"id": "2509.11421", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.11421", "abs": "https://arxiv.org/abs/2509.11421", "authors": ["Yusuf Emir Sezgin", "Mehmet Özdem", "Tuğçe Bilen"], "title": "Federated Edge Learning for Predictive Maintenance in 6G Small Cell Networks", "comment": null, "summary": "The rollout of 6G networks introduces unprecedented demands for autonomy,\nreliability, and scalability. However, the transmission of sensitive telemetry\ndata to central servers raises concerns about privacy and bandwidth. To address\nthis, we propose a federated edge learning framework for predictive maintenance\nin 6G small cell networks. The system adopts a Knowledge Defined Networking\n(KDN) architecture in Data, Knowledge, and Control Planes to support\ndecentralized intelligence, telemetry-driven training, and coordinated policy\nenforcement. In the proposed model, each base station independently trains a\nfailure prediction model using local telemetry metrics, including SINR, jitter,\ndelay, and transport block size, without sharing raw data. A threshold-based\nmulti-label encoding scheme enables the detection of concurrent fault\nconditions. We then conduct a comparative analysis of centralized and federated\ntraining strategies to evaluate their performance in this context. A realistic\nsimulation environment is implemented using the ns-3 mmWave module,\nincorporating hybrid user placement and base station fault injection across\nvarious deployment scenarios. The learning pipeline is orchestrated via the\nFlower framework, and model aggregation is performed using the Federated\nAveraging (FedAvg) algorithm. Experimental results demonstrate that the\nfederated model achieves performance comparable to centralized training in\nterms of accuracy and per-label precision, while preserving privacy and\nreducing communication overhead."}
{"id": "2509.10541", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10541", "abs": "https://arxiv.org/abs/2509.10541", "authors": ["V. Benes", "M. Svitek", "A. Michalikova", "M. Melicherik"], "title": "Situation Model of the Transport, Transport Emissions and Meteorological Conditions", "comment": null, "summary": "Air pollution in cities and the possibilities of reducing this pollution\nrepresents one of the most important factors that today's society has to deal\nwith. This paper focuses on a systemic approach to traffic emissions with their\nrelation to meteorological conditions, analyzing the effect of weather on the\nquantity and dispersion of traffic emissions in a city. Using fuzzy inference\nsystems (FIS) the model for prediction of changes in emissions depending on\nvarious conditions is developed. The proposed model is based on traffic,\nmeteorology and emission data measured in Prague, Czech Republic. The main\nobjective of the work is to provide insight into how urban planners and\npolicymakers can plan and manage urban transport more effectively with\nenvironmental protection in mind."}
{"id": "2509.11810", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.11810", "abs": "https://arxiv.org/abs/2509.11810", "authors": ["Ioannis Tsampras", "Georgios Stergiopoulos", "Tanya Politi", "Spyros Denazis"], "title": "Towards Dynamic Urban Scene Synthesis: The Digital Twin Descriptor Service", "comment": "6 pages, 5 figures, 1 table, ISC2 2025 conference", "summary": "Digital twins have been introduced as supporters to city operations, yet\nexisting scene-descriptor formats and digital twin platforms often lack the\nintegration, federation, and adaptable connectivity that urban environments\ndemand. Modern digital twin platforms decouple data streams and representations\ninto separate architectural planes, fusing them only at the visualization layer\nand limiting potential for simulation or further processing of the combined\nassets. At the same time, geometry-centric file standards for digital twin\ndescription, and services built on top of them, focus primarily on explicitly\ndeclaring geometry and additional structural or photorealistic parameters,\nmaking integration with evolving context information a complicated process\nwhile limiting compatibility with newer representation methods. Additionally,\nmulti-provider federation, critical in smart city services where multiple\nstakeholders may control distinct infrastructure or representation assets, is\nsparsely supported. Consequently, most pilots isolate context and\nrepresentation, fusing them per use case with ad hoc components and custom\ndescription files or glue code, which hinders interoperability. To address\nthese gaps, this paper proposes a novel concept, the 'Digital Twin Descriptor\nService (DTDS)' that fuses abstracted references to geometry assets and context\ninformation within a single, extensible descriptor service through NGSI-LD. The\nproposed DTDS provides dynamic and federated integration of context data,\nrepresentations, and runtime synchronization across heterogeneous engines and\nsimulators. This concept paper outlines the DTDS architectural components and\ndescription ontology that enable digital-twin processes in the modern smart\ncity."}
{"id": "2509.10660", "categories": ["cs.AI", "cs.MA", "q-bio.CB"], "pdf": "https://arxiv.org/pdf/2509.10660", "abs": "https://arxiv.org/abs/2509.10660", "authors": ["Nam H. Le", "Patrick Erickson", "Yanbo Zhang", "Michael Levin", "Josh Bongard"], "title": "ZapGPT: Free-form Language Prompting for Simulated Cellular Control", "comment": null, "summary": "Human language is one of the most expressive tools for conveying intent, yet\nmost artificial or biological systems lack mechanisms to interpret or respond\nmeaningfully to it. Bridging this gap could enable more natural forms of\ncontrol over complex, decentralized systems. In AI and artificial life, recent\nwork explores how language can specify high-level goals, but most systems still\ndepend on engineered rewards, task-specific supervision, or rigid command sets,\nlimiting generalization to novel instructions. Similar constraints apply in\nsynthetic biology and bioengineering, where the locus of control is often\ngenomic rather than environmental perturbation.\n  A key open question is whether artificial or biological collectives can be\nguided by free-form natural language alone, without task-specific tuning or\ncarefully designed evaluation metrics. We provide one possible answer here by\nshowing, for the first time, that simple agents' collective behavior can be\nguided by free-form language prompts: one AI model transforms an imperative\nprompt into an intervention that is applied to simulated cells; a second AI\nmodel scores how well the prompt describes the resulting cellular dynamics; and\nthe former AI model is evolved to improve the scores generated by the latter.\n  Unlike previous work, our method does not require engineered fitness\nfunctions or domain-specific prompt design. We show that the evolved system\ngeneralizes to unseen prompts without retraining. By treating natural language\nas a control layer, the system suggests a future in which spoken or written\nprompts could direct computational, robotic, or biological systems to desired\nbehaviors. This work provides a concrete step toward this vision of AI-biology\npartnerships, in which language replaces mathematical objective functions,\nfixed rules, and domain-specific programming."}
{"id": "2509.11969", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.11969", "abs": "https://arxiv.org/abs/2509.11969", "authors": ["Kaining Wang", "Bo Yang", "Zhiwen Yu", "Xuelin Cao", "Mérouane Debbah", "Chau Yuen"], "title": "Optimization for Massive 3D-RIS Deployment: A Generative Diffusion Model-Based Approach", "comment": null, "summary": "Reconfigurable Intelligent Surfaces (RISs) transform the wireless environment\nby modifying the amplitude, phase, and polarization of incoming waves,\nsignificantly improving coverage performance. Notably, optimizing the\ndeployment of RISs becomes vital, but existing optimization methods face\nchallenges such as high computational complexity, limited adaptability to\nchanging environments, and a tendency to converge on local optima. In this\npaper, we propose to optimize the deployment of large-scale 3D RISs using a\ndiffusion model based on probabilistic generative learning. We begin by\ndividing the target area into fixed grids, with each grid corresponding to a\npotential deployment location. Then, a multi-RIS deployment optimization\nproblem is formulated, which is difficult to solve directly. By treating RIS\ndeployment as a conditional generation task, the well-trained diffusion model\ncan generate the distribution of deployment strategies, and thus, the optimal\ndeployment strategy can be obtained by sampling from this distribution.\nSimulation results demonstrate that the proposed diffusion-based method\noutperforms traditional benchmark approaches in terms of exceed ratio and\ngeneralization."}
{"id": "2509.10704", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10704", "abs": "https://arxiv.org/abs/2509.10704", "authors": ["Xingchen Wan", "Han Zhou", "Ruoxi Sun", "Hootan Nakhost", "Ke Jiang", "Rajarishi Sinha", "Sercan Ö. Arık"], "title": "Maestro: Self-Improving Text-to-Image Generation via Agent Orchestration", "comment": "15 pages, 7 figures, 2 tables (22 pages, 9 figures and 3 tables\n  including references and appendices)", "summary": "Text-to-image (T2I) models, while offering immense creative potential, are\nhighly reliant on human intervention, posing significant usability challenges\nthat often necessitate manual, iterative prompt engineering over often\nunderspecified prompts. This paper introduces Maestro, a novel self-evolving\nimage generation system that enables T2I models to autonomously self-improve\ngenerated images through iterative evolution of prompts, using only an initial\nprompt. Maestro incorporates two key innovations: 1) self-critique, where\nspecialized multimodal LLM (MLLM) agents act as 'critics' to identify\nweaknesses in generated images, correct for under-specification, and provide\ninterpretable edit signals, which are then integrated by a 'verifier' agent\nwhile preserving user intent; and 2) self-evolution, utilizing MLLM-as-a-judge\nfor head-to-head comparisons between iteratively generated images, eschewing\nproblematic images, and evolving creative prompt candidates that align with\nuser intents. Extensive experiments on complex T2I tasks using black-box models\ndemonstrate that Maestro significantly improves image quality over initial\nprompts and state-of-the-art automated methods, with effectiveness scaling with\nmore advanced MLLM components. This work presents a robust, interpretable, and\neffective pathway towards self-improving T2I generation."}
{"id": "2507.17426", "categories": ["cs.IT", "cs.LG", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.17426", "abs": "https://arxiv.org/abs/2507.17426", "authors": ["Jaiprakash Nagar", "Zheng Chen", "Marios Kountouris", "Photios A. Stavrou"], "title": "Information Entropy-Based Scheduling for Communication-Efficient Decentralized Learning", "comment": null, "summary": "This paper addresses decentralized stochastic gradient descent (D-SGD) over\nresource-constrained networks by introducing node-based and link-based\nscheduling strategies to enhance communication efficiency. In each iteration of\nthe D-SGD algorithm, only a few disjoint subsets of nodes or links are randomly\nactivated, subject to a given communication cost constraint. We propose a novel\nimportance metric based on information entropy to determine node and link\nscheduling probabilities. We validate the effectiveness of our approach through\nextensive simulations, comparing it against state-of-the-art methods, including\nbetweenness centrality (BC) for node scheduling and \\textit{MATCHA} for link\nscheduling. The results show that our method consistently outperforms the\nBC-based method in the node scheduling case, achieving faster convergence with\nup to 60\\% lower communication budgets. At higher communication budgets (above\n60\\%), our method maintains comparable or superior performance. In the link\nscheduling case, our method delivers results that are superior to or on par\nwith those of \\textit{MATCHA}."}
{"id": "2509.10707", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10707", "abs": "https://arxiv.org/abs/2509.10707", "authors": ["Sajjad Abdoli", "Rudi Cilibrasi", "Rima Al-Shikh"], "title": "Understanding AI Evaluation Patterns: How Different GPT Models Assess Vision-Language Descriptions", "comment": null, "summary": "As AI systems increasingly evaluate other AI outputs, understanding their\nassessment behavior becomes crucial for preventing cascading biases. This study\nanalyzes vision-language descriptions generated by NVIDIA's Describe Anything\nModel and evaluated by three GPT variants (GPT-4o, GPT-4o-mini, GPT-5) to\nuncover distinct \"evaluation personalities\" the underlying assessment\nstrategies and biases each model demonstrates. GPT-4o-mini exhibits systematic\nconsistency with minimal variance, GPT-4o excels at error detection, while\nGPT-5 shows extreme conservatism with high variability. Controlled experiments\nusing Gemini 2.5 Pro as an independent question generator validate that these\npersonalities are inherent model properties rather than artifacts. Cross-family\nanalysis through semantic similarity of generated questions reveals significant\ndivergence: GPT models cluster together with high similarity while Gemini\nexhibits markedly different evaluation strategies. All GPT models demonstrate a\nconsistent 2:1 bias favoring negative assessment over positive confirmation,\nthough this pattern appears family-specific rather than universal across AI\narchitectures. These findings suggest that evaluation competence does not scale\nwith general capability and that robust AI assessment requires diverse\narchitectural perspectives."}
{"id": "2509.11636", "categories": ["cs.IT", "cs.AI", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.11636", "abs": "https://arxiv.org/abs/2509.11636", "authors": ["Shiyao Jiang", "Jian Jiao", "Xingjian Zhang", "Ye Wang", "Dusit Niyato", "Qinyu Zhang"], "title": "Task-Agnostic Learnable Weighted-Knowledge Base Scheme for Robust Semantic Communications", "comment": null, "summary": "With the emergence of diverse and massive data in the upcoming\nsixth-generation (6G) networks, the task-agnostic semantic communication system\nis regarded to provide robust intelligent services. In this paper, we propose a\ntask-agnostic learnable weighted-knowledge base semantic communication (TALSC)\nframework for robust image transmission to address the real-world heterogeneous\ndata bias in KB, including label flipping noise and class imbalance. The TALSC\nframework incorporates a sample confidence module (SCM) as meta-learner and the\nsemantic coding networks as learners. The learners are updated based on the\nempirical knowledge provided by the learnable weighted-KB (LW-KB). Meanwhile,\nthe meta-learner evaluates the significance of samples according to the task\nloss feedback, and adjusts the update strategy of learners to enhance the\nrobustness in semantic recovery for unknown tasks. To strike a balance between\nSCM parameters and precision of significance evaluation, we design an SCM-grid\nextension (SCM-GE) approach by embedding the Kolmogorov-Arnold networks (KAN)\nwithin SCM, which leverages the concept of spline refinement in KAN and enables\nscalable SCM with customizable granularity without retraining. Simulations\ndemonstrate that the TALSC framework effectively mitigates the effects of\nflipping noise and class imbalance in task-agnostic image semantic\ncommunication, achieving at least 12% higher semantic recovery accuracy (SRA)\nand multi-scale structural similarity (MS-SSIM) compared to state-of-the-art\nmethods."}
{"id": "2509.10762", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10762", "abs": "https://arxiv.org/abs/2509.10762", "authors": ["Arlen Kumar", "Leanid Palkhouski"], "title": "AI Answer Engine Citation Behavior An Empirical Analysis of the GEO16 Framework", "comment": null, "summary": "AI answer engines increasingly mediate access to domain knowledge by\ngenerating responses and citing web sources. We introduce GEO-16, a 16 pillar\nauditing framework that converts on page quality signals into banded pillar\nscores and a normalized GEO score G that ranges from 0 to 1. Using 70 product\nintent prompts, we collected 1,702 citations across three engines (Brave\nSummary, Google AI Overviews, and Perplexity) and audited 1,100 unique URLs. In\nour corpus, the engines differed in the GEO quality of the pages they cited,\nand pillars related to Metadata and Freshness, Semantic HTML, and Structured\nData showed the strongest associations with citation. Logistic models with\ndomain clustered standard errors indicate that overall page quality is a strong\npredictor of citation, and simple operating points (for example, G at least\n0.70 combined with at least 12 pillar hits) align with substantially higher\ncitation rates in our data. We report per engine contrasts, vertical effects,\nthreshold analysis, and diagnostics, then translate findings into a practical\nplaybook for publishers. The study is observational and focuses on English\nlanguage B2B SaaS pages; we discuss limitations, threats to validity, and\nreproducibility considerations."}
{"id": "2509.10769", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.10769", "abs": "https://arxiv.org/abs/2509.10769", "authors": ["Tara Bogavelli", "Roshnee Sharma", "Hari Subramani"], "title": "AgentArch: A Comprehensive Benchmark to Evaluate Agent Architectures in Enterprise", "comment": null, "summary": "While individual components of agentic architectures have been studied in\nisolation, there remains limited empirical understanding of how different\ndesign dimensions interact within complex multi-agent systems. This study aims\nto address these gaps by providing a comprehensive enterprise-specific\nbenchmark evaluating 18 distinct agentic configurations across state-of-the-art\nlarge language models. We examine four critical agentic system dimensions:\norchestration strategy, agent prompt implementation (ReAct versus function\ncalling), memory architecture, and thinking tool integration. Our benchmark\nreveals significant model-specific architectural preferences that challenge the\nprevalent one-size-fits-all paradigm in agentic AI systems. It also reveals\nsignificant weaknesses in overall agentic performance on enterprise tasks with\nthe highest scoring models achieving a maximum of only 35.3\\% success on the\nmore complex task and 70.8\\% on the simpler task. We hope these findings inform\nthe design of future agentic systems by enabling more empirically backed\ndecisions regarding architectural components and model selection."}
{"id": "2509.10818", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.10818", "abs": "https://arxiv.org/abs/2509.10818", "authors": ["Boris Kovalerchuk", "Brent D. Fegley"], "title": "LLM Enhancement with Domain Expert Mental Model to Reduce LLM Hallucination with Causal Prompt Engineering", "comment": "25 pages,4 figures, 2 tables", "summary": "Difficult decision-making problems abound in various disciplines and domains.\nThe proliferation of generative techniques, especially large language models\n(LLMs), has excited interest in using them for decision support. However, LLMs\ncannot yet resolve missingness in their training data, leading to\nhallucinations. Retrieval-Augmented Generation (RAG) enhances LLMs by\nincorporating external information retrieval, reducing hallucinations and\nimproving accuracy. Yet, RAG and related methods are only partial solutions, as\nthey may lack access to all necessary sources or key missing information. Even\neveryday issues often challenge LLMs' abilities. Submitting longer prompts with\ncontext and examples is one approach to address knowledge gaps, but designing\neffective prompts is non-trivial and may not capture complex mental models of\ndomain experts. For tasks with missing critical information, LLMs are\ninsufficient, as are many existing systems poorly represented in available\ndocuments. This paper explores how LLMs can make decision-making more\nefficient, using a running example of evaluating whether to respond to a call\nfor proposals. We propose a technology based on optimized human-machine\ndialogue and monotone Boolean and k-valued functions to discover a\ncomputationally tractable personal expert mental model (EMM) of\ndecision-making. Our EMM algorithm for LLM prompt engineering has four steps:\n(1) factor identification, (2) hierarchical structuring of factors, (3)\ngenerating a generalized expert mental model specification, and (4) generating\na detailed generalized expert mental model from that specification."}
{"id": "2509.10837", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10837", "abs": "https://arxiv.org/abs/2509.10837", "authors": ["Yuyin Lu", "Hegang Chen", "Yanghui Rao"], "title": "From Grounding to Skolemization: A Logic-Constrained Vector Symbolic Architecture for Complex Query Answering", "comment": null, "summary": "Complex Query Answering (CQA) over incomplete Knowledge Graphs (KGs),\ntypically formalized as reasoning with Existential First-Order predicate logic\nwith one free variable (EFO$_1$), faces a fundamental trade-off between logical\nsoundness and computational efficiency. This work establishes the\nGrounding-Skolemization dichotomy for systematically analyzing CQA methods\nthrough the lens of formal logic. While Grounding-based methods inherently\nsuffer from combinatorial explosion, most Skolemization-based methods neglect\nto explicitly model Skolem functions and compromise logical consistency. To\naddress these limitations, we propose the Logic-constrained Vector Symbolic\nArchitecture (LVSA), a neuro-symbolic framework that unifies a differentiable\nSkolemization module and a neural negator, as well as a logical\nconstraint-driven optimization protocol to harmonize geometric and logical\nrequirements. Theoretically, LVSA guarantees universality for all EFO$_1$\nqueries. Empirically, it outperforms state-of-the-art Skolemization-based\nmethods and reduces inference costs by orders of magnitude compared to\nGrounding-based baselines."}
{"id": "2509.10875", "categories": ["cs.AI", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2509.10875", "abs": "https://arxiv.org/abs/2509.10875", "authors": ["Jesse Gardner", "Vladimir A. Baulin"], "title": "Is the `Agent' Paradigm a Limiting Framework for Next-Generation Intelligent Systems?", "comment": null, "summary": "The concept of the 'agent' has profoundly shaped Artificial Intelligence (AI)\nresearch, guiding development from foundational theories to contemporary\napplications like Large Language Model (LLM)-based systems. This paper\ncritically re-evaluates the necessity and optimality of this agent-centric\nparadigm. We argue that its persistent conceptual ambiguities and inherent\nanthropocentric biases may represent a limiting framework. We distinguish\nbetween agentic systems (AI inspired by agency, often semi-autonomous, e.g.,\nLLM-based agents), agential systems (fully autonomous, self-producing systems,\ncurrently only biological), and non-agentic systems (tools without the\nimpression of agency). Our analysis, based on a systematic review of relevant\nliterature, deconstructs the agent paradigm across various AI frameworks,\nhighlighting challenges in defining and measuring properties like autonomy and\ngoal-directedness. We argue that the 'agentic' framing of many AI systems,\nwhile heuristically useful, can be misleading and may obscure the underlying\ncomputational mechanisms, particularly in Large Language Models (LLMs). As an\nalternative, we propose a shift in focus towards frameworks grounded in\nsystem-level dynamics, world modeling, and material intelligence. We conclude\nthat investigating non-agentic and systemic frameworks, inspired by complex\nsystems, biology, and unconventional computing, is essential for advancing\ntowards robust, scalable, and potentially non-anthropomorphic forms of general\nintelligence. This requires not only new architectures but also a fundamental\nreconsideration of our understanding of intelligence itself, moving beyond the\nagent metaphor."}
{"id": "2509.10931", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10931", "abs": "https://arxiv.org/abs/2509.10931", "authors": ["Seongho Joo", "Hyukhun Koh", "Kyomin Jung"], "title": "Harmful Prompt Laundering: Jailbreaking LLMs with Abductive Styles and Symbolic Encoding", "comment": "EMNLP 2025", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\ndiverse tasks, but their potential misuse for harmful purposes remains a\nsignificant concern. To strengthen defenses against such vulnerabilities, it is\nessential to investigate universal jailbreak attacks that exploit intrinsic\nweaknesses in the architecture and learning paradigms of LLMs. In response, we\npropose \\textbf{H}armful \\textbf{P}rompt \\textbf{La}undering (HaPLa), a novel\nand broadly applicable jailbreaking technique that requires only black-box\naccess to target models. HaPLa incorporates two primary strategies: 1)\n\\textit{abductive framing}, which instructs LLMs to infer plausible\nintermediate steps toward harmful activities, rather than directly responding\nto explicit harmful queries; and 2) \\textit{symbolic encoding}, a lightweight\nand flexible approach designed to obfuscate harmful content, given that current\nLLMs remain sensitive primarily to explicit harmful keywords. Experimental\nresults show that HaPLa achieves over 95% attack success rate on GPT-series\nmodels and 70% across all targets. Further analysis with diverse symbolic\nencoding rules also reveals a fundamental challenge: it remains difficult to\nsafely tune LLMs without significantly diminishing their helpfulness in\nresponding to benign queries."}
{"id": "2509.10932", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10932", "abs": "https://arxiv.org/abs/2509.10932", "authors": ["Seongho Joo", "Hyukhun Koh", "Kyomin Jung"], "title": "Public Data Assisted Differentially Private In-Context Learning", "comment": "EMNLP 2025 Findings", "summary": "In-context learning (ICL) in Large Language Models (LLMs) has shown\nremarkable performance across various tasks without requiring fine-tuning.\nHowever, recent studies have highlighted the risk of private data leakage\nthrough the prompt in ICL, especially when LLMs are exposed to malicious\nattacks. While differential privacy (DP) provides strong privacy guarantees, it\noften significantly reduces the utility of in-context learning (ICL). To\naddress this challenge, we incorporate task-related public data into the ICL\nframework while maintaining the DP guarantee. Based on this approach, we\npropose a private in-context learning algorithm that effectively balances\nprivacy protection and model utility. Through experiments, we demonstrate that\nour approach significantly improves the utility of private ICL with the\nassistance of public data. Additionally, we show that our method is robust\nagainst membership inference attacks, demonstrating empirical privacy\nprotection."}
{"id": "2509.10972", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10972", "abs": "https://arxiv.org/abs/2509.10972", "authors": ["Ron Sun"], "title": "Enhancing Computational Cognitive Architectures with LLMs: A Case Study", "comment": null, "summary": "Computational cognitive architectures are broadly scoped models of the human\nmind that combine different psychological functionalities (as well as often\ndifferent computational methods for these different functionalities) into one\nunified framework. They structure them in a psychologically plausible and\nvalidated way. However, such models thus far have only limited computational\ncapabilities, mostly limited by the computational tools and techniques that\nwere adopted. More recently, LLMs have proved to be more capable\ncomputationally than any other tools. Thus, in order to deal with both\nreal-world complexity and psychological realism at the same time, incorporating\nLLMs into cognitive architectures naturally becomes an important task. In the\npresent article, a synergistic combination of the Clarion cognitive\narchitecture and LLMs is discussed as a case study. The implicit-explicit\ndichotomy that is fundamental to Clarion is leveraged for a seamless\nintegration of Clarion and LLMs. As a result, computational power of LLMs is\ncombined with psychological nicety of Clarion."}
{"id": "2509.11026", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.11026", "abs": "https://arxiv.org/abs/2509.11026", "authors": ["Ziang Li", "Manasi Ganti", "Zixian Ma", "Helena Vasconcelos", "Qijia He", "Ranjay Krishna"], "title": "Rethinking Human Preference Evaluation of LLM Rationales", "comment": "Published in the XLLM-Reason-Plan Workshop on the Application of LLM\n  Explainability to Reasoning and Planning at COLM 2025", "summary": "Large language models (LLMs) often generate natural language rationales --\nfree-form explanations that help improve performance on complex reasoning tasks\nand enhance interpretability for human users. However, evaluating these\nrationales remains challenging. While recent work has relied on binary\npreference judgments from humans or LLM judges, such evaluations are often\nopaque and coarse-grained, offering limited insight into what makes one\nrationale better than another. In this work, we rethink preference evaluation\nfor LLM-generated rationales by asking: (1) What attributes define good\nrationales? (2) Can human preferences be explained by these attributes? (3) Can\nattribute-based evaluation overcome the limitations of binary comparisons? We\nidentify a set of key rationale attributes from prior literature and assess\nthem using automatic metrics, LLM judgments, and human annotations. We then\nanalyze two standard human preference datasets MT Bench and Chatbot Arena using\nSHAP to identify which attributes best explain human preference outcomes.\nFinally, we re-evaluate model-generated rationales using attribute-specific ELO\nscores, revealing more nuanced model comparisons and insights. Our findings\nsuggest that fine-grained attribute evaluations can better characterize\nrationale quality and guide future research toward more interpretable and\nreliable evaluation practices."}
{"id": "2509.11035", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11035", "abs": "https://arxiv.org/abs/2509.11035", "authors": ["Yu Cui", "Hang Fu", "Haibin Zhang", "Licheng Wang", "Cong Zuo"], "title": "Free-MAD: Consensus-Free Multi-Agent Debate", "comment": null, "summary": "Multi-agent debate (MAD) is an emerging approach to improving the reasoning\ncapabilities of large language models (LLMs). Existing MAD methods rely on\nmultiple rounds of interaction among agents to reach consensus, and the final\noutput is selected by majority voting in the last round. However, this\nconsensus-based design faces several limitations. First, multiple rounds of\ncommunication increases token overhead and limits scalability. Second, due to\nthe inherent conformity of LLMs, agents that initially produce correct\nresponses may be influenced by incorrect ones during the debate process,\ncausing error propagation. Third, majority voting introduces randomness and\nunfairness in the decision-making phase, and can degrade the reasoning\nperformance.\n  To address these issues, we propose \\textsc{Free-MAD}, a novel MAD framework\nthat eliminates the need for consensus among agents. \\textsc{Free-MAD}\nintroduces a novel score-based decision mechanism that evaluates the entire\ndebate trajectory rather than relying on the last round only. This mechanism\ntracks how each agent's reasoning evolves, enabling more accurate and fair\noutcomes. In addition, \\textsc{Free-MAD} reconstructs the debate phase by\nintroducing anti-conformity, a mechanism that enables agents to mitigate\nexcessive influence from the majority. Experiments on eight benchmark datasets\ndemonstrate that \\textsc{Free-MAD} significantly improves reasoning performance\nwhile requiring only a single-round debate and thus reducing token costs. We\nalso show that compared to existing MAD approaches, \\textsc{Free-MAD} exhibits\nimproved robustness in real-world attack scenarios."}
{"id": "2509.11067", "categories": ["cs.AI", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.11067", "abs": "https://arxiv.org/abs/2509.11067", "authors": ["Liangxuan Guo", "Bin Zhu", "Qingqian Tao", "Kangning Liu", "Xun Zhao", "Xianzhe Qin", "Jin Gao", "Guangfu Hao"], "title": "Agentic Lybic: Multi-Agent Execution System with Tiered Reasoning and Orchestration", "comment": null, "summary": "Autonomous agents for desktop automation struggle with complex multi-step\ntasks due to poor coordination and inadequate quality control. We introduce\n\\textsc{Agentic Lybic}, a novel multi-agent system where the entire\narchitecture operates as a finite-state machine (FSM). This core innovation\nenables dynamic orchestration. Our system comprises four components: a\nController, a Manager, three Workers (Technician for code-based operations,\nOperator for GUI interactions, and Analyst for decision support), and an\nEvaluator. The critical mechanism is the FSM-based routing between these\ncomponents, which provides flexibility and generalization by dynamically\nselecting the optimal execution strategy for each subtask. This principled\norchestration, combined with robust quality gating, enables adaptive replanning\nand error recovery. Evaluated officially on the OSWorld benchmark,\n\\textsc{Agentic Lybic} achieves a state-of-the-art 57.07\\% success rate in 50\nsteps, substantially outperforming existing methods. Results demonstrate that\nprincipled multi-agent orchestration with continuous quality control provides\nsuperior reliability for generalized desktop automation in complex computing\nenvironments."}
{"id": "2509.11068", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11068", "abs": "https://arxiv.org/abs/2509.11068", "authors": ["Zan-Kai Chong", "Hiroyuki Ohsaki", "Bryan Ng"], "title": "Tractable Asymmetric Verification for Large Language Models via Deterministic Replicability", "comment": null, "summary": "The landscape of Large Language Models (LLMs) shifts rapidly towards dynamic,\nmulti-agent systems. This introduces a fundamental challenge in establishing\ncomputational trust, specifically how one agent can verify that another's\noutput was genuinely produced by a claimed LLM, and not falsified or generated\nby a cheaper or inferior model. To address this challenge, this paper proposes\na verification framework that achieves tractable asymmetric effort, where the\ncost to verify a computation is substantially lower than the cost to perform\nit. Our approach is built upon the principle of deterministic replicability, a\nproperty inherent to autoregressive models that strictly necessitates a\ncomputationally homogeneous environment where all agents operate on identical\nhardware and software stacks. Within this defined context, our framework\nenables multiple validators to probabilistically audit small, random segments\nof an LLM's output and it distributes the verification workload effectively.\nThe simulations demonstrated that targeted verification can be over 12 times\nfaster than full regeneration, with tunable parameters to adjust the detection\nprobability. By establishing a tractable mechanism for auditable LLM systems,\nour work offers a foundational layer for responsible AI and serves as a\ncornerstone for future research into the more complex, heterogeneous\nmulti-agent systems."}
{"id": "2509.11078", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11078", "abs": "https://arxiv.org/abs/2509.11078", "authors": ["Yunghwei Lai", "Weizhi Ma", "Yang Liu"], "title": "Patient-Zero: A Unified Framework for Real-Record-Free Patient Agent Generation", "comment": null, "summary": "Synthetic data generation using large language models (LLMs) has emerged as a\npromising solution across various domains, particularly in medical field, to\nmitigate data collection challenges. However, existing studies mainly utilize\nLLMs to rewrite and complete existing medical records, where the limitations in\ndata privacy, accuracy, and diversity sill exist, and additionally lack the\nability to interact like real patients. To address these issues, we propose a\nrealistic patient generation framework, Patient-Zero, which requires no real\nmedical records. Patient-Zero first introduces a medically-aligned multi-step\ngeneration architecture, which builds comprehensive patient records through\nhierarchical medical knowledge injection without real medical records. Then, to\noptimize the virtual patient's interaction abilities with humans, Patient-Zero\ndesigns a dynamic updating mechanism to improve the consistency and\nconversational performance. Our framework enables the generation of\ncontextually diverse patient records while maintaining strict medical\ncoherence, supported by adaptive dialogue strategies and real-time clinical\nplausibility verification. Experimental results demonstrate that our model\nachieves good performance in accuracy, diversity, and consistency. After\ntraining with our generated virtual patients, existing models show significant\nimprovements on the MedQA dataset."}
{"id": "2509.11079", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11079", "abs": "https://arxiv.org/abs/2509.11079", "authors": ["Jinwei Su", "Yinghui Xia", "Qizhen Lan", "Xinyuan Song", "Yang Jingsong", "Lewei He", "Tianyu Shi"], "title": "Difficulty-Aware Agent Orchestration in LLM-Powered Workflows", "comment": null, "summary": "Large Language Model (LLM)-based agentic systems have shown strong\ncapabilities across various tasks. However, existing multi-agent frameworks\noften rely on static or task-level workflows, which either over-process simple\nqueries or underperform on complex ones, while also neglecting the\nefficiency-performance trade-offs across heterogeneous LLMs. To address these\nlimitations, we propose Difficulty-Aware Agentic Orchestration (DAAO), a\ndynamic framework that adapts workflow depth, operator selection, and LLM\nassignment based on the difficulty of each input query. DAAO comprises three\ninterdependent modules: a variational autoencoder (VAE) for difficulty\nestimation, a modular operator allocator, and a cost- and performance-aware LLM\nrouter. By leveraging heterogeneous LLMs and dynamically tailoring workflows,\nDAAO enables fine-grained, query-specific reasoning strategies. DAAO\noutperforms prior multi-agent systems in both accuracy and inference efficiency\nacross six benchmarks. We will release our code and implementation details upon\npublication."}
{"id": "2509.11131", "categories": ["cs.AI", "cs.MA", "q-bio.OT"], "pdf": "https://arxiv.org/pdf/2509.11131", "abs": "https://arxiv.org/abs/2509.11131", "authors": ["Benedikt Hartl", "Michael Levin", "Léo Pio-Lopez"], "title": "Neural cellular automata: applications to biology and beyond classical AI", "comment": null, "summary": "Neural Cellular Automata (NCA) represent a powerful framework for modeling\nbiological self-organization, extending classical rule-based systems with\ntrainable, differentiable (or evolvable) update rules that capture the adaptive\nself-regulatory dynamics of living matter. By embedding Artificial Neural\nNetworks (ANNs) as local decision-making centers and interaction rules between\nlocalized agents, NCA can simulate processes across molecular, cellular,\ntissue, and system-level scales, offering a multiscale competency architecture\nperspective on evolution, development, regeneration, aging, morphogenesis, and\nrobotic control. These models not only reproduce biologically inspired target\npatterns but also generalize to novel conditions, demonstrating robustness to\nperturbations and the capacity for open-ended adaptation and reasoning. Given\ntheir immense success in recent developments, we here review current literature\nof NCAs that are relevant primarily for biological or bioengineering\napplications. Moreover, we emphasize that beyond biology, NCAs display robust\nand generalizing goal-directed dynamics without centralized control, e.g., in\ncontrolling or regenerating composite robotic morphologies or even on\ncutting-edge reasoning tasks such as ARC-AGI-1. In addition, the same\nprinciples of iterative state-refinement is reminiscent to modern generative\nArtificial Intelligence (AI), such as probabilistic diffusion models. Their\ngoverning self-regulatory behavior is constraint to fully localized\ninteractions, yet their collective behavior scales into coordinated\nsystem-level outcomes. We thus argue that NCAs constitute a unifying\ncomputationally lean paradigm that not only bridges fundamental insights from\nmultiscale biology with modern generative AI, but have the potential to design\ntruly bio-inspired collective intelligence capable of hierarchical reasoning\nand control."}
{"id": "2509.11135", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11135", "abs": "https://arxiv.org/abs/2509.11135", "authors": ["Jing Xiao", "Chang You", "Zhiyu Chen"], "title": "AlignKT: Explicitly Modeling Knowledge State for Knowledge Tracing with Ideal State Alignment", "comment": null, "summary": "Knowledge Tracing (KT) serves as a fundamental component of Intelligent\nTutoring Systems (ITS), enabling these systems to monitor and understand\nlearners' progress by modeling their knowledge state. However, many existing KT\nmodels primarily focus on fitting the sequences of learners' interactions, and\noften overlook the knowledge state itself. This limitation leads to reduced\ninterpretability and insufficient instructional support from the ITS. To\naddress this challenge, we propose AlignKT, which employs a frontend-to-backend\narchitecture to explicitly model a stable knowledge state. In this approach,\nthe preliminary knowledge state is aligned with an additional criterion.\nSpecifically, we define an ideal knowledge state based on pedagogical theories\nas the alignment criterion, providing a foundation for interpretability. We\nutilize five encoders to implement this set-up, and incorporate a contrastive\nlearning module to enhance the robustness of the alignment process. Through\nextensive experiments, AlignKT demonstrates superior performance, outperforming\nseven KT baselines on three real-world datasets. It achieves state-of-the-art\nresults on two of these datasets and exhibits competitive performance on the\nthird. The code of this work is available at\nhttps://github.com/SCNU203/AlignKT."}
{"id": "2509.11151", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11151", "abs": "https://arxiv.org/abs/2509.11151", "authors": ["Jianxin Li", "Liang Qu", "Taotao Cai", "Zhixue Zhao", "Nur Al Hasan Haldar", "Aneesh Krishna", "Xiangjie Kong", "Flavio Romero Macau", "Tanmoy Chakraborty", "Aniket Deroy", "Binshan Lin", "Karen Blackmore", "Nasimul Noman", "Jingxian Cheng", "Ningning Cui", "Jianliang Xu"], "title": "AI-Generated Content in Cross-Domain Applications: Research Trends, Challenges and Propositions", "comment": null, "summary": "Artificial Intelligence Generated Content (AIGC) has rapidly emerged with the\ncapability to generate different forms of content, including text, images,\nvideos, and other modalities, which can achieve a quality similar to content\ncreated by humans. As a result, AIGC is now widely applied across various\ndomains such as digital marketing, education, and public health, and has shown\npromising results by enhancing content creation efficiency and improving\ninformation delivery. However, there are few studies that explore the latest\nprogress and emerging challenges of AIGC across different domains. To bridge\nthis gap, this paper brings together 16 scholars from multiple disciplines to\nprovide a cross-domain perspective on the trends and challenges of AIGC.\nSpecifically, the contributions of this paper are threefold: (1) It first\nprovides a broader overview of AIGC, spanning the training techniques of\nGenerative AI, detection methods, and both the spread and use of AI-generated\ncontent across digital platforms. (2) It then introduces the societal impacts\nof AIGC across diverse domains, along with a review of existing methods\nemployed in these contexts. (3) Finally, it discusses the key technical\nchallenges and presents research propositions to guide future work. Through\nthese contributions, this vision paper seeks to offer readers a cross-domain\nperspective on AIGC, providing insights into its current research trends,\nongoing challenges, and future directions."}
{"id": "2509.11253", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11253", "abs": "https://arxiv.org/abs/2509.11253", "authors": ["Xiao Liang", "Bangxin Li", "Zixuan Chen", "Hanyue Zheng", "Zhi Ma", "Di Wang", "Cong Tian", "Quan Wang"], "title": "VideoAgent: Personalized Synthesis of Scientific Videos", "comment": null, "summary": "Automating the generation of scientific videos is a crucial yet challenging\ntask for effective knowledge dissemination. However, existing works on document\nautomation primarily focus on static media such as posters and slides, lacking\nmechanisms for personalized dynamic orchestration and multimodal content\nsynchronization. To address these challenges, we introduce VideoAgent, a novel\nmulti-agent framework that synthesizes personalized scientific videos through a\nconversational interface. VideoAgent parses a source paper into a fine-grained\nasset library and, guided by user requirements, orchestrates a narrative flow\nthat synthesizes both static slides and dynamic animations to explain complex\nconcepts. To enable rigorous evaluation, we also propose SciVidEval, the first\ncomprehensive suite for this task, which combines automated metrics for\nmultimodal content quality and synchronization with a Video-Quiz-based human\nevaluation to measure knowledge transfer. Extensive experiments demonstrate\nthat our method significantly outperforms existing commercial scientific video\ngeneration services and approaches human-level quality in scientific\ncommunication."}
{"id": "2509.11311", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.11311", "abs": "https://arxiv.org/abs/2509.11311", "authors": ["Bingchen Wang", "Zi-Yu Khoo", "Bryan Kian Hsiang Low"], "title": "Prompts to Proxies: Emulating Human Preferences via a Compact LLM Ensemble", "comment": "Preprint of work originally submitted to AAAI 2026. Under revision\n  for resubmission to a machine learning venue", "summary": "Large language models (LLMs) have demonstrated promise in emulating\nhuman-like responses across a wide range of tasks. In this paper, we propose a\nnovel alignment framework that treats LLMs as agent proxies for human survey\nrespondents, affording a cost-effective and steerable solution to two pressing\nchallenges in the social sciences: the rising cost of survey deployment and the\ngrowing demographic imbalance in survey response data. Drawing inspiration from\nthe theory of revealed preference, we formulate alignment as a two-stage\nproblem: constructing diverse agent personas called endowments that simulate\nplausible respondent profiles, and selecting a representative subset to\napproximate a ground-truth population based on observed data. To implement the\nparadigm, we introduce P2P, a system that steers LLM agents toward\nrepresentative behavioral patterns using structured prompt engineering,\nentropy-based sampling, and regression-based selection. Unlike\npersonalization-heavy approaches, our alignment approach is\ndemographic-agnostic and relies only on aggregate survey results, offering\nbetter generalizability and parsimony. Beyond improving data efficiency in\nsocial science research, our framework offers a testbed for studying the\noperationalization of pluralistic alignment. We demonstrate the efficacy of our\napproach on real-world opinion survey datasets, showing that our aligned agent\npopulations can reproduce aggregate response patterns with high fidelity and\nexhibit substantial response diversity, even without demographic conditioning."}
{"id": "2509.11330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11330", "abs": "https://arxiv.org/abs/2509.11330", "authors": ["Sudeshna Jana", "Manjira Sinha", "Tirthankar Dasgupta"], "title": "Decoding Plastic Toxicity: An Intelligent Framework for Conflict-Aware Relational Metapath Extraction from Scientific Abstracts", "comment": "11 pages, 6 figures, 4 tables", "summary": "The widespread use of plastics and their persistence in the environment have\nled to the accumulation of micro- and nano-plastics across air, water, and\nsoil, posing serious health risks including respiratory, gastrointestinal, and\nneurological disorders. We propose a novel framework that leverages large\nlanguage models to extract relational metapaths, multi-hop semantic chains\nlinking pollutant sources to health impacts, from scientific abstracts. Our\nsystem identifies and connects entities across diverse contexts to construct\nstructured relational metapaths, which are aggregated into a Toxicity\nTrajectory Graph that traces pollutant propagation through exposure routes and\nbiological systems. Moreover, to ensure consistency and reliability, we\nincorporate a dynamic evidence reconciliation module that resolves semantic\nconflicts arising from evolving or contradictory research findings. Our\napproach demonstrates strong performance in extracting reliable, high-utility\nrelational knowledge from noisy scientific text and offers a scalable solution\nfor mining complex cause-effect structures in domain-specific corpora."}
{"id": "2509.11336", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11336", "abs": "https://arxiv.org/abs/2509.11336", "authors": ["William Farlessyost", "Sebastian Oberst", "Shweta Singh"], "title": "The power of dynamic causality in observer-based design for soft sensor applications", "comment": null, "summary": "This paper introduces a novel framework for optimizing observer-based soft\nsensors through dynamic causality analysis. Traditional approaches to sensor\nselection often rely on linearized observability indices or statistical\ncorrelations that fail to capture the temporal evolution of complex systems. We\naddress this gap by leveraging liquid-time constant (LTC) networks,\ncontinuous-time neural architectures with input-dependent time constants, to\nsystematically identify and prune sensor inputs with minimal causal influence\non state estimation. Our methodology implements an iterative workflow: training\nan LTC observer on candidate inputs, quantifying each input's causal impact\nthrough controlled perturbation analysis, removing inputs with negligible\neffect, and retraining until performance degradation occurs. We demonstrate\nthis approach on three mechanistic testbeds representing distinct physical\ndomains: a harmonically forced spring-mass-damper system, a nonlinear\ncontinuous stirred-tank reactor, and a predator-prey model following the\nstructure of the Lotka-Volterra model, but with seasonal forcing and added\ncomplexity. Results show that our causality-guided pruning consistently\nidentifies minimal sensor sets that align with underlying physics while\nimproving prediction accuracy. The framework automatically distinguishes\nessential physical measurements from noise and determines when derived\ninteraction terms provide complementary versus redundant information. Beyond\ncomputational efficiency, this approach enhances interpretability by grounding\nsensor selection decisions in dynamic causal relationships rather than static\ncorrelations, offering significant benefits for soft sensing applications\nacross process engineering, ecological monitoring, and agricultural domains."}
{"id": "2509.11361", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11361", "abs": "https://arxiv.org/abs/2509.11361", "authors": ["Yichen Han", "Bojun Liu", "Zhengpeng zhou", "Guanyu Liu", "Zeng Zhang", "Yang Yang", "Wenli Wang", "Isaac N Shi", "Yunyan", "Lewei He", "Tianyu Shi"], "title": "MAPGD: Multi-Agent Prompt Gradient Descent for Collaborative Prompt Optimization", "comment": null, "summary": "Prompt engineering is crucial for leveraging large language models (LLMs),\nbut existing methods often rely on a single optimization trajectory, limiting\nadaptability and efficiency while suffering from narrow perspectives, gradient\nconflicts, and high computational cost. We propose MAPGD (Multi-Agent Prompt\nGradient Descent), a framework integrating multi-agent collaboration with\ngradient-based optimization. MAPGD features specialized agents for task\nclarity, example selection, format design, and stylistic refinement; semantic\ngradient coordination to resolve conflicts; bandit-based candidate selection\nfor efficient exploration-exploitation; and theoretical convergence guarantees.\nExperiments on classification, generation, and reasoning tasks show MAPGD\noutperforms single-agent and random baselines in accuracy and efficiency.\nAblations confirm the benefits of gradient fusion, agent specialization, and\nconflict resolution, providing a unified, gradient-inspired multi-agent\napproach to robust and interpretable prompt optimization."}
{"id": "2509.11431", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.11431", "abs": "https://arxiv.org/abs/2509.11431", "authors": ["Aadil Gani Ganie"], "title": "Securing AI Agents: Implementing Role-Based Access Control for Industrial Applications", "comment": null, "summary": "The emergence of Large Language Models (LLMs) has significantly advanced\nsolutions across various domains, from political science to software\ndevelopment. However, these models are constrained by their training data,\nwhich is static and limited to information available up to a specific date.\nAdditionally, their generalized nature often necessitates fine-tuning --\nwhether for classification or instructional purposes -- to effectively perform\nspecific downstream tasks. AI agents, leveraging LLMs as their core, mitigate\nsome of these limitations by accessing external tools and real-time data,\nenabling applications such as live weather reporting and data analysis. In\nindustrial settings, AI agents are transforming operations by enhancing\ndecision-making, predictive maintenance, and process optimization. For example,\nin manufacturing, AI agents enable near-autonomous systems that boost\nproductivity and support real-time decision-making. Despite these advancements,\nAI agents remain vulnerable to security threats, including prompt injection\nattacks, which pose significant risks to their integrity and reliability. To\naddress these challenges, this paper proposes a framework for integrating\nRole-Based Access Control (RBAC) into AI agents, providing a robust security\nguardrail. This framework aims to support the effective and scalable deployment\nof AI agents, with a focus on on-premises implementations."}
{"id": "2509.11459", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11459", "abs": "https://arxiv.org/abs/2509.11459", "authors": ["Chen Jiang", "Kofi Osei", "Sai Deepthi Yeddula", "Dongji Feng", "Wei-Shinn Ku"], "title": "Knowledge-Guided Adaptive Mixture of Experts for Precipitation Prediction", "comment": "13 pages", "summary": "Accurate precipitation forecasting is indispensable in agriculture, disaster\nmanagement, and sustainable strategies. However, predicting rainfall has been\nchallenging due to the complexity of climate systems and the heterogeneous\nnature of multi-source observational data, including radar, satellite imagery,\nand surface-level measurements. The multi-source data vary in spatial and\ntemporal resolution, and they carry domain-specific features, making it\nchallenging for effective integration in conventional deep learning models.\nPrevious research has explored various machine learning techniques for weather\nprediction; however, most struggle with the integration of data with\nheterogeneous modalities. To address these limitations, we propose an Adaptive\nMixture of Experts (MoE) model tailored for precipitation rate prediction. Each\nexpert within the model specializes in a specific modality or spatio-temporal\npattern. We also incorporated a dynamic router that learns to assign inputs to\nthe most relevant experts. Our results show that this modular design enhances\npredictive accuracy and interpretability. In addition to the modeling\nframework, we introduced an interactive web-based visualization tool that\nenables users to intuitively explore historical weather patterns over time and\nspace. The tool was designed to support decision-making for stakeholders in\nclimate-sensitive sectors. We evaluated our approach using a curated multimodal\nclimate dataset capturing real-world conditions during Hurricane Ian in 2022.\nThe benchmark results show that the Adaptive MoE significantly outperformed all\nthe baselines."}
{"id": "2509.11480", "categories": ["cs.AI", "cs.CV", "cs.ET", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.11480", "abs": "https://arxiv.org/abs/2509.11480", "authors": ["Amir Taherin", "Juyi Lin", "Arash Akbari", "Arman Akbari", "Pu Zhao", "Weiwei Chen", "David Kaeli", "Yanzhi Wang"], "title": "Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs", "comment": "To appear in the Asilomar Conference on Signals, Systems, and\n  Computers 2025", "summary": "Vision-Language-Action (VLA) models have emerged as powerful generalist\npolicies for robotic control, yet their performance scaling across model\narchitectures and hardware platforms, as well as their associated power\nbudgets, remain poorly understood. This work presents an evaluation of five\nrepresentative VLA models -- spanning state-of-the-art baselines and two newly\nproposed architectures -- targeting edge and datacenter GPU platforms. Using\nthe LIBERO benchmark, we measure accuracy alongside system-level metrics,\nincluding latency, throughput, and peak memory usage, under varying edge power\nconstraints and high-performance datacenter GPU configurations. Our results\nidentify distinct scaling trends: (1) architectural choices, such as action\ntokenization and model backbone size, strongly influence throughput and memory\nfootprint; (2) power-constrained edge devices exhibit non-linear performance\ndegradation, with some configurations matching or exceeding older datacenter\nGPUs; and (3) high-throughput variants can be achieved without significant\naccuracy loss. These findings provide actionable insights when selecting and\noptimizing VLAs across a range of deployment constraints. Our work challenges\ncurrent assumptions about the superiority of datacenter hardware for robotic\ninference."}
{"id": "2509.11507", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11507", "abs": "https://arxiv.org/abs/2509.11507", "authors": ["Jared Zhu", "Junde Wu"], "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "comment": null, "summary": "Decades' advances in digital health technologies, such as electronic health\nrecords, have largely streamlined routine clinical processes. Yet, most these\nsystems are still hard to learn and use: Clinicians often face the burden of\nmanaging multiple tools, repeating manual actions for each patient, navigating\ncomplicated UI trees to locate functions, and spending significant time on\nadministration instead of caring for patients. The recent rise of large\nlanguage model (LLM) based agents demonstrates exceptional capability in coding\nand computer operation, revealing the potential for humans to interact with\noperating systems and software not by direct manipulation, but by instructing\nagents through natural language. This shift highlights the need for an\nabstraction layer, an agent-computer interface, that translates human language\ninto machine-executable commands. In digital healthcare, however, requires a\nmore domain-specific abstractions that strictly follow trusted clinical\nguidelines and procedural standards to ensure safety, transparency, and\ncompliance. To address this need, we present \\textbf{MedicalOS}, a unified\nagent-based operational system designed as such a domain-specific abstract\nlayer for healthcare. It translates human instructions into pre-defined digital\nhealthcare commands, such as patient inquiry, history retrieval, exam\nmanagement, report generation, referrals, treatment planning, that we wrapped\nas off-the-shelf tools using machine languages (e.g., Python, APIs, MCP,\nLinux). We empirically validate MedicalOS on 214 patient cases across 22\nspecialties, demonstrating high diagnostic accuracy and confidence, clinically\nsound examination requests, and consistent generation of structured reports and\nmedication recommendations. These results highlight MedicalOS as a trustworthy\nand scalable foundation for advancing workflow automation in clinical practice."}
{"id": "2509.11547", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11547", "abs": "https://arxiv.org/abs/2509.11547", "authors": ["Shanmuka Sadhu", "Arca Baran", "Preeti Pandey", "Ayush Kumar"], "title": "Task Decoding based on Eye Movements using Synthetic Data Augmentation", "comment": null, "summary": "Machine learning has been extensively used in various applications related to\neye-tracking research. Understanding eye movement is one of the most\nsignificant subsets of eye-tracking research that reveals the scanning pattern\nof an individual. Researchers have thoroughly analyzed eye movement data to\nunderstand various eye-tracking applications, such as attention mechanisms,\nnavigational behavior, task understanding, etc. The outcome of traditional\nmachine learning algorithms used for decoding tasks based on eye movement data\nhas received a mixed reaction to Yarbus' claim that it is possible to decode\nthe observer's task from their eye movements. In this paper, to support the\nhypothesis by Yarbus, we are decoding tasks categories while generating\nsynthetic data samples using well-known Synthetic Data Generators CTGAN and its\nvariations such as CopulaGAN and Gretel AI Synthetic Data generators on\navailable data from an in-person user study. Our results show that augmenting\nmore eye movement data combined with additional synthetically generated\nimproves classification accuracy even with traditional machine learning\nalgorithms. We see a significant improvement in task decoding accuracy from\n28.1% using Random Forest to 82% using Inception Time when five times more data\nis added in addition to the 320 real eye movement dataset sample. Our proposed\nframework outperforms all the available studies on this dataset because of the\nuse of additional synthetic datasets. We validated our claim with various\nalgorithms and combinations of real and synthetic data to show how decoding\naccuracy increases with the increase in the augmentation of generated data to\nreal data."}
{"id": "2509.11572", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.11572", "abs": "https://arxiv.org/abs/2509.11572", "authors": ["Tuan Bui", "An Nguyen", "Phat Thai", "Minh Hua", "Ngan Pham L. N.", "Ngan Pham T. B.", "Dung Le", "Long Nguyen", "Thanh-Tung Tran", "Thang Bui", "Tho Quan"], "title": "Formal Reasoning for Intelligent QA Systems: A Case Study in the Educational Domain", "comment": "Published at the 2nd ACM Workshop in AI-powered Question & Answering\n  Systems (AIQAM '25), co-located with ACM Multimedia 2025", "summary": "Reasoning is essential for closed-domain QA systems in which procedural\ncorrectness and policy compliance are critical. While large language models\n(LLMs) have shown strong performance on many reasoning tasks, recent work\nreveals that their reasoning traces are often unfaithful - serving more as\nplausible justifications than as causally grounded derivations. Efforts to\ncombine LLMs with symbolic engines (e.g., Prover9, Z3) have improved\nreliability but remain limited to static forms of logic, struggling with\ndynamic, state-based reasoning such as multi-step progressions and conditional\ntransitions.\n  In this paper, we propose MCFR (Model Checking for Formal Reasoning), a\nneuro-symbolic framework that integrates LLMs with model checking to support\nproperty verification. MCFR translates natural language into formal\nspecifications and verifies them over transition models. To support evaluation,\nwe introduce EduMC-QA, a benchmark dataset grounded in real academic\nprocedures. Our results show that MCFR improves reasoning faithfulness and\ninterpretability, offering a viable path toward verifiable QA in high-stakes\nclosed-domain applications. In addition to evaluating MCFR, we compare its\nperformance with state-of-the-art LLMs such as ChatGPT, DeepSeek, and Claude to\ncontextualize its effectiveness."}
{"id": "2509.11575", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11575", "abs": "https://arxiv.org/abs/2509.11575", "authors": ["Ching Chang", "Yidan Shi", "Defu Cao", "Wei Yang", "Jeehyun Hwang", "Haixin Wang", "Jiacheng Pang", "Wei Wang", "Yan Liu", "Wen-Chih Peng", "Tien-Fu Chen"], "title": "A Survey of Reasoning and Agentic Systems in Time Series with Large Language Models", "comment": "This paper is currently under review", "summary": "Time series reasoning treats time as a first-class axis and incorporates\nintermediate evidence directly into the answer. This survey defines the problem\nand organizes the literature by reasoning topology with three families: direct\nreasoning in one step, linear chain reasoning with explicit intermediates, and\nbranch-structured reasoning that explores, revises, and aggregates. The\ntopology is crossed with the main objectives of the field, including\ntraditional time series analysis, explanation and understanding, causal\ninference and decision making, and time series generation, while a compact tag\nset spans these axes and captures decomposition and verification, ensembling,\ntool use, knowledge access, multimodality, agent loops, and LLM alignment\nregimes. Methods and systems are reviewed across domains, showing what each\ntopology enables and where it breaks down in faithfulness or robustness, along\nwith curated datasets, benchmarks, and resources that support study and\ndeployment (https://github.com/blacksnail789521/Time-Series-Reasoning-Survey).\nEvaluation practices that keep evidence visible and temporally aligned are\nhighlighted, and guidance is distilled on matching topology to uncertainty,\ngrounding with observable artifacts, planning for shift and streaming, and\ntreating cost and latency as design budgets. We emphasize that reasoning\nstructures must balance capacity for grounding and self-correction against\ncomputational cost and reproducibility, while future progress will likely\ndepend on benchmarks that tie reasoning quality to utility and on closed-loop\ntestbeds that trade off cost and risk under shift-aware, streaming, and\nlong-horizon settings. Taken together, these directions mark a shift from\nnarrow accuracy toward reliability at scale, enabling systems that not only\nanalyze but also understand, explain, and act on dynamic worlds with traceable\nevidence and credible outcomes."}
{"id": "2509.11595", "categories": ["cs.AI", "cs.CE", "cs.CR", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.11595", "abs": "https://arxiv.org/abs/2509.11595", "authors": ["Sabin Huda", "Ernest Foo", "Zahra Jadidi", "MA Hakim Newton", "Abdul Sattar"], "title": "AMLNet: A Knowledge-Based Multi-Agent Framework to Generate and Detect Realistic Money Laundering Transactions", "comment": null, "summary": "Anti-money laundering (AML) research is constrained by the lack of publicly\nshareable, regulation-aligned transaction datasets. We present AMLNet, a\nknowledge-based multi-agent framework with two coordinated units: a\nregulation-aware transaction generator and an ensemble detection pipeline. The\ngenerator produces 1,090,173 synthetic transactions (approximately 0.16\\%\nlaundering-positive) spanning core laundering phases (placement, layering,\nintegration) and advanced typologies (e.g., structuring, adaptive threshold\nbehavior). Regulatory alignment reaches 75\\% based on AUSTRAC rule coverage\n(Section 4.2), while a composite technical fidelity score of 0.75 summarizes\ntemporal, structural, and behavioral realism components (Section 4.4). The\ndetection ensemble achieves F1 0.90 (precision 0.84, recall 0.97) on the\ninternal test partitions of AMLNet and adapts to the external SynthAML dataset,\nindicating architectural generalizability across different synthetic generation\nparadigms. We provide multi-dimensional evaluation (regulatory, temporal,\nnetwork, behavioral) and release the dataset (Version 1.0,\nhttps://doi.org/10.5281/zenodo.16736515), to advance reproducible and\nregulation-conscious AML experimentation."}
{"id": "2509.11645", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11645", "abs": "https://arxiv.org/abs/2509.11645", "authors": ["Zhaolong Wu", "Pu Luo", "Jason Pui Yin Cheung", "Teng Zhang"], "title": "Adapting and Evaluating Multimodal Large Language Models for Adolescent Idiopathic Scoliosis Self-Management: A Divide and Conquer Framework", "comment": "Accepted by MICCAI 2025 MLLMCP Workshop", "summary": "This study presents the first comprehensive evaluation of Multimodal Large\nLanguage Models (MLLMs) for Adolescent Idiopathic Scoliosis (AIS)\nself-management. We constructed a database of approximately 3,000\nanteroposterior X-rays with diagnostic texts and evaluated five MLLMs through a\n`Divide and Conquer' framework consisting of a visual question-answering task,\na domain knowledge assessment task, and a patient education counseling\nassessment task. Our investigation revealed limitations of MLLMs' ability in\ninterpreting complex spinal radiographs and comprehending AIS care knowledge.\nTo address these, we pioneered enhancing MLLMs with spinal keypoint prompting\nand compiled an AIS knowledge base for retrieval augmented generation (RAG),\nrespectively. Results showed varying effectiveness of visual prompting across\ndifferent architectures, while RAG substantially improved models' performances\non the knowledge assessment task. Our findings indicate current MLLMs are far\nfrom capable in realizing personalized assistant in AIS care. The greatest\nchallenge lies in their abilities to obtain accurate detections of spinal\ndeformity locations (best accuracy: 0.55) and directions (best accuracy: 0.13)."}
{"id": "2509.11719", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11719", "abs": "https://arxiv.org/abs/2509.11719", "authors": ["Bingqing Wei", "Lianmin Chen", "Zhongyu Xia", "Yongtao Wang"], "title": "HeLoFusion: An Efficient and Scalable Encoder for Modeling Heterogeneous and Multi-Scale Interactions in Trajectory Prediction", "comment": null, "summary": "Multi-agent trajectory prediction in autonomous driving requires a\ncomprehensive understanding of complex social dynamics. Existing methods,\nhowever, often struggle to capture the full richness of these dynamics,\nparticularly the co-existence of multi-scale interactions and the diverse\nbehaviors of heterogeneous agents. To address these challenges, this paper\nintroduces HeLoFusion, an efficient and scalable encoder for modeling\nheterogeneous and multi-scale agent interactions. Instead of relying on global\ncontext, HeLoFusion constructs local, multi-scale graphs centered on each\nagent, allowing it to effectively model both direct pairwise dependencies and\ncomplex group-wise interactions (\\textit{e.g.}, platooning vehicles or\npedestrian crowds). Furthermore, HeLoFusion tackles the critical challenge of\nagent heterogeneity through an aggregation-decomposition message-passing scheme\nand type-specific feature networks, enabling it to learn nuanced,\ntype-dependent interaction patterns. This locality-focused approach enables a\nprincipled representation of multi-level social context, yielding powerful and\nexpressive agent embeddings. On the challenging Waymo Open Motion Dataset,\nHeLoFusion achieves state-of-the-art performance, setting new benchmarks for\nkey metrics including Soft mAP and minADE. Our work demonstrates that a\nlocality-grounded architecture, which explicitly models multi-scale and\nheterogeneous interactions, is a highly effective strategy for advancing motion\nforecasting."}
{"id": "2509.11880", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.11880", "abs": "https://arxiv.org/abs/2509.11880", "authors": ["Carlos Celemin", "Joseph Brennan", "Pierluigi Vito Amadori", "Tim Bradley"], "title": "Learning Representations in Video Game Agents with Supervised Contrastive Imitation Learning", "comment": null, "summary": "This paper introduces a novel application of Supervised Contrastive Learning\n(SupCon) to Imitation Learning (IL), with a focus on learning more effective\nstate representations for agents in video game environments. The goal is to\nobtain latent representations of the observations that capture better the\naction-relevant factors, thereby modeling better the cause-effect relationship\nfrom the observations that are mapped to the actions performed by the\ndemonstrator, for example, the player jumps whenever an obstacle appears ahead.\nWe propose an approach to integrate the SupCon loss with continuous output\nspaces, enabling SupCon to operate without constraints regarding the type of\nactions of the environment. Experiments on the 3D games Astro Bot and Returnal,\nand multiple 2D Atari games show improved representation quality, faster\nlearning convergence, and better generalization compared to baseline models\ntrained only with supervised action prediction loss functions."}
{"id": "2509.11914", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11914", "abs": "https://arxiv.org/abs/2509.11914", "authors": ["Yiqun Yao", "Naitong Yu", "Xiang Li", "Xin Jiang", "Xuezhi Fang", "Wenjia Ma", "Xuying Meng", "Jing Li", "Aixin Sun", "Yequan Wang"], "title": "EgoMem: Lifelong Memory Agent for Full-duplex Omnimodal Models", "comment": null, "summary": "We introduce EgoMem, the first lifelong memory agent tailored for full-duplex\nmodels that process real-time omnimodal streams. EgoMem enables real-time\nmodels to recognize multiple users directly from raw audiovisual streams, to\nprovide personalized response, and to maintain long-term knowledge of users'\nfacts, preferences, and social relationships extracted from audiovisual\nhistory. EgoMem operates with three asynchronous processes: (i) a retrieval\nprocess that dynamically identifies user via face and voice, and gathers\nrelevant context from a long-term memory; (ii) an omnimodal dialog process that\ngenerates personalized audio responses based on the retrieved context; and\n(iii) a memory management process that automatically detects dialog boundaries\nfrom omnimodal streams, and extracts necessary information to update the\nlong-term memory. Unlike existing memory agents for LLMs, EgoMem relies\nentirely on raw audiovisual streams, making it especially suitable for\nlifelong, real-time, and embodied scenarios. Experimental results demonstrate\nthat EgoMem's retrieval and memory management modules achieve over 95% accuracy\non the test set. When integrated with a fine-tuned RoboEgo omnimodal chatbot,\nthe system achieves fact-consistency scores above 87% in real-time personalized\ndialogs, establishing a strong baseline for future research."}
{"id": "2509.11922", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11922", "abs": "https://arxiv.org/abs/2509.11922", "authors": ["Xilei Dai", "Ruotian Chen", "Songze Guan", "Wen-Tai Li", "Chau Yuen"], "title": "BuildingGym: An open-source toolbox for AI-based building energy management using reinforcement learning", "comment": null, "summary": "Reinforcement learning (RL) has proven effective for AI-based building energy\nmanagement. However, there is a lack of flexible framework to implement RL\nacross various control problems in building energy management. To address this\ngap, we propose BuildingGym, an open-source tool designed as a\nresearch-friendly and flexible framework for training RL control strategies for\ncommon challenges in building energy management. BuildingGym integrates\nEnergyPlus as its core simulator, making it suitable for both system-level and\nroom-level control. Additionally, BuildingGym is able to accept external\nsignals as control inputs instead of taking the building as a stand-alone\nentity. This feature makes BuildingGym applicable for more flexible\nenvironments, e.g. smart grid and EVs community. The tool provides several\nbuilt-in RL algorithms for control strategy training, simplifying the process\nfor building managers to obtain optimal control strategies. Users can achieve\nthis by following a few straightforward steps to configure BuildingGym for\noptimization control for common problems in the building energy management\nfield. Moreover, AI specialists can easily implement and test state-of-the-art\ncontrol algorithms within the platform. BuildingGym bridges the gap between\nbuilding managers and AI specialists by allowing for the easy configuration and\nreplacement of RL algorithms, simulators, and control environments or problems.\nWith BuildingGym, we efficiently set up training tasks for cooling load\nmanagement, targeting both constant and dynamic cooling load management. The\nbuilt-in algorithms demonstrated strong performance across both tasks,\nhighlighting the effectiveness of BuildingGym in optimizing cooling strategies."}
{"id": "2509.11940", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11940", "abs": "https://arxiv.org/abs/2509.11940", "authors": ["Marcel van Gerven"], "title": "Neuromorphic Intelligence", "comment": "18 pages, 3 figures", "summary": "Neuromorphic computing seeks to replicate the remarkable efficiency,\nflexibility, and adaptability of the human brain in artificial systems. Unlike\nconventional digital approaches, which depend on massive computational and\nenergy resources, neuromorphic systems exploit brain-inspired principles of\ncomputation to achieve orders of magnitude greater energy efficiency. By\ndrawing on insights from artificial intelligence, neuroscience, physics,\nchemistry, and materials science, neuromorphic computing promises to deliver\nintelligent systems that are sustainable, transparent, and widely accessible. A\ncentral challenge, however, is to identify a unifying theoretical framework\ncapable of bridging these diverse disciplines. We argue that dynamical systems\ntheory provides such a foundation. Rooted in differential calculus, it offers a\nprincipled language for modeling inference, learning, and control in both\nnatural and artificial substrates. Within this framework, noise can be\nharnessed as a resource for learning, while differential genetic programming\nenables the discovery of dynamical systems that implement adaptive behaviors.\nEmbracing this perspective paves the way toward emergent neuromorphic\nintelligence, where intelligent behavior arises from the dynamics of physical\nsubstrates, advancing both the science and sustainability of AI."}
{"id": "2509.11941", "categories": ["cs.AI", "cs.CL", "I.2.7; I.2.1"], "pdf": "https://arxiv.org/pdf/2509.11941", "abs": "https://arxiv.org/abs/2509.11941", "authors": ["Ilia Kopanichuk", "Petr Anokhin", "Vladimir Shaposhnikov", "Vladimir Makharev", "Ekaterina Tsapieva", "Iaroslav Bespalov", "Dmitry V. Dylov", "Ivan Oseledets"], "title": "How to Evaluate Medical AI", "comment": "10 pages, 7 fugures", "summary": "The integration of artificial intelligence (AI) into medical diagnostic\nworkflows requires robust and consistent evaluation methods to ensure\nreliability, clinical relevance, and the inherent variability in expert\njudgments. Traditional metrics like precision and recall often fail to account\nfor the inherent variability in expert judgments, leading to inconsistent\nassessments of AI performance. Inter-rater agreement statistics like Cohen's\nKappa are more reliable but they lack interpretability. We introduce Relative\nPrecision and Recall of Algorithmic Diagnostics (RPAD and RRAD) - a new\nevaluation metrics that compare AI outputs against multiple expert opinions\nrather than a single reference. By normalizing performance against inter-expert\ndisagreement, these metrics provide a more stable and realistic measure of the\nquality of predicted diagnosis. In addition to the comprehensive analysis of\ndiagnostic quality measures, our study contains a very important side result.\nOur evaluation methodology allows us to avoid selecting diagnoses from a\nlimited list when evaluating a given case. Instead, both the models being\ntested and the examiners verifying them arrive at a free-form diagnosis. In\nthis automated methodology for establishing the identity of free-form clinical\ndiagnoses, a remarkable 98% accuracy becomes attainable. We evaluate our\napproach using 360 medical dialogues, comparing multiple large language models\n(LLMs) against a panel of physicians. Large-scale study shows that\ntop-performing models, such as DeepSeek-V3, achieve consistency on par with or\nexceeding expert consensus. Moreover, we demonstrate that expert judgments\nexhibit significant variability - often greater than that between AI and\nhumans. This finding underscores the limitations of any absolute metrics and\nsupports the need to adopt relative metrics in medical AI."}
{"id": "2509.11943", "categories": ["cs.AI", "cs.LG", "cs.LO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.11943", "abs": "https://arxiv.org/abs/2509.11943", "authors": ["Antonin Sulc", "Thorsten Hellert"], "title": "Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics", "comment": "10 pages, 1 figure, Scaling Environments for Agents (SEA) Workshop at\n  NeuralIPS", "summary": "The development of intelligent agents, particularly those powered by language\nmodels (LMs), has shown the critical role in various environments that require\nintelligent and autonomous decision. Environments are not passive testing\ngrounds and they represent the data required for agents to learn and exhibit\nvery challenging conditions that require adaptive, complex and autonomous\ncapacity to make decisions. While the paradigm of scaling models and datasets\nhas led to remarkable emergent capabilities, we argue that scaling the\nstructure, fidelity, and logical consistency of agent reasoning within these\nenvironments is a crucial, yet underexplored, dimension of AI research. This\npaper introduces a neuro-symbolic multi-agent architecture where the belief\nstates of individual agents are formally represented as Kripke models. This\nfoundational choice enables them to reason about known concepts of\n\\emph{possibility} and \\emph{necessity} using the formal language of modal\nlogic. In this work, we use of immutable, domain-specific knowledge to make\ninfere information, which is encoded as logical constraints essential for\nproper diagnosis. In the proposed model, we show constraints that actively\nguide the hypothesis generation of LMs, effectively preventing them from\nreaching physically or logically untenable conclusions. In a high-fidelity\nsimulated particle accelerator environment, our system successfully diagnoses\ncomplex, cascading failures by combining the powerful semantic intuition of LMs\nwith the rigorous, verifiable validation of modal logic and a factual world\nmodel and showcasing a viable path toward more robust, reliable, and verifiable\nautonomous agents."}
{"id": "2509.11944", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11944", "abs": "https://arxiv.org/abs/2509.11944", "authors": ["Susanta Mitra"], "title": "Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare", "comment": null, "summary": "Healthcare and medicine are multimodal disciplines that deal with multimodal\ndata for reasoning and diagnosing multiple diseases. Although some multimodal\nreasoning models have emerged for reasoning complex tasks in scientific\ndomains, their applications in the healthcare domain remain limited and fall\nshort in correct reasoning for diagnosis. To address the challenges of\nmultimodal medical reasoning for correct diagnosis and assist the healthcare\nprofessionals, a novel temporal graph-based reasoning process modelled through\na directed graph has been proposed in the current work. It helps in\naccommodating dynamic changes in reasons through backtracking, refining the\nreasoning content, and creating new or deleting existing reasons to reach the\nbest recommendation or answer. Again, consideration of multimodal data at\ndifferent time points can enable tracking and analysis of patient health and\ndisease progression. Moreover, the proposed multi-agent temporal reasoning\nframework provides task distributions and a cross-validation mechanism to\nfurther enhance the accuracy of reasoning outputs. A few basic experiments and\nanalysis results justify the novelty and practical utility of the proposed\npreliminary approach."}
{"id": "2509.11973", "categories": ["cs.AI", "cs.MM", "cs.SD"], "pdf": "https://arxiv.org/pdf/2509.11973", "abs": "https://arxiv.org/abs/2509.11973", "authors": ["Markus J. Buehler"], "title": "MusicSwarm: Biologically Inspired Intelligence for Music Composition", "comment": null, "summary": "We show that coherent, long-form musical composition can emerge from a\ndecentralized swarm of identical, frozen foundation models that coordinate via\nstigmergic, peer-to-peer signals, without any weight updates. We compare a\ncentralized multi-agent system with a global critic to a fully decentralized\nswarm in which bar-wise agents sense and deposit harmonic, rhythmic, and\nstructural cues, adapt short-term memory, and reach consensus. Across symbolic,\naudio, and graph-theoretic analyses, the swarm yields superior quality while\ndelivering greater diversity and structural variety and leads across creativity\nmetrics. The dynamics contract toward a stable configuration of complementary\nroles, and self-similarity networks reveal a small-world architecture with\nefficient long-range connectivity and specialized bridging motifs, clarifying\nhow local novelties consolidate into global musical form. By shifting\nspecialization from parameter updates to interaction rules, shared memory, and\ndynamic consensus, MusicSwarm provides a compute- and data-efficient route to\nlong-horizon creative structure that is immediately transferable beyond music\nto collaborative writing, design, and scientific discovery."}
{"id": "2509.12034", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12034", "abs": "https://arxiv.org/abs/2509.12034", "authors": ["Emmanuel Adjei Domfeh", "Christopher L. Dancy"], "title": "Human-AI Use Patterns for Decision-Making in Disaster Scenarios: A Systematic Review", "comment": "10 pages, 2 figures", "summary": "In high-stakes disaster scenarios, timely and informed decision-making is\ncritical yet often challenged by uncertainty, dynamic environments, and limited\nresources. This paper presents a systematic review of Human-AI collaboration\npatterns that support decision-making across all disaster management phases.\nDrawing from 51 peer-reviewed studies, we identify four major categories:\nHuman-AI Decision Support Systems, Task and Resource Coordination, Trust and\nTransparency, and Simulation and Training. Within these, we analyze\nsub-patterns such as cognitive-augmented intelligence, multi-agent\ncoordination, explainable AI, and virtual training environments. Our review\nhighlights how AI systems may enhance situational awareness, improves response\nefficiency, and support complex decision-making, while also surfacing critical\nlimitations in scalability, interpretability, and system interoperability. We\nconclude by outlining key challenges and future research directions,\nemphasizing the need for adaptive, trustworthy, and context-aware Human-AI\nsystems to improve disaster resilience and equitable recovery outcomes."}
{"id": "2509.12060", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12060", "abs": "https://arxiv.org/abs/2509.12060", "authors": ["Wei Cai", "Shujuan Liu", "Jian Zhao", "Ziyan Shi", "Yusheng Zhao", "Yuchen Yuan", "Tianle Zhang", "Chi Zhang", "Xuelong Li"], "title": "When Safe Unimodal Inputs Collide: Optimizing Reasoning Chains for Cross-Modal Safety in Multimodal Large Language Models", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) are susceptible to the implicit\nreasoning risk, wherein innocuous unimodal inputs synergistically assemble into\nrisky multimodal data that produce harmful outputs. We attribute this\nvulnerability to the difficulty of MLLMs maintaining safety alignment through\nlong-chain reasoning. To address this issue, we introduce\nSafe-Semantics-but-Unsafe-Interpretation (SSUI), the first dataset featuring\ninterpretable reasoning paths tailored for such a cross-modal challenge. A\nnovel training framework, Safety-aware Reasoning Path Optimization (SRPO), is\nalso designed based on the SSUI dataset to align the MLLM's internal reasoning\nprocess with human safety values. Experimental results show that our\nSRPO-trained models achieve state-of-the-art results on key safety benchmarks,\nincluding the proposed Reasoning Path Benchmark (RSBench), significantly\noutperforming both open-source and top-tier commercial MLLMs."}
{"id": "2509.12091", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12091", "abs": "https://arxiv.org/abs/2509.12091", "authors": ["Hamied Nabizada", "Lasse Beers", "Alain Chahine", "Felix Gehlhoff", "Oliver Niggemann", "Alexander Fay"], "title": "Bridging Engineering and AI Planning through Model-Based Knowledge Transformation for the Validation of Automated Production System Variants", "comment": "Presented at the KEPS-Workshop, ICAPS 2025", "summary": "Engineering models created in Model-Based Systems Engineering (MBSE)\nenvironments contain detailed information about system structure and behavior.\nHowever, they typically lack symbolic planning semantics such as preconditions,\neffects, and constraints related to resource availability and timing. This\nlimits their ability to evaluate whether a given system variant can fulfill\nspecific tasks and how efficiently it performs compared to alternatives.\n  To address this gap, this paper presents a model-driven method that enables\nthe specification and automated generation of symbolic planning artifacts\nwithin SysML-based engineering models. A dedicated SysML profile introduces\nreusable stereotypes for core planning constructs. These are integrated into\nexisting model structures and processed by an algorithm that generates a valid\ndomain file and a corresponding problem file in Planning Domain Definition\nLanguage (PDDL). In contrast to previous approaches that rely on manual\ntransformations or external capability models, the method supports native\nintegration and maintains consistency between engineering and planning\nartifacts.\n  The applicability of the method is demonstrated through a case study from\naircraft assembly. The example illustrates how existing engineering models are\nenriched with planning semantics and how the proposed workflow is applied to\ngenerate consistent planning artifacts from these models. The generated\nplanning artifacts enable the validation of system variants through AI\nplanning."}
{"id": "2509.12104", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12104", "abs": "https://arxiv.org/abs/2509.12104", "authors": ["Zongyue Xue", "Siyuan Zheng", "Shaochun Wang", "Yiran Hu", "Shenran Wang", "Yuxin Yao", "Haitao Li", "Qingyao Ai", "Yiqun Liu", "Yun Liu", "Weixing Shen"], "title": "JustEva: A Toolkit to Evaluate LLM Fairness in Legal Knowledge Inference", "comment": "This paper has been accepted at CIKM 2025 (Demo Track)", "summary": "The integration of Large Language Models (LLMs) into legal practice raises\npressing concerns about judicial fairness, particularly due to the nature of\ntheir \"black-box\" processes. This study introduces JustEva, a comprehensive,\nopen-source evaluation toolkit designed to measure LLM fairness in legal tasks.\nJustEva features several advantages: (1) a structured label system covering 65\nextra-legal factors; (2) three core fairness metrics - inconsistency, bias, and\nimbalanced inaccuracy; (3) robust statistical inference methods; and (4)\ninformative visualizations. The toolkit supports two types of experiments,\nenabling a complete evaluation workflow: (1) generating structured outputs from\nLLMs using a provided dataset, and (2) conducting statistical analysis and\ninference on LLMs' outputs through regression and other statistical methods.\nEmpirical application of JustEva reveals significant fairness deficiencies in\ncurrent LLMs, highlighting the lack of fair and trustworthy LLM legal tools.\nJustEva offers a convenient tool and methodological foundation for evaluating\nand improving algorithmic fairness in the legal domain."}
{"id": "2509.12179", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.12179", "abs": "https://arxiv.org/abs/2509.12179", "authors": ["Yubo Li", "Weiyi Song"], "title": "Co-Alignment: Rethinking Alignment as Bidirectional Human-AI Cognitive Adaptation", "comment": null, "summary": "Current AI alignment through RLHF follows a single directional paradigm that\nAI conforms to human preferences while treating human cognition as fixed. We\npropose a shift to co-alignment through Bidirectional Cognitive Alignment\n(BiCA), where humans and AI mutually adapt. BiCA uses learnable protocols,\nrepresentation mapping, and KL-budget constraints for controlled co-evolution.\nIn collaborative navigation, BiCA achieved 85.5% success versus 70.3% baseline,\nwith 230% better mutual adaptation and 332% better protocol convergence.\nEmergent protocols outperformed handcrafted ones by 84%, while bidirectional\nadaptation unexpectedly improved safety (+23% out-of-distribution robustness).\nThe 46% synergy improvement demonstrates optimal collaboration exists at the\nintersection, not union, of human and AI capabilities, validating the shift\nfrom single-directional to co-alignment paradigms."}
{"id": "2509.12194", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.12194", "abs": "https://arxiv.org/abs/2509.12194", "authors": ["Thomas A. Buckley", "Riccardo Conci", "Peter G. Brodeur", "Jason Gusdorf", "Sourik Beltrán", "Bita Behrouzi", "Byron Crowe", "Jacob Dockterman", "Muzzammil Muhammad", "Sarah Ohnigian", "Andrew Sanchez", "James A. Diao", "Aashna P. Shah", "Daniel Restrepo", "Eric S. Rosenberg", "Andrew S. Lea", "Marinka Zitnik", "Scott H. Podolsky", "Zahir Kanjee", "Raja-Elie E. Abdulnour", "Jacob M. Koshy", "Adam Rodman", "Arjun K. Manrai"], "title": "Advancing Medical Artificial Intelligence Using a Century of Cases", "comment": null, "summary": "BACKGROUND: For over a century, the New England Journal of Medicine\nClinicopathological Conferences (CPCs) have tested the reasoning of expert\nphysicians and, recently, artificial intelligence (AI). However, prior AI\nevaluations have focused on final diagnoses without addressing the multifaceted\nreasoning and presentation skills required of expert discussants.\n  METHODS: Using 7102 CPCs (1923-2025) and 1021 Image Challenges (2006-2025),\nwe conducted extensive physician annotation and automated processing to create\nCPC-Bench, a physician-validated benchmark spanning 10 text-based and\nmultimodal tasks, against which we evaluated leading large language models\n(LLMs). Then, we developed \"Dr. CaBot,\" an AI discussant designed to produce\nwritten and slide-based video presentations using only the case presentation,\nmodeling the role of the human expert in these cases.\n  RESULTS: When challenged with 377 contemporary CPCs, o3 (OpenAI) ranked the\nfinal diagnosis first in 60% of cases and within the top ten in 84% of cases,\noutperforming a 20-physician baseline; next-test selection accuracy reached\n98%. Event-level physician annotations quantified AI diagnostic accuracy per\nunit of information. Performance was lower on literature search and image\ntasks; o3 and Gemini 2.5 Pro (Google) achieved 67% accuracy on image\nchallenges. In blinded comparisons of CaBot vs. human expert-generated text,\nphysicians misclassified the source of the differential in 46 of 62 (74%) of\ntrials, and scored CaBot more favorably across quality dimensions. To promote\nresearch, we are releasing CaBot and CPC-Bench.\n  CONCLUSIONS: LLMs exceed physician performance on complex text-based\ndifferential diagnosis and convincingly emulate expert medical presentations,\nbut image interpretation and literature retrieval remain weaker. CPC-Bench and\nCaBot may enable transparent and continued tracking of progress in medical AI."}
{"id": "2509.10486", "categories": ["cs.NI", "cs.AI", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.10486", "abs": "https://arxiv.org/abs/2509.10486", "authors": ["Pengcheng Luo", "Yunyang Zhao", "Bowen Zhang", "Genke Yang", "Boon-Hee Soong", "Chau Yuen"], "title": "SABR: A Stable Adaptive Bitrate Framework Using Behavior Cloning Pretraining and Reinforcement Learning Fine-Tuning", "comment": null, "summary": "With the advent of 5G, the internet has entered a new video-centric era. From\nshort-video platforms like TikTok to long-video platforms like Bilibili, online\nvideo services are reshaping user consumption habits. Adaptive Bitrate (ABR)\ncontrol is widely recognized as a critical factor influencing Quality of\nExperience (QoE). Recent learning-based ABR methods have attracted increasing\nattention. However, most of them rely on limited network trace sets during\ntraining and overlook the wide-distribution characteristics of real-world\nnetwork conditions, resulting in poor generalization in out-of-distribution\n(OOD) scenarios. To address this limitation, we propose SABR, a training\nframework that combines behavior cloning (BC) pretraining with reinforcement\nlearning (RL) fine-tuning. We also introduce benchmarks, ABRBench-3G and\nABRBench-4G+, which provide wide-coverage training traces and dedicated OOD\ntest sets for assessing robustness to unseen network conditions. Experimental\nresults demonstrate that SABR achieves the best average rank compared with\nPensieve, Comyco, and NetLLM across the proposed benchmarks. These results\nindicate that SABR enables more stable learning across wide distributions and\nimproves generalization to unseen network conditions."}
{"id": "2509.10493", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10493", "abs": "https://arxiv.org/abs/2509.10493", "authors": ["Ruiqi Wang", "Jing Ren", "Tongyu Song", "Wenjun Li", "Xiong Wang", "Sheng Wang", "Shizhong Xu"], "title": "Online Learning Based Efficient Resource Allocation for LoRaWAN Network", "comment": null, "summary": "The deployment of large-scale LoRaWAN networks requires jointly optimizing\nconflicting metrics like Packet Delivery Ratio (PDR) and Energy Efficiency (EE)\nby dynamically allocating transmission parameters, including Carrier Frequency,\nSpreading Factor, and Transmission Power. Existing methods often oversimplify\nthis challenge, focusing on a single metric or lacking the adaptability needed\nfor dynamic channel environments, leading to suboptimal performance. To address\nthis, we propose two online learning-based resource allocation frameworks that\nintelligently navigate the PDR-EE trade-off. Our foundational proposal, D-LoRa,\nis a fully distributed framework that models the problem as a Combinatorial\nMulti-Armed Bandit. By decomposing the joint parameter selection and employing\nspecialized, disaggregated reward functions, D-LoRa dramatically reduces\nlearning complexity and enables nodes to autonomously adapt to network\ndynamics. To further enhance performance in LoRaWAN networks, we introduce\nCD-LoRa, a hybrid framework that integrates a lightweight, centralized\ninitialization phase to perform a one-time, quasi-optimal channel assignment\nand action space pruning, thereby accelerating subsequent distributed learning.\nExtensive simulations and real-world field experiments demonstrate the\nsuperiority of our frameworks, showing that D-LoRa excels in non-stationary\nenvironments while CD-LoRa achieves the fastest convergence in stationary\nconditions. In physical deployments, our methods outperform state-of-the-art\nbaselines, improving PDR by up to 10.8% and EE by 26.1%, confirming their\npractical effectiveness for scalable and efficient LoRaWAN networks."}
{"id": "2509.10499", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10499", "abs": "https://arxiv.org/abs/2509.10499", "authors": ["Duc-Thinh Ngo", "Kandaraj Piamrat", "Ons Aouedi", "Thomas Hassan", "Philippe Raipin-Parvédy"], "title": "Towards Scalable O-RAN Resource Management: Graph-Augmented Proximal Policy Optimization", "comment": null, "summary": "Open Radio Access Network (O-RAN) architectures enable flexible, scalable,\nand cost-efficient mobile networks by disaggregating and virtualizing baseband\nfunctions. However, this flexibility introduces significant challenges for\nresource management, requiring joint optimization of functional split selection\nand virtualized unit placement under dynamic demands and complex topologies.\nExisting solutions often address these aspects separately or lack scalability\nin large and real-world scenarios. In this work, we propose a novel\nGraph-Augmented Proximal Policy Optimization (GPPO) framework that leverages\nGraph Neural Networks (GNNs) for topology-aware feature extraction and\nintegrates action masking to efficiently navigate the combinatorial decision\nspace. Our approach jointly optimizes functional split and placement decisions,\ncapturing the full complexity of O-RAN resource allocation. Extensive\nexperiments on both small-and large-scale O-RAN scenarios demonstrate that GPPO\nconsistently outperforms state-of-the-art baselines, achieving up to 18% lower\ndeployment cost and 25% higher reward in generalization tests, while\nmaintaining perfect reliability. These results highlight the effectiveness and\nscalability of GPPO for practical O-RAN deployments."}
{"id": "2509.10507", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10507", "abs": "https://arxiv.org/abs/2509.10507", "authors": ["Vadim Allayev", "Mahbubur Rahman"], "title": "An Internet of Intelligent Things Framework for Decentralized Heterogeneous Platforms", "comment": "11 pages", "summary": "Internet of Intelligent Things (IoIT), an emerging field, combines the\nutility of Internet of Things (IoT) devices with the innovation of embedded AI\nalgorithms. However, it does not come without challenges, and struggles\nregarding available computing resources, energy supply, and storage\nlimitations. In particular, many impediments to IoIT are linked to the\nenergy-efficient deployment of machine learning (ML)/deep learning (DL) models\nin embedded devices. Research has been conducted to design energy-efficient\nIoIT platforms, but these papers often focus on centralized systems, in which\nsome central entity processes all the data and coordinates actions. This can be\nproblematic, e.g., serve as bottleneck or lead to security concerns. In a\ndecentralized system, nodes/devices would self-organize and make their own\ndecisions. Therefore, to address such issues, we propose a heterogeneous,\ndecentralized sensing and monitoring IoIT peer-to-peer mesh network system\nmodel. Nodes in the network will coordinate towards several optimization goals:\nreliability, energy efficiency, and latency. The system employs federated\nlearning to train nodes in a distributed manner, metaheuristics to optimize\ntask allocation and routing paths, and multi-objective optimization to balance\nconflicting performance goals."}
{"id": "2509.10508", "categories": ["cs.NI", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.10508", "abs": "https://arxiv.org/abs/2509.10508", "authors": ["Aathira G Menon", "Prabu Krishnan", "Shyam Lal"], "title": "CAR-BRAINet: Sub-6GHz Aided Spatial Adaptive Beam Prediction with Multi Head Attention for Heterogeneous Vehicular Networks", "comment": "10 pages, 10 figures, 6 tables, (to be published)", "summary": "Heterogeneous Vehicular Networks (HetVNets) play a key role by stacking\ndifferent communication technologies such as sub-6GHz, mm-wave and DSRC to meet\ndiverse connectivity needs of 5G/B5G vehicular networks. HetVNet helps address\nthe humongous user demands-but maintaining a steady connection in a highly\nmobile, real-world conditions remain a challenge. Though there has been ample\nof studies on beam prediction models a dedicated solution for HetVNets is\nsparsely explored. Hence, it is the need of the hour to develop a reliable beam\nprediction solution, specifically for HetVNets. This paper introduces a\nlightweight deep learning-based solution termed-\"CAR-BRAINet\" which consists of\nconvolutional neural networks with a powerful multi-head attention (MHA)\nmechanism. Existing literature on beam prediction is largely studied under a\nlimited, idealised vehicular scenario, often overlooking the real-time\ncomplexities and intricacies of vehicular networks. Therefore, this study aims\nto mimic the complexities of a real-time driving scenario by incorporating key\nfactors such as prominent MAC protocols-3GPP-C-V2X and IEEE 802.11BD, the\neffect of Doppler shifts under high velocity and varying distance and SNR\nlevels into three high-quality dynamic datasets pertaining to urban, rural and\nhighway vehicular networks. CAR-BRAINet performs effectively across all the\nvehicular scenarios, demonstrating precise beam prediction with minimal beam\noverhead and a steady improvement of 17.9422% on the spectral efficiency over\nthe existing methods. Thus, this study justifies the effectiveness of\nCAR-BRAINet in complex HetVNets, offering promising performance without relying\non the location angle and antenna dimensions of the mobile users, and thereby\nreducing the redundant sensor-latency."}
{"id": "2509.10544", "categories": ["cs.NI", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.10544", "abs": "https://arxiv.org/abs/2509.10544", "authors": ["Alireza Mohammadhosseini", "Jacob Chakareski", "Nicholas Mastronarde"], "title": "ASL360: AI-Enabled Adaptive Streaming of Layered 360° Video over UAV-assisted Wireless Networks", "comment": "This paper has been accepted for presentation at the IEEE Global\n  Communications Conference (GLOBECOM) 2025", "summary": "We propose ASL360, an adaptive deep reinforcement learning-based scheduler\nfor on-demand 360{\\deg} video streaming to mobile VR users in next generation\nwireless networks. We aim to maximize the overall Quality of Experience (QoE)\nof the users served over a UAV-assisted 5G wireless network. Our system model\ncomprises a macro base station (MBS) and a UAV-mounted base station which both\ndeploy mm-Wave transmission to the users. The 360{\\deg} video is encoded into\ndependent layers and segmented tiles, allowing a user to schedule downloads of\neach layer's segments. Furthermore, each user utilizes multiple buffers to\nstore the corresponding video layer's segments. We model the scheduling\ndecision as a Constrained Markov Decision Process (CMDP), where the agent\nselects Base or Enhancement layers to maximize the QoE and use a policy\ngradient-based method (PPO) to find the optimal policy. Additionally, we\nimplement a dynamic adjustment mechanism for cost components, allowing the\nsystem to adaptively balance and prioritize the video quality, buffer\noccupancy, and quality change based on real-time network and streaming session\nconditions. We demonstrate that ASL360 significantly improves the QoE,\nachieving approximately 2 dB higher average video quality, 80% lower average\nrebuffering time, and 57% lower video quality variation, relative to\ncompetitive baseline methods. Our results show the effectiveness of our layered\nand adaptive approach in enhancing the QoE in immersive videostreaming\napplications, particularly in dynamic and challenging network environments."}
{"id": "2509.11112", "categories": ["cs.NI", "cs.AI", "cs.ET", "cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.11112", "abs": "https://arxiv.org/abs/2509.11112", "authors": ["Muhammad Baqer Mollah", "Honggang Wang", "Hua Fang"], "title": "Multi-Modal Sensing Aided mmWave Beamforming for V2V Communications with Transformers", "comment": "6 Pages, Accepted to present at 2025 IEEE Global Communications\n  Conference (GLOBECOM), Taipei, Taiwan", "summary": "Beamforming techniques are utilized in millimeter wave (mmWave) communication\nto address the inherent path loss limitation, thereby establishing and\nmaintaining reliable connections. However, adopting standard defined\nbeamforming approach in highly dynamic vehicular environments often incurs high\nbeam training overheads and reduces the available airtime for communications,\nwhich is mainly due to exchanging pilot signals and exhaustive beam\nmeasurements. To this end, we present a multi-modal sensing and fusion learning\nframework as a potential alternative solution to reduce such overheads. In this\nframework, we first extract the features individually from the visual and GPS\ncoordinates sensing modalities by modality specific encoders, and subsequently\nfuse the multimodal features to obtain predicted top-k beams so that the best\nline-of-sight links can be proactively established. To show the\ngeneralizability of the proposed framework, we perform a comprehensive\nexperiment in four different vehicle-to-vehicle (V2V) scenarios from real-world\nmulti-modal sensing and communication dataset. From the experiment, we observe\nthat the proposed framework achieves up to 77.58% accuracy on predicting top-15\nbeams correctly, outperforms single modalities, incurs roughly as low as 2.32\ndB average power loss, and considerably reduces the beam searching space\noverheads by 76.56% for top-15 beams with respect to standard defined approach."}
{"id": "2509.11289", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11289", "abs": "https://arxiv.org/abs/2509.11289", "authors": ["Rashmi Kamran", "Mahesh Ganesh Bhat", "Pranav Jha", "Shana Moothedath", "Manjesh Hanawal", "Prasanna Chaporkar"], "title": "Energy-Aware 6G Network Design: A Survey", "comment": null, "summary": "6th Generation (6G) mobile networks are envisioned to support several new\ncapabilities and data-centric applications for unprecedented number of users,\npotentially raising significant energy efficiency and sustainability concerns.\nThis brings focus on sustainability as one of the key objectives in the their\ndesign. To move towards sustainable solution, research and standardization\ncommunity is focusing on several key issues like energy information monitoring\nand exposure, use of renewable energy, and use of Artificial\nIntelligence/Machine Learning (AI/ML) for improving the energy efficiency in 6G\nnetworks. The goal is to build energy-aware solutions that takes into account\nthe energy information resulting in energy efficient networks. Design of\nenergy-aware 6G networks brings in new challenges like increased overheads in\ngathering and exposing of energy related information, and the associated user\nconsent management. The aim of this paper is to provide a comprehensive survey\nof methods used for design of energy efficient 6G networks, like energy\nharvesting, energy models and parameters, classification of energy-aware\nservices, and AI/ML-based solutions. The survey also includes few use cases\nthat demonstrate the benefits of incorporating energy awareness into network\ndecisions. Several ongoing standardization efforts in 3GPP, ITU, and IEEE are\nincluded to provide insights into the ongoing work and highlight the\nopportunities for new contributions. We conclude this survey with open research\nproblems and challenges that can be explored to make energy-aware design\nfeasible and ensure optimality regarding performance and energy goals for 6G\nnetworks."}
{"id": "2509.11636", "categories": ["cs.IT", "cs.AI", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.11636", "abs": "https://arxiv.org/abs/2509.11636", "authors": ["Shiyao Jiang", "Jian Jiao", "Xingjian Zhang", "Ye Wang", "Dusit Niyato", "Qinyu Zhang"], "title": "Task-Agnostic Learnable Weighted-Knowledge Base Scheme for Robust Semantic Communications", "comment": null, "summary": "With the emergence of diverse and massive data in the upcoming\nsixth-generation (6G) networks, the task-agnostic semantic communication system\nis regarded to provide robust intelligent services. In this paper, we propose a\ntask-agnostic learnable weighted-knowledge base semantic communication (TALSC)\nframework for robust image transmission to address the real-world heterogeneous\ndata bias in KB, including label flipping noise and class imbalance. The TALSC\nframework incorporates a sample confidence module (SCM) as meta-learner and the\nsemantic coding networks as learners. The learners are updated based on the\nempirical knowledge provided by the learnable weighted-KB (LW-KB). Meanwhile,\nthe meta-learner evaluates the significance of samples according to the task\nloss feedback, and adjusts the update strategy of learners to enhance the\nrobustness in semantic recovery for unknown tasks. To strike a balance between\nSCM parameters and precision of significance evaluation, we design an SCM-grid\nextension (SCM-GE) approach by embedding the Kolmogorov-Arnold networks (KAN)\nwithin SCM, which leverages the concept of spline refinement in KAN and enables\nscalable SCM with customizable granularity without retraining. Simulations\ndemonstrate that the TALSC framework effectively mitigates the effects of\nflipping noise and class imbalance in task-agnostic image semantic\ncommunication, achieving at least 12% higher semantic recovery accuracy (SRA)\nand multi-scale structural similarity (MS-SSIM) compared to state-of-the-art\nmethods."}
