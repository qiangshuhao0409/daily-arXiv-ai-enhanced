{"id": "2508.15795", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.15795", "abs": "https://arxiv.org/abs/2508.15795", "authors": ["Yanheng Liu", "Dalin Li", "Hao Wu", "Zemin Sun", "Weihong Qin", "Jun Li", "Hongyang Du", "Geng Sun"], "title": "Task Offloading and Resource Allocation for MEC-assisted Consumer Internet of Vehicle Systems", "comment": null, "summary": "Mobile edge computing (MEC)-assisted internet of vehicle (IoV) is emerging as\na promising paradigm to provide computing services for vehicles. However,\nmeeting the computing-sensitive and computation-intensive demands of vehicles\nposes several challenges, including the discrepancy between the limited\nresource provision and stringent computing requirement, the difficulty in\ncapturing and integrating the intricate features of the MEC-assisted IoV system\ninto the problem formulation, and the need for real-time processing and\nefficient resource management in the dynamic environment. In this work, we\nexplore the AI-enabled task offloading and resource allocation for MEC-assisted\nconsumer IoV systems. Specifically, we first present a multi-MEC-assisted\nconsumer IoV architecture that leverages the computational resources of MEC\nservers to provide offloading services close to vehicles. Subsequently, we\nformulate a system cost minimization optimization problem (SCMOP) by\nintegrating the service delay and energy consumption. To efficiently solve this\nproblem, we design a joint task offloading and computing resource allocation\napproach (JTOCRA) by applying the multi-agent deep deterministic policy\ngradient (MADDPG) algorithm. Finally, simulation results demonstrate that the\nproposed JTOCRA can achieve superior system performances and exhibits better\nscalability compared to other alternative approaches.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76MEC\u8f85\u52a9\u8f66\u8054\u7f51\u4e2d\u7684AI\u4efb\u52a1\u51fa\u7f6e\u548c\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u901a\u8fc7MADDPG\u7b97\u6cd5\u8bbe\u8ba1\u4e86\u8054\u5408\u4f18\u5316\u65b9\u6848JTOCRA\uff0c\u4ee5\u5b9e\u73b0\u7cfb\u7edf\u6210\u672c\u6700\u5c0f\u5316\u3002", "motivation": "\u8f66\u8054\u7f51\u4e2d\u8ba1\u7b97\u654f\u611f\u548c\u8ba1\u7b97\u5bc6\u96c6\u578b\u9700\u6c42\u5bfc\u81f4\u4e86\u8d44\u6e90\u4f9b\u7ed9\u4e0e\u4e25\u683c\u8ba1\u7b97\u8981\u6c42\u95f4\u7684\u5dee\u5f02\uff0c\u52a8\u6001\u73af\u5883\u4e0b\u7684\u5b9e\u65f6\u5904\u7406\u548c\u9ad8\u6548\u8d44\u6e90\u7ba1\u7406\u9760\u6218\u3002", "method": "\u9996\u5148\u63d0\u51fa\u591aMEC\u8f85\u52a9\u7684\u8f66\u8054\u7f51\u67b6\u6784\uff0c\u7136\u540e\u6784\u5efa\u4ee5\u670d\u52a1\u5ef6\u8fdf\u548c\u80fd\u6d88\u8017\u4e3a\u76ee\u6807\u7684\u7cfb\u7edf\u6210\u672c\u6700\u5c0f\u5316\u4f18\u5316\u95ee\u9898\uff0c\u6700\u540e\u91c7\u7528\u591a\u81ea\u7136\u4eba\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5(MADDPG)\u8bbe\u8ba1\u8054\u5408\u4efb\u52a1\u51fa\u7f6e\u548c\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u65b9\u6848JTOCRA\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684JTOCRA\u65b9\u6848\u80fd\u591f\u83b7\u5f97\u66f4\u4f18\u5f02\u7684\u7cfb\u7edf\u6027\u80fd\uff0c\u5e76\u4e14\u4e0e\u5176\u4ed6\u66ff\u4ee3\u65b9\u6848\u76f8\u6bd4\u5177\u6709\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7AI\u6280\u672f\u6709\u6548\u89e3\u51b3\u4e86MEC\u8f85\u52a9\u8f66\u8054\u7f51\u4e2d\u7684\u4efb\u52a1\u51fa\u7f6e\u548c\u8d44\u6e90\u5206\u914d\u6311\u6218\uff0c\u4e3a\u52a8\u6001\u73af\u5883\u4e0b\u7684\u5b9e\u65f6\u8ba1\u7b97\u670d\u52a1\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15821", "categories": ["cs.IT", "cs.AI", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.15821", "abs": "https://arxiv.org/abs/2508.15821", "authors": ["Bibo Wu", "Fang Fang", "Ming Zeng", "Xianbin Wang"], "title": "Straggler-Resilient Federated Learning over A Hybrid Conventional and Pinching Antenna Network", "comment": null, "summary": "Leveraging pinching antennas in wireless network enabled federated learning\n(FL) can effectively mitigate the common \"straggler\" issue in FL by dynamically\nestablishing strong line-of-sight (LoS) links on demand. This letter proposes a\nhybrid conventional and pinching antenna network (HCPAN) to significantly\nimprove communication efficiency in the non-orthogonal multiple access\n(NOMA)-enabled FL system. Within this framework, a fuzzy logic-based client\nclassification scheme is first proposed to effectively balance clients' data\ncontributions and communication conditions. Given this classification, we\nformulate a total time minimization problem to jointly optimize pinching\nantenna placement and resource allocation. Due to the complexity of variable\ncoupling and non-convexity, a deep reinforcement learning (DRL)-based algorithm\nis developed to effectively address this problem. Simulation results validate\nthe superiority of the proposed scheme in enhancing FL performance via the\noptimized deployment of pinching antenna.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u4f20\u7edf\u548c\u634f\u5408\u5929\u7ebf\u7f51\u7edc(HCPAN)\uff0c\u901a\u8fc7\u634f\u5408\u5929\u7ebf\u6280\u672f\u4f18\u5316\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u7684\u901a\u4fe1\u6548\u7387\uff0c\u4f7f\u7528\u6a21\u7cca\u903b\u8f91\u5206\u7c7b\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u89e3\u51b3\u8d44\u6e90\u5206\u914d\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\"\u62d6\u540e\u817f\"\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u5efa\u7acb\u5f3a\u89c6\u8ddd\u94fe\u63a5\u6765\u63d0\u9ad8\u901a\u4fe1\u6548\u7387\uff0c\u4f18\u5316\u975e\u6b63\u4ea4\u591a\u5740\u63a5\u5165\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u4f20\u7edf\u548c\u634f\u5408\u5929\u7ebf\u7f51\u7edc\u6846\u67b6\uff0c\u91c7\u7528\u6a21\u7cca\u903b\u8f91\u5ba2\u6237\u7aef\u5206\u7c7b\u65b9\u6848\u5e73\u8861\u6570\u636e\u8d21\u732e\u548c\u901a\u4fe1\u6761\u4ef6\uff0c\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u8054\u5408\u4f18\u5316\u634f\u5408\u5929\u7ebf\u90e8\u7f72\u548c\u8d44\u6e90\u5206\u914d\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6848\u901a\u8fc7\u4f18\u5316\u634f\u5408\u5929\u7ebf\u90e8\u7f72\u6765\u589e\u5f3a\u8054\u90a6\u5b66\u4e60\u6027\u80fd\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u634f\u5408\u5929\u7ebf\u6280\u672f\u80fd\u6709\u6548\u6539\u5584\u8054\u90a6\u5b66\u4e60\u901a\u4fe1\u6548\u7387\uff0c\u63d0\u51fa\u7684\u6df7\u5408\u7f51\u7edc\u6846\u67b6\u548c\u4f18\u5316\u7b97\u6cd5\u4e3a\u89e3\u51b3\u7cfb\u7edf\u590d\u6742\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15943", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15943", "abs": "https://arxiv.org/abs/2508.15943", "authors": ["Riccardo Andreoni", "Andrei Buliga", "Alessandro Daniele", "Chiara Ghidini", "Marco Montali", "Massimiliano Ronzani"], "title": "T-ILR: a Neurosymbolic Integration for LTLf", "comment": "Accepted for presentation at NeSy 2025. 10 pages", "summary": "State-of-the-art approaches for integrating symbolic knowledge with deep\nlearning architectures have demonstrated promising results in static domains.\nHowever, methods to handle temporal logic specifications remain underexplored.\nThe only existing approach relies on an explicit representation of a\nfinite-state automaton corresponding to the temporal specification. Instead, we\naim at proposing a neurosymbolic framework designed to incorporate temporal\nlogic specifications, expressed in Linear Temporal Logic over finite traces\n(LTLf), directly into deep learning architectures for sequence-based tasks. We\nextend the Iterative Local Refinement (ILR) neurosymbolic algorithm, leveraging\nthe recent introduction of fuzzy LTLf interpretations. We name this proposed\nmethod Temporal Iterative Local Refinement (T-ILR). We assess T-ILR on an\nexisting benchmark for temporal neurosymbolic architectures, consisting of the\nclassification of image sequences in the presence of temporal knowledge. The\nresults demonstrate improved accuracy and computational efficiency compared to\nthe state-of-the-art method.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u7b26\u53f7\u6846\u67b6T-ILR\uff0c\u7528\u4e8e\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u96c6\u6210\u65f6\u6001\u903b\u8f91\u89c4\u8303\uff0c\u5728\u56fe\u50cf\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u7684\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u4e3b\u8981\u5904\u7406\u9759\u6001\u9886\u57df\uff0c\u5bf9\u65f6\u6001\u903b\u8f91\u89c4\u8303\u7684\u5904\u7406\u65b9\u6cd5\u8f83\u5c11\u3002\u552f\u4e00\u7684\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u663e\u5f0f\u8868\u793a\u6709\u9650\u72b6\u6001\u81ea\u52a8\u673a\uff0c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u6269\u5c55\u4e86\u8fed\u4ee3\u5c40\u90e8\u7cbe\u70bc(ILR)\u7b97\u6cd5\uff0c\u5229\u7528\u6a21\u7ccaLTLf\u89e3\u91ca\uff0c\u63d0\u51faT-ILR\u65b9\u6cd5\u76f4\u63a5\u5c06\u6709\u9650\u8ff9LTLf\u8868\u8fbe\u7684\u65f6\u6001\u903b\u8f91\u89c4\u8303\u96c6\u6210\u5230\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u4e2d\u3002", "result": "\u5728\u65f6\u6001\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u6807\u51c6\u6d4b\u8bd5\u96c6\u4e0a\uff0cT-ILR\u65b9\u6cd5\u5728\u56fe\u50cf\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "T-ILR\u4e3a\u5904\u7406\u65f6\u6001\u903b\u8f91\u89c4\u8303\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u795e\u7ecf\u7b26\u53f7\u89e3\u51b3\u65b9\u6848\uff0c\u5145\u5b9e\u4e86\u6df1\u5ea6\u5b66\u4e60\u4e0e\u7b26\u53f7\u77e5\u8bc6\u96c6\u6210\u5728\u5e8f\u5217\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2508.15816", "categories": ["cs.NI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15816", "abs": "https://arxiv.org/abs/2508.15816", "authors": ["Mauro Belgiovine", "Chris Dick", "Kaushik Chowdhury"], "title": "Better Together: Leveraging Multiple Digital Twins for Deployment Optimization of Airborne Base Stations", "comment": "Submitted to IEEE Transactions on Mobile Computing (second round of\n  review)", "summary": "Airborne Base Stations (ABSs) allow for flexible geographical allocation of\nnetwork resources with dynamically changing load as well as rapid deployment of\nalternate connectivity solutions during natural disasters. Since the radio\ninfrastructure is carried by unmanned aerial vehicles (UAVs) with limited\nflight time, it is important to establish the best location for the ABS without\nexhaustive field trials. This paper proposes a digital twin (DT)-guided\napproach to achieve this through the following key contributions: (i)\nImplementation of an interactive software bridge between two open-source DTs\nsuch that the same scene is evaluated with high fidelity across NVIDIA's Sionna\nand Aerial Omniverse Digital Twin (AODT), highlighting the unique features of\neach of these platforms for this allocation problem, (ii) Design of a\nback-propagation-based algorithm in Sionna for rapidly converging on the\nphysical location of the UAVs, orientation of the antennas and transmit power\nto ensure efficient coverage across the swarm of the UAVs, and (iii) numerical\nevaluation in AODT for large network scenarios (50 UEs, 10 ABS) that identifies\nthe environmental conditions in which there is agreement or divergence of\nperformance results between these twins. Finally, (iv) we propose a resilience\nmechanism to provide consistent coverage to mission-critical devices and\ndemonstrate a use case for bi-directional flow of information between the two\nDTs.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u5b57\u53cc\u751f\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408NVIDIA Sionna\u548cAerial Omniverse\u4e24\u4e2a\u5e73\u53f0\u6765\u4f18\u5316\u7a7a\u4e2d\u57fa\u7ad9\u7f6e\u4f4d\uff0c\u63d0\u9ad8\u7f51\u7edc\u8986\u76d6\u6548\u7387\u548c\u5f39\u6027\u3002", "motivation": "\u7a7a\u4e2d\u57fa\u7ad9(ABS)\u53ef\u4ee5\u7075\u6d3b\u5206\u914d\u7f51\u7edc\u8d44\u6e90\u548c\u5728\u707e\u96be\u65f6\u63d0\u4f9b\u8fde\u63a5\uff0c\u4f46\u65e0\u4eba\u673a\u98de\u884c\u65f6\u95f4\u6709\u9650\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u4f4d\u7f6e\u4f18\u5316\u65b9\u6cd5\u907f\u514d\u6d4b\u8bd5\u6d6a\u8d39\u3002", "method": "\u5b9e\u73b0\u4e86\u4e24\u4e2a\u5f00\u6e90\u6570\u5b57\u53cc\u751f\u5e73\u53f0\u7684\u8f6f\u4ef6\u6865\u63a5\uff0c\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u53cd\u5411\u4f20\u64ad\u7684\u7b97\u6cd5\u6765\u4f18\u5316\u65e0\u4eba\u673a\u4f4d\u7f6e\u3001\u5929\u7ebf\u65b9\u5411\u548c\u53d1\u5c04\u529f\u7387\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u7f51\u7edc\u573a\u666f\u4e2d\u8fdb\u884c\u6570\u503c\u8bc4\u4f30\u3002", "result": "\u572850\u4e2a\u7528\u6237\u8bbe\u5907\u548c10\u4e2a\u7a7a\u4e2d\u57fa\u7ad9\u7684\u5927\u89c4\u6a21\u573a\u666f\u4e0b\uff0c\u8bc6\u522b\u4e86\u73af\u5883\u6761\u4ef6\u5bf9\u4e24\u4e2a\u6570\u5b57\u53cc\u751f\u5e73\u53f0\u6027\u80fd\u7ed3\u679c\u4e00\u81f4\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u4ee5\u4e3a\u5173\u952e\u8bbe\u5907\u63d0\u4f9b\u4e00\u81f4\u8986\u76d6\u7684\u5f39\u6027\u673a\u5236\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6570\u5b57\u53cc\u751f\u6280\u672f\u6709\u6548\u5730\u4f18\u5316\u4e86\u7a7a\u4e2d\u57fa\u7ad9\u7684\u7f6e\u4f4d\u914d\u7f6e\uff0c\u63d0\u9ad8\u4e86\u7f51\u7edc\u8986\u76d6\u6548\u7387\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u707e\u96be\u6062\u590d\u548c\u52a8\u6001\u8d1f\u8377\u5206\u914d\u63d0\u4f9b\u4e86\u91cd\u8981\u6280\u672f\u652f\u6491\u3002"}}
{"id": "2508.15924", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.15924", "abs": "https://arxiv.org/abs/2508.15924", "authors": ["Yinchen Li", "Chenhao Qi", "Shiwen Mao", "Octavia A. Dobre"], "title": "Tri-Hybrid Beamforming for Radiation-Center Reconfigurable Antenna Array: Spectral Efficiency and Energy Efficiency", "comment": null, "summary": "In this paper, we propose a tri-hybrid beamforming (THBF) architecture based\non the radiation-center (RC) reconfigurable antenna array (RCRAA), including\nthe digital beamforming, analog beamforming, and electromagnetic (EM)\nbeamforming, where the EM beamformer design is modeled as RC selection. Aiming\nat spectral efficiency (SE) maximization subject to the hardware and power\nconsumption constraints, we propose a tri-loop alternating optimization (TLAO)\nscheme for the THBF design, where the digital and analog beamformers are\noptimized based on the penalty dual decomposition in the inner and middle\nloops, and the RC selection is determined through the coordinate descent method\nin the outer loop. Aiming at energy-efficiency (EE) maximization, we develop a\ndual quadratic transform-based fractional programming (DQTFP) scheme, where the\nTLAO scheme is readily used for the THBF design. To reduce the computational\ncomplexity, we propose the Lagrange dual transform-based fractional programming\n(LDTFP) scheme, where each iteration has a closed-form solution. Simulation\nresults demonstrate the great potential of the RCRAA in improving both SE and\nEE. Compared to the DQTFP scheme, the LDTFP scheme significantly reduces the\ncomputational complexity with only minor performance loss.", "AI": {"tldr": "\u57fa\u4e8e\u8f90\u5c04\u4e2d\u5fc3\u53ef\u91cd\u914d\u5929\u7ebf\u6570\u7ec4\u7684\u4e09\u6df7\u5408\u653e\u5f62\u6210\u590d\u5408\u67b6\u6784\uff0c\u5305\u542b\u6570\u5b57\u3001\u6a21\u62df\u548c\u7535\u78c1\u653e\u5f62\u6210\uff0c\u901a\u8fc7\u4e09\u5faa\u73af\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\u5b9e\u73b0\u9891\u8c31\u6548\u7387\u548c\u80fd\u91cf\u6548\u7387\u7684\u6700\u5927\u5316\u3002", "motivation": "\u4e3a\u4e86\u5728\u786c\u4ef6\u548c\u529f\u8017\u7ea6\u675f\u4e0b\u63d0\u5347\u5929\u7ebf\u7cfb\u7edf\u7684\u9891\u8c31\u6548\u7387\u548c\u80fd\u91cf\u6548\u7387\uff0c\u63a2\u7d22\u57fa\u4e8e\u8f90\u5c04\u4e2d\u5fc3\u53ef\u91cd\u914d\u5929\u7ebf\u6570\u7ec4\u7684\u65b0\u578b\u6df7\u5408\u653e\u5f62\u6210\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e09\u6df7\u5408\u653e\u5f62\u6210\u67b6\u6784\uff0c\u5305\u542b\u6570\u5b57\u3001\u6a21\u62df\u548c\u7535\u78c1\u653e\u5f62\u6210\u3002\u4f7f\u7528\u4e09\u5faa\u73af\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\uff1a\u5185\u5faa\u73af\u548c\u4e2d\u5faa\u73af\u7528\u60e9\u7f5a\u5bf9\u5076\u5206\u89e3\u4f18\u5316\u6570\u5b57\u548c\u6a21\u62df\u653e\u5f62\u6210\uff0c\u5916\u5faa\u73af\u7528\u5750\u6807\u9012\u51cf\u6cd5\u786e\u5b9a\u8f90\u5c04\u4e2d\u5fc3\u9009\u62e9\u3002\u5bf9\u4e8e\u80fd\u91cf\u6548\u7387\u6700\u5927\u5316\uff0c\u63d0\u51fa\u53cc\u4e8c\u6b21\u53d8\u6362\u57fa\u4e8e\u7684\u5206\u6570\u89c4\u5212\u7b97\u6cd5\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8868\u660e\u8f90\u5c04\u4e2d\u5fc3\u53ef\u91cd\u914d\u5929\u7ebf\u6570\u7ec4\u5728\u63d0\u9ad8\u9891\u8c31\u6548\u7387\u548c\u80fd\u91cf\u6548\u7387\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u53d8\u6362\u57fa\u4e8e\u7684\u5206\u6570\u89c4\u5212\u7b97\u6cd5\u5728\u4ec5\u6709\u8f7b\u5fae\u6027\u80fd\u635f\u5931\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u4e09\u6df7\u5408\u653e\u5f62\u6210\u67b6\u6784\u548c\u76f8\u5e94\u4f18\u5316\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u5929\u7ebf\u7cfb\u7edf\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u4f18\u5316\u7684\u65b9\u6848\uff0c\u4e3a\u672a\u6765\u9ad8\u6548\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2508.16033", "categories": ["cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.16033", "abs": "https://arxiv.org/abs/2508.16033", "authors": ["Jong-Hwan Jang", "Junho Song", "Yong-Yeon Jo"], "title": "CoFE: A Framework Generating Counterfactual ECG for Explainable Cardiac AI-Diagnostics", "comment": "Demo paper, 5 pages", "summary": "Recognizing the need for explainable AI (XAI) approaches to enable the\nsuccessful integration of AI-based ECG prediction models (AI-ECG) into clinical\npractice, we introduce a framework generating \\textbf{Co}unter\\textbf{F}actual\n\\textbf{E}CGs (i,e., named CoFE) to illustrate how specific features, such as\namplitudes and intervals, influence the model's predictive decisions. To\ndemonstrate the applicability of the CoFE, we present two case studies: atrial\nfibrillation classification and potassium level regression models. The CoFE\nreveals feature changes in ECG signals that align with the established clinical\nknowledge. By clarifying both \\textbf{where valid features appear} in the ECG\nand \\textbf{how they influence the model's predictions}, we anticipate that our\nframework will enhance the interpretability of AI-ECG models and support more\neffective clinical decision-making. Our demonstration video is available at:\nhttps://www.youtube.com/watch?v=YoW0bNBPglQ.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u6027AI\u6846\u67b6CoFE\uff0c\u901a\u8fc7\u751f\u6210\u53cd\u4e8b\u5b9eECG\u4fe1\u53f7\u6765\u89e3\u91caAI-ECG\u6a21\u578b\u7684\u9884\u6d4b\u51b3\u7b56\uff0c\u63d0\u9ad8\u4e34\u5e8a\u5e94\u7528\u7684\u53ef\u4fe1\u8fc7\u7a0b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3AI\u57fa\u7840ECG\u9884\u6d4b\u6a21\u578b\u5728\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u9700\u6c42\uff0c\u4f7f\u5f97\u533b\u751f\u80fd\u591f\u7406\u89e3\u6a21\u578b\u7684\u51b3\u7b56\u8fc7\u7a0b\u548c\u4f9d\u636e\u3002", "method": "\u5f00\u53d1\u4e86\u53cd\u4e8b\u5b9eECG\u751f\u6210\u6846\u67b6(CoFE)\uff0c\u901a\u8fc7\u6539\u53d8ECG\u4fe1\u53f7\u7684\u7279\u5b9a\u7279\u5f81(\u5982\u632f\u5e45\u548c\u95f4\u9694)\u6765\u6f14\u793a\u5bf9\u6a21\u578b\u9884\u6d4b\u7684\u5f71\u54cd\uff0c\u5e76\u5728\u623f\u98a4\u5206\u7c7b\u548c\u94be\u6c34\u5e73\u56de\u5f52\u6a21\u578b\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "CoFE\u6846\u67b6\u751f\u6210\u7684\u53cd\u4e8b\u5b9eECG\u663e\u793a\u7684\u7279\u5f81\u53d8\u5316\u4e0e\u5df2\u77e5\u4e34\u5e8a\u77e5\u8bc6\u76f8\u7b26\u5408\uff0c\u80fd\u591f\u6e05\u6670\u5730\u5448\u73b0\u6709\u6548\u7279\u5f81\u51fa\u73b0\u7684\u4f4d\u7f6e\u4ee5\u53ca\u5b83\u4eec\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u9884\u6d4b\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u63d0\u9ad8AI-ECG\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u652f\u6301\u66f4\u6709\u6548\u7684\u4e34\u5e8a\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4fc3\u8fdbAI\u5728\u533b\u7597\u9884\u6d4b\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2508.15819", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.15819", "abs": "https://arxiv.org/abs/2508.15819", "authors": ["Qiang Duan", "Zhihui Lu"], "title": "Agent Communications toward Agentic AI at Edge -- A Case Study of the Agent2Agent Protocol", "comment": null, "summary": "The current evolution of artificial intelligence introduces a paradigm shift\ntoward agentic AI built upon multi-agent systems (MAS). Agent communications\nserve as a key to effective agent interactions in MAS and thus have a\nsignificant impact on the performance of agentic AI applications. The recent\nresearch on agent communications has made exciting rapid progress that leads to\na variety of protocol designs, among which the Agent2Agent (A2A) protocol is\nconsidered the most representative one. Simultaneously, the rise of edge\nintelligence is expected to enable agentic AI at the network edge. However, the\ncurrent agent communication protocols are designed without sufficient\nconsideration of the special challenges of edge computing, and their\neffectiveness in the edge environment is largely unexamined. In this paper, we\nattempt to assess the abilities of agent communication technologies to face the\nchallenges of edge computing using the A2A protocol as a representative case.\nWe first discuss the core functionalities of agent communications, present a\nlandscape of agent communication protocols, and identify the main challenges\nintroduced by edge computing. Then, we conduct a case study on the A2A protocol\nto examine the key technologies leveraged in the protocol for their\neffectiveness in meeting the requirements of agent communications in edge\ncomputing. Based on the insights obtained from this assessment, we identify\nopen issues in the current agent communication technologies and discuss\ndirections for future research to address these issues.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u5f53\u524d\u4ee3\u7406\u901a\u4fe1\u534f\u8bae\uff08\u7279\u522b\u662fA2A\u534f\u8bae\uff09\u5728\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\uff0c\u5206\u6790\u4e86\u8fb9\u7f18\u8ba1\u7b97\u5e26\u6765\u7684\u7279\u6b8a\u6311\u6218\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u8fb9\u7f18\u667a\u80fd\u7684\u5174\u8d77\uff0c\u9700\u8981\u5728\u7f51\u7edc\u8fb9\u7f18\u90e8\u7f72\u4ee3\u7406AI\uff0c\u4f46\u73b0\u6709\u7684\u4ee3\u7406\u901a\u4fe1\u534f\u8bae\u8bbe\u8ba1\u65f6\u672a\u5145\u5206\u8003\u8651\u8fb9\u7f18\u8ba1\u7b97\u7684\u7279\u6b8a\u6311\u6218\uff0c\u5176\u6709\u6548\u6027\u5728\u8fb9\u7f18\u73af\u5883\u4e2d\u5c1a\u672a\u5f97\u5230\u5145\u5206\u9a8c\u8bc1\u3002", "method": "\u9996\u5148\u8ba8\u8bba\u4ee3\u7406\u901a\u4fe1\u7684\u6838\u5fc3\u529f\u80fd\uff0c\u5c55\u793a\u4ee3\u7406\u901a\u4fe1\u534f\u8bae\u7684\u6982\u51b5\uff0c\u8bc6\u522b\u8fb9\u7f18\u8ba1\u7b97\u5e26\u6765\u7684\u4e3b\u8981\u6311\u6218\uff1b\u7136\u540e\u4ee5A2A\u534f\u8bae\u4e3a\u4ee3\u8868\u6027\u6848\u4f8b\u8fdb\u884c\u7814\u7a76\uff0c\u5206\u6790\u534f\u8bae\u4e2d\u91c7\u7528\u7684\u5173\u952e\u6280\u672f\u5bf9\u6ee1\u8db3\u8fb9\u7f18\u8ba1\u7b97\u9700\u6c42\u7684\u6548\u529b\u3002", "result": "\u901a\u8fc7\u8bc4\u4f30\u53d1\u73b0\u4e86\u5f53\u524d\u4ee3\u7406\u901a\u4fe1\u6280\u672f\u5728\u5e94\u5bf9\u8fb9\u7f18\u8ba1\u7b97\u6311\u6218\u65b9\u9762\u5b58\u5728\u7684\u95ee\u9898\u548c\u5c40\u9650\u6027\u3002", "conclusion": "\u57fa\u4e8e\u8bc4\u4f30\u83b7\u5f97\u7684\u89c1\u89e3\uff0c\u8bc6\u522b\u4e86\u5f53\u524d\u4ee3\u7406\u901a\u4fe1\u6280\u672f\u7684\u5f00\u653e\u6027\u95ee\u9898\uff0c\u5e76\u8ba8\u8bba\u4e86\u672a\u6765\u7814\u7a76\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u7684\u65b9\u5411\u3002"}}
{"id": "2508.16075", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.16075", "abs": "https://arxiv.org/abs/2508.16075", "authors": ["Geonho Han", "Hyuckjin Choi", "Hyesang Cho", "Jeong Hyeon Han", "Ki Tae Nam", "Junil Choi"], "title": "Multi-User SLNR-Based Precoding With Gold Nanoparticles in Vehicular VLC Systems", "comment": null, "summary": "Visible spectrum is an emerging frontier in wireless communications for\nenhancing connectivity and safety in vehicular environments. The vehicular\nvisible light communication (VVLC) system is a key feature in leveraging\nexisting infrastructures, but it still has several critical challenges.\nEspecially, VVLC channels are highly correlated due to the small gap between\nlight emitting diodes (LEDs) in each headlight, making it difficult to increase\ndata rates by spatial multiplexing. In this paper, we exploit recently\nsynthesized gold nanoparticles (GNPs) to reduce the correlation between LEDs,\ni.e., the chiroptical properties of GNPs for differential absorption depending\non the azimuth angle of incident light are used to mitigate the LED\ncorrelation. In addition, we adopt a signal-to-leakage-plus-noise ratio\n(SLNR)-based precoder to support multiple users. The ratio of RGB light sources\nin each LED also needs to be optimized to maximize the sum SLNR satisfying a\nwhite light constraint for illumination since the GNPs can vary the color of\ntransmitted light by the differential absorption across wavelength. The\nnonconvex optimization problems for precoders and RGB ratios can be solved by\nthe generalized Rayleigh quotient with the approximated shot noise and\nsuccessive convex approximation (SCA). The simulation results show that the\nSLNR-based precoder with the optimized RGB ratios significantly improves the\nsum rate in a multi-user vehicular environment and the secrecy rate in a\nwiretapping scenario. The proposed SLNR-based precoding verifies that the\ndecorrelation between LEDs and the RGB ratio optimization are essential to\nenhance the VVLC performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u91d1\u7eb3\u7c73\u7c92\u5b50(GNPs)\u548cSLNR\u9884\u7f16\u7801\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u964d\u4f4eLED\u76f8\u5173\u6027\u548c\u4f18\u5316RGB\u6bd4\u4f8b\u6765\u63d0\u9ad8\u8f66\u8f86\u53ef\u89c1\u5149\u901a\u4fe1\u7cfb\u7edf\u7684\u591a\u7528\u6237\u6027\u80fd\u548c\u5b89\u5168\u6027", "motivation": "\u8f66\u8f86\u53ef\u89c1\u5149\u901a\u4fe1(VVLC)\u7cfb\u7edf\u4e2dLED\u706f\u4e4b\u95f4\u5b58\u5728\u9ad8\u76f8\u5173\u6027\uff0c\u5bfc\u81f4\u7a7a\u95f4\u590d\u7528\u56f0\u96be\uff0c\u9650\u5236\u4e86\u6570\u636e\u901f\u7387\u7684\u63d0\u5347\uff0c\u9700\u8981\u65b0\u6280\u672f\u6765\u89e3\u51b3\u8fd9\u4e00\u6311\u6218", "method": "\u5229\u7528\u91d1\u7eb3\u7c73\u7c92\u5b50(GNPs)\u7684\u65cb\u5149\u7279\u6027\u964d\u4f4eLED\u76f8\u5173\u6027\uff0c\u91c7\u7528SLNR\u57fa\u7840\u7684\u9884\u7f16\u7801\u652f\u6301\u591a\u7528\u6237\uff0c\u901a\u8fc7\u666e\u901a\u96f7\u8fbe\u5549\u5549\u6bd4\u548c\u9010\u6b65\u51f8\u8fd1\u4f18\u5316\u6cd5\u89e3\u51b3RGB\u6bd4\u4f8b\u4f18\u5316\u95ee\u9898", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u4f18\u5316\u540e\u7684SLNR\u9884\u7f16\u7801\u65b9\u6848\u5728\u591a\u7528\u6237\u8f66\u8f86\u73af\u5883\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u603b\u901f\u7387\uff0c\u5728\u76d1\u542c\u573a\u666f\u4e2d\u4e5f\u63d0\u5347\u4e86\u4fdd\u5bc6\u901f\u7387", "conclusion": "\u8bc1\u660e\u4e86\u964d\u4f4eLED\u76f8\u5173\u6027\u548c\u4f18\u5316RGB\u6bd4\u4f8b\u5bf9\u63d0\u5347VVLC\u7cfb\u7edf\u6027\u80fd\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4e3a\u8f66\u8f86\u53ef\u89c1\u5149\u901a\u4fe1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6027\u80fd\u6539\u5584\u65b9\u6848"}}
{"id": "2508.16051", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16051", "abs": "https://arxiv.org/abs/2508.16051", "authors": ["Yiheng Hu", "Xiaoyang Wang", "Qing Liu", "Xiwei Xu", "Qian Fu", "Wenjie Zhang", "Liming Zhu"], "title": "MMAPG: A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs", "comment": null, "summary": "Multimodal Multi-hop question answering requires integrating information from\ndiverse sources, such as images and texts, to derive answers. Existing methods\ntypically rely on sequential retrieval and reasoning, where each step builds on\nthe previous output. However, this single-path paradigm makes them vulnerable\nto errors due to misleading intermediate steps. Moreover, developing multimodal\nmodels can be computationally expensive, often requiring extensive training. To\naddress these limitations, we propose a training-free framework guided by an\nAdaptive Planning Graph, which consists of planning, retrieval and reasoning\nmodules. The planning module analyzes the current state of the Adaptive\nPlanning Graph, determines the next action and where to expand the graph, which\nenables dynamic and flexible exploration of reasoning paths. To handle\nretrieval of text to unspecified target modalities, we devise modality-specific\nstrategies that dynamically adapt to distinct data types. Our approach\npreserves the characteristics of multimodal information without costly\ntask-specific training, enabling seamless integration with up-to-date models.\nFinally, the experiments on MultimodalQA and WebQA show that our approach\nmatches or outperforms existing models that rely on training.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u9002\u5e94\u89c4\u5212\u56fe\u7684\u65e0\u8bad\u7ec3\u591a\u6a21\u6001\u591a\u8df3\u95ee\u7b54\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u89c4\u5212\u3001\u68c0\u7d22\u548c\u63a8\u7406\u6a21\u5757\u5b9e\u73b0\u7075\u6d3b\u7684\u591a\u8def\u5f84\u63a8\u7406\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u4e2d\u95f4\u9519\u8bef\u7d2f\u79ef\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u591a\u8df3\u95ee\u7b54\u65b9\u6cd5\u4f9d\u8d56\u987a\u5e8f\u68c0\u7d22\u548c\u63a8\u7406\uff0c\u5bb9\u6613\u56e0\u4e2d\u95f4\u6b65\u9aa4\u9519\u8bef\u800c\u5931\u8d25\uff0c\u4e14\u8bad\u7ec3\u6210\u672c\u9ad8\u6602\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u80fd\u52a8\u6001\u63a2\u7d22\u591a\u8def\u5f84\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u81ea\u9002\u5e94\u89c4\u5212\u56fe\u6846\u67b6\uff0c\u5305\u542b\u89c4\u5212\u6a21\u5757\uff08\u5206\u6790\u5f53\u524d\u72b6\u6001\u51b3\u5b9a\u4e0b\u4e00\u6b65\u884c\u52a8\uff09\u3001\u68c0\u7d22\u6a21\u5757\uff08\u6a21\u6001\u7279\u5b9a\u7b56\u7565\u5904\u7406\u4e0d\u540c\u6570\u636e\u7c7b\u578b\uff09\u548c\u63a8\u7406\u6a21\u5757\uff0c\u5b9e\u73b0\u52a8\u6001\u7075\u6d3b\u7684\u63a8\u7406\u8def\u5f84\u63a2\u7d22\u3002", "result": "\u5728MultimodalQA\u548cWebQA\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u8fbe\u5230\u6216\u8d85\u8d8a\u4f9d\u8d56\u8bad\u7ec3\u7684\u73b0\u6709\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u65e0\u8bad\u7ec3\u81ea\u9002\u5e94\u89c4\u5212\u56fe\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u591a\u8df3\u95ee\u7b54\u4e2d\u7684\u9519\u8bef\u7d2f\u79ef\u548c\u8bad\u7ec3\u6210\u672c\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4e0e\u6700\u65b0\u6a21\u578b\u7684\u65e0\u7f1d\u96c6\u6210\u548c\u4f18\u5f02\u6027\u80fd\u3002"}}
{"id": "2508.15833", "categories": ["cs.NI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.15833", "abs": "https://arxiv.org/abs/2508.15833", "authors": ["Linfeng Shen", "Guanzhen Wu", "Cong Zhang", "Xiaoyi Fan", "Jiangchuan Liu"], "title": "Towards Integrated Energy-Communication-Transportation Hub: A Base-Station-Centric Design in 5G and Beyond", "comment": null, "summary": "The rise of 5G communication has transformed the telecom industry for\ncritical applications. With the widespread deployment of 5G base stations comes\na significant concern about energy consumption. Key industrial players have\nrecently shown strong interest in incorporating energy storage systems to store\nexcess energy during off-peak hours, reducing costs and participating in demand\nresponse. The fast development of batteries opens up new possibilities, such as\nthe transportation area. An effective method is needed to maximize base station\nbattery utilization and reduce operating costs. In this trend towards\nnext-generation smart and integrated energy-communication-transportation (ECT)\ninfrastructure, base stations are believed to play a key role as service hubs.\nBy exploring the overlap between base station distribution and electric vehicle\ncharging infrastructure, we demonstrate the feasibility of efficiently charging\nEVs using base station batteries and renewable power plants at the Hub. Our\nmodel considers various factors, including base station traffic conditions,\nweather, and EV charging behavior. This paper introduces an incentive mechanism\nfor setting charging prices and employs a deep reinforcement learning-based\nmethod for battery scheduling. Experimental results demonstrate the\neffectiveness of our proposed ECT-Hub in optimizing surplus energy utilization\nand reducing operating costs, particularly through revenue-generating EV\ncharging.", "AI": {"tldr": "\u57fa\u7ad9\u7ef4\u62a4\u6210\u672c\u9ad8\uff0c\u901a\u8fc75G\u57fa\u7ad9\u7ec4\u7f51\u4e0e\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u57fa\u7840\u8bbe\u65bd\u534f\u540c\uff0c\u5229\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u8c03\u5ea6\u9500\u4f59\u7535\u529b\uff0c\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u5e76\u901a\u8fc7EV\u5145\u7535\u83b7\u53d6\u6536\u76ca\u3002", "motivation": "5G\u57fa\u7ad9\u90e8\u7f72\u5e26\u6765\u5de8\u5927\u80fd\u8017\uff0c\u4e1a\u754c\u5e0c\u671b\u901a\u8fc7\u80fd\u6e90\u5b58\u50a8\u7cfb\u7edf\u5728\u8c37\u5e95\u65f6\u5b58\u50a8\u591a\u4f59\u7535\u529b\uff0c\u964d\u4f4e\u6210\u672c\u5e76\u53c2\u4e0e\u9700\u6c42\u54cd\u5e94\u3002\u7535\u6c60\u6280\u672f\u53d1\u5c55\u4e3a\u57fa\u7ad9\u8d44\u6e90\u5229\u7528\u5f00\u542f\u65b0\u53ef\u80fd\u6027\u3002", "method": "\u63a2\u7d22\u57fa\u7ad9\u5206\u5e03\u4e0eEV\u5145\u7535\u57fa\u7840\u8bbe\u65bd\u7684\u91cd\u5408\u533a\uff0c\u6784\u5efaECT-Hub\u6a21\u578b\u3002\u91c7\u7528\u6fc0\u52b1\u673a\u5236\u8bbe\u7f6e\u5145\u7535\u4ef7\u683c\uff0c\u5e76\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u7535\u6c60\u8c03\u5ea6\u3002\u8003\u8651\u57fa\u7ad9\u6d41\u91cf\u6761\u4ef6\u3001\u5929\u6c14\u548cEV\u5145\u7535\u884c\u4e3a\u7b49\u56e0\u7d20\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660eECT-Hub\u80fd\u591f\u6709\u6548\u4f18\u5316\u591a\u4f59\u80fd\u6e90\u5229\u7528\uff0c\u663e\u8457\u964d\u4f4e\u8fd0\u8425\u6210\u672c\uff0c\u5c24\u5176\u662f\u901a\u8fc7\u4ea7\u751f\u6536\u76ca\u7684EV\u5145\u7535\u670d\u52a1\u3002", "conclusion": "\u57fa\u7ad9\u5728\u667a\u80fd\u5316\u96c6\u6210\u80fd\u6e90-\u901a\u4fe1-\u4ea4\u901a\u57fa\u7840\u8bbe\u65bd\u4e2d\u53ef\u4ee5\u53d1\u6325\u5173\u952e\u4f5c\u7528\u3002\u901a\u8fc7\u57fa\u7ad9\u7535\u6c60\u4e3aEV\u63d0\u4f9b\u5145\u7535\u670d\u52a1\u7684\u6a21\u5f0f\u53ef\u884c\u4e14\u6548\u679c\u663e\u8457\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u667a\u80fd\u57fa\u7840\u8bbe\u65bd\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.16301", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.16301", "abs": "https://arxiv.org/abs/2508.16301", "authors": ["Evagoras Stylianou", "Charalambos D. Charalambous", "Themistoklis Charalambous"], "title": "Implicit and Explicit Formulas of the Joint RDF for a Tuple of Multivariate Gaussian Sources with Individual Square-Error Distortions", "comment": null, "summary": "This paper analyzes the joint Rate Distortion Function (RDF) of correlated\nmultivariate Gaussian sources with individual square-error distortions.\nLeveraging Hotelling's canonical variable form, presented is a closed-form\ncharacterization of the joint RDF, that involves {a system of nonlinear\nequations. Furthermore, for the special case of symmetric distortions (i.e.,\nequal distortions), the joint RDF is explicitly expressed in terms of} two\nwater-filling variables. The results greatly improve our understanding and\nadvance the development of closed-form solutions of the joint RDF for\nmultivariate Gaussian sources with individual square-error distortions.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u76f8\u5173\u591a\u5143\u9ad8\u65af\u6e90\u7684\u8054\u5408\u7387\u5931\u771f\u51fd\u6570\uff0c\u63d0\u51fa\u4e86\u95ed\u5f0f\u89e3\u548c\u5bf9\u79f0\u5931\u771f\u60c5\u51b5\u4e0b\u7684\u663e\u5f0f\u8868\u8fbe\u5f0f", "motivation": "\u7814\u7a76\u76f8\u5173\u591a\u5143\u9ad8\u65af\u6e90\u5728\u4e2a\u4f53\u5e73\u65b9\u8bef\u5dee\u5931\u771f\u4e0b\u7684\u8054\u5408\u7387\u5931\u771f\u51fd\u6570\uff0c\u4ee5\u6539\u8fdb\u5bf9\u8be5\u95ee\u9898\u7684\u7406\u89e3\u548c\u95ed\u5f0f\u89e3\u7684\u53d1\u5c55", "method": "\u5229\u7528Hotelling\u7684\u5178\u578b\u53d8\u91cf\u5f62\u5f0f\uff0c\u63a8\u5bfc\u51fa\u6d89\u53ca\u975e\u7ebf\u6027\u65b9\u7a0b\u7ec4\u7684\u95ed\u5f0f\u7279\u5f81\uff0c\u5e76\u5728\u5bf9\u79f0\u5931\u771f\u60c5\u51b5\u4e0b\u7528\u4e24\u4e2a\u6ce8\u6c34\u53d8\u91cf\u663e\u5f0f\u8868\u8fbe", "result": "\u83b7\u5f97\u4e86\u8054\u5408\u7387\u5931\u771f\u51fd\u6570\u7684\u95ed\u5f0f\u7279\u5f81\u548c\u5bf9\u79f0\u5931\u771f\u60c5\u51b5\u4e0b\u7684\u663e\u5f0f\u89e3\uff0c\u5927\u5927\u63d0\u9ad8\u4e86\u5bf9\u591a\u5143\u9ad8\u65af\u6e90\u7387\u5931\u771f\u95ee\u9898\u7684\u7406\u89e3", "conclusion": "\u8be5\u7814\u7a76\u663e\u8457\u63a8\u8fdb\u4e86\u591a\u5143\u9ad8\u65af\u6e90\u5728\u4e2a\u4f53\u5e73\u65b9\u8bef\u5dee\u5931\u771f\u4e0b\u8054\u5408\u7387\u5931\u771f\u51fd\u6570\u7684\u95ed\u5f0f\u89e3\u53d1\u5c55\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u8fdb\u5c55"}}
{"id": "2508.16054", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.16054", "abs": "https://arxiv.org/abs/2508.16054", "authors": ["Sonish Sivarajkumar", "Hang Zhang", "Yuelyu Ji", "Maneesh Bilalpur", "Xizhi Wu", "Chenyu Li", "Min Gu Kwak", "Shyam Visweswaran", "Yanshan Wang"], "title": "Generative Foundation Model for Structured and Unstructured Electronic Health Records", "comment": null, "summary": "Electronic health records (EHRs) are rich clinical data sources but complex\nrepositories of patient data, spanning structured elements (demographics,\nvitals, lab results, codes), unstructured clinical notes and other modalities\nof data. Harnessing this heterogeneity is critical for improving patient\noutcomes. Recent advances in large language models (LLMs) have enabled\nfoundation models that can learn from multiple data modalities and support\nclinical tasks. However, most current approaches simply serialize numeric EHR\ndata into text, which risks losing temporal and quantitative detail. We\nintroduce Generative Deep Patient (GDP), a multimodal foundation model that\nnatively encodes structured EHR time-series via a CNN-Transformer encoder and\nfuses it with unstructured EHRs through cross-modal attention into a\nLLaMA-based decoder. GDP is trained in two stages: (1) generative pretraining,\nwhere it learns to produce clinical narratives from raw patient timelines while\nalso performing masked feature prediction (MFP) and next time-step prediction\n(NTP) to capture temporal dynamics; and (2) multi-task fine-tuning for\nclinically meaningful predictions (e.g., heart failure, type 2 diabetes, 30-day\nreadmission). In clinical prediction, GDP demonstrated superior performance on\nMIMIC-IV: heart failure AUROC = 0.923, type 2 diabetes AUROC = 0.817, and\n30-day readmission AUROC = 0.627. For narrative generation, GDP achieved\nROUGE-L = 0.135 and BERTScore-F1 = 0.545. In a blinded human evaluation,\nGDP-Instruct scored highest on faithfulness, fluency, and overall clinical\nutility, suggesting reduced hospital documentation workload without sacrificing\naccuracy. Our results demonstrate that a single multimodal foundation model can\nboth predict clinically actionable events and generate high-quality clinical\nnarratives. Furthermore, GDP's flexible architecture can be extended to\nadditional modalities.", "AI": {"tldr": "GDP\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7CNN-Transformer\u7f16\u7801\u5668\u5904\u7406\u7ed3\u6784\u5316EHR\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5e76\u4e0e\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u6587\u672c\u878d\u5408\uff0c\u80fd\u591f\u540c\u65f6\u8fdb\u884c\u4e34\u5e8a\u9884\u6d4b\u548c\u9ad8\u8d28\u91cf\u4e34\u5e8a\u53d9\u8ff0\u751f\u6210\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55(EHR)\u5305\u542b\u4e30\u5bcc\u7684\u591a\u6a21\u6001\u4e34\u5e8a\u6570\u636e\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5c06\u6570\u503c\u6570\u636e\u5e8f\u5217\u5316\u4e3a\u6587\u672c\uff0c\u4f1a\u4e22\u5931\u65f6\u95f4\u548c\u5b9a\u91cf\u7ec6\u8282\u4fe1\u606f\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u539f\u751f\u5904\u7406\u591a\u6a21\u6001EHR\u6570\u636e\u7684\u57fa\u7840\u6a21\u578b\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a1)\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\uff0c\u5b66\u4e60\u4ece\u539f\u59cb\u60a3\u8005\u65f6\u95f4\u7ebf\u751f\u6210\u4e34\u5e8a\u53d9\u8ff0\uff0c\u540c\u65f6\u8fdb\u884c\u63a9\u7801\u7279\u5f81\u9884\u6d4b\u548c\u4e0b\u4e00\u65f6\u95f4\u6b65\u9884\u6d4b\uff1b2)\u591a\u4efb\u52a1\u5fae\u8c03\uff0c\u7528\u4e8e\u4e34\u5e8a\u9884\u6d4b\u4efb\u52a1\u3002\u4f7f\u7528CNN-Transformer\u7f16\u7801\u5668\u5904\u7406\u7ed3\u6784\u5316\u65f6\u95f4\u5e8f\u5217\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u4e0eLLaMA\u89e3\u7801\u5668\u878d\u5408\u3002", "result": "\u5728MIMIC-IV\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff1a\u5fc3\u8870\u9884\u6d4bAUROC=0.923\uff0c2\u578b\u7cd6\u5c3f\u75c5AUROC=0.817\uff0c30\u5929\u518d\u5165\u9662AUROC=0.627\u3002\u53d9\u8ff0\u751f\u6210\u8fbe\u5230ROUGE-L=0.135\u548cBERTScore-F1=0.545\u3002\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\u5728\u5fe0\u5b9e\u6027\u3001\u6d41\u7545\u6027\u548c\u4e34\u5e8a\u5b9e\u7528\u6027\u65b9\u9762\u5f97\u5206\u6700\u9ad8\u3002", "conclusion": "\u5355\u4e00\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u80fd\u591f\u540c\u65f6\u9884\u6d4b\u4e34\u5e8a\u53ef\u64cd\u4f5c\u4e8b\u4ef6\u548c\u751f\u6210\u9ad8\u8d28\u91cf\u4e34\u5e8a\u53d9\u8ff0\uff0c\u51cf\u5c11\u533b\u9662\u6587\u6863\u5de5\u4f5c\u8d1f\u62c5\u800c\u4e0d\u727a\u7272\u51c6\u786e\u6027\u3002GDP\u7684\u7075\u6d3b\u67b6\u6784\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u6a21\u6001\u3002"}}
{"id": "2508.15838", "categories": ["cs.NI", "cs.GT", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.15838", "abs": "https://arxiv.org/abs/2508.15838", "authors": ["Jiacheng Wang", "Jialing He", "Geng Sun", "Zehui Xiong", "Dusit Niyato", "Shiwen Mao", "Dong In Kim", "Tao Xiang"], "title": "Safeguarding ISAC Performance in Low-Altitude Wireless Networks Under Channel Access Attack", "comment": null, "summary": "The increasing saturation of terrestrial resources has driven the exploration\nof low-altitude applications such as air taxis. Low altitude wireless networks\n(LAWNs) serve as the foundation for these applications, and integrated sensing\nand communication (ISAC) constitutes one of the core technologies within LAWNs.\nHowever, the openness nature of low-altitude airspace makes LAWNs vulnerable to\nmalicious channel access attacks, which degrade the ISAC performance.\nTherefore, this paper develops a game-based framework to mitigate the influence\nof the attacks on LAWNs. Concretely, we first derive expressions of\ncommunication data's signal-to-interference-plus-noise ratio and the age of\ninformation of sensing data under attack conditions, which serve as quality of\nservice metrics. Then, we formulate the ISAC performance optimization problem\nas a Stackelberg game, where the attacker acts as the leader, and the\nlegitimate drone and the ground ISAC base station act as second and first\nfollowers, respectively. On this basis, we design a backward induction\nalgorithm that achieves the Stackelberg equilibrium while maximizing the\nutilities of all participants, thereby mitigating the attack-induced\ndegradation of ISAC performance in LAWNs. We further prove the existence and\nuniqueness of the equilibrium. Simulation results show that the proposed\nalgorithm outperforms existing baselines and a static Nash equilibrium\nbenchmark, ensuring that LAWNs can provide reliable service for low-altitude\napplications.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u6076\u610f\u4fe1\u9053\u63a5\u5165\u653b\u51fb\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eStackelberg\u535a\u5f08\u7684\u6846\u67b6\u6765\u4f18\u5316\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u6027\u80fd\uff0c\u901a\u8fc7\u9006\u5411\u5f52\u7eb3\u7b97\u6cd5\u5b9e\u73b0\u5747\u8861\u5e76\u8bc1\u660e\u4e86\u5747\u8861\u7684\u5b58\u5728\u6027\u548c\u552f\u4e00\u6027\u3002", "motivation": "\u968f\u7740\u5730\u9762\u8d44\u6e90\u65e5\u76ca\u9971\u548c\uff0c\u4f4e\u7a7a\u5e94\u7528\u5982\u7a7a\u4e2d\u51fa\u79df\u8f66\u5f97\u5230\u53d1\u5c55\uff0c\u4f46\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u7684\u5f00\u653e\u6027\u4f7f\u5176\u6613\u53d7\u6076\u610f\u4fe1\u9053\u63a5\u5165\u653b\u51fb\uff0c\u5f71\u54cd\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u6027\u80fd\u3002", "method": "\u9996\u5148\u63a8\u5bfc\u53d7\u653b\u51fb\u6761\u4ef6\u4e0b\u901a\u4fe1\u6570\u636e\u7684\u4fe1\u5e72\u566a\u6bd4\u548c\u611f\u77e5\u6570\u636e\u7684\u4fe1\u606f\u5e74\u9f84\u4f5c\u4e3a\u670d\u52a1\u8d28\u91cf\u6307\u6807\uff0c\u7136\u540e\u5c06ISAC\u6027\u80fd\u4f18\u5316\u95ee\u9898\u5efa\u6a21\u4e3aStackelberg\u535a\u5f08\uff0c\u8bbe\u8ba1\u9006\u5411\u5f52\u7eb3\u7b97\u6cd5\u5b9e\u73b0Stackelberg\u5747\u8861\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u548c\u9759\u6001\u7eb3\u4ec0\u5747\u8861\u57fa\u51c6\uff0c\u80fd\u591f\u786e\u4fdd\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u4e3a\u4f4e\u7a7a\u5e94\u7528\u63d0\u4f9b\u53ef\u9760\u670d\u52a1\u3002", "conclusion": "\u63d0\u51fa\u7684\u535a\u5f08\u6846\u67b6\u548c\u7b97\u6cd5\u6709\u6548\u7f13\u89e3\u4e86\u653b\u51fb\u5bf9\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edcISAC\u6027\u80fd\u7684\u9000\u5316\u5f71\u54cd\uff0c\u8bc1\u660e\u4e86\u5747\u8861\u7684\u5b58\u5728\u6027\u548c\u552f\u4e00\u6027\uff0c\u4e3a\u4f4e\u7a7a\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u670d\u52a1\u4fdd\u969c\u3002"}}
{"id": "2508.16379", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.16379", "abs": "https://arxiv.org/abs/2508.16379", "authors": ["Feibo Jiang", "Li Dong", "Xitao Pan", "Kezhi Wang", "Cunhua Pan"], "title": "Agentic AI Empowered Multi-UAV Trajectory Optimization in Low-Altitude Economy Networks", "comment": null, "summary": "This paper proposes a novel Agentic Retrieval-augmented generation with\nMamba-Attention Integrated Transformer (ARMAIT) framework for multi-Unmanned\nAerial Vehicle (UAV) trajectory optimization. The framework is built upon Large\nLanguage Models (LLMs), incorporating Retrieval-Augmented Generation (RAG)\nempowered by Agentic AI and integrated with a UAV-specific knowledge base.\nThrough the Agentic RAG, the LLM autonomously interprets high-level task\nrequirements and identifies the key components necessary for trajectory\noptimization, including model inputs and outputs, network architecture, reward\nfunctions, and task constraints. To support efficient modeling across different\nsystem scales, we introduce the Mamba-Attention Integrated Transformer (MAIT),\na hybrid neural architecture that combines the long-range dependency modeling\ncapability of attention mechanisms with the efficient temporal dynamic\nrepresentation of Mamba. Furthermore, a Trajectory-Group Relative Policy\nOptimization (T-GRPO) method is proposed to achieve unified policy gradient\noptimization in both discrete and continuous trajectory spaces for MAIT\ntraining. Extensive experimental results validate the feasibility and\neffectiveness of the proposed ARMAIT framework.", "AI": {"tldr": "ARMAIT\u6846\u67b6\u7ed3\u5408Agentic RAG\u548cMamba-Attention\u96c6\u6210Transformer\uff0c\u7528\u4e8e\u591a\u65e0\u4eba\u673a\u8f68\u8ff9\u4f18\u5316\uff0c\u901a\u8fc7\u81ea\u4e3b\u89e3\u91ca\u4efb\u52a1\u9700\u6c42\u5e76\u5b9e\u73b0\u79bb\u6563\u548c\u8fde\u7eed\u8f68\u8ff9\u7a7a\u95f4\u7684\u7edf\u4e00\u7b56\u7565\u4f18\u5316\u3002", "motivation": "\u89e3\u51b3\u591a\u65e0\u4eba\u673a\u8f68\u8ff9\u4f18\u5316\u4e2d\u9ad8\u7ef4\u72b6\u6001\u7a7a\u95f4\u3001\u590d\u6742\u7ea6\u675f\u548c\u4e0d\u540c\u7cfb\u7edf\u89c4\u6a21\u4e0b\u7684\u9ad8\u6548\u5efa\u6a21\u6311\u6218\uff0c\u9700\u8981\u80fd\u591f\u81ea\u4e3b\u7406\u89e3\u4efb\u52a1\u9700\u6c42\u5e76\u6709\u6548\u5904\u7406\u957f\u5e8f\u5217\u4f9d\u8d56\u7684\u667a\u80fd\u6846\u67b6\u3002", "method": "1) \u57fa\u4e8eLLM\u7684Agentic RAG\u81ea\u4e3b\u89e3\u6790\u4efb\u52a1\u9700\u6c42\uff1b2) \u63d0\u51faMamba-Attention\u96c6\u6210Transformer(MAIT)\u6df7\u5408\u67b6\u6784\uff1b3) \u8bbe\u8ba1Trajectory-Group Relative Policy Optimization(T-GRPO)\u65b9\u6cd5\u8fdb\u884c\u7edf\u4e00\u7b56\u7565\u4f18\u5316", "result": "\u5927\u91cf\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86ARMAIT\u6846\u67b6\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\uff0c\u5728\u591a\u65e0\u4eba\u673a\u8f68\u8ff9\u4f18\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "ARMAIT\u6846\u67b6\u6210\u529f\u6574\u5408\u4e86Agentic AI\u3001RAG\u548c\u6df7\u5408\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u4e3a\u591a\u65e0\u4eba\u673a\u8f68\u8ff9\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u81ea\u4e3b\u4efb\u52a1\u7406\u89e3\u548c\u9ad8\u6548\u7b56\u7565\u4f18\u5316\u3002"}}
{"id": "2508.16057", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.16057", "abs": "https://arxiv.org/abs/2508.16057", "authors": ["Sijie Yang", "Binyu Lei", "Filip Biljecki"], "title": "Urban Comfort Assessment in the Era of Digital Planning: A Multidimensional, Data-driven, and AI-assisted Framework", "comment": "Presented at 19th International Conference on Computational Urban\n  Planning and Urban Management (CUPUM 2025)", "summary": "Ensuring liveability and comfort is one of the fundamental objectives of\nurban planning. Numerous studies have employed computational methods to assess\nand quantify factors related to urban comfort such as greenery coverage,\nthermal comfort, and walkability. However, a clear definition of urban comfort\nand its comprehensive evaluation framework remain elusive. Our research\nexplores the theoretical interpretations and methodologies for assessing urban\ncomfort within digital planning, emphasising three key dimensions:\nmultidimensional analysis, data support, and AI assistance.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u6570\u5b57\u89c4\u5212\u4e2d\u57ce\u5e02\u8212\u9002\u5ea6\u7684\u7406\u8bba\u89e3\u91ca\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u591a\u7ef4\u5206\u6790\u3001\u6570\u636e\u652f\u6301\u548cAI\u8f85\u52a9\u4e09\u4e2a\u5173\u952e\u7ef4\u5ea6", "motivation": "\u786e\u4fdd\u5b9c\u5c45\u6027\u548c\u8212\u9002\u5ea6\u662f\u57ce\u5e02\u89c4\u5212\u7684\u57fa\u672c\u76ee\u6807\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u57ce\u5e02\u8212\u9002\u5ea6\u7684\u660e\u786e\u5b9a\u4e49\u548c\u7efc\u5408\u8bc4\u4f30\u6846\u67b6", "method": "\u901a\u8fc7\u591a\u7ef4\u5206\u6790\u3001\u6570\u636e\u652f\u6301\u548cAI\u8f85\u52a9\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u57ce\u5e02\u8212\u9002\u5ea6\uff0c\u5305\u62ec\u7eff\u5316\u8986\u76d6\u7387\u3001\u70ed\u8212\u9002\u5ea6\u548c\u6b65\u884c\u6027\u7b49\u56e0\u7d20", "result": "\u63d0\u51fa\u4e86\u57ce\u5e02\u8212\u9002\u5ea6\u8bc4\u4f30\u7684\u7406\u8bba\u6846\u67b6\u548c\u65b9\u6cd5\u8bba\uff0c\u4e3a\u6570\u5b57\u89c4\u5212\u63d0\u4f9b\u652f\u6301", "conclusion": "\u7814\u7a76\u4e3a\u57ce\u5e02\u8212\u9002\u5ea6\u7684\u7efc\u5408\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u65b9\u6cd5\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u57ce\u5e02\u89c4\u5212\u7684\u5b9c\u5c45\u6027\u548c\u8212\u9002\u5ea6"}}
{"id": "2508.15843", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.15843", "abs": "https://arxiv.org/abs/2508.15843", "authors": ["Peihao Yan", "Huacheng Zeng", "Y. Thomas Hou"], "title": "xDiff: Online Diffusion Model for Collaborative Inter-Cell Interference Management in 5G O-RAN", "comment": null, "summary": "Open Radio Access Network (O-RAN) is a key architectural paradigm for 5G and\nbeyond cellular networks, enabling the adoption of intelligent and efficient\nresource management solutions. Meanwhile, diffusion models have demonstrated\nremarkable capabilities in image and video generation, making them attractive\nfor network optimization tasks. In this paper, we propose xDiff, a\ndiffusion-based reinforcement learning(RL) framework for inter-cell\ninterference management (ICIM) in O-RAN. We first formulate ICIM as a resource\nallocation optimization problem aimed at maximizing a user-defined reward\nfunction and then develop an online learning solution by integrating a\ndiffusion model into an RL framework for near-real-time policy generation.\nParticularly, we introduce a novel metric, preference values, as the policy\nrepresentation to enable efficient policy-guided resource allocation within\nO-RAN distributed units (DUs). We implement xDiff on a 5G testbed consisting of\nthree cells and a set of smartphones in two small-cell scenarios. Experimental\nresults demonstrate that xDiff outperforms state-of-the-art ICIM approaches,\nhighlighting the potential of diffusion models for online optimization of\nO-RAN. Source code is available on GitHub [1].", "AI": {"tldr": "xDiff\u662f\u4e00\u4e2a\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8eO-RAN\u7f51\u7edc\u4e2d\u7684\u5c0f\u533a\u95f4\u5e72\u6270\u7ba1\u7406\uff0c\u901a\u8fc7\u6269\u6563\u6a21\u578b\u5b9e\u73b0\u8fd1\u5b9e\u65f6\u7b56\u7565\u751f\u6210\uff0c\u57285G\u6d4b\u8bd5\u5e8a\u4e0a\u9a8c\u8bc1\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "O-RAN\u662f5G\u53ca\u672a\u6765\u8702\u7a9d\u7f51\u7edc\u7684\u5173\u952e\u67b6\u6784\u8303\u5f0f\uff0c\u9700\u8981\u667a\u80fd\u9ad8\u6548\u7684\u8d44\u6e90\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002\u6269\u6563\u6a21\u578b\u5728\u56fe\u50cf\u548c\u89c6\u9891\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u6709\u6f5c\u529b\u7528\u4e8e\u7f51\u7edc\u4f18\u5316\u4efb\u52a1\u3002", "method": "\u5c06\u5c0f\u533a\u95f4\u5e72\u6270\u7ba1\u7406\u5efa\u6a21\u4e3a\u8d44\u6e90\u5206\u914d\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u6269\u6563\u6a21\u578b\u96c6\u6210\u5230\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e2d\u5b9e\u73b0\u5728\u7ebf\u5b66\u4e60\uff0c\u5f15\u5165\u504f\u597d\u503c\u4f5c\u4e3a\u7b56\u7565\u8868\u793a\uff0c\u5728O-RAN\u5206\u5e03\u5f0f\u5355\u5143\u4e2d\u5b9e\u73b0\u7b56\u7565\u5f15\u5bfc\u7684\u8d44\u6e90\u5206\u914d\u3002", "result": "\u5728\u7531\u4e09\u4e2a\u5c0f\u533a\u548c\u4e00\u7ec4\u667a\u80fd\u624b\u673a\u7ec4\u6210\u76845G\u6d4b\u8bd5\u5e8a\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0cxDiff\u5728\u4e24\u79cd\u5c0f\u5c0f\u533a\u573a\u666f\u4e0b\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u5c0f\u533a\u95f4\u5e72\u6270\u7ba1\u7406\u65b9\u6cd5\u3002", "conclusion": "xDiff\u5c55\u793a\u4e86\u6269\u6563\u6a21\u578b\u5728O-RAN\u5728\u7ebf\u4f18\u5316\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u7f51\u7edc\u8d44\u6e90\u7ba1\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.16498", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.16498", "abs": "https://arxiv.org/abs/2508.16498", "authors": ["Jiajie Li", "Sihui Shen", "Warren J. Gross"], "title": "Enhanced Successive Cancellation List Decoder for Long Polar Codes Targeting 6G Air Interface", "comment": null, "summary": "The 6th generation communication standard's air interface requires innovation\nin channel coding to fulfill anticipated energy and area cost reduction\nrequirements. In this paper, we propose algorithmic techniques to enable the\nimplementation of long polar codes (e.g., length 8K bits) in next-generation\ncommunications standards by addressing key challenges in memory usage and\ncomputational complexity presented by successive decoding list (SCL) polar\ndecoding. Perturbation-enhanced (PE) successive cancelation list (SCL) decoders\nwith a list size of $L$ reach the decoding performance of the SCL decoder with\na list size of $2L$. The proposed bias-enhanced (BE) SCL decoders, which\nsimplifies the PE SCL decoder based on insights gained by an ablation study,\nreturns similar decoding performance to PE SCL decoders. Also, proposed BE\ngeneralized partitioned SCL (GPSCL) decoders with a list size of $8$ have a\n$67\\%$ reduction in the memory usage and similar decoding performance compared\nto SCL decoders with a list size of $16$. Furthermore, input-distribution-aware\n(IDA) decoding is applied to BE GPSCL decoders. Up to $5.4\\times$ reduction in\nthe computational complexity is achieved compared to SCL decoders with a list\nsize of $16$. The degraded decoding performance is at most $0.05\\text{ dB}$\ncompared to BE GPSCL decoders without IDA decoding.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u7b97\u6cd5\u6539\u8fdb\u6280\u672f\uff0c\u5305\u62ecPE SCL\u3001BE SCL\u3001BE GPSCL\u548cIDA\u89e3\u7801\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u89e3\u7801\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u957f\u6781\u7801\u7684\u5185\u5b58\u4f7f\u7528\u548c\u8ba1\u7b97\u590d\u6742\u5ea6", "motivation": "\u4e3a\u6ee1\u8db36G\u901a\u4fe1\u6807\u51c6\u5bf9\u80fd\u6e90\u548c\u9762\u79ef\u6210\u672c\u964d\u4f4e\u7684\u8981\u6c42\uff0c\u9700\u8981\u89e3\u51b3\u957f\u6781\u7801\uff088K\u6bd4\u7279\uff09\u5728SCL\u89e3\u7801\u4e2d\u7684\u5185\u5b58\u4f7f\u7528\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u6311\u6218", "method": "\u63d0\u51fa\u56db\u79cd\u7b97\u6cd5\u6280\u672f\uff1a1\u3001\u6c61\u6ce2\u589e\u5f3a(PE)SCL\u89e3\u7801\u5668\uff1b2\u3001\u504f\u7f6e\u589e\u5f3a(BE)SCL\u89e3\u7801\u5668\uff1b3\u3001BE\u5e7f\u4e49\u5206\u533a(GPSCL)\u89e3\u7801\u5668\uff1b4\u3001\u8f93\u5165\u5206\u5e03\u611f\u77e5(IDA)\u89e3\u7801", "result": "PE SCL\u89e3\u7801\u5668\u7528L\u5217\u8868\u5927\u5c0f\u8fbe\u52302L\u7684\u89e3\u7801\u6027\u80fd\uff1bBE GPSCL\u89e3\u7801\u5668\u5185\u5b58\u4f7f\u7528\u964d\u4f4e67%\uff1bIDA\u89e3\u7801\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u4f4e5.4\u500d\uff0c\u6027\u80fd\u635f\u5931\u4ec50.05dB\u4ee5\u5185", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a6G\u901a\u4fe1\u6807\u51c6\u4e2d\u957f\u6781\u7801\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u9ad8\u89e3\u7801\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u4f18\u5316\u4e86\u786c\u4ef6\u8d44\u6e90\u6d88\u8017"}}
{"id": "2508.16059", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.16059", "abs": "https://arxiv.org/abs/2508.16059", "authors": ["Zhuomin Chen", "Dan Li", "Jiahui Zhou", "Shunyu Wu", "Haozheng Ye", "Jian Lou", "See-Kiong Ng"], "title": "Integrating Time Series into LLMs via Multi-layer Steerable Embedding Fusion for Enhanced Forecasting", "comment": "To be published in CIKM 2025", "summary": "Time series (TS) data are ubiquitous across various application areas,\nrendering time series forecasting (TSF) a fundamental task. With the astounding\nadvances in large language models (LLMs), a variety of methods have been\ndeveloped to adapt LLMs for time series forecasting. Despite unlocking the\npotential of LLMs in comprehending TS data, existing methods are inherently\nconstrained by their shallow integration of TS information, wherein LLMs\ntypically access TS representations at shallow layers, primarily at the input\nlayer. This causes the influence of TS representations to progressively fade in\ndeeper layers and eventually leads to ineffective adaptation between textual\nembeddings and TS representations. In this paper, we propose the Multi-layer\nSteerable Embedding Fusion (MSEF), a novel framework that enables LLMs to\ndirectly access time series patterns at all depths, thereby mitigating the\nprogressive loss of TS information in deeper layers. Specifically, MSEF\nleverages off-the-shelf time series foundation models to extract semantically\nrich embeddings, which are fused with intermediate text representations across\nLLM layers via layer-specific steering vectors. These steering vectors are\ndesigned to continuously optimize the alignment between time series and textual\nmodalities and facilitate a layer-specific adaptation mechanism that ensures\nefficient few-shot learning capabilities. Experimental results on seven\nbenchmarks demonstrate significant performance improvements by MSEF compared\nwith baselines, with an average reduction of 31.8% in terms of MSE. The code is\navailable at https://github.com/One1sAll/MSEF.", "AI": {"tldr": "MSEF\u6846\u67b6\u901a\u8fc7\u591a\u5c42\u53ef\u5f15\u5bfc\u5d4c\u5165\u878d\u5408\uff0c\u89e3\u51b3LLM\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2dTS\u4fe1\u606f\u5728\u6df1\u5c42\u9010\u6e10\u6d88\u5931\u7684\u95ee\u9898\uff0c\u57287\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747MSE\u964d\u4f4e31.8%", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u65f6\u95f4\u5e8f\u5217\u4fe1\u606f\u6d45\u5c42\u96c6\u6210\u5230LLM\u4e2d\uff0c\u5bfc\u81f4TS\u8868\u793a\u5728\u6df1\u5c42\u9010\u6e10\u6d88\u5931\uff0c\u6587\u672c\u5d4c\u5165\u4e0eTS\u8868\u793a\u4e4b\u95f4\u9002\u5e94\u6548\u679c\u4e0d\u4f73", "method": "\u5229\u7528\u73b0\u6210\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u63d0\u53d6\u8bed\u4e49\u4e30\u5bcc\u7684\u5d4c\u5165\uff0c\u901a\u8fc7\u5c42\u7279\u5b9a\u5f15\u5bfc\u5411\u91cf\u5728LLM\u5404\u5c42\u4e2d\u95f4\u6587\u672c\u8868\u793a\u8fdb\u884c\u878d\u5408\uff0c\u6301\u7eed\u4f18\u5316\u65f6\u95f4\u5e8f\u5217\u4e0e\u6587\u672c\u6a21\u6001\u7684\u5bf9\u9f50", "result": "\u57287\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u8868\u73b0\u663e\u8457\u63d0\u5347\uff0c\u5e73\u5747MSE\u964d\u4f4e31.8%", "conclusion": "MSEF\u6846\u67b6\u901a\u8fc7\u591a\u5c42\u878d\u5408\u673a\u5236\u6709\u6548\u7f13\u89e3\u4e86TS\u4fe1\u606f\u5728LLM\u6df1\u5c42\u4e22\u5931\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5c0f\u6837\u672c\u5b66\u4e60\u80fd\u529b"}}
{"id": "2508.16035", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16035", "abs": "https://arxiv.org/abs/2508.16035", "authors": ["Poorvi Joshi", "Mohan Gurusamy"], "title": "Time Series Based Network Intrusion Detection using MTF-Aided Transformer", "comment": "7 pages, 3 figures. Accepted and presented at The Fifth Intelligent\n  Cybersecurity Conference (ICSC 2025), nominated for Best Paper Award", "summary": "This paper introduces a novel approach to time series classification using a\nMarkov Transition Field (MTF)-aided Transformer model, specifically designed\nfor Software-Defined Networks (SDNs). The proposed model integrates the\ntemporal dependency modeling strengths of MTFs with the sophisticated pattern\nrecognition capabilities of Transformer architectures. We evaluate the model's\nperformance using the InSDN dataset, demonstrating that our model outperforms\nbaseline classification models, particularly in data-constrained environments\ncommonly encountered in SDN applications. We also highlight the relationship\nbetween the MTF and Transformer components, which leads to better performance,\neven with limited data. Furthermore, our approach achieves competitive training\nand inference times, making it an efficient solution for real-world SDN\napplications. These findings establish the potential of MTF-aided Transformers\nto address the challenges of time series classification in SDNs, offering a\npromising path for reliable and scalable analysis in scenarios with sparse\ndata.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u8f6c\u79fb\u573a(MTF)\u8f85\u52a9Transformer\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u65b0\u65b9\u6cd5\uff0c\u4e13\u95e8\u7528\u4e8e\u8f6f\u4ef6\u5b9a\u4e49\u7f51\u7edc(SDN)\uff0c\u5728\u6570\u636e\u53d7\u9650\u73af\u5883\u4e0b\u8868\u73b0\u4f18\u5f02", "motivation": "\u89e3\u51b3SDN\u4e2d\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u758f\u73af\u5883\u4e0b\u4f20\u7edf\u65b9\u6cd5\u6027\u80fd\u53d7\u9650\u7684\u95ee\u9898", "method": "\u5c06MTF\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u5efa\u6a21\u80fd\u529b\u4e0eTransformer\u7684\u590d\u6742\u6a21\u5f0f\u8bc6\u522b\u80fd\u529b\u76f8\u7ed3\u5408\uff0c\u6784\u5efaMTF\u8f85\u52a9\u7684Transformer\u6a21\u578b", "result": "\u5728InSDN\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u57fa\u7ebf\u5206\u7c7b\u6a21\u578b\uff0c\u5728\u6570\u636e\u53d7\u9650\u73af\u5883\u4e2d\u8868\u73b0\u5c24\u5176\u7a81\u51fa\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u95f4", "conclusion": "MTF\u8f85\u52a9Transformer\u4e3a\u89e3\u51b3SDN\u4e2d\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u758f\u573a\u666f\u4e0b\u5177\u6709\u53ef\u9760\u548c\u53ef\u6269\u5c55\u7684\u5206\u6790\u80fd\u529b"}}
{"id": "2508.16072", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.16072", "abs": "https://arxiv.org/abs/2508.16072", "authors": ["Zizhen Li", "Chuanhao Li", "Yibin Wang", "Qi Chen", "Diping Song", "Yukang Feng", "Jianwen Sun", "Jiaxin Ai", "Fanrui Zhang", "Mingzhu Sun", "Kaipeng Zhang"], "title": "InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles", "comment": "EMNLP 2025 MainConference", "summary": "LLMs have shown strong performance on human-centric reasoning tasks. While\nprevious evaluations have explored whether LLMs can infer intentions or detect\ndeception, they often overlook the individualized reasoning styles that\ninfluence how people interpret and act in social contexts. Social deduction\ngames (SDGs) provide a natural testbed for evaluating individualized reasoning\nstyles, where different players may adopt diverse but contextually valid\nreasoning strategies under identical conditions. To address this, we introduce\nInMind, a cognitively grounded evaluation framework designed to assess whether\nLLMs can capture and apply personalized reasoning styles in SDGs. InMind\nenhances structured gameplay data with round-level strategy traces and\npost-game reflections, collected under both Observer and Participant modes. It\nsupports four cognitively motivated tasks that jointly evaluate both static\nalignment and dynamic adaptation. As a case study, we apply InMind to the game\nAvalon, evaluating 11 state-of-the-art LLMs. General-purpose LLMs, even GPT-4o\nfrequently rely on lexical cues, struggling to anchor reflections in temporal\ngameplay or adapt to evolving strategies. In contrast, reasoning-enhanced LLMs\nlike DeepSeek-R1 exhibit early signs of style-sensitive reasoning. These\nfindings reveal key limitations in current LLMs' capacity for individualized,\nadaptive reasoning, and position InMind as a step toward cognitively aligned\nhuman-AI interaction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86InMind\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u6d4b\u8bd5\u5927\u8bed\u8a00\u6a21\u578b\u5728\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u4e2d\u6355\u6349\u548c\u5e94\u7528\u4e2a\u6027\u5316\u63a8\u7406\u98ce\u683c\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524dLLMs\u5728\u4e2a\u4f53\u5316\u9002\u5e94\u6027\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u5c40\u9650\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u5f80\u5f80\u5ffd\u89c6\u4e2a\u4f53\u5316\u63a8\u7406\u98ce\u683c\u5bf9\u793e\u4ea4\u60c5\u5883\u7406\u89e3\u7684\u5f71\u54cd\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8bc4\u4f30LLMs\u662f\u5426\u80fd\u591f\u7406\u89e3\u548c\u5e94\u7528\u4e2a\u6027\u5316\u63a8\u7406\u7b56\u7565\u7684\u6846\u67b6\u3002", "method": "\u5f15\u5165InMind\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3a\u7ed3\u6784\u5316\u6e38\u620f\u6570\u636e\uff08\u56de\u5408\u7ea7\u7b56\u7565\u8ffd\u8e2a\u548c\u8d5b\u540e\u53cd\u601d\uff09\uff0c\u5728\u89c2\u5bdf\u8005\u548c\u53c2\u4e0e\u8005\u4e24\u79cd\u6a21\u5f0f\u4e0b\u6536\u96c6\u6570\u636e\uff0c\u652f\u63014\u4e2a\u8ba4\u77e5\u9a71\u52a8\u7684\u8bc4\u4f30\u4efb\u52a1\u3002", "result": "\u901a\u7528LLMs\uff08\u5305\u62ecGPT-4o\uff09\u8fc7\u5ea6\u4f9d\u8d56\u8bcd\u6c47\u7ebf\u7d22\uff0c\u96be\u4ee5\u5728\u65f6\u95f4\u6e38\u620f\u4e2d\u951a\u5b9a\u53cd\u601d\u6216\u9002\u5e94\u6f14\u5316\u7b56\u7565\uff1b\u800c\u63a8\u7406\u589e\u5f3a\u578bLLMs\uff08\u5982DeepSeek-R1\uff09\u663e\u793a\u51fa\u98ce\u683c\u654f\u611f\u63a8\u7406\u7684\u65e9\u671f\u8ff9\u8c61\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u4e2a\u4f53\u5316\u9002\u5e94\u6027\u63a8\u7406\u80fd\u529b\u4e0a\u5b58\u5728\u5173\u952e\u5c40\u9650\uff0cInMind\u6846\u67b6\u4e3a\u8ba4\u77e5\u5bf9\u9f50\u7684\u4eba\u673a\u4ea4\u4e92\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2508.16074", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.16074", "abs": "https://arxiv.org/abs/2508.16074", "authors": ["Zhiyuan He", "Aashish Gottipati", "Lili Qiu", "Yuqing Yang", "Francis Y. Yan"], "title": "Congestion Control System Optimization with Large Language Models", "comment": null, "summary": "Congestion control is a fundamental component of Internet infrastructure, and\nresearchers have dedicated considerable effort to developing improved\ncongestion control algorithms. However, despite extensive study, existing\nalgorithms continue to exhibit suboptimal performance across diverse network\nenvironments. In this paper, we introduce a novel approach that automatically\noptimizes congestion control algorithms using large language models (LLMs). Our\nframework consists of a structured algorithm generation process, an\nemulation-based evaluation pipeline covering a broad range of network\nconditions, and a statistically guided method to substantially reduce\nevaluation time. Empirical results from four distinct LLMs validate the\neffectiveness of our approach. We successfully identify algorithms that achieve\nup to 27% performance improvements over the original BBR algorithm in a\nproduction QUIC implementation. Our work demonstrates the potential of LLMs to\naccelerate the design of high-performance network algorithms and paves the way\nfor broader applications in networking systems.", "AI": {"tldr": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4f18\u5316\u62e5\u585e\u63a7\u5236\u7b97\u6cd5\uff0c\u5728QUIC\u5b9e\u73b0\u4e2d\u6bd4\u539f\u59cbBBR\u7b97\u6cd5\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe27%", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u5927\u91cf\u7814\u7a76\uff0c\u73b0\u6709\u62e5\u585e\u63a7\u5236\u7b97\u6cd5\u5728\u4e0d\u540c\u7f51\u7edc\u73af\u5883\u4e2d\u4ecd\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u65b0\u7684\u4f18\u5316\u65b9\u6cd5", "method": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7b97\u6cd5\u751f\u6210\u6846\u67b6\uff0c\u5305\u542b\u7ed3\u6784\u5316\u7b97\u6cd5\u751f\u6210\u8fc7\u7a0b\u3001\u8986\u76d6\u5e7f\u6cdb\u7f51\u7edc\u6761\u4ef6\u7684\u4eff\u771f\u8bc4\u4f30\u7ba1\u9053\uff0c\u4ee5\u53ca\u7edf\u8ba1\u6307\u5bfc\u7684\u8bc4\u4f30\u65f6\u95f4\u7f29\u51cf\u65b9\u6cd5", "result": "\u56db\u4e2a\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u8bc1\u7ed3\u679c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5728QUIC\u5b9e\u73b0\u4e2d\u8bc6\u522b\u51fa\u6bd4\u539f\u59cbBBR\u7b97\u6cd5\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe27%\u7684\u7b97\u6cd5", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u52a0\u901f\u9ad8\u6027\u80fd\u7f51\u7edc\u7b97\u6cd5\u8bbe\u8ba1\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3a\u7f51\u7edc\u7cfb\u7edf\u4e2d\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u94fa\u5e73\u4e86\u9053\u8def"}}
{"id": "2508.16112", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16112", "abs": "https://arxiv.org/abs/2508.16112", "authors": ["Heewoong Noh", "Namkyeong Lee", "Gyoung S. Na", "Kibum Kim", "Chanyoung Park"], "title": "IR-Agent: Expert-Inspired LLM Agents for Structure Elucidation from Infrared Spectra", "comment": null, "summary": "Spectral analysis provides crucial clues for the elucidation of unknown\nmaterials. Among various techniques, infrared spectroscopy (IR) plays an\nimportant role in laboratory settings due to its high accessibility and low\ncost. However, existing approaches often fail to reflect expert analytical\nprocesses and lack flexibility in incorporating diverse types of chemical\nknowledge, which is essential in real-world analytical scenarios. In this\npaper, we propose IR-Agent, a novel multi-agent framework for molecular\nstructure elucidation from IR spectra. The framework is designed to emulate\nexpert-driven IR analysis procedures and is inherently extensible. Each agent\nspecializes in a specific aspect of IR interpretation, and their complementary\nroles enable integrated reasoning, thereby improving the overall accuracy of\nstructure elucidation. Through extensive experiments, we demonstrate that\nIR-Agent not only improves baseline performance on experimental IR spectra but\nalso shows strong adaptability to various forms of chemical information.", "AI": {"tldr": "IR-Agent\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u7ea2\u5916\u5149\u8c31\u4e2d\u89e3\u6790\u5206\u5b50\u7ed3\u6784\uff0c\u6a21\u62df\u4e13\u5bb6\u5206\u6790\u6d41\u7a0b\u5e76\u5177\u6709\u826f\u597d\u6269\u5c55\u6027", "motivation": "\u73b0\u6709\u7ea2\u5916\u5149\u8c31\u5206\u6790\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u53cd\u6620\u4e13\u5bb6\u5206\u6790\u8fc7\u7a0b\uff0c\u7f3a\u4e4f\u6574\u5408\u591a\u79cd\u5316\u5b66\u77e5\u8bc6\u7684\u7075\u6d3b\u6027\uff0c\u800c\u8fd9\u5bf9\u5b9e\u9645\u5206\u6790\u573a\u666f\u81f3\u5173\u91cd\u8981", "method": "\u63d0\u51fa\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u6bcf\u4e2a\u4ee3\u7406\u4e13\u95e8\u8d1f\u8d23\u7ea2\u5916\u5149\u8c31\u89e3\u91ca\u7684\u7279\u5b9a\u65b9\u9762\uff0c\u901a\u8fc7\u4e92\u8865\u89d2\u8272\u5b9e\u73b0\u96c6\u6210\u63a8\u7406", "result": "\u5b9e\u9a8c\u8868\u660eIR-Agent\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u5b9e\u9a8c\u7ea2\u5916\u5149\u8c31\u7684\u57fa\u7ebf\u6027\u80fd\uff0c\u8fd8\u5c55\u73b0\u51fa\u5bf9\u5404\u79cd\u5316\u5b66\u4fe1\u606f\u5f62\u5f0f\u7684\u5f3a\u9002\u5e94\u6027", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u6a21\u62df\u4e13\u5bb6\u9a71\u52a8\u7684\u7ea2\u5916\u5206\u6790\u6d41\u7a0b\uff0c\u63d0\u9ad8\u7ed3\u6784\u89e3\u6790\u7684\u6574\u4f53\u51c6\u786e\u6027\uff0c\u5e76\u5177\u6709\u56fa\u6709\u7684\u53ef\u6269\u5c55\u6027"}}
{"id": "2508.16119", "categories": ["cs.NI", "cs.AI", "60K20 (Primary), 90B25, 68M15 (Secondary)", "C.2.4; D.4.7; I.2.6"], "pdf": "https://arxiv.org/pdf/2508.16119", "abs": "https://arxiv.org/abs/2508.16119", "authors": ["Madhava Gaikwad", "Abhishek Gandhi"], "title": "ANSC: Probabilistic Capacity Health Scoring for Datacenter-Scale Reliability", "comment": "3 pages", "summary": "We present ANSC, a probabilistic capacity health scoring framework for\nhyperscale datacenter fabrics. While existing alerting systems detect\nindividual device or link failures, they do not capture the aggregate risk of\ncascading capacity shortfalls. ANSC provides a color-coded scoring system that\nindicates the urgency of issues \\emph{not solely by current impact, but by the\nprobability of imminent capacity violations}. Our system accounts for both\ncurrent residual capacity and the probability of additional failures,\nnormalized at datacenter and regional level. We demonstrate that ANSC enables\noperators to prioritize remediation across more than 400 datacenters and 60\nregions, reducing noise and aligning SRE focus on the most critical risks.", "AI": {"tldr": "ANSC\u662f\u4e00\u4e2a\u6982\u7387\u5bb9\u91cf\u5065\u5eb7\u8bc4\u5206\u6846\u67b6\uff0c\u7528\u4e8e\u8d85\u5927\u89c4\u6a21\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\uff0c\u901a\u8fc7\u989c\u8272\u7f16\u7801\u7cfb\u7edf\u8bc4\u4f30\u5bb9\u91cf\u8fdd\u89c4\u7684\u7d27\u8feb\u6027\u6982\u7387\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5f53\u524d\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u544a\u8b66\u7cfb\u7edf\u53ea\u80fd\u68c0\u6d4b\u5355\u4e2a\u8bbe\u5907\u6216\u94fe\u8def\u6545\u969c\uff0c\u65e0\u6cd5\u6355\u6349\u7ea7\u8054\u5bb9\u91cf\u77ed\u7f3a\u7684\u805a\u5408\u98ce\u9669\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u8bc4\u4f30\u5373\u5c06\u53d1\u751f\u5bb9\u91cf\u8fdd\u89c4\u6982\u7387\u7684\u7cfb\u7edf\u3002", "method": "ANSC\u7efc\u5408\u8003\u8651\u5f53\u524d\u5269\u4f59\u5bb9\u91cf\u548c\u989d\u5916\u6545\u969c\u6982\u7387\uff0c\u5728\u6570\u636e\u4e2d\u5fc3\u548c\u533a\u57df\u7ea7\u522b\u8fdb\u884c\u5f52\u4e00\u5316\u5904\u7406\uff0c\u63d0\u4f9b\u989c\u8272\u7f16\u7801\u7684\u8bc4\u5206\u7cfb\u7edf\u3002", "result": "ANSC\u4f7f\u64cd\u4f5c\u4eba\u5458\u80fd\u591f\u5728400\u591a\u4e2a\u6570\u636e\u4e2d\u5fc3\u548c60\u4e2a\u533a\u57df\u4e2d\u4f18\u5148\u5904\u7406\u4fee\u590d\u5de5\u4f5c\uff0c\u51cf\u5c11\u566a\u97f3\u5e76\u4f7fSRE\u4e13\u6ce8\u4e8e\u6700\u5173\u952e\u7684\u98ce\u9669\u3002", "conclusion": "ANSC\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u8d85\u5927\u89c4\u6a21\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u4e2d\u5bb9\u91cf\u98ce\u9669\u7684\u6982\u7387\u8bc4\u4f30\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u8fd0\u7ef4\u6548\u7387\u548c\u98ce\u9669\u7ba1\u7406\u7684\u7cbe\u51c6\u6027\u3002"}}
{"id": "2508.16117", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.16117", "abs": "https://arxiv.org/abs/2508.16117", "authors": ["Saransh Kumar Gupta", "Rizwan Gulzar Mir", "Lipika Dey", "Partha Pratim Das", "Anirban Sen", "Ramesh Jain"], "title": "Extending FKG.in: Towards a Food Claim Traceability Network", "comment": "10 pages, 3 figures, 1 table, 45 references, ACM International\n  Conference on Multimedia 2025 - Multi-modal Food Computing Workshop", "summary": "The global food landscape is rife with scientific, cultural, and commercial\nclaims about what foods are, what they do, what they should not do, or should\nnot do. These range from rigorously studied health benefits (probiotics improve\ngut health) and misrepresentations (soaked almonds make one smarter) to vague\npromises (superfoods boost immunity) and culturally rooted beliefs (cold foods\ncause coughs). Despite their widespread influence, the infrastructure for\ntracing, verifying, and contextualizing these claims remains fragmented and\nunderdeveloped. In this paper, we propose a Food Claim-Traceability Network\n(FCN) as an extension of FKG.in, a knowledge graph of Indian food that we have\nbeen incrementally building. We also present the ontology design and the\nsemi-automated knowledge curation workflow that we used to develop a proof of\nconcept of FKG.in-FCN using Reddit data and Large Language Models. FCN\nintegrates curated data inputs, structured schemas, and provenance-aware\npipelines for food-related claim extraction and validation. While directly\nlinked to the Indian food knowledge graph as an application, our methodology\nremains application-agnostic and adaptable to other geographic, culinary, or\nregulatory settings. By modeling food claims and their traceability in a\nstructured, verifiable, and explainable way, we aim to contribute to more\ntransparent and accountable food knowledge ecosystems, supporting researchers,\npolicymakers, and most importantly, everyday consumers in navigating a world\nsaturated with dietary assertions.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u98df\u7269\u58f0\u660e\u53ef\u8ffd\u6eaf\u7f51\u7edc(FCN)\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u548c\u534a\u81ea\u52a8\u5316\u77e5\u8bc6\u7ec4\u7ec7\u65b9\u6cd5\uff0c\u5efa\u7acb\u7ed3\u6784\u5316\u7684\u98df\u7269\u76f8\u5173\u58f0\u660e\u9a8c\u8bc1\u4f53\u7cfb\uff0c\u4ee5\u5e94\u5bf9\u98df\u54c1\u9884\u9632\u5065\u5eb7\u58f0\u660e\u7684\u6df7\u4e71\u73b0\u8c61\u3002", "motivation": "\u5f53\u524d\u5168\u7403\u98df\u54c1\u9884\u9632\u5065\u5eb7\u58f0\u660e\u6df7\u4e71\u4e0d\u6e05\uff0c\u5305\u542b\u79d1\u5b66\u3001\u6587\u5316\u548c\u5546\u4e1a\u5404\u79cd\u58f0\u660e\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u8ffd\u8e2a\u3001\u9a8c\u8bc1\u548c\u4e0a\u4e0b\u6587\u5316\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u5728\u5370\u5ea6\u98df\u7269\u77e5\u8bc6\u56feFKG.in\u57fa\u7840\u4e0a\u6269\u5c55\u6784\u5efaFCN\uff0c\u4f7f\u7528\u672c\u4f53\u8bba\u8bbe\u8ba1\u548c\u534a\u81ea\u52a8\u5316\u77e5\u8bc6\u7ec4\u7ec7\u6d41\u7a0b\uff0c\u5229\u7528Reddit\u6570\u636e\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u539f\u578b\u7cfb\u7edf\u3002", "result": "\u5f00\u53d1\u4e86\u96c6\u6210\u7cbe\u9009\u6570\u636e\u8f93\u5165\u3001\u7ed3\u6784\u5316\u6a21\u5f0f\u548c\u6765\u6e90\u53ef\u8ffd\u6eaf\u6d41\u7a0b\u7684FCN\u7cfb\u7edf\uff0c\u65b9\u6cd5\u8bba\u5177\u6709\u5e94\u7528\u65e0\u5173\u6027\uff0c\u53ef\u9002\u914d\u4e0d\u540c\u5730\u7406\u3001\u7096\u996a\u6216\u76d1\u7ba1\u73af\u5883\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5316\u3001\u53ef\u9a8c\u8bc1\u548c\u53ef\u89e3\u91ca\u7684\u65b9\u5f0f\u5efa\u6a21\u98df\u7269\u58f0\u660e\u53ef\u8ffd\u6eaf\u6027\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u900f\u660e\u8d1f\u8d23\u7684\u98df\u7269\u77e5\u8bc6\u751f\u6001\u7cfb\u7edf\uff0c\u652f\u6301\u7814\u7a76\u4eba\u5458\u3001\u653f\u7b56\u5236\u5b9a\u8005\u548c\u666e\u901a\u6d88\u8d39\u8005\u5e94\u5bf9\u98df\u7269\u58f0\u660e\u6c89\u6dc0\u7684\u4e16\u754c\u3002"}}
{"id": "2508.16184", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.16184", "abs": "https://arxiv.org/abs/2508.16184", "authors": ["Yuhao Zheng", "Ting You", "Kejia Peng", "Chang Liu"], "title": "Joint Cache Placement and Routing in Satellite-Terrestrial Edge Computing Network: A GNN-Enabled DRL Approach", "comment": "5 pages, 6 figures", "summary": "In this letter, we investigate the problem of joint content caching and\nrouting in satellite-terrestrial edge computing networks (STECNs) to improve\ncaching service for geographically distributed users. To handle the challenges\narising from dynamic low Earth orbit (LEO) satellite topologies and\nheterogeneous content demands, we propose a learning-based framework that\nintegrates graph neural networks (GNNs) with deep reinforcement learning (DRL).\nThe satellite network is represented as a dynamic graph, where GNNs are\nembedded within the DRL agent to capture spatial and topological dependencies\nand support routing-aware decision-making. The caching strategy is optimized by\nformulating the problem as a Markov decision process (MDP) and applying soft\nactor-critic (SAC) algorithm. Simulation results demonstrate that our approach\nsignificantly improves the delivery success rate and reduces communication\ntraffic cost.", "AI": {"tldr": "\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u5361\u8f66\u670d\u52a1\u4f18\u5316\u65b9\u6848\uff0c\u5728\u536b\u661f\u5730\u9762\u8fb9\u7f18\u8ba1\u7b97\u7f51\u7edc\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5185\u5bb9\u4f20\u8f93\u6548\u7387", "motivation": "\u89e3\u51b3\u52a8\u6001\u4f4e\u8d68\u9053\u536b\u661f\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\u548c\u5f02\u6784\u5185\u5bb9\u9700\u6c42\u5e26\u6765\u7684\u6311\u6218\uff0c\u63d0\u5347\u5730\u7406\u5206\u5e03\u7528\u6237\u7684\u7f13\u5b58\u670d\u52a1\u8d28\u91cf", "method": "\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc(GNN)\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60(DRL)\u76f8\u7ed3\u5408\u7684\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u536b\u661f\u7f51\u7edc\u8868\u793a\u4e3a\u52a8\u6001\u56fe\uff0c\u901a\u8fc7Markov\u51b3\u7b56\u8fc7\u7a0b(MDP)\u548c\u8f6f\u6267\u884c\u7b56-\u8bc4\u4f30\u8005(SAC)\u7b97\u6cd5\u4f18\u5316\u7f13\u5b58\u7b56\u7565", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5185\u5bb9\u4f20\u8f93\u6210\u529f\u7387\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u901a\u4fe1\u6d41\u91cf\u6210\u672c", "conclusion": "\u8be5\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u536b\u661f\u7f51\u7edc\u7684\u52a8\u6001\u6027\u548c\u590d\u6742\u6027\uff0c\u4e3a\u5730\u7406\u5206\u5e03\u7528\u6237\u63d0\u4f9b\u66f4\u597d\u7684\u7f13\u5b58\u670d\u52a1"}}
{"id": "2508.16129", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16129", "abs": "https://arxiv.org/abs/2508.16129", "authors": ["Ruiqi Wu", "Yuang Yao", "Tengfei Ma", "Chenran Zhang", "Na Su", "Tao Zhou", "Geng Chen", "Wen Fan", "Yi Zhou"], "title": "Bridging the Gap in Ophthalmic AI: MM-Retinal-Reason Dataset and OphthaReason Model toward Dynamic Multimodal Reasoning", "comment": null, "summary": "Multimodal large language models (MLLMs) have recently demonstrated\nremarkable reasoning abilities with reinforcement learning paradigm. Although\nseveral multimodal reasoning models have been explored in the medical domain,\nmost of them focus exclusively on basic reasoning, which refers to shallow\ninference based on visual feature matching. However, real-world clinical\ndiagnosis extends beyond basic reasoning, demanding reasoning processes that\nintegrate heterogeneous clinical information (such as chief complaints and\nmedical history) with multimodal medical imaging data. To bridge this gap, we\nintroduce MM-Retinal-Reason, the first ophthalmic multimodal dataset with the\nfull spectrum of perception and reasoning. It encompasses both basic reasoning\ntasks and complex reasoning tasks, aiming to enhance visual-centric fundamental\nreasoning capabilities and emulate realistic clinical thinking patterns.\nBuilding upon MM-Retinal-Reason, we propose OphthaReason, the first\nophthalmology-specific multimodal reasoning model with step-by-step reasoning\ntraces. To enable flexible adaptation to both basic and complex reasoning\ntasks, we specifically design a novel method called Uncertainty-Aware Dynamic\nThinking (UADT), which estimates sample-level uncertainty via entropy and\ndynamically modulates the model's exploration depth using a shaped advantage\nmechanism. Comprehensive experiments demonstrate that our model achieves\nstate-of-the-art performance on both basic and complex reasoning tasks,\noutperforming general-purpose MLLMs, medical MLLMs, RL-based medical MLLMs, and\nophthalmic MLLMs by at least 24.92\\%, 15.00\\%, 21.20\\%, and 17.66\\%. Project\nPage: \\href{https://github.com/lxirich/OphthaReason}{link}.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86OphthaReason\u6a21\u578b\u548cUADT\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u7b2c\u4e00\u4e2a\u773c\u79d1\u591a\u6a21\u6001\u6570\u636e\u96c6MM-Retinal-Reason\uff0c\u5728\u773c\u79d1\u533b\u5b66\u8bca\u65ad\u4e2d\u5b9e\u73b0\u4e86\u57fa\u7840\u548c\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u6700\u4f73\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\u4ec5\u805a\u7126\u57fa\u7840\u63a8\u7406\uff0c\u800c\u771f\u5b9e\u4e34\u5e8a\u8bca\u65ad\u9700\u8981\u6574\u5408\u5f02\u6784\u4e34\u5e8a\u4fe1\u606f\u548c\u591a\u6a21\u6001\u533b\u5b66\u5f71\u50cf\u6570\u636e\u7684\u590d\u6742\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u6784\u5efaMM-Retinal-Reason\u6570\u636e\u96c6\uff0c\u63d0\u51faOphthaReason\u6a21\u578b\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u52a8\u6001\u601d\u7ef4\uff08UADT\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u71b3\u63d0\u4f30\u8ba1\u6837\u672c\u4e0d\u786e\u5b9a\u6027\u5e76\u52a8\u6001\u8c03\u8282\u6a21\u578b\u63a2\u7d22\u6df1\u5ea6\u3002", "result": "\u6a21\u578b\u5728\u57fa\u7840\u548c\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u90fd\u8fbe\u5230\u6700\u4f73\u6027\u80fd\uff0c\u8d85\u8fc7\u901a\u7528MLLM\u3001\u533b\u5b66MLLM\u3001RL\u57fa\u7840\u533b\u5b66MLLM\u548c\u773c\u79d1MLLM\u81f3\u5c1124.92%\u300115.00%\u300121.20%\u548c17.66%\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u773c\u79d1\u591a\u6a21\u6001\u63a8\u7406\u7684\u7a7a\u767d\uff0c\u901a\u8fc7UADT\u65b9\u6cd5\u5b9e\u73b0\u4e86\u7cbe\u51c6\u7684\u4e34\u5e8a\u601d\u7ef4\u6a21\u62df\uff0c\u4e3a\u533b\u5b66AI\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.16268", "categories": ["cs.NI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.16268", "abs": "https://arxiv.org/abs/2508.16268", "authors": ["Rob Carson", "Mohamed Chahine Ghanem", "Feriel Bouakkaz"], "title": "Self-Healing Network of Interconnected Edge Devices Empowered by Infrastructure-as-Code and LoRa Communication", "comment": null, "summary": "This Paper proposes a self-healing, automated network of Raspberry Pi devices\ndesigned for deployment in scenarios where traditional networking is\nunavailable. Leveraging the low-power, long-range capabilities of the LoRa\n(Long Range) protocol alongside Infrastructure as Code (IaC) methodologies, the\nresearch addresses challenges such as limited bandwidth, data collisions, and\nnode failures. Given that LoRa's packet-based system is incompatible with\nconventional IaC tools like Ansible and Terraform, which rely on TCP/IP\nnetworking, the research adapts IaC principles within a containerised\narchitecture deployed across a Raspberry Pi cluster. Evaluation experiments\nindicate that fragmenting data packets and retransmitting any missed fragments\ncan mitigate LoRa's inherent throughput and packet size limitations, although\nissues such as collisions and line-of-sight interference persist. An automated\nfailover mechanism was integrated into the architecture, enabling unresponsive\nservices to be redeployed to alternative nodes within one second, demonstrating\nthe system's resilience in maintaining operational continuity despite node or\nservice failures. The paper also identifies practical challenges, including the\nnecessity for time-slotting transmissions to prevent data packet overlap and\ncollisions. Future research should explore the integration of mesh networking\nto enhance range, develop more advanced scheduling algorithms, and adopt\ncutting-edge low-power wide-area network (LPWAN) techniques.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRaspberry Pi\u548cLoRa\u534f\u8bae\u7684\u81ea\u6062\u590d\u81ea\u52a8\u5316\u7f51\u7edc\u7cfb\u7edf\uff0c\u901a\u8fc7\u5bb9\u5668\u5316\u67b6\u6784\u548cIaC\u539f\u5219\u89e3\u51b3\u4f20\u7edfIaC\u5de5\u5177\u5728LoRa\u7f51\u7edc\u4e2d\u7684\u517c\u5bb9\u6027\u95ee\u9898\uff0c\u5e76\u96c6\u6210\u4e86\u81ea\u52a8\u6545\u969c\u8f6c\u79fb\u673a\u5236\u3002", "motivation": "\u89e3\u51b3\u5728\u4f20\u7edf\u7f51\u7edc\u4e0d\u53ef\u7528\u573a\u666f\u4e0b\uff0c\u4f7f\u7528LoRa\u534f\u8bae\u7684\u4f4e\u529f\u8017\u957f\u8ddd\u79bb\u7f51\u7edc\u90e8\u7f72\u7684\u6311\u6218\uff0c\u5305\u62ec\u5e26\u5bbd\u9650\u5236\u3001\u6570\u636e\u78b0\u649e\u548c\u8282\u70b9\u6545\u969c\u7b49\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5bb9\u5668\u5316\u67b6\u6784\u5728Raspberry Pi\u96c6\u7fa4\u4e2d\u90e8\u7f72\uff0c\u9002\u914dIaC\u539f\u5219\u4ee5\u6ee1\u8db3LoRa\u534f\u8bae\u7684\u5305\u57fa\u7840\u7ed3\u6784\u3002\u901a\u8fc7\u6570\u636e\u5305\u5206\u7247\u548c\u91cd\u4f20\u673a\u5236\u7f13\u89e3\u901a\u4fe1\u9650\u5236\uff0c\u5e76\u96c6\u6210\u81ea\u52a8\u6545\u969c\u8f6c\u79fb\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u6570\u636e\u5305\u5206\u7247\u548c\u91cd\u4f20\u673a\u5236\u53ef\u6709\u6548\u7f13\u89e3LoRa\u7684\u541e\u5410\u91cf\u548c\u5305\u5927\u5c0f\u9650\u5236\u3002\u81ea\u52a8\u6545\u969c\u8f6c\u79fb\u673a\u5236\u80fd\u57281\u79d2\u5185\u5c06\u670d\u52a1\u91cd\u65b0\u90e8\u7f72\u5230\u5176\u4ed6\u8282\u70b9\uff0c\u663e\u793a\u4e86\u7cfb\u7edf\u7684\u5f39\u6027\u3002\u4f46\u78b0\u649e\u548c\u89c6\u7ebf\u5e72\u6270\u95ee\u9898\u4ecd\u5b58\u5728\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5c55\u793a\u4e86\u5728LoRa\u7f51\u7edc\u4e2d\u5b9e\u73b0IaC\u539f\u5219\u7684\u53ef\u884c\u6027\u3002\u672a\u6765\u5de5\u4f5c\u5e94\u63a2\u7d22\u7f51\u683c\u7f51\u7edc\u96c6\u6210\u3001\u66f4\u5148\u8fdb\u7684\u8c03\u5ea6\u7b97\u6cd5\u4ee5\u53ca\u65b0\u5174\u7684\u4f4e\u529f\u8017\u5e7f\u57df\u7f51\u6280\u672f\u6765\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2508.16172", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16172", "abs": "https://arxiv.org/abs/2508.16172", "authors": ["Kai Hu", "Parfait Atchade-Adelomou", "Carlo Adornetto", "Adrian Mora-Carrero", "Luis Alonso-Pastor", "Ariel Noyman", "Yubo Liu", "Kent Larson"], "title": "Graph RAG as Human Choice Model: Building a Data-Driven Mobility Agent with Preference Chain", "comment": null, "summary": "Understanding human behavior in urban environments is a crucial field within\ncity sciences. However, collecting accurate behavioral data, particularly in\nnewly developed areas, poses significant challenges. Recent advances in\ngenerative agents, powered by Large Language Models (LLMs), have shown promise\nin simulating human behaviors without relying on extensive datasets.\nNevertheless, these methods often struggle with generating consistent,\ncontext-sensitive, and realistic behavioral outputs. To address these\nlimitations, this paper introduces the Preference Chain, a novel method that\nintegrates Graph Retrieval-Augmented Generation (RAG) with LLMs to enhance\ncontext-aware simulation of human behavior in transportation systems.\nExperiments conducted on the Replica dataset demonstrate that the Preference\nChain outperforms standard LLM in aligning with real-world transportation mode\nchoices. The development of the Mobility Agent highlights potential\napplications of proposed method in urban mobility modeling for emerging cities,\npersonalized travel behavior analysis, and dynamic traffic forecasting. Despite\nlimitations such as slow inference and the risk of hallucination, the method\noffers a promising framework for simulating complex human behavior in\ndata-scarce environments, where traditional data-driven models struggle due to\nlimited data availability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPreference Chain\u65b9\u6cd5\uff0c\u7ed3\u5408\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548cLLM\uff0c\u63d0\u5347\u4ea4\u901a\u7cfb\u7edf\u4e2d\u4eba\u7c7b\u884c\u4e3a\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u6a21\u62df\u6548\u679c\uff0c\u5728Replica\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u6807\u51c6LLM\u3002", "motivation": "\u57ce\u5e02\u73af\u5883\u4e2d\u4eba\u7c7b\u884c\u4e3a\u7406\u89e3\u5f88\u91cd\u8981\uff0c\u4f46\u51c6\u786e\u6570\u636e\u6536\u96c6\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u65b0\u5174\u533a\u57df\u3002\u73b0\u6709\u751f\u6210\u4ee3\u7406\u65b9\u6cd5\u5728\u4ea7\u751f\u4e00\u81f4\u3001\u4e0a\u4e0b\u6587\u654f\u611f\u548c\u73b0\u5b9e\u884c\u4e3a\u8f93\u51fa\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51faPreference Chain\u65b9\u6cd5\uff0c\u6574\u5408\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u589e\u5f3a\u4ea4\u901a\u7cfb\u7edf\u4e2d\u4eba\u7c7b\u884c\u4e3a\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u6a21\u62df\u80fd\u529b\u3002", "result": "\u5728Replica\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPreference Chain\u5728\u7b26\u5408\u771f\u5b9e\u4e16\u754c\u4ea4\u901a\u65b9\u5f0f\u9009\u62e9\u65b9\u9762\u4f18\u4e8e\u6807\u51c6LLM\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6570\u636e\u7a00\u7f3a\u73af\u5883\u4e2d\u6a21\u62df\u590d\u6742\u4eba\u7c7b\u884c\u4e3a\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u6846\u67b6\uff0c\u53ef\u5e94\u7528\u4e8e\u65b0\u5174\u57ce\u5e02\u79fb\u52a8\u6027\u5efa\u6a21\u3001\u4e2a\u6027\u5316\u51fa\u884c\u884c\u4e3a\u5206\u6790\u548c\u52a8\u6001\u4ea4\u901a\u9884\u6d4b\u3002"}}
{"id": "2508.16204", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2508.16204", "abs": "https://arxiv.org/abs/2508.16204", "authors": ["Jo\u00e3o Abrantes", "Robert Tjarko Lange", "Yujin Tang"], "title": "Competition and Attraction Improve Model Fusion", "comment": "Accepted at GECCO 2025 as a full paper", "summary": "Model merging is a powerful technique for integrating the specialized\nknowledge of multiple machine learning models into a single model. However,\nexisting methods require manually partitioning model parameters into fixed\ngroups for merging, which restricts the exploration of potential combinations\nand limits performance. To overcome these limitations, we propose Model Merging\nof Natural Niches (M2N2), an evolutionary algorithm with three key features:\n(1) dynamic adjustment of merging boundaries to progressively explore a broader\nrange of parameter combinations; (2) a diversity preservation mechanism\ninspired by the competition for resources in nature, to maintain a population\nof diverse, high-performing models that are particularly well-suited for\nmerging; and (3) a heuristicbased attraction metric to identify the most\npromising pairs of models for fusion. Our experimental results demonstrate, for\nthe first time, that model merging can be used to evolve models entirely from\nscratch. Specifically, we apply M2N2 to evolve MNIST classifiers from scratch\nand achieve performance comparable to CMA-ES, while being computationally more\nefficient. Furthermore, M2N2 scales to merge specialized language and image\ngeneration models, achieving state-of-the-art performance. Notably, it\npreserves crucial model capabilities beyond those explicitly optimized by the\nfitness function, highlighting its robustness and versatility. Our code is\navailable at https://github.com/SakanaAI/natural_niches", "AI": {"tldr": "M2N2\u662f\u4e00\u79cd\u57fa\u4e8e\u8fdb\u5316\u7b97\u6cd5\u7684\u6a21\u578b\u878d\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u878d\u5408\u8fb9\u754c\u3001\u591a\u6837\u6027\u4fdd\u6301\u673a\u5236\u548c\u542f\u53d1\u5f0f\u5438\u5f15\u529b\u5ea6\u91cf\uff0c\u5b9e\u73b0\u4e86\u4ece\u96f6\u5f00\u59cb\u8fdb\u5316\u6a21\u578b\uff0c\u5728MNIST\u5206\u7c7b\u548c\u8bed\u8a00/\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\u8fbe\u5230\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u878d\u5408\u65b9\u6cd5\u9700\u8981\u624b\u52a8\u5c06\u53c2\u6570\u5212\u5206\u4e3a\u56fa\u5b9a\u7ec4\u8fdb\u884c\u878d\u5408\uff0c\u9650\u5236\u4e86\u6f5c\u5728\u7ec4\u5408\u7684\u63a2\u7d22\u548c\u6027\u80fd\u63d0\u5347\u3002", "method": "\u63d0\u51faM2N2\u8fdb\u5316\u7b97\u6cd5\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7279\u5f81\uff1a\u52a8\u6001\u8c03\u6574\u878d\u5408\u8fb9\u754c\u3001\u57fa\u4e8e\u81ea\u7136\u7ade\u4e89\u7684\u8d44\u6e90\u591a\u6837\u6027\u4fdd\u6301\u673a\u5236\u3001\u542f\u53d1\u5f0f\u5438\u5f15\u529b\u5ea6\u91cf\u6765\u8bc6\u522b\u6700\u6709\u524d\u666f\u7684\u6a21\u578b\u5bf9\u8fdb\u884c\u878d\u5408\u3002", "result": "\u9996\u6b21\u8bc1\u660e\u6a21\u578b\u878d\u5408\u53ef\u4ee5\u4ece\u96f6\u5f00\u59cb\u8fdb\u5316\u6a21\u578b\uff0c\u5728MNIST\u5206\u7c7b\u4e0a\u8fbe\u5230\u4e0eCMA-ES\u76f8\u5f53\u7684\u6027\u80fd\u4f46\u8ba1\u7b97\u66f4\u9ad8\u6548\uff0c\u5728\u8bed\u8a00\u548c\u56fe\u50cf\u751f\u6210\u6a21\u578b\u878d\u5408\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "M2N2\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u548c\u591a\u529f\u80fd\u6027\uff0c\u80fd\u591f\u4fdd\u6301\u8d85\u51fa\u9002\u5e94\u5ea6\u51fd\u6570\u660e\u786e\u4f18\u5316\u7684\u5173\u952e\u6a21\u578b\u80fd\u529b\uff0c\u4e3a\u6a21\u578b\u878d\u5408\u63d0\u4f9b\u4e86\u65b0\u7684\u8fdb\u5316\u9014\u5f84\u3002"}}
{"id": "2508.16277", "categories": ["cs.AI", "cs.HC", "68T01, 68T05, 68T42, 91A80", "I.2; K.4"], "pdf": "https://arxiv.org/pdf/2508.16277", "abs": "https://arxiv.org/abs/2508.16277", "authors": ["Alexandru Tugui"], "title": "The next question after Turing's question: Introducing the Grow-AI test", "comment": "9th International Conference on Inventive Systems and Control ICISC\n  2025", "summary": "This study aims to extend the framework for assessing artificial\nintelligence, called GROW-AI (Growth and Realization of Autonomous Wisdom),\ndesigned to answer the question \"Can machines grow up?\" -- a natural successor\nto the Turing Test. The methodology applied is based on a system of six primary\ncriteria (C1-C6), each assessed through a specific \"game\", divided into four\narenas that explore both the human dimension and its transposition into AI. All\ndecisions and actions of the entity are recorded in a standardized AI Journal,\nthe primary source for calculating composite scores. The assessment uses the\nprior expert method to establish initial weights, and the global score -- Grow\nUp Index -- is calculated as the arithmetic mean of the six scores, with\ninterpretation on maturity thresholds. The results show that the methodology\nallows for a coherent and comparable assessment of the level of \"growth\" of AI\nentities, regardless of their type (robots, software agents, LLMs). The\nmulti-game structure highlights strengths and vulnerable areas, and the use of\na unified journal guarantees traceability and replicability in the evaluation.\nThe originality of the work lies in the conceptual transposition of the process\nof \"growing\" from the human world to that of artificial intelligence, in an\nintegrated testing format that combines perspectives from psychology, robotics,\ncomputer science, and ethics. Through this approach, GROW-AI not only measures\nperformance but also captures the evolutionary path of an AI entity towards\nmaturity.", "AI": {"tldr": "GROW-AI\u6846\u67b6\u6269\u5c55\u4e86\u4eba\u5de5\u667a\u80fd\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u516d\u4e2a\u6807\u51c6\u6e38\u620f\u5316\u6d4b\u8bd5\u6765\u8bc4\u4f30AI\u7684\"\u6210\u957f\"\u6c34\u5e73\uff0c\u8ba1\u7b97\u6210\u957f\u6307\u6570\u5e76\u786e\u5b9a\u6210\u719f\u5ea6\u9608\u503c", "motivation": "\u89e3\u51b3\"\u673a\u5668\u80fd\u5426\u6210\u957f\"\u7684\u95ee\u9898\uff0c\u4f5c\u4e3a\u56fe\u7075\u6d4b\u8bd5\u7684\u81ea\u7136\u5ef6\u4f38\uff0c\u5c06\u4eba\u7c7b\u6210\u957f\u8fc7\u7a0b\u6982\u5ff5\u5316\u5730\u79fb\u690d\u5230\u4eba\u5de5\u667a\u80fd\u9886\u57df", "method": "\u57fa\u4e8e\u516d\u4e2a\u4e3b\u8981\u6807\u51c6(C1-C6)\u7684\u6e38\u620f\u5316\u8bc4\u4f30\u7cfb\u7edf\uff0c\u5206\u4e3a\u56db\u4e2a\u7ade\u6280\u573a\uff0c\u4f7f\u7528\u6807\u51c6\u5316AI\u65e5\u5fd7\u8bb0\u5f55\u6240\u6709\u51b3\u7b56\u548c\u884c\u52a8\uff0c\u91c7\u7528\u4e13\u5bb6\u5148\u9a8c\u65b9\u6cd5\u786e\u5b9a\u6743\u91cd\uff0c\u8ba1\u7b97\u7b97\u672f\u5e73\u5747\u7684\u6210\u957f\u6307\u6570", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5bf9\u4e0d\u540c\u7c7b\u578bAI\u5b9e\u4f53(\u673a\u5668\u4eba\u3001\u8f6f\u4ef6\u4ee3\u7406\u3001\u5927\u8bed\u8a00\u6a21\u578b)\u8fdb\u884c\u4e00\u81f4\u4e14\u53ef\u6bd4\u8f83\u7684\"\u6210\u957f\"\u6c34\u5e73\u8bc4\u4f30\uff0c\u591a\u6e38\u620f\u7ed3\u6784\u80fd\u7a81\u51fa\u4f18\u52bf\u9886\u57df\u548c\u8584\u5f31\u73af\u8282", "conclusion": "GROW-AI\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u5fc3\u7406\u5b66\u3001\u673a\u5668\u4eba\u5b66\u3001\u8ba1\u7b97\u673a\u79d1\u5b66\u548c\u4f26\u7406\u5b66\u7684\u7efc\u5408\u6d4b\u8bd5\u683c\u5f0f\uff0c\u4e0d\u4ec5\u6d4b\u91cf\u6027\u80fd\uff0c\u8fd8\u80fd\u6355\u6349AI\u5b9e\u4f53\u5411\u6210\u719f\u5ea6\u8fdb\u5316\u7684\u8def\u5f84\uff0c\u4fdd\u8bc1\u4e86\u8bc4\u4f30\u7684\u53ef\u8ffd\u6eaf\u6027\u548c\u53ef\u590d\u73b0\u6027"}}
{"id": "2508.16279", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16279", "abs": "https://arxiv.org/abs/2508.16279", "authors": ["Dawei Gao", "Zitao Li", "Yuexiang Xie", "Weirui Kuang", "Liuyi Yao", "Bingchen Qian", "Zhijian Ma", "Yue Cui", "Haohao Luo", "Shen Li", "Lu Yi", "Yi Yu", "Shiqi He", "Zhiling Luo", "Wenmeng Zhou", "Zhicheng Zhang", "Xuguang He", "Ziqian Chen", "Weikai Liao", "Farruh Isakulovich Kushnazarov", "Yaliang Li", "Bolin Ding", "Jingren Zhou"], "title": "AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications", "comment": null, "summary": "Driven by rapid advancements of Large Language Models (LLMs), agents are\nempowered to combine intrinsic knowledge with dynamic tool use, greatly\nenhancing their capacity to address real-world tasks. In line with such an\nevolution, AgentScope introduces major improvements in a new version (1.0),\ntowards comprehensively supporting flexible and efficient tool-based\nagent-environment interactions for building agentic applications. Specifically,\nwe abstract foundational components essential for agentic applications and\nprovide unified interfaces and extensible modules, enabling developers to\neasily leverage the latest progress, such as new models and MCPs. Furthermore,\nwe ground agent behaviors in the ReAct paradigm and offer advanced agent-level\ninfrastructure based on a systematic asynchronous design, which enriches both\nhuman-agent and agent-agent interaction patterns while improving execution\nefficiency. Building on this foundation, we integrate several built-in agents\ntailored to specific practical scenarios. AgentScope also includes robust\nengineering support for developer-friendly experiences. We provide a scalable\nevaluation module with a visual studio interface, making the development of\nlong-trajectory agentic applications more manageable and easier to trace. In\naddition, AgentScope offers a runtime sandbox to ensure safe agent execution\nand facilitates rapid deployment in production environments. With these\nenhancements, AgentScope provides a practical foundation for building scalable,\nadaptive, and effective agentic applications.", "AI": {"tldr": "AgentScope 1.0\u662f\u4e00\u4e2a\u652f\u6301\u5de5\u5177\u9a71\u52a8\u667a\u80fd\u4f53\u4ea4\u4e92\u7684\u6846\u67b6\uff0c\u63d0\u4f9b\u7edf\u4e00\u63a5\u53e3\u3001\u5f02\u6b65\u8bbe\u8ba1\u3001\u5185\u7f6e\u667a\u80fd\u4f53\u548c\u5de5\u7a0b\u652f\u6301\uff0c\u7528\u4e8e\u6784\u5efa\u53ef\u6269\u5c55\u7684\u667a\u80fd\u4f53\u5e94\u7528\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u667a\u80fd\u4f53\u9700\u8981\u7ed3\u5408\u5185\u5728\u77e5\u8bc6\u548c\u52a8\u6001\u5de5\u5177\u4f7f\u7528\u6765\u589e\u5f3a\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u9700\u8981\u4e00\u4e2a\u652f\u6301\u7075\u6d3b\u9ad8\u6548\u5de5\u5177\u4ea4\u4e92\u7684\u6846\u67b6\u3002", "method": "\u62bd\u8c61\u57fa\u7840\u7ec4\u4ef6\u5e76\u63d0\u4f9b\u7edf\u4e00\u63a5\u53e3\u548c\u53ef\u6269\u5c55\u6a21\u5757\uff0c\u57fa\u4e8eReAct\u8303\u5f0f\u8bbe\u8ba1\u7cfb\u7edf\u7ea7\u5f02\u6b65\u67b6\u6784\uff0c\u96c6\u6210\u5185\u7f6e\u667a\u80fd\u4f53\uff0c\u63d0\u4f9b\u53ef\u89c6\u5316\u8bc4\u4f30\u6a21\u5757\u548c\u8fd0\u884c\u65f6\u6c99\u76d2\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u652f\u6301\u4eba\u7c7b-\u667a\u80fd\u4f53\u548c\u667a\u80fd\u4f53-\u667a\u80fd\u4f53\u4ea4\u4e92\u6a21\u5f0f\u7684\u6846\u67b6\uff0c\u63d0\u9ad8\u4e86\u6267\u884c\u6548\u7387\uff0c\u4f7f\u957f\u8f68\u8ff9\u667a\u80fd\u4f53\u5e94\u7528\u5f00\u53d1\u66f4\u6613\u7ba1\u7406\u548c\u8ffd\u8e2a\u3002", "conclusion": "AgentScope 1.0\u4e3a\u6784\u5efa\u53ef\u6269\u5c55\u3001\u81ea\u9002\u5e94\u548c\u6709\u6548\u7684\u667a\u80fd\u4f53\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\uff0c\u652f\u6301\u5b89\u5168\u6267\u884c\u548c\u5feb\u901f\u90e8\u7f72\u3002"}}
{"id": "2508.16292", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.16292", "abs": "https://arxiv.org/abs/2508.16292", "authors": ["Wen-Han Hsieh", "Elvis Hsieh", "Dantong Niu", "Trevor Darrell", "Roei Herzig", "David M. Chan"], "title": "Do What? Teaching Vision-Language-Action Models to Reject the Impossible", "comment": "9 pages, 2 figures, 1 table", "summary": "Recently, Vision-Language-Action (VLA) models have demonstrated strong\nperformance on a range of robotic tasks. These models rely on multimodal\ninputs, with language instructions playing a crucial role -- not only in\npredicting actions, but also in robustly interpreting user intent, even when\nthe requests are impossible to fulfill. In this work, we investigate how VLAs\ncan recognize, interpret, and respond to false-premise instructions: natural\nlanguage commands that reference objects or conditions absent from the\nenvironment. We propose Instruct-Verify-and-Act (IVA), a unified framework that\n(i) detects when an instruction cannot be executed due to a false premise, (ii)\nengages in language-based clarification or correction, and (iii) grounds\nplausible alternatives in perception and action. Towards this end, we construct\na large-scale instruction tuning setup with structured language prompts and\ntrain a VLA model capable of handling both accurate and erroneous requests. Our\napproach leverages a contextually augmented, semi-synthetic dataset containing\npaired positive and false-premise instructions, enabling robust detection and\nnatural language correction. Our experiments show that IVA improves false\npremise detection accuracy by 97.56% over baselines, while increasing\nsuccessful responses in false-premise scenarios by 50.78%.", "AI": {"tldr": "\u63d0\u51fa\u4e86IVA\u6846\u67b6\uff0c\u4f7f\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u80fd\u591f\u68c0\u6d4b\u9519\u8bef\u524d\u63d0\u6307\u4ee4\u3001\u8fdb\u884c\u8bed\u8a00\u6f84\u6e05\u5e76\u6267\u884c\u5408\u7406\u66ff\u4ee3\u65b9\u6848", "motivation": "\u73b0\u6709VLA\u6a21\u578b\u5728\u5904\u7406\u9519\u8bef\u524d\u63d0\u6307\u4ee4\uff08\u5f15\u7528\u73af\u5883\u4e2d\u4e0d\u5b58\u5728\u5bf9\u8c61\u6216\u6761\u4ef6\u7684\u6307\u4ee4\uff09\u65f6\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u63d0\u5347\u6a21\u578b\u8bc6\u522b\u548c\u54cd\u5e94\u8fd9\u7c7b\u6307\u4ee4\u7684\u80fd\u529b", "method": "\u6784\u5efa\u5927\u89c4\u6a21\u6307\u4ee4\u8c03\u4f18\u8bbe\u7f6e\uff0c\u4f7f\u7528\u7ed3\u6784\u5316\u8bed\u8a00\u63d0\u793a\u8bad\u7ec3VLA\u6a21\u578b\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u589e\u5f3a\u7684\u534a\u5408\u6210\u6570\u636e\u96c6\u5305\u542b\u914d\u5bf9\u7684\u6b63\u4f8b\u548c\u9519\u8bef\u524d\u63d0\u6307\u4ee4", "result": "IVA\u5728\u9519\u8bef\u524d\u63d0\u68c0\u6d4b\u51c6\u786e\u7387\u4e0a\u6bd4\u57fa\u7ebf\u63d0\u9ad897.56%\uff0c\u5728\u9519\u8bef\u524d\u63d0\u573a\u666f\u4e2d\u7684\u6210\u529f\u54cd\u5e94\u7387\u63d0\u9ad850.78%", "conclusion": "IVA\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86VLA\u6a21\u578b\u5904\u7406\u9519\u8bef\u524d\u63d0\u6307\u4ee4\u7684\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u68c0\u6d4b\u3001\u6f84\u6e05\u548c\u6267\u884c\u7684\u7edf\u4e00\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.16352", "categories": ["cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.16352", "abs": "https://arxiv.org/abs/2508.16352", "authors": ["Nasir Khan", "Asmaa Abdallah", "Abdulkadir Celik", "Ahmed M. Eltawil", "Sinem Coleri"], "title": "Causal Beam Selection for Reliable Initial Access in AI-driven Beam Management", "comment": null, "summary": "Efficient and reliable beam alignment is a critical requirement for mmWave\nmultiple-input multiple-output (MIMO) systems, especially in 6G and beyond,\nwhere communication must be fast, adaptive, and resilient to real-world\nuncertainties. Existing deep learning (DL)-based beam alignment methods often\nneglect the underlying causal relationships between inputs and outputs, leading\nto limited interpretability, poor generalization, and unnecessary beam sweeping\noverhead. In this work, we propose a causally-aware DL framework that\nintegrates causal discovery into beam management pipeline. Particularly, we\npropose a novel two-stage causal beam selection algorithm to identify a minimal\nset of relevant inputs for beam prediction. First, causal discovery learns a\nBayesian graph capturing dependencies between received power inputs and the\noptimal beam. Then, this graph guides causal feature selection for the DL-based\nclassifier. Simulation results reveal that the proposed causal beam selection\nmatches the performance of conventional methods while drastically reducing\ninput selection time by 94.4% and beam sweeping overhead by 59.4% by focusing\nonly on causally relevant features.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u53d1\u73b0\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u6beb\u7c73\u6ce2MIMO\u7cfb\u7edf\u4e2d\u7684\u6ce2\u675f\u5bf9\u9f50\uff0c\u901a\u8fc7\u56e0\u679c\u7279\u5f81\u9009\u62e9\u663e\u8457\u51cf\u5c11\u8f93\u5165\u9009\u62e9\u65f6\u95f4\u548c\u6ce2\u675f\u626b\u63cf\u5f00\u9500", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6ce2\u675f\u5bf9\u9f50\u65b9\u6cd5\u5f80\u5f80\u5ffd\u7565\u8f93\u5165\u8f93\u51fa\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u5bfc\u81f4\u53ef\u89e3\u91ca\u6027\u5dee\u3001\u6cdb\u5316\u80fd\u529b\u6709\u9650\u548c\u4e0d\u5fc5\u8981\u7684\u6ce2\u675f\u626b\u63cf\u5f00\u9500", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u56e0\u679c\u6ce2\u675f\u9009\u62e9\u7b97\u6cd5\uff1a\u9996\u5148\u901a\u8fc7\u56e0\u679c\u53d1\u73b0\u5b66\u4e60\u63a5\u6536\u529f\u7387\u8f93\u5165\u4e0e\u6700\u4f18\u6ce2\u675f\u4e4b\u95f4\u7684\u8d1d\u53f6\u65af\u56fe\uff0c\u7136\u540e\u5229\u7528\u8be5\u56fe\u6307\u5bfc\u57fa\u4e8eDL\u7684\u5206\u7c7b\u5668\u7684\u56e0\u679c\u7279\u5f81\u9009\u62e9", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u56e0\u679c\u6ce2\u675f\u9009\u62e9\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4e0e\u5e38\u89c4\u65b9\u6cd5\u76f8\u5f53\uff0c\u540c\u65f6\u5c06\u8f93\u5165\u9009\u62e9\u65f6\u95f4\u51cf\u5c1194.4%\uff0c\u6ce2\u675f\u626b\u63cf\u5f00\u9500\u51cf\u5c1159.4%", "conclusion": "\u56e0\u679c\u611f\u77e5\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u8bc6\u522b\u56e0\u679c\u76f8\u5173\u7279\u5f81\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u7cfb\u7edf\u5f00\u9500\uff0c\u4e3a6G\u53ca\u4ee5\u540e\u7684\u6beb\u7c73\u6ce2MIMO\u7cfb\u7edf\u63d0\u4f9b\u9ad8\u6548\u53ef\u9760\u7684\u6ce2\u675f\u5bf9\u9f50\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.16383", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.16383", "abs": "https://arxiv.org/abs/2508.16383", "authors": ["Xinyu Yang", "Chenlong Deng", "Zhicheng Dou"], "title": "GLARE: Agentic Reasoning for Legal Judgment Prediction", "comment": null, "summary": "Legal judgment prediction (LJP) has become increasingly important in the\nlegal field. In this paper, we identify that existing large language models\n(LLMs) have significant problems of insufficient reasoning due to a lack of\nlegal knowledge. Therefore, we introduce GLARE, an agentic legal reasoning\nframework that dynamically acquires key legal knowledge by invoking different\nmodules, thereby improving the breadth and depth of reasoning. Experiments\nconducted on the real-world dataset verify the effectiveness of our method.\nFurthermore, the reasoning chain generated during the analysis process can\nincrease interpretability and provide the possibility for practical\napplications.", "AI": {"tldr": "GLARE\u662f\u4e00\u4e2a\u57fa\u4e8e\u4ee3\u7406\u7684\u6cd5\u5f8b\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u83b7\u53d6\u5173\u952e\u6cd5\u5f8b\u77e5\u8bc6\u6765\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u4e2d\u63a8\u7406\u4e0d\u8db3\u7684\u95ee\u9898", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u9886\u57df\u56e0\u7f3a\u4e4f\u6cd5\u5f8b\u77e5\u8bc6\u800c\u5bfc\u81f4\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\uff0c\u9700\u8981\u6539\u8fdb\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6df1\u5ea6", "method": "\u5f00\u53d1GLARE\u4ee3\u7406\u6cd5\u5f8b\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u8c03\u7528\u4e0d\u540c\u6a21\u5757\u52a8\u6001\u83b7\u53d6\u5173\u952e\u6cd5\u5f8b\u77e5\u8bc6\uff0c\u63d0\u5347\u63a8\u7406\u7684\u5e7f\u5ea6\u548c\u6df1\u5ea6", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u751f\u6210\u7684\u63a8\u7406\u94fe\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027", "conclusion": "GLARE\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u7684\u6027\u80fd\uff0c\u5e76\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027"}}
{"id": "2508.16463", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.16463", "abs": "https://arxiv.org/abs/2508.16463", "authors": ["Aniello Panariello", "Emanuele Frascaroli", "Pietro Buzzega", "Lorenzo Bonicelli", "Angelo Porrello", "Simone Calderara"], "title": "Modular Embedding Recomposition for Incremental Learning", "comment": "Accepted to the 36th British Machine Vision Conference (BMVC 2025),\n  Sheffield, UK", "summary": "The advent of pre-trained Vision-Language Models (VLMs) has significantly\ntransformed Continual Learning (CL), mainly due to their zero-shot\nclassification abilities. Such proficiency makes VLMs well-suited for\nreal-world applications, enabling robust performance on novel unseen classes\nwithout requiring adaptation. However, fine-tuning remains essential when\ndownstream tasks deviate significantly from the pre-training domain. Prior CL\napproaches primarily focus on preserving the zero-shot capabilities of VLMs\nduring incremental fine-tuning on a downstream task. We take a step further by\ndevising an approach that transforms preservation into enhancement of the\nzero-shot capabilities of VLMs. Our approach, named MoDular Embedding\nRecomposition (MoDER), introduces a modular framework that trains multiple\ntextual experts, each specialized in a single seen class, and stores them in a\nfoundational hub. At inference time, for each unseen class, we query the hub\nand compose the retrieved experts to synthesize a refined prototype that\nimproves classification. We show the effectiveness of our method across two\npopular zero-shot incremental protocols, Class-IL and MTIL, comprising a total\nof 14 datasets. The codebase is available at\nhttps://github.com/aimagelab/mammoth.", "AI": {"tldr": "\u63d0\u51faMoDER\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u4e13\u5bb6\u8bad\u7ec3\u548c\u7ec4\u5408\u6765\u589e\u5f3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u96f6\u6837\u672c\u80fd\u529b\uff0c\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u5b9e\u73b0\u96f6\u6837\u672c\u5206\u7c7b\u6027\u80fd\u7684\u63d0\u5347", "motivation": "\u73b0\u6709\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4fdd\u6301\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u96f6\u6837\u672c\u80fd\u529b\uff0c\u4f46\u672c\u6587\u5e0c\u671b\u8fdb\u4e00\u6b65\u5c06\u8fd9\u4e9b\u80fd\u529b\u4ece\u4fdd\u6301\u8f6c\u53d8\u4e3a\u589e\u5f3a\uff0c\u7279\u522b\u662f\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0e\u9884\u8bad\u7ec3\u9886\u57df\u5dee\u5f02\u8f83\u5927\u65f6", "method": "MoDER\u65b9\u6cd5\u8bad\u7ec3\u591a\u4e2a\u6587\u672c\u4e13\u5bb6\uff08\u6bcf\u4e2a\u4e13\u5bb6\u4e13\u6ce8\u4e8e\u4e00\u4e2a\u5df2\u89c1\u7c7b\u522b\uff09\uff0c\u5b58\u50a8\u5728\u57fa\u7840\u4e2d\u5fc3\u4e2d\u3002\u63a8\u7406\u65f6\uff0c\u4e3a\u6bcf\u4e2a\u672a\u89c1\u7c7b\u522b\u67e5\u8be2\u4e2d\u5fc3\u5e76\u7ec4\u5408\u68c0\u7d22\u5230\u7684\u4e13\u5bb6\uff0c\u5408\u6210\u6539\u8fdb\u7684\u5206\u7c7b\u539f\u578b", "result": "\u5728\u5305\u542b14\u4e2a\u6570\u636e\u96c6\u7684\u4e24\u79cd\u96f6\u6837\u672c\u589e\u91cf\u534f\u8bae\uff08Class-IL\u548cMTIL\uff09\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "MoDER\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u96f6\u6837\u672c\u80fd\u529b\u4ece\u4fdd\u6301\u8f6c\u53d8\u4e3a\u589e\u5f3a\uff0c\u4e3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.16524", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16524", "abs": "https://arxiv.org/abs/2508.16524", "authors": ["Xuan Zhang", "Zhijian Zhou", "Weidi Xu", "Yanting Miao", "Chao Qu", "Yuan Qi"], "title": "Constraints-Guided Diffusion Reasoner for Neuro-Symbolic Learning", "comment": null, "summary": "Enabling neural networks to learn complex logical constraints and fulfill\nsymbolic reasoning is a critical challenge. Bridging this gap often requires\nguiding the neural network's output distribution to move closer to the symbolic\nconstraints. While diffusion models have shown remarkable generative capability\nacross various domains, we employ the powerful architecture to perform\nneuro-symbolic learning and solve logical puzzles. Our diffusion-based pipeline\nadopts a two-stage training strategy: the first stage focuses on cultivating\nbasic reasoning abilities, while the second emphasizes systematic learning of\nlogical constraints. To impose hard constraints on neural outputs in the second\nstage, we formulate the diffusion reasoner as a Markov decision process and\ninnovatively fine-tune it with an improved proximal policy optimization\nalgorithm. We utilize a rule-based reward signal derived from the logical\nconsistency of neural outputs and adopt a flexible strategy to optimize the\ndiffusion reasoner's policy. We evaluate our methodology on some classical\nsymbolic reasoning benchmarks, including Sudoku, Maze, pathfinding and\npreference learning. Experimental results demonstrate that our approach\nachieves outstanding accuracy and logical consistency among neural networks.", "AI": {"tldr": "\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u5728\u6570\u72ec\u3001\u8ff7\u5bab\u7b49\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e0a\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u548c\u903b\u8f91\u4e00\u81f4\u6027", "motivation": "\u89e3\u51b3\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u590d\u6742\u903b\u8f91\u7ea6\u675f\u548c\u7b26\u53f7\u63a8\u7406\u7684\u6311\u6218\uff0c\u5f25\u5408\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u5206\u5e03\u4e0e\u7b26\u53f7\u7ea6\u675f\u4e4b\u95f4\u7684\u5dee\u8ddd", "method": "\u91c7\u7528\u6269\u6563\u6a21\u578b\u67b6\u6784\uff0c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a\u7b2c\u4e00\u9636\u6bb5\u57f9\u517b\u57fa\u7840\u63a8\u7406\u80fd\u529b\uff0c\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5efa\u6a21\uff0c\u4f7f\u7528\u6539\u8fdb\u7684\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u8fdb\u884c\u5fae\u8c03\uff0c\u57fa\u4e8e\u903b\u8f91\u4e00\u81f4\u6027\u7684\u89c4\u5219\u5956\u52b1\u4fe1\u53f7", "result": "\u5728\u6570\u72ec\u3001\u8ff7\u5bab\u3001\u8def\u5f84\u89c4\u5212\u548c\u504f\u597d\u5b66\u4e60\u7b49\u7ecf\u5178\u7b26\u53f7\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u51c6\u786e\u6027\u548c\u903b\u8f91\u4e00\u81f4\u6027", "conclusion": "\u6269\u6563\u6a21\u578b\u67b6\u6784\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u903b\u8f91\u63a8\u7406\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u9014\u5f84"}}
{"id": "2508.16571", "categories": ["cs.AI", "cs.IR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.16571", "abs": "https://arxiv.org/abs/2508.16571", "authors": ["Alisa Vinogradova", "Vlad Vinogradov", "Dmitrii Radkevich", "Ilya Yasny", "Dmitry Kobyzev", "Ivan Izmailov", "Katsiaryna Yanchanka", "Andrey Doronichev"], "title": "LLM-Based Agents for Competitive Landscape Mapping in Drug Asset Due Diligence", "comment": null, "summary": "In this paper, we describe and benchmark a competitor-discovery component\nused within an agentic AI system for fast drug asset due diligence. A\ncompetitor-discovery AI agent, given an indication, retrieves all drugs\ncomprising the competitive landscape of that indication and extracts canonical\nattributes for these drugs. The competitor definition is investor-specific, and\ndata is paywalled/licensed, fragmented across registries, ontology-mismatched\nby indication, alias-heavy for drug names, multimodal, and rapidly changing.\nAlthough considered the best tool for this problem, the current LLM-based AI\nsystems aren't capable of reliably retrieving all competing drug names, and\nthere is no accepted public benchmark for this task. To address the lack of\nevaluation, we use LLM-based agents to transform five years of multi-modal,\nunstructured diligence memos from a private biotech VC fund into a structured\nevaluation corpus mapping indications to competitor drugs with normalized\nattributes. We also introduce a competitor validating LLM-as-a-judge agent that\nfilters out false positives from the list of predicted competitors to maximize\nprecision and suppress hallucinations. On this benchmark, our\ncompetitor-discovery agent achieves 83% recall, exceeding OpenAI Deep Research\n(65%) and Perplexity Labs (60%). The system is deployed in production with\nenterprise users; in a case study with a biotech VC investment fund, analyst\nturnaround time dropped from 2.5 days to $\\sim$3 hours ($\\sim$20x) for the\ncompetitive analysis.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7528\u4e8e\u836f\u7269\u8d44\u4ea7\u5feb\u901f\u5c3d\u804c\u8c03\u67e5\u7684\u7ade\u4e89\u5bf9\u624b\u53d1\u73b0AI\u7cfb\u7edf\uff0c\u901a\u8fc7LLM\u4ee3\u7406\u5c06\u591a\u6a21\u6001\u975e\u7ed3\u6784\u5316\u6570\u636e\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u8bc4\u4f30\u8bed\u6599\u5e93\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523083%\u7684\u53ec\u56de\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684AI\u7cfb\u7edf\u65e0\u6cd5\u53ef\u9760\u68c0\u7d22\u6240\u6709\u7ade\u4e89\u836f\u7269\u540d\u79f0\uff0c\u4e14\u7f3a\u4e4f\u516c\u8ba4\u7684\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u3002\u836f\u7269\u7ade\u4e89\u6570\u636e\u5177\u6709\u6295\u8d44\u8005\u7279\u5b9a\u3001\u4ed8\u8d39\u5899\u9650\u5236\u3001\u8de8\u6ce8\u518c\u8868\u788e\u7247\u5316\u3001\u672c\u4f53\u8bba\u4e0d\u5339\u914d\u3001\u522b\u540d\u7e41\u591a\u3001\u591a\u6a21\u6001\u548c\u5feb\u901f\u53d8\u5316\u7b49\u7279\u70b9\u3002", "method": "\u4f7f\u7528LLM\u4ee3\u7406\u5c065\u5e74\u591a\u6a21\u6001\u975e\u7ed3\u6784\u5316\u5c3d\u804c\u8c03\u67e5\u5907\u5fd8\u5f55\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u8bc4\u4f30\u8bed\u6599\u5e93\uff0c\u5efa\u7acb\u6307\u793a\u5230\u7ade\u4e89\u836f\u7269\u7684\u6620\u5c04\uff0c\u5e76\u5f15\u5165\u7ade\u4e89\u5bf9\u624b\u9a8c\u8bc1LLM\u4f5c\u4e3a\u8bc4\u5224\u4ee3\u7406\u6765\u8fc7\u6ee4\u8bef\u62a5\u3002", "result": "\u7ade\u4e89\u5bf9\u624b\u53d1\u73b0\u4ee3\u7406\u8fbe\u523083%\u7684\u53ec\u56de\u7387\uff0c\u663e\u8457\u8d85\u8fc7OpenAI Deep Research\uff0865%\uff09\u548cPerplexity Labs\uff0860%\uff09\u3002\u5728\u751f\u7269\u6280\u672fVC\u57fa\u91d1\u6848\u4f8b\u4e2d\uff0c\u5206\u6790\u5e08\u5468\u8f6c\u65f6\u95f4\u4ece2.5\u5929\u964d\u81f3\u7ea63\u5c0f\u65f6\uff08\u7ea620\u500d\u63d0\u5347\uff09\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6210\u529f\u89e3\u51b3\u4e86\u836f\u7269\u7ade\u4e89\u53d1\u73b0\u7684\u5173\u952e\u6311\u6218\uff0c\u5728\u751f\u4ea7\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u7ade\u4e89\u5206\u6790\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
