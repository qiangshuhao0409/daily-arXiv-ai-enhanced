{"id": "2507.17036", "categories": ["cs.IT", "cs.DS", "cs.NA", "math.IT", "math.NA"], "pdf": "https://arxiv.org/pdf/2507.17036", "abs": "https://arxiv.org/abs/2507.17036", "authors": ["Edem Boahen", "Simone Brugiapaglia", "Hung-Hsu Chou", "Mark Iwen", "Felix Krahmer"], "title": "Fast One-Pass Sparse Approximation of the Top Eigenvectors of Huge Low-Rank Matrices? Yes, $MAM^*$!", "comment": null, "summary": "Motivated by applications such as sparse PCA, in this paper we present\nprovably-accurate one-pass algorithms for the sparse approximation of the top\neigenvectors of extremely massive matrices based on a single compact linear\nsketch. The resulting compressive-sensing-based approaches can approximate the\nleading eigenvectors of huge approximately low-rank matrices that are too large\nto store in memory based on a single pass over its entries while utilizing a\ntotal memory footprint on the order of the much smaller desired sparse\neigenvector approximations. Finally, the compressive sensing recovery algorithm\nitself (which takes the gathered compressive matrix measurements as input, and\nthen outputs sparse approximations of its top eigenvectors) can also be\nformulated to run in a time which principally depends on the size of the sought\nsparse approximations, making its runtime sublinear in the size of the large\nmatrix whose eigenvectors one aims to approximate. Preliminary experiments on\nhuge matrices having $\\sim 10^{16}$ entries illustrate the developed theory and\ndemonstrate the practical potential of the proposed approach."}
{"id": "2507.17214", "categories": ["cs.AI", "cs.CY", "cs.NI", "cs.SY", "eess.SY", "I.2; B.8; C.2; I.5; J.7"], "pdf": "https://arxiv.org/pdf/2507.17214", "abs": "https://arxiv.org/abs/2507.17214", "authors": ["Amod Kant Agrawal"], "title": "Our Cars Can Talk: How IoT Brings AI to Vehicles", "comment": "3 pages, 1 figure; To appear in IEEE Computer (Nov 2025)", "summary": "Bringing AI to vehicles and enabling them as sensing platforms is key to\ntransforming maintenance from reactive to proactive. Now is the time to\nintegrate AI copilots that speak both languages: machine and driver. This\narticle offers a conceptual and technical perspective intended to spark\ninterdisciplinary dialogue and guide future research and development in\nintelligent vehicle systems, predictive maintenance, and AI-powered user\ninteraction."}
{"id": "2507.17129", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.17129", "abs": "https://arxiv.org/abs/2507.17129", "authors": ["Jingze Ding", "Zijian Zhou", "Bingli Jiao", "Rui Zhang"], "title": "Secure Wireless Communication via Polarforming", "comment": null, "summary": "Polarforming is a promising technique that enables dynamic adjustment of\nantenna polarization to mitigate depolarization effects commonly encountered\nduring electromagnetic (EM) wave propagation. In this letter, we investigate\nthe polarforming design for secure wireless communication systems, where the\nbase station (BS) is equipped with polarization-reconfigurable antennas (PRAs)\nand can flexibly adjust the antenna polarization to transmit confidential\ninformation to a legitimate user in the presence of an eavesdropper. To\nmaximize the achievable secrecy rate, we propose an efficient iterative\nalgorithm to jointly optimize transmit beamforming and polarforming, where\nbeamforming exploits spatial degrees of freedom (DoFs) to steer the transmit\nbeam toward the user, while polarforming leverages polarization DoFs to align\nthe polarization state of the EM wave received by the user with that of its\nantenna. Simulation results demonstrate that, compared to conventional\nfixed-polarization antenna (FPA) systems, polarforming can fully exploit the\nDoFs in antenna polarization optimization to significantly enhance the security\nperformance of wireless communication systems."}
{"id": "2507.17319", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.17319", "abs": "https://arxiv.org/abs/2507.17319", "authors": ["Mengying Gao", "Yuhua Sun", "Tongjiang Yan", "Chun'e Zhao"], "title": "Construction of Self-Orthogonal Quasi-Cyclic Codes and Their Application to Quantum Error-Correcting Codes", "comment": null, "summary": "In this paper, necessary and sufficient conditions for the self-orthogonality\nof t-generator quasi-cyclic (QC) codes are presented under the Euclidean,\nHermitian, and symplectic inner products, respectively. Particularly, by\nstudying the structure of the dual codes of a class of 2-generator QC codes, we\nderive necessary and sufficient conditions for the QC codes to be\ndual-containing under the above three inner products. This class of 2-generator\nQC codes generalizes many known codes in the literature. Based on the above\nconditions, we construct several quantum stabilizer codes and quantum\nsynchronizable codes with good parameters, some of which share parameters with\ncertain best-known codes listed in Grassl's code table."}
{"id": "2507.17366", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.17366", "abs": "https://arxiv.org/abs/2507.17366", "authors": ["Giuseppe Serra", "Photios A. Stavrou", "Marios Kountouris"], "title": "On Distributionally Robust Lossy Source Coding", "comment": null, "summary": "In this paper, we investigate the problem of distributionally robust source\ncoding, i.e., source coding under uncertainty in the source distribution,\ndiscussing both the coding and computational aspects of the problem. We propose\ntwo extensions of the so-called Strong Functional Representation Lemma (SFRL),\nconsidering the cases where, for a fixed conditional distribution, the marginal\ninducing the joint coupling belongs to either a finite set of distributions or\na Kullback-Leibler divergence sphere (KL-Sphere) centered at a fixed nominal\ndistribution. Using these extensions, we derive distributionally robust coding\nschemes for both the one-shot and asymptotic regimes, generalizing previous\nresults in the literature. Focusing on the case where the source distribution\nbelongs to a given KL-Sphere, we derive an implicit characterization of the\npoints attaining the robust rate-distortion function (R-RDF), which we later\nexploit to implement a novel algorithm for computing the R-RDF. Finally, we\ncharacterize the analytical expression of the R-RDF for Bernoulli sources,\nproviding a theoretical benchmark to evaluate the estimation performance of the\nproposed algorithm."}
{"id": "2507.17012", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2507.17012", "abs": "https://arxiv.org/abs/2507.17012", "authors": ["Zhihan Zhang", "Alexander Metzger", "Yuxuan Mei", "Felix HÃ¤hnlein", "Zachary Englhardt", "Tingyu Cheng", "Gregory D. Abowd", "Shwetak Patel", "Adriana Schulz", "Vikram Iyer"], "title": "Towards Autonomous Sustainability Assessment via Multimodal AI Agents", "comment": null, "summary": "Interest in sustainability information has surged in recent years. However,\nthe data required for a life cycle assessment (LCA) that maps the materials and\nprocesses from product manufacturing to disposal into environmental impacts\n(EI) are often unavailable. Here we reimagine conventional LCA by introducing\nmultimodal AI agents that emulate interactions between LCA experts and\nstakeholders like product managers and engineers to calculate the\ncradle-to-gate (production) carbon emissions of electronic devices. The AI\nagents iteratively generate a detailed life-cycle inventory leveraging a custom\ndata abstraction and software tools that extract information from online text\nand images from repair communities and government certifications. This approach\nreduces weeks or months of expert time to under one minute and closes data\navailability gaps while yielding carbon footprint estimates within 19% of\nexpert LCAs with zero proprietary data. Additionally, we develop a method to\ndirectly estimate EI by comparing an input to a cluster of products with\nsimilar descriptions and known carbon footprints. This runs in 3 ms on a laptop\nwith a MAPE of 12.28% on electronic products. Further, we develop a data-driven\nmethod to generate emission factors. We use the properties of an unknown\nmaterial to represent it as a weighted sum of emission factors for similar\nmaterials. Compared to human experts picking the closest LCA database entry,\nthis improves MAPE by 120.26%. We analyze the data and compute scaling of this\napproach and discuss its implications for future LCA workflows."}
{"id": "2507.17188", "categories": ["cs.NI", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17188", "abs": "https://arxiv.org/abs/2507.17188", "authors": ["Lijie Zheng", "Ji He", "Shih Yu Chang", "Yulong Shen", "Dusit Niyato"], "title": "LLM Meets the Sky: Heuristic Multi-Agent Reinforcement Learning for Secure Heterogeneous UAV Networks", "comment": "Submitted to IEEE Transactions on Mobile Computing", "summary": "This work tackles the physical layer security (PLS) problem of maximizing the\nsecrecy rate in heterogeneous UAV networks (HetUAVNs) under propulsion energy\nconstraints. Unlike prior studies that assume uniform UAV capabilities or\noverlook energy-security trade-offs, we consider a realistic scenario where\nUAVs with diverse payloads and computation resources collaborate to serve\nground terminals in the presence of eavesdroppers. To manage the complex\ncoupling between UAV motion and communication, we propose a hierarchical\noptimization framework. The inner layer uses a semidefinite relaxation\n(SDR)-based S2DC algorithm combining penalty functions and difference-of-convex\n(d.c.) programming to solve the secrecy precoding problem with fixed UAV\npositions. The outer layer introduces a Large Language Model (LLM)-guided\nheuristic multi-agent reinforcement learning approach (LLM-HeMARL) for\ntrajectory optimization. LLM-HeMARL efficiently incorporates expert heuristics\npolicy generated by the LLM, enabling UAVs to learn energy-aware,\nsecurity-driven trajectories without the inference overhead of real-time LLM\ncalls. The simulation results show that our method outperforms existing\nbaselines in secrecy rate and energy efficiency, with consistent robustness\nacross varying UAV swarm sizes and random seeds."}
{"id": "2507.17426", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.17426", "abs": "https://arxiv.org/abs/2507.17426", "authors": ["Jaiprakash Nagar", "Zheng Chen", "Marios Kountouris", "Photios A. Stavrou"], "title": "Information Entropy-Based Scheduling for Communication-Efficient Decentralized Learning", "comment": null, "summary": "This paper addresses decentralized stochastic gradient descent (D-SGD) over\nresource-constrained networks by introducing node-based and link-based\nscheduling strategies to enhance communication efficiency. In each iteration of\nthe D-SGD algorithm, only a few disjoint subsets of nodes or links are randomly\nactivated, subject to a given communication cost constraint. We propose a novel\nimportance metric based on information entropy to determine node and link\nscheduling probabilities. We validate the effectiveness of our approach through\nextensive simulations, comparing it against state-of-the-art methods, including\nbetweenness centrality (BC) for node scheduling and \\textit{MATCHA} for link\nscheduling. The results show that our method consistently outperforms the\nBC-based method in the node scheduling case, achieving faster convergence with\nup to 60\\% lower communication budgets. At higher communication budgets (above\n60\\%), our method maintains comparable or superior performance. In the link\nscheduling case, our method delivers results that are superior to or on par\nwith those of \\textit{MATCHA}."}
{"id": "2507.17054", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17054", "abs": "https://arxiv.org/abs/2507.17054", "authors": ["Shao-Hung Chan", "Thomy Phan", "Jiaoyang Li", "Sven Koenig"], "title": "New Mechanisms in Flex Distribution for Bounded Suboptimal Multi-Agent Path Finding", "comment": "9 pages, 10 figures, International Symposium on Combinatorial Search,\n  2025", "summary": "Multi-Agent Path Finding (MAPF) is the problem of finding a set of\ncollision-free paths, one for each agent in a shared environment. Its objective\nis to minimize the sum of path costs (SOC), where the path cost of each agent\nis defined as the travel time from its start location to its target location.\nExplicit Estimation Conflict-Based Search (EECBS) is the leading algorithm for\nbounded-suboptimal MAPF, with the SOC of the solution being at most a\nuser-specified factor $w$ away from optimal. EECBS maintains sets of paths and\na lower bound $LB$ on the optimal SOC. Then, it iteratively selects a set of\npaths whose SOC is at most $w \\cdot LB$ and introduces constraints to resolve\ncollisions. For each path in a set, EECBS maintains a lower bound on its\noptimal path that satisfies constraints. By finding an individually\nbounded-suboptimal path with cost at most a threshold of $w$ times its lower\nbound, EECBS guarantees to find a bounded-suboptimal solution. To speed up\nEECBS, previous work uses flex distribution to increase the threshold. Though\nEECBS with flex distribution guarantees to find a bounded-suboptimal solution,\nincreasing the thresholds may push the SOC beyond $w \\cdot LB$, forcing EECBS\nto switch among different sets of paths instead of resolving collisions on a\nparticular set of paths, and thus reducing efficiency. To address this issue,\nwe propose Conflict-Based Flex Distribution that distributes flex in proportion\nto the number of collisions. We also estimate the delays needed to satisfy\nconstraints and propose Delay-Based Flex Distribution. On top of that, we\npropose Mixed-Strategy Flex Distribution, combining both in a hierarchical\nframework. We prove that EECBS with our new flex distribution mechanisms is\ncomplete and bounded-suboptimal. Our experiments show that our approaches\noutperform the original (greedy) flex distribution."}
{"id": "2507.17195", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.17195", "abs": "https://arxiv.org/abs/2507.17195", "authors": ["Jianpeng Qi", "Chao Liu", "Rui Wang", "Junyu Dong", "Yanwei Yu"], "title": "Closed-Form and Boundary Expressions for Task-Success Probability in Status-Driven Systems", "comment": "10 pages, 10 figures", "summary": "Timely and efficient dissemination of server status is critical in\ncompute-first networking systems, where user tasks arrive dynamically and\ncomputing resources are limited and stochastic. In such systems, the access\npoint plays a key role in forwarding tasks to a server based on its latest\nreceived server status. However, modeling the task-success probability\nsuffering the factors of stochastic arrivals, limited server capacity, and\nbidirectional link delays. Therefore, we introduce a unified analytical\nframework that abstracts the AP forwarding rule as a single probability and\nmodels all network and waiting delays via their Laplace transforms. This\napproach yields a closed form expression for the end to end task success\nprobability, together with upper and lower bounds that capture Erlang loss\nblocking, information staleness, and random uplink/downlink delays. We validate\nour results through simulations across a wide range of parameters, showing that\ntheoretical predictions and bounds consistently enclose observed success rates.\nOur framework requires only two interchangeable inputs (the forwarding\nprobability and the delay transforms), making it readily adaptable to\nalternative forwarding policies and delay distributions. Experiments\ndemonstrate that our bounds are able to achieve accuracy within 0.01 (upper\nbound) and 0.016 (lower bound) of the empirical task success probability."}
{"id": "2507.17427", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.17427", "abs": "https://arxiv.org/abs/2507.17427", "authors": ["Ezgi Ozyilkan", "OÄuzhan Kubilay Ãlger", "Elza Erkip"], "title": "Learning to Write on Dirty Paper", "comment": "accepter for publication at 2025 IEEE Information Theory Workshop\n  (ITW)", "summary": "Dirty paper coding (DPC) is a classical problem in information theory that\nconsiders communication in the presence of channel state known only at the\ntransmitter. While the theoretical impact of DPC has been substantial,\npractical realizations of DPC, such as Tomlinson-Harashima precoding (THP) or\nlattice-based schemes, often rely on specific modeling assumptions about the\ninput, state and channel. In this work, we explore whether modern\nlearning-based approaches can offer a complementary path forward by revisiting\nthe DPC problem. We propose a data-driven solution in which both the encoder\nand decoder are parameterized by neural networks. Our proposed model operates\nwithout prior knowledge of the state (also referred to as \"interference\"),\nchannel or input statistics, and recovers nonlinear mappings that yield\neffective interference pre-cancellation. To the best of our knowledge, this is\nthe first interpretable proof-of-concept demonstrating that learning-based DPC\nschemes can recover characteristic features of well-established solutions, such\nas THP and lattice-based precoding, and outperform them in several regimes."}
{"id": "2507.17075", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17075", "abs": "https://arxiv.org/abs/2507.17075", "authors": ["Yihao Xue", "Baharan Mirzasoleiman"], "title": "LoRA is All You Need for Safety Alignment of Reasoning LLMs", "comment": null, "summary": "Reasoning LLMs have demonstrated remarkable breakthroughs in solving complex\nproblems that were previously out of reach. To ensure LLMs do not assist with\nharmful requests, safety alignment fine-tuning is necessary in the\npost-training phase. However, safety alignment fine-tuning has recently been\nshown to significantly degrade reasoning abilities, a phenomenon known as the\n\"Safety Tax\". In this work, we show that using LoRA for SFT on refusal datasets\neffectively aligns the model for safety without harming its reasoning\ncapabilities. This is because restricting the safety weight updates to a\nlow-rank space minimizes the interference with the reasoning weights. Our\nextensive experiments across four benchmarks covering math, science, and coding\nshow that this approach produces highly safe LLMs -- with safety levels\ncomparable to full-model fine-tuning -- without compromising their reasoning\nabilities. Additionally, we observe that LoRA induces weight updates with\nsmaller overlap with the initial weights compared to full-model fine-tuning. We\nalso explore methods that further reduce such overlap -- via regularization or\nduring weight merging -- and observe some improvement on certain tasks. We hope\nthis result motivates designing approaches that yield more consistent\nimprovements in the reasoning-safety trade-off."}
{"id": "2507.17403", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.17403", "abs": "https://arxiv.org/abs/2507.17403", "authors": ["Alice Le Bihan", "Felix Flentge", "Juan A. Fraire"], "title": "Custody Transfer and Compressed Status Reporting for Bundle Protocol Version 7", "comment": null, "summary": "As space missions increase, there is a growing need to replace point-to-point\ncommunication with an efficient and reliable network-centric communication\napproach. Disruption/Delay Tolerant Networking (DTN) with the Bundle Protocol\n(BP) has been selected as an interoperable network protocol in the LunaNet\nInteroperability Specification. It is also considered for future Earth\nObservation and Mars communication scenarios. In a DTN, the \"bundle\" -- the\nfundamental data unit of BP -- requires dedicated mechanisms to ensure\nreliability due to the challenges posed by intermittent connectivity and long\ndelays. The previous version of BP, BPv6, contained a mechanism for reliable\ntransfer between \"custodial nodes\" called \"custody transfer\". However, this\napproach has been removed from the core protocol specification for BPv7, which\nrequires a corresponding BP reliability extension to be defined separately.\nThis paper introduces a new custody transfer process for BPv7 (expected to be\npublished by CCSDS as an experimental specification in 2025). The core features\nof this new custody transfer method for BPv7 are: (1) A strategy to efficiently\nidentify sets of bundles by sequence numbering (2) A new Custody Transfer\nExtension Block and a corresponding administrative record, Compressed Custody\nSignal, to efficiently report on the acceptance or rejection of custody using\nsequence numbering (3) A new Compressed Reporting Extension Block requesting\nreporting on bundle processing steps using a corresponding administrative\nrecord with sequence numbering for efficiency. The paper will describe those\nconcepts and their design, specification, and implementation in detail. These\nmechanisms have been prototyped in the ESA BP implementation and tested in\nEarth Observation and Lunar communication simulation scenarios. The results\nwill be presented, as will an outlook on future work in the DTN reliable\ntransfer domain."}
{"id": "2507.17432", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.17432", "abs": "https://arxiv.org/abs/2507.17432", "authors": ["Jiahui Wei", "Philippe Mary", "Elsa Dupraz"], "title": "Non-Asymptotic Achievable Rate-Distortion Region for Indirect Wyner-Ziv Source Coding", "comment": "8 pages, 2 figures, 3 pages' appendix", "summary": "In the Wyner-Ziv source coding problem, a source $X$ has to be encoded while\nthe decoder has access to side information $Y$. This paper investigates the\nindirect setup, in which a latent source $S$, unobserved by both the encoder\nand the decoder, must also be reconstructed at the decoder. This scenario is\nincreasingly relevant in the context of goal-oriented communications, where $S$\ncan represent semantic information obtained from $X$. This paper derives the\nindirect Wyner-Ziv rate-distortion function in asymptotic regime and provides\nan achievable region in finite block-length. Furthermore, a Blahut-Arimoto\nalgorithm tailored for the indirect Wyner-Ziv setup, is proposed. This\nalgorithm is then used to give a numerical evaluation of the achievable\nindirect rate-distortion region when $S$ is treated as a classification label."}
{"id": "2507.17118", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17118", "abs": "https://arxiv.org/abs/2507.17118", "authors": ["Mandar Pitale", "Jelena Frtunikj", "Abhinaw Priyadershi", "Vasu Singh", "Maria Spence"], "title": "HySafe-AI: Hybrid Safety Architectural Analysis Framework for AI Systems: A Case Study", "comment": "7 pages", "summary": "AI has become integral to safety-critical areas like autonomous driving\nsystems (ADS) and robotics. The architecture of recent autonomous systems are\ntrending toward end-to-end (E2E) monolithic architectures such as large\nlanguage models (LLMs) and vision language models (VLMs). In this paper, we\nreview different architectural solutions and then evaluate the efficacy of\ncommon safety analyses such as failure modes and effect analysis (FMEA) and\nfault tree analysis (FTA). We show how these techniques can be improved for the\nintricate nature of the foundational models, particularly in how they form and\nutilize latent representations. We introduce HySAFE-AI, Hybrid Safety\nArchitectural Analysis Framework for AI Systems, a hybrid framework that adapts\ntraditional methods to evaluate the safety of AI systems. Lastly, we offer\nhints of future work and suggestions to guide the evolution of future AI safety\nstandards."}
{"id": "2507.17214", "categories": ["cs.AI", "cs.CY", "cs.NI", "cs.SY", "eess.SY", "I.2; B.8; C.2; I.5; J.7"], "pdf": "https://arxiv.org/pdf/2507.17214", "abs": "https://arxiv.org/abs/2507.17214", "authors": ["Amod Kant Agrawal"], "title": "Our Cars Can Talk: How IoT Brings AI to Vehicles", "comment": "3 pages, 1 figure; To appear in IEEE Computer (Nov 2025)", "summary": "Bringing AI to vehicles and enabling them as sensing platforms is key to\ntransforming maintenance from reactive to proactive. Now is the time to\nintegrate AI copilots that speak both languages: machine and driver. This\narticle offers a conceptual and technical perspective intended to spark\ninterdisciplinary dialogue and guide future research and development in\nintelligent vehicle systems, predictive maintenance, and AI-powered user\ninteraction."}
{"id": "2507.17571", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.17571", "abs": "https://arxiv.org/abs/2507.17571", "authors": ["Hassan Ou-azzou", "Anna-Lena Horlemann", "Nuh Aydin"], "title": "Bounds and Equivalence of Skew Polycyclic Codes over Finite Fields", "comment": null, "summary": "We study skew polycyclic codes over a finite field $\\mathbb{F}_q$, associated\nwith a skew polynomial $f(x) \\in \\mathbb{F}_q[x;\\sigma]$, where $\\sigma$ is an\nautomorphism of $\\mathbb{F}_q$. We start by proving the Roos-like bound for\nboth the Hamming and the rank metric for this class of codes. Next, we focus on\nthe Hamming and rank equivalence between two classes of polycyclic codes by\nintroducing an equivalence relation and describing its equivalence classes.\nFinally, we present examples that illustrate applications of the theory\ndeveloped in this paper."}
{"id": "2507.17168", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17168", "abs": "https://arxiv.org/abs/2507.17168", "authors": ["Qifan Zhang", "Nuo Chen", "Zehua Li", "Miao Peng", "Jing Tang", "Jia Li"], "title": "Improving LLMs' Generalized Reasoning Abilities by Graph Problems", "comment": "COLM2025", "summary": "Large Language Models (LLMs) have made remarkable strides in reasoning tasks,\nyet their performance often falters on novel and complex problems.\nDomain-specific continued pretraining (CPT) methods, such as those tailored for\nmathematical reasoning, have shown promise but lack transferability to broader\nreasoning tasks. In this work, we pioneer the use of Graph Problem Reasoning\n(GPR) to enhance the general reasoning capabilities of LLMs. GPR tasks,\nspanning pathfinding, network analysis, numerical computation, and topological\nreasoning, require sophisticated logical and relational reasoning, making them\nideal for teaching diverse reasoning patterns. To achieve this, we introduce\nGraphPile, the first large-scale corpus specifically designed for CPT using GPR\ndata. Spanning 10.9 billion tokens across 23 graph tasks, the dataset includes\nchain-of-thought, program-of-thought, trace of execution, and real-world graph\ndata. Using GraphPile, we train GraphMind on popular base models Llama 3 and\n3.1, as well as Gemma 2, achieving up to 4.9 percent higher accuracy in\nmathematical reasoning and up to 21.2 percent improvement in non-mathematical\nreasoning tasks such as logical and commonsense reasoning. By being the first\nto harness GPR for enhancing reasoning patterns and introducing the first\ndataset of its kind, our work bridges the gap between domain-specific\npretraining and universal reasoning capabilities, advancing the adaptability\nand robustness of LLMs."}
{"id": "2507.17695", "categories": ["cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.17695", "abs": "https://arxiv.org/abs/2507.17695", "authors": ["Ilias Chatzistefanidis", "Navid Nikaein"], "title": "Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks", "comment": "Submitted to Computer Networks AI for 6G", "summary": "Large Language Model (LLM)-based autonomous agents are expected to play a\nvital role in the evolution of 6G networks, by empowering real-time\ndecision-making related to management and service provisioning to end-users.\nThis shift facilitates the transition from a specialized intelligence approach,\nwhere artificial intelligence (AI) algorithms handle isolated tasks, to\nartificial general intelligence (AGI)-driven networks, where agents possess\nbroader reasoning capabilities and can manage diverse network functions. In\nthis paper, we introduce a novel agentic paradigm that combines LLMs with\nreal-time optimization algorithms towards Trustworthy AI, defined as symbiotic\nagents. Optimizers at the LLM's input-level provide bounded uncertainty\nsteering for numerically precise tasks, whereas output-level optimizers\nsupervised by the LLM enable adaptive real-time control. We design and\nimplement two novel agent types including: (i) Radio Access Network optimizers,\nand (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We\nfurther propose an end-to-end architecture for AGI networks and evaluate it on\na 5G testbed capturing channel fluctuations from moving vehicles. Results show\nthat symbiotic agents reduce decision errors fivefold compared to standalone\nLLM-based agents, while smaller language models (SLM) achieve similar accuracy\nwith a 99.9% reduction in GPU resource overhead and in near-real-time loops of\n82 ms. A multi-agent demonstration for collaborative RAN on the real-world\ntestbed highlights significant flexibility in service-level agreement and\nresource allocation, reducing RAN over-utilization by approximately 44%.\nDrawing on our findings and open-source implementations, we introduce the\nsymbiotic paradigm as the foundation for next-generation, AGI-driven\nnetworks-systems designed to remain adaptable, efficient, and trustworthy even\nas LLMs advance."}
{"id": "2507.17654", "categories": ["cs.IT", "cs.DM", "cs.IR", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.17654", "abs": "https://arxiv.org/abs/2507.17654", "authors": ["Gyanendra K. Verma", "Abhay Kumar Singh"], "title": "On Function-Correcting Codes in the Lee Metric", "comment": null, "summary": "Function-correcting codes are a coding framework designed to minimize\nredundancy while ensuring that specific functions or computations of encoded\ndata can be reliably recovered, even in the presence of errors. The choice of\nmetric is crucial in designing such codes, as it determines which computations\nmust be protected and how errors are measured and corrected. Previous work by\nLiu and Liu [6] studied function-correcting codes over $\\mathbb{Z}_{2^l},\\\nl\\geq 2$ using the homogeneous metric, which coincides with the Lee metric over\n$\\mathbb{Z}_4$. In this paper, we extend the study to codes over\n$\\mathbb{Z}_m,$ for any positive integer $m\\geq 2$ under the Lee metric and aim\nto determine their optimal redundancy. To achieve this, we introduce irregular\nLee distance codes and derive upper and lower bounds on the optimal redundancy\nby characterizing the shortest possible length of such codes. These general\nbounds are then simplified and applied to specific classes of functions,\nincluding Lee-local functions, Lee weight functions, and Lee weight\ndistribution functions, leading to improved some bounds compared to those of\nLiu and Liu [6] over $\\mathbb{Z}_4$ and generalize the other bounds over\n$\\mathbb{Z}_m$ in the Lee metric."}
{"id": "2507.17214", "categories": ["cs.AI", "cs.CY", "cs.NI", "cs.SY", "eess.SY", "I.2; B.8; C.2; I.5; J.7"], "pdf": "https://arxiv.org/pdf/2507.17214", "abs": "https://arxiv.org/abs/2507.17214", "authors": ["Amod Kant Agrawal"], "title": "Our Cars Can Talk: How IoT Brings AI to Vehicles", "comment": "3 pages, 1 figure; To appear in IEEE Computer (Nov 2025)", "summary": "Bringing AI to vehicles and enabling them as sensing platforms is key to\ntransforming maintenance from reactive to proactive. Now is the time to\nintegrate AI copilots that speak both languages: machine and driver. This\narticle offers a conceptual and technical perspective intended to spark\ninterdisciplinary dialogue and guide future research and development in\nintelligent vehicle systems, predictive maintenance, and AI-powered user\ninteraction."}
{"id": "2507.17736", "categories": ["cs.IT", "cs.CR", "cs.DB", "cs.NI", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.17736", "abs": "https://arxiv.org/abs/2507.17736", "authors": ["Shreya Meel", "Sennur Ulukus"], "title": "Symmetric Private Information Retrieval (SPIR) on Graph-Based Replicated Systems", "comment": null, "summary": "We introduce the problem of symmetric private information retrieval (SPIR) on\nreplicated databases modeled by a simple graph. In this model, each vertex\ncorresponds to a server, and a message is replicated on two servers if and only\nif there is an edge between them. We consider the setting where the server-side\ncommon randomness necessary to accomplish SPIR is also replicated at the\nservers according to the graph, and we call this as message-specific common\nrandomness. In this setting, we establish a lower bound on the SPIR capacity,\ni.e., the maximum download rate, for general graphs, by proposing an achievable\nSPIR scheme. Next, we prove that, for any SPIR scheme to be feasible, the\nminimum size of message-specific randomness should be equal to the size of a\nmessage. Finally, by providing matching upper bounds, we derive the exact SPIR\ncapacity for the class of path and regular graphs."}
{"id": "2507.17736", "categories": ["cs.IT", "cs.CR", "cs.DB", "cs.NI", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.17736", "abs": "https://arxiv.org/abs/2507.17736", "authors": ["Shreya Meel", "Sennur Ulukus"], "title": "Symmetric Private Information Retrieval (SPIR) on Graph-Based Replicated Systems", "comment": null, "summary": "We introduce the problem of symmetric private information retrieval (SPIR) on\nreplicated databases modeled by a simple graph. In this model, each vertex\ncorresponds to a server, and a message is replicated on two servers if and only\nif there is an edge between them. We consider the setting where the server-side\ncommon randomness necessary to accomplish SPIR is also replicated at the\nservers according to the graph, and we call this as message-specific common\nrandomness. In this setting, we establish a lower bound on the SPIR capacity,\ni.e., the maximum download rate, for general graphs, by proposing an achievable\nSPIR scheme. Next, we prove that, for any SPIR scheme to be feasible, the\nminimum size of message-specific randomness should be equal to the size of a\nmessage. Finally, by providing matching upper bounds, we derive the exact SPIR\ncapacity for the class of path and regular graphs."}
{"id": "2507.17257", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.17257", "abs": "https://arxiv.org/abs/2507.17257", "authors": ["Elija Perrier", "Michael Timothy Bennett"], "title": "Agent Identity Evals: Measuring Agentic Identity", "comment": null, "summary": "Central to agentic capability and trustworthiness of language model agents\n(LMAs) is the extent they maintain stable, reliable, identity over time.\nHowever, LMAs inherit pathologies from large language models (LLMs)\n(statelessness, stochasticity, sensitivity to prompts and\nlinguistically-intermediation) which can undermine their identifiability,\ncontinuity, persistence and consistency. This attrition of identity can erode\ntheir reliability, trustworthiness and utility by interfering with their\nagentic capabilities such as reasoning, planning and action. To address these\nchallenges, we introduce \\textit{agent identity evals} (AIE), a rigorous,\nstatistically-driven, empirical framework for measuring the degree to which an\nLMA system exhibit and maintain their agentic identity over time, including\ntheir capabilities, properties and ability to recover from state perturbations.\nAIE comprises a set of novel metrics which can integrate with other measures of\nperformance, capability and agentic robustness to assist in the design of\noptimal LMA infrastructure and scaffolding such as memory and tools. We set out\nformal definitions and methods that can be applied at each stage of the LMA\nlife-cycle, and worked examples of how to apply them."}
{"id": "2507.17258", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17258", "abs": "https://arxiv.org/abs/2507.17258", "authors": ["Andreas Scholl", "Natalie Kiesler"], "title": "Students' Feedback Requests and Interactions with the SCRIPT Chatbot: Do They Get What They Ask For?", "comment": "Accepted at PPIG 2025", "summary": "Building on prior research on Generative AI (GenAI) and related tools for\nprogramming education, we developed SCRIPT, a chatbot based on ChatGPT-4o-mini,\nto support novice learners. SCRIPT allows for open-ended interactions and\nstructured guidance through predefined prompts. We evaluated the tool via an\nexperiment with 136 students from an introductory programming course at a large\nGerman university and analyzed how students interacted with SCRIPT while\nsolving programming tasks with a focus on their feedback preferences. The\nresults reveal that students' feedback requests seem to follow a specific\nsequence. Moreover, the chatbot responses aligned well with students' requested\nfeedback types (in 75%), and it adhered to the system prompt constraints. These\ninsights inform the design of GenAI-based learning support systems and\nhighlight challenges in balancing guidance and flexibility in AI-assisted\ntools."}
{"id": "2507.17289", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17289", "abs": "https://arxiv.org/abs/2507.17289", "authors": ["Shitong Zhu", "Chenhao Fang", "Derek Larson", "Neel Reddy Pochareddy", "Rajeev Rao", "Sophie Zeng", "Yanqing Peng", "Wendy Summer", "Alex Goncalves", "Arya Pudota", "Herve Robert"], "title": "Compliance Brain Assistant: Conversational Agentic AI for Assisting Compliance Tasks in Enterprise Environments", "comment": null, "summary": "This paper presents Compliance Brain Assistant (CBA), a conversational,\nagentic AI assistant designed to boost the efficiency of daily compliance tasks\nfor personnel in enterprise environments. To strike a good balance between\nresponse quality and latency, we design a user query router that can\nintelligently choose between (i) FastTrack mode: to handle simple requests that\nonly need additional relevant context retrieved from knowledge corpora; and\n(ii) FullAgentic mode: to handle complicated requests that need composite\nactions and tool invocations to proactively discover context across various\ncompliance artifacts, and/or involving other APIs/models for accommodating\nrequests. A typical example would be to start with a user query, use its\ndescription to find a specific entity and then use the entity's information to\nquery other APIs for curating and enriching the final AI response.\n  Our experimental evaluations compared CBA against an out-of-the-box LLM on\nvarious real-world privacy/compliance-related queries targeting various\npersonas. We found that CBA substantially improved upon the vanilla LLM's\nperformance on metrics such as average keyword match rate (83.7% vs. 41.7%) and\nLLM-judge pass rate (82.0% vs. 20.0%). We also compared metrics for the full\nrouting-based design against the `fast-track only` and `full-agentic` modes and\nfound that it had a better average match-rate and pass-rate while keeping the\nrun-time approximately the same. This finding validated our hypothesis that the\nrouting mechanism leads to a good trade-off between the two worlds."}
{"id": "2507.17418", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17418", "abs": "https://arxiv.org/abs/2507.17418", "authors": ["Joobin Jin", "Seokjun Hong", "Gyeongseon Baek", "Yeeun Kim", "Byeongjoon Noh"], "title": "Ctx2TrajGen: Traffic Context-Aware Microscale Vehicle Trajectories using Generative Adversarial Imitation Learning", "comment": null, "summary": "Precise modeling of microscopic vehicle trajectories is critical for traffic\nbehavior analysis and autonomous driving systems. We propose Ctx2TrajGen, a\ncontext-aware trajectory generation framework that synthesizes realistic urban\ndriving behaviors using GAIL. Leveraging PPO and WGAN-GP, our model addresses\nnonlinear interdependencies and training instability inherent in microscopic\nsettings. By explicitly conditioning on surrounding vehicles and road geometry,\nCtx2TrajGen generates interaction-aware trajectories aligned with real-world\ncontext. Experiments on the drone-captured DRIFT dataset demonstrate superior\nperformance over existing methods in terms of realism, behavioral diversity,\nand contextual fidelity, offering a robust solution to data scarcity and domain\nshift without simulation."}
{"id": "2507.17477", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17477", "abs": "https://arxiv.org/abs/2507.17477", "authors": ["Haoran Sun", "Zekun Zhang", "Shaoning Zeng"], "title": "An Uncertainty-Driven Adaptive Self-Alignment Framework for Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable progress in\ninstruction following and general-purpose reasoning. However, achieving\nhigh-quality alignment with human intent and safety norms without human\nannotations remains a fundamental challenge. In this work, we propose an\nUncertainty-Driven Adaptive Self-Alignment (UDASA) framework designed to\nimprove LLM alignment in a fully automated manner. UDASA first generates\nmultiple responses for each input and quantifies output uncertainty across\nthree dimensions: semantics, factuality, and value alignment. Based on these\nuncertainty scores, the framework constructs preference pairs and categorizes\ntraining samples into three stages, conservative, moderate, and exploratory,\naccording to their uncertainty difference. The model is then optimized\nprogressively across these stages. In addition, we conduct a series of\npreliminary studies to validate the core design assumptions and provide strong\nempirical motivation for the proposed framework. Experimental results show that\nUDASA outperforms existing alignment methods across multiple tasks, including\nharmlessness, helpfulness, truthfulness, and controlled sentiment generation,\nsignificantly improving model performance."}
{"id": "2507.17482", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17482", "abs": "https://arxiv.org/abs/2507.17482", "authors": ["Luca Salvatore Lorello", "Nikolaos Manginas", "Marco Lippi", "Stefano Melacci"], "title": "LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning", "comment": null, "summary": "Neuro-symbolic artificial intelligence aims to combine neural architectures\nwith symbolic approaches that can represent knowledge in a human-interpretable\nformalism. Continual learning concerns with agents that expand their knowledge\nover time, improving their skills while avoiding to forget previously learned\nconcepts. Most of the existing approaches for neuro-symbolic artificial\nintelligence are applied to static scenarios only, and the challenging setting\nwhere reasoning along the temporal dimension is necessary has been seldom\nexplored. In this work we introduce LTLZinc, a benchmarking framework that can\nbe used to generate datasets covering a variety of different problems, against\nwhich neuro-symbolic and continual learning methods can be evaluated along the\ntemporal and constraint-driven dimensions. Our framework generates expressive\ntemporal reasoning and continual learning tasks from a linear temporal logic\nspecification over MiniZinc constraints, and arbitrary image classification\ndatasets. Fine-grained annotations allow multiple neural and neuro-symbolic\ntraining settings on the same generated datasets. Experiments on six\nneuro-symbolic sequence classification and four class-continual learning tasks\ngenerated by LTLZinc, demonstrate the challenging nature of temporal learning\nand reasoning, and highlight limitations of current state-of-the-art methods.\nWe release the LTLZinc generator and ten ready-to-use tasks to the\nneuro-symbolic and continual learning communities, in the hope of fostering\nresearch towards unified temporal learning and reasoning frameworks."}
{"id": "2507.17487", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2507.17487", "abs": "https://arxiv.org/abs/2507.17487", "authors": ["Lorenzo Marconi", "Flavia Ricci", "Riccardo Rosati"], "title": "CQE under Epistemic Dependencies: Algorithms and Experiments (extended version)", "comment": "Extended version of paper accepted at the 24th International Semantic\n  Web Conference (ISWC 2025)", "summary": "We investigate Controlled Query Evaluation (CQE) over ontologies, where\ninformation disclosure is regulated by epistemic dependencies (EDs), a family\nof logical rules recently proposed for the CQE framework. In particular, we\ncombine EDs with the notion of optimal GA censors, i.e. maximal sets of ground\natoms that are entailed by the ontology and can be safely revealed. We focus on\nanswering Boolean unions of conjunctive queries (BUCQs) with respect to the\nintersection of all optimal GA censors - an approach that has been shown in\nother contexts to ensure strong security guarantees with favorable\ncomputational behavior. First, we characterize the security of this\nintersection-based approach and identify a class of EDs (namely, full EDs) for\nwhich it remains safe. Then, for a subclass of EDs and for DL-Lite_R\nontologies, we show that answering BUCQs in the above CQE semantics is in AC^0\nin data complexity by presenting a suitable, detailed first-order rewriting\nalgorithm. Finally, we report on experiments conducted in two different\nevaluation scenarios, showing the practical feasibility of our rewriting\nfunction."}
{"id": "2507.17493", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.17493", "abs": "https://arxiv.org/abs/2507.17493", "authors": ["Alexander Beiser", "Markus Hecher", "Stefan Woltran"], "title": "Automated Hybrid Grounding Using Structural and Data-Driven Heuristics", "comment": null, "summary": "The grounding bottleneck poses one of the key challenges that hinders the\nwidespread adoption of Answer Set Programming in industry. Hybrid Grounding is\na step in alleviating the bottleneck by combining the strength of standard\nbottom-up grounding with recently proposed techniques where rule bodies are\ndecoupled during grounding. However, it has remained unclear when hybrid\ngrounding shall use body-decoupled grounding and when to use standard bottom-up\ngrounding. In this paper, we address this issue by developing automated hybrid\ngrounding: we introduce a splitting algorithm based on data-structural\nheuristics that detects when to use body-decoupled grounding and when standard\ngrounding is beneficial. We base our heuristics on the structure of rules and\nan estimation procedure that incorporates the data of the instance. The\nexperiments conducted on our prototypical implementation demonstrate promising\nresults, which show an improvement on hard-to-ground scenarios, whereas on\nhard-to-solve instances we approach state-of-the-art performance."}
{"id": "2507.17512", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17512", "abs": "https://arxiv.org/abs/2507.17512", "authors": ["Yu Li", "Zhuoshi Pan", "Honglin Lin", "Mengyuan Sun", "Conghui He", "Lijun Wu"], "title": "Can One Domain Help Others? A Data-Centric Study on Multi-Domain Reasoning via Reinforcement Learning", "comment": "27 pages, 24 figures", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a\npowerful paradigm for enhancing the reasoning capabilities of LLMs. Existing\nresearch has predominantly concentrated on isolated reasoning domains such as\nmathematical problem-solving, coding tasks, or logical reasoning. However, real\nworld reasoning scenarios inherently demand an integrated application of\nmultiple cognitive skills. Despite this, the interplay among these reasoning\nskills under reinforcement learning remains poorly understood. To bridge this\ngap, we present a systematic investigation of multi-domain reasoning within the\nRLVR framework, explicitly focusing on three primary domains: mathematical\nreasoning, code generation, and logical puzzle solving. We conduct a\ncomprehensive study comprising four key components: (1) Leveraging the GRPO\nalgorithm and the Qwen-2.5-7B model family, our study thoroughly evaluates the\nmodels' in-domain improvements and cross-domain generalization capabilities\nwhen trained on single-domain datasets. (2) Additionally, we examine the\nintricate interactions including mutual enhancements and conflicts that emerge\nduring combined cross-domain training. (3) To further understand the influence\nof SFT on RL, we also analyze and compare performance differences between base\nand instruct models under identical RL configurations. (4) Furthermore, we\ndelve into critical RL training details, systematically exploring the impacts\nof curriculum learning strategies, variations in reward design, and\nlanguage-specific factors. Through extensive experiments, our results offer\nsignificant insights into the dynamics governing domain interactions, revealing\nkey factors influencing both specialized and generalizable reasoning\nperformance. These findings provide valuable guidance for optimizing RL\nmethodologies to foster comprehensive, multi-domain reasoning capabilities in\nLLMs."}
{"id": "2507.17514", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17514", "abs": "https://arxiv.org/abs/2507.17514", "authors": ["Athanasios Davvetas", "Xenia Ziouvelou", "Ypatia Dami", "Alexis Kaponis", "Konstantina Giouvanopoulou", "Michael Papademas"], "title": "TAI Scan Tool: A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment", "comment": "9 pages, 1 figure, 4 tables", "summary": "This paper introduces the TAI Scan Tool, a RAG-based TAI self-assessment tool\nwith minimalistic input. The current version of the tool supports the legal TAI\nassessment, with a particular emphasis on facilitating compliance with the AI\nAct. It involves a two-step approach with a pre-screening and an assessment\nphase. The assessment output of the system includes insight regarding the\nrisk-level of the AI system according to the AI Act, while at the same time\nretrieving relevant articles to aid with compliance and notify on their\nobligations. Our qualitative evaluation using use-case scenarios yields\npromising results, correctly predicting risk levels while retrieving relevant\narticles across three distinct semantic groups. Furthermore, interpretation of\nresults shows that the tool's reasoning relies on comparison with the setting\nof high-risk systems, a behaviour attributed to their deployment requiring\ncareful consideration, and therefore frequently presented within the AI Act."}
{"id": "2507.17539", "categories": ["cs.AI", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.17539", "abs": "https://arxiv.org/abs/2507.17539", "authors": ["Xinyao Liu", "Diping Song"], "title": "Constructing Ophthalmic MLLM for Positioning-diagnosis Collaboration Through Clinical Cognitive Chain Reasoning", "comment": null, "summary": "Multimodal large language models (MLLMs) demonstrate significant potential in\nthe field of medical diagnosis. However, they face critical challenges in\nspecialized domains such as ophthalmology, particularly the fragmentation of\nannotation granularity and inconsistencies in clinical reasoning logic, which\nhinder precise cross-modal understanding. This paper introduces FundusExpert,\nan ophthalmology-specific MLLM with integrated positioning-diagnosis reasoning\ncapabilities, along with FundusGen, a dataset constructed through the\nintelligent Fundus-Engine system. Fundus-Engine automates localization and\nleverages MLLM-based semantic expansion to integrate global disease\nclassification, local object detection, and fine-grained feature analysis\nwithin a single fundus image. Additionally, by constructing a clinically\naligned cognitive chain, it guides the model to generate interpretable\nreasoning paths. FundusExpert, fine-tuned with instruction data from FundusGen,\nachieves the best performance in ophthalmic question-answering tasks,\nsurpassing the average accuracy of the 40B MedRegA by 26.6%. It also excels in\nzero-shot report generation tasks, achieving a clinical consistency of 77.0%,\nsignificantly outperforming GPT-4o's 47.6%. Furthermore, we reveal a scaling\nlaw between data quality and model capability ($L \\propto N^{0.068}$),\ndemonstrating that the cognitive alignment annotations in FundusGen enhance\ndata utilization efficiency. By integrating region-level localization with\ndiagnostic reasoning chains, our work develops a scalable, clinically-aligned\nMLLM and explores a pathway toward bridging the visual-language gap in specific\nMLLMs. Our project can be found at https://github.com/MeteorElf/FundusExpert."}
{"id": "2507.17680", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.17680", "abs": "https://arxiv.org/abs/2507.17680", "authors": ["Yongchao Zeng", "Calum Brown", "Ioannis Kyriakou", "Ronja Hotz", "Mark Rounsevell"], "title": "Simulating multiple human perspectives in socio-ecological systems using large language models", "comment": null, "summary": "Understanding socio-ecological systems requires insights from diverse\nstakeholder perspectives, which are often hard to access. To enable\nalternative, simulation-based exploration of different stakeholder\nperspectives, we develop the HoPeS (Human-Oriented Perspective Shifting)\nmodelling framework. HoPeS employs agents powered by large language models\n(LLMs) to represent various stakeholders; users can step into the agent roles\nto experience perspectival differences. A simulation protocol serves as a\n\"scaffold\" to streamline multiple perspective-taking simulations, supporting\nusers in reflecting on, transitioning between, and integrating across\nperspectives. A prototype system is developed to demonstrate HoPeS in the\ncontext of institutional dynamics and land use change, enabling both\nnarrative-driven and numerical experiments. In an illustrative experiment, a\nuser successively adopts the perspectives of a system observer and a researcher\n- a role that analyses data from the embedded land use model to inform\nevidence-based decision-making for other LLM agents representing various\ninstitutions. Despite the user's effort to recommend technically sound\npolicies, discrepancies persist between the policy recommendation and\nimplementation due to stakeholders' competing advocacies, mirroring real-world\nmisalignment between researcher and policymaker perspectives. The user's\nreflection highlights the subjective feelings of frustration and disappointment\nas a researcher, especially due to the challenge of maintaining political\nneutrality while attempting to gain political influence. Despite this, the user\nexhibits high motivation to experiment with alternative narrative framing\nstrategies, suggesting the system's potential in exploring different\nperspectives. Further system and protocol refinement are likely to enable new\nforms of interdisciplinary collaboration in socio-ecological simulations."}
{"id": "2507.17695", "categories": ["cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.17695", "abs": "https://arxiv.org/abs/2507.17695", "authors": ["Ilias Chatzistefanidis", "Navid Nikaein"], "title": "Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks", "comment": "Submitted to Computer Networks AI for 6G", "summary": "Large Language Model (LLM)-based autonomous agents are expected to play a\nvital role in the evolution of 6G networks, by empowering real-time\ndecision-making related to management and service provisioning to end-users.\nThis shift facilitates the transition from a specialized intelligence approach,\nwhere artificial intelligence (AI) algorithms handle isolated tasks, to\nartificial general intelligence (AGI)-driven networks, where agents possess\nbroader reasoning capabilities and can manage diverse network functions. In\nthis paper, we introduce a novel agentic paradigm that combines LLMs with\nreal-time optimization algorithms towards Trustworthy AI, defined as symbiotic\nagents. Optimizers at the LLM's input-level provide bounded uncertainty\nsteering for numerically precise tasks, whereas output-level optimizers\nsupervised by the LLM enable adaptive real-time control. We design and\nimplement two novel agent types including: (i) Radio Access Network optimizers,\nand (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We\nfurther propose an end-to-end architecture for AGI networks and evaluate it on\na 5G testbed capturing channel fluctuations from moving vehicles. Results show\nthat symbiotic agents reduce decision errors fivefold compared to standalone\nLLM-based agents, while smaller language models (SLM) achieve similar accuracy\nwith a 99.9% reduction in GPU resource overhead and in near-real-time loops of\n82 ms. A multi-agent demonstration for collaborative RAN on the real-world\ntestbed highlights significant flexibility in service-level agreement and\nresource allocation, reducing RAN over-utilization by approximately 44%.\nDrawing on our findings and open-source implementations, we introduce the\nsymbiotic paradigm as the foundation for next-generation, AGI-driven\nnetworks-systems designed to remain adaptable, efficient, and trustworthy even\nas LLMs advance."}
{"id": "2507.17699", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17699", "abs": "https://arxiv.org/abs/2507.17699", "authors": ["Zhao Song", "Song Yue", "Jiahao Zhang"], "title": "Thinking Isn't an Illusion: Overcoming the Limitations of Reasoning Models via Tool Augmentations", "comment": null, "summary": "Large Reasoning Models (LRMs) have become a central focus in today's large\nlanguage model (LLM) research, where models are designed to output a\nstep-by-step thinking process before arriving at a final answer to handle\ncomplex reasoning tasks. Despite their promise, recent empirical studies (e.g.,\n[Shojaee et al., 2025] from Apple) suggest that this thinking process may not\nactually enhance reasoning ability, where LLMs without explicit reasoning\nactually outperform LRMs on tasks with low or high complexity. In this work, we\nrevisit these findings and investigate whether the limitations of LRMs persist\nwhen tool augmentations are introduced. We incorporate two types of tools,\nPython interpreters and scratchpads, and evaluate three representative LLMs and\ntheir LRM counterparts on Apple's benchmark reasoning puzzles. Our results show\nthat, with proper tool use, LRMs consistently outperform their non-reasoning\ncounterparts across all levels of task complexity. These findings challenge the\nrecent narrative that reasoning is an illusion and highlight the potential of\ntool-augmented LRMs for solving complex problems."}
{"id": "2507.17730", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17730", "abs": "https://arxiv.org/abs/2507.17730", "authors": ["Zhe Chen", "Daniel Harabor", "Ryan Hechnenberger", "Nathan R. Sturtevant"], "title": "Online Submission and Evaluation System Design for Competition Operations", "comment": "This work was presented at the Workshop on the International Planning\n  Competition (WIPC 2024)", "summary": "Research communities have developed benchmark datasets across domains to\ncompare the performance of algorithms and techniques However, tracking the\nprogress in these research areas is not easy, as publications appear in\ndifferent venues at the same time, and many of them claim to represent the\nstate-of-the-art. To address this, research communities often organise periodic\ncompetitions to evaluate the performance of various algorithms and techniques,\nthereby tracking advancements in the field. However, these competitions pose a\nsignificant operational burden. The organisers must manage and evaluate a large\nvolume of submissions. Furthermore, participants typically develop their\nsolutions in diverse environments, leading to compatibility issues during the\nevaluation of their submissions. This paper presents an online competition\nsystem that automates the submission and evaluation process for a competition.\nThe competition system allows organisers to manage large numbers of submissions\nefficiently, utilising isolated environments to evaluate submissions. This\nsystem has already been used successfully for several competitions, including\nthe Grid-Based Pathfinding Competition and the League of Robot Runners\ncompetition."}
{"id": "2507.17188", "categories": ["cs.NI", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17188", "abs": "https://arxiv.org/abs/2507.17188", "authors": ["Lijie Zheng", "Ji He", "Shih Yu Chang", "Yulong Shen", "Dusit Niyato"], "title": "LLM Meets the Sky: Heuristic Multi-Agent Reinforcement Learning for Secure Heterogeneous UAV Networks", "comment": "Submitted to IEEE Transactions on Mobile Computing", "summary": "This work tackles the physical layer security (PLS) problem of maximizing the\nsecrecy rate in heterogeneous UAV networks (HetUAVNs) under propulsion energy\nconstraints. Unlike prior studies that assume uniform UAV capabilities or\noverlook energy-security trade-offs, we consider a realistic scenario where\nUAVs with diverse payloads and computation resources collaborate to serve\nground terminals in the presence of eavesdroppers. To manage the complex\ncoupling between UAV motion and communication, we propose a hierarchical\noptimization framework. The inner layer uses a semidefinite relaxation\n(SDR)-based S2DC algorithm combining penalty functions and difference-of-convex\n(d.c.) programming to solve the secrecy precoding problem with fixed UAV\npositions. The outer layer introduces a Large Language Model (LLM)-guided\nheuristic multi-agent reinforcement learning approach (LLM-HeMARL) for\ntrajectory optimization. LLM-HeMARL efficiently incorporates expert heuristics\npolicy generated by the LLM, enabling UAVs to learn energy-aware,\nsecurity-driven trajectories without the inference overhead of real-time LLM\ncalls. The simulation results show that our method outperforms existing\nbaselines in secrecy rate and energy efficiency, with consistent robustness\nacross varying UAV swarm sizes and random seeds."}
