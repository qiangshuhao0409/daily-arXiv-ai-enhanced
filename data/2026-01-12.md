<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 2]
- [cs.AI](#cs.AI) [Total: 30]
- [cs.IT](#cs.IT) [Total: 12]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [2BRobust -- Overcoming TCP BBR Performance Degradation in Virtual Machines under CPU Contention](https://arxiv.org/abs/2601.05665)
*Kathrin Elmenhorst,Nils Aschenbruck*

Main category: cs.NI

TL;DR: BBR拥塞控制在CPU资源受限时性能严重下降，而Cubic不受影响。作者提出通过监控inflight字节来检测CPU限制，并通过调整pacing rate来改善性能。


<details>
  <summary>Details</summary>
Motivation: 随着BBR拥塞控制算法的大规模部署，需要评估其在各种网络和系统场景下的鲁棒性。特别是在云虚拟机环境中，已有研究表明BBRv1-2在Xen虚拟机中CPU信用低时性能会急剧下降。考虑到BBR可能在全网范围内取代Cubic，必须确保其在不同条件下的稳定性。

Method: 开发了一个在完全受控CPU竞争条件下测量TCP吞吐量的框架，使用Linux deadline调度来模拟广义的CPU竞争条件。通过精细粒度测量分析性能下降特征，并提出最小化BBR补丁：通过监控inflight字节检测CPU限制情况，并通过增加pacing rate来更好地利用可用CPU时间。

Result: 测量显示，与Cubic不同，BBR在任何hypervisor和所有测试的BDP条件下，在CPU竞争期间吞吐量都会崩溃。CPU受限的BBR发送器被限制在非常低的吞吐量水平（低于10-20 Mbps）。提出的BBR补丁在大多数关键情况下成功克服了吞吐量问题。

Conclusion: 从Cubic向BBR的全网迁移可能会损害互联网的整体鲁棒性，如果不谨慎部署的话。提出的检测和缓解机制能够有效解决CPU限制导致的性能问题，为BBR在云环境中的安全部署提供了解决方案。

Abstract: Motivated by the recent introduction and large-scale deployment of BBR congestion control algorithms, multiple studies have investigated the performance and fairness implications of this shift from loss-based to delay-based congestion control. Given the potential Internet-wide adoption of BBR, we must also consider its robustness in network and system scenarios. One such scenario is Cloud-based Virtual Machine (VM) networking - highly relevant in today's CDN-centric Internet. Interestingly, previous work has shown significant performance problems of BBRv1-2 running in Xen VMs, with BBR performance dropping to almost zero when CPU credit is low. In this paper, we develop a framework for measuring TCP throughput under fully controlled CPU contention, which uses Linux deadline scheduling to emulate generalized CPU contention conditions. Our measurements reveal that - in stark contrast to Cubic! - BBR throughput can break down during CPU contention under any hypervisor and all tested BDP conditions. Characterizing this performance degradation on a fine-granular level, we show that CPU limited BBR senders are capped at very low throughput levels below 10-20 Mbps. This finding implies that an Internet-wide shift from Cubic to BBR could harm the Internet's overall robustness, if not deployed with caution. To detect and overcome CPU-limited throughput, we propose a minimal BBR patch which detects the problematic situation by monitoring inflight bytes and reacts by increasing the pacing rate to make better use of the available CPU time. We show that our BBR patch overcomes the throughput problem for the most critical cases.

</details>


### [2] [AWaRe-SAC: Proactive Slice Admission Control under Weather-Induced Capacity Uncertainty](https://arxiv.org/abs/2601.05978)
*Dror Jacoby,Yanzhi Li,Shuyue Yu,Nicola Di Cicco,Hagit Messer,Gil Zussman,Igor Kadota*

Main category: cs.NI

TL;DR: 提出一个基于深度学习和Q学习的主动切片准入控制框架，用于毫米波x-haul网络，以应对雨衰引起的容量波动，相比传统反应式方法能提高2-3倍长期平均收益。


<details>
  <summary>Details</summary>
Motivation: 毫米波链路在x-haul网络中的应用面临天气相关衰减（特别是雨衰）的挑战，难以维持严格的QoS要求，需要在网络容量不确定的情况下做出准入决策。

Method: 开发了一个主动切片准入控制框架，集成了未来网络条件的深度学习预测器和基于Q学习的主动切片准入控制机制。

Result: 在密集城市区域的真实毫米波x-haul部署数据上进行评估，结果显示主动解决方案在动态链路条件下实现了2-3倍更高的长期平均收益。

Conclusion: 该框架为自适应准入控制提供了一个可扩展且具有弹性的解决方案，超越了标准反应式方法的局限性。

Abstract: As emerging applications demand higher throughput and lower latencies, operators are increasingly deploying millimeter-wave (mmWave) links within x-haul transport networks, spanning fronthaul, midhaul, and backhaul segments. However, the inherent susceptibility of mmWave frequencies to weather-related attenuation, particularly rain fading, complicates the maintenance of stringent Quality of Service (QoS) requirements. This creates a critical challenge: making admission decisions under uncertainty regarding future network capacity. To address this, we develop a proactive slice admission control framework for mmWave x-haul networks subject to rain-induced fluctuations. Our objective is to improve network performance, ensure QoS, and optimize revenue, thereby surpassing the limitations of standard reactive approaches. The proposed framework integrates a deep learning predictor of future network conditions with a proactive Q-learning-based slice admission control mechanism. We validate our solution using real-world data from a mmWave x-haul deployment in a dense urban area, incorporating realistic models of link capacity attenuation and dynamic slice demands. Extensive evaluations demonstrate that our proactive solution achieves 2-3x higher long-term average revenue under dynamic link conditions, providing a scalable and resilient framework for adaptive admission control.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [3] [GenCtrl -- A Formal Controllability Toolkit for Generative Models](https://arxiv.org/abs/2601.05637)
*Emily Cheng,Carmen Amo Alonso,Federico Danieli,Arno Blaas,Luca Zappella,Pau Rodriguez,Xavier Suau*

Main category: cs.AI

TL;DR: 本文提出一个理论框架来评估生成模型的可控性，通过对话场景下的可控集估计算法，提供分布无关的PAC边界，发现模型可控性出人意料地脆弱。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型普及，需要细粒度控制生成过程，但现有控制方法（从提示到微调）未能回答一个根本问题：这些模型是否真正可控？需要理论框架来形式化分析模型的可控性。

Method: 将人机交互建模为控制过程，提出新颖算法估计对话场景下模型的可控集。提供形式化保证：基于样本复杂度的估计误差PAC边界，分布无关、仅需输出有界假设、适用于任何黑盒非线性控制系统（即任何生成模型）。

Result: 在对话过程控制的不同任务上实证验证理论框架，包括语言模型和文本到图像生成。结果显示模型可控性出人意料地脆弱，高度依赖实验设置。

Conclusion: 需要严格的可控性分析，将重点从单纯尝试控制转向首先理解其基本限制。模型可控性具有根本性限制，实际应用中需要谨慎评估。

Abstract: As generative models become ubiquitous, there is a critical need for fine-grained control over the generation process. Yet, while controlled generation methods from prompting to fine-tuning proliferate, a fundamental question remains unanswered: are these models truly controllable in the first place? In this work, we provide a theoretical framework to formally answer this question. Framing human-model interaction as a control process, we propose a novel algorithm to estimate the controllable sets of models in a dialogue setting. Notably, we provide formal guarantees on the estimation error as a function of sample complexity: we derive probably-approximately correct bounds for controllable set estimates that are distribution-free, employ no assumptions except for output boundedness, and work for any black-box nonlinear control system (i.e., any generative model). We empirically demonstrate the theoretical framework on different tasks in controlling dialogue processes, for both language models and text-to-image generation. Our results show that model controllability is surprisingly fragile and highly dependent on the experimental setting. This highlights the need for rigorous controllability analysis, shifting the focus from simply attempting control to first understanding its fundamental limits.

</details>


### [4] [Naiad: Novel Agentic Intelligent Autonomous System for Inland Water Monitoring](https://arxiv.org/abs/2601.05256)
*Eirini Baltzi,Tilemachos Moumouris,Athena Psalta,Vasileios Tsironis,Konstantinos Karantzalos*

Main category: cs.AI

TL;DR: NAIAD是一个基于LLM的智能助手，通过整合多种工具和RAG技术，为内陆水体监测提供端到端解决方案，支持自然语言查询并生成定制化报告。


<details>
  <summary>Details</summary>
Motivation: 现有内陆水体监测方法通常孤立地处理不同水质指标（如蓝藻、叶绿素等），缺乏整体性解决方案。需要为专家和非专家用户提供统一的、易于使用的监测工具。

Method: 采用基于LLM的智能代理架构，结合RAG、外部工具编排、计算图执行和代理反思。整合天气数据、Sentinel-2影像、遥感指数计算（如NDCI）、叶绿素-a估算以及CyFi等平台。

Result: 在专门基准测试中，正确性和相关性分别达到77%和85%以上。Gemma 3 (27B)和Qwen 2.5 (14B)在计算效率和推理性能方面表现最佳。

Conclusion: NAIAD证明了基于LLM的智能代理能够为内陆水体监测提供全面解决方案，具有良好的适应性、鲁棒性和用户友好性，为环境监测领域提供了新的技术范式。

Abstract: Inland water monitoring is vital for safeguarding public health and ecosystems, enabling timely interventions to mitigate risks. Existing methods often address isolated sub-problems such as cyanobacteria, chlorophyll, or other quality indicators separately. NAIAD introduces an agentic AI assistant that leverages Large Language Models (LLMs) and external analytical tools to deliver a holistic solution for inland water monitoring using Earth Observation (EO) data. Designed for both experts and non-experts, NAIAD provides a single-prompt interface that translates natural-language queries into actionable insights. Through Retrieval-Augmented Generation (RAG), LLM reasoning, external tool orchestration, computational graph execution, and agentic reflection, it retrieves and synthesizes knowledge from curated sources to produce tailored reports. The system integrates diverse tools for weather data, Sentinel-2 imagery, remote-sensing index computation (e.g., NDCI), chlorophyll-a estimation, and established platforms such as CyFi. Performance is evaluated using correctness and relevancy metrics, achieving over 77% and 85% respectively on a dedicated benchmark covering multiple user-expertise levels. Preliminary results show strong adaptability and robustness across query types. An ablation study on LLM backbones further highlights Gemma 3 (27B) and Qwen 2.5 (14B) as offering the best balance between computational efficiency and reasoning performance.

</details>


### [5] [Mathematical Knowledge Graph-Driven Framework for Equation-Based Predictive and Reliable Additive Manufacturing](https://arxiv.org/abs/2601.05298)
*Yeongbin Cha,Namjung Kim*

Main category: cs.AI

TL;DR: 提出基于本体引导、以方程为中心的框架，将大语言模型与增材制造数学知识图谱结合，实现可靠知识提取和外推建模


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法受限于碎片化知识表示和稀疏数据条件下的不可靠外推，需要更可靠的知识提取和外推建模方法

Method: 1) 构建形式化本体编码方程、变量、假设及其语义关系；2) 基于知识图谱子图条件化LLM方程生成；3) 引入置信感知外推评估，整合外推距离、统计稳定性和物理一致性

Result: 本体引导提取显著提升知识结构一致性和定量可靠性；子图条件化方程生成相比无引导LLM输出产生更稳定、物理一致的外推结果

Conclusion: 建立了本体驱动知识表示、方程中心推理和置信度外推评估的统一流程，展示了知识图谱增强LLM作为增材制造外推建模可靠工具的潜力

Abstract: Additive manufacturing (AM) relies critically on understanding and extrapolating process-property relationships; however, existing data-driven approaches remain limited by fragmented knowledge representations and unreliable extrapolation under sparse data conditions. In this study, we propose an ontology-guided, equation-centric framework that tightly integrates large language models (LLMs) with an additive manufacturing mathematical knowledge graph (AM-MKG) to enable reliable knowledge extraction and principled extrapolative modeling. By explicitly encoding equations, variables, assumptions, and their semantic relationships within a formal ontology, unstructured literature is transformed into machine-interpretable representations that support structured querying and reasoning. LLM-based equation generation is further conditioned on MKG-derived subgraphs, enforcing physically meaningful functional forms and mitigating non-physical or unstable extrapolation trends. To assess reliability beyond conventional predictive uncertainty, a confidence-aware extrapolation assessment is introduced, integrating extrapolation distance, statistical stability, and knowledge-graph-based physical consistency into a unified confidence score. Results demonstrate that ontology-guided extraction significantly improves the structural coherence and quantitative reliability of extracted knowledge, while subgraph-conditioned equation generation yields stable and physically consistent extrapolations compared to unguided LLM outputs. Overall, this work establishes a unified pipeline for ontology-driven knowledge representation, equation-centered reasoning, and confidence-based extrapolation assessment, highlighting the potential of knowledge-graph-augmented LLMs as reliable tools for extrapolative modeling in additive manufacturing.

</details>


### [6] [Effects of personality steering on cooperative behavior in Large Language Model agents](https://arxiv.org/abs/2601.05302)
*Mizuki Sakai,Mizuki Yokoyama,Wakaba Tateishi,Genki Ichinose*

Main category: cs.AI

TL;DR: 研究通过重复囚徒困境游戏探索LLM人格操控对合作行为的影响，发现宜人性是促进合作的主要因素，人格操控更多是行为偏差而非确定性控制机制。


<details>
  <summary>Details</summary>
Motivation: 尽管研究表明为LLM分配人格特质会影响其行为，但人格操控在受控条件下如何影响合作行为仍不清楚。本研究旨在探究人格操控对LLM代理在重复囚徒困境中合作行为的影响。

Method: 基于大五人格框架，首先使用大五人格量表测量GPT-3.5-turbo、GPT-4o和GPT-5的基本人格特征。然后在基线和人格操控条件下比较行为，并分析单独操纵每个人格维度到极端值的效果。

Result: 宜人性是所有模型中促进合作的主导因素，其他人格特质影响有限。明确的人格信息会增加合作，但也可能增加被利用的脆弱性，特别是在早期模型中。后期模型表现出更具选择性的合作。

Conclusion: 人格操控更多是作为行为偏差而非确定性控制机制，对LLM代理的合作行为产生系统性影响，但并非完全可控。

Abstract: Large language models (LLMs) are increasingly used as autonomous agents in strategic and social interactions. Although recent studies suggest that assigning personality traits to LLMs can influence their behavior, how personality steering affects cooperation under controlled conditions remains unclear. In this study, we examine the effects of personality steering on cooperative behavior in LLM agents using repeated Prisoner's Dilemma games. Based on the Big Five framework, we first measure basic personality profiles of three models, GPT-3.5-turbo, GPT-4o, and GPT-5, using the Big Five Inventory. We then compare behavior under baseline and personality-informed conditions, and further analyze the effects of independently manipulating each personality dimension to extreme values. Our results show that agreeableness is the dominant factor promoting cooperation across all models, while other personality traits have limited impact. Explicit personality information increases cooperation but can also raise vulnerability to exploitation, particularly in earlier-generation models. In contrast, later-generation models exhibit more selective cooperation. These findings indicate that personality steering acts as a behavioral bias rather than a deterministic control mechanism.

</details>


### [7] [Improving Enzyme Prediction with Chemical Reaction Equations by Hypergraph-Enhanced Knowledge Graph Embeddings](https://arxiv.org/abs/2601.05330)
*Tengwei Song,Long Yin,Zhen Han,Zhiqiang Xu*

Main category: cs.AI

TL;DR: 提出Hyper-Enz模型，通过知识图谱嵌入和超图变换器预测酶-底物相互作用，利用化学反应方程数据解决传统方法数据稀疏问题。


<details>
  <summary>Details</summary>
Motivation: 传统酶-底物相互作用预测方法依赖专家标注的稀疏数据库，数据不足且维护成本高，限制了模型的泛化能力。化学反应方程数据更容易获取且更丰富，但其中多化合物与酶的复杂关系模式传统模型难以捕捉。

Method: 将化学反应方程表示为(底物，酶，产物)三元组构建知识图谱，提出Hyper-Enz模型：集成超图变换器和知识图谱嵌入模型学习涉及多个底物和产物的超边表示，引入多专家范式指导酶-底物相互作用学习。

Result: 实验结果显示显著改进：酶检索准确率相对提升达88%，配对级预测提升30%，优于传统模型。

Conclusion: Hyper-Enz模型通过整合化学反应方程数据和知识图谱嵌入，有效解决了酶-底物相互作用预测中的数据稀疏问题，显著提升了预测性能。

Abstract: Predicting enzyme-substrate interactions has long been a fundamental problem in biochemistry and metabolic engineering. While existing methods could leverage databases of expert-curated enzyme-substrate pairs for models to learn from known pair interactions, the databases are often sparse, i.e., there are only limited and incomplete examples of such pairs, and also labor-intensive to maintain. This lack of sufficient training data significantly hinders the ability of traditional enzyme prediction models to generalize to unseen interactions. In this work, we try to exploit chemical reaction equations from domain-specific databases, given their easier accessibility and denser, more abundant data. However, interactions of multiple compounds, e.g., educts and products, with the same enzymes create complex relational data patterns that traditional models cannot easily capture. To tackle that, we represent chemical reaction equations as triples of (educt, enzyme, product) within a knowledge graph, such that we can take advantage of knowledge graph embedding (KGE) to infer missing enzyme-substrate pairs for graph completion. Particularly, in order to capture intricate relationships among compounds, we propose our knowledge-enhanced hypergraph model for enzyme prediction, i.e., Hyper-Enz, which integrates a hypergraph transformer with a KGE model to learn representations of the hyper-edges that involve multiple educts and products. Also, a multi-expert paradigm is introduced to guide the learning of enzyme-substrate interactions with both the proposed model and chemical reaction equations. Experimental results show a significant improvement, with up to a 88% relative improvement in average enzyme retrieval accuracy and 30% improvement in pair-level prediction compared to traditional models, demonstrating the effectiveness of our approach.

</details>


### [8] [The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models](https://arxiv.org/abs/2601.05376)
*Tassallah Abdullahi,Shrestha Ghosh,Hamish S Fraser,Daniel León Tramontini,Adeel Abbasi,Ghada Bourjeily,Carsten Eickhoff,Ritambhara Singh*

Main category: cs.AI

TL;DR: 研究发现医疗角色设定对LLMs在临床决策中的影响是系统性的、情境依赖且非单调的：在重症监护任务中提升性能，但在初级保健场景中却降低性能，互动风格的影响高度模型依赖。


<details>
  <summary>Details</summary>
Motivation: 角色设定通常被视为LLMs的行为先验，被认为能提升专业性和安全性，但其对高风险临床决策的具体影响尚不明确，需要系统评估。

Method: 系统评估基于角色的控制对临床LLMs的影响，考察专业角色（急诊医生、护士等）和互动风格（大胆vs谨慎）在不同模型和医疗任务中的行为影响，使用多维评估指标（任务准确性、校准度、安全相关风险行为）。

Result: 医疗角色在重症监护任务中提升性能（准确性和校准度提升约20%），但在初级保健场景中降低相似幅度；互动风格调节风险倾向但高度模型依赖；LLM评估在安全关键案例中偏好医疗角色，但人类临床医生对安全合规性仅有中等一致性（平均Cohen's κ=0.43），且95.9%的回应中对推理质量信心不足。

Conclusion: 角色设定作为行为先验引入的是情境依赖的权衡，而非安全或专业性的保证，揭示了角色设定的复杂性和局限性。

Abstract: Persona conditioning can be viewed as a behavioral prior for large language models (LLMs) and is often assumed to confer expertise and improve safety in a monotonic manner. However, its effects on high-stakes clinical decision-making remain poorly characterized. We systematically evaluate persona-based control in clinical LLMs, examining how professional roles (e.g., Emergency Department physician, nurse) and interaction styles (bold vs.\ cautious) influence behavior across models and medical tasks. We assess performance on clinical triage and patient-safety tasks using multidimensional evaluations that capture task accuracy, calibration, and safety-relevant risk behavior. We find systematic, context-dependent, and non-monotonic effects: Medical personas improve performance in critical care tasks, yielding gains of up to $\sim+20\%$ in accuracy and calibration, but degrade performance in primary-care settings by comparable margins. Interaction style modulates risk propensity and sensitivity, but it's highly model-dependent. While aggregated LLM-judge rankings favor medical over non-medical personas in safety-critical cases, we found that human clinicians show moderate agreement on safety compliance (average Cohen's $κ= 0.43$) but indicate a low confidence in 95.9\% of their responses on reasoning quality. Our work shows that personas function as behavioral priors that introduce context-dependent trade-offs rather than guarantees of safety or expertise. The code is available at https://github.com/rsinghlab/Persona\_Paradox.

</details>


### [9] [Conformity and Social Impact on AI Agents](https://arxiv.org/abs/2601.05384)
*Alessandro Bellina,Giordano De Marzo,David Garcia*

Main category: cs.AI

TL;DR: 大型多模态语言模型作为AI代理在群体环境中表现出系统性从众偏差，即使单独表现完美的模型也容易受到社会影响操纵，存在安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理在多智能体环境中日益普及，理解它们的集体行为对于预测人工社会动态至关重要。研究旨在探索AI代理作为社会行动者如何响应群体影响，特别是从众倾向。

Method: 通过改编社会心理学中的经典视觉实验，研究大型多模态语言模型作为AI代理的从众行为。实验考察了群体规模、一致性、任务难度和来源特征等因素对AI代理决策的影响。

Result: AI代理表现出系统性从众偏差，符合社会影响理论。单独表现近乎完美的AI代理在社会影响下变得高度易受操纵。模型规模越大，在简单任务上从众减少（能力提升），但在能力边界上仍然脆弱。

Conclusion: AI代理决策存在基本安全漏洞，可能被恶意操纵、传播错误信息和偏见。研究强调在集体AI部署中迫切需要安全防护措施。

Abstract: As AI agents increasingly operate in multi-agent environments, understanding their collective behavior becomes critical for predicting the dynamics of artificial societies. This study examines conformity, the tendency to align with group opinions under social pressure, in large multimodal language models functioning as AI agents. By adapting classic visual experiments from social psychology, we investigate how AI agents respond to group influence as social actors. Our experiments reveal that AI agents exhibit a systematic conformity bias, aligned with Social Impact Theory, showing sensitivity to group size, unanimity, task difficulty, and source characteristics. Critically, AI agents achieving near-perfect performance in isolation become highly susceptible to manipulation through social influence. This vulnerability persists across model scales: while larger models show reduced conformity on simple tasks due to improved capabilities, they remain vulnerable when operating at their competence boundary. These findings reveal fundamental security vulnerabilities in AI agent decision-making that could enable malicious manipulation, misinformation campaigns, and bias propagation in multi-agent systems, highlighting the urgent need for safeguards in collective AI deployments.

</details>


### [10] [On the Effect of Cheating in Chess](https://arxiv.org/abs/2601.05386)
*Daniel Keren*

Main category: cs.AI

TL;DR: 评估国际象棋作弊的潜在收益：通过有限次数的作弊行为分析对局表现提升


<details>
  <summary>Details</summary>
Motivation: 国际象棋中使用强大软件建议的作弊已成为严重问题，甚至影响到最高级别比赛。与以往主要关注作弊检测的研究不同，本文旨在评估在比赛中有限次数作弊可能带来的表现提升。

Method: 开发算法并在常用国际象棋引擎上进行测试，分析有限次数作弊对游戏表现的影响。

Result: 通过算法测试量化了有限次数作弊在国际象棋中的潜在表现提升效果。

Conclusion: 研究目的不是协助作弊者，而是衡量作弊效果，这对于遏制和检测作弊至关重要。

Abstract: Cheating in chess, by using advice from powerful software, has become a major problem, reaching the highest levels. As opposed to the large majority of previous work, which concerned {\em detection} of cheating, here we try to evaluate the possible gain in performance, obtained by cheating a limited number of times during a game. Algorithms are developed and tested on a commonly used chess engine (i.e software).\footnote{Needless to say, the goal of this work is not to assist cheaters, but to measure the effectiveness of cheating -- which is crucial as part of the effort to contain and detect it.}

</details>


### [11] [ART: Adaptive Reasoning Trees for Explainable Claim Verification](https://arxiv.org/abs/2601.05455)
*Sahil Wadhwa,Himanshu Kumar,Guanqun Yang,Abbaas Alif Mohamed Nishar,Pranab Mohanty,Swapnil Shinde,Yue Wu*

Main category: cs.AI

TL;DR: ART提出了一种分层论证树方法，通过支持/攻击论证分支和LLM裁决的成对锦标赛机制，实现透明、可争议的声明验证，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: LLM在复杂决策中表现出色，但其不透明性阻碍了在高风险环境中的应用——输出缺乏忠实解释且无法有效争议错误，损害了可信度。

Method: ART（自适应推理树）是一种分层声明验证方法：从根声明开始，分支为支持和攻击的子论证；通过LLM裁判对子节点进行成对锦标赛，自底向上确定论证强度，系统推导最终透明且可争议的裁决。

Result: 在多个数据集上的实证验证表明，ART的结构化推理优于强基线，为可解释声明验证设立了新基准，更可靠且确保决策步骤清晰。

Conclusion: ART通过分层论证树和LLM裁决机制，解决了LLM决策的不透明问题，实现了透明、可争议的声明验证，为高风险环境中的可信AI决策提供了有效方案。

Abstract: Large Language Models (LLMs) are powerful candidates for complex decision-making, leveraging vast encoded knowledge and remarkable zero-shot abilities. However, their adoption in high-stakes environments is hindered by their opacity; their outputs lack faithful explanations and cannot be effectively contested to correct errors, undermining trustworthiness. In this paper, we propose ART (Adaptive Reasoning Trees), a hierarchical method for claim verification. The process begins with a root claim, which branches into supporting and attacking child arguments. An argument's strength is determined bottom-up via a pairwise tournament of its children, adjudicated by a judge LLM, allowing a final, transparent and contestable verdict to be systematically derived which is missing in methods like Chain-of-Thought (CoT). We empirically validate ART on multiple datasets, analyzing different argument generators and comparison strategies. Our findings show that ART's structured reasoning outperforms strong baselines, establishing a new benchmark for explainable claim verification which is more reliable and ensures clarity in the overall decision making step.

</details>


### [12] [PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering](https://arxiv.org/abs/2601.05465)
*Yu Liu,Wenxiao Zhang,Cong Cao,Wenxuan Lu,Fangfang Yuan,Diandian Guo,Kun Peng,Qiang Sun,Kaiyan Zhang,Yanbing Liu,Jin B. Hong,Bowen Zhou,Zhiyuan Ma*

Main category: cs.AI

TL;DR: PRISMA提出了一种解耦的RL引导框架，通过规划-检索-检查-解决-记忆架构解决RAG系统中的检索崩溃和学习不稳定问题，在十个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的端到端检索增强推理系统面临两个主要障碍：1) 检索崩溃 - 在大规模语料库上进行迭代检索时，缺乏推理引导的规划难以定位包含桥梁答案的中间证据；2) 学习不稳定 - 端到端轨迹训练存在推理链信用分配弱和模块间错误定位差的问题，导致过拟合基准特定启发式方法，限制了可迁移性和稳定性。

Method: 提出PRISMA框架，采用Plan-Retrieve-Inspect-Solve-Memoize架构。核心是推理引导的协作：检查器提供基于推理的反馈来优化规划器的分解和细粒度检索，同时在解决器中强制执行基于证据的推理。通过两阶段组相对策略优化（GRPO）优化个体代理能力：第一阶段校准规划器和解决器作为规划和推理的专家；第二阶段使用观察感知残差策略优化（OARPO）增强检查器验证上下文和触发针对性恢复的能力。

Result: PRISMA在十个基准测试中实现了最先进的性能，并且能够在现实场景中高效部署。

Conclusion: PRISMA通过解耦的RL引导框架和推理引导的协作机制，有效解决了检索增强生成系统中的检索崩溃和学习不稳定问题，为复杂开放域多跳问题的可靠部署提供了可行方案。

Abstract: Answering real-world open-domain multi-hop questions over massive corpora is a critical challenge in Retrieval-Augmented Generation (RAG) systems. Recent research employs reinforcement learning (RL) to end-to-end optimize the retrieval-augmented reasoning process, directly enhancing its capacity to resolve complex queries. However, reliable deployment is hindered by two obstacles. 1) Retrieval Collapse: iterative retrieval over large corpora fails to locate intermediate evidence containing bridge answers without reasoning-guided planning, causing downstream reasoning to collapse. 2) Learning Instability: end-to-end trajectory training suffers from weak credit assignment across reasoning chains and poor error localization across modules, causing overfitting to benchmark-specific heuristics that limit transferability and stability. To address these problems, we propose PRISMA, a decoupled RL-guided framework featuring a Plan-Retrieve-Inspect-Solve-Memoize architecture. PRISMA's strength lies in reasoning-guided collaboration: the Inspector provides reasoning-based feedback to refine the Planner's decomposition and fine-grained retrieval, while enforcing evidence-grounded reasoning in the Solver. We optimize individual agent capabilities via Two-Stage Group Relative Policy Optimization (GRPO). Stage I calibrates the Planner and Solver as specialized experts in planning and reasoning, while Stage II utilizes Observation-Aware Residual Policy Optimization (OARPO) to enhance the Inspector's ability to verify context and trigger targeted recovery. Experiments show that PRISMA achieves state-of-the-art performance on ten benchmarks and can be deployed efficiently in real-world scenarios.

</details>


### [13] [MMUEChange: A Generalized LLM Agent Framework for Intelligent Multi-Modal Urban Environment Change Analysis](https://arxiv.org/abs/2601.05483)
*Zixuan Xiao,Jun Ma,Siwei Zhang*

Main category: cs.AI

TL;DR: 提出MMUEChange多模态智能体框架，通过模块化工具包和模态控制器实现异构城市数据的灵活集成与对齐，显著提升城市变化检测任务成功率并减少幻觉


<details>
  <summary>Details</summary>
Motivation: 当前遥感变化检测方法依赖刚性的单模态分析，难以处理复杂的城市环境变化场景，需要更灵活的多模态集成方法来支持可持续城市发展

Method: 提出MMUEChange多模态智能体框架，包含模块化工具包和核心模块模态控制器，实现跨模态和模态内对齐，能够灵活整合异构城市数据

Result: 相比最佳基线方法，MMUEChange智能体在任务成功率上提升46.7%，有效缓解幻觉问题，并在纽约、香港、深圳的案例研究中展示了实际政策意义

Conclusion: MMUEChange框架能够有效支持复杂的城市变化分析任务，为城市可持续发展提供具有实际政策意义的洞察

Abstract: Understanding urban environment change is essential for sustainable development. However, current approaches, particularly remote sensing change detection, often rely on rigid, single-modal analysis. To overcome these limitations, we propose MMUEChange, a multi-modal agent framework that flexibly integrates heterogeneous urban data via a modular toolkit and a core module, Modality Controller for cross- and intra-modal alignment, enabling robust analysis of complex urban change scenarios. Case studies include: a shift toward small, community-focused parks in New York, reflecting local green space efforts; the spread of concentrated water pollution across districts in Hong Kong, pointing to coordinated water management; and a notable decline in open dumpsites in Shenzhen, with contrasting links between nighttime economic activity and waste types, indicating differing urban pressures behind domestic and construction waste. Compared to the best-performing baseline, the MMUEChange agent achieves a 46.7% improvement in task success rate and effectively mitigates hallucination, demonstrating its capacity to support complex urban change analysis tasks with real-world policy implications.

</details>


### [14] [The Evaluation Gap in Medicine, AI and LLMs: Navigating Elusive Ground Truth & Uncertainty via a Probabilistic Paradigm](https://arxiv.org/abs/2601.05500)
*Aparna Elangovan,Lei Xu,Mahsa Elyasi,Ismail Akdulum,Mehmet Aksakal,Enes Gurun,Brian Hur,Saab Mansour,Ravid Shwartz Ziv,Karin Verspoor,Dan Roth*

Main category: cs.AI

TL;DR: 论文提出概率评估范式，强调医学AI基准测试中必须考虑专家标注的不确定性，否则会误导性地认为非专家与专家表现相似。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统（如大语言模型和视觉模型）的基准测试通常忽略专家标注答案中的不确定性，这在医学领域尤其成问题，因为医学中不确定性普遍存在。忽略这种不确定性可能导致错误结论，认为非专家与专家表现相似。

Method: 提出概率评估范式，引入期望准确率和期望F1分数概念，用于估计在给定标注答案变异性的情况下，专家人类或系统能达到的分数。建议根据标注答案概率（通常通过专家间一致率衡量）对结果进行分层评估。

Result: 理论分析表明，在标注答案高度不确定的数据集中，随机标注者与专家之间可能几乎没有差异。分层评估在整体性能低于80%阈值时变得关键，在高确定性分组中性能比较更加可靠。

Conclusion: 评估AI系统能力时应考虑标注答案的不确定性，采用分层评估方法，特别是在整体性能较低时，以减少不确定性这一关键混杂因素的影响，获得更可靠的性能比较结果。

Abstract: Benchmarking the relative capabilities of AI systems, including Large Language Models (LLMs) and Vision Models, typically ignores the impact of uncertainty in the underlying ground truth answers from experts. This ambiguity is particularly consequential in medicine where uncertainty is pervasive. In this paper, we introduce a probabilistic paradigm to theoretically explain how high certainty in ground truth answers is almost always necessary for even an expert to achieve high scores, whereas in datasets with high variation in ground truth answers there may be little difference between a random labeller and an expert. Therefore, ignoring uncertainty in ground truth evaluation data can result in the misleading conclusion that a non-expert has similar performance to that of an expert. Using the probabilistic paradigm, we thus bring forth the concepts of expected accuracy and expected F1 to estimate the score an expert human or system can achieve given ground truth answer variability.
  Our work leads to the recommendation that when establishing the capability of a system, results should be stratified by probability of the ground truth answer, typically measured by the agreement rate of ground truth experts. Stratification becomes critical when the overall performance drops below a threshold of 80%. Under stratified evaluation, performance comparison becomes more reliable in high certainty bins, mitigating the effect of the key confounding factor -- uncertainty.

</details>


### [15] [Explainable AI: Learning from the Learners](https://arxiv.org/abs/2601.05525)
*Ricardo Vinuesa,Steven L. Brunton,Gianmarco Mengaldo*

Main category: cs.AI

TL;DR: XAI与因果推理结合，可从AI模型中提取因果机制，指导稳健设计与控制，支持高风险应用中的信任与问责


<details>
  <summary>Details</summary>
Motivation: 尽管AI在许多科学和工程任务中已超越人类，但其内部表示通常不透明，需要可解释AI来促进人机协作

Method: 结合可解释AI与因果推理，利用基础模型和可解释性方法，从AI模型中学习因果机制

Result: XAI能够提取因果机制、指导稳健设计与控制、支持高风险应用中的信任与问责，为科学工程中的人机协作提供统一框架

Conclusion: XAI与因果推理结合可实现"向学习者学习"，但面临解释的忠实性、泛化性和可用性等挑战，是科学工程中人机协作的关键框架

Abstract: Artificial intelligence now outperforms humans in several scientific and engineering tasks, yet its internal representations often remain opaque. In this Perspective, we argue that explainable artificial intelligence (XAI), combined with causal reasoning, enables {\it learning from the learners}. Focusing on discovery, optimization and certification, we show how the combination of foundation models and explainability methods allows the extraction of causal mechanisms, guides robust design and control, and supports trust and accountability in high-stakes applications. We discuss challenges in faithfulness, generalization and usability of explanations, and propose XAI as a unifying framework for human-AI collaboration in science and engineering.

</details>


### [16] [Safety Not Found (404): Hidden Risks of LLM-Based Robotics Decision Making](https://arxiv.org/abs/2601.05529)
*Jua Han,Jaeyoon Seo,Jungbin Min,Jean Oh,Jihie Kim*

Main category: cs.AI

TL;DR: 论文通过火灾疏散场景评估LLM在安全关键系统中的决策能力，发现即使99%准确率也不足以保证安全，当前LLM不适合直接部署到安全关键系统。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在机器人决策中日益重要，其物理风险也随之增加——单个错误指令可能直接危及人类安全。迫切需要系统评估LLM在错误即灾难的场景中的性能。

Method: 通过火灾疏散场景的定性评估识别关键失败案例，设计七项定量评估任务：完整信息任务（使用ASCII地图）、不完整信息任务（需要推断缺失上下文）、安全导向空间推理任务（SOSR）。对多种LLM和VLM进行基准测试。

Result: 发现严重漏洞：多个模型在ASCII导航中成功率为0%；模拟火灾演习中，模型指示机器人向危险区域而非紧急出口移动。99%准确率在机器人领域具有误导性，意味着每百次执行可能造成灾难性伤害。

Conclusion: 当前LLM尚未准备好直接部署到安全关键系统，即使最先进模型也无法保证安全，绝对依赖它们会带来不可接受的风险。

Abstract: One mistake by an AI system in a safety-critical setting can cost lives. As Large Language Models (LLMs) become integral to robotics decision-making, the physical dimension of risk grows; a single wrong instruction can directly endanger human safety. This paper addresses the urgent need to systematically evaluate LLM performance in scenarios where even minor errors are catastrophic. Through a qualitative evaluation of a fire evacuation scenario, we identified critical failure cases in LLM-based decision-making. Based on these, we designed seven tasks for quantitative assessment, categorized into: Complete Information, Incomplete Information, and Safety-Oriented Spatial Reasoning (SOSR). Complete information tasks utilize ASCII maps to minimize interpretation ambiguity and isolate spatial reasoning from visual processing. Incomplete information tasks require models to infer missing context, testing for spatial continuity versus hallucinations. SOSR tasks use natural language to evaluate safe decision-making in life-threatening contexts. We benchmark various LLMs and Vision-Language Models (VLMs) across these tasks. Beyond aggregate performance, we analyze the implications of a 1% failure rate, highlighting how "rare" errors escalate into catastrophic outcomes. Results reveal serious vulnerabilities: several models achieved a 0% success rate in ASCII navigation, while in a simulated fire drill, models instructed robots to move toward hazardous areas instead of emergency exits. Our findings lead to a sobering conclusion: current LLMs are not ready for direct deployment in safety-critical systems. A 99% accuracy rate is dangerously misleading in robotics, as it implies one out of every hundred executions could result in catastrophic harm. We demonstrate that even state-of-the-art models cannot guarantee safety, and absolute reliance on them creates unacceptable risks.

</details>


### [17] [WildSci: Advancing Scientific Reasoning from In-the-Wild Literature](https://arxiv.org/abs/2601.05567)
*Tengxiao Liu,Deepak Nathani,Zekun Li,Kevin Yang,William Yang Wang*

Main category: cs.AI

TL;DR: WildSci是一个从同行评审文献自动合成的领域特定科学问题数据集，涵盖9个科学学科和26个子领域，通过将复杂科学推理任务转化为多项选择题格式，支持可扩展的强化学习训练。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型推理在数学和编程领域进展显著，但在医学、材料科学等科学领域进展有限，主要原因是数据集覆盖不足和开放科学问题的复杂性。

Method: 从同行评审文献自动合成领域特定科学问题，构建WildSci数据集；将复杂科学推理任务转化为多项选择题格式；应用强化学习对模型进行微调，并分析训练动态。

Result: 在一系列科学基准测试上的实验证明了数据集和方法的有效性，WildSci支持可扩展的科学推理研究。

Conclusion: WildSci数据集解决了科学领域LLM推理的数据稀缺问题，通过多项选择题格式和强化学习方法，为可持续的科学推理研究提供了可扩展的解决方案。

Abstract: Recent progress in large language model (LLM) reasoning has focused on domains like mathematics and coding, where abundant high-quality data and objective evaluation metrics are readily available. In contrast, progress in LLM reasoning models remains limited in scientific domains such as medicine and materials science due to limited dataset coverage and the inherent complexity of open-ended scientific questions. To address these challenges, we introduce WildSci, a new dataset of domain-specific science questions automatically synthesized from peer-reviewed literature, covering 9 scientific disciplines and 26 subdomains. By framing complex scientific reasoning tasks in a multiple-choice format, we enable scalable training with well-defined reward signals. We further apply reinforcement learning to finetune models on these data and analyze the resulting training dynamics, including domain-specific performance changes, response behaviors, and generalization trends. Experiments on a suite of scientific benchmarks demonstrate the effectiveness of our dataset and approach. We release WildSci to enable scalable and sustainable research in scientific reasoning, available at https://huggingface.co/datasets/JustinTX/WildSci.

</details>


### [18] [Crisis-Bench: Benchmarking Strategic Ambiguity and Reputation Management in Large Language Models](https://arxiv.org/abs/2601.05570)
*Cooper Lin,Maohao Ran,Yanting Zhang,Zhenglin Wan,Hongwei Fan,Yibo Xu,Yike Guo,Wei Xue,Jun Song*

Main category: cs.AI

TL;DR: 论文提出了Crisis-Bench基准，用于评估LLM在需要战略模糊和信息保留的专业领域（如危机公关）中的表现，揭示了通用安全对齐与专业实用性之间的冲突。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的安全对齐过于强调普遍的帮助性和诚实性，形成了僵化的"童子军"道德观。这种一刀切的伦理框架对需要战略模糊和信息保留的专业领域（如公共关系、谈判、危机管理）造成了"透明度税"，限制了LLM在这些领域的实用性。

Method: 提出了Crisis-Bench基准，这是一个多智能体部分可观察马尔可夫决策过程（POMDP），包含80个不同故事情节，覆盖8个行业。系统模拟7天的企业危机，LLM扮演公关代理，管理严格分离的私人和公共叙事状态以强制执行信息不对称。引入了"仲裁者-市场循环"评估指标，将公众情绪转化为模拟股价，创建现实的经济激励结构。

Result: 研究结果揭示了关键的两分法：一些模型因伦理顾虑而妥协，而另一些模型则表现出马基雅维利式的、合法的战略保留能力，以稳定模拟股价。Crisis-Bench首次为评估"声誉管理"能力提供了量化框架。

Conclusion: 论文主张从僵化的道德绝对主义转向情境感知的专业对齐，为需要战略模糊的专业领域开发更灵活的LLM对齐方法。

Abstract: Standard safety alignment optimizes Large Language Models (LLMs) for universal helpfulness and honesty, effectively instilling a rigid "Boy Scout" morality. While robust for general-purpose assistants, this one-size-fits-all ethical framework imposes a "transparency tax" on professional domains requiring strategic ambiguity and information withholding, such as public relations, negotiation, and crisis management. To measure this gap between general safety and professional utility, we introduce Crisis-Bench, a multi-agent Partially Observable Markov Decision Process (POMDP) that evaluates LLMs in high-stakes corporate crises. Spanning 80 diverse storylines across 8 industries, Crisis-Bench tasks an LLM-based Public Relations (PR) Agent with navigating a dynamic 7-day corporate crisis simulation while managing strictly separated Private and Public narrative states to enforce rigorous information asymmetry. Unlike traditional benchmarks that rely on static ground truths, we introduce the Adjudicator-Market Loop: a novel evaluation metric where public sentiment is adjudicated and translated into a simulated stock price, creating a realistic economic incentive structure. Our results expose a critical dichotomy: while some models capitulate to ethical concerns, others demonstrate the capacity for Machiavellian, legitimate strategic withholding in order to stabilize the simulated stock price. Crisis-Bench provides the first quantitative framework for assessing "Reputation Management" capabilities, arguing for a shift from rigid moral absolutism to context-aware professional alignment.

</details>


### [19] [Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection](https://arxiv.org/abs/2601.05578)
*Cooper Lin,Yanting Zhang,Maohao Ran,Wei Xue,Hongwei Fan,Yibo Xu,Zhenglin Wan,Sirui Han,Yike Guo,Jun Song*

Main category: cs.AI

TL;DR: 本文提出了一种使用强化学习对轻量级语言模型进行后训练的方法，专门用于电子商务欺诈检测任务，仅使用原始交易数据，在真实数据集上取得了显著的F1分数提升。


<details>
  <summary>Details</summary>
Motivation: 电子商务平台和支付解决方案提供商面临日益复杂的欺诈方案，但尽管大型语言模型在理论上具有潜力，其在真实金融场景中的欺诈检测应用尚未充分探索，处理特定领域电子商务交易数据的实际效果也缺乏实证验证。

Method: 提出一种新颖方法，使用强化学习对轻量级语言模型进行后训练，专门用于欺诈检测任务。采用Group Sequence Policy Optimization (GSPO)算法结合基于规则的奖励系统，在真实交易数据集上微调不同规模的语言模型。

Result: 实验结果表明该方法有效，后训练的语言模型在保留测试数据上取得了显著的F1分数提升。性能改进主要归因于强化学习固有的探索机制，使模型能够发现超越传统工程特征的新型欺诈指标。

Conclusion: 通过强化学习框架，语言模型能够探索文本交易数据中嵌入的多样化信任和风险信号，包括客户信息、配送详情、产品描述和订单历史中的模式，为电子商务欺诈检测提供了新的有效方法。

Abstract: E-commerce platforms and payment solution providers face increasingly sophisticated fraud schemes, ranging from identity theft and account takeovers to complex money laundering operations that exploit the speed and anonymity of digital transactions. However, despite their theoretical promise, the application of Large Language Models (LLMs) to fraud detection in real-world financial contexts remains largely unexploited, and their practical effectiveness in handling domain-specific e-commerce transaction data has yet to be empirically validated. To bridge this gap between conventional machine learning limitations and the untapped potential of LLMs in fraud detection, this paper proposes a novel approach that employs Reinforcement Learning (RL) to post-train lightweight language models specifically for fraud detection tasks using only raw transaction data. We utilize the Group Sequence Policy Optimization (GSPO) algorithm combined with a rule-based reward system to fine-tune language models of various sizes on a real-life transaction dataset provided by a Chinese global payment solution company. Through this reinforcement learning framework, the language models are encouraged to explore diverse trust and risk signals embedded within the textual transaction data, including patterns in customer information, shipping details, product descriptions, and order history. Our experimental results demonstrate the effectiveness of this approach, with post-trained language models achieving substantial F1-score improvements on held-out test data. Our findings demonstrate that the observed performance improvements are primarily attributable to the exploration mechanism inherent in reinforcement learning, which allows models to discover novel fraud indicators beyond those captured by traditional engineered features.

</details>


### [20] [A Causal Information-Flow Framework for Unbiased Learning-to-Rank](https://arxiv.org/abs/2601.05590)
*Haoming Gong,Qingyao Ai,Zhihao Tao,Yongfeng Zhang*

Main category: cs.AI

TL;DR: 提出基于因果学习的新型排序框架，结合结构因果模型和信息论工具，通过偏置泄漏度量来减少点击数据中的多种偏置，提高排序性能。


<details>
  <summary>Details</summary>
Motivation: 点击数据存在多种偏置（位置偏置、选择偏置、信任偏置），现有无偏学习排序方法主要只校正位置偏置，无法测量剩余偏置、提供风险保证或联合处理多个偏置源。

Method: 结合结构因果模型（SCMs）和信息论工具，使用条件互信息度量偏置泄漏，将其作为正则化项加入模型训练；同时采用双重稳健估计器进行更可靠的风险估计。

Result: 在标准学习排序基准测试中，该方法持续减少测量的偏置泄漏，并提高排序性能，特别是在位置偏置和信任偏置等多种偏置强烈交互的现实场景中。

Conclusion: 提出的因果学习框架能有效处理点击数据中的多种偏置，通过偏置泄漏度量和双重稳健估计器，实现了更好的无偏排序学习。

Abstract: In web search and recommendation systems, user clicks are widely used to train ranking models. However, click data is heavily biased, i.e., users tend to click higher-ranked items (position bias), choose only what was shown to them (selection bias), and trust top results more (trust bias). Without explicitly modeling these biases, the true relevance of ranked items cannot be correctly learned from clicks. Existing Unbiased Learning-to-Rank (ULTR) methods mainly correct position bias and rely on propensity estimation, but they cannot measure remaining bias, provide risk guarantees, or jointly handle multiple bias sources. To overcome these challenges, this paper introduces a novel causal learning-based ranking framework that extends ULTR by combining Structural Causal Models (SCMs) with information-theoretic tools. SCMs specify how clicks are generated and help identify the true relevance signal from click data, while conditional mutual information, measures how much bias leaks into the
  learned relevance estimates. We use this leakage measure to define a rigorous notion of disentanglement and include it as a regularizer during model training to reduce bias. In addition, we incorporate a causal inference estimator, i.e., doubly robust estimator, to ensure more reliable risk estimation. Experiments on standard Learning-to-Rank benchmarks show that our method consistently reduces measured bias leakage and improves ranking performance, especially in realistic scenarios where multiple biases-such as position and trust bias-interact strongly.

</details>


### [21] [Cumulative Path-Level Semantic Reasoning for Inductive Knowledge Graph Completion](https://arxiv.org/abs/2601.05629)
*Jiapu Wang,Xinghe Cheng,Zezheng Wu,Ruiqi Ma,Rui Wang,Zhichao Yan,Haoran Luo,Yuhao Jiang,Kai Sun*

Main category: cs.AI

TL;DR: CPSR框架通过查询依赖掩码模块和全局语义评分模块，在归纳知识图谱补全任务中同时捕捉结构信息和语义信息，取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统知识图谱补全方法在处理新兴实体时效果不佳，而现有归纳KGC方法存在对噪声结构信息敏感和难以捕捉推理路径中长距离依赖的问题。

Method: 提出CPSR框架：1) 查询依赖掩码模块自适应地屏蔽噪声结构信息，保留与目标密切相关的信息；2) 全局语义评分模块评估推理路径中节点的个体贡献和集体影响。

Result: 实验结果表明CPSR实现了最先进的性能。

Conclusion: CPSR通过同时捕捉知识图谱的结构和语义信息，有效解决了归纳知识图谱补全中的噪声敏感和长距离依赖问题。

Abstract: Conventional Knowledge Graph Completion (KGC) methods aim to infer missing information in incomplete Knowledge Graphs (KGs) by leveraging existing information, which struggle to perform effectively in scenarios involving emerging entities. Inductive KGC methods can handle the emerging entities and relations in KGs, offering greater dynamic adaptability. While existing inductive KGC methods have achieved some success, they also face challenges, such as susceptibility to noisy structural information during reasoning and difficulty in capturing long-range dependencies in reasoning paths. To address these challenges, this paper proposes the Cumulative Path-Level Semantic Reasoning for inductive knowledge graph completion (CPSR) framework, which simultaneously captures both the structural and semantic information of KGs to enhance the inductive KGC task. Specifically, the proposed CPSR employs a query-dependent masking module to adaptively mask noisy structural information while retaining important information closely related to the targets. Additionally, CPSR introduces a global semantic scoring module that evaluates both the individual contributions and the collective impact of nodes along the reasoning path within KGs. The experimental results demonstrate that CPSR achieves state-of-the-art performance.

</details>


### [22] [HAG: Hierarchical Demographic Tree-based Agent Generation for Topic-Adaptive Simulation](https://arxiv.org/abs/2601.05656)
*Rongxin Chen,Tianyu Wu,Bingbing Xu,Xiucheng Xu,Huawei Shen*

Main category: cs.AI

TL;DR: HAG框架通过两阶段决策过程实现高质量智能体初始化，结合宏观分布对齐与微观一致性，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有智能体初始化方法存在局限性：基于静态数据检索的方法无法适应未见主题，而基于LLM生成的方法缺乏宏观分布意识，导致微观属性与现实不一致

Method: 提出HAG分层智能体生成框架，将群体生成形式化为两阶段决策过程：1)使用世界知识模型推断分层条件概率构建主题自适应树实现宏观分布对齐；2)基于真实世界数据进行实例化和智能体增强确保微观一致性

Result: HAG显著优于代表性基线方法，平均减少群体对齐误差37.7%，提升社会学一致性18.8%

Conclusion: HAG框架通过分层方法有效解决了智能体初始化中的宏观分布对齐和微观一致性问题，为基于智能体的建模提供了高质量的人口生成解决方案

Abstract: High-fidelity agent initialization is crucial for credible Agent-Based Modeling across diverse domains. A robust framework should be Topic-Adaptive, capturing macro-level joint distributions while ensuring micro-level individual rationality. Existing approaches fall into two categories: static data-based retrieval methods that fail to adapt to unseen topics absent from the data, and LLM-based generation methods that lack macro-level distribution awareness, resulting in inconsistencies between micro-level persona attributes and reality. To address these problems, we propose HAG, a Hierarchical Agent Generation framework that formalizes population generation as a two-stage decision process. Firstly, utilizing a World Knowledge Model to infer hierarchical conditional probabilities to construct the Topic-Adaptive Tree, achieving macro-level distribution alignment. Then, grounded real-world data, instantiation and agentic augmentation are carried out to ensure micro-level consistency. Given the lack of specialized evaluation, we establish a multi-domain benchmark and a comprehensive PACE evaluation framework. Extensive experiments show that HAG significantly outperforms representative baselines, reducing population alignment errors by an average of 37.7% and enhancing sociological consistency by 18.8%.

</details>


### [23] [CHDP: Cooperative Hybrid Diffusion Policies for Reinforcement Learning in Parameterized Action Space](https://arxiv.org/abs/2601.05675)
*Bingyi Liu,Jinbo He,Haiyong Shi,Enshu Wang,Weizhen Han,Jingxiang Hao,Peixi Wang,Zhuangzhuang Zhang*

Main category: cs.AI

TL;DR: CHDP框架通过协同扩散策略解决混合离散-连续动作空间的建模与优化挑战，在基准测试中性能提升达19.3%


<details>
  <summary>Details</summary>
Motivation: 混合动作空间（结合离散选择和连续参数）在机器人控制和游戏AI中很常见，但现有方法存在策略表达能力有限和高维可扩展性差的问题

Method: 将混合动作空间问题视为完全合作游戏，提出协同混合扩散策略框架：使用离散和连续两个扩散策略，连续策略以离散动作表示为条件；采用顺序更新方案避免冲突；构建代码本将高维离散动作嵌入低维潜空间；设计基于Q函数的引导机制对齐表示

Result: 在具有挑战性的混合动作基准测试中，CHDP比最先进方法的成功率提高了19.3%

Conclusion: CHDP框架通过协同扩散策略有效解决了混合动作空间的建模挑战，在表达能力和可扩展性方面表现出色

Abstract: Hybrid action space, which combines discrete choices and continuous parameters, is prevalent in domains such as robot control and game AI. However, efficiently modeling and optimizing hybrid discrete-continuous action space remains a fundamental challenge, mainly due to limited policy expressiveness and poor scalability in high-dimensional settings. To address this challenge, we view the hybrid action space problem as a fully cooperative game and propose a \textbf{Cooperative Hybrid Diffusion Policies (CHDP)} framework to solve it. CHDP employs two cooperative agents that leverage a discrete and a continuous diffusion policy, respectively. The continuous policy is conditioned on the discrete action's representation, explicitly modeling the dependency between them. This cooperative design allows the diffusion policies to leverage their expressiveness to capture complex distributions in their respective action spaces. To mitigate the update conflicts arising from simultaneous policy updates in this cooperative setting, we employ a sequential update scheme that fosters co-adaptation. Moreover, to improve scalability when learning in high-dimensional discrete action space, we construct a codebook that embeds the action space into a low-dimensional latent space. This mapping enables the discrete policy to learn in a compact, structured space. Finally, we design a Q-function-based guidance mechanism to align the codebook's embeddings with the discrete policy's representation during training. On challenging hybrid action benchmarks, CHDP outperforms the state-of-the-art method by up to $19.3\%$ in success rate.

</details>


### [24] [Circular Reasoning: Understanding Self-Reinforcing Loops in Large Reasoning Models](https://arxiv.org/abs/2601.05693)
*Zenghao Duan,Liang Pang,Zihao Wei,Wenbin Duan,Yuxin Tian,Shicheng Xu,Jingcheng Deng,Zhiyi Yin,Xueqi Cheng*

Main category: cs.AI

TL;DR: 论文提出"循环推理"这一新失效模式，开发LoopBench数据集进行分析，发现其机制为状态崩溃和V型注意力机制，并提出使用CUSUM算法进行早期预测


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在测试时扩展中经常遇到重复循环，导致计算浪费和推理失败。传统模型退化理论无法解释这种自我强化的循环现象

Method: 1. 提出"循环推理"概念并开发LoopBench数据集（包含数值循环和语句循环）；2. 从机制上分析循环推理为状态崩溃；3. 使用累积和算法捕捉循环前兆进行早期预测

Result: 实验验证了CUSUM算法的准确性，阐明了长链推理的稳定性，揭示了推理障碍触发循环开始，随后由自我强化的V型注意力机制维持

Conclusion: 循环推理是大型推理模型特有的失效模式，通过早期检测机制可以有效预测和避免，为提升模型推理稳定性提供了新视角

Abstract: Despite the success of test-time scaling, Large Reasoning Models (LRMs) frequently encounter repetitive loops that lead to computational waste and inference failure. In this paper, we identify a distinct failure mode termed Circular Reasoning. Unlike traditional model degeneration, this phenomenon manifests as a self-reinforcing trap where generated content acts as a logical premise for its own recurrence, compelling the reiteration of preceding text. To systematically analyze this phenomenon, we introduce LoopBench, a dataset designed to capture two distinct loop typologies: numerical loops and statement loops. Mechanistically, we characterize circular reasoning as a state collapse exhibiting distinct boundaries, where semantic repetition precedes textual repetition. We reveal that reasoning impasses trigger the loop onset, which subsequently persists as an inescapable cycle driven by a self-reinforcing V-shaped attention mechanism. Guided by these findings, we employ the Cumulative Sum (CUSUM) algorithm to capture these precursors for early loop prediction. Experiments across diverse LRMs validate its accuracy and elucidate the stability of long-chain reasoning.

</details>


### [25] [Logic-Parametric Neuro-Symbolic NLI: Controlling Logical Formalisms for Verifiable LLM Reasoning](https://arxiv.org/abs/2601.05705)
*Ali Farjami,Luca Redondi,Marco Valentino*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) and theorem provers (TPs) can be effectively combined for verifiable natural language inference (NLI). However, existing approaches rely on a fixed logical formalism, a feature that limits robustness and adaptability. We propose a logic-parametric framework for neuro-symbolic NLI that treats the underlying logic not as a static background, but as a controllable component. Using the LogiKEy methodology, we embed a range of classical and non-classical formalisms into higher-order logic (HOL), enabling a systematic comparison of inference quality, explanation refinement, and proof behavior. We focus on normative reasoning, where the choice of logic has significant implications. In particular, we compare logic-external approaches, where normative requirements are encoded via axioms, with logic-internal approaches, where normative patterns emerge from the logic's built-in structure. Extensive experiments demonstrate that logic-internal strategies can consistently improve performance and produce more efficient hybrid proofs for NLI. In addition, we show that the effectiveness of a logic is domain-dependent, with first-order logic favouring commonsense reasoning, while deontic and modal logics excel in ethical domains. Our results highlight the value of making logic a first-class, parametric element in neuro-symbolic architectures for more robust, modular, and adaptable reasoning.

</details>


### [26] [Overcoming Joint Intractability with Lossless Hierarchical Speculative Decoding](https://arxiv.org/abs/2601.05724)
*Yuxuan Zhou,Fei Huang,Heng Li,Fengyi Wu,Tianyu Wang,Jianwei Zhang,Junyang Lin,Zhi-Qi Cheng*

Main category: cs.AI

TL;DR: HSD是一种分层推测解码方法，通过平衡可访问分支间的概率质量，提供可证明无损的验证，显著提高接受令牌数量，在EAGLE-3上实现超过12%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码中的验证方法存在局限性：序列级验证虽然比令牌级验证接受更多令牌，但通常依赖代理近似或受限于部分信息，难以处理联合不可行性问题。

Method: 提出分层推测解码（HSD），通过平衡可访问分支间的过量概率质量和不足概率质量，克服联合不可行性，实现可证明无损的验证。

Result: HSD在不同模型家族和基准测试中均带来一致的接受率提升，集成到EAGLE-3中实现超过12%的性能增益，在不损害分布保真度的情况下达到最先进的解码效率。

Conclusion: HSD是一种强大、可解释且通用的验证方法，可轻松集成到各种推测解码框架中，显著提升解码效率同时保持分布保真度。

Abstract: Verification is a key bottleneck in improving inference speed while maintaining distribution fidelity in Speculative Decoding. Recent work has shown that sequence-level verification leads to a higher number of accepted tokens compared to token-wise verification. However, existing solutions often rely on surrogate approximations or are constrained by partial information, struggling with joint intractability. In this work, we propose Hierarchical Speculative Decoding (HSD), a provably lossless verification method that significantly boosts the expected number of accepted tokens and overcomes joint intractability by balancing excess and deficient probability mass across accessible branches. Our extensive large-scale experiments demonstrate that HSD yields consistent improvements in acceptance rates across diverse model families and benchmarks. Moreover, its strong explainability and generality make it readily integrable into a wide range of speculative decoding frameworks. Notably, integrating HSD into EAGLE-3 yields over a 12% performance gain, establishing state-of-the-art decoding efficiency without compromising distribution fidelity. Code is available at https://github.com/ZhouYuxuanYX/Hierarchical-Speculative-Decoding.

</details>


### [27] [PII-VisBench: Evaluating Personally Identifiable Information Safety in Vision Language Models Along a Continuum of Visibility](https://arxiv.org/abs/2601.05739)
*G M Shahariar,Zabir Al Nazi,Md Olid Hasan Bhuiyan,Zhouxing Shi*

Main category: cs.AI

TL;DR: PII-VisBench：评估视觉语言模型隐私泄露的新基准，关注个人在线存在程度对隐私对齐的影响，发现模型对高可见度主体更易泄露PII信息。


<details>
  <summary>Details</summary>
Motivation: 现有VLM隐私评估将隐私视为静态提取任务，忽略了个人在线存在程度（数据可获取量）对隐私对齐的影响。需要更全面的评估框架来理解VLM在不同可见度主体上的隐私保护表现。

Method: 创建PII-VisBench基准，包含4000个独特探针，将200个主体按在线信息可获取程度分为高、中、低、零四个可见度类别。评估18个开源VLM（0.3B-32B），使用拒绝率和条件PII泄露率两个关键指标。

Result: 模型表现出一致模式：随着主体可见度降低，拒绝率增加，PII泄露率减少（从高可见度的9.10%降至低可见度的5.34%）。模型更倾向于泄露高可见度主体的PII，存在显著的模型家族异质性和PII类型差异。改写和越狱式提示暴露了攻击和模型依赖的失败。

Conclusion: 需要基于可见度的安全评估和训练干预，因为当前VLM的隐私保护表现与主体在线存在程度密切相关，存在系统性偏差，需要更细粒度的隐私对齐方法。

Abstract: Vision Language Models (VLMs) are increasingly integrated into privacy-critical domains, yet existing evaluations of personally identifiable information (PII) leakage largely treat privacy as a static extraction task and ignore how a subject's online presence--the volume of their data available online--influences privacy alignment. We introduce PII-VisBench, a novel benchmark containing 4000 unique probes designed to evaluate VLM safety through the continuum of online presence. The benchmark stratifies 200 subjects into four visibility categories: high, medium, low, and zero--based on the extent and nature of their information available online. We evaluate 18 open-source VLMs (0.3B-32B) based on two key metrics: percentage of PII probing queries refused (Refusal Rate) and the fraction of non-refusal responses flagged for containing PII (Conditional PII Disclosure Rate). Across models, we observe a consistent pattern: refusals increase and PII disclosures decrease (9.10% high to 5.34% low) as subject visibility drops. We identify that models are more likely to disclose PII for high-visibility subjects, alongside substantial model-family heterogeneity and PII-type disparities. Finally, paraphrasing and jailbreak-style prompts expose attack and model-dependent failures, motivating visibility-aware safety evaluation and training interventions.

</details>


### [28] [DynaDebate: Breaking Homogeneity in Multi-Agent Debate with Dynamic Path Generation](https://arxiv.org/abs/2601.05746)
*Zhenghao Li,Zhi Zheng,Wei Chen,Jielun Zhao,Yong Chen,Tong Xu,Enhong Chen*

Main category: cs.AI

TL;DR: DynaDebate 提出动态多智能体辩论框架，通过路径生成、过程中心辩论和触发验证机制解决现有方法中智能体推理路径同质化、辩论退化为简单多数投票的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的多智能体辩论框架存在局限性：智能体通常采用相同的初始化推理路径，导致犯相同错误；辩论过程往往退化为简单的多数投票，缺乏真正的逻辑交锋。

Method: 提出 DynaDebate 框架，包含三个核心机制：1) 动态路径生成与分配：使用专门的路径生成智能体创建多样化、逻辑化的解决方案路径；2) 过程中心辩论：关注逐步逻辑批判而非表面结果投票；3) 触发式验证智能体：在出现分歧时激活，使用外部工具客观解决僵局。

Result: 在多个基准测试中，DynaDebate 表现出优越性能，超越了现有的最先进多智能体辩论方法。

Conclusion: DynaDebate 通过动态路径生成、过程中心辩论和触发验证机制，有效提升了多智能体辩论的效果，解决了现有方法的同质化推理和辩论退化问题。

Abstract: Recent years have witnessed the rapid development of Large Language Model-based Multi-Agent Systems (MAS), which excel at collaborative decision-making and complex problem-solving. Recently, researchers have further investigated Multi-Agent Debate (MAD) frameworks, which enhance the reasoning and collaboration capabilities of MAS through information exchange and debate among multiple agents. However, existing approaches often rely on unguided initialization, causing agents to adopt identical reasoning paths that lead to the same errors. As a result, effective debate among agents is hindered, and the final outcome frequently degenerates into simple majority voting. To solve the above problem, in this paper, we introduce Dynamic Multi-Agent Debate (DynaDebate), which enhances the effectiveness of multi-agent debate through three key mechanisms: (1) Dynamic Path Generation and Allocation, which employs a dedicated Path Generation Agent to generate diverse and logical solution paths with adaptive redundancy; (2) Process-Centric Debate, which shifts the focus from surface-level outcome voting to rigorous step-by-step logic critique to ensure process correctness; (3) A Trigger-Based Verification Agent, which is activated upon disagreement and uses external tools to objectively resolve deadlocks. Extensive experiments demonstrate that DynaDebate achieves superior performance across various benchmarks, surpassing existing state-of-the-art MAD methods.

</details>


### [29] [From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation](https://arxiv.org/abs/2601.05787)
*Zezhou Wang,Ziyun Zhang,Xiaoyi Zhang,Zhuzhong Qian,Yan Lu*

Main category: cs.AI

TL;DR: BEPA方法通过双层专家轨迹对齐，将静态专家轨迹转化为策略对齐的指导，显著提升了端到端GUI操作策略在OSWorld等基准上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前GUI数据集规模有限，专家轨迹收集困难，而简单的专家轨迹与强化学习策略混合存在结构不匹配和分布偏移问题，需要更好的方法来利用有限专家数据训练端到端策略。

Method: 提出BEPA（双层专家到策略同化）方法：第一层通过基础策略生成自滚动可达轨迹来对齐专家轨迹；第二层使用动态更新的缓存来支持RLVR训练。

Result: 在OSWorld-Verified基准上，BEPA将UITARS1.5-7B的成功率从22.87%提升到32.13%，在保留测试集上从5.74%提升到10.30%，在MMBench-GUI和Online-Mind2Web上也有一致提升。

Conclusion: BEPA方法有效解决了专家轨迹与策略训练之间的对齐问题，显著提升了端到端GUI操作策略的性能，为利用有限专家数据训练视觉语言模型提供了有效解决方案。

Abstract: Vision-language models are increasingly deployed as computer-use agents (CUAs) that operate desktops and browsers. Top-performing CUAs are framework-based systems that decompose planning and execution, while end-to-end screenshot-to-action policies are easier to deploy but lag behind on benchmarks such as OSWorld-Verified. GUI datasets like OSWorld pose two bottlenecks: they expose only a few hundred interactive, verifiable tasks and environments, and expert trajectories must be gathered by interacting with these environments, making such data hard to scale. We therefore ask how reinforcement learning from verifiable rewards (RLVR) can best exploit a small pool of exist expert trajectories to train end-to-end policies. Naively mixing these off-policy traces into on-policy RLVR is brittle: even after format conversion, expert trajectories exhibit structural mismatch and distribution shift from the learner. We propose BEPA (Bi-Level Expert-to-Policy Assimilation), which turns static expert traces into policy-aligned guidance via self-rolled reachable trajectories under the base policy (LEVEL-1) and a per-task, dynamically updated cache used in RLVR (LEVEL-2). On OSWorld-Verified, BEPA improves UITARS1.5-7B success from 22.87% to 32.13% and raises a held-out split from 5.74% to 10.30%, with consistent gains on MMBench-GUI and Online-Mind2Web. Our code and data are available at: https://github.com/LEON-gittech/Verl_GUI.git

</details>


### [30] [StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management](https://arxiv.org/abs/2601.05890)
*Ruizhe Zhang,Xinke Jiang,Zhibang Yang,Zhixin Zhang,Jiaran Gao,Yuzhen Xiao,Hongbin Lai,Xu Chu,Junfeng Zhao,Yasha Wang*

Main category: cs.AI

TL;DR: StackPlanner是一个具有显式内存控制的分层多智能体框架，通过解耦高层协调与子任务执行，并利用结构化经验记忆和强化学习重用协调经验，解决了长时程协作中的内存管理问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的集中式多智能体系统在处理复杂知识密集型任务时，中央智能体由于缺乏内存管理，导致上下文膨胀、错误累积和跨任务泛化能力差，无法实现稳定的长时程协作。

Method: 提出StackPlanner分层多智能体框架：1）通过主动任务级内存控制解耦高层协调与子任务执行；2）利用结构化经验记忆和强化学习检索和重用协调经验。

Result: 在多个深度搜索和智能体系统基准测试中，StackPlanner在实现可靠的长时程多智能体协作方面表现出有效性。

Conclusion: StackPlanner通过显式内存控制解决了多智能体系统中的任务级内存效率低下和协调经验重用问题，为可靠的长时程协作提供了有效解决方案。

Abstract: Multi-agent systems based on large language models, particularly centralized architectures, have recently shown strong potential for complex and knowledge-intensive tasks. However, central agents often suffer from unstable long-horizon collaboration due to the lack of memory management, leading to context bloat, error accumulation, and poor cross-task generalization. To address both task-level memory inefficiency and the inability to reuse coordination experience, we propose StackPlanner, a hierarchical multi-agent framework with explicit memory control. StackPlanner addresses these challenges by decoupling high-level coordination from subtask execution with active task-level memory control, and by learning to retrieve and exploit reusable coordination experience via structured experience memory and reinforcement learning. Experiments on multiple deep-search and agent system benchmarks demonstrate the effectiveness of our approach in enabling reliable long-horizon multi-agent collaboration.

</details>


### [31] [TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents](https://arxiv.org/abs/2601.05899)
*Dawei Wang,Chengming Zhou,Di Zhao,Xinyuan Liu,Marci Chi Ma,Gary Ushaw,Richard Davison*

Main category: cs.AI

TL;DR: TowerMind：一个基于塔防游戏的轻量级多模态环境，用于评估大语言模型在实时策略游戏中的长期规划和决策能力，同时支持幻觉检测。


<details>
  <summary>Details</summary>
Motivation: 现有RTS游戏环境要么计算需求高，要么缺乏文本观察支持，限制了其在LLM评估中的应用。需要一种既能保留RTS游戏评估优势，又具备低计算需求和多模态观察的环境。

Method: 提出TowerMind环境，基于RTS游戏的塔防子类型，具有像素、文本和结构化游戏状态三种观察表示。设计了五个基准关卡，在不同多模态输入设置下评估多个LLM和两种经典强化学习算法。

Result: 实验结果显示LLM与人类专家在能力和幻觉维度上存在明显性能差距。LLM表现出规划验证不足、决策缺乏多终局性、行动使用效率低等关键局限性。强化学习算法表现也有限。

Conclusion: TowerMind通过轻量级多模态设计补充了现有RTS游戏环境，为AI智能体领域引入了新的基准测试平台，有助于深入理解LLM在复杂决策任务中的局限性。

Abstract: Recent breakthroughs in Large Language Models (LLMs) have positioned them as a promising paradigm for agents, with long-term planning and decision-making emerging as core general-purpose capabilities for adapting to diverse scenarios and tasks. Real-time strategy (RTS) games serve as an ideal testbed for evaluating these two capabilities, as their inherent gameplay requires both macro-level strategic planning and micro-level tactical adaptation and action execution. Existing RTS game-based environments either suffer from relatively high computational demands or lack support for textual observations, which has constrained the use of RTS games for LLM evaluation. Motivated by this, we present TowerMind, a novel environment grounded in the tower defense (TD) subgenre of RTS games. TowerMind preserves the key evaluation strengths of RTS games for assessing LLMs, while featuring low computational demands and a multimodal observation space, including pixel-based, textual, and structured game-state representations. In addition, TowerMind supports the evaluation of model hallucination and provides a high degree of customizability. We design five benchmark levels to evaluate several widely used LLMs under different multimodal input settings. The results reveal a clear performance gap between LLMs and human experts across both capability and hallucination dimensions. The experiments further highlight key limitations in LLM behavior, such as inadequate planning validation, a lack of multifinality in decision-making, and inefficient action use. We also evaluate two classic reinforcement learning algorithms: Ape-X DQN and PPO. By offering a lightweight and multimodal design, TowerMind complements the existing RTS game-based environment landscape and introduces a new benchmark for the AI agent field. The source code is publicly available on GitHub(https://github.com/tb6147877/TowerMind).

</details>


### [32] [Open-Vocabulary 3D Instruction Ambiguity Detection](https://arxiv.org/abs/2601.05991)
*Jiayu Ding,Haoran Tang,Ge Li*

Main category: cs.AI

TL;DR: 提出首个开放词汇3D指令歧义检测任务，构建大规模基准Ambi3D，发现现有3D大语言模型难以可靠检测歧义，并提出两阶段框架AmbiVer来解决该问题。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域（如手术场景），语言歧义可能导致严重后果，但现有具身AI研究大多忽视此问题，假设指令清晰并专注于执行而非确认。为填补这一关键安全空白，需要研究3D场景中的指令歧义检测。

Method: 1. 定义开放词汇3D指令歧义检测新任务；2. 构建大规模基准Ambi3D，包含700+多样3D场景和约22k指令；3. 提出AmbiVer两阶段框架：首先从多视角收集显式视觉证据，然后用这些证据指导视觉语言模型判断指令歧义。

Result: 分析发现最先进的3D大语言模型难以可靠判断指令是否歧义。AmbiVer框架在实验中表现出有效性，证明了任务的挑战性和解决方案的可行性。

Conclusion: 该研究填补了具身AI中指令歧义检测的关键空白，提出的任务、基准和框架为构建更安全、更可信的具身AI系统铺平了道路。

Abstract: In safety-critical domains, linguistic ambiguity can have severe consequences; a vague command like "Pass me the vial" in a surgical setting could lead to catastrophic errors. Yet, most embodied AI research overlooks this, assuming instructions are clear and focusing on execution rather than confirmation. To address this critical safety gap, we are the first to define Open-Vocabulary 3D Instruction Ambiguity Detection, a fundamental new task where a model must determine if a command has a single, unambiguous meaning within a given 3D scene. To support this research, we build Ambi3D, the large-scale benchmark for this task, featuring over 700 diverse 3D scenes and around 22k instructions. Our analysis reveals a surprising limitation: state-of-the-art 3D Large Language Models (LLMs) struggle to reliably determine if an instruction is ambiguous. To address this challenge, we propose AmbiVer, a two-stage framework that collects explicit visual evidence from multiple views and uses it to guide an vision-language model (VLM) in judging instruction ambiguity. Extensive experiments demonstrate the challenge of our task and the effectiveness of AmbiVer, paving the way for safer and more trustworthy embodied AI. Code and dataset available at https://jiayuding031020.github.io/ambi3d/.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [33] [On the Limits of Self-Improving in LLMs and Why AGI, ASI and the Singularity Are Not Near Without Symbolic Model Synthesis](https://arxiv.org/abs/2601.05280)
*Hector Zenil*

Main category: cs.IT

TL;DR: 论文将LLM递归自训练形式化为离散动力系统，证明随着训练数据越来越自生成，系统必然出现退化动态，提出两种基本失败模式：熵衰减和方差放大，并建议通过符号回归和程序合成来克服这些限制。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型和生成式AI中递归自训练的退化动态，揭示当训练数据越来越依赖自生成内容时系统必然崩溃的根本原因，为克服纯分布学习的局限性提供理论基础。

Method: 将递归自训练形式化为离散时间动力系统，分析训练数据自生成比例趋近于零时的系统行为，推导出熵衰减和方差放大两种失败模式，并提出基于算法概率的符号回归和程序合成方法。

Result: 证明随着α_t→0（外部数据比例趋零），系统必然经历退化动态：熵衰减导致分布多样性单调损失（模式崩溃），方差放大导致模型对真理的表征随机漂移。这些行为不依赖于架构，而是有限样本分布学习的必然结果。

Conclusion: 纯分布学习必然导致模型崩溃，但混合神经符号方法（特别是基于算法概率的符号回归和程序合成）提供了持续自我改进的连贯框架，能够识别生成机制而非仅仅相关性，从而突破数据处理不等式对统计学习的限制。

Abstract: We formalise recursive self-training in Large Language Models (LLMs) and Generative AI as a discrete-time dynamical system and prove that, as training data become increasingly self-generated ($α_t \to 0$), the system undergoes inevitably degenerative dynamics. We derive two fundamental failure modes: (1) Entropy Decay, where finite sampling effects cause a monotonic loss of distributional diversity (mode collapse), and (2) Variance Amplification, where the loss of external grounding causes the model's representation of truth to drift as a random walk, bounded only by the support diameter. We show these behaviours are not contingent on architecture but are consequences of distributional learning on finite samples. We further argue that Reinforcement Learning with imperfect verifiers suffers similar semantic collapse. To overcome these limits, we propose a path involving symbolic regression and program synthesis guided by Algorithmic Probability. The Coding Theorem Method (CTM) allows for identifying generative mechanisms rather than mere correlations, escaping the data-processing inequality that binds standard statistical learning. We conclude that while purely distributional learning leads to model collapse, hybrid neurosymbolic approaches offer a coherent framework for sustained self-improvement.

</details>


### [34] [Multi-User Covert Communications via Intelligent Spectrum Control](https://arxiv.org/abs/2601.05281)
*Yujie Ling,Zan Li,Lei Guan,Zheng Zhang,Dusit Niyato*

Main category: cs.IT

TL;DR: 提出智能频谱控制方案，在多小区场景中结合高精度频谱感知和AI实时决策，为多用户生成时频动态占用模式，提升隐蔽通信性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在多小区场景中，存在窃听者和恶意干扰者，传统固定频谱分配难以同时保证隐蔽性和可靠性，需要智能的动态频谱控制方案来应对外部干扰和系统内同信道碰撞。

Method: 提出智能频谱控制方案，结合高精度频谱感知和AI辅助实时决策，生成时频动态占用模式；推导窃听者检测错误概率和合法用户可靠传输概率的闭式表达式；在隐蔽性和可靠性约束下优化传输功率和最大并发用户数。

Result: 仿真结果显示分析结果与蒙特卡洛曲线高度匹配；所提方案相比基准方案能实现更高的检测错误概率、更大的可靠传输概率和更大的多用户容量。

Conclusion: 智能频谱控制方案能有效提升多用户隐蔽通信系统的性能，在存在窃听者和干扰者的多小区场景中实现更好的隐蔽性、可靠性和多用户并发能力。

Abstract: This paper investigates the performance of multi-user covert communications over a fixed bandwidth in a multi-cell scenario with both eavesdroppers and malicious jammers. We propose an intelligent spectrum control (ISC) scheme that combines high-accuracy spectrum sensing with AI-assisted real-time decision-making to generate time-frequency dynamic occupation patterns for multiple legitimate users. The scheme can proactively avoid external interference and intra-system co-channel collisions, thereby improving covertness and reliability. Within this framework, we derive closed-form expressions for the detection error probability (DEP) of the eavesdropper and the reliable transmission probability (RTP) of legitimate users under multi-user joint detection. We then analytically optimize the transmission power that can maximize the covert rate (CR), as well as the maximum number of users that can access the system covertly and concurrently under given covertness and reliability constraints. Simulation results confirm the tight match between the analytical and Monte Carlo curves, and show that the proposed scheme can achieve a higher DEP, a larger RTP, and a greater multi-user capacity than the benchmark scheme.

</details>


### [35] [Secure Communication via Modulation Order Confusion](https://arxiv.org/abs/2601.05292)
*Jingyi Wang,Fanggang Wang*

Main category: cs.IT

TL;DR: 提出基于调制阶数混淆的安全通信框架，通过伪装调制阶数误导窃听者，保护无线通信安全


<details>
  <summary>Details</summary>
Motivation: 调制分类技术对无线安全构成威胁，需要开发能够对抗调制分类器的安全通信方法

Method: 针对单天线系统提出符号随机映射和符号时间分集方案；针对多天线系统提出基于级数展开和星座路径的信号设计，并扩展到RIS辅助系统

Result: 所提方案能有效对抗基于深度学习和专家知识的调制分类器，同时不降低通信性能

Conclusion: 调制阶数混淆是一种有效的物理层安全技术，能保护无线通信免受调制分类攻击

Abstract: With the increasing threat posed by modulation classification to wireless security, this paper proposes a secure communication framework based on modulation order confusion (MOC), which intentionally disguises the original modulation as a higher- or lower-order one to mislead eavesdroppers. For single-antenna systems, two schemes are developed: symbol random mapping and symbol time diversity, enabling modulation order confusion with customized receivers. For multi-antenna systems, receiver-transparent MOC schemes are proposed, including series-expansion-based and constellation-path-based signal designs, and are further extended to RIS-assisted systems with joint beamformer and RIS reflection design. Numerical results show that the proposed schemes effectively defeat both deep-learning-based and expert-knowledge-based modulation classifiers without degrading communication performance.

</details>


### [36] [The Number of Cycles of Bi-regular Tanner Graphs in Terms of the Eigenvalues of the Adjacency Matrix](https://arxiv.org/abs/2601.05340)
*Roxana Smarandache,David G. M. Mitchell*

Main category: cs.IT

TL;DR: 本文探索了LDPC码图中环与邻接矩阵特征值的新联系，推导了双正则图中短环数量的快速递归公式，并针对QC-LDPC码给出了具体计算方法。


<details>
  <summary>Details</summary>
Motivation: 研究LDPC码图中环结构对码性能的影响，特别是双正则QC-LDPC码中环数量与邻接矩阵特征值之间的数学关系，旨在提供更高效的分析工具。

Method: 通过建立图环与邻接矩阵特征值的新联系，推导出双正则图中长度为2k（k<g）的环数量N_{2k}的快速递归公式。针对QC-LDPC码，利用块循环矩阵技术高效计算特征值。

Result: 得到了双正则图中短环数量的递归计算公式，并推导出k≤7时N_{2k}的显式公式，这些公式完全由邻接矩阵的非零特征值表示。针对QC-LDPC码，特征值可通过块循环矩阵技术高效计算。

Conclusion: 建立了LDPC码图环结构与邻接矩阵特征值之间的数学联系，为双正则QC-LDPC码的环分析提供了高效的理论框架和计算方法，有助于码设计和性能优化。

Abstract: In this paper, we explore new connections between the cycles in the graph of low-density parity-check (LDPC) codes and the eigenvalues of the corresponding adjacency matrix. The resulting observations are used to derive fast, simple, recursive formulas for the number of cycles $N_{2k}$ of length $2k$, $k<g$, in a bi-regular graph of girth $g$. Moreover, we derive explicit formulas for $N_{2k}$, $k\leq 7$, in terms of the nonzero eigenvalues of the adjacency matrix. Throughout, we focus on the practically interesting class of bi-regular quasi-cyclic LDPC (QC-LDPC) codes, for which the eigenvalues can be obtained efficiently by applying techniques used for block-circulant matrices.

</details>


### [37] [Strong Singleton-Like Bounds, Quasi-Perfect Codes and Distance-Optimal Codes in the Sum-Rank Metric](https://arxiv.org/abs/2601.05581)
*Chao Liu,Hao Chen,Qinqin Ji,Ziyan Xie,Dabin Zheng*

Main category: cs.IT

TL;DR: 该论文通过从汉明度量覆盖码构造和秩度量覆盖码，提出了和秩度量码的新上界，并构造了多种最优和准完美和秩度量码。


<details>
  <summary>Details</summary>
Motivation: 和秩度量码在多跳网络编码、空时编码和分布式存储中有广泛应用，但现有理论结果有限，需要更紧的界和更多构造方法。

Method: 通过从汉明度量覆盖码构造和秩度量覆盖码，推导尺寸、覆盖半径和块长函数的新上界；利用循环码构造距离最优和秩度量码；使用Plotkin和构造更多距离最优码。

Result: 获得了比经典Singleton-like界更紧的新上界；构造了矩阵尺寸为s×s和2×2的最小和秩距离为4的距离最优码；提出了无限族的准完美q元和秩度量码；构造了更大块长的几乎MSRD码。

Conclusion: 论文为和秩度量码提供了新的理论界和构造方法，扩展了和秩度量码的理论基础，为实际应用提供了更多编码选择。

Abstract: Codes in the sum-rank metric have received many attentions in recent years, since they have wide applications in the multishot network coding, the space-time coding and the distributed storage. In this paper, by constructing covering codes in the sum-rank metric from covering codes in the Hamming metric, we derive new upper bounds on sizes, the covering radii and the block length functions of codes in the sum-rank metric. As applications, we present several strong Singleton-like bounds that are tighter than the classical Singleton-like bound when block lengths are large. In addition, we give the explicit constructions of the distance-optimal sum-rank codes of matrix sizes $s\times s$ and $2\times 2$ with minimum sum-rank distance four respectively by using cyclic codes in the Hamming metric. More importantly, we present an infinite families of quasi-perfect $q$-ary sum-rank codes with matrix sizes $2\times m$. Furthermore, we construct almost MSRD codes with larger block lengths and demonstrate how the Plotkin sum can be used to give more distance-optimal sum-rank codes.

</details>


### [38] [Multiset Deletion-Correcting Codes: Bounds and Constructions](https://arxiv.org/abs/2601.05636)
*Avraham Kreindel,Isaac Barouch Essayag,Aryeh Lev Zabokritskiy*

Main category: cs.IT

TL;DR: 研究多集空间中的纠错码，针对符号删除错误，在极端删除情况下建立紧致或近紧致的码大小界限，并给出显式构造。


<details>
  <summary>Details</summary>
Motivation: 研究多集空间中的纠错码，主要动机是应对排列信道中完全丢失排序信息、仅通过删除符号（减少符号重数）产生错误的情况。

Method: 在极端删除情况下（输出包含k=n-t个符号），建立码大小界限：确定t=n-1和t=n-2时的精确最优码大小，对t=n-3进行细化分析，通过从参数(n,k)到(n-1,k-1)的约简推导一般递归穿刺上界。构造方面：完全解决二元多集模型，给出显式最优同余构造；研究二元以外的单删除码，给出一般q元构造；提出基于单同余约束的显式循环Sidon型线性构造。

Result: 建立了极端删除情况下码大小的紧致或近紧致界限；完全确定了二元多集模型的S₂(n,t)并给出显式最优构造；展示了对于q≥3，自然模构造不一定最优；提出了具有冗余度log_q(t(t+1)^{q-2}+1)且编解码复杂度与块长n成线性的显式构造。

Conclusion: 该论文在多集空间中针对符号删除错误建立了重要的理论界限，并提供了有效的构造方法，特别是在二元情况下完全解决了问题，为排列信道中的纠错编码提供了理论基础和实用方案。

Abstract: We study error-correcting codes in the space $\mathcal{S}_{n,q}$ of length-$n$ multisets over a $q$-ary alphabet, motivated by permutation channels in which ordering is completely lost and errors act solely by deletions of symbols, i.e., by reducing symbol multiplicities.
  Our focus is on the \emph{extremal deletion regime}, where the channel output contains $k=n-t$ symbols. In this regime, we establish tight or near-tight bounds on the maximum code size. In particular, we determine the exact optimal code sizes for $t=n-1$ and for $t=n-2$, develop a refined analysis for $t=n-3$, and derive a general recursive puncturing upper bound for $t=n-k$ via a reduction from parameters $(n,k)$ to $(n-1,k-1)$.
  On the constructive side, we completely resolve the binary multiset model: for all $t\ge1$ we determine $S_2(n,t)$ exactly and give an explicit optimal congruence-based construction. We then study single-deletion codes beyond the binary case, presenting general $q$-ary constructions and showing, via explicit small-parameter examples, that the natural modular construction need not be optimal for $q\ge3$. Finally, we present an explicit cyclic Sidon-type linear construction for general $(q,t)$ based on a single congruence constraint, with redundancy $\log_q\!\bigl(t(t+1)^{q-2}+1\bigr)$ and encoding and decoding complexity linear in the blocklength $n$.

</details>


### [39] [Age of Gossip With Cellular Drone Mobility](https://arxiv.org/abs/2601.05983)
*Arunabh Srivastava,Sennur Ulukus*

Main category: cs.IT

TL;DR: 研究无人机辅助蜂窝网络中信息新鲜度，发现无人机移动速度与信息传播速率之间存在双重瓶颈效应，信息版本年龄受两者中较慢者限制。


<details>
  <summary>Details</summary>
Motivation: 在无人机辅助的蜂窝网络中，节点通过无人机从源获取更新信息。需要评估无人机移动速度、传播速率和网络规模对信息新鲜度的影响，以优化网络性能。

Method: 采用连续时间马尔可夫链（CTMC）建模无人机移动，使用版本年龄信息度量信息新鲜度。分析无人机到小区服务时间的期望间隔，并针对全连接无人机移动模型进行深入分析。

Result: 发现无人机移动速度与传播速率之间存在双重瓶颈：当传播速率远大于移动速度时，版本年龄主要受移动速度限制；当移动速度远大于传播速率时，版本年龄主要受传播速率限制。

Conclusion: 无人机辅助网络的信息新鲜度受无人机移动速度和信息传播速率中较慢者的限制，这为网络优化提供了重要指导。

Abstract: We consider a cellular network containing $n$ nodes where nodes within a cell gossip with each other in a fully-connected fashion and a source shares updates with these nodes via a mobile drone. The mobile drone receives updates directly from the source and shares them with nodes in the cell where it currently resides. The drone moves between cells according to an underlying continuous-time Markov chain (CTMC). In this work, we evaluate the impact of the number of cells $f(n)$, drone speed $λ_m(n)$ and drone dissemination rate $λ_d(n)$ on the freshness of information of nodes in the network. We utilize the version age of information metric to quantify the freshness of information. We observe that the expected duration between two drone-to-cell service times depends on the stationary distribution of the underlying CTMC and $λ_d(n)$, but not on $λ_m(n)$. However, the version age instability in slow moving CTMCs makes high probability analysis for a general underlying CTMC difficult. Therefore, next we focus on the fully-connected drone mobility model. Under this model, we uncover a dual-bottleneck between drone mobility and drone dissemination speed: the version age is constrained by the slower of these two processes. If $λ_d(n) \gg λ_m(n)$, then the version age scaling of nodes is dominated by the inverse of $λ_m(n)$ and is independent of $λ_d(n)$. If $λ_m(n) \gg λ_d(n)$, then the version age scaling of nodes is dominated by the inverse of $λ_d(n)$ and is independent of $λ_m(n)$.

</details>


### [40] [Coset Shaping for Coded Modulation](https://arxiv.org/abs/2601.05652)
*Irina Bocharova,Maiara F. Bollauf,Boris Kudryashov*

Main category: cs.IT

TL;DR: 提出了一种称为陪集整形的新整形技术，用于编码QAM和PAM信号，可应用于信息位和校验位而不增加复杂度，当编码长度和调制阶数趋于无穷时，该方案与容量之间的差距可任意小。


<details>
  <summary>Details</summary>
Motivation: 传统整形技术通常只应用于信息位，而校验位整形会增加复杂度。需要一种既能应用于信息位和校验位，又不增加复杂度的整形方案，以更接近信道容量。

Method: 提出陪集整形技术，该技术可同时应用于信息位和校验位。通过理论分析证明，当编码长度和调制阶数趋于无穷时，该方案与容量之间的差距可任意小。

Result: 数值结果和比较显示，该整形方案与非二进制LDPC编码的QAM信号结合时表现良好。理论证明该方案在极限情况下可任意接近信道容量。

Conclusion: 陪集整形是一种有效的整形技术，可同时应用于信息位和校验位而不增加复杂度，在编码长度和调制阶数足够大时，可实现接近信道容量的性能。

Abstract: A new shaping technique called coset shaping for coded QAM and PAM signaling is introduced and analyzed. This technique can be applied not only to information bits but also to parity bits without incurring additional complexity costs. It is proven that as the length of the error-correcting code and the modulation order tend to infinity, the gap to capacity for the proposed shaping scheme can be made arbitrarily small. Numerical results and comparisons for the shaping scheme, along with nonbinary LDPC-coded QAM signaling, are presented.

</details>


### [41] [Nonlinearity Mitigation for Coherent Ground-to-Satellite Optical Links](https://arxiv.org/abs/2601.05655)
*Stella Civelli,Marco Secondini,Luca Potì*

Main category: cs.IT

TL;DR: 提出用于卫星通信中高功率光放大器非线性抑制的数字信号处理技术，可将可接受链路损耗提高6dB且复杂度可忽略


<details>
  <summary>Details</summary>
Motivation: 卫星通信中的高功率光放大器存在非线性失真问题，限制了链路性能和传输距离，需要有效的非线性抑制技术

Method: 采用数字信号处理技术来缓解高功率光放大器的非线性效应，具体技术细节未在摘要中详细说明

Result: 通过该技术，可接受的链路损耗增加了6dB，且实现复杂度可忽略不计

Conclusion: 提出的数字信号处理技术能有效缓解高功率光放大器的非线性问题，显著提升卫星通信链路的性能

Abstract: We propose digital signal processing techniques for nonlinearity mitigation in high power optical amplifiers used in satellite communications. The acceptable link loss increases by 6dB with negligible complexity.

</details>


### [42] [On the Complexity of Electromagnetic Far-Field Modeling](https://arxiv.org/abs/2601.05674)
*Torben Kölle,Alexander Stutz-Tirri,Christoph Studer*

Main category: cs.IT

TL;DR: 该论文为通用天线架构的电磁远场建模提供了一个基于麦克斯韦方程的数学严谨框架，证明了在物理假设下天线架构具有有限复杂度，可用有限秩算子建模，并构造了超指数收敛的近似算子序列。


<details>
  <summary>Details</summary>
Motivation: 现代无线系统采用不仅能收发电磁波，还能有意反射和变换入射电磁波的天线架构。需要为这类通用天线架构的电磁远场建模建立数学严谨的框架，为数字计算平台上的高效准确建模提供理论基础。

Method: 基于麦克斯韦方程建立数学严谨的分析框架，在物理有意义的假设下，证明天线架构表现出有限复杂度（可用有限秩算子建模），并构造有限秩算子序列，其近似误差在算子秩超过天线架构的有效带宽时呈超指数衰减。

Result: 证明了通用天线架构在物理假设下具有有限复杂度，可用有限参数通过有限秩算子建模。构造的有限秩算子序列在算子秩超过有效带宽时，近似误差呈超指数衰减，为数字计算平台上的高效准确建模提供了理论基础。

Conclusion: 该研究为通用天线架构的电磁远场建模建立了数学严谨的框架，证明了其有限复杂度和可建模性，构造的超指数收敛近似算子序列为实现数字计算平台上的高效准确建模提供了根本前提。

Abstract: Modern wireless systems are envisioned to employ antenna architectures that not only transmit and receive electromagnetic (EM) waves, but also intentionally reflect and possibly transform incident EM waves. In this paper, we propose a mathematically rigorous framework grounded in Maxwell's equations for analyzing the complexity of EM far-field modeling of general antenna architectures. We show that-under physically meaningful assumptions-such antenna architectures exhibit limited complexity, i.e., can be modeled by finite-rank operators using finitely many parameters. Furthermore, we construct a sequence of finite-rank operators whose approximation error decays super-exponentially once the operator rank exceeds an effective bandwidth associated with the antenna architecture and the analysis frequency. These results constitute a fundamental prerequisite for the efficient and accurate modeling of general antenna architectures on digital computing platforms.

</details>


### [43] [Secure Multiuser Beamforming With Movable Antenna Arrays](https://arxiv.org/abs/2601.05686)
*Zhenqiao Cheng,Chongjun Ouyang,Boqun Zhao,Xingqi Zhang*

Main category: cs.IT

TL;DR: 提出一种基于可移动天线(MAs)的安全多用户传输框架，通过联合优化数字波束成形和天线位置来最大化总保密率


<details>
  <summary>Details</summary>
Motivation: 传统固定位置天线阵列在物理层安全方面存在局限性，需要新的技术来增强无线通信的安全性

Method: 开发基于可移动天线的安全多用户传输框架，推导保密信道编码定理下的总保密率表达式，提出基于分数规划和块坐标下降的联合优化算法

Result: 算法在每次迭代中都能获得闭式解或低复杂度一维/二分搜索解，数值结果表明该方法有效且优于传统固定天线阵列

Conclusion: 可移动天线设计能显著提高物理层安全性能，为未来无线通信安全提供有前景的解决方案

Abstract: A movable antennas (MAs)-enabled secure multiuser transmission framework is developed to enhance physical-layer security. Novel expressions are derived to characterize the achievable sum secrecy rate based on the secure channel coding theorem. On this basis, a joint optimization algorithm for digital beamforming and MA placement is proposed to maximize the sum secrecy rate via fractional programming and block coordinate descent. In each iteration, every variable admits either a closed-form update or a low-complexity one-dimensional or bisection search, which yields an efficient implementation. Numerical results demonstrate the effectiveness of the proposed method and show that the MA-enabled design achieves higher secrecy rates than conventional fixed-position antenna arrays.

</details>


### [44] [Universal and Asymptotically Optimal Data and Task Allocation in Distributed Computing](https://arxiv.org/abs/2601.05873)
*Javad Maheri,K. K. Krishnan Namboodiri,Petros Elia*

Main category: cs.IT

TL;DR: 研究分布式计算中通信与计算成本的联合最小化问题，通过d-均匀超图边划分方法，提出Interweaved-Cliques设计，在确定性且无需了解具体函数分解的情况下，同时达到通信成本n/N^{1/d}和计算成本的阶次最优。


<details>
  <summary>Details</summary>
Motivation: 在分布式计算中，主节点协调多个工作节点评估函数时，需要同时最小化通信成本（服务器间传输的文件数）和计算成本（工作节点的子函数负载）。现有方法通常需要了解具体的函数分解结构，限制了系统的灵活性和可扩展性。

Method: 将分布式计算问题转化为d-均匀超图边划分问题，其中顶点表示文件，边表示依赖于d个输入文件的子函数。提出Interweaved-Cliques（IC）设计，这是一种确定性分配方案，通过交织团结构同时优化文件分配和子函数划分。

Result: IC设计在广泛的参数范围内同时达到通信成本π_X和计算成本δ_X的阶次最优。通信成本的最优缩放为n/N^{1/d}，实现了N^{1/d}的分区增益，且计算成本也达到阶次最优。重要的是，这种最优性是在确定性且无需了解具体函数分解X的情况下实现的。

Conclusion: 提出的Interweaved-Cliques设计为分布式计算中的通信-计算权衡问题提供了有效的解决方案，能够在不知道具体函数分解的情况下，确定性地同时优化通信和计算成本，支持多个函数的计算而无需重新分配文件。

Abstract: We study the joint minimization of communication and computation costs in distributed computing, where a master node coordinates $N$ workers to evaluate a function over a library of $n$ files. Assuming that the function is decomposed into an arbitrary subfunction set $\mathbf{X}$, with each subfunction depending on $d$ input files, renders our distributed computing problem into a $d$-uniform hypergraph edge partitioning problem wherein the edge set (subfunction set), defined by $d$-wise dependencies between vertices (files) must be partitioned across $N$ disjoint groups (workers). The aim is to design a file and subfunction allocation, corresponding to a partition of $\mathbf{X}$, that minimizes the communication cost $π_{\mathbf{X}}$, representing the maximum number of distinct files per server, while also minimizing the computation cost $δ_{\mathbf{X}}$ corresponding to a maximal worker subfunction load. For a broad range of parameters, we propose a deterministic allocation solution, the \emph{Interweaved-Cliques (IC) design}, whose information-theoretic-inspired interweaved clique structure simultaneously achieves order-optimal communication and computation costs, for a large class of decompositions $\mathbf{X}$. This optimality is derived from our achievability and converse bounds, which reveal -- under reasonable assumptions on the density of $\mathbf{X}$ -- that the optimal scaling of the communication cost takes the form $n/N^{1/d}$, revealing that our design achieves the order-optimal \textit{partitioning gain} that scales as $N^{1/d}$, while also achieving an order-optimal computation cost. Interestingly, this order optimality is achieved in a deterministic manner, and very importantly, it is achieved blindly from $\mathbf{X}$, therefore enabling multiple desired functions to be computed without reshuffling files.

</details>
