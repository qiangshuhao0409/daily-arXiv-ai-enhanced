<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 9]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.IT](#cs.IT) [Total: 7]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Photonic Rails in ML Datacenters](https://arxiv.org/abs/2507.08119)
*Eric Ding,Chuhan Ouyang,Rachee Singh*

Main category: cs.NI

TL;DR: 论文提出了一种基于光电路交换机的铁路优化网络架构，以解决传统高基数电气交换机在大型ML训练中的高功耗、高成本和高复杂性问题。通过并行驱动的铁路重配置和控制平面Opus，实现了光交换机的时间复用仿真。


<details>
  <summary>Details</summary>
Motivation: 传统铁路优化网络架构使用高基数电气交换机实现全连接，但带来了巨大的功耗、成本和复杂性开销。光交换机虽然能解决这些问题，但其一对一连接特性限制了ML工作负载的扇出能力。

Method: 提出并行驱动的铁路重配置方法，利用不同并行性流量之间的顺序性，设计控制平面Opus，实现光交换机的时间复用仿真。

Result: 成功实现了光交换机对电气铁路交换机的时间复用仿真，为数据中心网络架构提供了新的研究方向。

Conclusion: 论文提出了一种新的数据中心网络架构研究方向，即网络架构与模型并行维度共同演进，而非在任务开始前静态配置网络。

Abstract: Rail-optimized network fabrics have become the de facto datacenter scale-out
fabric for large-scale ML training. However, the use of high-radix electrical
switches to provide all-to-all connectivity in rails imposes massive power,
cost, and complexity overheads. We propose a rethinking of the rail abstraction
by retaining its communication semantics, but realizing it using optical
circuit switches. The key challenge is that optical switches support only
one-to-one connectivity at a time, limiting the fan-out of traffic in ML
workloads using hybrid parallelisms. We introduce parallelism-driven rail
reconfiguration as a solution that leverages the sequential ordering between
traffic from different parallelisms. We design a control plane, Opus, to enable
time-multiplexed emulation of electrical rail switches using optical switches.
More broadly, our work discusses a new research agenda: datacenter fabrics that
co-evolve with the model parallelism dimensions within each job, as opposed to
the prevailing mindset of reconfiguring networks before a job begins.

</details>


### [2] [Rattan: An Extensible and Scalable Modular Internet Path Emulator](https://arxiv.org/abs/2507.08134)
*Minhu Wang,Yixin Shen,Bo Wang,Haixuan Tong,Yutong Xie,Yixuan Gao,Yan Liu,Li Chen,Mingwei Xu,Jianping Wu*

Main category: cs.NI

TL;DR: Rattan是一种可扩展和可扩展的软件网络路径模拟器，通过模块化“单元”架构解决现有模拟器在灵活性、可扩展性和可用性上的不足。


<details>
  <summary>Details</summary>
Motivation: 互联网路径的异质性、规模和动态性快速增长，现有模拟器在灵活性、可扩展性和可用性上不足。

Method: 采用基于单元的架构，将模拟功能拆分为模块化单元，用户可通过层次化链接组合单元或构建新单元。

Result: 支持单机上百个千兆级路径和集群级实验，并能通过新单元模拟新网络条件。

Conclusion: Rattan为开发者和研究人员提供了高效、可靠的网络传输创新评估工具。

Abstract: The rapid growth of Internet paths in heterogeneity, scale, and dynamics has
made existing emulators increasingly insufficient in flexibility, scalability,
and usability. To address these limitations, we present Rattan, an extensible
and scalable software network path emulator for modern Internet conditions.
Rattan's core innovation lies in its cell-based architecture: by splitting
emulation functions into modular "cells" with well-documented asynchronous
interfaces, users are allowed to easily compose different cells by
hierarchically linking them and easily construct new cells by using standard
cell interfaces. This design enables: (1) scalability, supporting hundreds of
concurrent gigabit-level paths on a single machine and cluster-level
experiments composed of multiple machines; (2) extensibility, simulating new
network conditions by constructing new cells. Rattan empowers developers and
researchers to efficiently and confidently evaluate, validate, and diagnose
diverse network transport innovations for online services.

</details>


### [3] [KP-A: A Unified Network Knowledge Plane for Catalyzing Agentic Network Intelligence](https://arxiv.org/abs/2507.08164)
*Yun Tang,Mengbang Zou,Zeinab Nezami,Syed Ali Raza Zaidi,Weisi Guo*

Main category: cs.NI

TL;DR: KP-A是一个统一的网络知识平面，旨在为6G网络中的智能代理提供一致的知识接口，减少冗余数据流和不一致解释，并简化开发和维护。


<details>
  <summary>Details</summary>
Motivation: 当前6G网络中智能任务的实现需要独立的知识检索管道，导致数据冗余和解释不一致，KP-A旨在解决这些问题。

Method: KP-A通过解耦网络知识获取与管理与智能逻辑，提供统一的知识接口，支持智能代理的互操作性。

Result: KP-A在实时网络知识问答和边缘AI服务编排两个任务中展示了其有效性，并开源了实现。

Conclusion: KP-A为6G网络的智能代理提供了一种高效、统一的知识管理方案，支持未来的标准化工作。

Abstract: The emergence of large language models (LLMs) and agentic systems is enabling
autonomous 6G networks with advanced intelligence, including
self-configuration, self-optimization, and self-healing. However, the current
implementation of individual intelligence tasks necessitates isolated knowledge
retrieval pipelines, resulting in redundant data flows and inconsistent
interpretations. Inspired by the service model unification effort in Open-RAN
(to support interoperability and vendor diversity), we propose KP-A: a unified
Network Knowledge Plane specifically designed for Agentic network intelligence.
By decoupling network knowledge acquisition and management from intelligence
logic, KP-A streamlines development and reduces maintenance complexity for
intelligence engineers. By offering an intuitive and consistent knowledge
interface, KP-A also enhances interoperability for the network intelligence
agents. We demonstrate KP-A in two representative intelligence tasks: live
network knowledge Q&A and edge AI service orchestration. All implementation
artifacts have been open-sourced to support reproducibility and future
standardization efforts.

</details>


### [4] [Towards AI-Native RAN: An Operator's Perspective of 6G Day 1 Standardization](https://arxiv.org/abs/2507.08403)
*Nan Li,Qi Sun,Lehan Wang,Xiaofei Xu,Jinri Huang,Chunhui Liu,Jing Gao,Yuhong Huang,Chih-Lin I*

Main category: cs.NI

TL;DR: 本文探讨了6G移动网络中AI原生无线接入网（RAN）的设计与标准化原则，提出了关键Day 1架构、功能与能力，并通过大规模试验验证其性能提升。


<details>
  <summary>Details</summary>
Motivation: 5G中AI/ML仅为附加功能，而6G需从设计之初就原生集成AI以应对复杂性并支持广泛AI应用。

Method: 提出AI原生RAN框架，包括AI驱动的RAN处理/优化/自动化、可靠的AI生命周期管理（LCM）及AI即服务（AIaaS）三大能力，并设计Day 1标准化架构。

Result: 通过5000多个5G-A基站的大规模试验，验证了所提架构在降低延迟、根因识别和能耗方面的显著改进。

Conclusion: 为6G AI原生RAN标准化提供了Day 1框架，平衡技术创新与实际部署。

Abstract: Artificial Intelligence/Machine Learning (AI/ML) has become the most certain
and prominent feature of 6G mobile networks. Unlike 5G, where AI/ML was not
natively integrated but rather an add-on feature over existing architecture, 6G
shall incorporate AI from the onset to address its complexity and support
ubiquitous AI applications. Based on our extensive mobile network operation and
standardization experience from 2G to 5G, this paper explores the design and
standardization principles of AI-Native radio access networks (RAN) for 6G,
with a particular focus on its critical Day 1 architecture, functionalities and
capabilities. We investigate the framework of AI-Native RAN and present its
three essential capabilities to shed some light on the standardization
direction; namely, AI-driven RAN processing/optimization/automation, reliable
AI lifecycle management (LCM), and AI-as-a-Service (AIaaS) provisioning. The
standardization of AI-Native RAN, in particular the Day 1 features, including
an AI-Native 6G RAN architecture, were proposed. For validation, a large-scale
field trial with over 5000 5G-A base stations have been built and delivered
significant improvements in average air interface latency, root cause
identification, and network energy consumption with the proposed architecture
and the supporting AI functions. This paper aims to provide a Day 1 framework
for 6G AI-Native RAN standardization design, balancing technical innovation
with practical deployment.

</details>


### [5] [Age of Information Optimization in Laser-charged UAV-assisted IoT Networks: A Multi-agent Deep Reinforcement Learning Method](https://arxiv.org/abs/2507.08429)
*Geng Sun,Likun Zhang,Jiahui Li,Jing Wu,Jiacheng Wang,Zemin Sun,Changyuan Zhao,Victor C. M. Leung*

Main category: cs.NI

TL;DR: 论文研究了激光束充电无人机（UAV）辅助物联网（IoT）网络中的信息时效性（AoI）优化问题，提出了一种多智能体近端策略优化框架（MAPPO-TM），显著降低了峰值AoI并提高了能源效率。


<details>
  <summary>Details</summary>
Motivation: 无人机与物联网网络的结合为高效数据收集提供了新方案，但无人机的有限能源容量是一个主要挑战。激光束充电技术（LBD）可以解决这一问题，但如何优化信息时效性（AoI）仍是一个复杂问题。

Method: 提出了一种多智能体近端策略优化框架（MAPPO-TM），结合时间记忆机制和多智能体协调，优化无人机轨迹和激光充电策略。

Result: 仿真结果显示，MAPPO-TM在峰值AoI最小化和能源效率方面优于传统方法，峰值AoI降低了15.1%。

Conclusion: MAPPO-TM框架有效解决了无人机辅助物联网网络中的AoI优化问题，为未来研究提供了新方向。

Abstract: The integration of unmanned aerial vehicles (UAVs) with Internet of Things
(IoT) networks offers promising solutions for efficient data collection.
However, the limited energy capacity of UAVs remains a significant challenge.
In this case, laser beam directors (LBDs) have emerged as an effective
technology for wireless charging of UAVs during operation, thereby enabling
sustained data collection without frequent returns to charging stations (CSs).
In this work, we investigate the age of information (AoI) optimization in
LBD-powered UAV-assisted IoT networks, where multiple UAVs collect data from
distributed IoTs while being recharged by laser beams. We formulate a joint
optimization problem that aims to minimize the peak AoI while determining
optimal UAV trajectories and laser charging strategies. This problem is
particularly challenging due to its non-convex nature, complex temporal
dependencies, and the need to balance data collection efficiency with energy
consumption constraints. To address these challenges, we propose a novel
multi-agent proximal policy optimization with temporal memory and multi-agent
coordination (MAPPO-TM) framework. Specifically, MAPPO-TM incorporates temporal
memory mechanisms to capture the dynamic nature of UAV operations and
facilitates effective coordination among multiple UAVs through decentralized
learning while considering global system objectives. Simulation results
demonstrate that the proposed MAPPO-TM algorithm outperforms conventional
approaches in terms of peak AoI minimization and energy efficiency. Ideally,
the proposed algorithm achieves up to 15.1% reduction in peak AoI compared to
conventional multi-agent deep reinforcement learning (MADRL) methods.

</details>


### [6] [Recovery of UAV Swarm-enabled Collaborative Beamforming in Low-altitude Wireless Networks under Wind Field Disturbances](https://arxiv.org/abs/2507.08507)
*Geng Sun,Chenbang Liu,Jiahui Li,Guannan Qu,Shuang Liang,Jiacheng Wang,Changyuan Zhao,Dusit Niyato*

Main category: cs.NI

TL;DR: 论文研究了无人机群在低空无线网络中利用协作波束形成时，风场干扰对性能的影响，并提出了一种基于PPO-LA算法的实时优化框架。


<details>
  <summary>Details</summary>
Motivation: 风场干扰会显著降低无人机虚拟天线阵列的波束形成性能，影响通信可靠性和效率，因此需要一种能实时适应风场变化的优化方法。

Method: 提出了一种结合LSTM和自适应学习率的PPO-LA算法，用于实时优化波束形成的激励电流权重，以应对不同风场条件。

Result: 仿真结果表明，PPO-LA算法能有效恢复波束形成性能，并在多种风场条件下优于基准算法。

Conclusion: PPO-LA算法为解决风场干扰下的协作波束形成问题提供了一种高效且适应性强的解决方案。

Abstract: Unmanned aerial vehicle (UAV) swarms utilizing collaborative beamforming (CB)
in low-altitude wireless networks (LAWN) demonstrate significant potential for
enhanced communication range, energy efficiency, and signal directivity through
the formation of virtual antenna arrays (VAA). However, environmental
disturbances, particularly wind fields, significantly degrade CB performance by
introducing positional errors that disrupt beam patterns, thereby compromising
transmission reliability. This paper investigates the critical challenge of
maintaining CB performance in UAV-based VAAs operating in LAWN under wind field
disturbances. We propose a comprehensive framework that models the impact of
three distinct wind conditions (constant, shear, and turbulent) on UAV array
performance, and formulate a long-term real-time optimization problem to
maximize directivity while minimizing maximum sidelobe levels through adaptive
excitation current weight adjustments. To address the inherent complexity of
this problem, we propose a novel proximal policy optimization algorithm with
long short-term memory (LSTM) structure and adaptive learning rate (PPO-LA),
which effectively captures temporal patterns in wind field disturbances and
enables real-time adaptation without requiring extensive prior training for
specific wind conditions. Our simulation results demonstrate that the proposed
PPO-LA algorithm successfully recovers degraded CB performance across various
wind scenarios, and thus significantly outperforming benchmark algorithms.

</details>


### [7] [Stabilizing and Optimizing Inter-Shell Routing in LEO Networks with Integrated Routing Cost](https://arxiv.org/abs/2507.08549)
*Yaojia Wang,Qi Zhang,Kun Qiu,Yue Gao*

Main category: cs.NI

TL;DR: 论文提出了一种基于动态规划的集成路由成本算法（DP-IRC），用于优化低地球轨道（LEO）多壳网络中的跨壳路由稳定性，显著降低了链路切换频率。


<details>
  <summary>Details</summary>
Motivation: 现有的跨壳路由策略（如最小跳数路径集和自适应路径路由方案）在动态网络拓扑中表现不佳，要么忽略链路切换成本，要么陷入局部最优。

Method: 通过将多壳路径建模为多阶段决策问题，DP-IRC使用集成路由成本（IRC）指标平衡跳数和链路稳定性。

Result: 实验表明，DP-IRC比最小跳数路径集和自适应路径路由方案分别减少39.1%和22.0%的链路切换率，同时保持接近最优的端到端距离。

Conclusion: DP-IRC在跨壳路由中实现了链路稳定性和路径效率的平衡，为LEO多壳网络提供了一种有效的解决方案。

Abstract: The low Earth orbit (LEO) mega-constellation network (LMCN), which uses
thousands of satellites across multi-shell architectures to deliver different
services, is facing challenges in inter-shell routing stability due to dynamic
network topologies and frequent inter-satellite link (ISL) switching. Existing
strategies, such as the Minimum Hop Path set, prioritize minimizing hop counts
to reduce latency, but ignore ISL switching costs, which leads to high
instability. To overcome this, the Adaptive Path Routing Scheme introduces path
similarity thresholds to reduce the ISL switching frequency between shells.
However, the greedy approach of Adaptive Path Routing Scheme is often trapped
in local optima, sacrificing inter-shell path distance efficiency. To address
these limitations, we propose the Dynamic Programming-based Integrated Routing
Cost (DP-IRC) algorithm, which is designed explicitly for inter-shell routing
optimization. By formulating multi-shell paths as a multistage decision
problem, DP-IRC balances hop counts and ISL stability through an Integrated
Routing Cost (IRC) metric, combining inter-/intra-shell hops and switching
costs. Experiments over 60 time slots with real-world Starlink and OneWeb
configurations show that DP-IRC reduces inter-shell ISL switching rates by
39.1% and 22.0% compared to the Minimum Hop Path set strategy and Adaptive Path
Routing Scheme, respectively, while still maintaining near-optimal end-to-end
distances.

</details>


### [8] [Qualitative Assessment of Low Power Wide Area Network Protocols and their Security Aspect](https://arxiv.org/abs/2507.08677)
*Wesley dos Reis Bezerra,Lais Machado Bezerra,Carlos Becker Westphal*

Main category: cs.NI

TL;DR: 本文分析了低功耗广域网（LPWAN）协议的定性特征，探讨了在稀疏网络中基于长寿命电池的受限设备的挑战与机遇。


<details>
  <summary>Details</summary>
Motivation: 物联网中通信选项众多，理解每种选项的差异和特性对专业人士和研究人员具有挑战性。

Method: 通过文献调查分析了三种协议（LoRaWAN、NB-IoT和Sigfox），并详细讨论了LoRaWAN。

Result: 讨论了所选网络协议及其在稀疏传感器物联网解决方案中的应用。

Conclusion: 研究为理解LPWAN协议及其在受限设备中的应用提供了参考。

Abstract: There are currently many communication options in the Internet of Things,
even in particular areas such as constrained and battery-powered devices, such
as Low Power Wide Area Networks. Understanding the differences and
characteristics of each option is a challenge, even for professionals and
researchers in the field. To meet this need, this work analyses the qualitative
characteristics of Low Power Wide Area Network protocols and the challenges and
opportunities of using constrained devices for sparse networks based on
long-life batteries. For this study, a bibliographic survey of the literature
was carried out as an analysis of three protocols (LoRaWAN, NB-IoT, and
Sigfox), and a detailing of the first one. As a result, there is a discussion
about the chosen network protocol and its use in IoT solutions with sparse
sensors.

</details>


### [9] [Knowledge Graph-Based approach for Sustainable 6G End-to-End System Design](https://arxiv.org/abs/2507.08717)
*Akshay Jain,Sylvaine Kerboeuf,Sokratis Barmpounakis,Cristóbal Vinagre Z.,Stefan Wendt,Dinh Thai Bui,Pol Alemany,Riccardo Nicolicchia,José María Jorquera Valero,Dani Korpi,Mohammad Hossein Moghaddam,Mikko A. Uusitalo,Patrik Rugeland,Abdelkader Outtagarts,Karthik Upadhya,Panagiotis Demestichas,Raul Muñoz,Manuel Gil Pérez,Daniel Adanza,Ricard Vilalta*

Main category: cs.NI

TL;DR: 本文提出了一种基于知识图谱（KG）的6G端到端系统设计新方法，综合考虑性能指标（KPI）、可持续性需求（KV/KVI）及技术使能因素，并通过实际用例验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 5G等前代通信技术主要关注性能指标，而6G需同时满足性能和可持续性目标，尤其是社会可持续性。现有文献缺乏技术使能与可持续性指标间的明确联系，因此需要新的设计方法。

Method: 采用知识图谱（KG）方法，整合用例KPI、可持续性需求（KV/KVI）、技术使能能力、6G设计原则、技术成熟度及使能间依赖关系，并引入新方法确定技术使能的关键价值。

Result: 在Hexa-X-II项目的协作移动机器人用例中，成功应用KG方法筛选出82个使能，并通过概念验证演示证明了该方法的有效性。

Conclusion: KG方法为设计可持续的6G系统提供了有效途径，未来可进一步扩展应用。

Abstract: Previous generations of cellular communication, such as 5G, have been
designed with the objective of improving key performance indicators (KPIs) such
as throughput, latency, etc. However, to meet the evolving KPI demands as well
as the ambitious sustainability targets for the ICT industry, 6G will need to
be designed differently. Concretely, 6G will need to consider both the
performance and sustainability targets for the various use cases it will serve.
Moreover, like previous generations, 6G will have various candidate
technological enablers, making the design space of the system even more
complex. Furthermore, given the subjective nature of the sustainability
indicators, in particular social sustainability, there is a significant gap in
literature on how technical enablers and 6G System design can be linked to
them. Hence, in this article a novel method for 6G end-to-end (E2E) system
design based on Knowledge graphs (KG) has been introduced. It considers as its
input: the use case KPIs, use case sustainability requirements expressed as Key
Values (KV) and KV Indicators (KVIs), the ability of the technological enablers
to satisfy these KPIs and KVIs, the 6G system design principles defined in
Hexa-X-II project, the maturity of a technological enabler and the dependencies
between the various enablers. As part of the KG method, a novel approach for
determining the key values a technological enabler addresses, has also been
introduced. The effectiveness of the KG method was demonstrated by its
application in designing the 6G E2E system for the cooperating mobile robot use
case defined in the Hexa-X-II project, where 82 enablers were selected. Lastly,
results from proof-of-concept demonstrations for a subset of the selected
enablers have also been provided, which reinforce the efficacy of the KG method
for designing a sustainable 6G system.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [10] [Human Creativity and AI](https://arxiv.org/abs/2507.08001)
*Shengyi Xie*

Main category: cs.AI

TL;DR: 本文探讨AI是否能表现创造力，结合心理学、认知神经科学和哲学视角，分析创造力的定义及其在AI技术发展中的影响。


<details>
  <summary>Details</summary>
Motivation: 随着科技进步，创造力哲学被重新诠释，研究旨在回答AI是否具备创造力这一核心问题。

Method: 回顾创造力哲学的历史观点，结合心理学和认知神经科学的进展，分析创造力的多种定义。

Result: 探讨了自然主义和认知神经科学对创造力的回应，揭示了AI技术对创造力研究的潜在影响。

Conclusion: AI在创造力方面的表现仍需进一步研究，但其发展已为创造力哲学和科学探索提供了新视角。

Abstract: With the advancement of science and technology, the philosophy of creativity
has undergone significant reinterpretation. This paper investigates
contemporary research in the fields of psychology, cognitive neuroscience, and
the philosophy of creativity, particularly in the context of the development of
artificial intelligence (AI) techniques. It aims to address the central
question: Can AI exhibit creativity? The paper reviews the historical
perspectives on the philosophy of creativity and explores the influence of
psychological advancements on the study of creativity. Furthermore, it analyzes
various definitions of creativity and examines the responses of naturalism and
cognitive neuroscience to the concept of creativity.

</details>


### [11] [TableReasoner: Advancing Table Reasoning Framework with Large Language Models](https://arxiv.org/abs/2507.08046)
*Sishi Xiong,Dakai Wang,Yu Zhao,Jie Zhang,Changzai Pan,Haowei He,Xiangyu Li,Wenhan Chang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 论文提出了一种名为TableReasoner的框架，结合大型语言模型和编程方法，解决表格问答任务中的挑战，如表格规模大、语义不完整和实体歧义。


<details>
  <summary>Details</summary>
Motivation: 表格问答任务面临真实世界表格数据的挑战，如规模大、语义不完整和实体歧义，需要一种高效且准确的解决方案。

Method: 提出TableReasoner框架，结合结构化和语义表示的表模式，设计多步模式链接计划，生成聚焦表模式，并集成迭代思考架构。

Result: 系统在SemEval-2025 Task 8的两个子任务中均获得第一名。

Conclusion: TableReasoner通过结合LLM和编程方法，有效解决了表格问答中的挑战，并在实际任务中表现优异。

Abstract: The paper presents our system developed for table question answering (TQA).
TQA tasks face challenges due to the characteristics of real-world tabular
data, such as large size, incomplete column semantics, and entity ambiguity. To
address these issues, we propose a large language model (LLM)-powered and
programming-based table reasoning framework, named TableReasoner. It models a
table using the schema that combines structural and semantic representations,
enabling holistic understanding and efficient processing of large tables. We
design a multi-step schema linking plan to derive a focused table schema that
retains only query-relevant information, eliminating ambiguity and alleviating
hallucinations. This focused table schema provides precise and sufficient table
details for query refinement and programming. Furthermore, we integrate the
reasoning workflow into an iterative thinking architecture, allowing
incremental cycles of thinking, reasoning and reflection. Our system achieves
first place in both subtasks of SemEval-2025 Task 8.

</details>


### [12] [System-of-systems Modeling and Optimization: An Integrated Framework for Intermodal Mobility](https://arxiv.org/abs/2507.08715)
*Paul Saves,Jasper Bussemaker,Rémi Lafage,Thierry Lefebvre,Nathalie Bartoli,Youssef Diouane,Joseph Morlier*

Main category: cs.AI

TL;DR: 论文探讨了在系统架构开发中，使用基于代理的优化算法（如贝叶斯优化）来解决传统物理模拟方法带来的计算复杂性和优化挑战。


<details>
  <summary>Details</summary>
Motivation: 针对系统架构开发中传统物理模拟方法的高计算成本和潜在失败问题，研究如何通过更高效的优化技术来探索新架构。

Method: 提出使用基于代理的优化算法，特别是贝叶斯优化结合高斯过程模型，以降低计算复杂性。

Result: 研究表明，基于代理的优化算法能有效减少计算成本并提高优化效率。

Conclusion: 基于代理的优化算法为系统架构开发提供了一种高效且可靠的解决方案。

Abstract: For developing innovative systems architectures, modeling and optimization
techniques have been central to frame the architecting process and define the
optimization and modeling problems. In this context, for system-of-systems the
use of efficient dedicated approaches (often physics-based simulations) is
highly recommended to reduce the computational complexity of the targeted
applications. However, exploring novel architectures using such dedicated
approaches might pose challenges for optimization algorithms, including
increased evaluation costs and potential failures. To address these challenges,
surrogate-based optimization algorithms, such as Bayesian optimization
utilizing Gaussian process models have emerged.

</details>


### [13] [A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking](https://arxiv.org/abs/2507.08207)
*Zhengye Han,Quanyan Zhu*

Main category: cs.AI

TL;DR: 本文提出了一种动态Stackelberg博弈框架，用于建模LLM越狱中的攻防交互，并引入“Purple Agent”结合RRT技术主动防御。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在关键应用中的部署增加，越狱攻击成为重要问题，需开发有效防御方法。

Method: 采用Stackelberg博弈框架，将提示-响应动态建模为顺序扩展博弈，提出结合RRT的Purple Agent进行主动防御。

Result: 框架为分析对抗动态提供了原则性方法，并能主动预防有害输出。

Conclusion: 该研究为缓解LLM越狱风险提供了理论基础和实用工具。

Abstract: As large language models (LLMs) are increasingly deployed in critical
applications, the challenge of jailbreaking, where adversaries manipulate the
models to bypass safety mechanisms, has become a significant concern. This
paper presents a dynamic Stackelberg game framework to model the interactions
between attackers and defenders in the context of LLM jailbreaking. The
framework treats the prompt-response dynamics as a sequential extensive-form
game, where the defender, as the leader, commits to a strategy while
anticipating the attacker's optimal responses. We propose a novel agentic AI
solution, the "Purple Agent," which integrates adversarial exploration and
defensive strategies using Rapidly-exploring Random Trees (RRT). The Purple
Agent actively simulates potential attack trajectories and intervenes
proactively to prevent harmful outputs. This approach offers a principled
method for analyzing adversarial dynamics and provides a foundation for
mitigating the risk of jailbreaking.

</details>


### [14] [Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions](https://arxiv.org/abs/2507.08208)
*Quanyan Zhu*

Main category: cs.AI

TL;DR: LLM-Nash框架通过游戏理论模型研究LLM驱动的决策，引入提示选择以捕捉有限理性，定义提示空间均衡，展示与传统纳什均衡的差异。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在战略交互中的有限理性行为，弥补传统游戏理论中完全理性假设的不足。

Method: 采用游戏理论模型，代理通过选择提示指导LLM决策，定义提示空间均衡。

Result: 通过示例展示推理均衡与传统纳什均衡的差异，为LLM系统战略交互提供新视角。

Conclusion: LLM-Nash框架为研究有限理性、认知约束和战略交互提供了新工具。

Abstract: We introduce the LLM-Nash framework, a game-theoretic model where agents
select reasoning prompts to guide decision-making via Large Language Models
(LLMs). Unlike classical games that assume utility-maximizing agents with full
rationality, this framework captures bounded rationality by modeling the
reasoning process explicitly. Equilibrium is defined over the prompt space,
with actions emerging as the behavioral output of LLM inference. This approach
enables the study of cognitive constraints, mindset expressiveness, and
epistemic learning. Through illustrative examples, we show how reasoning
equilibria can diverge from classical Nash outcomes, offering a new foundation
for strategic interaction in LLM-enabled systems.

</details>


### [15] [From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration](https://arxiv.org/abs/2507.08210)
*Fryderyk Mantiuk,Hanqi Zhou,Charley M. Wu*

Main category: cs.AI

TL;DR: 论文探讨了智能体如何在探索世界（好奇心）与控制环境（能力）之间取得平衡，通过比较两种模型（Tabular和Dreamer），揭示了探索与表征学习的相互作用。


<details>
  <summary>Details</summary>
Motivation: 研究智能体如何平衡好奇心（追求知识）与能力（控制环境），以理解探索行为的驱动机制。

Method: 比较了两种基于模型的智能体：Tabular（手工设计状态抽象）和Dreamer（学习内部世界模型）。

Result: Tabular智能体显示好奇心和能力引导探索的不同模式，而Dreamer智能体揭示了探索与表征学习的双向互动。

Conclusion: 研究形式化了适应性探索为追求未知与可控之间的平衡，为认知理论和强化学习提供了新见解。

Abstract: What drives an agent to explore the world while also maintaining control over
the environment? From a child at play to scientists in the lab, intelligent
agents must balance curiosity (the drive to seek knowledge) with competence
(the drive to master and control the environment). Bridging cognitive theories
of intrinsic motivation with reinforcement learning, we ask how evolving
internal representations mediate the trade-off between curiosity (novelty or
information gain) and competence (empowerment). We compare two model-based
agents using handcrafted state abstractions (Tabular) or learning an internal
world model (Dreamer). The Tabular agent shows curiosity and competence guide
exploration in distinct patterns, while prioritizing both improves exploration.
The Dreamer agent reveals a two-way interaction between exploration and
representation learning, mirroring the developmental co-evolution of curiosity
and competence. Our findings formalize adaptive exploration as a balance
between pursuing the unknown and the controllable, offering insights for
cognitive theories and efficient reinforcement learning.

</details>


### [16] [Grounding Methods for Neural-Symbolic AI](https://arxiv.org/abs/2507.08216)
*Rodrigo Castellano Ontiveros,Francesco Giannini,Marco Gori,Giuseppe Marra,Michelangelo Diligenti*

Main category: cs.AI

TL;DR: 本文提出了一种参数化的逻辑接地方法，通过广义反向链控制表达力与可扩展性的权衡，解决了传统方法在组合爆炸或启发式选择上的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统神经符号方法在逻辑接地时面临组合爆炸或缺乏理论保证的问题，需要一种更灵活且可控的方法。

Method: 提出一种参数化家族方法，广义反向链，涵盖常见接地方法，并允许控制表达力与可扩展性的平衡。

Result: 实验表明，接地准则的选择对神经符号方法的性能至关重要。

Conclusion: 参数化接地方法为神经符号推理提供了灵活性与可控性，显著提升了性能。

Abstract: A large class of Neural-Symbolic (NeSy) methods employs a machine learner to
process the input entities, while relying on a reasoner based on First-Order
Logic to represent and process more complex relationships among the entities. A
fundamental role for these methods is played by the process of logic grounding,
which determines the relevant substitutions for the logic rules using a
(sub)set of entities. Some NeSy methods use an exhaustive derivation of all
possible substitutions, preserving the full expressive power of the logic
knowledge. This leads to a combinatorial explosion in the number of ground
formulas to consider and, therefore, strongly limits their scalability. Other
methods rely on heuristic-based selective derivations, which are generally more
computationally efficient, but lack a justification and provide no guarantees
of preserving the information provided to and returned by the reasoner. Taking
inspiration from multi-hop symbolic reasoning, this paper proposes a
parametrized family of grounding methods generalizing classic Backward
Chaining. Different selections within this family allow us to obtain commonly
employed grounding methods as special cases, and to control the trade-off
between expressiveness and scalability of the reasoner. The experimental
results show that the selection of the grounding criterion is often as
important as the NeSy method itself.

</details>


### [17] [Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach](https://arxiv.org/abs/2507.08217)
*Atit Pokharel,Ratun Rahman,Thomas Morris,Dinh C. Nguyen*

Main category: cs.AI

TL;DR: 提出了一种多模态量子联邦学习方法，通过量子纠缠实现中间融合，并引入缺失模态无关机制（MMA）以提升模型稳定性。实验显示在IID和非IID数据分布下，准确率分别提高了6.84%和7.25%。


<details>
  <summary>Details</summary>
Motivation: 现有量子联邦学习（QFL）框架多为单模态，难以应对现实任务中的多模态需求，且模态缺失会影响性能。

Method: 采用多模态QFL框架，利用量子纠缠实现中间融合，并提出MMA机制隔离未训练的量子电路。

Result: 在IID和非IID数据分布下，准确率分别提升了6.84%和7.25%。

Conclusion: 多模态QFL结合MMA机制显著提升了模型性能，解决了模态缺失问题。

Abstract: Quantum federated learning (QFL) has been recently introduced to enable a
distributed privacy-preserving quantum machine learning (QML) model training
across quantum processors (clients). Despite recent research efforts, existing
QFL frameworks predominantly focus on unimodal systems, limiting their
applicability to real-world tasks that often naturally involve multiple
modalities. To fill this significant gap, we present for the first time a novel
multimodal approach specifically tailored for the QFL setting with the
intermediate fusion using quantum entanglement. Furthermore, to address a major
bottleneck in multimodal QFL, where the absence of certain modalities during
training can degrade model performance, we introduce a Missing Modality
Agnostic (MMA) mechanism that isolates untrained quantum circuits, ensuring
stable training without corrupted states. Simulation results demonstrate that
the proposed multimodal QFL method with MMA yields an improvement in accuracy
of 6.84% in independent and identically distributed (IID) and 7.25% in non-IID
data distributions compared to the state-of-the-art methods.

</details>


### [18] [Giving AI Agents Access to Cryptocurrency and Smart Contracts Creates New Vectors of AI Harm](https://arxiv.org/abs/2507.08249)
*Bill Marino,Ari Juels*

Main category: cs.AI

TL;DR: 本文探讨了赋予AI代理加密货币和智能合约访问权限可能带来的新危害，并呼吁更多技术研究以预防和减轻这些危害。


<details>
  <summary>Details</summary>
Motivation: 随着对AI代理使用加密货币和智能合约的兴趣增加，研究其潜在危害变得至关重要。

Method: 分析了加密货币和智能合约的独特属性，详细描述了可能的新危害向量。

Result: 识别了新的AI危害向量，强调了潜在风险。

Conclusion: 呼吁更多技术研究以确保AI代理安全使用加密货币和智能合约。

Abstract: There is growing interest in giving AI agents access to cryptocurrencies as
well as to the smart contracts that transact them. But doing so, this position
paper argues, could lead to formidable new vectors of AI harm. To support this
argument, we first examine the unique properties of cryptocurrencies and smart
contracts that could lead to these new vectors of harm. Next, we describe each
of these new vectors of harm in detail. Finally, we conclude with a call for
more technical research aimed at preventing and mitigating these harms and,
thereby making it safer to endow AI agents with cryptocurrencies and smart
contracts.

</details>


### [19] [Abductive Computational Systems: Creative Abduction and Future Directions](https://arxiv.org/abs/2507.08264)
*Abhinav Sood,Kazjon Grace,Stephen Wan,Cecile Paris*

Main category: cs.AI

TL;DR: 论文综述了溯因推理在认识论、科学和设计中的讨论，分析了计算系统的应用，发现理论和计算实现均未充分支持创造性假设生成。


<details>
  <summary>Details</summary>
Motivation: 探讨溯因推理在不同领域的理解差异，并评估其在计算系统中的实现情况。

Method: 综述理论文献并分析计算系统的溯因推理实现。

Result: 理论和计算系统均未能有效支持创造性溯因假设的生成。

Conclusion: 提出未来研究方向以改进计算系统中的创造性溯因推理。

Abstract: Abductive reasoning, reasoning for inferring explanations for observations,
is often mentioned in scientific, design-related and artistic contexts, but its
understanding varies across these domains. This paper reviews how abductive
reasoning is discussed in epistemology, science and design, and then analyses
how various computational systems use abductive reasoning. Our analysis shows
that neither theoretical accounts nor computational implementations of
abductive reasoning adequately address generating creative hypotheses.
Theoretical frameworks do not provide a straightforward model for generating
creative abductive hypotheses, computational systems largely implement
syllogistic forms of abductive reasoning. We break down abductive computational
systems into components and conclude by identifying specific directions for
future research that could advance the state of creative abductive reasoning in
computational systems.

</details>


### [20] [Agent Safety Alignment via Reinforcement Learning](https://arxiv.org/abs/2507.08270)
*Zeyang Sha,Hanling Tian,Zhuoer Xu,Shiwen Cui,Changhua Meng,Weiqiang Wang*

Main category: cs.AI

TL;DR: 论文提出了一种统一的安全对齐框架，用于处理使用工具的LLM代理的安全风险，包括用户和工具端的威胁。


<details>
  <summary>Details</summary>
Motivation: 自主LLM代理的工具使用带来了新的安全风险，传统对话滥用之外，还存在用户和工具端的威胁。

Method: 提出了一种三模态分类法（良性、恶意、敏感），结合结构化推理和沙盒强化学习，设计了策略驱动的决策模型。

Result: 在多个基准测试中，安全对齐的代理显著提高了对安全威胁的抵抗能力，同时保持了良性任务的高效性。

Conclusion: 安全与有效性可以共同优化，为自主LLM代理的可信部署奠定了基础。

Abstract: The emergence of autonomous Large Language Model (LLM) agents capable of tool
usage has introduced new safety risks that go beyond traditional conversational
misuse. These agents, empowered to execute external functions, are vulnerable
to both user-initiated threats (e.g., adversarial prompts) and tool-initiated
threats (e.g., malicious outputs from compromised tools). In this paper, we
propose the first unified safety-alignment framework for tool-using agents,
enabling models to handle both channels of threat via structured reasoning and
sandboxed reinforcement learning. We introduce a tri-modal taxonomy, including
benign, malicious, and sensitive for both user prompts and tool responses, and
define a policy-driven decision model. Our framework employs a custom-designed
sandbox environment that simulates real-world tool execution and allows
fine-grained reward shaping. Through extensive evaluations on public and
self-built benchmarks, including Agent SafetyBench, InjecAgent, and BFCL, we
demonstrate that our safety-aligned agents significantly improve resistance to
security threats while preserving strong utility on benign tasks. Our results
show that safety and effectiveness can be jointly optimized, laying the
groundwork for trustworthy deployment of autonomous LLM agents.

</details>


### [21] [M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning](https://arxiv.org/abs/2507.08306)
*Inclusion AI,:,Fudong Wang,Jiajia Liu,Jingdong Chen,Jun Zhou,Kaixiang Ji,Lixiang Ru,Qingpei Guo,Ruobing Zheng,Tianqi Li,Yi Yuan,Yifan Mao,Yuting Xiao,Ziping Ma*

Main category: cs.AI

TL;DR: M2-Reasoning-7B模型通过高质量数据和动态多任务训练策略，提升了多模态大语言模型在动态空间交互中的推理能力，并在8个基准测试中达到新SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在动态空间交互能力上存在不足，限制了实际应用。

Method: 提出M2-Reasoning-7B，结合高质量数据生成（294.2K样本）和动态多任务训练策略（任务特定奖励）。

Result: 在8个基准测试中达到新SOTA，尤其在通用和空间推理领域表现优异。

Conclusion: M2-Reasoning-7B通过数据与训练策略的创新，显著提升了模型在动态空间交互中的能力。

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs), particularly
through Reinforcement Learning with Verifiable Rewards (RLVR), have
significantly enhanced their reasoning abilities. However, a critical gap
persists: these models struggle with dynamic spatial interactions, a capability
essential for real-world applications. To bridge this gap, we introduce
M2-Reasoning-7B, a model designed to excel in both general and spatial
reasoning. Our approach integrates two key innovations: (1) a novel data
pipeline that generates 294.2K high-quality data samples (168K for cold-start
fine-tuning and 126.2K for RLVR), which feature logically coherent reasoning
trajectories and have undergone comprehensive assessment; and (2) a dynamic
multi-task training strategy with step-wise optimization to mitigate conflicts
between data, and task-specific rewards for delivering tailored incentive
signals. This combination of curated data and advanced training allows
M2-Reasoning-7B to set a new state-of-the-art (SOTA) across 8 benchmarks,
showcasing superior performance in both general and spatial reasoning domains.

</details>


### [22] [Multi-Agent LLMs as Ethics Advocates in AI-Based Systems](https://arxiv.org/abs/2507.08392)
*Asma Yamani,Malak Baslyman,Moataz Ahmed*

Main category: cs.AI

TL;DR: 论文提出了一种在多智能体LLM环境中引入伦理倡导代理的框架，用于生成伦理需求草稿，并通过案例研究验证其有效性，同时指出需要人工反馈以提高可靠性。


<details>
  <summary>Details</summary>
Motivation: 由于时间和资源限制，手动获取伦理需求具有挑战性且优先级较低，因此需要一种自动化方法来促进伦理需求的生成。

Method: 在多智能体LLM环境中引入伦理倡导代理，根据系统描述提供伦理问题的批评和输入，生成伦理需求草稿。

Result: 案例研究表明，该框架能捕捉大部分研究人员在30分钟访谈中识别的伦理需求，并引入额外相关需求，但也存在可靠性问题。

Conclusion: 该框架有助于在需求工程中更广泛地采用伦理考量，但需结合人工反馈以确保可靠性。

Abstract: Incorporating ethics into the requirement elicitation process is essential
for creating ethically aligned systems. Although eliciting manual ethics
requirements is effective, it requires diverse input from multiple
stakeholders, which can be challenging due to time and resource constraints.
Moreover, it is often given a low priority in the requirements elicitation
process. This study proposes a framework for generating ethics requirements
drafts by introducing an ethics advocate agent in a multi-agent LLM setting.
This agent critiques and provides input on ethical issues based on the system
description. The proposed framework is evaluated through two case studies from
different contexts, demonstrating that it captures the majority of ethics
requirements identified by researchers during 30-minute interviews and
introduces several additional relevant requirements. However, it also
highlights reliability issues in generating ethics requirements, emphasizing
the need for human feedback in this sensitive domain. We believe this work can
facilitate the broader adoption of ethics in the requirements engineering
process, ultimately leading to more ethically aligned products.

</details>


### [23] [Why this and not that? A Logic-based Framework for Contrastive Explanations](https://arxiv.org/abs/2507.08454)
*Tobias Geibinger,Reijo Jaakkola,Antti Kuusisto,Xinghan Liu,Miikka Vilander*

Main category: cs.AI

TL;DR: 论文定义了与对比解释相关的几个典型问题，研究其基本性质、计算复杂性，并通过实例展示其实际应用。


<details>
  <summary>Details</summary>
Motivation: 解决对比解释问题（如“为什么是P而不是Q？”），明确比较P和Q的差异。

Method: 在命题逻辑中定义问题，分析其计算复杂性，并使用答案集编程实现CNF公式的解决方案。

Result: 框架捕捉了文献中对比解释的基数最小版本，并提供了计算复杂性的详细分析。

Conclusion: 提出的框架有效解决了对比解释问题，并通过实例验证了其实际可行性。

Abstract: We define several canonical problems related to contrastive explanations,
each answering a question of the form ''Why P but not Q?''. The problems
compute causes for both P and Q, explicitly comparing their differences. We
investigate the basic properties of our definitions in the setting of
propositional logic. We show, inter alia, that our framework captures a
cardinality-minimal version of existing contrastive explanations in the
literature. Furthermore, we provide an extensive analysis of the computational
complexities of the problems. We also implement the problems for CNF-formulas
using answer set programming and present several examples demonstrating how
they work in practice.

</details>


### [24] [From Language to Logic: A Bi-Level Framework for Structured Reasoning](https://arxiv.org/abs/2507.08501)
*Keying Yang,Hao Wang,Kai Yang*

Main category: cs.AI

TL;DR: 提出了一种双层框架，通过任务抽象和逻辑生成两阶段将自然语言映射到逻辑表示，显著提升了推理准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言输入到形式逻辑表示的转换问题，以实现准确且可解释的推理。

Method: 采用双层框架：高层任务抽象和低层逻辑生成，结合端到端优化方法。

Result: 在多个基准测试中，准确率提升高达40%，同时增强了透明度和错误可追溯性。

Conclusion: 该框架为LLM的可信和系统性推理提供了有效途径。

Abstract: Structured reasoning over natural language inputs remains a core challenge in
artificial intelligence, as it requires bridging the gap between unstructured
linguistic expressions and formal logical representations. In this paper, we
propose a novel \textbf{bi-level framework} that maps language to logic through
a two-stage process: high-level task abstraction and low-level logic
generation. At the upper level, a large language model (LLM) parses natural
language queries into intermediate structured representations specifying the
problem type, objectives, decision variables, and symbolic constraints. At the
lower level, the LLM uses these representations to generate symbolic workflows
or executable reasoning programs for accurate and interpretable decision
making. The framework supports modular reasoning, enforces explicit
constraints, and generalizes across domains such as mathematical problem
solving, question answering, and logical inference. We further optimize the
framework with an end-to-end {bi-level} optimization approach that jointly
refines both the high-level abstraction and low-level logic generation stages.
Experiments on multiple realistic reasoning benchmarks demonstrate that our
approach significantly outperforms existing baselines in accuracy, with
accuracy gains reaching as high as 40\%. Moreover, the bi-level design enhances
transparency and error traceability, offering a promising step toward
trustworthy and systematic reasoning with LLMs.

</details>


### [25] [A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis](https://arxiv.org/abs/2507.08529)
*Mingda Zhang,Na Zhao,Jianglong Qin,Guoyu Ye,Ruixiang Tang*

Main category: cs.AI

TL;DR: 提出了一种结合多粒度稀疏激活和分层知识图谱的框架，用于罕见病诊断，实验显示性能提升，接近临床阈值。


<details>
  <summary>Details</summary>
Motivation: 罕见病诊断因知识表示不足、概念理解有限和临床推理受限而受阻，需改进。

Method: 采用多粒度稀疏激活、分层知识图谱（分类、临床特征、实例）、四种匹配算法、多样性控制和五级回退策略。

Result: 在BioASQ罕见病QA集上，BLEU提升0.09，ROUGE提升0.05，准确率提升0.12，峰值准确率0.89接近临床阈值0.90。

Conclusion: 该方法提高了信息质量、推理能力和专业表达，有望缩短罕见病患者的诊断时间。

Abstract: Despite advances from medical large language models in healthcare,
rare-disease diagnosis remains hampered by insufficient
knowledge-representation depth, limited concept understanding, and constrained
clinical reasoning. We propose a framework that couples multi-granularity
sparse activation of medical concepts with a hierarchical knowledge graph. Four
complementary matching algorithms, diversity control, and a five-level fallback
strategy enable precise concept activation, while a three-layer knowledge graph
(taxonomy, clinical features, instances) provides structured, up-to-date
context. Experiments on the BioASQ rare-disease QA set show BLEU gains of 0.09,
ROUGE gains of 0.05, and accuracy gains of 0.12, with peak accuracy of 0.89
approaching the 0.90 clinical threshold. Expert evaluation confirms
improvements in information quality, reasoning, and professional expression,
suggesting our approach shortens the "diagnostic odyssey" for rare-disease
patients.

</details>


### [26] [Large Multi-modal Model Cartographic Map Comprehension for Textual Locality Georeferencing](https://arxiv.org/abs/2507.08575)
*Kalana Wijegunarathna,Kristin Stock,Christopher B. Jones*

Main category: cs.AI

TL;DR: 论文提出了一种利用多模态大模型（LMM）自动地理参考生物样本记录的新方法，通过视觉上下文理解空间关系，实验结果显示其优于单模态方法和现有工具。


<details>
  <summary>Details</summary>
Motivation: 解决自然历史收藏中大量未地理参考的生物样本记录问题，传统方法劳动密集且效率低。

Method: 采用网格化方法，利用多模态大模型（LMM）在零样本设置下进行地理参考，结合视觉和文本信息。

Result: 实验显示该方法平均距离误差约为1公里，优于单模态语言模型和现有工具。

Conclusion: 多模态大模型在理解精细地图方面表现优异，论文提出了将其整合到地理参考工作流程的实用框架。

Abstract: Millions of biological sample records collected in the last few centuries
archived in natural history collections are un-georeferenced. Georeferencing
complex locality descriptions associated with these collection samples is a
highly labour-intensive task collection agencies struggle with. None of the
existing automated methods exploit maps that are an essential tool for
georeferencing complex relations. We present preliminary experiments and
results of a novel method that exploits multi-modal capabilities of recent
Large Multi-Modal Models (LMM). This method enables the model to visually
contextualize spatial relations it reads in the locality description. We use a
grid-based approach to adapt these auto-regressive models for this task in a
zero-shot setting. Our experiments conducted on a small manually annotated
dataset show impressive results for our approach ($\sim$1 km Average distance
error) compared to uni-modal georeferencing with Large Language Models and
existing georeferencing tools. The paper also discusses the findings of the
experiments in light of an LMM's ability to comprehend fine-grained maps.
Motivated by these results, a practical framework is proposed to integrate this
method into a georeferencing workflow.

</details>


### [27] [Unlocking Speech Instruction Data Potential with Query Rewriting](https://arxiv.org/abs/2507.08603)
*Yonghua Hei,Yibo Yan,Shuliang Liu,Huiyu Zhou,Linfeng Zhang,Xuming Hu*

Main category: cs.AI

TL;DR: 论文提出了一种基于多LLM知识融合的查询重写框架，用于构建高质量语音指令数据集，解决了TTS模型在分布外文本指令转换中的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前语音指令数据集的缺乏和训练任务的偏差限制了大型语音语言模型（LSLMs）的指令跟随能力，而人工标注成本高，合成语音成为替代方案。但TTS模型在分布外文本指令转换中存在困难。

Method: 提出多LLM知识融合的查询重写框架，通过多智能体标注和验证合成语音，无需人工标注即可构建高质量语音指令数据集。

Result: 实验表明，该方法通过零样本重写将数据可用性从72%提升至93%，并在复杂知识和上下文相关任务中表现优异。

Conclusion: 该方法为构建高质量语音指令数据集提供了高效且低成本的解决方案，显著提升了TTS模型的适用性。

Abstract: End-to-end Large Speech Language Models~(\textbf{LSLMs}) demonstrate strong
potential in response latency and speech comprehension capabilities, showcasing
general intelligence across speech understanding tasks. However, the ability to
follow speech instructions has not been fully realized due to the lack of
datasets and heavily biased training tasks. Leveraging the rich ASR datasets,
previous approaches have used Large Language Models~(\textbf{LLMs}) to continue
the linguistic information of speech to construct speech instruction datasets.
Yet, due to the gap between LLM-generated results and real human responses, the
continuation methods further amplify these shortcomings. Given the high costs
of collecting and annotating speech instruction datasets by humans, using
speech synthesis to construct large-scale speech instruction datasets has
become a balanced and robust alternative. Although modern
Text-To-Speech~(\textbf{TTS}) models have achieved near-human-level synthesis
quality, it is challenging to appropriately convert out-of-distribution text
instruction to speech due to the limitations of the training data distribution
in TTS models. To address this issue, we propose a query rewriting framework
with multi-LLM knowledge fusion, employing multiple agents to annotate and
validate the synthesized speech, making it possible to construct high-quality
speech instruction datasets without relying on human annotation. Experiments
show that this method can transform text instructions into distributions more
suitable for TTS models for speech synthesis through zero-shot rewriting,
increasing data usability from 72\% to 93\%. It also demonstrates unique
advantages in rewriting tasks that require complex knowledge and
context-related abilities.

</details>


### [28] [Agentic Large Language Models for Conceptual Systems Engineering and Design](https://arxiv.org/abs/2507.08619)
*Soheyl Massoudi,Mark Fuge*

Main category: cs.AI

TL;DR: 论文研究了多智能体系统（MAS）在早期工程设计中的表现，比较了其与双智能体系统（2AS）在需求提取、功能分解和代码生成方面的效果。结果显示MAS在生成更细粒度的设计状态图（DSG）方面表现更好，但需求覆盖率和代码兼容性仍有不足。


<details>
  <summary>Details</summary>
Motivation: 早期工程设计涉及复杂的迭代推理，现有的大语言模型（LLM）工作流难以保持任务连续性和生成可执行模型。研究旨在评估结构化多智能体系统是否能更有效地管理设计流程。

Method: 通过设计状态图（DSG）表示需求、物理实现和Python物理模型，比较九角色MAS与双角色2AS的表现。实验使用两种LLM（Llama 3.3 70B和DeepSeek R1 70B），在不同配置下运行60次实验。

Result: MAS在生成细粒度DSG方面优于2AS，但需求覆盖率低（<20%）。代码兼容性在特定2AS设置下达到100%，但MAS平均低于50%。DeepSeek R1 70B能可靠标记工作流完成。

Conclusion: 结构化多智能体编排提升了设计细节，推理蒸馏的LLM提高了完成率，但需求覆盖和代码保真度仍需改进。

Abstract: Early-stage engineering design involves complex, iterative reasoning, yet
existing large language model (LLM) workflows struggle to maintain task
continuity and generate executable models. We evaluate whether a structured
multi-agent system (MAS) can more effectively manage requirements extraction,
functional decomposition, and simulator code generation than a simpler
two-agent system (2AS). The target application is a solar-powered water
filtration system as described in a cahier des charges. We introduce the
Design-State Graph (DSG), a JSON-serializable representation that bundles
requirements, physical embodiments, and Python-based physics models into graph
nodes. A nine-role MAS iteratively builds and refines the DSG, while the 2AS
collapses the process to a Generator-Reflector loop. Both systems run a total
of 60 experiments (2 LLMs - Llama 3.3 70B vs reasoning-distilled DeepSeek R1
70B x 2 agent configurations x 3 temperatures x 5 seeds). We report a JSON
validity, requirement coverage, embodiment presence, code compatibility,
workflow completion, runtime, and graph size. Across all runs, both MAS and 2AS
maintained perfect JSON integrity and embodiment tagging. Requirement coverage
remained minimal (less than 20\%). Code compatibility peaked at 100\% under
specific 2AS settings but averaged below 50\% for MAS. Only the
reasoning-distilled model reliably flagged workflow completion. Powered by
DeepSeek R1 70B, the MAS generated more granular DSGs (average 5-6 nodes)
whereas 2AS mode-collapsed. Structured multi-agent orchestration enhanced
design detail. Reasoning-distilled LLM improved completion rates, yet low
requirements and fidelity gaps in coding persisted.

</details>


### [29] [Leanabell-Prover-V2: Verifier-integrated Reasoning for Formal Theorem Proving via Reinforcement Learning](https://arxiv.org/abs/2507.08649)
*Xingguang Ji,Yahui Liu,Qi Wang,Jingyuan Zhang,Yang Yue,Rui Shi,Chenxi Sun,Fuzheng Zhang,Guorui Zhou,Kun Gai*

Main category: cs.AI

TL;DR: Leanabell-Prover-V2是一个7B参数的大型语言模型，用于在Lean 4中生成形式化定理证明，通过验证器集成的长链思维（CoT）优化性能。


<details>
  <summary>Details</summary>
Motivation: 在Leanabell-Prover-V1的基础上，进一步优化模型性能，特别是通过验证器反馈提升推理能力。

Method: 采用强化学习（RL）结合Lean 4验证器反馈，包括错误指示和成功确认，使模型能够自我修正推理错误。同时使用反馈令牌掩码和简单奖励策略。

Result: 在MiniF2F测试集上，性能分别提升了3.2%（Kimina-Prover-Preview-Distill-7B）和2.0%（DeepSeek-Prover-V2-7B）。

Conclusion: Leanabell-Prover-V2通过验证器反馈和强化学习显著提升了形式化定理证明的性能。

Abstract: We introduce our Leanabell-Prover-V2, a 7B large language models (LLMs) that
can produce formal theorem proofs in Lean 4, with verifier-integrated Long
Chain-of-Thoughts (CoT). Following our previous work Leanabell-Prover-V1, we
continual to choose to posttrain existing strong prover models for further
performance improvement. In our V2 version, we mainly upgrade the Reinforcement
Learning (RL) with feedback provided by the Lean 4 verifier. Crucially,
verifier feedback, such as indicating success or detailing specific errors,
allows the LLM to become ``self-aware'' of the correctness of its own reasoning
process and learn to reflexively correct errors. Leanabell-Prover-V2 directly
optimizes LLM reasoning trajectories with multi-turn verifier interactions,
together with feedback token masking for stable RL training and a simple reward
strategy. Experiments show that Leanabell-Prover-V2 improves performance by
3.2% (pass@128) with Kimina-Prover-Preview-Distill-7B and 2.0% (pass@128) with
DeepSeek-Prover-V2-7B on the MiniF2F test set. The source codes, curated data
and models are available at:
https://github.com/Leanabell-LM/Leanabell-Prover-V2.

</details>


### [30] [Introspection of Thought Helps AI Agents](https://arxiv.org/abs/2507.08664)
*Haoran Sun,Shaoning Zeng*

Main category: cs.AI

TL;DR: 提出了一种名为INoT的新型AI代理推理框架，通过设计LLM可读的提示代码，减少推理成本并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理依赖LLMs和MLLMs，但其推理过程成本高且受限于语言理解能力。

Method: 设计LLM-Read代码提示，使LLM在内部执行程序化对话推理，减少外部迭代成本。

Result: 在六个基准测试中，性能平均提升7.95%，推理成本降低58.3%。

Conclusion: INoT框架在性能和成本上均优于基线方法，并展示了在图像任务中的通用性。

Abstract: AI Agents rely on Large Language Models (LLMs) and Multimodal-LLMs (MLLMs) to
perform interpretation and inference in text and image tasks without
post-training, where LLMs and MLLMs play the most critical role and determine
the initial ability and limitations of AI Agents. Usually, AI Agents utilize
sophisticated prompt engineering and external reasoning framework to obtain a
promising interaction with LLMs, e.g., Chain-of-Thought, Iteration of Thought
and Image-of-Thought. However, they are still constrained by the inherent
limitations of LLM in understanding natural language, and the iterative
reasoning process will generate a large amount of inference cost. To this end,
we propose a novel AI Agent Reasoning Framework with Introspection of Thought
(INoT) by designing a new LLM-Read code in prompt. It enables LLM to execute
programmatic dialogue reasoning processes following the code in prompt.
Therefore, self-denial and reflection occur within LLM instead of outside LLM,
which can reduce token cost effectively. Through our experiments on six
benchmarks for three different tasks, the effectiveness of INoT is verified,
with an average improvement of 7.95\% in performance, exceeding the baselines.
Furthermore, the token cost of INoT is lower on average than the best
performing method at baseline by 58.3\%. In addition, we demonstrate the
versatility of INoT in image interpretation and inference through verification
experiments.

</details>


### [31] [elsciRL: Integrating Language Solutions into Reinforcement Learning Problem Settings](https://arxiv.org/abs/2507.08705)
*Philip Osborne,Danilo S. Carvalho,André Freitas*

Main category: cs.AI

TL;DR: elsciRL是一个开源Python库，用于在强化学习问题中应用语言解决方案。通过结合LLMs扩展了现有框架，并提供了易于使用的GUI。实验表明，生成的指令可以提升强化学习代理的性能。


<details>
  <summary>Details</summary>
Motivation: 加速语言解决方案在奖励环境中的评估，为科学发现提供新机会。

Method: 扩展了Language Adapter with Self-Completing Instruction框架，结合LLMs生成指令，并提供GUI支持用户输入文本。

Result: 生成的指令能够提升强化学习代理的性能。

Conclusion: elsciRL为语言解决方案在强化学习中的应用提供了便捷工具，具有广泛的应用潜力。

Abstract: We present elsciRL, an open-source Python library to facilitate the
application of language solutions on reinforcement learning problems. We
demonstrate the potential of our software by extending the Language Adapter
with Self-Completing Instruction framework defined in (Osborne, 2024) with the
use of LLMs. Our approach can be re-applied to new applications with minimal
setup requirements. We provide a novel GUI that allows a user to provide text
input for an LLM to generate instructions which it can then self-complete.
Empirical results indicate that these instructions \textit{can} improve a
reinforcement learning agent's performance. Therefore, we present this work to
accelerate the evaluation of language solutions on reward based environments to
enable new opportunities for scientific discovery.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [32] [New constructions of $2$-to-$1$ mappings over $\gf_{2^n}$ and their applications to binary linear codes](https://arxiv.org/abs/2507.08315)
*Yaqin Li,Kangquan Li,Qiancheng Zhang*

Main category: cs.IT

TL;DR: 本文总结了有限域上2-to-1映射的构造方法，并应用广义切换方法提出了16类新的2-to-1映射，其中9类为单项式形式，7类为二项式形式。这些新映射在编码理论中应用，构造了自正交、极小且少权的二进制线性码。


<details>
  <summary>Details</summary>
Motivation: 2-to-1映射在组合数学和编码理论中有广泛应用，但现有构造方法有限，因此需要探索新的构造方式。

Method: 采用广义切换方法，结合Dickson多项式理论和低次方程性质，构造了16类新的2-to-1映射。

Result: 提出了16类新的2-to-1映射，并利用这些映射构造了自正交、极小且少权的二进制线性码。

Conclusion: 新构造的2-to-1映射丰富了现有理论，并在编码理论中展示了实际应用价值。

Abstract: The $2$-to-$1$ mapping over finite fields has a wide range of applications,
including combinatorial mathematics and coding theory. Thus, constructions of
$2$-to-$1$ mappings have attracted considerable attention recently. Based on
summarizing the existing construction results of all $2$-to-$1$ mappings over
finite fields with even characteristic, this article first applies the
generalized switching method to the study of $2$-to-$1$ mappings, that is, to
construct $2$-to-$1$ mappings over the finite field $\mathbb{F}_{q^l}$ with
$F(x)=G(x)+{\rm Tr}_{q^l/q}(R(x))$, where $G$ is a monomial and $R$ is a
monomial or binomial. Using the properties of Dickson polynomial theory and the
complete characterization of low-degree equations, we construct a total of $16$
new classes of $2$-to-$1$ mappings, which are not QM-equivalent to any existing
$2$-to-$1$ polynomials. Among these, $9$ classes are of the form $cx + {\rm
Tr}_{q^l/q}(x^d)$, and $7$ classes have the form $cx + {\rm Tr}_{q^l/q}(x^{d_1}
+ x^{d_2})$. These new infinite classes explain most of numerical results by
MAGMA under the conditions that $q=2^k$, $k>1$, $kl<14$ and $c \in
\gf_{q^l}^*$. Finally, we construct some binary linear codes using the newly
proposed $2$-to-$1$ mappings of the form $cx + {\rm Tr}_{q^l/q}(x^d)$. The
weight distributions of these codes are also determined. Interestingly, our
codes are self-orthogonal, minimal, and have few weights.

</details>


### [33] [Secrecy Offloading Analysis of UAV-assisted NOMA-MEC Incorporating WPT in IoT Networks](https://arxiv.org/abs/2507.08352)
*Gia-Huy Nguyen,Anh-Nhat Nguyen,Minh-Sang Nguyen,Khai Nguyen,Tung-Son Ngo,Ngoc-Anh Bui,Phuong-Chi Le,Manh-Duc Hoang*

Main category: cs.IT

TL;DR: 研究了无人机辅助的非正交多址接入（NOMA）与移动边缘计算（MEC）结合的物联网网络中无线能量传输（WPT）对数据卸载效率的影响。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限的边缘设备（EDs）在被动窃听者干扰下的数据卸载问题，利用无人机的双重角色（计算平台和能量供应站）提升效率。

Method: 推导了Nakagami-m衰落信道下的保密成功计算概率（SSCP）闭式表达式，并通过多种参数验证分析精度。

Result: 理论结果验证了无人机双重角色在提升数据卸载效率和安全性方面的有效性。

Conclusion: 无人机在NOMA-MEC-WPT系统中能显著提升资源受限设备的计算效率和安全性。

Abstract: This article studies the efficiency of secrecy data offloading for an
unmanned aerial vehicle (UAV)-assisted nonorthogonal multiple access
(NOMA)-integrated mobile-edge computing (MEC) incorporating wireless power
transfer (WPT) within an Internet of Things (IoT) network. Specifically, this
study assumes an UAV to function in dual roles: as a mobile computation
platform and as an aerial power-supply station, offering substantial advantages
for resource-constrained edge devices (EDs) in mitigating interference from an
passive eavesdropper. To assess the system's secrecy offloading efficacy, the
secrecy successful computation probability (SSCP) closed-formed formulation
under Nakagami-m fading channel is derived. The theoretical results are
conducted with a variety of parameters, thereby validating the precision of our
analysis.

</details>


### [34] [Discovering the Unequal Importance of Coded Bits in the Decoding of Polar Codes](https://arxiv.org/abs/2507.08598)
*Hossam Hassan,Ali Gaber,Mohammed Karmoose,Noha Korany*

Main category: cs.IT

TL;DR: 本文研究了极化码中编码比特在解码过程中的重要性，并通过暴力搜索和代理优化技术确定关键比特，展示了如何将这些比特映射到可靠信道以提升性能。


<details>
  <summary>Details</summary>
Motivation: 极化码因其容量逼近特性在现代通信系统中广泛应用，但解码过程中哪些比特对成功解码贡献最大尚不明确。

Method: 采用暴力搜索和代理优化技术识别关键编码比特，并将其映射到最可靠的信道。

Result: 在OFDM系统中，提出的比特映射方法可将BER性能提升高达7倍。

Conclusion: 通过优化比特映射，可以显著提升极化码解码性能，且额外成本极低。

Abstract: Polar codes are widely used in modern communication systems due to their
capacity-achieving properties. This paper investigates the importance of coded
bits in the decoding process of polar codes and aims to determine which bits
contribute most to successful decoding. We investigate the problem via a
brute-force search approach and surrogate optimization techniques to identify
the most critical coded bits. We also demonstrate how mapping these important
bits to the most reliable channels improves system performance with minimal
additional cost. We show the performance of our proposed bit mapping in OFDM
based systems, and demonstrate up to x7 gain in BER performance.

</details>


### [35] [Learning to Transmit Over Unknown Erasure Channels with Empirical Erasure Rate Feedback](https://arxiv.org/abs/2507.08599)
*Haricharan Balasundaram,Krishna Jagannathan*

Main category: cs.IT

TL;DR: 论文研究了在有限时间T内通过未知擦除概率的二进制擦除信道进行可靠数据传输的问题，提出了两种策略以最小化遗憾值。


<details>
  <summary>Details</summary>
Motivation: 解决在未知擦除概率的信道中，如何平衡学习和传输以实现可靠数据传输的问题。

Method: 提出了两种策略：(1) 两阶段方法，先估计擦除概率再传输；(2) 几何递增窗口策略。

Result: 第一种策略使用一次查询达到O(T^(2/3))遗憾，第二种策略使用O(log(T))查询达到O(√T)遗憾。

Conclusion: 两种策略在不同查询复杂度下均能有效减少遗憾值，为未知信道下的数据传输提供了实用解决方案。

Abstract: We address the problem of reliable data transmission within a finite time
horizon $T$ over a binary erasure channel with unknown erasure probability. We
consider a feedback model wherein the transmitter can query the receiver
infrequently and obtain the empirical erasure rate experienced by the latter.
We aim to minimize a regret quantity, i.e. how much worse a strategy performs
compared to an oracle who knows the probability of erasure, while operating at
the same block error rate. A learning vs. exploitation dilemma manifests in
this scenario -- specifically, we need to balance between (i) learning the
erasure probability with reasonable accuracy and (ii) utilizing the channel to
transmit as many information bits as possible. We propose two strategies: (i) a
two-phase approach using rate estimation followed by transmission that achieves
an $O({T}^{\frac 23})$ regret using only one query, and (ii) a windowing
strategy using geometrically-increasing window sizes that achieves an
$O({\sqrt{T}})$ regret using $O(\log(T))$ queries.

</details>


### [36] [Evaluating the Performance of Reconfigurable Intelligent Base Stations through Ray Tracing](https://arxiv.org/abs/2507.08611)
*Sina Beyraghi,Giovanni Interdonato,Giovanni Geraci,Stefano Buzzi,Angel Lozano*

Main category: cs.IT

TL;DR: 论文提出了一种基于可重构智能基站（RIBS）的新型mMIMO系统，通过减少射频链数量实现与传统mMIMO阵列相当的性能，并使用SIONNA射线追踪模块评估其性能。


<details>
  <summary>Details</summary>
Motivation: 5G无线系统中，mMIMO是提升容量的关键技术，但传统系统需要大量射频链。RIBS通过可重构智能表面减少射频链数量，同时保持性能，因此需要评估其实际表现。

Method: 使用SIONNA射线追踪模块和统计3GPP信道模型对比RIBS性能，优化功率和RIS配置以最大化频谱效率。

Result: 射线追踪预测的性能优于统计模型，表明站点特定建模的潜力。

Conclusion: RIBS在减少射频链的同时性能接近传统mMIMO，但需进一步实证验证射线追踪的优势。

Abstract: Massive multiple-input multiple-output (mMIMO) is a key capacity-boosting
technology in 5G wireless systems. To reduce the number of radio frequency (RF)
chains needed in such systems, a novel approach has recently been introduced
involving an antenna array supported by a reconfigurable intelligent surface.
This arrangement, known as a reconfigurable intelligent base station (RIBS),
offers performance comparable to that of a traditional mMIMO array, but with
significantly fewer RF chains. Given the growing importance of precise,
location-specific performance prediction, this paper evaluates the performance
of an RIBS system by means of the SIONNA ray-tracing module. That performance
is contrasted against results derived from a statistical 3GPP-compliant channel
model, optimizing power and RIS configuration to maximize the sum spectral
efficiency. Ray tracing predicts better performance than the statistical model
in the evaluated scenario, suggesting the potential of site-specific modeling.
However, empirical validation is needed to confirm this advantage.

</details>


### [37] [Fine-tuning ORBGRAND with Very Few Channel Soft Values](https://arxiv.org/abs/2507.08696)
*Li Wan,Huarui Yin,Wenyi Zhang*

Main category: cs.IT

TL;DR: 提出了一种改进ORBGRAND的方法，通过少量精确信道软值调整测试顺序，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 结合最大似然解码的高性能和ORBGRAND的高效实现，解决有限长码性能损失问题。

Method: 基于整数划分理论设计度量标准，评估错误模式的顺序性，并通过少量软值调整测试顺序。

Result: 数值实验表明，该方法显著提升了ORBGRAND的性能。

Conclusion: 提出的微调方法在复杂度几乎不增加的情况下，有效提升了解码性能。

Abstract: Guessing random additive noise decoding (GRAND) is a universal decoding
paradigm that decodes by repeatedly testing error patterns until identifying a
codeword, where the ordering of tests is generated by the received channel
values. On one hand, while testing error patterns in a descending order of
posterior probabilities leads to maximum likelihood decoding, its
implementation complexity is prohibitive. On the other hand, testing error
patterns with a prescribed set of error patterns permuted by the ranking among
magnitudes of log-likelihood ratios (i.e., ordered reliability bits, ORB)
enables efficient implementation, but results in performance loss for
finite-length codes. Aiming at harnessing the strengths of these two
approaches, this work proposes a fine-tuning method to improve ORBGRAND,
adjusting the ordering of tests with the aid of very few exact channel soft
values. This method is based on a metric for assessing the ``well-orderedness''
of error patterns. The metric is studied via the lens of the asymptotic theory
of integer partitioning, which provides highly accurate estimation in numerical
experiments. The metric then leads to an effective identification of
fine-tuning to conduct, at the cost of a negligible increment of complexity.
Numerical experiments demonstrate that the proposed fine-tuning method achieves
a substantial performance enhancement compared with ORBGRAND.

</details>


### [38] [Column Twisted Reed-Solomon Codes as MDS Codes](https://arxiv.org/abs/2507.08755)
*Wei Liu,Jinquan Luo,Puyin Wang,Dengxin Zhai*

Main category: cs.IT

TL;DR: 研究了列扭曲Reed-Solomon（TRS）码，提出了其成为MDS码的条件，并证明其Schur平方码的维数为2k，表明TRS码与RS码不等价。构造方法比之前的TGRS码更灵活，码长可达(q+3)/2。


<details>
  <summary>Details</summary>
Motivation: 探索一种新的构造MDS码的方法，通过向RS码的生成矩阵添加列向量，提供更灵活的码参数。

Method: 研究了列TRS码的性质，建立了其成为MDS码的条件，并分析了其Schur平方码的维数。

Result: 证明了TRS码与RS码不等价，且构造的码长可达(q+3)/2，优于之前的TGRS码。

Conclusion: 提供了一种新的构造MDS码的方法，扩展了码的参数范围，具有实际应用潜力。

Abstract: In this paper, we study column twisted Reed-Solomon(TRS) codes. We establish
some conditions for column TRS codes to be MDS codes and show that the
dimension of their Schur square codes is $2k$. Consequently, these TRS codes
are not equivalent to Reed-Solomon(RS) codes. Moreover, this construction
method provides more flexible parameters compared to previous twisted
generalized Reed-Solomon(TGRS) code constructions. For large odd prime power
$q$, different from the systematically constructed TGRS codes whose length was
previously limited to $\frac{q+1}{2}$, our construction achieves code lengths
up to $\frac{q+3}{2}$. Finally, we present the dual codes of column TRS codes.
This paper provides a new approach to construct MDS codes by adding column
vectors to generator matrix of RS codes.

</details>
