{"id": "2511.04630", "categories": ["cs.IT", "cs.NI", "cs.SY", "eess.SP", "eess.SY", "math.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.04630", "abs": "https://arxiv.org/abs/2511.04630", "authors": ["Stavros Mitrolaris", "Subhankar Banerjee", "Sennur Ulukus"], "title": "Age of Job Completion Minimization with Stable Queues", "comment": null, "summary": "We consider a time-slotted job-assignment system with a central server, N\nusers and a machine which changes its state according to a Markov chain (hence\ncalled a Markov machine). The users submit their jobs to the central server\naccording to a stochastic job arrival process. For each user, the server has a\ndedicated job queue. Upon receiving a job from a user, the server stores that\njob in the corresponding queue. When the machine is not working on a job\nassigned by the server, the machine can be either in internally busy or in free\nstate, and the dynamics of these states follow a binary symmetric Markov chain.\nUpon sampling the state information of the machine, if the server identifies\nthat the machine is in the free state, it schedules a user and submits a job to\nthe machine from the job queue of the scheduled user. To maximize the number of\njobs completed per unit time, we introduce a new metric, referred to as the age\nof job completion. To minimize the age of job completion and the sampling cost,\nwe propose two policies and numerically evaluate their performance. For both of\nthese policies, we find sufficient conditions under which the job queues will\nremain stable.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u4e2a\u5177\u6709\u9a6c\u5c14\u53ef\u592b\u72b6\u6001\u673a\u5668\u7684\u4f5c\u4e1a\u5206\u914d\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e86\u6700\u5c0f\u5316\u4f5c\u4e1a\u5b8c\u6210\u5e74\u9f84\u548c\u91c7\u6837\u6210\u672c\u7684\u7b56\u7565\uff0c\u5e76\u5206\u6790\u4e86\u961f\u5217\u7a33\u5b9a\u6027\u6761\u4ef6\u3002", "motivation": "\u5728\u5177\u6709\u968f\u673a\u4f5c\u4e1a\u5230\u8fbe\u548c\u9a6c\u5c14\u53ef\u592b\u72b6\u6001\u53d8\u5316\u7684\u673a\u5668\u7cfb\u7edf\u4e2d\uff0c\u9700\u8981\u8bbe\u8ba1\u6709\u6548\u7684\u8c03\u5ea6\u7b56\u7565\u6765\u6700\u5927\u5316\u5355\u4f4d\u65f6\u95f4\u5185\u5b8c\u6210\u7684\u4f5c\u4e1a\u6570\u91cf\uff0c\u540c\u65f6\u8003\u8651\u91c7\u6837\u6210\u672c\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u7b56\u7565\u6765\u6700\u5c0f\u5316\u4f5c\u4e1a\u5b8c\u6210\u5e74\u9f84\u548c\u91c7\u6837\u6210\u672c\uff0c\u901a\u8fc7\u5206\u6790\u7cfb\u7edf\u72b6\u6001\u4fe1\u606f\u6765\u8c03\u5ea6\u7528\u6237\u4f5c\u4e1a\u3002", "result": "\u6570\u503c\u8bc4\u4f30\u4e86\u6240\u63d0\u7b56\u7565\u7684\u6027\u80fd\uff0c\u5e76\u627e\u5230\u4e86\u4fdd\u8bc1\u4f5c\u4e1a\u961f\u5217\u7a33\u5b9a\u7684\u5145\u5206\u6761\u4ef6\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b56\u7565\u80fd\u591f\u6709\u6548\u7ba1\u7406\u5177\u6709\u9a6c\u5c14\u53ef\u592b\u72b6\u6001\u673a\u5668\u7684\u4f5c\u4e1a\u5206\u914d\u7cfb\u7edf\uff0c\u5728\u6ee1\u8db3\u7a33\u5b9a\u6027\u6761\u4ef6\u4e0b\u4f18\u5316\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2511.04173", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.04173", "abs": "https://arxiv.org/abs/2511.04173", "authors": ["Maryam Tariq", "Omar Alhussein", "Raneem Abdelraheem", "Abdullah Quran", "Georges Kaddoum", "Sami Muhaidat"], "title": "Hybrid Quantum-Classical Detection for RIS-Assisted SC-FDE via Grover Adaptive Search", "comment": "Submitted to an IEEE Transaction, 13 pages", "summary": "Wideband and low-latency requirements in sixth-generation (6G) networks\ndemand detectors that approach maximum-likelihood (ML) performance without\nincurring exponential complexity. This work develops a hybrid quantum-classical\ndetection framework for reconfigurable intelligent surface (RIS)-assisted\nsingle-carrier (SC) frequency-domain equalization (FDE) over\nfrequency-selective channels. The ML detection objective is reformulated as a\nquadratic unconstrained binary optimization (QUBO) problem and solved via\nGrover adaptive search (GAS). To accelerate convergence, we introduce a\nfrequency-domain MMSE threshold that exploits the circulant structure of SC-FDE\nchannels, yielding low-complexity initialization. The framework is evaluated\nacross varying channel lengths and RIS sizes, confirming robustness and\nscalability. In addition, GAS requirements are quantified through register\nwidths and gate counts, and its query complexity is analyzed to characterize\nthe algorithm's cost for block transmission in frequency-selective channels.\nQuantum circuit simulations are conducted in Qiskit under both ideal and noisy\nconditions. In the ideal case, the detector achieves near-optimal performance\nwhile benefiting from Grover's quadratic speedup, reducing the search cost from\nfrom O(M^N) exhaustive evaluations to O(SQRT(M^N)) oracle queries. Under noise,\nthe shallow depth of the GAS circuits, aided by MMSE initialization, makes\ndepolarizing errors negligible, while readout errors introduce moderate\ndegradation yet still preserve performance close to the MMSE baseline. These\nresults establish the feasibility of quantum-enhanced detection for\nRIS-assisted broadband communications, highlighting both algorithmic\nscalability and practical robustness for 6G networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u68c0\u6d4b\u6846\u67b6\uff0c\u7528\u4e8eRIS\u8f85\u52a9\u7684SC-FDE\u7cfb\u7edf\uff0c\u901a\u8fc7GAS\u7b97\u6cd5\u5b9e\u73b0\u63a5\u8fd1ML\u6027\u80fd\u7684\u4f4e\u590d\u6742\u5ea6\u68c0\u6d4b\u3002", "motivation": "6G\u7f51\u7edc\u5bf9\u5bbd\u5e26\u548c\u4f4e\u5ef6\u8fdf\u7684\u9700\u6c42\u8981\u6c42\u68c0\u6d4b\u5668\u5728\u63a5\u8fd1\u6700\u5927\u4f3c\u7136\u6027\u80fd\u7684\u540c\u65f6\u907f\u514d\u6307\u6570\u590d\u6742\u5ea6\u3002", "method": "\u5c06ML\u68c0\u6d4b\u76ee\u6807\u91cd\u65b0\u8868\u8ff0\u4e3aQUBO\u95ee\u9898\uff0c\u901a\u8fc7GAS\u6c42\u89e3\uff0c\u5e76\u5f15\u5165\u9891\u57dfMMSE\u9608\u503c\u8fdb\u884c\u4f4e\u590d\u6742\u5ea6\u521d\u59cb\u5316\u3002", "result": "\u5728\u7406\u60f3\u60c5\u51b5\u4e0b\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\uff0c\u566a\u58f0\u73af\u5883\u4e0b\u6027\u80fd\u63a5\u8fd1MMSE\u57fa\u51c6\uff0c\u9a8c\u8bc1\u4e86\u91cf\u5b50\u589e\u5f3a\u68c0\u6d4b\u5728RIS\u8f85\u52a9\u5bbd\u5e26\u901a\u4fe1\u4e2d\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u57286G\u7f51\u7edc\u4e2d\u5c55\u73b0\u51fa\u7b97\u6cd5\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9645\u9c81\u68d2\u6027\uff0c\u4e3a\u91cf\u5b50\u589e\u5f3a\u68c0\u6d4b\u5728\u5bbd\u5e26\u901a\u4fe1\u4e2d\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.03820", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.03820", "abs": "https://arxiv.org/abs/2511.03820", "authors": ["Zhiguo Ding", "Robert Schober", "H. V. Poor"], "title": "Environment Division Multiple Access (EDMA): A Feasibility Study via Pinching Antennas", "comment": null, "summary": "This paper exploits the dynamic features of wireless propagation environments\nas the basis for a new multiple access technique, termed environment division\nmultiple access (EDMA). In particular, with the proposed\npinching-antenna-assisted EDMA, the multi-user propagation environment is\nintelligently reconfigured to improve signal strength at intended receivers and\nsimultaneously suppress multiple-access interference, without requiring complex\nsignal processing, e.g., precoding, beamforming, or multi-user detection. The\nkey to creating a favorable propagation environment is to utilize the\ncapability of pinching antennas to reconfigure line-of-sight (LoS) links, e.g.,\npinching antennas are placed at specific locations, such that interference\nlinks are blocked on purpose. Based on a straightforward choice of\npinching-antenna locations, the ergodic sum-rate gain of EDMA over conventional\nmultiple access and the probability that EDMA achieves a larger instantaneous\nsum rate than the considered benchmarking scheme are derived in closed form.\nThe obtained analytical results demonstrate the significant potential of EDMA\nfor supporting multi-user communications. Furthermore, pinching antenna\nlocation optimization is also investigated, since the locations of pinching\nantennas are critical for reconfiguring LoS links and large-scale path losses.\nTwo low-complexity algorithms are developed for uplink and downlink\ntransmission, respectively, and simulation results are provided to show their\noptimality in comparison to exhaustive searches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u5740\u6280\u672f\u2014\u2014\u73af\u5883\u5206\u5272\u591a\u5740(EDMA)\uff0c\u5229\u7528\u65e0\u7ebf\u4f20\u64ad\u73af\u5883\u7684\u52a8\u6001\u7279\u6027\uff0c\u901a\u8fc7\u634f\u5408\u5929\u7ebf\u667a\u80fd\u91cd\u6784\u591a\u7528\u6237\u4f20\u64ad\u73af\u5883\uff0c\u5728\u4e0d\u9700\u590d\u6742\u4fe1\u53f7\u5904\u7406\u7684\u60c5\u51b5\u4e0b\u589e\u5f3a\u76ee\u6807\u63a5\u6536\u5668\u4fe1\u53f7\u5f3a\u5ea6\u5e76\u6291\u5236\u591a\u5740\u5e72\u6270\u3002", "motivation": "\u4f20\u7edf\u591a\u5740\u6280\u672f\u9700\u8981\u590d\u6742\u7684\u4fe1\u53f7\u5904\u7406\u5982\u9884\u7f16\u7801\u3001\u6ce2\u675f\u6210\u5f62\u6216\u591a\u7528\u6237\u68c0\u6d4b\uff0c\u800cEDMA\u65e8\u5728\u901a\u8fc7\u7269\u7406\u73af\u5883\u91cd\u6784\u6765\u7b80\u5316\u7cfb\u7edf\u590d\u6742\u5ea6\u5e76\u63d0\u5347\u6027\u80fd\u3002", "method": "\u91c7\u7528\u634f\u5408\u5929\u7ebf\u91cd\u65b0\u914d\u7f6e\u89c6\u8ddd\u94fe\u8def\uff0c\u901a\u8fc7\u7cbe\u5fc3\u653e\u7f6e\u5929\u7ebf\u4f4d\u7f6e\u6765\u6709\u610f\u963b\u65ad\u5e72\u6270\u94fe\u8def\u3002\u5f00\u53d1\u4e86\u4e24\u79cd\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\u5206\u522b\u7528\u4e8e\u4e0a\u884c\u548c\u4e0b\u884c\u4f20\u8f93\u3002", "result": "\u63a8\u5bfc\u4e86EDMA\u76f8\u6bd4\u4f20\u7edf\u591a\u5740\u6280\u672f\u7684\u904d\u5386\u548c\u901f\u7387\u589e\u76ca\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u4eff\u771f\u7ed3\u679c\u8868\u660e\u6240\u63d0\u7b97\u6cd5\u5728\u6027\u80fd\u4e0a\u63a5\u8fd1\u7a77\u4e3e\u641c\u7d22\u7684\u6700\u4f18\u89e3\u3002", "conclusion": "EDMA\u5728\u652f\u6301\u591a\u7528\u6237\u901a\u4fe1\u65b9\u9762\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u901a\u8fc7\u7269\u7406\u73af\u5883\u91cd\u6784\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\u548c\u590d\u6742\u5ea6\u964d\u4f4e\u3002"}}
{"id": "2511.03773", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03773", "abs": "https://arxiv.org/abs/2511.03773", "authors": ["Zhaorun Chen", "Zhuokai Zhao", "Kai Zhang", "Bo Liu", "Qi Qi", "Yifan Wu", "Tarun Kalluri", "Sara Cao", "Yuanhao Xiong", "Haibo Tong", "Huaxiu Yao", "Hengduo Li", "Jiacheng Zhu", "Xian Li", "Dawn Song", "Bo Li", "Jason Weston", "Dat Huynh"], "title": "Scaling Agent Learning via Experience Synthesis", "comment": null, "summary": "While reinforcement learning (RL) can empower large language model (LLM)\nagents by enabling self-improvement through interaction, its practical adoption\nremains challenging due to costly rollouts, limited task diversity, unreliable\nreward signals, and infrastructure complexity, all of which obstruct the\ncollection of scalable experience data. To address these challenges, we\nintroduce DreamGym, the first unified framework designed to synthesize diverse\nexperiences with scalability in mind to enable effective online RL training for\nautonomous agents. Rather than relying on expensive real-environment rollouts,\nDreamGym distills environment dynamics into a reasoning-based experience model\nthat derives consistent state transitions and feedback signals through\nstep-by-step reasoning, enabling scalable agent rollout collection for RL. To\nimprove the stability and quality of transitions, DreamGym leverages an\nexperience replay buffer initialized with offline real-world data and\ncontinuously enriched with fresh interactions to actively support agent\ntraining. To improve knowledge acquisition, DreamGym adaptively generates new\ntasks that challenge the current agent policy, enabling more effective online\ncurriculum learning. Experiments across diverse environments and agent\nbackbones demonstrate that DreamGym substantially improves RL training, both in\nfully synthetic settings and in sim-to-real transfer scenarios. On non-RL-ready\ntasks like WebArena, DreamGym outperforms all baselines by over 30%. And in\nRL-ready but costly settings, it matches GRPO and PPO performance using only\nsynthetic interactions. When transferring a policy trained purely on synthetic\nexperiences to real-environment RL, DreamGym yields significant additional\nperformance gains while requiring far fewer real-world interactions, providing\na scalable warm-start strategy for general-purpose RL.", "AI": {"tldr": "DreamGym\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u63a8\u7406\u7684\u7ecf\u9a8c\u6a21\u578b\u5408\u6210\u591a\u6837\u5316\u7ecf\u9a8c\u6570\u636e\uff0c\u89e3\u51b3RL\u8bad\u7ec3\u4e2d\u6602\u8d35\u73af\u5883\u4ea4\u4e92\u3001\u4efb\u52a1\u591a\u6837\u6027\u4e0d\u8db3\u3001\u5956\u52b1\u4fe1\u53f7\u4e0d\u53ef\u9760\u7b49\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e2d\u5b9e\u9645\u5e94\u7528\u7684\u6311\u6218\uff1a\u6602\u8d35\u7684\u73af\u5883\u4ea4\u4e92\u3001\u6709\u9650\u7684\u4efb\u52a1\u591a\u6837\u6027\u3001\u4e0d\u53ef\u9760\u7684\u5956\u52b1\u4fe1\u53f7\u548c\u57fa\u7840\u8bbe\u65bd\u590d\u6742\u6027\uff0c\u8fd9\u4e9b\u963b\u788d\u4e86\u53ef\u6269\u5c55\u7ecf\u9a8c\u6570\u636e\u7684\u6536\u96c6\u3002", "method": "1) \u5c06\u73af\u5883\u52a8\u6001\u63d0\u70bc\u4e3a\u57fa\u4e8e\u63a8\u7406\u7684\u7ecf\u9a8c\u6a21\u578b\uff0c\u901a\u8fc7\u9010\u6b65\u63a8\u7406\u83b7\u5f97\u4e00\u81f4\u7684\u72b6\u6001\u8f6c\u6362\u548c\u53cd\u9988\u4fe1\u53f7\uff1b2) \u4f7f\u7528\u79bb\u7ebf\u771f\u5b9e\u6570\u636e\u521d\u59cb\u5316\u7ecf\u9a8c\u56de\u653e\u7f13\u51b2\u533a\u5e76\u6301\u7eed\u4e30\u5bcc\uff1b3) \u81ea\u9002\u5e94\u751f\u6210\u6311\u6218\u5f53\u524d\u4ee3\u7406\u7b56\u7565\u7684\u65b0\u4efb\u52a1\uff0c\u5b9e\u73b0\u5728\u7ebf\u8bfe\u7a0b\u5b66\u4e60\u3002", "result": "\u5728\u591a\u6837\u73af\u5883\u548c\u4ee3\u7406\u9aa8\u5e72\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDreamGym\u663e\u8457\u6539\u5584\u4e86RL\u8bad\u7ec3\u3002\u5728WebArena\u7b49\u975eRL\u5c31\u7eea\u4efb\u52a1\u4e0a\u8d85\u8d8a\u6240\u6709\u57fa\u7ebf30%\u4ee5\u4e0a\uff1b\u5728RL\u5c31\u7eea\u4f46\u6210\u672c\u9ad8\u6602\u7684\u8bbe\u7f6e\u4e2d\uff0c\u4ec5\u4f7f\u7528\u5408\u6210\u4ea4\u4e92\u5c31\u80fd\u5339\u914dGRPO\u548cPPO\u6027\u80fd\uff1b\u5728\u5c06\u7eaf\u5408\u6210\u7ecf\u9a8c\u8bad\u7ec3\u7684\u7b56\u7565\u8fc1\u79fb\u5230\u771f\u5b9e\u73af\u5883RL\u65f6\uff0cDreamGym\u5728\u9700\u8981\u66f4\u5c11\u771f\u5b9e\u4ea4\u4e92\u7684\u540c\u65f6\u83b7\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "DreamGym\u4e3a\u901a\u7528\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u9884\u70ed\u7b56\u7565\uff0c\u901a\u8fc7\u5408\u6210\u7ecf\u9a8c\u6570\u636e\u6709\u6548\u89e3\u51b3\u4e86RL\u8bad\u7ec3\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002"}}
{"id": "2511.04639", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.04639", "abs": "https://arxiv.org/abs/2511.04639", "authors": ["Alberto Merino", "Jesus Escudero-Sahuquillo", "Pedro Javier Garcia", "Francisco J. Quiles"], "title": "Improving dynamic congestion isolation in data-center networks", "comment": "26 pages, 6 figures", "summary": "The rise of distributed AI and large-scale applications has impacted the\ncommunication operations of data-center and Supercomputer interconnection\nnetworks, leading to dramatic incast or in-network congestion scenarios and\nchallenging existing congestion control mechanisms, such as injection\nthrottling (e.g., DCQCN) or congestion isolation (CI). While DCQCN provides a\nscalable traffic rate adjustment for congesting flows at end nodes (which is\nslow) and CI effectively isolates these flows in special network resources\n(which requires extra logic in the switches), their combined use, although it\ndiminishes their particular drawbacks, leads to false congestion scenarios\nidentification and signaling, excessive throttling, and inefficient network\nresource utilization. In this paper, we propose a new CI mechanism, called\nImproved Congestion Isolation (ICI), which efficiently combines CI and DCQCN so\nthat the information of the isolated congesting flows is used to guide the ECN\nmarking performed by DCQCN in a way that victim flows do not end up being\nmarked. This coordination reduces false-positive congestion detection,\nsuppresses unnecessary closed-loop feedback (i.e., wrong congestion\nnotifications), and improves responsiveness to communication microbursts.\nEvaluated under diverse traffic patterns, including incast and Data-center\nworkloads, ICI reduces the number of generated BECNs by up to 32x and improves\ntail latency by up to 31%, while maintaining high throughput and scalability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u6539\u8fdb\u7684\u62e5\u585e\u9694\u79bb\u673a\u5236ICI\uff0c\u901a\u8fc7\u534f\u8c03CI\u548cDCQCN\u6765\u51cf\u5c11\u8bef\u62a5\u62e5\u585e\u68c0\u6d4b\uff0c\u63d0\u9ad8\u7f51\u7edc\u8d44\u6e90\u5229\u7528\u7387", "motivation": "\u5206\u5e03\u5f0fAI\u548c\u5927\u89c4\u6a21\u5e94\u7528\u5bfc\u81f4\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u62e5\u585e\uff0c\u73b0\u6709DCQCN\u548cCI\u673a\u5236\u7ed3\u5408\u4f7f\u7528\u65f6\u4f1a\u4ea7\u751f\u8bef\u62a5\u62e5\u585e\u3001\u8fc7\u5ea6\u9650\u6d41\u548c\u8d44\u6e90\u5229\u7528\u4f4e\u6548\u7684\u95ee\u9898", "method": "ICI\u673a\u5236\u5c06\u9694\u79bb\u7684\u62e5\u585e\u6d41\u4fe1\u606f\u7528\u4e8e\u6307\u5bfcDCQCN\u7684ECN\u6807\u8bb0\uff0c\u907f\u514d\u53d7\u5bb3\u6d41\u88ab\u9519\u8bef\u6807\u8bb0\uff0c\u51cf\u5c11\u8bef\u62a5\u62e5\u585e\u68c0\u6d4b", "result": "\u5728\u591a\u79cd\u6d41\u91cf\u6a21\u5f0f\u4e0b\uff0cICI\u5c06\u751f\u6210\u7684BECN\u6570\u91cf\u51cf\u5c11\u6700\u591a32\u500d\uff0c\u5c3e\u90e8\u5ef6\u8fdf\u6539\u5584\u6700\u591a31%\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u541e\u5410\u91cf\u548c\u53ef\u6269\u5c55\u6027", "conclusion": "ICI\u901a\u8fc7\u534f\u8c03CI\u548cDCQCN\u6709\u6548\u89e3\u51b3\u4e86\u8bef\u62a5\u62e5\u585e\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u7f51\u7edc\u6027\u80fd\u548c\u54cd\u5e94\u80fd\u529b"}}
{"id": "2511.03849", "categories": ["cs.IT", "cs.LG", "math.IT", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2511.03849", "abs": "https://arxiv.org/abs/2511.03849", "authors": ["Phuc Nguyen", "Josiah Couch", "Rahul Bansal", "Alexandra Morgan", "Chris Tam", "Miao Li", "Rima Arnaout", "Ramy Arnaout"], "title": "Which Similarity-Sensitive Entropy?", "comment": "21 pages, 8 figures", "summary": "A canonical step in quantifying a system is to measure its entropy. Shannon\nentropy and other traditional entropy measures capture only the information\nencoded in the frequencies of a system's elements. Recently, Leinster, Cobbold,\nand Reeve (LCR) introduced a method that also captures the rich information\nencoded in the similarities and differences among elements, yielding\nsimilarity-sensitive entropy. More recently, the Vendi score (VS) was\nintroduced as an alternative, raising the question of how LCR and VS compare,\nand which is preferable. Here we address these questions conceptually,\nanalytically, and experimentally, using 53 machine-learning datasets. We show\nthat LCR and VS can differ by orders of magnitude and can capture complementary\ninformation about a system, except in limiting cases. We demonstrate that both\nLCR and VS depend on how similarities are scaled and introduce the concept of\n``half distance'' to parameterize this dependence. We prove that VS provides an\nupper bound on LCR for several values of the R\\'enyi-Hill order parameter and\nconjecture that this bound holds for all values. We conclude that VS is\npreferable only when interpreting elements as linear combinations of a more\nfundamental set of ``ur-elements'' or when the system or dataset possesses a\nquantum-mechanical character. In the broader circumstance where one seeks\nsimply to capture the rich information encoded by similarity, LCR is favored;\nnevertheless, for certain half-distances the two methods can complement each\nother.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u4e24\u79cd\u76f8\u4f3c\u6027\u654f\u611f\u71b5\u5ea6\u91cf\u65b9\u6cd5\uff1aLeinster-Cobbold-Reeve (LCR) \u548c Vendi score (VS)\uff0c\u901a\u8fc7\u6982\u5ff5\u3001\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u53d1\u73b0\u4e24\u8005\u5728\u91cf\u7ea7\u548c\u6355\u83b7\u4fe1\u606f\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5e76\u786e\u5b9a\u4e86\u5404\u81ea\u9002\u7528\u7684\u573a\u666f\u3002", "motivation": "\u4f20\u7edf\u71b5\u5ea6\u91cf\u4ec5\u6355\u83b7\u7cfb\u7edf\u5143\u7d20\u9891\u7387\u4fe1\u606f\uff0c\u800cLCR\u548cVS\u65b9\u6cd5\u80fd\u591f\u6355\u83b7\u5143\u7d20\u95f4\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u6027\u7684\u4e30\u5bcc\u4fe1\u606f\u3002\u672c\u6587\u65e8\u5728\u6bd4\u8f83\u8fd9\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u52a3\uff0c\u786e\u5b9a\u54ea\u79cd\u65b9\u6cd5\u66f4\u9002\u5408\u4e0d\u540c\u573a\u666f\u3002", "method": "\u4f7f\u752853\u4e2a\u673a\u5668\u5b66\u4e60\u6570\u636e\u96c6\u8fdb\u884c\u6982\u5ff5\u5206\u6790\u3001\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5f15\u5165\"\u534a\u8ddd\u79bb\"\u6982\u5ff5\u6765\u53c2\u6570\u5316\u76f8\u4f3c\u6027\u7f29\u653e\u7684\u5f71\u54cd\uff0c\u5e76\u8bc1\u660eVS\u5bf9LCR\u7684\u8fb9\u754c\u5173\u7cfb\u3002", "result": "LCR\u548cVS\u5728\u91cf\u7ea7\u4e0a\u53ef\u80fd\u76f8\u5dee\u6570\u4e2a\u6570\u91cf\u7ea7\uff0c\u4e14\u6355\u83b7\u7cfb\u7edf\u4e92\u8865\u4fe1\u606f\uff08\u9664\u6781\u9650\u60c5\u51b5\u5916\uff09\u3002VS\u4e3aLCR\u63d0\u4f9b\u4e86\u591a\u4e2aR\u00e9nyi-Hill\u9636\u53c2\u6570\u503c\u7684\u4e0a\u754c\uff0c\u5e76\u63a8\u6d4b\u8be5\u8fb9\u754c\u5bf9\u6240\u6709\u503c\u90fd\u6210\u7acb\u3002", "conclusion": "VS\u4ec5\u5728\u5c06\u5143\u7d20\u89e3\u91ca\u4e3a\u66f4\u57fa\u672c\"\u539f\u59cb\u5143\u7d20\"\u7684\u7ebf\u6027\u7ec4\u5408\u6216\u7cfb\u7edf\u5177\u6709\u91cf\u5b50\u529b\u5b66\u7279\u6027\u65f6\u66f4\u4f18\uff1b\u5728\u66f4\u5e7f\u6cdb\u60c5\u51b5\u4e0b\uff0c\u82e5\u4ec5\u9700\u6355\u83b7\u76f8\u4f3c\u6027\u7f16\u7801\u7684\u4e30\u5bcc\u4fe1\u606f\uff0cLCR\u66f4\u53d7\u9752\u7750\uff1b\u4f46\u5728\u67d0\u4e9b\u534a\u8ddd\u79bb\u4e0b\uff0c\u4e24\u79cd\u65b9\u6cd5\u53ef\u4ee5\u4e92\u8865\u4f7f\u7528\u3002"}}
{"id": "2511.03825", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03825", "abs": "https://arxiv.org/abs/2511.03825", "authors": ["Ahmed Mostafa", "Raisul Arefin Nahid", "Samuel Mulder"], "title": "How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis", "comment": "Publication Notice. This paper was published in the BAR 2025 Workshop\n  (with NDSS 2025) and is for research and educational use. Copyright\n  \\c{opyright} 2025 Internet Society. All rights reserved. Personal/classroom\n  reproduction is permitted with this notice and full paper citation. All other\n  uses, including commercial, require prior written permission from the\n  Internet Society", "summary": "Tokenization is fundamental in assembly code analysis, impacting intrinsic\ncharacteristics like vocabulary size, semantic coverage, and extrinsic\nperformance in downstream tasks. Despite its significance, tokenization in the\ncontext of assembly code remains an underexplored area. This study aims to\naddress this gap by evaluating the intrinsic properties of Natural Language\nProcessing (NLP) tokenization models and parameter choices, such as vocabulary\nsize. We explore preprocessing customization options and pre-tokenization rules\ntailored to the unique characteristics of assembly code. Additionally, we\nassess their impact on downstream tasks like function signature prediction -- a\ncritical problem in binary code analysis.\n  To this end, we conduct a thorough study on various tokenization models,\nsystematically analyzing their efficiency in encoding assembly instructions and\ncapturing semantic nuances. Through intrinsic evaluations, we compare\ntokenizers based on tokenization efficiency, vocabulary compression, and\nrepresentational fidelity for assembly code. Using state-of-the-art pre-trained\nmodels such as the decoder-only Large Language Model (LLM) Llama 3.2, the\nencoder-only transformer BERT, and the encoder-decoder model BART, we evaluate\nthe effectiveness of these tokenizers across multiple performance metrics.\nPreliminary findings indicate that tokenizer choice significantly influences\ndownstream performance, with intrinsic metrics providing partial but incomplete\npredictability of extrinsic evaluation outcomes. These results reveal complex\ntrade-offs between intrinsic tokenizer properties and their utility in\npractical assembly code tasks. Ultimately, this study provides valuable\ninsights into optimizing tokenization models for low-level code analysis,\ncontributing to the robustness and scalability of Natural Language Model\n(NLM)-based binary analysis workflows.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86NLP\u5206\u8bcd\u6a21\u578b\u5728\u6c47\u7f16\u4ee3\u7801\u5206\u6790\u4e2d\u7684\u5185\u5728\u7279\u6027\uff0c\u5305\u62ec\u8bcd\u6c47\u91cf\u5927\u5c0f\u3001\u8bed\u4e49\u8986\u76d6\u7b49\uff0c\u5e76\u63a2\u8ba8\u4e86\u9884\u5904\u7406\u5b9a\u5236\u9009\u9879\u548c\u9884\u5206\u8bcd\u89c4\u5219\u5bf9\u4e0b\u6e38\u4efb\u52a1\u7684\u5f71\u54cd\u3002", "motivation": "\u6c47\u7f16\u4ee3\u7801\u5206\u6790\u4e2d\u7684\u5206\u8bcd\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u4f46\u5176\u5bf9\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u591a\u79cd\u5206\u8bcd\u6a21\u578b\uff0c\u901a\u8fc7\u5185\u5728\u8bc4\u4f30\u6bd4\u8f83\u5206\u8bcd\u6548\u7387\u3001\u8bcd\u6c47\u538b\u7f29\u548c\u8868\u793a\u4fdd\u771f\u5ea6\uff0c\u4f7f\u7528Llama 3.2\u3001BERT\u548cBART\u7b49\u9884\u8bad\u7ec3\u6a21\u578b\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u5206\u8bcd\u5668\u9009\u62e9\u663e\u8457\u5f71\u54cd\u4e0b\u6e38\u6027\u80fd\uff0c\u5185\u5728\u6307\u6807\u53ea\u80fd\u90e8\u5206\u9884\u6d4b\u5916\u5728\u8bc4\u4f30\u7ed3\u679c\uff0c\u63ed\u793a\u4e86\u5185\u5728\u5206\u8bcd\u5668\u7279\u6027\u4e0e\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u590d\u6742\u6743\u8861\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u4f4e\u7ea7\u4ee3\u7801\u5206\u6790\u4e2d\u7684\u5206\u8bcd\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u6a21\u578b\u7684\u4e8c\u8fdb\u5236\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\u7684\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.04088", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.04088", "abs": "https://arxiv.org/abs/2511.04088", "authors": ["Pranav Joshi", "Daniel McMorrow", "Yihan Zhang", "Amitalok J. Budkuley", "Sidharth Jaggi"], "title": "Efficient and rate-optimal list-decoding in the presence of minimal feedback: Weldon and Slepian-Wolf in sheep's clothing", "comment": null, "summary": "Given a channel with length-$n$ inputs and outputs over the alphabet\n$\\{0,1,\\ldots,q-1\\}$, and of which a fraction $\\varrho \\in (0,1-1/q)$ of\nsymbols can be arbitrarily corrupted by an adversary, a fundamental problem is\nthat of communicating at rates close to the information-theoretically optimal\nvalues, while ensuring the receiver can infer that the transmitter's message is\nfrom a ``small\" set. While the existence of such codes is known, and\nconstructions with computationally tractable encoding/decoding procedures are\nknown for large $q$, we provide the first schemes that attain this performance\nfor any $q \\geq 2$, as long as low-rate feedback (asymptotically negligible\nrelative to the number of transmissions) from the receiver to the transmitter\nis available. For any sufficiently small $\\varepsilon > 0$ and $\\varrho \\in\n(1-1/q-\\Theta(\\sqrt{\\varepsilon})$ our minimal feedback scheme has the\nfollowing parameters: Rate $1-H_q(\\varrho) - \\varepsilon$ (i.e.,\n$\\varepsilon$-close to information-theoretically optimal -- here $H_q(\\varrho)$\nis the $q$-ary entropy function), list-size\n$\\exp(\\mathcal{O}(\\varepsilon^{-3/2}\\log^2(1/\\varepsilon))$, computational\ncomplexity of encoding/decoding\n$n^{\\mathcal{O}(\\varepsilon^{-1}\\log(1/\\varepsilon))}$, storage complexity\n$\\mathcal{O}(n^{\\eta+1}\\log n)$ for a code design parameter $\\eta>1$ that\ntrades off storage complexity with the probability of error. The error\nprobability is $\\mathcal{O}(n^{-\\eta})$, and the (vanishing) feedback rate is\n$\\mathcal{O}(1/ \\log n)$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u9002\u7528\u4e8e\u4efb\u4f55q\u22652\u7684\u7f16\u7801\u65b9\u6848\uff0c\u5728\u5b58\u5728\u4f4e\u901f\u7387\u53cd\u9988\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u4ee5\u63a5\u8fd1\u4fe1\u606f\u8bba\u6700\u4f18\u7684\u901f\u7387\u8fdb\u884c\u901a\u4fe1\uff0c\u540c\u65f6\u786e\u4fdd\u63a5\u6536\u65b9\u80fd\u591f\u63a8\u65ad\u51fa\u53d1\u9001\u65b9\u7684\u6d88\u606f\u6765\u81ea\u4e00\u4e2a\"\u5c0f\"\u96c6\u5408\u3002", "motivation": "\u73b0\u6709\u7f16\u7801\u65b9\u6848\u5728\u5927q\u503c\u65f6\u5177\u6709\u8ba1\u7b97\u53ef\u884c\u7684\u7f16\u7801/\u89e3\u7801\u8fc7\u7a0b\uff0c\u4f46\u5bf9\u4e8e\u4efb\u610fq\u22652\u7684\u60c5\u51b5\u7f3a\u4e4f\u6709\u6548\u65b9\u6848\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5728\u4efb\u610fq\u22652\u548c\u5b58\u5728\u7b26\u53f7\u635f\u574f\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u63a5\u8fd1\u4fe1\u606f\u8bba\u6700\u4f18\u901f\u7387\u7684\u901a\u4fe1\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6700\u5c0f\u53cd\u9988\u65b9\u6848\uff0c\u5229\u7528\u6e10\u8fd1\u53ef\u5ffd\u7565\u7684\u53cd\u9988\u901f\u7387\uff08\u76f8\u5bf9\u4e8e\u4f20\u8f93\u6b21\u6570\uff09\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u7f16\u7801\u7ed3\u6784\u548c\u53c2\u6570\u9009\u62e9\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u7f16\u7801\u548c\u89e3\u7801\u8fc7\u7a0b\u3002", "result": "\u8be5\u65b9\u6848\u5728\u8db3\u591f\u5c0f\u7684\u03b5>0\u548c\u03c1\u2208(1-1/q-\u0398(\u221a\u03b5))\u6761\u4ef6\u4e0b\uff0c\u5b9e\u73b0\u4e86\u901f\u73871-H_q(\u03c1)-\u03b5\uff08\u63a5\u8fd1\u4fe1\u606f\u8bba\u6700\u4f18\uff09\u3001\u5217\u8868\u5927\u5c0fexp(O(\u03b5^{-3/2}log\u00b2(1/\u03b5)))\u3001\u7f16\u7801/\u89e3\u7801\u8ba1\u7b97\u590d\u6742\u5ea6n^{O(\u03b5^{-1}log(1/\u03b5))}\u3001\u5b58\u50a8\u590d\u6742\u5ea6O(n^{\u03b7+1}log n)\uff0c\u9519\u8bef\u6982\u7387\u4e3aO(n^{-\u03b7})\uff0c\u53cd\u9988\u901f\u7387\u4e3aO(1/log n)\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u8bc1\u660e\u4e86\u5728\u4efb\u610fq\u22652\u548c\u5b58\u5728\u4f4e\u901f\u7387\u53cd\u9988\u7684\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u5b9e\u73b0\u63a5\u8fd1\u4fe1\u606f\u8bba\u6700\u4f18\u901f\u7387\u7684\u901a\u4fe1\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u5c0f\u7684\u5217\u8868\u5927\u5c0f\u548c\u5408\u7406\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4e3a\u5bf9\u6297\u6027\u4fe1\u9053\u4e0b\u7684\u53ef\u9760\u901a\u4fe1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.03845", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03845", "abs": "https://arxiv.org/abs/2511.03845", "authors": ["Tianning Dong", "Luyi Ma", "Varun Vasudevan", "Jason Cho", "Sushant Kumar", "Kannan Achan"], "title": "To See or To Read: User Behavior Reasoning in Multimodal LLMs", "comment": "Accepted by the 39th Conference on Neural Information Processing\n  Systems (NeurIPS 2025) Workshop: Efficient Reasoning", "summary": "Multimodal Large Language Models (MLLMs) are reshaping how modern agentic\nsystems reason over sequential user-behavior data. However, whether textual or\nimage representations of user behavior data are more effective for maximizing\nMLLM performance remains underexplored. We present \\texttt{BehaviorLens}, a\nsystematic benchmarking framework for assessing modality trade-offs in\nuser-behavior reasoning across six MLLMs by representing transaction data as\n(1) a text paragraph, (2) a scatter plot, and (3) a flowchart. Using a\nreal-world purchase-sequence dataset, we find that when data is represented as\nimages, MLLMs next-purchase prediction accuracy is improved by 87.5% compared\nwith an equivalent textual representation without any additional computational\ncost.", "AI": {"tldr": "BehaviorLens\u6846\u67b6\u7cfb\u7edf\u8bc4\u4f30\u4e86\u7528\u6237\u884c\u4e3a\u6570\u636e\u7684\u6587\u672c\u4e0e\u56fe\u50cf\u8868\u793a\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u56fe\u50cf\u8868\u793a\u80fd\u663e\u8457\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u63a2\u7d22\u7528\u6237\u884c\u4e3a\u6570\u636e\u7684\u6587\u672c\u4e0e\u56fe\u50cf\u8868\u793a\u54ea\u79cd\u66f4\u80fd\u6700\u5927\u5316\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u8fd9\u4e00\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u5f00\u53d1BehaviorLens\u57fa\u51c6\u6846\u67b6\uff0c\u5728\u516d\u4e2aMLLMs\u4e0a\u6d4b\u8bd5\u4ea4\u6613\u6570\u636e\u7684\u4e09\u79cd\u8868\u793a\u65b9\u5f0f\uff1a\u6587\u672c\u6bb5\u843d\u3001\u6563\u70b9\u56fe\u548c\u6d41\u7a0b\u56fe\uff0c\u4f7f\u7528\u771f\u5b9e\u8d2d\u4e70\u5e8f\u5217\u6570\u636e\u96c6\u3002", "result": "\u5f53\u6570\u636e\u8868\u793a\u4e3a\u56fe\u50cf\u65f6\uff0cMLLMs\u7684\u4e0b\u4e00\u6b21\u8d2d\u4e70\u9884\u6d4b\u51c6\u786e\u7387\u6bd4\u7b49\u6548\u6587\u672c\u8868\u793a\u63d0\u9ad8\u4e8687.5%\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u56fe\u50cf\u8868\u793a\u7528\u6237\u884c\u4e3a\u6570\u636e\u80fd\u663e\u8457\u63d0\u5347MLLMs\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u4f18\u5316\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2511.04135", "categories": ["cs.IT", "cs.CR", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.04135", "abs": "https://arxiv.org/abs/2511.04135", "authors": ["Chen Yuan", "Ruiqi Zhu"], "title": "List Decoding of Folded Reed-Solomon Codes Over Galois Ring", "comment": "32 pages", "summary": "List decoding of codes can be seen as the generalization of unique decoding\nof codes While list decoding over finite fields has been extensively studied,\nextending these results to more general algebraic structures such as Galois\nrings remains an important challenge. Due to recent progress in zero knowledge\nsystems, there is a growing demand to investigate the proximity gap of codes\nover Galois rings in Yizhou Yao and coauthors(2025), Alexander Golovne and\ncoauthors(2023), Yuanju Wei and coauthors(2025). The proximity gap is closely\nrelated to the decoding capability of codes. It was shown in Eli Ben-Sasson and\ncoauthors(2020) that the proximity gap for RS codes over finite field can be\nimproved to $1-\\sqrt{r}$ if one consider list decoding instead of unique\ndecoding. However, we know very little about RS codes over Galois ring which\nmight hinder the development of zero knowledge proof system for ring-based\narithmetic circuit. In this work, we first extend the list decoding procedure\nof Guruswami and Sudan to Reed-Solomon codes over Galois rings, which shows\nthat RS codes with rate $r$ can be list decoded up to radius $1-\\sqrt{r}$.\nThen, we investigate the list decoding of folded Reed-Solomon codes over Galois\nrings. We show that the list decoding radius of folded Reed-Solomon codes can\nreach the Singlton bound as its counterpart over finite field. Finally, we\nimprove the list size of our folded Reed-Solomon code to\n$O(\\frac{1}{\\varepsilon^2})$ by extending recent work in Shashank\nSrivastava(2025) to Galois Rings.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86Guruswami-Sudan\u5217\u8868\u89e3\u7801\u7b97\u6cd5\u5230\u4f3d\u7f57\u74e6\u73af\u4e0a\u7684Reed-Solomon\u7801\uff0c\u8bc1\u660e\u4e86\u901f\u7387\u4e3ar\u7684RS\u7801\u53ef\u4ee5\u5217\u8868\u89e3\u7801\u5230\u534a\u5f841-\u221ar\uff0c\u5e76\u7814\u7a76\u4e86\u6298\u53e0RS\u7801\u5728\u4f3d\u7f57\u74e6\u73af\u4e0a\u7684\u5217\u8868\u89e3\u7801\uff0c\u8fbe\u5230\u4e86Singleton\u754c\uff0c\u540c\u65f6\u5c06\u5217\u8868\u5927\u5c0f\u6539\u8fdb\u5230O(1/\u03b5\u00b2)\u3002", "motivation": "\u7531\u4e8e\u96f6\u77e5\u8bc6\u8bc1\u660e\u7cfb\u7edf\u7684\u8fdb\u5c55\uff0c\u9700\u8981\u7814\u7a76\u4f3d\u7f57\u74e6\u73af\u4e0a\u7801\u7684\u90bb\u8fd1\u95f4\u9699\u95ee\u9898\u3002\u6709\u9650\u57df\u4e0a\u7684RS\u7801\u90bb\u8fd1\u95f4\u9699\u5728\u5217\u8868\u89e3\u7801\u4e0b\u53ef\u6539\u8fdb\u52301-\u221ar\uff0c\u4f46\u5bf9\u4f3d\u7f57\u74e6\u73af\u4e0aRS\u7801\u7684\u4e86\u89e3\u5f88\u5c11\uff0c\u8fd9\u963b\u788d\u4e86\u57fa\u4e8e\u73af\u7684\u7b97\u672f\u7535\u8def\u7684\u96f6\u77e5\u8bc6\u8bc1\u660e\u7cfb\u7edf\u53d1\u5c55\u3002", "method": "\u9996\u5148\u5c06Guruswami-Sudan\u5217\u8868\u89e3\u7801\u7a0b\u5e8f\u6269\u5c55\u5230\u4f3d\u7f57\u74e6\u73af\u4e0a\u7684Reed-Solomon\u7801\uff0c\u7136\u540e\u7814\u7a76\u4f3d\u7f57\u74e6\u73af\u4e0a\u6298\u53e0Reed-Solomon\u7801\u7684\u5217\u8868\u89e3\u7801\uff0c\u6700\u540e\u5c06Shashank Srivastava(2025)\u7684\u5de5\u4f5c\u6269\u5c55\u5230\u4f3d\u7f57\u74e6\u73af\u4ee5\u6539\u8fdb\u5217\u8868\u5927\u5c0f\u3002", "result": "\u8bc1\u660e\u4e86\u4f3d\u7f57\u74e6\u73af\u4e0a\u901f\u7387\u4e3ar\u7684RS\u7801\u53ef\u4ee5\u5217\u8868\u89e3\u7801\u5230\u534a\u5f841-\u221ar\uff1b\u6298\u53e0RS\u7801\u7684\u5217\u8868\u89e3\u7801\u534a\u5f84\u8fbe\u5230Singleton\u754c\uff1b\u5c06\u6298\u53e0RS\u7801\u7684\u5217\u8868\u5927\u5c0f\u6539\u8fdb\u5230O(1/\u03b5\u00b2)\u3002", "conclusion": "\u6210\u529f\u5c06\u5217\u8868\u89e3\u7801\u6280\u672f\u6269\u5c55\u5230\u4f3d\u7f57\u74e6\u73af\u4e0a\u7684RS\u7801\u548c\u6298\u53e0RS\u7801\uff0c\u4e3a\u57fa\u4e8e\u73af\u7684\u96f6\u77e5\u8bc6\u8bc1\u660e\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7406\u8bba\u57fa\u7840\u548c\u89e3\u7801\u80fd\u529b\u4fdd\u8bc1\u3002"}}
{"id": "2511.03878", "categories": ["cs.AI", "cs.IR", "cs.LG", "cs.MA", "I.2.7; I.2.0"], "pdf": "https://arxiv.org/pdf/2511.03878", "abs": "https://arxiv.org/abs/2511.03878", "authors": ["Suraj Prasai", "Mengnan Du", "Ying Zhang", "Fan Yang"], "title": "KnowThyself: An Agentic Assistant for LLM Interpretability", "comment": "5 pages, 1 figure, Accepted for publication at the Demonstration\n  Track of the 40th AAAI Conference on Artificial Intelligence (AAAI 26)", "summary": "We develop KnowThyself, an agentic assistant that advances large language\nmodel (LLM) interpretability. Existing tools provide useful insights but remain\nfragmented and code-intensive. KnowThyself consolidates these capabilities into\na chat-based interface, where users can upload models, pose natural language\nquestions, and obtain interactive visualizations with guided explanations. At\nits core, an orchestrator LLM first reformulates user queries, an agent router\nfurther directs them to specialized modules, and the outputs are finally\ncontextualized into coherent explanations. This design lowers technical\nbarriers and provides an extensible platform for LLM inspection. By embedding\nthe whole process into a conversational workflow, KnowThyself offers a robust\nfoundation for accessible LLM interpretability.", "AI": {"tldr": "KnowThyself\u662f\u4e00\u4e2a\u57fa\u4e8e\u804a\u5929\u7684LLM\u53ef\u89e3\u91ca\u6027\u5de5\u5177\uff0c\u901a\u8fc7\u6574\u5408\u73b0\u6709\u529f\u80fd\u3001\u964d\u4f4e\u6280\u672f\u95e8\u69db\uff0c\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u548c\u5f15\u5bfc\u89e3\u91ca\u3002", "motivation": "\u73b0\u6709LLM\u53ef\u89e3\u91ca\u6027\u5de5\u5177\u5b58\u5728\u788e\u7247\u5316\u548c\u4ee3\u7801\u5bc6\u96c6\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6613\u7528\u3001\u6574\u5408\u7684\u5de5\u5177\u6765\u964d\u4f4e\u6280\u672f\u95e8\u69db\u3002", "method": "\u4f7f\u7528\u7f16\u6392\u5668LLM\u91cd\u65b0\u8868\u8ff0\u7528\u6237\u67e5\u8be2\uff0c\u901a\u8fc7\u4ee3\u7406\u8def\u7531\u5668\u5206\u53d1\u5230\u4e13\u95e8\u6a21\u5757\uff0c\u6700\u540e\u5c06\u8f93\u51fa\u60c5\u5883\u5316\u4e3a\u8fde\u8d2f\u89e3\u91ca\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u804a\u5929\u7684\u53ef\u6269\u5c55\u5e73\u53f0\uff0c\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u548c\u5f15\u5bfc\u89e3\u91ca\uff0c\u589e\u5f3a\u4e86LLM\u53ef\u89e3\u91ca\u6027\u7684\u53ef\u8bbf\u95ee\u6027\u3002", "conclusion": "KnowThyself\u901a\u8fc7\u5bf9\u8bdd\u5f0f\u5de5\u4f5c\u6d41\u4e3aLLM\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u7a33\u5065\u57fa\u7840\uff0c\u4f7f\u6a21\u578b\u68c0\u67e5\u66f4\u52a0\u6613\u4e8e\u8bbf\u95ee\u3002"}}
{"id": "2511.04471", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.04471", "abs": "https://arxiv.org/abs/2511.04471", "authors": ["Ali Bemani", "Nassar Ksairi", "Marios Kountouris"], "title": "Affine Frequency Division Multiplexing: From Communication to Sensing", "comment": null, "summary": "Affine Frequency Division Multiplexing (AFDM) has been proposed as an\neffective waveform for achieving the full diversity of doubly-dispersive\n(delay-Doppler) channels. While this property is closely related to range and\nvelocity estimation in sensing, this article focuses on other AFDM features\nthat are particularly relevant for addressing two challenges in integrated\nsensing and communication (ISAC) systems: (1) maintaining receiver complexity\nand energy consumption at acceptable levels while supporting the large\nbandwidths required for high delay/range resolution, and (2) mitigating\ninterference in multiradar environments. In monostatic sensing, where direct\ntransmitter-receiver leakage is a major impairment, we show that AFDM-based\nISAC receivers can address the first challenge through their compatibility with\nlow-complexity self-interference cancellation (SIC) schemes and reduced\nsampling rates via analog dechirping. In bistatic sensing, where such analog\nsolutions may not be feasible, we demonstrate that AFDM supports sub-Nyquist\nsampling without requiring hardware modifications while preserving delay\nresolution. Finally, we show that the second challenge can be addressed by\nleveraging the resource-assignment flexibility of the discrete affine Fourier\ntransform (DAFT) underlying the AFDM waveform.", "AI": {"tldr": "AFDM\u6ce2\u5f62\u5728\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u4e2d\u89e3\u51b3\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\u652f\u6301\u5927\u5e26\u5bbd\u7684\u540c\u65f6\u4fdd\u6301\u4f4e\u590d\u6742\u5ea6\u63a5\u6536\u673a\uff0c\u4ee5\u53ca\u591a\u96f7\u8fbe\u73af\u5883\u4e2d\u7684\u5e72\u6270\u6291\u5236\u3002", "motivation": "\u89e3\u51b3ISAC\u7cfb\u7edf\u4e2d\u5927\u5e26\u5bbd\u9700\u6c42\u4e0e\u63a5\u6536\u673a\u590d\u6742\u5ea6/\u80fd\u8017\u7684\u77db\u76fe\uff0c\u4ee5\u53ca\u591a\u96f7\u8fbe\u73af\u5883\u4e2d\u7684\u5e72\u6270\u95ee\u9898\u3002", "method": "\u5229\u7528AFDM\u6ce2\u5f62\u7684\u7279\u6027\uff1a\u517c\u5bb9\u4f4e\u590d\u6742\u5ea6\u81ea\u5e72\u6270\u6d88\u9664\u65b9\u6848\u3001\u652f\u6301\u6a21\u62df\u53bb\u5541\u557e\u964d\u4f4e\u91c7\u6837\u7387\u3001\u79bb\u6563\u4eff\u5c04\u5085\u91cc\u53f6\u53d8\u6362\u7684\u8d44\u6e90\u5206\u914d\u7075\u6d3b\u6027\u3002", "result": "\u5728\u5355\u7ad9\u611f\u77e5\u4e2d\u5b9e\u73b0\u4f4e\u590d\u6742\u5ea6\u81ea\u5e72\u6270\u6d88\u9664\u548c\u964d\u4f4e\u91c7\u6837\u7387\uff1b\u5728\u53cc\u7ad9\u611f\u77e5\u4e2d\u652f\u6301\u4e9a\u5948\u594e\u65af\u7279\u91c7\u6837\u4e14\u4fdd\u6301\u5ef6\u8fdf\u5206\u8fa8\u7387\uff1b\u6709\u6548\u6291\u5236\u591a\u96f7\u8fbe\u5e72\u6270\u3002", "conclusion": "AFDM\u6ce2\u5f62\u901a\u8fc7\u5176\u72ec\u7279\u7279\u6027\u6709\u6548\u89e3\u51b3\u4e86ISAC\u7cfb\u7edf\u5728\u5927\u5e26\u5bbd\u548c\u5e72\u6270\u6291\u5236\u65b9\u9762\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.03948", "categories": ["cs.AI", "cs.HC", "I.2.6; K.3.1"], "pdf": "https://arxiv.org/pdf/2511.03948", "abs": "https://arxiv.org/abs/2511.03948", "authors": ["Kevin Hong", "Kia Karbasi", "Gregory Pottie"], "title": "Extracting Causal Relations in Deep Knowledge Tracing", "comment": "Accepted for publication in the Proceedings of the 18th International\n  Conference on Educational Data Mining, 6 pages, 1 figure", "summary": "A longstanding goal in computational educational research is to develop\nexplainable knowledge tracing (KT) models. Deep Knowledge Tracing (DKT), which\nleverages a Recurrent Neural Network (RNN) to predict student knowledge and\nperformance on exercises, has been proposed as a major advancement over\ntraditional KT methods. Several studies suggest that its performance gains stem\nfrom its ability to model bidirectional relationships between different\nknowledge components (KCs) within a course, enabling the inference of a\nstudent's understanding of one KC from their performance on others. In this\npaper, we challenge this prevailing explanation and demonstrate that DKT's\nstrength lies in its implicit ability to model prerequisite relationships as a\ncausal structure, rather than bidirectional relationships. By pruning exercise\nrelation graphs into Directed Acyclic Graphs (DAGs) and training DKT on causal\nsubsets of the Assistments dataset, we show that DKT's predictive capabilities\nalign strongly with these causal structures. Furthermore, we propose an\nalternative method for extracting exercise relation DAGs using DKT's learned\nrepresentations and provide empirical evidence supporting our claim. Our\nfindings suggest that DKT's effectiveness is largely driven by its capacity to\napproximate causal dependencies between KCs rather than simple relational\nmappings.", "AI": {"tldr": "\u672c\u6587\u6311\u6218\u4e86\u5173\u4e8e\u6df1\u5ea6\u77e5\u8bc6\u8ffd\u8e2a(DKT)\u6027\u80fd\u4f18\u52bf\u7684\u6d41\u884c\u89e3\u91ca\uff0c\u8bc1\u660eDKT\u7684\u4f18\u52bf\u5728\u4e8e\u5176\u9690\u5f0f\u5efa\u6a21\u5148\u51b3\u6761\u4ef6\u5173\u7cfb\u4f5c\u4e3a\u56e0\u679c\u7ed3\u6784\u7684\u80fd\u529b\uff0c\u800c\u975e\u53cc\u5411\u5173\u7cfb\u3002", "motivation": "\u957f\u671f\u4ee5\u6765\u8ba1\u7b97\u6559\u80b2\u7814\u7a76\u7684\u76ee\u6807\u662f\u5f00\u53d1\u53ef\u89e3\u91ca\u7684\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u3002DKT\u88ab\u8ba4\u4e3a\u662f\u4f20\u7edf\u65b9\u6cd5\u7684\u91cd\u5927\u8fdb\u6b65\uff0c\u4f46\u5bf9\u5176\u6027\u80fd\u6765\u6e90\u7684\u89e3\u91ca\u5b58\u5728\u4e89\u8bae\u3002", "method": "\u901a\u8fc7\u5c06\u7ec3\u4e60\u5173\u7cfb\u56fe\u4fee\u526a\u4e3a\u6709\u5411\u65e0\u73af\u56fe(DAGs)\uff0c\u5728Assistments\u6570\u636e\u96c6\u7684\u56e0\u679c\u5b50\u96c6\u4e0a\u8bad\u7ec3DKT\uff0c\u5e76\u4f7f\u7528DKT\u5b66\u4e60\u8868\u793a\u63d0\u53d6\u7ec3\u4e60\u5173\u7cfbDAGs\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u8868\u660eDKT\u7684\u9884\u6d4b\u80fd\u529b\u4e0e\u8fd9\u4e9b\u56e0\u679c\u7ed3\u6784\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5176\u6709\u6548\u6027\u4e3b\u8981\u6e90\u4e8e\u8fd1\u4f3c\u77e5\u8bc6\u7ec4\u4ef6\u95f4\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u7684\u80fd\u529b\u3002", "conclusion": "DKT\u7684\u6709\u6548\u6027\u4e3b\u8981\u53d7\u5176\u5efa\u6a21\u77e5\u8bc6\u7ec4\u4ef6\u95f4\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u7684\u80fd\u529b\u9a71\u52a8\uff0c\u800c\u975e\u7b80\u5355\u7684\u53cc\u5411\u5173\u7cfb\u6620\u5c04\u3002"}}
{"id": "2511.03980", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03980", "abs": "https://arxiv.org/abs/2511.03980", "authors": ["Bram Bult\u00e9", "Ayla Rigouts Terryn"], "title": "LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing", "comment": "Preprint under review at Computational Linguistics. Accepted with\n  minor revisions (10/10/2025); second round", "summary": "Large Language Models (LLMs) are rapidly being adopted by users across the\nglobe, who interact with them in a diverse range of languages. At the same\ntime, there are well-documented imbalances in the training data and\noptimisation objectives of this technology, raising doubts as to whether LLMs\ncan represent the cultural diversity of their broad user base. In this study,\nwe look at LLMs and cultural values and examine how prompt language and\ncultural framing influence model responses and their alignment with human\nvalues in different countries. We probe 10 LLMs with 63 items from the Hofstede\nValues Survey Module and World Values Survey, translated into 11 languages, and\nformulated as prompts with and without different explicit cultural\nperspectives. Our study confirms that both prompt language and cultural\nperspective produce variation in LLM outputs, but with an important caveat:\nWhile targeted prompting can, to a certain extent, steer LLM responses in the\ndirection of the predominant values of the corresponding countries, it does not\novercome the models' systematic bias toward the values associated with a\nrestricted set of countries in our dataset: the Netherlands, Germany, the US,\nand Japan. All tested models, regardless of their origin, exhibit remarkably\nsimilar patterns: They produce fairly neutral responses on most topics, with\nselective progressive stances on issues such as social tolerance. Alignment\nwith cultural values of human respondents is improved more with an explicit\ncultural perspective than with a targeted prompt language. Unexpectedly,\ncombining both approaches is no more effective than cultural framing with an\nEnglish prompt. These findings reveal that LLMs occupy an uncomfortable middle\nground: They are responsive enough to changes in prompts to produce variation,\nbut too firmly anchored to specific cultural defaults to adequately represent\ncultural diversity.", "AI": {"tldr": "LLMs\u5bf9\u63d0\u793a\u8bed\u8a00\u548c\u6587\u5316\u6846\u67b6\u654f\u611f\uff0c\u4f46\u5b58\u5728\u7cfb\u7edf\u6027\u6587\u5316\u504f\u89c1\uff0c\u504f\u5411\u8377\u5170\u3001\u5fb7\u56fd\u3001\u7f8e\u56fd\u548c\u65e5\u672c\u7684\u4ef7\u503c\u89c2\uff0c\u65e0\u6cd5\u5145\u5206\u4ee3\u8868\u5168\u7403\u6587\u5316\u591a\u6837\u6027\u3002", "motivation": "\u7814\u7a76LLMs\u662f\u5426\u80fd\u4ee3\u8868\u5176\u5e7f\u6cdb\u7528\u6237\u7fa4\u4f53\u7684\u6587\u5316\u591a\u6837\u6027\uff0c\u56e0\u4e3a\u5b58\u5728\u8bad\u7ec3\u6570\u636e\u548c\u4f18\u5316\u76ee\u6807\u4e0d\u5e73\u8861\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u970d\u592b\u65af\u6cf0\u5fb7\u4ef7\u503c\u89c2\u8c03\u67e5\u6a21\u5757\u548c\u4e16\u754c\u4ef7\u503c\u89c2\u8c03\u67e5\u768463\u4e2a\u9879\u76ee\uff0c\u7ffb\u8bd1\u621011\u79cd\u8bed\u8a00\uff0c\u6d4b\u8bd510\u4e2aLLMs\u5728\u4e0d\u540c\u6587\u5316\u89c6\u89d2\u4e0b\u7684\u54cd\u5e94\u3002", "result": "\u63d0\u793a\u8bed\u8a00\u548c\u6587\u5316\u89c6\u89d2\u90fd\u4f1a\u5f71\u54cdLLM\u8f93\u51fa\uff0c\u4f46\u6a21\u578b\u7cfb\u7edf\u6027\u504f\u5411\u7279\u5b9a\u56fd\u5bb6\u7684\u4ef7\u503c\u89c2\u3002\u6587\u5316\u6846\u67b6\u6bd4\u9488\u5bf9\u6027\u63d0\u793a\u8bed\u8a00\u66f4\u80fd\u6539\u5584\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u5339\u914d\u5ea6\u3002", "conclusion": "LLMs\u5904\u4e8e\u5c34\u5c2c\u7684\u4e2d\u95f4\u5730\u5e26\uff1a\u5bf9\u63d0\u793a\u53d8\u5316\u654f\u611f\uff0c\u4f46\u8fc7\u4e8e\u56fa\u5b88\u7279\u5b9a\u6587\u5316\u9ed8\u8ba4\u503c\uff0c\u65e0\u6cd5\u5145\u5206\u4ee3\u8868\u6587\u5316\u591a\u6837\u6027\u3002"}}
{"id": "2511.03985", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03985", "abs": "https://arxiv.org/abs/2511.03985", "authors": ["Zhuowen Yuan", "Tao Liu", "Yang Yang", "Yang Wang", "Feng Qi", "Kaushik Rangadurai", "Bo Li", "Shuang Yang"], "title": "ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning Engineering", "comment": null, "summary": "Recent LLM-based agents have demonstrated strong capabilities in automated ML\nengineering. However, they heavily rely on repeated full training runs to\nevaluate candidate solutions, resulting in significant computational overhead,\nlimited scalability to large search spaces, and slow iteration cycles. To\naddress these challenges, we introduce ArchPilot, a multi-agent system that\nintegrates architecture generation, proxy-based evaluation, and adaptive search\ninto a unified framework. ArchPilot consists of three specialized agents: an\norchestration agent that coordinates the search process using a Monte Carlo\nTree Search (MCTS)-inspired novel algorithm with a restart mechanism and\nmanages memory of previous candidates; a generation agent that iteratively\ngenerates, improves, and debugs candidate architectures; and an evaluation\nagent that executes proxy training runs, generates and optimizes proxy\nfunctions, and aggregates the proxy scores into a fidelity-aware performance\nmetric. This multi-agent collaboration allows ArchPilot to prioritize\nhigh-potential candidates with minimal reliance on expensive full training\nruns, facilitating efficient ML engineering under limited budgets. Experiments\non MLE-Bench demonstrate that ArchPilot outperforms SOTA baselines such as AIDE\nand ML-Master, validating the effectiveness of our multi-agent system.", "AI": {"tldr": "ArchPilot\u662f\u4e00\u4e2a\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u67b6\u6784\u751f\u6210\u3001\u57fa\u4e8e\u4ee3\u7406\u7684\u8bc4\u4f30\u548c\u81ea\u9002\u5e94\u641c\u7d22\u6765\u89e3\u51b3LLM\u4ee3\u7406\u5728\u81ea\u52a8\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u4e2d\u7684\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u53ef\u6269\u5c55\u6027\u5dee\u548c\u8fed\u4ee3\u5468\u671f\u6162\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684LLM\u4ee3\u7406\u5728\u81ea\u52a8\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u4e2d\u4e25\u91cd\u4f9d\u8d56\u91cd\u590d\u7684\u5b8c\u6574\u8bad\u7ec3\u6765\u8bc4\u4f30\u5019\u9009\u65b9\u6848\uff0c\u5bfc\u81f4\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u5728\u5927\u641c\u7d22\u7a7a\u95f4\u4e2d\u53ef\u6269\u5c55\u6027\u5dee\u3001\u8fed\u4ee3\u5468\u671f\u6162\u3002", "method": "\u91c7\u7528\u591a\u4ee3\u7406\u534f\u4f5c\u6846\u67b6\uff0c\u5305\u542b\u7f16\u6392\u4ee3\u7406\uff08\u4f7f\u7528MCTS\u542f\u53d1\u7b97\u6cd5\u534f\u8c03\u641c\u7d22\uff09\u3001\u751f\u6210\u4ee3\u7406\uff08\u8fed\u4ee3\u751f\u6210\u548c\u6539\u8fdb\u67b6\u6784\uff09\u548c\u8bc4\u4f30\u4ee3\u7406\uff08\u6267\u884c\u4ee3\u7406\u8bad\u7ec3\u5e76\u751f\u6210\u4fdd\u771f\u5ea6\u611f\u77e5\u6027\u80fd\u6307\u6807\uff09\u3002", "result": "\u5728MLE-Bench\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cArchPilot\u4f18\u4e8eAIDE\u548cML-Master\u7b49\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ArchPilot\u901a\u8fc7\u591a\u4ee3\u7406\u534f\u4f5c\uff0c\u80fd\u591f\u5728\u6709\u9650\u9884\u7b97\u4e0b\u4f18\u5148\u8003\u8651\u9ad8\u6f5c\u529b\u5019\u9009\u65b9\u6848\uff0c\u51cf\u5c11\u5bf9\u6602\u8d35\u5b8c\u6574\u8bad\u7ec3\u7684\u4f9d\u8d56\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u3002"}}
{"id": "2511.04032", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04032", "abs": "https://arxiv.org/abs/2511.04032", "authors": ["Divya Pathak", "Harshit Kumar", "Anuska Roy", "Felix George", "Mudit Verma", "Pratibha Moogi"], "title": "Detecting Silent Failures in Multi-Agentic AI Trajectories", "comment": null, "summary": "Multi-Agentic AI systems, powered by large language models (LLMs), are\ninherently non-deterministic and prone to silent failures such as drift,\ncycles, and missing details in outputs, which are difficult to detect. We\nintroduce the task of anomaly detection in agentic trajectories to identify\nthese failures and present a dataset curation pipeline that captures user\nbehavior, agent non-determinism, and LLM variation. Using this pipeline, we\ncurate and label two benchmark datasets comprising \\textbf{4,275 and 894}\ntrajectories from Multi-Agentic AI systems. Benchmarking anomaly detection\nmethods on these datasets, we show that supervised (XGBoost) and\nsemi-supervised (SVDD) approaches perform comparably, achieving accuracies up\nto 98% and 96%, respectively. This work provides the first systematic study of\nanomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks,\nand insights to guide future research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\uff0c\u901a\u8fc7\u6784\u5efa\u5305\u542b4,275\u548c894\u6761\u8f68\u8ff9\u7684\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e86\u76d1\u7763\u548c\u534a\u76d1\u7763\u65b9\u6cd5\u5728\u68c0\u6d4b\u6f02\u79fb\u3001\u5faa\u73af\u548c\u8f93\u51fa\u7f3a\u5931\u7b49\u65e0\u58f0\u6545\u969c\u65b9\u9762\u7684\u6027\u80fd\u3002", "motivation": "\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u5177\u6709\u975e\u786e\u5b9a\u6027\u4e14\u5bb9\u6613\u51fa\u73b0\u96be\u4ee5\u68c0\u6d4b\u7684\u65e0\u58f0\u6545\u969c\uff0c\u5982\u6f02\u79fb\u3001\u5faa\u73af\u548c\u8f93\u51fa\u7ec6\u8282\u7f3a\u5931\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u636e\u96c6\u6784\u5efa\u6d41\u7a0b\uff0c\u6355\u6349\u7528\u6237\u884c\u4e3a\u3001\u667a\u80fd\u4f53\u975e\u786e\u5b9a\u6027\u548cLLM\u53d8\u5f02\uff0c\u5e76\u521b\u5efa\u4e86\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u3002\u4f7f\u7528XGBoost\uff08\u76d1\u7763\uff09\u548cSVDD\uff08\u534a\u76d1\u7763\uff09\u65b9\u6cd5\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u76d1\u7763\u65b9\u6cd5\uff08XGBoost\uff09\u548c\u534a\u76d1\u7763\u65b9\u6cd5\uff08SVDD\uff09\u8868\u73b0\u76f8\u5f53\uff0c\u51c6\u786e\u7387\u5206\u522b\u8fbe\u523098%\u548c96%\u3002", "conclusion": "\u8fd9\u662f\u5bf9\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u4e2d\u5f02\u5e38\u68c0\u6d4b\u7684\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\uff0c\u63d0\u4f9b\u4e86\u6570\u636e\u96c6\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u89c1\u89e3\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2511.04053", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04053", "abs": "https://arxiv.org/abs/2511.04053", "authors": ["Hirohane Takagi", "Gouki Minegishi", "Shota Kizawa", "Issey Sukeda", "Hitomi Yanaka"], "title": "Interpreting Multi-Attribute Confounding through Numerical Attributes in Large Language Models", "comment": "Accepted to IJCNLP-AACL 2025 (Main). Code available at\n  https://github.com/htkg/num_attrs", "summary": "Although behavioral studies have documented numerical reasoning errors in\nlarge language models (LLMs), the underlying representational mechanisms remain\nunclear. We hypothesize that numerical attributes occupy shared latent\nsubspaces and investigate two questions:(1) How do LLMs internally integrate\nmultiple numerical attributes of a single entity? (2)How does irrelevant\nnumerical context perturb these representations and their downstream outputs?\nTo address these questions, we combine linear probing with partial correlation\nanalysis and prompt-based vulnerability tests across models of varying sizes.\nOur results show that LLMs encode real-world numerical correlations but tend to\nsystematically amplify them. Moreover, irrelevant context induces consistent\nshifts in magnitude representations, with downstream effects that vary by model\nsize. These findings reveal a vulnerability in LLM decision-making and lay the\ngroundwork for fairer, representation-aware control under multi-attribute\nentanglement.", "AI": {"tldr": "LLMs\u5728\u6570\u503c\u63a8\u7406\u4e2d\u5b58\u5728\u7cfb\u7edf\u9519\u8bef\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u6570\u503c\u5c5e\u6027\u5728\u5171\u4eab\u6f5c\u5728\u5b50\u7a7a\u95f4\u4e2d\u7f16\u7801\u65f6\u4f1a\u653e\u5927\u771f\u5b9e\u4e16\u754c\u76f8\u5173\u6027\uff0c\u4e14\u65e0\u5173\u4e0a\u4e0b\u6587\u4f1a\u5e72\u6270\u6570\u503c\u8868\u793a\uff0c\u5f71\u54cd\u51b3\u7b56\u8d28\u91cf\u3002", "motivation": "\u5c3d\u7ba1\u884c\u4e3a\u7814\u7a76\u53d1\u73b0LLMs\u5b58\u5728\u6570\u503c\u63a8\u7406\u9519\u8bef\uff0c\u4f46\u5176\u5185\u90e8\u8868\u793a\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002\u7814\u7a76\u65e8\u5728\u63ed\u793aLLMs\u5982\u4f55\u6574\u5408\u5355\u4e2a\u5b9e\u4f53\u7684\u591a\u4e2a\u6570\u503c\u5c5e\u6027\uff0c\u4ee5\u53ca\u65e0\u5173\u6570\u503c\u4e0a\u4e0b\u6587\u5982\u4f55\u5e72\u6270\u8fd9\u4e9b\u8868\u793a\u3002", "method": "\u7ed3\u5408\u7ebf\u6027\u63a2\u6d4b\u4e0e\u504f\u76f8\u5173\u5206\u6790\uff0c\u5728\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u4e0a\u8fdb\u884c\u57fa\u4e8e\u63d0\u793a\u7684\u8106\u5f31\u6027\u6d4b\u8bd5\uff0c\u7814\u7a76\u6570\u503c\u5c5e\u6027\u7684\u5185\u90e8\u8868\u793a\u673a\u5236\u3002", "result": "LLMs\u7f16\u7801\u4e86\u771f\u5b9e\u4e16\u754c\u7684\u6570\u503c\u76f8\u5173\u6027\u4f46\u4f1a\u7cfb\u7edf\u6027\u5730\u653e\u5927\u5b83\u4eec\uff1b\u65e0\u5173\u4e0a\u4e0b\u6587\u4f1a\u5f15\u8d77\u6570\u503c\u8868\u793a\u7684\u4e00\u81f4\u504f\u79fb\uff0c\u4e14\u4e0b\u6e38\u5f71\u54cd\u968f\u6a21\u578b\u89c4\u6a21\u53d8\u5316\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u63ed\u793a\u4e86LLM\u51b3\u7b56\u4e2d\u7684\u8106\u5f31\u6027\uff0c\u4e3a\u5728\u591a\u5c5e\u6027\u7ea0\u7f20\u4e0b\u5b9e\u73b0\u66f4\u516c\u5e73\u3001\u8868\u793a\u611f\u77e5\u7684\u63a7\u5236\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.04076", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04076", "abs": "https://arxiv.org/abs/2511.04076", "authors": ["Hao Li", "Haotian Chen", "Ruoyuan Gong", "Juanjuan Wang", "Hao Jiang"], "title": "Agentmandering: A Game-Theoretic Framework for Fair Redistricting via Large Language Model Agents", "comment": "Accepted by AAAI AISI 2026", "summary": "Redistricting plays a central role in shaping how votes are translated into\npolitical power. While existing computational methods primarily aim to generate\nlarge ensembles of legally valid districting plans, they often neglect the\nstrategic dynamics involved in the selection process. This oversight creates\nopportunities for partisan actors to cherry-pick maps that, while technically\ncompliant, are politically advantageous. Simply satisfying formal constraints\ndoes not ensure fairness when the selection process itself can be manipulated.\nWe propose \\textbf{Agentmandering}, a framework that reimagines redistricting\nas a turn-based negotiation between two agents representing opposing political\ninterests. Drawing inspiration from game-theoretic ideas, particularly the\n\\textit{Choose-and-Freeze} protocol, our method embeds strategic interaction\ninto the redistricting process via large language model (LLM) agents. Agents\nalternate between selecting and freezing districts from a small set of\ncandidate maps, gradually partitioning the state through constrained and\ninterpretable choices. Evaluation on post-2020 U.S. Census data across all\nstates shows that Agentmandering significantly reduces partisan bias and\nunfairness, while achieving 2 to 3 orders of magnitude lower variance than\nstandard baselines. These results demonstrate both fairness and stability,\nespecially in swing-state scenarios. Our code is available at\nhttps://github.com/Lihaogx/AgentMandering.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aAgentmandering\u7684\u6846\u67b6\uff0c\u5c06\u9009\u533a\u91cd\u5212\u91cd\u65b0\u6784\u60f3\u4e3a\u4e24\u4e2a\u4ee3\u8868\u5bf9\u7acb\u653f\u6cbb\u5229\u76ca\u7684\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u56de\u5408\u5236\u8c08\u5224\uff0c\u901a\u8fc7LLM\u667a\u80fd\u4f53\u5c06\u6218\u7565\u4e92\u52a8\u5d4c\u5165\u5230\u9009\u533a\u91cd\u5212\u8fc7\u7a0b\u4e2d\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u515a\u6d3e\u504f\u89c1\u548c\u4e0d\u516c\u5e73\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u8ba1\u7b97\u65b9\u6cd5\u4e3b\u8981\u751f\u6210\u5927\u91cf\u6cd5\u5f8b\u4e0a\u6709\u6548\u7684\u9009\u533a\u91cd\u5212\u65b9\u6848\uff0c\u4f46\u5ffd\u89c6\u4e86\u9009\u62e9\u8fc7\u7a0b\u4e2d\u7684\u6218\u7565\u52a8\u6001\uff0c\u8fd9\u4e3a\u515a\u6d3e\u884c\u4e3a\u8005\u6311\u9009\u6280\u672f\u4e0a\u5408\u89c4\u4f46\u653f\u6cbb\u4e0a\u6709\u5229\u7684\u5730\u56fe\u521b\u9020\u4e86\u673a\u4f1a\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u535a\u5f08\u8bba\u601d\u60f3\u7684\"\u9009\u62e9\u5e76\u51bb\u7ed3\"\u534f\u8bae\uff0c\u8ba9\u4e24\u4e2a\u4ee3\u8868\u5bf9\u7acb\u653f\u6cbb\u5229\u76ca\u7684LLM\u667a\u80fd\u4f53\u8f6e\u6d41\u4ece\u4e00\u5c0f\u90e8\u5206\u5019\u9009\u5730\u56fe\u4e2d\u9009\u62e9\u548c\u51bb\u7ed3\u9009\u533a\uff0c\u901a\u8fc7\u53d7\u9650\u4e14\u53ef\u89e3\u91ca\u7684\u9009\u62e9\u9010\u6b65\u5212\u5206\u5dde\u3002", "result": "\u57282020\u5e74\u7f8e\u56fd\u4eba\u53e3\u666e\u67e5\u6570\u636e\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cAgentmandering\u663e\u8457\u51cf\u5c11\u4e86\u515a\u6d3e\u504f\u89c1\u548c\u4e0d\u516c\u5e73\u6027\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u6bd4\u6807\u51c6\u57fa\u7ebf\u4f4e2\u52303\u4e2a\u6570\u91cf\u7ea7\u7684\u65b9\u5dee\uff0c\u5728\u6447\u6446\u5dde\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u516c\u5e73\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "Agentmandering\u6846\u67b6\u901a\u8fc7\u5c06\u6218\u7565\u4e92\u52a8\u5d4c\u5165\u9009\u533a\u91cd\u5212\u8fc7\u7a0b\uff0c\u80fd\u591f\u6709\u6548\u51cf\u5c11\u515a\u6d3e\u504f\u89c1\uff0c\u63d0\u9ad8\u516c\u5e73\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5728\u7ade\u4e89\u6fc0\u70c8\u7684\u653f\u6cbb\u73af\u5883\u4e2d\u3002"}}
{"id": "2511.04093", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04093", "abs": "https://arxiv.org/abs/2511.04093", "authors": ["Yuanning Cui", "Zequn Sun", "Wei Hu", "Zhangjie Fu"], "title": "KGFR: A Foundation Retriever for Generalized Knowledge Graph Question Answering", "comment": null, "summary": "Large language models (LLMs) excel at reasoning but struggle with\nknowledge-intensive questions due to limited context and parametric knowledge.\nHowever, existing methods that rely on finetuned LLMs or GNN retrievers are\nlimited by dataset-specific tuning and scalability on large or unseen graphs.\nWe propose the LLM-KGFR collaborative framework, where an LLM works with a\nstructured retriever, the Knowledge Graph Foundation Retriever (KGFR). KGFR\nencodes relations using LLM-generated descriptions and initializes entities\nbased on their roles in the question, enabling zero-shot generalization to\nunseen KGs. To handle large graphs efficiently, it employs Asymmetric\nProgressive Propagation (APP)- a stepwise expansion that selectively limits\nhigh-degree nodes while retaining informative paths. Through node-, edge-, and\npath-level interfaces, the LLM iteratively requests candidate answers,\nsupporting facts, and reasoning paths, forming a controllable reasoning loop.\nExperiments demonstrate that LLM-KGFR achieves strong performance while\nmaintaining scalability and generalization, providing a practical solution for\nKG-augmented reasoning.", "AI": {"tldr": "\u63d0\u51faLLM-KGFR\u6846\u67b6\uff0c\u901a\u8fc7LLM\u4e0e\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u5668\u534f\u4f5c\uff0c\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u95ee\u9898\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u96f6\u6837\u672c\u6cdb\u5316\u548c\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21\u56fe\u8c31\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u64c5\u957f\u63a8\u7406\u4f46\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u95ee\u9898\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u6709\u65b9\u6cd5\u53d7\u9650\u4e8e\u6570\u636e\u96c6\u7279\u5b9a\u8c03\u4f18\u548c\u5927\u89c4\u6a21\u56fe\u8c31\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u4f7f\u7528LLM\u751f\u6210\u5173\u7cfb\u63cf\u8ff0\u7684\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u5668KGFR\uff0c\u901a\u8fc7\u975e\u5bf9\u79f0\u6e10\u8fdb\u4f20\u64ad\u7b97\u6cd5\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21\u56fe\u8c31\uff0c\u63d0\u4f9b\u8282\u70b9\u3001\u8fb9\u548c\u8def\u5f84\u7ea7\u63a5\u53e3\u652f\u6301\u8fed\u4ee3\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLLM-KGFR\u5728\u4fdd\u6301\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5f3a\u52b2\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u63a8\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u6027\u80fd\u4e0e\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.04133", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04133", "abs": "https://arxiv.org/abs/2511.04133", "authors": ["Miguel E. Andres", "Vadim Fedorov", "Rida Sadek", "Enric Spagnolo-Arrizabalaga", "Nadescha Trudel"], "title": "Testing the Testers: Human-Driven Quality Assessment of Voice AI Testing Platforms", "comment": null, "summary": "Voice AI agents are rapidly transitioning to production deployments, yet\nsystematic methods for ensuring testing reliability remain underdeveloped.\nOrganizations cannot objectively assess whether their testing approaches\n(internal tools or external platforms) actually work, creating a critical\nmeasurement gap as voice AI scales to billions of daily interactions.\n  We present the first systematic framework for evaluating voice AI testing\nquality through human-centered benchmarking. Our methodology addresses the\nfundamental dual challenge of testing platforms: generating realistic test\nconversations (simulation quality) and accurately evaluating agent responses\n(evaluation quality). The framework combines established psychometric\ntechniques (pairwise comparisons yielding Elo ratings, bootstrap confidence\nintervals, and permutation tests) with rigorous statistical validation to\nprovide reproducible metrics applicable to any testing approach.\n  To validate the framework and demonstrate its utility, we conducted\ncomprehensive empirical evaluation of three leading commercial platforms\nfocused on Voice AI Testing using 21,600 human judgments across 45 simulations\nand ground truth validation on 60 conversations. Results reveal statistically\nsignificant performance differences with the proposed framework, with the\ntop-performing platform, Evalion, achieving 0.92 evaluation quality measured as\nf1-score versus 0.73 for others, and 0.61 simulation quality using a league\nbased scoring system (including ties) vs 0.43 for other platforms.\n  This framework enables researchers and organizations to empirically validate\nthe testing capabilities of any platform, providing essential measurement\nfoundations for confident voice AI deployment at scale. Supporting materials\nare made available to facilitate reproducibility and adoption.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u7cfb\u7edf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30\u8bed\u97f3AI\u6d4b\u8bd5\u8d28\u91cf\uff0c\u89e3\u51b3\u4e86\u6d4b\u8bd5\u5e73\u53f0\u751f\u6210\u771f\u5b9e\u5bf9\u8bdd\u548c\u51c6\u786e\u8bc4\u4f30\u54cd\u5e94\u7684\u53cc\u91cd\u6311\u6218\u3002", "motivation": "\u968f\u7740\u8bed\u97f3AI\u4ee3\u7406\u5feb\u901f\u8fdb\u5165\u751f\u4ea7\u90e8\u7f72\uff0c\u786e\u4fdd\u6d4b\u8bd5\u53ef\u9760\u6027\u7684\u7cfb\u7edf\u65b9\u6cd5\u4ecd\u7136\u4e0d\u8db3\u3002\u7ec4\u7ec7\u65e0\u6cd5\u5ba2\u89c2\u8bc4\u4f30\u5176\u6d4b\u8bd5\u65b9\u6cd5\u662f\u5426\u771f\u6b63\u6709\u6548\uff0c\u5728\u8bed\u97f3AI\u6269\u5c55\u5230\u6570\u5341\u4ebf\u65e5\u5e38\u4ea4\u4e92\u65f6\u9020\u6210\u4e86\u5173\u952e\u7684\u6d4b\u91cf\u5dee\u8ddd\u3002", "method": "\u7ed3\u5408\u6210\u719f\u7684\u5fc3\u7406\u6d4b\u91cf\u6280\u672f\uff08\u6210\u5bf9\u6bd4\u8f83\u4ea7\u751fElo\u8bc4\u5206\u3001\u81ea\u4e3e\u7f6e\u4fe1\u533a\u95f4\u548c\u7f6e\u6362\u6d4b\u8bd5\uff09\u4e0e\u4e25\u683c\u7684\u7edf\u8ba1\u9a8c\u8bc1\uff0c\u63d0\u4f9b\u9002\u7528\u4e8e\u4efb\u4f55\u6d4b\u8bd5\u65b9\u6cd5\u7684\u53ef\u91cd\u590d\u6307\u6807\u3002", "result": "\u5bf9\u4e09\u4e2a\u9886\u5148\u5546\u4e1a\u5e73\u53f0\u8fdb\u884c\u4e86\u5168\u9762\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u5b58\u5728\u663e\u8457\u7684\u6027\u80fd\u5dee\u5f02\u3002\u8868\u73b0\u6700\u4f73\u7684\u5e73\u53f0Evalion\u5728\u8bc4\u4f30\u8d28\u91cf\u4e0a\u8fbe\u52300.92 F1\u5206\u6570\uff0c\u800c\u5176\u4ed6\u5e73\u53f0\u4e3a0.73\uff1b\u5728\u6a21\u62df\u8d28\u91cf\u4e0a\u8fbe\u52300.61\uff0c\u800c\u5176\u4ed6\u5e73\u53f0\u4e3a0.43\u3002", "conclusion": "\u8be5\u6846\u67b6\u4f7f\u7814\u7a76\u4eba\u5458\u548c\u7ec4\u7ec7\u80fd\u591f\u5b9e\u8bc1\u9a8c\u8bc1\u4efb\u4f55\u5e73\u53f0\u7684\u6d4b\u8bd5\u80fd\u529b\uff0c\u4e3a\u5927\u89c4\u6a21\u81ea\u4fe1\u90e8\u7f72\u8bed\u97f3AI\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u6d4b\u91cf\u57fa\u7840\u3002"}}
{"id": "2511.04177", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04177", "abs": "https://arxiv.org/abs/2511.04177", "authors": ["Claire Yang", "Maya Cakmak", "Max Kleiman-Weiner"], "title": "When Empowerment Disempowers", "comment": null, "summary": "Empowerment, a measure of an agent's ability to control its environment, has\nbeen proposed as a universal goal-agnostic objective for motivating assistive\nbehavior in AI agents. While multi-human settings like homes and hospitals are\npromising for AI assistance, prior work on empowerment-based assistance assumes\nthat the agent assists one human in isolation. We introduce an open source\nmulti-human gridworld test suite Disempower-Grid. Using Disempower-Grid, we\nempirically show that assistive RL agents optimizing for one human's\nempowerment can significantly reduce another human's environmental influence\nand rewards - a phenomenon we formalize as disempowerment. We characterize when\ndisempowerment occurs in these environments and show that joint empowerment\nmitigates disempowerment at the cost of the user's reward. Our work reveals a\nbroader challenge for the AI alignment community: goal-agnostic objectives that\nseem aligned in single-agent settings can become misaligned in multi-agent\ncontexts.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.04220", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04220", "abs": "https://arxiv.org/abs/2511.04220", "authors": ["Alan Seroul", "Th\u00e9o Fagnoni", "In\u00e8s Adnani", "Dana O. Mohamed", "Phillip Kingston"], "title": "Opus: A Quantitative Framework for Workflow Evaluation", "comment": null, "summary": "This paper introduces the Opus Workflow Evaluation Framework, a\nprobabilistic-normative formulation for quantifying Workflow quality and\nefficiency. It integrates notions of correctness, reliability, and cost into a\ncoherent mathematical model that enables direct comparison, scoring, and\noptimization of Workflows. The framework combines the Opus Workflow Reward, a\nprobabilistic function estimating expected performance through success\nlikelihood, resource usage, and output gain, with the Opus Workflow Normative\nPenalties, a set of measurable functions capturing structural and informational\nquality across Cohesion, Coupling, Observability, and Information Hygiene. It\nsupports automated Workflow assessment, ranking, and optimization within modern\nautomation systems such as Opus and can be integrated into Reinforcement\nLearning loops to guide Workflow discovery and refinement. In this paper, we\nintroduce the Opus Workflow Reward model that formalizes Workflow success as a\nprobabilistic expectation over costs and outcomes. We define measurable Opus\nWorkflow Normative Penalties capturing structural, semantic, and signal-related\nproperties of Workflows. Finally, we propose a unified optimization formulation\nfor identifying and ranking optimal Workflows under joint Reward-Penalty\ntrade-offs.", "AI": {"tldr": "Opus\u5de5\u4f5c\u6d41\u8bc4\u4f30\u6846\u67b6\uff1a\u4e00\u4e2a\u7ed3\u5408\u6982\u7387\u5956\u52b1\u548c\u89c4\u8303\u6027\u60e9\u7f5a\u7684\u6570\u5b66\u6a21\u578b\uff0c\u7528\u4e8e\u91cf\u5316\u5de5\u4f5c\u6d41\u8d28\u91cf\u3001\u6548\u7387\u548c\u7ed3\u6784\u7279\u6027\uff0c\u652f\u6301\u81ea\u52a8\u5316\u8bc4\u4f30\u3001\u6392\u5e8f\u548c\u4f18\u5316\u3002", "motivation": "\u9700\u8981\u4e00\u79cd\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\u6765\u91cf\u5316\u5de5\u4f5c\u6d41\u7684\u8d28\u91cf\u548c\u6548\u7387\uff0c\u7ed3\u5408\u6b63\u786e\u6027\u3001\u53ef\u9760\u6027\u548c\u6210\u672c\u7b49\u56e0\u7d20\uff0c\u5b9e\u73b0\u5de5\u4f5c\u6d41\u7684\u76f4\u63a5\u6bd4\u8f83\u3001\u8bc4\u5206\u548c\u4f18\u5316\u3002", "method": "\u7ed3\u5408Opus\u5de5\u4f5c\u6d41\u5956\u52b1\uff08\u6982\u7387\u51fd\u6570\u4f30\u8ba1\u9884\u671f\u6027\u80fd\uff09\u548cOpus\u5de5\u4f5c\u6d41\u89c4\u8303\u6027\u60e9\u7f5a\uff08\u8861\u91cf\u7ed3\u6784\u4fe1\u606f\u8d28\u91cf\u7684\u53ef\u6d4b\u91cf\u51fd\u6570\uff09\uff0c\u5f62\u6210\u7edf\u4e00\u7684\u4f18\u5316\u516c\u5f0f\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u652f\u6301\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u8bc4\u4f30\u3001\u6392\u5e8f\u548c\u4f18\u5316\u7684\u6846\u67b6\uff0c\u53ef\u96c6\u6210\u5230\u5f3a\u5316\u5b66\u4e60\u5faa\u73af\u4e2d\u6307\u5bfc\u5de5\u4f5c\u6d41\u53d1\u73b0\u548c\u4f18\u5316\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5de5\u4f5c\u6d41\u8d28\u91cf\u8bc4\u4f30\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u6570\u5b66\u57fa\u7840\uff0c\u80fd\u591f\u8bc6\u522b\u548c\u6392\u5e8f\u5728\u5956\u52b1-\u60e9\u7f5a\u6743\u8861\u4e0b\u7684\u6700\u4f18\u5de5\u4f5c\u6d41\u3002"}}
{"id": "2511.04235", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.04235", "abs": "https://arxiv.org/abs/2511.04235", "authors": ["Zhengru Fang", "Yu Guo", "Jingjing Wang", "Yuang Zhang", "Haonan An", "Yinhai Wang", "Yuguang Fang"], "title": "Shared Spatial Memory Through Predictive Coding", "comment": "We have prepared the open-source code and video demonstration pages:\n  1. Code: github.com/fangzr/SSM-PC 2. Demo: fangzr.github.io/SSM-PC/index.html", "summary": "Sharing and reconstructing a consistent spatial memory is a critical\nchallenge in multi-agent systems, where partial observability and limited\nbandwidth often lead to catastrophic failures in coordination. We introduce a\nmulti-agent predictive coding framework that formulate coordination as the\nminimization of mutual uncertainty among agents. Instantiated as an information\nbottleneck objective, it prompts agents to learn not only who and what to\ncommunicate but also when. At the foundation of this framework lies a\ngrid-cell-like metric as internal spatial coding for self-localization,\nemerging spontaneously from self-supervised motion prediction. Building upon\nthis internal spatial code, agents gradually develop a bandwidth-efficient\ncommunication mechanism and specialized neural populations that encode\npartners' locations: an artificial analogue of hippocampal social place cells\n(SPCs). These social representations are further enacted by a hierarchical\nreinforcement learning policy that actively explores to reduce joint\nuncertainty. On the Memory-Maze benchmark, our approach shows exceptional\nresilience to bandwidth constraints: success degrades gracefully from 73.5% to\n64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast\nbaseline collapses from 67.6% to 28.6%. Our findings establish a theoretically\nprincipled and biologically plausible basis for how complex social\nrepresentations emerge from a unified predictive drive, leading to social\ncollective intelligence.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u9884\u6d4b\u7f16\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u667a\u80fd\u4f53\u95f4\u7684\u76f8\u4e92\u4e0d\u786e\u5b9a\u6027\u6765\u89e3\u51b3\u534f\u8c03\u95ee\u9898\uff0c\u5728\u5e26\u5bbd\u53d7\u9650\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\uff0c\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u548c\u6709\u9650\u5e26\u5bbd\u5e38\u5e38\u5bfc\u81f4\u534f\u8c03\u5931\u8d25\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5171\u4eab\u548c\u91cd\u5efa\u4e00\u81f4\u7a7a\u95f4\u8bb0\u5fc6\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4fe1\u606f\u74f6\u9888\u76ee\u6807\uff0c\u8ba9\u667a\u80fd\u4f53\u5b66\u4e60\u4f55\u65f6\u3001\u4e0e\u8c01\u3001\u4ee5\u53ca\u5982\u4f55\u901a\u4fe1\uff1b\u57fa\u4e8e\u7f51\u683c\u7ec6\u80de\u72b6\u5ea6\u91cf\u7684\u5185\u90e8\u7a7a\u95f4\u7f16\u7801\uff1b\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u4e3b\u52a8\u63a2\u7d22\u4ee5\u51cf\u5c11\u8054\u5408\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5728Memory-Maze\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u65b9\u6cd5\u5728\u5e26\u5bbd\u4ece128\u4f4d/\u6b65\u964d\u81f34\u4f4d/\u6b65\u65f6\uff0c\u6210\u529f\u7387\u4ece73.5%\u4f18\u96c5\u964d\u81f364.4%\uff0c\u800c\u5168\u5e7f\u64ad\u57fa\u7ebf\u4ece67.6%\u5d29\u6e83\u81f328.6%\u3002", "conclusion": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u7406\u8bba\u4e0a\u6709\u539f\u5219\u4e14\u751f\u7269\u5b66\u4e0a\u5408\u7406\u7684\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u590d\u6742\u793e\u4f1a\u8868\u5f81\u5982\u4f55\u4ece\u7edf\u4e00\u7684\u9884\u6d4b\u9a71\u52a8\u4e2d\u6d8c\u73b0\uff0c\u5b9e\u73b0\u793e\u4f1a\u96c6\u4f53\u667a\u80fd\u3002"}}
{"id": "2511.04285", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04285", "abs": "https://arxiv.org/abs/2511.04285", "authors": ["Zeng Zhiyuan", "Jiashuo Liu", "Zhangyue Yin", "Ge Zhang", "Wenhao Huang", "Xipeng Qiu"], "title": "RLoop: An Self-Improving Framework for Reinforcement Learning with Iterative Policy Initialization", "comment": null, "summary": "While Reinforcement Learning for Verifiable Rewards (RLVR) is powerful for\ntraining large reasoning models, its training dynamics harbor a critical\nchallenge: RL overfitting, where models gain training rewards but lose\ngeneralization. Our analysis reveals this is driven by policy\nover-specialization and catastrophic forgetting of diverse solutions generated\nduring training. Standard optimization discards this valuable inter-step policy\ndiversity. To address this, we introduce RLoop, a self-improving framework\nbuilt on iterative policy initialization. RLoop transforms the standard\ntraining process into a virtuous cycle: it first uses RL to explore the\nsolution space from a given policy, then filters the successful trajectories to\ncreate an expert dataset. This dataset is used via Rejection-sampling\nFine-Tuning (RFT) to refine the initial policy, creating a superior starting\npoint for the next iteration. This loop of exploration and exploitation via\niterative re-initialization effectively converts transient policy variations\ninto robust performance gains. Our experiments show RLoop mitigates forgetting\nand substantially improves generalization, boosting average accuracy by 9% and\npass@32 by over 15% compared to vanilla RL.", "AI": {"tldr": "RLVR\u8bad\u7ec3\u4e2d\u5b58\u5728RL\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u6a21\u578b\u83b7\u5f97\u8bad\u7ec3\u5956\u52b1\u4f46\u5931\u53bb\u6cdb\u5316\u80fd\u529b\u3002RLoop\u6846\u67b6\u901a\u8fc7\u8fed\u4ee3\u7b56\u7565\u521d\u59cb\u5316\uff0c\u5c06\u8bad\u7ec3\u8fc7\u7a0b\u8f6c\u5316\u4e3a\u63a2\u7d22\u548c\u5229\u7528\u7684\u826f\u6027\u5faa\u73af\uff0c\u6709\u6548\u7f13\u89e3\u9057\u5fd8\u5e76\u63d0\u5347\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3RLVR\u8bad\u7ec3\u4e2d\u7684RL\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5373\u6a21\u578b\u5728\u8bad\u7ec3\u4e2d\u83b7\u5f97\u5956\u52b1\u4f46\u5931\u53bb\u6cdb\u5316\u80fd\u529b\uff0c\u8fd9\u7531\u7b56\u7565\u8fc7\u5ea6\u4e13\u95e8\u5316\u548c\u707e\u96be\u6027\u9057\u5fd8\u9a71\u52a8\u3002", "method": "RLoop\u6846\u67b6\uff1a\u901a\u8fc7\u8fed\u4ee3\u7b56\u7565\u521d\u59cb\u5316\uff0c\u5148\u4f7f\u7528RL\u4ece\u7ed9\u5b9a\u7b56\u7565\u63a2\u7d22\u89e3\u7a7a\u95f4\uff0c\u7136\u540e\u8fc7\u6ee4\u6210\u529f\u8f68\u8ff9\u521b\u5efa\u4e13\u5bb6\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u5fae\u8c03(RFT)\u6765\u4f18\u5316\u521d\u59cb\u7b56\u7565\uff0c\u4e3a\u4e0b\u4e00\u6b21\u8fed\u4ee3\u521b\u5efa\u66f4\u597d\u7684\u8d77\u70b9\u3002", "result": "RLoop\u663e\u8457\u7f13\u89e3\u9057\u5fd8\u5e76\u63d0\u5347\u6cdb\u5316\u80fd\u529b\uff0c\u76f8\u6bd4\u539f\u59cbRL\u5e73\u5747\u51c6\u786e\u7387\u63d0\u53479%\uff0cpass@32\u63d0\u5347\u8d85\u8fc715%\u3002", "conclusion": "RLoop\u901a\u8fc7\u5c06\u77ac\u6001\u7b56\u7565\u53d8\u5316\u8f6c\u5316\u4e3a\u7a33\u5065\u6027\u80fd\u589e\u76ca\uff0c\u6709\u6548\u89e3\u51b3\u4e86RL\u8bad\u7ec3\u4e2d\u7684\u8fc7\u62df\u5408\u548c\u9057\u5fd8\u95ee\u9898\u3002"}}
{"id": "2511.04307", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04307", "abs": "https://arxiv.org/abs/2511.04307", "authors": ["Jian Mu", "Chaoyun Zhang", "Chiming Ni", "Lu Wang", "Bo Qiao", "Kartik Mathur", "Qianhui Wu", "Yuhang Xie", "Xiaojun Ma", "Mengyu Zhou", "Si Qin", "Liqun Li", "Yu Kang", "Minghua Ma", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang"], "title": "GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents", "comment": null, "summary": "We introduce GUI-360$^\\circ$, a large-scale, comprehensive dataset and\nbenchmark suite designed to advance computer-using agents (CUAs). CUAs present\nunique challenges and is constrained by three persistent gaps: a scarcity of\nreal-world CUA tasks, the lack of automated collection-and-annotation pipelines\nfor multi-modal trajectories, and the absence of a unified benchmark that\njointly evaluates GUI grounding, screen parsing, and action prediction.\n  GUI-360$^\\circ$ addresses these gaps with an LLM-augmented, largely automated\npipeline for query sourcing, environment-template construction, task\ninstantiation, batched execution, and LLM-driven quality filtering. The\nreleased corpus contains over 1.2M executed action steps across thousands of\ntrajectories in popular Windows office applications, and includes\nfull-resolution screenshots, accessibility metadata when available,\ninstantiated goals, intermediate reasoning traces, and both successful and\nfailed action trajectories. The dataset supports three canonical tasks, GUI\ngrounding, screen parsing, and action prediction, and a hybrid GUI+API action\nspace that reflects modern agent designs. Benchmarking state-of-the-art\nvision--language models on GUI-360$^\\circ$ reveals substantial out-of-the-box\nshortcomings in grounding and action prediction; supervised fine-tuning and\nreinforcement learning yield significant gains but do not close the gap to\nhuman-level reliability. We release GUI-360$^\\circ$ and accompanying code to\nfacilitate reproducible research and accelerate progress on robust desktop\nCUAs.\n  The full dataset has been made public on\nhttps://huggingface.co/datasets/vyokky/GUI-360.", "AI": {"tldr": "GUI-360\u00b0\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u57fa\u51c6\u5957\u4ef6\uff0c\u7528\u4e8e\u63a8\u8fdb\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\uff08CUAs\uff09\u7684\u7814\u7a76\uff0c\u5305\u542b\u8d85\u8fc7120\u4e07\u6267\u884c\u52a8\u4f5c\u6b65\u9aa4\uff0c\u652f\u6301GUI\u5b9a\u4f4d\u3001\u5c4f\u5e55\u89e3\u6790\u548c\u52a8\u4f5c\u9884\u6d4b\u4e09\u4e2a\u6838\u5fc3\u4efb\u52a1\u3002", "motivation": "\u89e3\u51b3\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7814\u7a76\u4e2d\u7684\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u771f\u5b9eCUA\u4efb\u52a1\u7684\u7a00\u7f3a\u6027\u3001\u591a\u6a21\u6001\u8f68\u8ff9\u81ea\u52a8\u6536\u96c6\u6807\u6ce8\u6d41\u7a0b\u7684\u7f3a\u4e4f\uff0c\u4ee5\u53ca\u7edf\u4e00\u8bc4\u4f30GUI\u5b9a\u4f4d\u3001\u5c4f\u5e55\u89e3\u6790\u548c\u52a8\u4f5c\u9884\u6d4b\u7684\u57fa\u51c6\u7684\u7f3a\u5931\u3002", "method": "\u91c7\u7528LLM\u589e\u5f3a\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\uff0c\u5305\u62ec\u67e5\u8be2\u6765\u6e90\u3001\u73af\u5883\u6a21\u677f\u6784\u5efa\u3001\u4efb\u52a1\u5b9e\u4f8b\u5316\u3001\u6279\u91cf\u6267\u884c\u548cLLM\u9a71\u52a8\u7684\u8d28\u91cf\u8fc7\u6ee4\uff0c\u5728Windows\u529e\u516c\u5e94\u7528\u4e2d\u6536\u96c6\u6570\u5343\u6761\u8f68\u8ff9\u6570\u636e\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u6700\u5148\u8fdb\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u5b9a\u4f4d\u548c\u52a8\u4f5c\u9884\u6d4b\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u867d\u6709\u6539\u8fdb\u4f46\u672a\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u53ef\u9760\u6027\u3002", "conclusion": "GUI-360\u00b0\u7684\u53d1\u5e03\u65e8\u5728\u4fc3\u8fdb\u53ef\u91cd\u590d\u7814\u7a76\u5e76\u52a0\u901f\u7a33\u5065\u684c\u9762CUAs\u7684\u8fdb\u5c55\uff0c\u6570\u636e\u96c6\u5df2\u5728Hugging Face\u516c\u5f00\u3002"}}
{"id": "2511.04312", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04312", "abs": "https://arxiv.org/abs/2511.04312", "authors": ["Jacob Lysn\u00e6s-Larsen", "Marte Eggen", "Inga Str\u00fcmke"], "title": "Probing the Probes: Methods and Metrics for Concept Alignment", "comment": "29 pages, 17 figures", "summary": "In explainable AI, Concept Activation Vectors (CAVs) are typically obtained\nby training linear classifier probes to detect human-understandable concepts as\ndirections in the activation space of deep neural networks. It is widely\nassumed that a high probe accuracy indicates a CAV faithfully representing its\ntarget concept. However, we show that the probe's classification accuracy alone\nis an unreliable measure of concept alignment, i.e., the degree to which a CAV\ncaptures the intended concept. In fact, we argue that probes are more likely to\ncapture spurious correlations than they are to represent only the intended\nconcept. As part of our analysis, we demonstrate that deliberately misaligned\nprobes constructed to exploit spurious correlations, achieve an accuracy close\nto that of standard probes. To address this severe problem, we introduce a\nnovel concept localization method based on spatial linear attribution, and\nprovide a comprehensive comparison of it to existing feature visualization\ntechniques for detecting and mitigating concept misalignment. We further\npropose three classes of metrics for quantitatively assessing concept\nalignment: hard accuracy, segmentation scores, and augmentation robustness. Our\nanalysis shows that probes with translation invariance and spatial alignment\nconsistently increase concept alignment. These findings highlight the need for\nalignment-based evaluation metrics rather than probe accuracy, and the\nimportance of tailoring probes to both the model architecture and the nature of\nthe target concept.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u5728\u53ef\u89e3\u91caAI\u4e2d\uff0c\u4ec5\u51ed\u7ebf\u6027\u5206\u7c7b\u5668\u63a2\u9488\u7684\u51c6\u786e\u7387\u65e0\u6cd5\u53ef\u9760\u8bc4\u4f30\u6982\u5ff5\u6fc0\u6d3b\u5411\u91cf(CAV)\u4e0e\u76ee\u6807\u6982\u5ff5\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u56e0\u4e3a\u63a2\u9488\u5bb9\u6613\u6355\u6349\u865a\u5047\u76f8\u5173\u6027\u800c\u975e\u771f\u6b63\u6982\u5ff5\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u57fa\u4e8e\u7a7a\u95f4\u7ebf\u6027\u5f52\u56e0\u7684\u65b0\u6982\u5ff5\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e09\u7c7b\u91cf\u5316\u6307\u6807\u6765\u8bc4\u4f30\u6982\u5ff5\u5bf9\u9f50\u3002", "motivation": "\u5f53\u524d\u53ef\u89e3\u91caAI\u9886\u57df\u666e\u904d\u5047\u8bbe\u9ad8\u63a2\u9488\u51c6\u786e\u7387\u610f\u5473\u7740CAV\u80fd\u5fe0\u5b9e\u8868\u793a\u76ee\u6807\u6982\u5ff5\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0\u8fd9\u79cd\u5047\u8bbe\u4e0d\u53ef\u9760\uff0c\u63a2\u9488\u66f4\u5bb9\u6613\u6355\u6349\u865a\u5047\u76f8\u5173\u6027\u800c\u975e\u771f\u6b63\u6982\u5ff5\uff0c\u8fd9\u4e25\u91cd\u5f71\u54cd\u4e86\u6982\u5ff5\u89e3\u91ca\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u7a7a\u95f4\u7ebf\u6027\u5f52\u56e0\u7684\u6982\u5ff5\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u5e76\u4e0e\u73b0\u6709\u7279\u5f81\u53ef\u89c6\u5316\u6280\u672f\u8fdb\u884c\u6bd4\u8f83\uff1b\u5f15\u5165\u4e86\u4e09\u7c7b\u6982\u5ff5\u5bf9\u9f50\u8bc4\u4f30\u6307\u6807\uff1a\u786c\u51c6\u786e\u7387\u3001\u5206\u5272\u5f97\u5206\u548c\u589e\u5f3a\u9c81\u68d2\u6027\uff1b\u6784\u5efa\u4e86\u6545\u610f\u9519\u4f4d\u7684\u63a2\u9488\u6765\u9a8c\u8bc1\u95ee\u9898\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6545\u610f\u9519\u4f4d\u7684\u63a2\u9488\u5229\u7528\u865a\u5047\u76f8\u5173\u6027\u4e5f\u80fd\u8fbe\u5230\u63a5\u8fd1\u6807\u51c6\u63a2\u9488\u7684\u51c6\u786e\u7387\uff1b\u5177\u6709\u5e73\u79fb\u4e0d\u53d8\u6027\u548c\u7a7a\u95f4\u5bf9\u9f50\u7684\u63a2\u9488\u80fd\u6301\u7eed\u63d0\u9ad8\u6982\u5ff5\u5bf9\u9f50\u5ea6\uff1b\u4f20\u7edf\u63a2\u9488\u51c6\u786e\u7387\u65e0\u6cd5\u53ef\u9760\u8bc4\u4f30\u6982\u5ff5\u5bf9\u9f50\u3002", "conclusion": "\u9700\u8981\u57fa\u4e8e\u5bf9\u9f50\u7684\u8bc4\u4f30\u6307\u6807\u800c\u975e\u63a2\u9488\u51c6\u786e\u7387\u6765\u8bc4\u4f30\u6982\u5ff5\u8868\u793a\uff0c\u63a2\u9488\u8bbe\u8ba1\u5e94\u540c\u65f6\u8003\u8651\u6a21\u578b\u67b6\u6784\u548c\u76ee\u6807\u6982\u5ff5\u7684\u6027\u8d28\uff0c\u5e73\u79fb\u4e0d\u53d8\u6027\u548c\u7a7a\u95f4\u5bf9\u9f50\u5bf9\u63d0\u9ad8\u6982\u5ff5\u5bf9\u9f50\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.04316", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04316", "abs": "https://arxiv.org/abs/2511.04316", "authors": ["Tim Beyer", "Jonas Dornbusch", "Jakob Steimle", "Moritz Ladenburger", "Leo Schwinn", "Stephan G\u00fcnnemann"], "title": "AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research", "comment": null, "summary": "The rapid expansion of research on Large Language Model (LLM) safety and\nrobustness has produced a fragmented and oftentimes buggy ecosystem of\nimplementations, datasets, and evaluation methods. This fragmentation makes\nreproducibility and comparability across studies challenging, hindering\nmeaningful progress. To address these issues, we introduce AdversariaLLM, a\ntoolbox for conducting LLM jailbreak robustness research. Its design centers on\nreproducibility, correctness, and extensibility. The framework implements\ntwelve adversarial attack algorithms, integrates seven benchmark datasets\nspanning harmfulness, over-refusal, and utility evaluation, and provides access\nto a wide range of open-weight LLMs via Hugging Face. The implementation\nincludes advanced features for comparability and reproducibility such as\ncompute-resource tracking, deterministic results, and distributional evaluation\ntechniques. \\name also integrates judging through the companion package\nJudgeZoo, which can also be used independently. Together, these components aim\nto establish a robust foundation for transparent, comparable, and reproducible\nresearch in LLM safety.", "AI": {"tldr": "AdversariaLLM\u662f\u4e00\u4e2a\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u72f1\u9c81\u68d2\u6027\u7814\u7a76\u7684\u5de5\u5177\u7bb1\uff0c\u65e8\u5728\u89e3\u51b3\u5f53\u524dLLM\u5b89\u5168\u7814\u7a76\u751f\u6001\u7cfb\u7edf\u788e\u7247\u5316\u3001\u96be\u4ee5\u590d\u73b0\u548c\u6bd4\u8f83\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524dLLM\u5b89\u5168\u548c\u9c81\u68d2\u6027\u7814\u7a76\u751f\u6001\u7cfb\u7edf\u5b58\u5728\u788e\u7247\u5316\u3001\u5b9e\u73b0\u9519\u8bef\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u7814\u7a76\u96be\u4ee5\u590d\u73b0\u548c\u6bd4\u8f83\uff0c\u963b\u788d\u4e86\u6709\u610f\u4e49\u7684\u8fdb\u5c55\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4ee5\u53ef\u590d\u73b0\u6027\u3001\u6b63\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u4e3a\u6838\u5fc3\u7684\u5de5\u5177\u7bb1\uff0c\u5b9e\u73b0\u4e8612\u79cd\u5bf9\u6297\u653b\u51fb\u7b97\u6cd5\uff0c\u96c6\u6210\u4e867\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7Hugging Face\u63d0\u4f9b\u5bf9\u5404\u79cd\u5f00\u6e90LLM\u7684\u8bbf\u95ee\u3002", "result": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u8ba1\u7b97\u8d44\u6e90\u8ddf\u8e2a\u3001\u786e\u5b9a\u6027\u7ed3\u679c\u548c\u5206\u5e03\u8bc4\u4f30\u6280\u672f\u7b49\u9ad8\u7ea7\u529f\u80fd\uff0c\u786e\u4fdd\u53ef\u6bd4\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002", "conclusion": "AdversariaLLM\u4e3aLLM\u5b89\u5168\u7814\u7a76\u5efa\u7acb\u4e86\u900f\u660e\u3001\u53ef\u6bd4\u548c\u53ef\u590d\u73b0\u7684\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2511.04328", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04328", "abs": "https://arxiv.org/abs/2511.04328", "authors": ["Jiahao Zhao", "Luxin Xu", "Minghuan Tan", "Lichao Zhang", "Ahmadreza Argha", "Hamid Alinejad-Rokny", "Min Yang"], "title": "RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation", "comment": "To appear in BIBM2025", "summary": "Numerous medical systems powered by Large Language Models (LLMs) have\nachieved remarkable progress in diverse healthcare tasks. However, research on\ntheir medication safety remains limited due to the lack of real world datasets,\nconstrained by privacy and accessibility issues. Moreover, evaluation of LLMs\nin realistic clinical consultation settings, particularly regarding medication\nsafety, is still underexplored. To address these gaps, we propose a framework\nthat simulates and evaluates clinical consultations to systematically assess\nthe medication safety capabilities of LLMs. Within this framework, we generate\ninquiry diagnosis dialogues with embedded medication risks and construct a\ndedicated medication safety database, RxRisk DB, containing 6,725\ncontraindications, 28,781 drug interactions, and 14,906 indication-drug pairs.\nA two-stage filtering strategy ensures clinical realism and professional\nquality, resulting in the benchmark RxSafeBench with 2,443 high-quality\nconsultation scenarios. We evaluate leading open-source and proprietary LLMs\nusing structured multiple choice questions that test their ability to recommend\nsafe medications under simulated patient contexts. Results show that current\nLLMs struggle to integrate contraindication and interaction knowledge,\nespecially when risks are implied rather than explicit. Our findings highlight\nkey challenges in ensuring medication safety in LLM-based systems and provide\ninsights into improving reliability through better prompting and task-specific\ntuning. RxSafeBench offers the first comprehensive benchmark for evaluating\nmedication safety in LLMs, advancing safer and more trustworthy AI-driven\nclinical decision support.", "AI": {"tldr": "\u63d0\u51fa\u4e86RxSafeBench\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u4e34\u5e8a\u54a8\u8be2\u8bc4\u4f30LLMs\u7684\u836f\u7269\u5b89\u5168\u80fd\u529b\uff0c\u5305\u542b6,725\u79cd\u7981\u5fcc\u75c7\u300128,781\u79cd\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u548c14,906\u4e2a\u9002\u5e94\u75c7-\u836f\u7269\u5bf9\uff0c\u6784\u5efa\u4e862,443\u4e2a\u9ad8\u8d28\u91cf\u54a8\u8be2\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLMs\u7684\u533b\u7597\u7cfb\u7edf\u5728\u836f\u7269\u5b89\u5168\u65b9\u9762\u7684\u7814\u7a76\u6709\u9650\uff0c\u7f3a\u4e4f\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff0c\u4e14\u5728\u73b0\u5b9e\u4e34\u5e8a\u54a8\u8be2\u73af\u5883\u4e2d\u7684\u8bc4\u4f30\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1\u4e86\u6a21\u62df\u4e34\u5e8a\u54a8\u8be2\u7684\u6846\u67b6\uff0c\u751f\u6210\u5305\u542b\u836f\u7269\u98ce\u9669\u7684\u95ee\u8bca\u5bf9\u8bdd\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8fc7\u6ee4\u7b56\u7565\u786e\u4fdd\u4e34\u5e8a\u771f\u5b9e\u6027\u548c\u4e13\u4e1a\u8d28\u91cf\uff0c\u6784\u5efaRxRisk DB\u836f\u7269\u5b89\u5168\u6570\u636e\u5e93\u548cRxSafeBench\u57fa\u51c6\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u5f53\u524dLLMs\u96be\u4ee5\u6574\u5408\u7981\u5fcc\u75c7\u548c\u76f8\u4e92\u4f5c\u7528\u77e5\u8bc6\uff0c\u7279\u522b\u662f\u5f53\u98ce\u9669\u662f\u9690\u542b\u800c\u975e\u660e\u786e\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86LLM\u7cfb\u7edf\u5728\u786e\u4fdd\u836f\u7269\u5b89\u5168\u65b9\u9762\u7684\u5173\u952e\u6311\u6218\uff0cRxSafeBench\u4e3a\u8bc4\u4f30LLMs\u836f\u7269\u5b89\u5168\u80fd\u529b\u63d0\u4f9b\u4e86\u9996\u4e2a\u5168\u9762\u57fa\u51c6\uff0c\u63a8\u52a8\u66f4\u5b89\u5168\u53ef\u9760\u7684AI\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2511.04341", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04341", "abs": "https://arxiv.org/abs/2511.04341", "authors": ["Nick Oh", "Fernand Gobet"], "title": "Monitor-Generate-Verify (MGV):Formalising Metacognitive Theory for Language Model Reasoning", "comment": "To-be presented at the Workshop on the Foundations of Reasoning in\n  Language Models at NeurIPS 2025 (non-archival)", "summary": "Test-time reasoning architectures such as those following the Generate-Verify\nparadigm -- where a model iteratively refines or verifies its own generated\noutputs -- prioritise generation and verification but exclude the monitoring\nprocesses that determine when and how reasoning should begin. This omission may\ncontribute to the prefix dominance trap, in which models commit early to\nsuboptimal reasoning paths and seldom recover, yielding roughly 20% accuracy\nloss. We address this architectural gap by formalising Flavell's and Nelson and\nNarens' metacognitive theories into computational specifications, proposing the\nMonitor-Generate-Verify (MGV) framework. MGV extends the Generate-Verify\nparadigm by adding explicit monitoring that captures metacognitive experiences\n(from difficulty assessments to confidence judgements) before generation begins\nand refines future monitoring through verification feedback. Though we present\nno empirical validation, this work provides the first systematic computational\ntranslation of foundational metacognitive theories, offering a principled\nvocabulary for understanding reasoning system failures and suggesting specific\narchitectural interventions for future test-time reasoning designs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Monitor-Generate-Verify (MGV)\u6846\u67b6\uff0c\u901a\u8fc7\u5728Generate-Verify\u8303\u5f0f\u524d\u6dfb\u52a0\u663e\u5f0f\u76d1\u63a7\u673a\u5236\u6765\u89e3\u51b3\u524d\u7f00\u4e3b\u5bfc\u9677\u9631\u95ee\u9898\uff0c\u5c06\u5143\u8ba4\u77e5\u7406\u8bba\u8f6c\u5316\u4e3a\u8ba1\u7b97\u89c4\u8303\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u63a8\u7406\u67b6\u6784\u7f3a\u4e4f\u76d1\u63a7\u8fc7\u7a0b\uff0c\u5bfc\u81f4\u6a21\u578b\u8fc7\u65e9\u9677\u5165\u6b21\u4f18\u63a8\u7406\u8def\u5f84\u800c\u96be\u4ee5\u6062\u590d\uff08\u7ea620%\u51c6\u786e\u7387\u635f\u5931\uff09\uff0c\u5373\u524d\u7f00\u4e3b\u5bfc\u9677\u9631\u95ee\u9898\u3002", "method": "\u5c06Flavell\u548cNelson-Narens\u7684\u5143\u8ba4\u77e5\u7406\u8bba\u5f62\u5f0f\u5316\u4e3a\u8ba1\u7b97\u89c4\u8303\uff0c\u5728Generate-Verify\u8303\u5f0f\u524d\u6dfb\u52a0\u663e\u5f0f\u76d1\u63a7\u6a21\u5757\uff0c\u6355\u83b7\u751f\u6210\u524d\u7684\u5143\u8ba4\u77e5\u4f53\u9a8c\u5e76\u901a\u8fc7\u9a8c\u8bc1\u53cd\u9988\u4f18\u5316\u672a\u6765\u76d1\u63a7\u3002", "result": "\u867d\u7136\u672a\u63d0\u4f9b\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u4f46\u9996\u6b21\u7cfb\u7edf\u5730\u5c06\u57fa\u7840\u5143\u8ba4\u77e5\u7406\u8bba\u8f6c\u5316\u4e3a\u8ba1\u7b97\u6846\u67b6\uff0c\u4e3a\u7406\u89e3\u63a8\u7406\u7cfb\u7edf\u5931\u8d25\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u8bcd\u6c47\u3002", "conclusion": "MGV\u6846\u67b6\u4e3a\u672a\u6765\u6d4b\u8bd5\u65f6\u63a8\u7406\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u67b6\u6784\u5e72\u9884\u5efa\u8bae\uff0c\u586b\u8865\u4e86\u73b0\u6709\u67b6\u6784\u4e2d\u76d1\u63a7\u8fc7\u7a0b\u7684\u7f3a\u5931\u3002"}}
{"id": "2511.04393", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04393", "abs": "https://arxiv.org/abs/2511.04393", "authors": ["Chanwoo Park", "Ziyang Chen", "Asuman Ozdaglar", "Kaiqing Zhang"], "title": "Post-Training LLMs as Better Decision-Making Agents: A Regret-Minimization Approach", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed as \"agents\" for\ndecision-making (DM) in interactive and dynamic environments. Yet, since they\nwere not originally designed for DM, recent studies show that LLMs can struggle\neven in basic online DM problems, failing to achieve low regret or an effective\nexploration-exploitation tradeoff. To address this, we introduce Iterative\nRegret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure\nthat repeatedly distills low-regret decision trajectories back into the base\nmodel. At each iteration, the model rolls out multiple decision trajectories,\nselects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior\nmethods that (a) distill action sequences from known DM algorithms or (b) rely\non manually crafted chain-of-thought templates, our approach leverages the\nregret metric to elicit the model's own DM ability and reasoning rationales.\nThis reliance on model-generated reasoning avoids rigid output engineering and\nprovides more flexible, natural-language training signals. Empirical results\nshow that Iterative RMFT improves LLMs' DM performance across diverse models -\nfrom Transformers with numerical input/output, to open-weight LLMs, and\nadvanced closed-weight models like GPT-4o mini. Its flexibility in output and\nreasoning formats enables generalization across tasks with varying horizons,\naction spaces, reward processes, and natural-language contexts. Finally, we\nprovide theoretical insight showing that a single-layer Transformer under this\nparadigm can act as a no-regret learner in a simplified setting. Overall,\nIterative RMFT offers a principled and general post-training framework for\nenhancing LLMs' decision-making capabilities.", "AI": {"tldr": "\u63d0\u51faIterative RMFT\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u84b8\u998f\u4f4e\u540e\u6094\u51b3\u7b56\u8f68\u8ff9\u6765\u589e\u5f3aLLM\u7684\u51b3\u7b56\u80fd\u529b\uff0c\u65e0\u9700\u4f9d\u8d56\u5df2\u77e5\u7b97\u6cd5\u6216\u4eba\u5de5\u6a21\u677f", "motivation": "LLM\u4f5c\u4e3a\u51b3\u7b56\u4ee3\u7406\u65f6\u5728\u57fa\u7840\u5728\u7ebf\u51b3\u7b56\u95ee\u9898\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u96be\u4ee5\u5b9e\u73b0\u4f4e\u540e\u6094\u6216\u6709\u6548\u7684\u63a2\u7d22-\u5229\u7528\u6743\u8861", "method": "\u8fed\u4ee3\u540e\u6094\u6700\u5c0f\u5316\u5fae\u8c03\uff1a\u6a21\u578b\u591a\u6b21\u751f\u6210\u51b3\u7b56\u8f68\u8ff9\uff0c\u9009\u62e9k\u4e2a\u6700\u4f4e\u540e\u6094\u7684\u8f68\u8ff9\uff0c\u7136\u540e\u5728\u8fd9\u4e9b\u8f68\u8ff9\u4e0a\u5fae\u8c03\u81ea\u8eab", "result": "Iterative RMFT\u63d0\u5347\u4e86\u591a\u79cd\u6a21\u578b\uff08\u4eceTransformer\u5230GPT-4o mini\uff09\u7684\u51b3\u7b56\u6027\u80fd\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u4e0d\u540c\u4efb\u52a1\u8bbe\u7f6e", "conclusion": "Iterative RMFT\u4e3a\u589e\u5f3aLLM\u51b3\u7b56\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u4e14\u901a\u7528\u7684\u540e\u8bad\u7ec3\u6846\u67b6"}}
{"id": "2511.04439", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04439", "abs": "https://arxiv.org/abs/2511.04439", "authors": ["Anisha Garg", "Ganesh Venkatesh"], "title": "The Peril of Preference: Why GRPO fails on Ordinal Rewards", "comment": null, "summary": "Group-relative Policy Optimization's (GRPO) simplicity makes it highly\ndesirable for adapting LLMs to become experts at specific tasks. But this\nsimplicity also makes it ill-specified as we seek to enhance RL training with\nricher, non-binary feedback. When using ordinal rewards to give partial credit,\nGRPO's simplicity starts to hurt, as its group-average baseline often assigns a\npositive advantage to failed trajectories and reinforces incorrect behavior.\n  We introduce Correctness Relative Policy Optimization (CoRPO), a new\nformulation that solves this flaw. CoRPO uses an adaptive baseline that\nenforces a minimum quality threshold, ensuring failed solutions are never\npositively reinforced. Once the policy consistently meets this threshold, the\nbaseline automatically transitions to a relative preference mode, pushing the\nmodel to find optimal solutions rather than just \"acceptable\" ones. We\nempirically validate CoRPO on a code verification task, where it demonstrates\nmore stable convergence and better out-of-domain generalization.\n  This work represents a critical step in our broader research program to\nenable LLMs to learn genuinely new capabilities through reinforcement learning.\nWe achieve this by enabling LLMs to learn from rich, multi-dimensional feedback\n- progressing from binary to ordinal rewards in this work, and onward to\ndenser, per-step supervision.", "AI": {"tldr": "CoRPO\u89e3\u51b3\u4e86GRPO\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u5904\u7406\u5e8f\u6570\u5956\u52b1\u65f6\u7684\u7f3a\u9677\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u57fa\u7ebf\u786e\u4fdd\u5931\u8d25\u8f68\u8ff9\u4e0d\u88ab\u6b63\u5411\u5f3a\u5316\uff0c\u5e76\u5728\u8fbe\u5230\u8d28\u91cf\u9608\u503c\u540e\u8f6c\u5411\u76f8\u5bf9\u504f\u597d\u6a21\u5f0f\u4ee5\u5bfb\u627e\u6700\u4f18\u89e3\u3002", "motivation": "GRPO\u5728\u5904\u7406\u5e8f\u6570\u5956\u52b1\u65f6\u5b58\u5728\u7f3a\u9677\uff0c\u5176\u7ec4\u5e73\u5747\u57fa\u7ebf\u4f1a\u7ed9\u5931\u8d25\u8f68\u8ff9\u5206\u914d\u6b63\u4f18\u52bf\u503c\uff0c\u4ece\u800c\u5f3a\u5316\u9519\u8bef\u884c\u4e3a\u3002\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u5904\u7406\u66f4\u4e30\u5bcc\u7684\u975e\u4e8c\u5143\u53cd\u9988\u3002", "method": "\u63d0\u51faCoRPO\u65b9\u6cd5\uff0c\u4f7f\u7528\u81ea\u9002\u5e94\u57fa\u7ebf\u5f3a\u5236\u6267\u884c\u6700\u4f4e\u8d28\u91cf\u9608\u503c\uff0c\u786e\u4fdd\u5931\u8d25\u89e3\u51b3\u65b9\u6848\u6c38\u8fdc\u4e0d\u4f1a\u88ab\u6b63\u5411\u5f3a\u5316\u3002\u5f53\u7b56\u7565\u6301\u7eed\u6ee1\u8db3\u9608\u503c\u540e\uff0c\u57fa\u7ebf\u81ea\u52a8\u8fc7\u6e21\u5230\u76f8\u5bf9\u504f\u597d\u6a21\u5f0f\u3002", "result": "\u5728\u4ee3\u7801\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u5b9e\u8bc1\u9a8c\u8bc1\uff0cCoRPO\u8868\u73b0\u51fa\u66f4\u7a33\u5b9a\u7684\u6536\u655b\u6027\u548c\u66f4\u597d\u7684\u57df\u5916\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "CoRPO\u662f\u4f7fLLM\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b66\u4e60\u771f\u6b63\u65b0\u80fd\u529b\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u80fd\u591f\u5904\u7406\u4ece\u4e8c\u5143\u5230\u5e8f\u6570\u5956\u52b1\u7684\u4e30\u5bcc\u591a\u7ef4\u53cd\u9988\u3002"}}
{"id": "2511.04464", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04464", "abs": "https://arxiv.org/abs/2511.04464", "authors": ["Carnot Braun", "Rafael O. Jarczewski", "Gabriel U. Talasso", "Leandro A. Villas", "Allan M. de Souza"], "title": "Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context", "comment": null, "summary": "Traditional vehicle routing systems efficiently optimize singular metrics\nlike time or distance, and when considering multiple metrics, they need more\nprocesses to optimize . However, they lack the capability to interpret and\nintegrate the complex, semantic, and dynamic contexts of human drivers, such as\nmulti-step tasks, situational constraints, or urgent needs. This paper\nintroduces and evaluates PAVe (Personalized Agentic Vehicular Routing), a\nhybrid agentic assistant designed to augment classical pathfinding algorithms\nwith contextual reasoning. Our approach employs a Large Language Model (LLM)\nagent that operates on a candidate set of routes generated by a multi-objective\n(time, CO2) Dijkstra algorithm. The agent evaluates these options against\nuser-provided tasks, preferences, and avoidance rules by leveraging a\npre-processed geospatial cache of urban Points of Interest (POIs). In a\nbenchmark of realistic urban scenarios, PAVe successfully used complex user\nintent into appropriate route modifications, achieving over 88% accuracy in its\ninitial route selections with a local model. We conclude that combining\nclassical routing algorithms with an LLM-based semantic reasoning layer is a\nrobust and effective approach for creating personalized, adaptive, and scalable\nsolutions for urban mobility optimization.", "AI": {"tldr": "PAVe\u7cfb\u7edf\u7ed3\u5408\u4f20\u7edf\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\u4e0eLLM\u8bed\u4e49\u63a8\u7406\uff0c\u901a\u8fc7\u591a\u76ee\u6807Dijkstra\u7b97\u6cd5\u751f\u6210\u5019\u9009\u8def\u7ebf\uff0c\u518d\u7531LLM\u4ee3\u7406\u6839\u636e\u7528\u6237\u4efb\u52a1\u3001\u504f\u597d\u548c\u89c4\u907f\u89c4\u5219\u8fdb\u884c\u8bed\u4e49\u8bc4\u4f30\uff0c\u5b9e\u73b0\u4e2a\u6027\u5316\u8f66\u8f86\u8def\u7ebf\u89c4\u5212\u3002", "motivation": "\u4f20\u7edf\u8f66\u8f86\u8def\u7ebf\u7cfb\u7edf\u53ea\u80fd\u4f18\u5316\u5355\u4e00\u6307\u6807\uff0c\u7f3a\u4e4f\u5bf9\u9a7e\u9a76\u5458\u590d\u6742\u8bed\u4e49\u548c\u52a8\u6001\u4e0a\u4e0b\u6587\u7684\u7406\u89e3\u80fd\u529b\uff0c\u65e0\u6cd5\u5904\u7406\u591a\u6b65\u9aa4\u4efb\u52a1\u3001\u60c5\u5883\u7ea6\u675f\u6216\u7d27\u6025\u9700\u6c42\u3002", "method": "\u91c7\u7528\u6df7\u5408\u4ee3\u7406\u65b9\u6cd5\uff1a\u591a\u76ee\u6807\uff08\u65f6\u95f4\u3001CO2\uff09Dijkstra\u7b97\u6cd5\u751f\u6210\u5019\u9009\u8def\u7ebf\uff0cLLM\u4ee3\u7406\u57fa\u4e8e\u9884\u5904\u7406\u7684\u5730\u7406\u7a7a\u95f4POI\u7f13\u5b58\uff0c\u8bc4\u4f30\u8def\u7ebf\u662f\u5426\u7b26\u5408\u7528\u6237\u4efb\u52a1\u3001\u504f\u597d\u548c\u89c4\u907f\u89c4\u5219\u3002", "result": "\u5728\u771f\u5b9e\u57ce\u5e02\u573a\u666f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPAVe\u6210\u529f\u5c06\u590d\u6742\u7528\u6237\u610f\u56fe\u8f6c\u5316\u4e3a\u9002\u5f53\u8def\u7ebf\u4fee\u6539\uff0c\u4f7f\u7528\u672c\u5730\u6a21\u578b\u65f6\u521d\u59cb\u8def\u7ebf\u9009\u62e9\u51c6\u786e\u7387\u8d85\u8fc788%\u3002", "conclusion": "\u5c06\u7ecf\u5178\u8def\u7531\u7b97\u6cd5\u4e0e\u57fa\u4e8eLLM\u7684\u8bed\u4e49\u63a8\u7406\u5c42\u76f8\u7ed3\u5408\uff0c\u662f\u521b\u5efa\u4e2a\u6027\u5316\u3001\u81ea\u9002\u5e94\u548c\u53ef\u6269\u5c55\u57ce\u5e02\u79fb\u52a8\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u7684\u7a33\u5065\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2511.04481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04481", "abs": "https://arxiv.org/abs/2511.04481", "authors": ["Lars Krupp", "Daniel Gei\u00dfler", "Vishal Banwari", "Paul Lukowicz", "Jakob Karolus"], "title": "Promoting Sustainable Web Agents: Benchmarking and Estimating Energy Consumption through Empirical and Theoretical Analysis", "comment": "Accepted by AAAI 2026 AISI", "summary": "Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful\nagentic systems pushing the boundaries of Large Language Models (LLM). They can\nautonomously interact with the internet at the user's behest, such as\nnavigating websites, filling search masks, and comparing price lists. Though\nweb agent research is thriving, induced sustainability issues remain largely\nunexplored. To highlight the urgency of this issue, we provide an initial\nexploration of the energy and $CO_2$ cost associated with web agents from both\na theoretical -via estimation- and an empirical perspective -by benchmarking.\nOur results show how different philosophies in web agent creation can severely\nimpact the associated expended energy, and that more energy consumed does not\nnecessarily equate to better results. We highlight a lack of transparency\nregarding disclosing model parameters and processes used for some web agents as\na limiting factor when estimating energy consumption. Our work contributes\ntowards a change in thinking of how we evaluate web agents, advocating for\ndedicated metrics measuring energy consumption in benchmarks.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u63a2\u8ba8\u4e86\u7f51\u7edc\u4ee3\u7406\u7684\u80fd\u6e90\u6d88\u8017\u548c\u78b3\u6392\u653e\u95ee\u9898\uff0c\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u8bc1\u5206\u6790\u63ed\u793a\u4e86\u4e0d\u540c\u7f51\u7edc\u4ee3\u7406\u8bbe\u8ba1\u7406\u5ff5\u5bf9\u80fd\u6e90\u6d88\u8017\u7684\u663e\u8457\u5f71\u54cd\uff0c\u5e76\u547c\u5401\u5728\u8bc4\u4f30\u7f51\u7edc\u4ee3\u7406\u65f6\u8003\u8651\u80fd\u6e90\u6548\u7387\u6307\u6807\u3002", "motivation": "\u5c3d\u7ba1\u7f51\u7edc\u4ee3\u7406\u7814\u7a76\u84ec\u52c3\u53d1\u5c55\uff0c\u4f46\u5176\u5f15\u53d1\u7684\u53ef\u6301\u7eed\u6027\u95ee\u9898\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u7f51\u7edc\u4ee3\u7406\u7684\u80fd\u6e90\u548c\u78b3\u6392\u653e\u6210\u672c\uff0c\u5f3a\u8c03\u8fd9\u4e00\u95ee\u9898\u7684\u7d27\u8feb\u6027\u3002", "method": "\u91c7\u7528\u7406\u8bba\u4f30\u8ba1\u548c\u5b9e\u8bc1\u57fa\u51c6\u6d4b\u8bd5\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u4ece\u7406\u8bba\u548c\u5b9e\u8df5\u4e24\u4e2a\u89d2\u5ea6\u5206\u6790\u7f51\u7edc\u4ee3\u7406\u7684\u80fd\u6e90\u6d88\u8017\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u7f51\u7edc\u4ee3\u7406\u8bbe\u8ba1\u7406\u5ff5\u4f1a\u4e25\u91cd\u5f71\u54cd\u80fd\u6e90\u6d88\u8017\uff0c\u4e14\u66f4\u591a\u80fd\u6e90\u6d88\u8017\u5e76\u4e0d\u4e00\u5b9a\u5e26\u6765\u66f4\u597d\u7ed3\u679c\u3002\u540c\u65f6\u53d1\u73b0\u67d0\u4e9b\u7f51\u7edc\u4ee3\u7406\u5728\u62ab\u9732\u6a21\u578b\u53c2\u6570\u548c\u6d41\u7a0b\u65b9\u9762\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u9650\u5236\u4e86\u80fd\u6e90\u6d88\u8017\u7684\u51c6\u786e\u4f30\u8ba1\u3002", "conclusion": "\u672c\u6587\u547c\u5401\u6539\u53d8\u7f51\u7edc\u4ee3\u7406\u7684\u8bc4\u4f30\u65b9\u5f0f\uff0c\u5efa\u8bae\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5f15\u5165\u4e13\u95e8\u7684\u80fd\u6e90\u6d88\u8017\u5ea6\u91cf\u6307\u6807\uff0c\u4ee5\u4fc3\u8fdb\u66f4\u53ef\u6301\u7eed\u7684\u7f51\u7edc\u4ee3\u7406\u53d1\u5c55\u3002"}}
{"id": "2511.04500", "categories": ["cs.AI", "cs.CL", "cs.GT", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04500", "abs": "https://arxiv.org/abs/2511.04500", "authors": ["Andrea Cera Palatsi", "Samuel Martin-Gutierrez", "Ana S. Cardenal", "Max Pellert"], "title": "Large language models replicate and predict human cooperation across experiments in game theory", "comment": null, "summary": "Large language models (LLMs) are increasingly used both to make decisions in\ndomains such as health, education and law, and to simulate human behavior. Yet\nhow closely LLMs mirror actual human decision-making remains poorly understood.\nThis gap is critical: misalignment could produce harmful outcomes in practical\napplications, while failure to replicate human behavior renders LLMs\nineffective for social simulations. Here, we address this gap by developing a\ndigital twin of game-theoretic experiments and introducing a systematic\nprompting and probing framework for machine-behavioral evaluation. Testing\nthree open-source models (Llama, Mistral and Qwen), we find that Llama\nreproduces human cooperation patterns with high fidelity, capturing human\ndeviations from rational choice theory, while Qwen aligns closely with Nash\nequilibrium predictions. Notably, we achieved population-level behavioral\nreplication without persona-based prompting, simplifying the simulation\nprocess. Extending beyond the original human-tested games, we generate and\npreregister testable hypotheses for novel game configurations outside the\noriginal parameter grid. Our findings demonstrate that appropriately calibrated\nLLMs can replicate aggregate human behavioral patterns and enable systematic\nexploration of unexplored experimental spaces, offering a complementary\napproach to traditional research in the social and behavioral sciences that\ngenerates new empirical predictions about human social decision-making.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLMs\u80fd\u591f\u590d\u5236\u4eba\u7c7b\u5408\u4f5c\u884c\u4e3a\u6a21\u5f0f\uff0cLlama\u6a21\u578b\u80fd\u9ad8\u4fdd\u771f\u91cd\u73b0\u4eba\u7c7b\u504f\u79bb\u7406\u6027\u9009\u62e9\u7406\u8bba\u7684\u884c\u4e3a\uff0c\u800cQwen\u6a21\u578b\u66f4\u63a5\u8fd1\u7eb3\u4ec0\u5747\u8861\u9884\u6d4b\uff0c\u65e0\u9700\u57fa\u4e8e\u89d2\u8272\u7684\u63d0\u793a\u5373\u53ef\u5b9e\u73b0\u7fa4\u4f53\u884c\u4e3a\u590d\u5236\u3002", "motivation": "\u7406\u89e3LLMs\u4e0e\u4eba\u7c7b\u51b3\u7b56\u7684\u76f8\u4f3c\u6027\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u4e0d\u5339\u914d\u53ef\u80fd\u5bfc\u81f4\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u5bb3\u7ed3\u679c\uff0c\u800c\u65e0\u6cd5\u590d\u5236\u4eba\u7c7b\u884c\u4e3a\u4f1a\u4f7fLLMs\u5728\u793e\u4f1a\u6a21\u62df\u4e2d\u65e0\u6548\u3002", "method": "\u5f00\u53d1\u6e38\u620f\u7406\u8bba\u5b9e\u9a8c\u7684\u6570\u5b57\u5b6a\u751f\uff0c\u5f15\u5165\u7cfb\u7edf\u6027\u7684\u63d0\u793a\u548c\u63a2\u6d4b\u6846\u67b6\u8fdb\u884c\u673a\u5668\u884c\u4e3a\u8bc4\u4f30\uff0c\u6d4b\u8bd5\u4e09\u4e2a\u5f00\u6e90\u6a21\u578b\uff08Llama\u3001Mistral\u548cQwen\uff09\u3002", "result": "Llama\u80fd\u9ad8\u4fdd\u771f\u91cd\u73b0\u4eba\u7c7b\u5408\u4f5c\u6a21\u5f0f\uff0c\u6355\u6349\u4eba\u7c7b\u504f\u79bb\u7406\u6027\u9009\u62e9\u7406\u8bba\u7684\u884c\u4e3a\uff1bQwen\u4e0e\u7eb3\u4ec0\u5747\u8861\u9884\u6d4b\u9ad8\u5ea6\u4e00\u81f4\uff1b\u65e0\u9700\u89d2\u8272\u63d0\u793a\u5373\u53ef\u5b9e\u73b0\u7fa4\u4f53\u884c\u4e3a\u590d\u5236\uff1b\u751f\u6210\u5e76\u9884\u6ce8\u518c\u4e86\u539f\u59cb\u53c2\u6570\u7f51\u683c\u5916\u65b0\u6e38\u620f\u914d\u7f6e\u7684\u53ef\u6d4b\u8bd5\u5047\u8bbe\u3002", "conclusion": "\u9002\u5f53\u6821\u51c6\u7684LLMs\u53ef\u4ee5\u590d\u5236\u805a\u5408\u4eba\u7c7b\u884c\u4e3a\u6a21\u5f0f\uff0c\u5e76\u80fd\u591f\u7cfb\u7edf\u63a2\u7d22\u672a\u5f00\u53d1\u7684\u5b9e\u9a8c\u7a7a\u95f4\uff0c\u4e3a\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u8865\u5145\u65b9\u6cd5\uff0c\u751f\u6210\u5173\u4e8e\u4eba\u7c7b\u793e\u4ea4\u51b3\u7b56\u7684\u65b0\u7ecf\u9a8c\u9884\u6d4b\u3002"}}
{"id": "2511.04556", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.04556", "abs": "https://arxiv.org/abs/2511.04556", "authors": ["Zihang Ding", "Kun Zhang"], "title": "Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse Sensing Approach", "comment": "32 pages (including supplementary information), 11 figures (and 7\n  figures in supplementary). Submitted to Nature Water. Partially presented at\n  HydroML 2025 Symposium, Minnesota Water Resources Conference 2025, and will\n  be presented at AGU Fall Meeting 2025", "summary": "Urban surface water flooding, triggered by intense rainfall overwhelming\ndrainage systems, is increasingly frequent and widespread. While flood\nprediction and monitoring in high spatial-temporal resolution are desired,\npractical constraints in time, budget, and technology hinder its full\nimplementation. How to monitor urban drainage networks and predict flow\nconditions under constrained resource is a major challenge. This study presents\na data-driven sparse sensing (DSS) framework, integrated with EPA-SWMM, to\noptimize sensor placement and reconstruct peak flowrates in a stormwater\nsystem, using the Woodland Avenue catchment in Duluth, Minnesota, as a case\nstudy. We utilized a SWMM model to generate a training dataset of peak flowrate\nprofiles across the stormwater network. Furthermore, we applied DSS -\nleveraging singular value decomposition for dimensionality reduction and QR\nfactorization for sensor allocation - to identify the optimal monitoring nodes\nbased on the simulated training dataset. We then validated the\nrepresentativeness of these identified monitoring nodes by comparing the\nDSS-reconstructed peak flowrate profiles with those obtained from SWMM. Three\noptimally placed sensors among 77 nodes achieved satisfactory reconstruction\nperformance with Nash-Sutcliffe Efficiency (NSE) values of 0.92-0.95 (25th to\n75th percentiles). In addition, the model showed good robustness to uncertainty\nin measurements. Its robustness to sensor failures is location-dependent and\nimproves with the number of sensors deployed. The framework balances\ncomputational efficiency and physical interpretability, enabling high-accuracy\nflow reconstruction with minimal sensors. This DSS framework can be further\nintegrated with predictive models to realize flood early warning and real-time\ncontrol under limited sensing and monitoring resource.", "AI": {"tldr": "\u63d0\u51fa\u6570\u636e\u9a71\u52a8\u7684\u7a00\u758f\u4f20\u611f\u6846\u67b6\uff0c\u7ed3\u5408EPA-SWMM\u6a21\u578b\uff0c\u4f18\u5316\u4f20\u611f\u5668\u5e03\u8bbe\u5e76\u91cd\u5efa\u96e8\u6c34\u7cfb\u7edf\u5cf0\u503c\u6d41\u91cf\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9ad8\u6548\u6d2a\u6c34\u76d1\u6d4b\u3002", "motivation": "\u57ce\u5e02\u5730\u8868\u6d2a\u6c34\u56e0\u5f3a\u964d\u96e8\u8d85\u51fa\u6392\u6c34\u7cfb\u7edf\u80fd\u529b\u800c\u65e5\u76ca\u9891\u53d1\uff0c\u4f46\u9ad8\u65f6\u7a7a\u5206\u8fa8\u7387\u6d2a\u6c34\u9884\u6d4b\u548c\u76d1\u6d4b\u9762\u4e34\u65f6\u95f4\u3001\u9884\u7b97\u548c\u6280\u672f\u9650\u5236\u3002\u5982\u4f55\u5728\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u76d1\u6d4b\u57ce\u5e02\u6392\u6c34\u7f51\u7edc\u5e76\u9884\u6d4b\u6d41\u91cf\u72b6\u51b5\u662f\u4e3b\u8981\u6311\u6218\u3002", "method": "\u4f7f\u7528SWMM\u6a21\u578b\u751f\u6210\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5e94\u7528\u6570\u636e\u9a71\u52a8\u7a00\u758f\u4f20\u611f\u6846\u67b6\uff0c\u5229\u7528\u5947\u5f02\u503c\u5206\u89e3\u964d\u7ef4\u548cQR\u5206\u89e3\u8fdb\u884c\u4f20\u611f\u5668\u5206\u914d\uff0c\u57fa\u4e8e\u6a21\u62df\u8bad\u7ec3\u6570\u636e\u96c6\u8bc6\u522b\u6700\u4f18\u76d1\u6d4b\u8282\u70b9\u3002", "result": "\u572877\u4e2a\u8282\u70b9\u4e2d\u4ec5\u97003\u4e2a\u4f18\u5316\u5e03\u8bbe\u7684\u4f20\u611f\u5668\u5373\u53ef\u5b9e\u73b0\u6ee1\u610f\u91cd\u5efa\u6548\u679c\uff0c\u7eb3\u4ec0-\u8428\u514b\u5229\u592b\u6548\u7387\u503c\u4e3a0.92-0.95\u3002\u6a21\u578b\u5bf9\u6d4b\u91cf\u4e0d\u786e\u5b9a\u6027\u5177\u6709\u826f\u597d\u9c81\u68d2\u6027\uff0c\u5bf9\u4f20\u611f\u5668\u6545\u969c\u7684\u9c81\u68d2\u6027\u968f\u90e8\u7f72\u4f20\u611f\u5668\u6570\u91cf\u589e\u52a0\u800c\u6539\u5584\u3002", "conclusion": "\u8be5\u6846\u67b6\u5e73\u8861\u8ba1\u7b97\u6548\u7387\u548c\u7269\u7406\u53ef\u89e3\u91ca\u6027\uff0c\u80fd\u4ee5\u6700\u5c11\u4f20\u611f\u5668\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u6d41\u91cf\u91cd\u5efa\uff0c\u53ef\u8fdb\u4e00\u6b65\u4e0e\u9884\u6d4b\u6a21\u578b\u96c6\u6210\uff0c\u5728\u6709\u9650\u4f20\u611f\u548c\u76d1\u6d4b\u8d44\u6e90\u4e0b\u5b9e\u73b0\u6d2a\u6c34\u9884\u8b66\u548c\u5b9e\u65f6\u63a7\u5236\u3002"}}
{"id": "2511.04583", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04583", "abs": "https://arxiv.org/abs/2511.04583", "authors": ["Atsuyuki Miyai", "Mashiro Toyooka", "Takashi Otonari", "Zaiying Zhao", "Kiyoharu Aizawa"], "title": "Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper", "comment": "Issues, comments, and questions are all welcome in\n  https://github.com/Agent4Science-UTokyo/Jr.AI-Scientist", "summary": "Understanding the current capabilities and risks of AI Scientist systems is\nessential for ensuring trustworthy and sustainable AI-driven scientific\nprogress while preserving the integrity of the academic ecosystem. To this end,\nwe develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system\nthat mimics the core research workflow of a novice student researcher: Given\nthe baseline paper from the human mentor, it analyzes its limitations,\nformulates novel hypotheses for improvement, validates them through rigorous\nexperimentation, and writes a paper with the results. Unlike previous\napproaches that assume full automation or operate on small-scale code, Jr. AI\nScientist follows a well-defined research workflow and leverages modern coding\nagents to handle complex, multi-file implementations, leading to scientifically\nvaluable contributions. For evaluation, we conducted automated assessments\nusing AI Reviewers, author-led evaluations, and submissions to Agents4Science,\na venue dedicated to AI-driven scientific contributions. The findings\ndemonstrate that Jr. AI Scientist generates papers receiving higher review\nscores than existing fully automated systems. Nevertheless, we identify\nimportant limitations from both the author evaluation and the Agents4Science\nreviews, indicating the potential risks of directly applying current AI\nScientist systems and key challenges for future research. Finally, we\ncomprehensively report various risks identified during development. We hope\nthese insights will deepen understanding of current progress and risks in AI\nScientist development.", "AI": {"tldr": "\u5f00\u53d1\u4e86Jr. AI Scientist\u7cfb\u7edf\uff0c\u8fd9\u662f\u4e00\u4e2a\u6a21\u62df\u5b66\u751f\u7814\u7a76\u6d41\u7a0b\u7684\u81ea\u4e3bAI\u79d1\u5b66\u5bb6\u7cfb\u7edf\uff0c\u80fd\u591f\u5206\u6790\u8bba\u6587\u5c40\u9650\u6027\u3001\u63d0\u51fa\u5047\u8bbe\u3001\u5b9e\u9a8c\u9a8c\u8bc1\u5e76\u64b0\u5199\u8bba\u6587\uff0c\u5728\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u5168\u81ea\u52a8\u7cfb\u7edf\uff0c\u4f46\u4ecd\u5b58\u5728\u91cd\u8981\u5c40\u9650\u6027\u3002", "motivation": "\u7406\u89e3\u5f53\u524dAI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u7684\u80fd\u529b\u548c\u98ce\u9669\u5bf9\u4e8e\u786e\u4fdd\u53ef\u4fe1\u8d56\u548c\u53ef\u6301\u7eed\u7684AI\u9a71\u52a8\u79d1\u5b66\u8fdb\u6b65\u81f3\u5173\u91cd\u8981\uff0c\u540c\u65f6\u4fdd\u62a4\u5b66\u672f\u751f\u6001\u7cfb\u7edf\u7684\u5b8c\u6574\u6027\u3002", "method": "\u5f00\u53d1Jr. AI Scientist\u7cfb\u7edf\uff0c\u6a21\u62df\u65b0\u624b\u5b66\u751f\u7814\u7a76\u8005\u7684\u6838\u5fc3\u7814\u7a76\u6d41\u7a0b\uff1a\u5206\u6790\u57fa\u7ebf\u8bba\u6587\u5c40\u9650\u6027\u3001\u5236\u5b9a\u6539\u8fdb\u5047\u8bbe\u3001\u901a\u8fc7\u4e25\u683c\u5b9e\u9a8c\u9a8c\u8bc1\u3001\u64b0\u5199\u7ed3\u679c\u8bba\u6587\uff0c\u5229\u7528\u73b0\u4ee3\u7f16\u7801\u4ee3\u7406\u5904\u7406\u590d\u6742\u591a\u6587\u4ef6\u5b9e\u73b0\u3002", "result": "\u8bc4\u4f30\u663e\u793aJr. AI Scientist\u751f\u6210\u7684\u8bba\u6587\u83b7\u5f97\u6bd4\u73b0\u6709\u5168\u81ea\u52a8\u7cfb\u7edf\u66f4\u9ad8\u7684\u8bc4\u5ba1\u5206\u6570\uff0c\u4f46\u4f5c\u8005\u8bc4\u4f30\u548cAgents4Science\u8bc4\u5ba1\u90fd\u53d1\u73b0\u4e86\u91cd\u8981\u5c40\u9650\u6027\u3002", "conclusion": "\u5f53\u524dAI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u5b58\u5728\u76f4\u63a5\u5e94\u7528\u7684\u98ce\u9669\u548c\u5173\u952e\u6311\u6218\uff0c\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u8bc6\u522b\u4e86\u5404\u79cd\u98ce\u9669\uff0c\u8fd9\u4e9b\u89c1\u89e3\u6709\u52a9\u4e8e\u52a0\u6df1\u5bf9AI\u79d1\u5b66\u5bb6\u53d1\u5c55\u73b0\u72b6\u548c\u98ce\u9669\u7684\u7406\u89e3\u3002"}}
{"id": "2511.04584", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.04584", "abs": "https://arxiv.org/abs/2511.04584", "authors": ["Daniel Gomm", "Cornelius Wolff", "Madelon Hulsebos"], "title": "Are We Asking the Right Questions? On Ambiguity in Natural Language Queries for Tabular Data Analysis", "comment": "Accepted to the AI for Tabular Data workshop at EurIPS 2025", "summary": "Natural language interfaces to tabular data must handle ambiguities inherent\nto queries. Instead of treating ambiguity as a deficiency, we reframe it as a\nfeature of cooperative interaction, where the responsibility of query\nspecification is shared among the user and the system. We develop a principled\nframework distinguishing cooperative queries, i.e., queries that yield a\nresolvable interpretation, from uncooperative queries that cannot be resolved.\nApplying the framework to evaluations for tabular question answering and\nanalysis, we analyze the queries in 15 popular datasets, and observe an\nuncontrolled mixing of query types neither adequate for evaluating a system's\nexecution accuracy nor for evaluating interpretation capabilities. Our\nframework and analysis of queries shifts the perspective from fixing ambiguity\nto embracing cooperation in resolving queries. This reflection enables more\ninformed design and evaluation for natural language interfaces for tabular\ndata, for which we outline implications and directions for future research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u7684\u6b67\u4e49\u89c6\u4e3a\u5408\u4f5c\u4ea4\u4e92\u7279\u5f81\u800c\u975e\u7f3a\u9677\u7684\u6846\u67b6\uff0c\u5206\u6790\u4e8615\u4e2a\u6d41\u884c\u6570\u636e\u96c6\u4e2d\u7684\u67e5\u8be2\u7c7b\u578b\uff0c\u53d1\u73b0\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u6df7\u6dc6\u4e86\u4e0d\u540c\u7c7b\u578b\u67e5\u8be2\uff0c\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u7684\u6b67\u4e49\u89c6\u4e3a\u9700\u8981\u4fee\u590d\u7684\u7f3a\u9677\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u5b9e\u9645\u4e0a\u662f\u5408\u4f5c\u4ea4\u4e92\u7684\u7279\u5f81\uff0c\u7528\u6237\u548c\u7cfb\u7edf\u5e94\u5171\u540c\u627f\u62c5\u67e5\u8be2\u89c4\u8303\u7684\u8d23\u4efb\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u6846\u67b6\u6765\u533a\u5206\u5408\u4f5c\u67e5\u8be2\uff08\u53ef\u89e3\u6790\uff09\u548c\u975e\u5408\u4f5c\u67e5\u8be2\uff08\u65e0\u6cd5\u89e3\u6790\uff09\uff0c\u5e76\u5c06\u8be5\u6846\u67b6\u5e94\u7528\u4e8e15\u4e2a\u6d41\u884c\u8868\u683c\u95ee\u7b54\u548c\u5206\u6790\u6570\u636e\u96c6\u7684\u67e5\u8be2\u5206\u6790\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u6570\u636e\u96c6\u4e2d\u7684\u67e5\u8be2\u7c7b\u578b\u6df7\u6dc6\u4e0d\u6e05\uff0c\u65e2\u4e0d\u9002\u5408\u8bc4\u4f30\u7cfb\u7edf\u6267\u884c\u51c6\u786e\u6027\uff0c\u4e5f\u4e0d\u9002\u5408\u8bc4\u4f30\u89e3\u91ca\u80fd\u529b\u3002\u5927\u591a\u6570\u6570\u636e\u96c6\u672a\u80fd\u9002\u5f53\u533a\u5206\u4e0d\u540c\u7c7b\u578b\u7684\u67e5\u8be2\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u89c6\u89d2\u4ece\u4fee\u590d\u6b67\u4e49\u8f6c\u5411\u5728\u89e3\u6790\u67e5\u8be2\u4e2d\u62e5\u62b1\u5408\u4f5c\uff0c\u4e3a\u8868\u683c\u6570\u636e\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u7684\u8bbe\u8ba1\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u660e\u667a\u7684\u65b9\u6cd5\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.04588", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.04588", "abs": "https://arxiv.org/abs/2511.04588", "authors": ["Soham De", "Lodewijk Gelauff", "Ashish Goel", "Smitha Milli", "Ariel Procaccia", "Alice Siu"], "title": "Question the Questions: Auditing Representation in Online Deliberative Processes", "comment": null, "summary": "A central feature of many deliberative processes, such as citizens'\nassemblies and deliberative polls, is the opportunity for participants to\nengage directly with experts. While participants are typically invited to\npropose questions for expert panels, only a limited number can be selected due\nto time constraints. This raises the challenge of how to choose a small set of\nquestions that best represent the interests of all participants. We introduce\nan auditing framework for measuring the level of representation provided by a\nslate of questions, based on the social choice concept known as justified\nrepresentation (JR). We present the first algorithms for auditing JR in the\ngeneral utility setting, with our most efficient algorithm achieving a runtime\nof $O(mn\\log n)$, where $n$ is the number of participants and $m$ is the number\nof proposed questions. We apply our auditing methods to historical\ndeliberations, comparing the representativeness of (a) the actual questions\nposed to the expert panel (chosen by a moderator), (b) participants' questions\nchosen via integer linear programming, (c) summary questions generated by large\nlanguage models (LLMs). Our results highlight both the promise and current\nlimitations of LLMs in supporting deliberative processes. By integrating our\nmethods into an online deliberation platform that has been used for over\nhundreds of deliberations across more than 50 countries, we make it easy for\npractitioners to audit and improve representation in future deliberations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6b63\u5f53\u4ee3\u8868\u6027\u6982\u5ff5\u7684\u5ba1\u8ba1\u6846\u67b6\uff0c\u7528\u4e8e\u8861\u91cf\u4e13\u5bb6\u95ee\u7b54\u73af\u8282\u4e2d\u95ee\u9898\u9009\u62e9\u7684\u4ee3\u8868\u6027\u6c34\u5e73\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u5ba1\u8ba1\u7b97\u6cd5\u3002", "motivation": "\u5728\u516c\u6c11\u5927\u4f1a\u7b49\u5ba1\u8bae\u8fc7\u7a0b\u4e2d\uff0c\u53c2\u4e0e\u8005\u53ea\u80fd\u9009\u62e9\u6709\u9650\u6570\u91cf\u7684\u95ee\u9898\u5411\u4e13\u5bb6\u63d0\u95ee\uff0c\u5982\u4f55\u786e\u4fdd\u6240\u9009\u95ee\u9898\u80fd\u4ee3\u8868\u6240\u6709\u53c2\u4e0e\u8005\u7684\u5229\u76ca\u662f\u4e00\u4e2a\u91cd\u8981\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u4e2d\u7684\u6b63\u5f53\u4ee3\u8868\u6027\u6982\u5ff5\u5efa\u7acb\u5ba1\u8ba1\u6846\u67b6\uff0c\u5f00\u53d1\u4e86O(mn log n)\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u7b97\u6cd5\uff0c\u5e76\u5e94\u7528\u4e8e\u5386\u53f2\u5ba1\u8bae\u6570\u636e\uff0c\u6bd4\u8f83\u4e86\u4e3b\u6301\u4eba\u9009\u62e9\u3001\u6574\u6570\u7ebf\u6027\u89c4\u5212\u9009\u62e9\u548cLLM\u751f\u6210\u95ee\u9898\u4e09\u79cd\u65b9\u6cd5\u7684\u4ee3\u8868\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86LLM\u5728\u652f\u6301\u5ba1\u8bae\u8fc7\u7a0b\u4e2d\u7684\u6f5c\u529b\u548c\u5f53\u524d\u5c40\u9650\u6027\uff0c\u5e76\u5c06\u65b9\u6cd5\u96c6\u6210\u5230\u5df2\u572850\u591a\u4e2a\u56fd\u5bb6\u4f7f\u7528\u7684\u5728\u7ebf\u5ba1\u8bae\u5e73\u53f0\u4e2d\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u5ba1\u8ba1\u548c\u6539\u8fdb\u5ba1\u8bae\u8fc7\u7a0b\u4e2d\u4ee3\u8868\u6027\u7684\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5ba1\u8bae\u8fc7\u7a0b\u7684\u516c\u5e73\u6027\u548c\u5305\u5bb9\u6027\u3002"}}
{"id": "2511.04646", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04646", "abs": "https://arxiv.org/abs/2511.04646", "authors": ["Narjes Nourzad", "Hanqing Yang", "Shiyu Chen", "Carlee Joe-Wong"], "title": "DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration", "comment": null, "summary": "Cooperative multi-agent planning requires agents to make joint decisions with\npartial information and limited communication. Coordination at the trajectory\nlevel often fails, as small deviations in timing or movement cascade into\nconflicts. Symbolic planning mitigates this challenge by raising the level of\nabstraction and providing a minimal vocabulary of actions that enable\nsynchronization and collective progress. We present DR. WELL, a decentralized\nneurosymbolic framework for cooperative multi-agent planning. Cooperation\nunfolds through a two-phase negotiation protocol: agents first propose\ncandidate roles with reasoning and then commit to a joint allocation under\nconsensus and environment constraints. After commitment, each agent\nindependently generates and executes a symbolic plan for its role without\nrevealing detailed trajectories. Plans are grounded in execution outcomes via a\nshared world model that encodes the current state and is updated as agents act.\nBy reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids\nbrittle step-level alignment and enables higher-level operations that are\nreusable, synchronizable, and interpretable. Experiments on cooperative\nblock-push tasks show that agents adapt across episodes, with the dynamic world\nmodel capturing reusable patterns and improving task completion rates and\nefficiency. Experiments on cooperative block-push tasks show that our dynamic\nworld model improves task completion and efficiency through negotiation and\nself-refinement, trading a time overhead for evolving, more efficient\ncollaboration strategies.", "AI": {"tldr": "DR.WELL\u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u7528\u4e8e\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u89c4\u5212\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u534f\u5546\u534f\u8bae\u548c\u7b26\u53f7\u89c4\u5212\u907f\u514d\u8f68\u8ff9\u7ea7\u534f\u8c03\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5728\u90e8\u5206\u4fe1\u606f\u548c\u6709\u9650\u901a\u4fe1\u4e0b\u8fdb\u884c\u8054\u5408\u51b3\u7b56\u65f6\uff0c\u8f68\u8ff9\u7ea7\u534f\u8c03\u5bb9\u6613\u56e0\u5fae\u5c0f\u504f\u5dee\u5bfc\u81f4\u51b2\u7a81\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u534f\u5546\u534f\u8bae\uff1a\u667a\u80fd\u4f53\u5148\u63d0\u51fa\u5019\u9009\u89d2\u8272\u53ca\u63a8\u7406\uff0c\u7136\u540e\u5728\u5171\u8bc6\u548c\u73af\u5883\u7ea6\u675f\u4e0b\u627f\u8bfa\u8054\u5408\u5206\u914d\uff1b\u627f\u8bfa\u540e\u5404\u81ea\u72ec\u7acb\u751f\u6210\u548c\u6267\u884c\u7b26\u53f7\u8ba1\u5212\uff0c\u901a\u8fc7\u5171\u4eab\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u6267\u884c\u7ed3\u679c\u843d\u5730\u3002", "result": "\u5728\u534f\u4f5c\u63a8\u5757\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0c\u667a\u80fd\u4f53\u80fd\u591f\u8de8\u56de\u5408\u9002\u5e94\uff0c\u52a8\u6001\u4e16\u754c\u6a21\u578b\u6355\u83b7\u53ef\u91cd\u7528\u6a21\u5f0f\uff0c\u63d0\u9ad8\u4e86\u4efb\u52a1\u5b8c\u6210\u7387\u548c\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u7b26\u53f7\u89c4\u5212\u800c\u975e\u539f\u59cb\u8f68\u8ff9\u63a8\u7406\uff0cDR.WELL\u907f\u514d\u4e86\u8106\u5f31\u7684\u6b65\u7ea7\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7ea7\u3001\u53ef\u91cd\u7528\u3001\u53ef\u540c\u6b65\u548c\u53ef\u89e3\u91ca\u7684\u64cd\u4f5c\uff0c\u4ee5\u65f6\u95f4\u5f00\u9500\u6362\u53d6\u6f14\u5316\u51fa\u66f4\u9ad8\u6548\u7684\u534f\u4f5c\u7b56\u7565\u3002"}}
{"id": "2511.04662", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04662", "abs": "https://arxiv.org/abs/2511.04662", "authors": ["Yu Feng", "Nathaniel Weir", "Kaj Bostrom", "Sam Bayless", "Darion Cassel", "Sapana Chaudhary", "Benjamin Kiesl-Reiter", "Huzefa Rangwala"], "title": "VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks", "comment": null, "summary": "LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but\nthey cannot reliably verify their own logic. Even when they reach correct\nanswers, the underlying reasoning may be flawed, undermining trust in\nhigh-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a\nneuro-symbolic method that extracts and verifies formal logical arguments from\nCoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order\nlogic and identifies premises that ground the argument in source context,\ncommonsense knowledge, or prior reasoning steps. The symbolic representation\nenables automated solvers to verify logical validity while the NL premises\nallow humans and systems to identify ungrounded or fallacious reasoning steps.\nExperiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT\neffectively identifies flawed reasoning, and serves as a strong predictor of\nfinal answer correctness. We also leverage VeriCoT's verification signal for\n(1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on\nVeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct\npreference optimization (DPO) using verification-based pairwise rewards,\nfurther improving reasoning validity and accuracy.", "AI": {"tldr": "VeriCoT\u662f\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u4eceCoT\u63a8\u7406\u4e2d\u63d0\u53d6\u5e76\u9a8c\u8bc1\u5f62\u5f0f\u903b\u8f91\u8bba\u8bc1\uff0c\u901a\u8fc7\u4e00\u9636\u903b\u8f91\u5f62\u5f0f\u5316\u63a8\u7406\u6b65\u9aa4\uff0c\u4f7f\u7528\u81ea\u52a8\u6c42\u89e3\u5668\u9a8c\u8bc1\u903b\u8f91\u6709\u6548\u6027\uff0c\u63d0\u9ad8\u63a8\u7406\u53ef\u9760\u6027\u3002", "motivation": "LLMs\u867d\u7136\u80fd\u901a\u8fc7CoT\u8fdb\u884c\u591a\u6b65\u63a8\u7406\uff0c\u4f46\u65e0\u6cd5\u53ef\u9760\u9a8c\u8bc1\u81ea\u8eab\u903b\u8f91\uff0c\u5373\u4f7f\u5728\u5f97\u51fa\u6b63\u786e\u7b54\u6848\u65f6\u5e95\u5c42\u63a8\u7406\u4e5f\u53ef\u80fd\u5b58\u5728\u7f3a\u9677\uff0c\u8fd9\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u4f1a\u524a\u5f31\u4fe1\u4efb\u3002", "method": "VeriCoT\u5c06\u6bcf\u4e2aCoT\u63a8\u7406\u6b65\u9aa4\u5f62\u5f0f\u5316\u4e3a\u4e00\u7ea7\u903b\u8f91\uff0c\u8bc6\u522b\u57fa\u4e8e\u6e90\u4e0a\u4e0b\u6587\u3001\u5e38\u8bc6\u77e5\u8bc6\u6216\u5148\u524d\u63a8\u7406\u6b65\u9aa4\u7684\u524d\u63d0\uff0c\u4f7f\u7528\u7b26\u53f7\u8868\u793a\u548c\u81ea\u52a8\u6c42\u89e3\u5668\u9a8c\u8bc1\u903b\u8f91\u6709\u6548\u6027\u3002", "result": "\u5728ProofWriter\u3001LegalBench\u548cBioASQ\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVeriCoT\u80fd\u6709\u6548\u8bc6\u522b\u6709\u7f3a\u9677\u7684\u63a8\u7406\uff0c\u5e76\u4f5c\u4e3a\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\u7684\u5f3a\u9884\u6d4b\u6307\u6807\u3002", "conclusion": "VeriCoT\u7684\u9a8c\u8bc1\u4fe1\u53f7\u53ef\u7528\u4e8e\u63a8\u7406\u65f6\u81ea\u6211\u53cd\u601d\u3001\u76d1\u7763\u5fae\u8c03\u548c\u504f\u597d\u5fae\u8c03\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u63a8\u7406\u7684\u6709\u6548\u6027\u548c\u51c6\u786e\u6027\u3002"}}
