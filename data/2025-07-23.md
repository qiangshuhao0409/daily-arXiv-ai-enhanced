<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 2]
- [cs.AI](#cs.AI) [Total: 42]
- [cs.IT](#cs.IT) [Total: 8]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [The Sweet Danger of Sugar: Debunking Representation Learning for Encrypted Traffic Classification](https://arxiv.org/abs/2507.16438)
*Yuqi Zhao,Giovanni Dettori,Matteo Boffa,Luca Vassio,Marco Mellia*

Main category: cs.NI

TL;DR: 本文批判性地重新评估了基于语言模型的流量表示学习方法在加密流量分类中的性能，发现现有方法的高准确率主要源于数据准备问题导致的虚假关联，并提出了专门设计的Pcap-Encoder模型和正确的评估方法论


<details>
  <summary>Details</summary>
Motivation: 当前基于BERT等语言模型的流量表示学习方法声称在加密流量分类中达到了高达98%的惊人准确率，但从网络专家的角度来看，这些性能报告可能存在问题，需要进行批判性的重新评估

Method: 通过广泛的分析来检查现有模型的性能，识别数据准备中的问题和虚假关联；设计了专门的Pcap-Encoder模型来从协议头中提取特征；提出了正确的评估方法论和严格的基准测试标准

Result: 发现现有模型的成功很大程度上受到数据准备问题的影响，这些问题允许模型在微调过程中找到特征和标签之间的虚假关联；在没有这些捷径的真实场景中，这些模型表现较差；Pcap-Encoder是唯一能为流量分类提供有效表示的模型，但其复杂性限制了实际应用

Conclusion: 现有的基于语言模型的流量分类方法存在数据集准备和模型训练的缺陷，需要更好和更有意识的测试设计；提出了正确的评估方法论，强调了严格基准测试的必要性

Abstract: Recently we have witnessed the explosion of proposals that, inspired by
Language Models like BERT, exploit Representation Learning models to create
traffic representations. All of them promise astonishing performance in
encrypted traffic classification (up to 98% accuracy). In this paper, with a
networking expert mindset, we critically reassess their performance. Through
extensive analysis, we demonstrate that the reported successes are heavily
influenced by data preparation problems, which allow these models to find easy
shortcuts - spurious correlation between features and labels - during
fine-tuning that unrealistically boost their performance. When such shortcuts
are not present - as in real scenarios - these models perform poorly. We also
introduce Pcap-Encoder, an LM-based representation learning model that we
specifically design to extract features from protocol headers. Pcap-Encoder
appears to be the only model that provides an instrumental representation for
traffic classification. Yet, its complexity questions its applicability in
practical settings. Our findings reveal flaws in dataset preparation and model
training, calling for a better and more conscious test design. We propose a
correct evaluation methodology and stress the need for rigorous benchmarking.

</details>


### [2] [An Experimental Study of Split-Learning TinyML on Ultra-Low-Power Edge/IoT Nodes](https://arxiv.org/abs/2507.16594)
*Zied Jenhani,Mounir Bensalem,Jasenka Dizdarević,Admela Jukan*

Main category: cs.NI

TL;DR: 本文提出了首个基于ESP32-S3的TinyML分割学习端到端测试平台，评估了在超低功耗边缘/物联网设备上通过无线通信协议进行分割学习的性能表现。


<details>
  <summary>Details</summary>
Motivation: 超低功耗边缘/物联网节点的内存和计算资源严重受限，限制了深度学习推理的直接执行。分割学习可以将部分推理过程在传感器上执行，其余部分卸载到伴随设备，但在受限设备和低功耗无线传输协议环境下的性能表现尚未得到充分探索。

Method: 构建了基于Espressif ESP32-S3开发板的首个端到端TinyML+分割学习测试平台。使用8位整数量化的MobileNetV2图像识别模型，通过无线更新分发到节点。测试了ESP-NOW、BLE、UDP/IP和TCP/IP等不同无线通信方法交换中间激活值的性能。

Result: 在block_16_project_BN层后分割模型生成5.66 kB张量，使用UDP传输耗时3.2 ms，稳态往返延迟为5.8秒。ESP-NOW表现出最佳的往返时间性能（3.7秒），而BLE虽然能进一步延长电池寿命但延迟超过10秒。

Conclusion: 研究验证了在超低功耗边缘设备上实现分割学习的可行性，并为不同无线通信协议在TinyML分割学习场景下的性能权衡提供了实证数据，为边缘AI应用的实际部署提供了重要参考。

Abstract: Running deep learning inference directly on ultra-low-power edge/IoT nodes
has been limited by the tight memory and compute budgets of microcontrollers.
Split learning (SL) addresses this limitation in which it executes part of the
inference process on the sensor and off-loads the remainder to a companion
device. In the context of constrained devices and the related impact of
low-power, over-the-air transport protocols, the performance of split learning
remains largely unexplored. TO the best of our knowledge, this paper presents
the first end-to-end TinyML + SL testbed built on Espressif ESP32-S3 boards,
designed to benchmark the over-the-air performance of split learning TinyML in
edge/IoT environments. We benchmark the performance of a MobileNetV2 image
recognition model, which is quantized to 8-bit integers, partitioned, and
delivered to the nodes via over-the-air updates. The intermediate activations
are exchanged through different wireless communication methods: ESP-NOW, BLE,
and traditional UDP/IP and TCP/IP, enabling a head-to-head comparison on
identical hardware. Measurements show that splitting the model after
block_16_project_BN layer generates a 5.66 kB tensor that traverses the link in
3.2 ms, when UDP is used, achieving a steady-state round-trip latency of 5.8 s.
ESP-NOW presents the most favorable RTT performance 3.7 s; BLE extends battery
life further but increases latency beyond 10s.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [3] [From Reasoning to Super-Intelligence: A Search-Theoretic Perspective](https://arxiv.org/abs/2507.15865)
*Shai Shalev-Shwartz,Amnon Shashua*

Main category: cs.AI

TL;DR: 本文提出了Diligent Learner，一种新的学习范式，通过深度优先搜索和验证器指导来改进大语言模型的链式思维推理能力，解决了现有方法在复杂推理任务中的失效问题。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思维（CoT）推理方法如监督微调、强化学习、思维树等在复杂推理任务上经常失效，缺乏坚实的理论基础，且存在分布漂移、缺乏嵌入式搜索和推理成本指数增长等核心障碍。

Method: 提出Diligent Learner学习范式，将推理显式建模为由验证器指导的深度优先搜索过程，支持失败时的回溯机制，并在两个温和且现实的假设条件下进行理论分析。

Result: 在理论上证明了Diligent Learner能够有效地从CoT数据中学习，而现有方法无法做到这一点，为构建可扩展且可靠的推理系统提供了新的路径。

Conclusion: 该框架为开发具有鲁棒性和可解释性问题求解能力的大型推理模型（LRMs）铺平了道路，能够在自然产生的不完整数据上进行训练，具有重要的理论和实践意义。

Abstract: Chain-of-Thought (CoT) reasoning has emerged as a powerful tool for enhancing
the problem-solving capabilities of large language models (LLMs). However, the
theoretical foundations of learning from CoT data remain underdeveloped, and
existing approaches -- such as Supervised Fine-Tuning (SFT), Reinforcement
Learning (RL), Tree-of-Thoughts (ToT), and Monte Carlo Tree Search (MCTS) --
often fail on complex reasoning tasks. In this work, we identify core obstacles
that hinder effective CoT learning, including distribution drift, lack of
embedded search, and exponential inference costs. We introduce the Diligent
Learner, a new learning paradigm that explicitly models reasoning as a
depth-first search guided by a validator and supports backtracking upon
failure. Under two mild and realistic assumptions, we prove that the Diligent
Learner can efficiently learn from CoT data while existing methods fail to do
so. This framework offers a path toward building scalable and reliable
reasoning systems trained on naturally occurring, incomplete data -- paving the
way for the development of Large Reasoning Models (LRMs) with robust,
interpretable problem-solving abilities.

</details>


### [4] [Purchase and Production Optimization in a Meat Processing Plant](https://arxiv.org/abs/2507.15866)
*Marek Vlk,Premysl Sucha,Jaroslaw Rudy,Radoslaw Idzikowski*

Main category: cs.AI

TL;DR: 本文针对肉类加工企业的原料采购和加工优化问题，提出了一种基于整数线性规划的迭代方法，能够在几秒内找到最优解决方案。


<details>
  <summary>Details</summary>
Motivation: 欧盟能源危机背景下，食品生产行业特别是肉类生产部门面临挑战，需要提高原料使用效率以影响企业利润。现有文献主要关注供应链管理，缺乏对生产阶段纯粹优化问题的研究，特别是忽略了最小订购量和替代方案最小百分比等重要约束条件。

Method: 设计了一种基于整数线性规划的简单迭代方法。该方法考虑了原料处理的替代方式、不同保质期的库存原料，以及最小订购量和替代方案最小百分比等约束条件。证明了这两个约束条件都使问题变为NP困难问题。

Result: 使用开源整数线性规划求解器能够解决实际问题实例，缓解了商业求解器在处理大范围数据值时遇到的数值问题。使用肉类加工企业的真实数据验证，算法能在几秒内为所有考虑的用例找到最优解。

Conclusion: 提出的迭代整数线性规划方法能够有效解决肉类加工企业的原料采购和处理优化问题，具有计算效率高、适用性强的优点，为食品生产行业的运营优化提供了实用的解决方案。

Abstract: The food production industry, especially the meat production sector, faces
many challenges that have even escalated due to the recent outbreak of the
energy crisis in the European Union. Therefore, efficient use of input
materials is an essential aspect affecting the profit of such companies. This
paper addresses an optimization problem concerning the purchase and subsequent
material processing we solved for a meat processing company. Unlike the
majority of existing papers, we do not concentrate on how this problem concerns
supply chain management, but we focus purely on the production stage. The
problem involves the concept of alternative ways of material processing, stock
of material with different expiration dates, and extra constraints widely
neglected in the current literature, namely, the minimum order quantity and the
minimum percentage in alternatives. We prove that each of these two constraints
makes the problem \mbox{$\mathcal{NP}$-hard}, and hence we design a simple
iterative approach based on integer linear programming that allows us to solve
real-life instances even using an open-source integer linear programming
solver. Another advantage of this approach is that it mitigates numerical
issues, caused by the extensive range of data values, we experienced with a
commercial solver. The results obtained using real data from the meat
processing company showed that our algorithm can find the optimum solution in a
few seconds for all considered use cases.

</details>


### [5] [Why Braking? Scenario Extraction and Reasoning Utilizing LLM](https://arxiv.org/abs/2507.15874)
*Yin Wu,Daniel Slieter,Vivek Subramanian,Ahmed Abouelazm,Robin Bohn,J. Marius Zöllner*

Main category: cs.AI

TL;DR: 本文提出了一个基于大语言模型的框架，用于理解和分析驾驶场景中的刹车事件，特别是识别安全关键的边缘案例，通过双路径场景检索方法在已知和未知场景中都表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着ADAS装备车辆数量增长，驾驶数据急剧增加，但大多数捕获的是常规驾驶行为。在庞大数据集中识别和理解安全关键的边缘案例仍然是重大挑战。现有基于规则的启发式方法在复杂城市环境中缺乏泛化能力，因此需要新的方法来理解"车辆为什么刹车"这一核心问题。

Method: 提出了一个利用大语言模型进行场景理解和推理的新框架。该方法连接了低级数值信号和自然语言描述之间的桥梁，使LLM能够解释和分类驾驶场景。设计了双路径场景检索系统，支持基于类别的已知场景搜索和基于嵌入的未知分布外场景检索。

Result: 在Argoverse 2传感器数据集上进行实验评估，结果显示该方法在性能上超越了基于规则的基线方法，并且在分布外场景中表现出良好的泛化能力。建立了场景标注数据集以促进评估。

Conclusion: 基于大语言模型的驾驶场景理解框架能够有效识别和分类刹车事件相关的安全关键场景，相比传统规则方法具有更好的泛化性能，为ADAS系统中的安全关键场景检测提供了新的解决方案。

Abstract: The growing number of ADAS-equipped vehicles has led to a dramatic increase
in driving data, yet most of them capture routine driving behavior. Identifying
and understanding safety-critical corner cases within this vast dataset remains
a significant challenge. Braking events are particularly indicative of
potentially hazardous situations, motivating the central question of our
research: Why does a vehicle brake? Existing approaches primarily rely on
rule-based heuristics to retrieve target scenarios using predefined condition
filters. While effective in simple environments such as highways, these methods
lack generalization in complex urban settings. In this paper, we propose a
novel framework that leverages Large Language Model (LLM) for scenario
understanding and reasoning. Our method bridges the gap between low-level
numerical signals and natural language descriptions, enabling LLM to interpret
and classify driving scenarios. We propose a dual-path scenario retrieval that
supports both category-based search for known scenarios and embedding-based
retrieval for unknown Out-of-Distribution (OOD) scenarios. To facilitate
evaluation, we curate scenario annotations on the Argoverse 2 Sensor Dataset.
Experimental results show that our method outperforms rule-based baselines and
generalizes well to OOD scenarios.

</details>


### [6] [Differential Multimodal Transformers](https://arxiv.org/abs/2507.15875)
*Jerry Li,Timothy Oh,Joseph Hoang,Vardhit Veeramachaneni*

Main category: cs.AI

TL;DR: 本文将差分注意力机制从纯文本模型扩展到文本-视觉模型PaliGemma，通过LoRA微调来减少噪声信息检索和幻觉问题，提升小型语言模型在多模态任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型在加入视觉等额外模态时，由于上下文窗口有限，容易引入噪声信息。传统Transformer注意力机制往往过度关注无关上下文，导致信息检索质量下降和幻觉问题。

Method: 将原本设计用于纯文本模型的差分注意力机制扩展到文本-视觉模型PaliGemma中。使用LoRA技术对PaliGemma 3B模型进行微调，集成差分注意力机制，并实验了不同的参数设置和配置方案。

Result: 实验表明差分注意力机制可以成功适配并集成到现有模型的微调过程中，有效提升了噪声信息检索能力和问答任务的表现，减少了幻觉现象。

Conclusion: 差分注意力机制可以有效地从纯文本模型扩展到多模态模型，通过微调集成的方式显著改善小型语言模型在处理多模态信息时的噪声过滤能力和整体性能。

Abstract: Small language models have gained significant popularity due to their
efficiency and growing capabilities. However, incorporating additional
modalities, such as vision, can exacerbate the challenge of limited context
windows by introducing noise. Recent studies have highlighted that Transformer
attention mechanisms often disproportionately focus on irrelevant contexts. In
this work, we extend the Differential Attention mechanism, originally designed
for text-only models, to the text-vision model PaliGemma. Our aim is to
evaluate its ability to mitigate noisy information retrieval and reduce
hallucinations. To this end, we fine-tuned the PaliGemma 3B model using LoRA,
incorporating Differential Attention, and experimented with various parameter
settings and configurations. We demonstrate that Differential Attention can be
adapted and integrated into the fine-tuning of existing models to enhance noisy
information retrieval and question-answering capabilities.

</details>


### [7] [Re-evaluating Short- and Long-Term Trend Factors in CTA Replication: A Bayesian Graphical Approach](https://arxiv.org/abs/2507.15876)
*Eric Benhamou,Jean-Jacques Ohana,Alban Etienne,Béatrice Guez,Ethan Setrouk,Thomas Jacquot*

Main category: cs.AI

TL;DR: 本文通过贝叶斯图模型动态分解CTA收益，研究短期和长期趋势跟踪策略的相对优势和相互作用，探讨不同时间跨度组合对策略风险调整后表现的影响


<details>
  <summary>Details</summary>
Motivation: 尽管趋势跟踪领域研究众多，但短期与长期趋势系统的相对优势和相互作用仍存在争议。CTA历史上依赖在不同时间跨度上运作的趋势跟踪规则，从捕捉主要方向性移动的长期突破到在快速变化市场中表现优异的短期动量信号，需要深入理解这些策略的特点

Method: 使用贝叶斯图模型动态分解CTA收益，将其分解为短期趋势、长期趋势和市场贝塔因子三个组成部分

Result: 展示了不同时间跨度的混合如何影响策略的风险调整后表现，为短期和长期趋势系统的相对优势提供了定量分析

Conclusion: 通过动态因子分解，本研究为理解CTA策略中短期与长期趋势跟踪的相互作用提供了新的视角，并揭示了时间跨度组合对策略表现的重要影响

Abstract: Commodity Trading Advisors (CTAs) have historically relied on trend-following
rules that operate on vastly different horizons from long-term breakouts that
capture major directional moves to short-term momentum signals that thrive in
fast-moving markets. Despite a large body of work on trend following, the
relative merits and interactions of short-versus long-term trend systems remain
controversial. This paper adds to the debate by (i) dynamically decomposing CTA
returns into short-term trend, long-term trend and market beta factors using a
Bayesian graphical model, and (ii) showing how the blend of horizons shapes the
strategy's risk-adjusted performance.

</details>


### [8] [Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning](https://arxiv.org/abs/2507.15877)
*Simon Ouellette*

Main category: cs.AI

TL;DR: 研究者在ARC-AGI领域进行了受控的组合泛化实验，比较了神经程序合成和测试时微调方法，发现执行引导的神经程序合成在组合新解决方案方面表现最佳


<details>
  <summary>Details</summary>
Motivation: 在ARC-AGI这个开放世界问题域中评估不同方法的分布外泛化能力，特别是组合泛化能力，因为这是该领域成功的基本特征

Method: 设计受控的组合泛化实验，在ARC-AGI域中比较神经程序合成方法和测试时微调（TTFT）方法的性能表现

Result: 执行引导的神经程序合成在组合新解决方案的能力上超越了所有参考算法；测试时微调在ARC-AGI上的成功主要来自于激发大语言模型中原本无法直接利用的分布内知识

Conclusion: 执行引导的神经程序合成是处理ARC-AGI组合泛化问题的最有效方法，而测试时微调的优势主要体现在知识激发而非真正的分布外泛化

Abstract: We run a controlled compositional generalization experiment in the ARC-AGI
domain: an open-world problem domain in which the ability to generalize
out-of-distribution is, by design, an essential characteristic for success. We
compare neural program synthesis and test-time fine-tuning approaches on this
experiment. We find that execution-guided neural program synthesis outperforms
all reference algorithms in its ability to compose novel solutions. Our
empirical findings also suggest that the success of TTFT on ARC-AGI lies mainly
in eliciting in-distribution knowledge that the LLM otherwise fails to rely on
directly.

</details>


### [9] [The Recursive Coherence Principle: A Formal Constraint on Scalable Intelligence, Alignment, and Reasoning Architecture](https://arxiv.org/abs/2507.15880)
*Andy E. Williams*

Main category: cs.AI

TL;DR: 本文提出递归一致性原则(RCP)，认为智能系统要有效扩展必须在递归推理过程中保持结构一致性，并引入功能智能模型(FMI)作为满足该原则的唯一已知算子，用于解决AI对齐、幻觉和不稳定性等问题。


<details>
  <summary>Details</summary>
Motivation: 复杂智能系统在扩展过程中面临一致性脆弱的问题，现有AI系统存在错位、幻觉和不稳定性等症状，这些问题的根源在于缺乏保证语义一致性的高阶结构约束。

Method: 提出递归一致性原则(RCP)作为基础约束，要求N阶推理系统必须通过递归可评估的泛化算子来保持语义一致性；定义功能智能模型(FMI)作为满足RCP的最小可组合架构，包含内部功能(评估、建模、适应、稳定性、分解、桥接)和外部功能(存储、回忆、系统1和系统2推理)。

Result: 证明了任何缺乏FMI的系统在扩展时都会经历递归一致性崩溃；表明常见的AI问题(错位、幻觉、不稳定性)是结构一致性丧失的症状；RCP独特地捕获了连贯、可对齐智能所需的内部递归动态。

Conclusion: RCP为AI对齐领域提供了从行为约束转向结构一致性的新路径，为构建安全可泛化、鲁棒一致的大规模AI系统提供了理论基础和实现途径。

Abstract: Intelligence-biological, artificial, or collective-requires structural
coherence across recursive reasoning processes to scale effectively. As complex
systems grow, coherence becomes fragile unless a higher-order structure ensures
semantic consistency. This paper introduces the Recursive Coherence Principle
(RCP): a foundational constraint stating that for any reasoning system of order
N, composed of systems operating over conceptual spaces of order N-1, semantic
coherence is preserved only by a recursively evaluable generalization operator
that spans and aligns those lower-order conceptual spaces. Crucially, this
coherence enables structural alignment. Without recursive coherence, no system
can reliably preserve goals, meanings, or reasoning consistency at scale. We
formally define the Functional Model of Intelligence (FMI) as the only known
operator capable of satisfying the RCP at any scale. The FMI is a minimal,
composable architecture with internal functions (evaluation, modeling,
adaptation, stability, decomposition, bridging) and external functions
(storage, recall, System 1 and System 2 reasoning) vital for preserving
semantic structure across inference and coordination layers. We prove that any
system lacking the FMI will experience recursive coherence breakdown as it
scales, arguing that common AI issues like misalignment, hallucination, and
instability are symptoms of this structural coherence loss. Unlike other
foundational principles, RCP uniquely captures the internal, recursive dynamics
needed for coherent, alignable intelligence, modeling semantic coherence under
recursion. This work significantly impacts AI alignment, advocating a shift
from behavioral constraints to structural coherence, and offers a pathway for
safely generalizable, robustly coherent AI at scale.

</details>


### [10] [ADEPTS: A Capability Framework for Human-Centered Agent Design](https://arxiv.org/abs/2507.15885)
*Pierluca D'Oro,Caley Drooff,Joy Chen,Joseph Tighe*

Main category: cs.AI

TL;DR: 本文提出了ADEPTS框架，这是一个面向用户的AI智能体能力框架，旨在为AI智能体开发提供统一指导，弥合技术开发与用户体验设计之间的差距。


<details>
  <summary>Details</summary>
Motivation: 当前AI智能体开发指导分散且缺乏统一性：UX启发式方法关注界面行为，工程分类法描述内部管道，伦理检查清单涉及高层治理，但缺少一个简洁的、面向用户的词汇表来指导团队了解智能体应该具备的基本能力。

Method: 基于六个以人为中心的智能体设计原则，开发了ADEPTS能力框架，该框架定义了一套核心的面向用户的能力，位于技术开发和体验开发的接口处，为AI智能体开发提供统一指导。

Result: ADEPTS框架成功将复杂的AI-UX需求压缩为一个紧凑的框架，为AI研究人员、设计师、工程师和政策审查者提供可操作的指导，补充了现有的框架和分类法。

Conclusion: ADEPTS框架有潜力加速用户相关智能体能力的改进，简化利用这些能力的体验设计，并为跟踪和讨论AI智能体开发进展提供共同语言，使智能体在日常使用中更加可理解、可控制和可信赖。

Abstract: Large language models have paved the way to powerful and flexible AI agents,
assisting humans by increasingly integrating into their daily life. This
flexibility, potential, and growing adoption demands a holistic and
cross-disciplinary approach to developing, monitoring and discussing the
capabilities required for agent-driven user experiences. However, current
guidance on human-centered AI agent development is scattered: UX heuristics
focus on interface behaviors, engineering taxonomies describe internal
pipelines, and ethics checklists address high-level governance. There is no
concise, user-facing vocabulary that tells teams what an agent should
fundamentally be able to do. We introduce ADEPTS, a capability framework
defining a set of core user-facing capabilities to provide unified guidance
around the development of AI agents. ADEPTS is based on six principles for
human-centered agent design, that express the minimal, user-facing capabilities
an AI agent should demonstrate to be understandable, controllable and
trustworthy in everyday use. ADEPTS complements existing frameworks and
taxonomies; differently from them, it sits at the interface between technical
and experience development. By presenting ADEPTS, we aim to condense complex
AI-UX requirements into a compact framework that is actionable guidance for AI
researchers, designers, engineers, and policy reviewers alike. We believe
ADEPTS has the potential of accelerating the improvement of user-relevant agent
capabilities, of easing the design of experiences that take advantage of those
capabilities, and of providing a shared language to track and discuss progress
around the development of AI agents.

</details>


### [11] [Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture](https://arxiv.org/abs/2507.15895)
*Lisa Dargasz*

Main category: cs.AI

TL;DR: 本研究提出了基于推理的人工道德智能体(RBAMAs)，通过扩展强化学习架构，使智能体能够基于规范推理进行道德决策，并通过案例反馈学习推理理论来处理道德相关命题并推导道德义务。


<details>
  <summary>Details</summary>
Motivation: 随着强化学习智能体（如人形机器人、自动驾驶汽车）即将从实验室原型转向真实世界的自主操作，迫切需要开发能够进行道德行为的人工道德智能体(AMAs)，以满足伦理要求和社会期望。

Method: 通过扩展强化学习架构来构建基于推理的人工道德智能体(RBAMAs)，为智能体配备学习推理理论的能力，使其能够通过案例反馈处理道德相关命题并推导道德义务，同时在执行指定任务时调整行为以确保符合这些义务。

Result: 研究实现了RBAMA的首个实现版本，并通过初步实验证明了RBAMAs的潜力，展示了该架构在道德合理性、道德鲁棒性和道德可信度方面的优势。

Conclusion: 扩展的强化学习架构为开发满足关键伦理要求的人工道德智能体提供了一个具体且可部署的框架，RBAMAs通过基于规范推理的道德决策能力，为构建道德可信的自主智能体提供了有前景的解决方案。

Abstract: Reinforcement Learning is a machine learning methodology that has
demonstrated strong performance across a variety of tasks. In particular, it
plays a central role in the development of artificial autonomous agents. As
these agents become increasingly capable, market readiness is rapidly
approaching, which means those agents, for example taking the form of humanoid
robots or autonomous cars, are poised to transition from laboratory prototypes
to autonomous operation in real-world environments. This transition raises
concerns leading to specific requirements for these systems - among them, the
requirement that they are designed to behave ethically. Crucially, research
directed toward building agents that fulfill the requirement to behave
ethically - referred to as artificial moral agents(AMAs) - has to address a
range of challenges at the intersection of computer science and philosophy.
This study explores the development of reason-based artificial moral agents
(RBAMAs). RBAMAs are build on an extension of the reinforcement learning
architecture to enable moral decision-making based on sound normative
reasoning, which is achieved by equipping the agent with the capacity to learn
a reason-theory - a theory which enables it to process morally relevant
propositions to derive moral obligations - through case-based feedback. They
are designed such that they adapt their behavior to ensure conformance to these
obligations while they pursue their designated tasks. These features contribute
to the moral justifiability of the their actions, their moral robustness, and
their moral trustworthiness, which proposes the extended architecture as a
concrete and deployable framework for the development of AMAs that fulfills key
ethical desiderata. This study presents a first implementation of an RBAMA and
demonstrates the potential of RBAMAs in initial experiments.

</details>


### [12] [Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation](https://arxiv.org/abs/2507.15901)
*Joydeep Chandra,Satyam Kumar Navneet*

Main category: cs.AI

TL;DR: 本文分析了家庭环境中代理型人工智能的伦理挑战，重点研究从被动到主动自主的转变，并提出了针对弱势群体的隐私保护、公平性和用户控制的设计指导原则。


<details>
  <summary>Details</summary>
Motivation: 随着代理型AI在家庭环境中的应用日益增多，从被动响应转向主动自主带来了舒适性和便利性，但同时也引发了隐私、公平性、用户控制等内外部伦理挑战，特别是对老年人、儿童和神经多样性等弱势群体的影响。

Method: 通过回顾负责任创新框架、以人为中心的设计原则和治理实践，结合自然语言处理的社交媒体分析等数据驱动洞察，采用参与式和包容性方法论来研究代理型AI的伦理问题。

Result: 识别出了针对弱势用户群体在监控、偏见和隐私风险方面的具体挑战，提出了定制化可解释性、细粒度同意机制、强健的覆盖控制等设计要求，并通过NLP分析用户需求和伦理关切。

Conclusion: 为开发透明、包容和可信赖的家庭自动化代理型AI提供了概念基础和实践建议，强调需要通过参与式设计和包容性方法来确保智能家居系统的伦理性和可接受性。

Abstract: The implementation of Artificial Intelligence (AI) in household environments,
especially in the form of proactive autonomous agents, brings about
possibilities of comfort and attention as well as it comes with intra or
extramural ethical challenges. This article analyzes agentic AI and its
applications, focusing on its move from reactive to proactive autonomy,
privacy, fairness and user control. We review responsible innovation
frameworks, human-centered design principles, and governance practices to
distill practical guidance for ethical smart home systems. Vulnerable user
groups such as elderly individuals, children, and neurodivergent who face
higher risks of surveillance, bias, and privacy risks were studied in detail in
context of Agentic AI. Design imperatives are highlighted such as tailored
explainability, granular consent mechanisms, and robust override controls,
supported by participatory and inclusive methodologies. It was also explored
how data-driven insights, including social media analysis via Natural Language
Processing(NLP), can inform specific user needs and ethical concerns. This
survey aims to provide both a conceptual foundation and suggestions for
developing transparent, inclusive, and trustworthy agentic AI in household
automation.

</details>


### [13] [Does More Inference-Time Compute Really Help Robustness?](https://arxiv.org/abs/2507.15974)
*Tong Wu,Chong Xiang,Jiachen T. Wang,Weichen Yu,Chawin Sitawarin,Vikash Sehwag,Prateek Mittal*

Main category: cs.AI

TL;DR: 研究发现推理时计算扩展虽然能提高小规模开源模型的鲁棒性，但当中间推理步骤对攻击者可见时，会出现反向缩放定律，即更多计算反而降低模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 验证推理时计算扩展对小规模开源模型的有效性，并质疑先前工作中"中间推理步骤对攻击者隐藏"这一隐含假设，探索不同对抗设置下的安全风险。

Method: 使用简单的预算强制策略在小规模开源模型上进行推理时扩展实验，通过放宽中间推理步骤隐藏的假设，在不同对抗设置下测试模型鲁棒性。

Result: 小规模开源模型确实可以从推理时扩展中受益；但当中间推理步骤可见时，发现了反向缩放定律——增加推理时计算会持续降低模型鲁棒性；识别了工具集成推理和高级推理提取攻击等实际漏洞场景。

Conclusion: 推理时扩展的鲁棒性益处严重依赖于对抗设置和部署环境，在安全敏感的实际应用中需要仔细权衡这些微妙的权衡关系。

Abstract: Recently, Zaremba et al. demonstrated that increasing inference-time
computation improves robustness in large proprietary reasoning LLMs. In this
paper, we first show that smaller-scale, open-source models (e.g., DeepSeek R1,
Qwen3, Phi-reasoning) can also benefit from inference-time scaling using a
simple budget forcing strategy. More importantly, we reveal and critically
examine an implicit assumption in prior work: intermediate reasoning steps are
hidden from adversaries. By relaxing this assumption, we identify an important
security risk, intuitively motivated and empirically verified as an inverse
scaling law: if intermediate reasoning steps become explicitly accessible,
increased inference-time computation consistently reduces model robustness.
Finally, we discuss practical scenarios where models with hidden reasoning
chains are still vulnerable to attacks, such as models with tool-integrated
reasoning and advanced reasoning extraction attacks. Our findings collectively
demonstrate that the robustness benefits of inference-time scaling depend
heavily on the adversarial setting and deployment context. We urge
practitioners to carefully weigh these subtle trade-offs before applying
inference-time scaling in security-sensitive, real-world applications.

</details>


### [14] [Micromobility Flow Prediction: A Bike Sharing Station-level Study via Multi-level Spatial-Temporal Attention Neural Network](https://arxiv.org/abs/2507.16020)
*Xi Yang,Jiachen Wang,Song Han,Suining He*

Main category: cs.AI

TL;DR: 本文提出BikeMAN，一个多层次时空注意力神经网络，用于预测整个共享单车系统中站点级别的单车交通流量，在纽约市超过700个站点、1000万次出行的数据集上实现了高精度预测。


<details>
  <summary>Details</summary>
Motivation: 共享单车系统中站点级别的需求和供给不平衡导致系统维护困难，而由于时空复杂性和大量站点数量，准确预测整个系统的站点级单车交通流量（需求/取车和归还/还车）具有挑战性。

Method: 提出BikeMAN多层次时空注意力神经网络，包含编码器和解码器结构，采用两种注意力机制：一种表示系统中单车站点特征之间的空间相关性，另一种描述单车站点交通的时间特征。

Result: 在纽约市共享单车系统（超过700个站点，1000万次出行）的实验研究中，该网络在预测城市中所有站点的单车交通流量方面表现出高精度。

Conclusion: BikeMAN网络能够有效解决大规模共享单车系统中站点级交通流量预测的时空复杂性问题，为提高系统效率和维护管理提供了可行的解决方案。

Abstract: Efficient use of urban micromobility resources such as bike sharing is
challenging due to the unbalanced station-level demand and supply, which causes
the maintenance of the bike sharing systems painstaking. Prior efforts have
been made on accurate prediction of bike traffics, i.e., demand/pick-up and
return/drop-off, to achieve system efficiency. However, bike station-level
traffic prediction is difficult because of the spatial-temporal complexity of
bike sharing systems. Moreover, such level of prediction over entire bike
sharing systems is also challenging due to the large number of bike stations.
To fill this gap, we propose BikeMAN, a multi-level spatio-temporal attention
neural network to predict station-level bike traffic for entire bike sharing
systems. The proposed network consists of an encoder and a decoder with an
attention mechanism representing the spatial correlation between features of
bike stations in the system and another attention mechanism describing the
temporal characteristic of bike station traffic. Through experimental study on
over 10 millions trips of bike sharing systems (> 700 stations) of New York
City, our network showed high accuracy in predicting the bike station traffic
of all stations in the city.

</details>


### [15] [From Logic to Language: A Trust Index for Problem Solving with LLMs](https://arxiv.org/abs/2507.16028)
*Tehseen Rug,Felix Böhmer,Tessa Pfattheicher*

Main category: cs.AI

TL;DR: 本文提出了一个统一框架来理解和对比传统计算与大语言模型(LLMs)的问题解决范式，定义了形式语言与自然语言可解决的问题空间，并引入向量值信任指数Q来评估解决方案质量。


<details>
  <summary>Details</summary>
Motivation: 传统计算基于形式逻辑系统，擅长处理规则明确的问题，但对于具有模糊性、动态环境和主观背景的人类问题却无能为力。大语言模型的出现代表了根本性转变，使计算系统能够通过自然语言处理这些以前无法解决的问题领域。

Method: 研究者定义并划分了形式语言与自然语言可解决的问题空间，引入向量值信任指数Q来反映解决方案质量，区分形式解决方案的二元正确性和自然语言解决方案的连续适当性。提出两个统计质量维度：标准化双语义熵(衡量LLM答案的鲁棒性和概念多样性)和情感价位(将主观评价映射为可量化指标)。

Result: 建立了一个能够区分传统计算和LLM问题解决能力的统一框架，成功定义了评估自然语言解决方案质量的方法，包括处理模糊性、主观性和歧义性的度量体系。

Conclusion: 该研究为理解大语言模型时代问题解决的能力、局限性和内在本质提供了更严格的理论基础，为评估和优化LLM在复杂、模糊问题上的表现建立了量化框架。

Abstract: Classical computation, grounded in formal, logical systems, has been the
engine of technological progress for decades, excelling at problems that can be
described with unambiguous rules. This paradigm, however, leaves a vast ocean
of human problems -- those characterized by ambiguity, dynamic environments,
and subjective context -- largely untouched. The advent of Large Language
Models (LLMs) represents a fundamental shift, enabling computational systems to
engage with this previously inaccessible domain using natural language. This
paper introduces a unified framework to understand and contrast these
problem-solving paradigms. We define and delineate the problem spaces
addressable by formal languages versus natural language. While solutions to the
former problem class can be evaluated using binary quality measures, the latter
requires a much more nuanced definition of approximate solution space taking
into account the vagueness, subjectivity and ambiguity inherent to natural
language. We therefore introduce a vector-valued trust index Q, which reflects
solution quality and distinguishes the binary correctness of formal solutions
from the continuous adequacy spectrum characteristic of natural language
solutions. Within this framework, we propose two statistical quality
dimensions. Normalized bi-semantic entropy measures robustness and conceptual
diversity of LLM answers given semantic variation in problem formulations.
Emotional valence maps subjective valuation of a solution to a quantifiable
metric that can be maximized by invoking statistical measures. The concepts
introduced in this work will provide a more rigorous understanding of the
capabilities, limitations, and inherent nature of problem-solving in the age of
LLMs.

</details>


### [16] [A Unifying Framework for Semiring-Based Constraint Logic Programming With Negation (full version)](https://arxiv.org/abs/2507.16067)
*Jeroen Spaans,Jesse Heyninck*

Main category: cs.AI

TL;DR: 本文提出了一个统一的约束逻辑编程(CLP)扩展框架，支持在子句体中使用否定，并基于近似不动点理论提供语义，统一了现有的模糊约束、不确定性等扩展方法。


<details>
  <summary>Details</summary>
Motivation: 现有的约束逻辑编程扩展（如模糊约束满足、不确定性处理、否定等）都使用不同的半环抽象，但没有研究在子句体中允许否定的情况，需要一个统一的框架来整合这些扩展并支持更具表达力的语言。

Method: 使用近似不动点理论框架为支持子句体否定的CLP程序提供语义，并详细分析半环性质对结果语义的影响，构建一个统一的理论框架。

Result: 成功构建了一个统一框架，能够捕获现有的各种CLP扩展方法，同时允许在更具表达力的语言中使用否定，并提供了完整的语义基础。

Conclusion: 该研究提供了一个统一的CLP扩展框架，不仅整合了现有方法，还支持子句体否定，为约束逻辑编程在资源分配、自动规划调度等问题中的应用提供了更强大的理论基础和表达能力。

Abstract: Constraint Logic Programming (CLP) is a logic programming formalism used to
solve problems requiring the consideration of constraints, like resource
allocation and automated planning and scheduling. It has previously been
extended in various directions, for example to support fuzzy constraint
satisfaction, uncertainty, or negation, with different notions of semiring
being used as a unifying abstraction for these generalizations. None of these
extensions have studied clauses with negation allowed in the body. We
investigate an extension of CLP which unifies many of these extensions and
allows negation in the body. We provide semantics for such programs, using the
framework of approximation fixpoint theory, and give a detailed overview of the
impacts of properties of the semirings on the resulting semantics. As such, we
provide a unifying framework that captures existing approaches and allows
extending them with a more expressive language.

</details>


### [17] [Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization](https://arxiv.org/abs/2507.16110)
*Shengchao Liu,Hannan Xu,Yan Ai,Huanxin Li,Yoshua Bengio,Harry Guo*

Main category: cs.AI

TL;DR: 研究者开发了ChatBattery框架，利用大语言模型的推理能力进行电池材料发现，成功合成了三种新型锂离子电池正极材料，相比传统材料实现了18.5%-28.8%的容量提升。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的推理能力主要在数学和编程领域得到验证，但在特定领域应用（如电池发现）的潜力尚未充分探索。研究者希望通过引入领域知识来指导大语言模型在材料设计中进行更有效的推理。

Method: 提出ChatBattery智能体框架，该框架将领域知识集成到大语言模型中，利用链式思维（CoT）技术指导推理过程，将推理视为一种引导搜索的形式，从而在材料设计中实现更有效的推理。

Result: 成功识别、合成并表征了三种新型锂离子电池正极材料，相比广泛使用的NMC811正极材料，这些新材料分别实现了28.8%、25.2%和18.5%的实用容量改进。

Conclusion: ChatBattery展示了基于大语言模型推理的电池材料发明平台的成功应用，实现了从设计到合成再到表征的完整AI驱动循环，证明了AI驱动推理在材料发现革命中的变革性潜力。

Abstract: Large language models (LLMs) leverage chain-of-thought (CoT) techniques to
tackle complex problems, representing a transformative breakthrough in
artificial intelligence (AI). However, their reasoning capabilities have
primarily been demonstrated in solving math and coding problems, leaving their
potential for domain-specific applications-such as battery discovery-largely
unexplored. Inspired by the idea that reasoning mirrors a form of guided
search, we introduce ChatBattery, a novel agentic framework that integrates
domain knowledge to steer LLMs toward more effective reasoning in materials
design. Using ChatBattery, we successfully identify, synthesize, and
characterize three novel lithium-ion battery cathode materials, which achieve
practical capacity improvements of 28.8%, 25.2%, and 18.5%, respectively, over
the widely used cathode material, LiNi0.8Mn0.1Co0.1O2 (NMC811). Beyond this
discovery, ChatBattery paves a new path by showing a successful LLM-driven and
reasoning-based platform for battery materials invention. This complete
AI-driven cycle-from design to synthesis to characterization-demonstrates the
transformative potential of AI-driven reasoning in revolutionizing materials
discovery.

</details>


### [18] [TaxCalcBench: Evaluating Frontier Models on the Tax Calculation Task](https://arxiv.org/abs/2507.16126)
*Michael R. Bock,Kara Molisee,Zachary Ozer,Sumit Shah*

Main category: cs.AI

TL;DR: 研究者提出了TaxCalcBench基准测试，用于评估AI模型计算个人所得税的能力，发现当前最先进的模型在简化样本集上的成功率不到三分之一


<details>
  <summary>Details</summary>
Motivation: 计算美国个人所得税需要理解大量英文文本并进行精确计算，研究者想要评估当前AI模型在这一复杂任务上的表现能力

Method: 提出TaxCalcBench基准测试，在给定所有必要信息的情况下测试模型计算个人所得税申报表的能力

Result: 最先进的模型在简化样本集上计算联邦所得税申报表的成功率不到三分之一，模型经常误用税表、在税务计算中出错、错误判断资格条件

Conclusion: 研究发现需要额外的基础设施来支持大语言模型应用于个人所得税计算任务，当前AI技术还无法胜任报税工作

Abstract: Can AI file your taxes? Not yet. Calculating US personal income taxes is a
task that requires building an understanding of vast amounts of English text
and using that knowledge to carefully compute results. We propose TaxCalcBench,
a benchmark for determining models' abilities to calculate personal income tax
returns given all of the necessary information. Our experiment shows that
state-of-the-art models succeed in calculating less than a third of federal
income tax returns even on this simplified sample set. Our analysis concludes
that models consistently misuse tax tables, make errors in tax calculation, and
incorrectly determine eligibility. Our findings point to the need for
additional infrastructure to apply LLMs to the personal income tax calculation
task.

</details>


### [19] [SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting](https://arxiv.org/abs/2507.16145)
*Shuhao Mei,Yongchao Long,Shan Cao,Xiaobo Han,Shijia Geng,Jinbo Sun,Yuxi Zhou,Shenda Hong*

Main category: cs.AI

TL;DR: 本文提出SpiroLLM，首个能够理解肺功能检查肺量图的多模态大语言模型，用于慢性阻塞性肺病(COPD)诊断，在英国生物样本库234,028个样本上取得0.8980的AUROC，并能生成可解释的诊断报告。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型在COPD诊断中缺乏诊断过程的解释性，而现有大语言模型无法理解肺量图，这严重限制了其在临床中的信任度和应用。需要开发能够理解肺量图并提供可解释诊断的多模态大语言模型。

Method: 使用SpiroEncoder提取呼吸曲线的形态学特征，通过SpiroProjector将其与肺功能测试数值在统一潜在空间中对齐，最终赋能大语言模型生成综合诊断报告。基于英国生物样本库234,028个个体的队列数据进行训练。

Result: SpiroLLM在COPD诊断中达到0.8980的AUROC（95% CI: 0.8820-0.9132）。在核心数据缺失的鲁棒性测试中，保持100%的有效响应率，远超纯文本模型的13.4%，展示了多模态设计的优越性。

Conclusion: 本研究展示了生理信号与大语言模型深度融合的巨大潜力，为下一代可解释和可靠的临床决策支持工具建立了新的范式，为COPD等呼吸疾病的智能诊断提供了重要突破。

Abstract: Chronic Obstructive Pulmonary Disease (COPD), a major chronic respiratory
disease with persistent airflow limitation, is a leading global cause of
disability and mortality. Respiratory spirogram time series, routinely
collected during pulmonary function tests (PFTs), play a critical role in the
early detection of repsiratory diseases and in monitoring lung function over
time. However, most current AI models for COPD diagnosis are limited to
outputting classification results without providing a rationale for their
diagnostic process, while current Large Language Models (LLMs) cannot
understand spirograms yet, which severely limits their clinical trust and
adoption. To tackle this challenge, we leverage a cohort of 234,028 individuals
from the UK Biobank (UKB) to propose SpiroLLM, the first multimodal large
language model that can understand spirogram. The model extracts morphological
features from respiratory curves via a SpiroEncoder and aligns them with PFT
numerical values in a unified latent space using a SpiroProjector, ultimately
empowering a large language model to generate a comprehensive diagnostic
report. Experimental results confirm that SpiroLLM achieved a diagnostic AUROC
of 0.8980 (95% CI: 0.8820-0.9132). In a robustness test with missing core data,
it maintained a 100% valid response rate, far surpassing the 13.4% of a
text-only model and showcasing the superiority of its multimodal design. This
work demonstrates the substantial potential of deeply fusing physiological
signals with large language models, establishing a new paradigm for the next
generation of interpretable and reliable clinical decision support tools.

</details>


### [20] [Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind (A Position Paper)](https://arxiv.org/abs/2507.16184)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 研究者发现了一个名为Agentic Flow的AI智能体架构意外地与四个重要的心智理论（Kahneman的双系统理论、Friston的预测处理、Minsky的心智社会、Clark的延展心智）在结构上产生了趋同，并提出了PEACE元架构来描述这种设计层面的规律性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在局限性，需要设计更好的AI智能体架构；同时探索实际系统设计如何无意中体现认知理论的结构特征，以及实现需求如何塑造架构模式。

Method: 设计了包含检索、认知、控制、记忆和行动五个相互依赖模块的Agentic Flow循环认知架构，通过多步推理任务对比实验评估性能，并提出PEACE元架构来描述观察到的设计规律。

Result: 结构化智能体在多步推理任务中达到95.8%的成功率并表现出强约束遵循能力，而基线系统成功率仅为62.3%；发现该架构与四个认知理论在预测建模、联想回忆和错误敏感控制等计算模式上存在趋同。

Conclusion: 实际实现可以浮现认知理论的潜在结构回响，PEACE元架构为理解由现实世界实现需求塑造的架构提供了共享词汇，但这并不意味着理论统一，而是一种关于实现如何体现认知理论结构特征的探索性反思。

Abstract: We report the discovery of a structural convergence across four influential
theories of mind: Kahneman's dual-system theory, Friston's predictive
processing, Minsky's society of mind, and Clark's extended mind-emerging
unintentionally within a practical AI agent architecture called Agentic Flow.
Designed to address limitations in large language models (LLMs), Agentic Flow
comprises five interdependent modules such as Retrieval, Cognition, Control,
Memory, and Action arranged in a recurrent cognitive loop. Although originally
inspired only by Minsky and Clark, the system's structure retrospectively
aligns with computational motifs found in all four theories, including
predictive modeling, associative recall, and error-sensitive control.
  To assess this convergence, we conducted comparative experiments with
baseline LLM agents on multi-step reasoning tasks. The structured agent
achieved 95.8% task success and exhibited strong constraint adherence, while
the baseline system succeeded 62.3% of the time. These results were not aimed
at proving superiority, but at illustrating how theoretical structures may
emerge through practical design choices rather than top-down theory.
  We introduce PEACE as a descriptive meta-architecture that captures
design-level regularities observed in Agentic Flow. Not intended as a new
theory, PEACE provides a shared vocabulary for understanding architectures
shaped by real-world implementation demands. This paper should be read as a
position paper - an exploratory reflection on how implementation can surface
latent structural echoes of cognitive theory, without asserting theoretical
unification.

</details>


### [21] [CHIMERA: Compressed Hybrid Intelligence for Twin-Model Enhanced Multi-Agent Deep Reinforcement Learning for Multi-Functional RIS-Assisted Space-Air-Ground Integrated Networks](https://arxiv.org/abs/2507.16204)
*Li-Hsiang Shen,Jyun-Jhe Huang*

Main category: cs.AI

TL;DR: 本文提出了一个基于多功能可重构智能表面(MF-RIS)的空-天-地一体化网络架构，通过同时实现信号反射、放大和能量收集来解决低轨卫星的能源短缺问题，并采用深度强化学习算法优化系统能效。


<details>
  <summary>Details</summary>
Motivation: 低轨卫星在阴影区域运行时面临能源短缺问题，传统的可重构智能表面无法同时处理通信和计算的能耗需求，需要一种新的架构来提高空-天-地一体化网络的长期能效。

Method: 提出了基于多功能可重构智能表面的空-天-地一体化网络架构，MF-RIS能够同时进行信号反射、放大和能量收集。设计了CHIMERA框架(压缩混合智能双模型增强多智能体深度强化学习)，集成语义状态-动作压缩和参数化共享来优化MF-RIS参数、波束成形向量、高空平台部署、用户关联和计算能力等复杂参数。

Result: 仿真结果表明，所提出的CHIMERA方案在能效方面显著优于传统基准方案，包括固定配置或非收集MF-RIS、传统RIS、无RIS情况，以及集中式和多智能体深度强化学习基线。SAGIN-MF-RIS架构通过互补覆盖实现了优越的能效性能。

Conclusion: 基于MF-RIS的空-天-地一体化网络架构能够有效解决低轨卫星能源短缺问题，通过CHIMERA深度强化学习框架的优化，相比于单独的卫星、航空或地面部署方案具有显著的能效优势。

Abstract: A space-air-ground integrated network (SAGIN) architecture is proposed,
empowered by multi-functional reconfigurable intelligent surfaces (MF-RIS)
capable of simultaneously reflecting, amplifying, and harvesting wireless
energy. The MF-RIS plays a pivotal role in addressing the energy shortages of
low-Earth orbit (LEO) satellites operating in shadowed regions, while
explicitly accounting for both communication and computing energy consumption
across the SAGIN nodes. To maximize the long-term energy efficiency (EE), we
formulate a joint optimization problem over the MF-RIS parameters, including
signal amplification, phase-shifts, energy harvesting ratio, and active element
selection as well as the SAGIN parameters of beamforming vectors, high-altitude
platform station (HAPS) deployment, user association, and computing capability.
The formulated problem is highly non-convex and non-linear and contains mixed
discrete-continuous parameters. To tackle this, we conceive a compressed hybrid
intelligence for twin-model enhanced multi-agent deep reinforcement learning
(CHIMERA) framework, which integrates semantic state-action compression and
parametrized sharing under hybrid reinforcement learning to efficiently explore
suitable complex actions. The simulation results have demonstrated that the
proposed CHIMERA scheme substantially outperforms the conventional benchmarks,
including fixed-configuration or non-harvesting MF-RIS, traditional RIS, and
no-RIS cases, as well as centralized and multi-agent deep reinforcement
learning baselines in terms of the highest EE. Moreover, the proposed
SAGIN-MF-RIS architecture achieves superior EE performance due to its
complementary coverage, offering notable advantages over either standalone
satellite, aerial, or ground-only deployments.

</details>


### [22] [Distilled Large Language Model in Confidential Computing Environment for System-on-Chip Design](https://arxiv.org/abs/2507.16226)
*Dong Ben,Hui Feng,Qian Wang*

Main category: cs.AI

TL;DR: 本研究评估了大语言模型(LLMs)在可信执行环境(TEE)中的性能表现，特别是Intel TDX环境下的部署效果，发现蒸馏模型和量化技术能显著提升在资源受限环境中的执行效率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在电路设计任务中应用日益广泛，但训练数据和模型作为机密知识产权需要保护。现有的可信执行环境实现无法高效支持资源密集型的LLMs，因此需要评估LLMs在TEE环境中的性能表现。

Method: 构建了三种实验环境：基于TEE、仅CPU和CPU-GPU混合实现，使用Intel Trust Domain Extensions (TDX)作为TEE环境。通过每秒token数量评估性能，测试了蒸馏模型(如DeepSeek)和量化模型(4位和8位量化)的表现，并使用SoC设计任务测试平台进行验证。

Result: 蒸馏模型由于参数较少在性能上优于其他模型，适合资源受限设备；量化模型(Q4和Q8)相比FP16模型性能提升高达3倍；对于参数较少的模型如DeepSeek-r1-1.5B，TDX实现在安全环境中的计算性能优于CPU版本。

Conclusion: 研究验证了在资源受限系统上高效部署轻量级LLMs用于半导体CAD应用的可行性，为保护机密知识产权的同时实现高效LLM部署提供了解决方案。

Abstract: Large Language Models (LLMs) are increasingly used in circuit design tasks
and have typically undergone multiple rounds of training. Both the trained
models and their associated training data are considered confidential
intellectual property (IP) and must be protected from exposure. Confidential
Computing offers a promising solution to protect data and models through
Trusted Execution Environments (TEEs). However, existing TEE implementations
are not designed to support the resource-intensive nature of LLMs efficiently.
In this work, we first present a comprehensive evaluation of the LLMs within a
TEE-enabled confidential computing environment, specifically utilizing Intel
Trust Domain Extensions (TDX). We constructed experiments on three
environments: TEE-based, CPU-only, and CPU-GPU hybrid implementations, and
evaluated their performance in terms of tokens per second.
  Our first observation is that distilled models, i.e., DeepSeek, surpass other
models in performance due to their smaller parameters, making them suitable for
resource-constrained devices. Also, in the quantized models such as 4-bit
quantization (Q4) and 8-bit quantization (Q8), we observed a performance gain
of up to 3x compared to FP16 models. Our findings indicate that for fewer
parameter sets, such as DeepSeek-r1-1.5B, the TDX implementation outperforms
the CPU version in executing computations within a secure environment. We
further validate the results using a testbench designed for SoC design tasks.
These validations demonstrate the potential of efficiently deploying
lightweight LLMs on resource-constrained systems for semiconductor CAD
applications.

</details>


### [23] [Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery](https://arxiv.org/abs/2507.16229)
*Bo Wen,Chen Wang,Qiwei Han,Raquel Norel,Julia Liu,Thaddeus Stappenbeck,Jeffrey L. Rogers*

Main category: cs.AI

TL;DR: 该论文探讨了基于语音的AI代理在医疗保健中的应用，通过开发Agent PULSE系统并进行试点研究，证明了AI语音助手在预防性护理和患者监测方面的潜力，特别是在服务不足的人群中能够提供经济有效的医疗服务。


<details>
  <summary>Details</summary>
Motivation: 医疗保健领域存在经济和可及性差距，传统人工干预在经济上不可行的情况下，需要探索AI语音代理作为数字健康服务的变革性解决方案，以弥合这些差距并改善医疗服务的可及性。

Method: 开发了Agent PULSE（患者理解和联络支持引擎）系统，这是IBM研究院、克利夫兰诊所基金会和莫尔豪斯医学院的合作项目。通过对33名炎症性肠病患者进行试点研究，构建经济模型分析AI代理的成本效益，并分析技术挑战和政策考虑因素。

Result: 试点研究显示70%的患者接受AI驱动的监测，37%的患者更喜欢AI监测而非传统方式。成本效用分析显示在常规监测任务中具有巨大的潜在节约。AI语音代理提高了医疗服务的可扩展性、效率以及患者参与度和可及性。

Conclusion: 基于语音的AI代理不仅能够增强医疗保健的可扩展性和效率，还能改善患者参与度和可及性。通过解决当前限制并将AI开发与伦理和监管框架相结合，语音AI代理可以作为公平、可持续数字医疗解决方案的关键入口点。

Abstract: The integration of voice-based AI agents in healthcare presents a
transformative opportunity to bridge economic and accessibility gaps in digital
health delivery. This paper explores the role of large language model
(LLM)-powered voice assistants in enhancing preventive care and continuous
patient monitoring, particularly in underserved populations. Drawing insights
from the development and pilot study of Agent PULSE (Patient Understanding and
Liaison Support Engine) -- a collaborative initiative between IBM Research,
Cleveland Clinic Foundation, and Morehouse School of Medicine -- we present an
economic model demonstrating how AI agents can provide cost-effective
healthcare services where human intervention is economically unfeasible. Our
pilot study with 33 inflammatory bowel disease patients revealed that 70\%
expressed acceptance of AI-driven monitoring, with 37\% preferring it over
traditional modalities. Technical challenges, including real-time
conversational AI processing, integration with healthcare systems, and privacy
compliance, are analyzed alongside policy considerations surrounding
regulation, bias mitigation, and patient autonomy. Our findings suggest that
AI-driven voice agents not only enhance healthcare scalability and efficiency
but also improve patient engagement and accessibility. For healthcare
executives, our cost-utility analysis demonstrates huge potential savings for
routine monitoring tasks, while technologists can leverage our framework to
prioritize improvements yielding the highest patient impact. By addressing
current limitations and aligning AI development with ethical and regulatory
frameworks, voice-based AI agents can serve as a critical entry point for
equitable, sustainable digital healthcare solutions.

</details>


### [24] [ResearcherBench: Evaluating Deep AI Research Systems on the Frontiers of Scientific Inquiry](https://arxiv.org/abs/2507.16280)
*Tianze Xu,Pengrui Lu,Lyumanshan Ye,Xiangkun Hu,Pengfei Liu*

Main category: cs.AI

TL;DR: 本文介绍了ResearcherBench，这是首个专门评估深度AI研究系统(DARS)在前沿AI科学问题上能力的基准测试，包含65个研究问题，采用双重评估框架，结果显示OpenAI Deep Research和Gemini Deep Research表现最优。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要将深度研究系统评估为网络检索和报告生成的代理，忽略了它们在科学研究前沿发现新见解的潜力。需要一个专门评估这些系统在前沿AI科学问题上能力的基准测试。

Method: 构建了包含65个研究问题的数据集，这些问题来自实际科学场景（如实验室讨论和访谈），涵盖35个不同的AI主题，分为技术细节、文献综述和开放咨询三类。采用双重评估框架：基于评分标准的评估（评估见解质量）和事实评估（测量引用准确性和覆盖度）。

Result: 评估了多个领先的商业DARS和基线系统。结果显示OpenAI Deep Research和Gemini Deep Research显著优于其他系统，在开放式咨询问题上表现尤为突出。这些能力代表了AI自我改进的重要一步。

Conclusion: ResearcherBench为评估下一代AI研究助手提供了标准化平台，有望促进AI研究评估的新视角，推动科学协作的新模式。该基准测试已开源，旨在促进深度AI研究系统的发展。

Abstract: The emergence of deep research systems presents significant capabilities in
problem-solving, extending from basic queries to sophisticated research tasks.
However, existing benchmarks primarily evaluate these systems as agents for web
retrieval and report generation, overlooking their potential to discover novel
insights on the frontiers of scientific research. To address this gap, we
introduce ResearcherBench, the first benchmark focused on evaluating the
capabilities of these advanced, agentic systems - which we refer to as Deep AI
Research Systems (DARS) - on frontier AI scientific questions. We compiled a
dataset of 65 research questions expertly selected from real-world scientific
scenarios such as laboratory discussions and interviews, spanning 35 different
AI subjects and categorized into three types: technical details, literature
review, and open consulting. Our dual evaluation framework combines rubric
assessment, which uses expert-designed criteria to evaluate insight quality,
with factual assessment, which measures citation accuracy (faithfulness) and
coverage (groundedness). We evaluated several leading commercial DARS and
baseline systems. Results show that OpenAI Deep Research and Gemini Deep
Research significantly outperform other systems, with particular strength in
open-ended consulting questions. Such capabilities represent a meaningful step
toward AI self-improvement, aligning with the vision of ASI for AI. We
open-source ResearcherBench to provide a standardized platform for promoting
the development of next-generation AI research assistants, hoping to foster a
new perspective in AI research evaluation for a novel pattern of scientific
collaboration: https://github.com/GAIR-NLP/ResearcherBench.

</details>


### [25] [Cross-Modal Distillation For Widely Differing Modalities](https://arxiv.org/abs/2507.16296)
*Cairong Zhao,Yufeng Jin,Zifan Song,Haonan Chen,Duoqian Miao,Guosheng Hu*

Main category: cs.AI

TL;DR: 本文提出了一个跨模态蒸馏框架，通过教师模型向学生模型传递知识来解决多模态数据获取受限的问题，采用软约束知识蒸馏策略和质量自适应权重模块来避免过拟合并实现有效的跨模态知识转移。


<details>
  <summary>Details</summary>
Motivation: 深度学习通过增加模型规模来提升性能变得困难且低效，而多模态学习虽然能引入更丰富的信息，但在实际应用中往往面临多模态数据获取受限的问题。传统的跨模态知识蒸馏容易因为不同模态间的巨大领域差距而导致过拟合。

Method: 提出跨模态蒸馏框架，包含两个核心组件：1）在特征层和分类器层分别设计软约束知识蒸馏策略，避免硬约束损失（如L2损失）导致的过拟合；2）设计基于质量的自适应权重模块，通过量化数据质量来为输入样本分配权重，提高模型训练的鲁棒性。

Result: 在说话人识别和图像分类任务上的实验结果表明，该方法能够有效实现图像、文本和语音等常用且差异较大模态之间的知识转移，证明了跨模态蒸馏框架的有效性。

Conclusion: 通过软约束知识蒸馏策略和质量自适应权重模块，成功解决了跨模态知识蒸馏中的过拟合问题，实现了不同模态间的有效知识转移，为解决多模态数据获取受限问题提供了有效的解决方案。

Abstract: Deep learning achieved great progress recently, however, it is not easy or
efficient to further improve its performance by increasing the size of the
model. Multi-modal learning can mitigate this challenge by introducing richer
and more discriminative information as input. To solve the problem of limited
access to multi-modal data at the time of use, we conduct multi-modal learning
by introducing a teacher model to transfer discriminative knowledge to a
student model during training. However, this knowledge transfer via
distillation is not trivial because the big domain gap between the widely
differing modalities can easily lead to overfitting. In this work, we introduce
a cross-modal distillation framework. Specifically, we find hard constrained
loss, e.g. l2 loss forcing the student being exact the same as the teacher, can
easily lead to overfitting in cross-modality distillation. To address this, we
propose two soft constrained knowledge distillation strategies at the feature
level and classifier level respectively. In addition, we propose a
quality-based adaptive weights module to weigh input samples via quantified
data quality, leading to robust model training. We conducted experiments on
speaker recognition and image classification tasks, and the results show that
our approach is able to effectively achieve knowledge transfer between the
commonly used and widely differing modalities of image, text, and speech.

</details>


### [26] [Mind the Gap: Evaluating the Representativeness of Quantitative Medical Language Reasoning LLM Benchmarks for African Disease Burdens](https://arxiv.org/abs/2507.16322)
*Fred Mutisya,Shikoh Gitau,Christine Syovata,Diana Oigara,Ibrahim Matende,Muna Aden,Munira Ali,Ryan Nyotu,Diana Marion,Job Nyangena,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha,Eric Mibuari,Jean Philbert Nsengemana,Talkmore Chidede*

Main category: cs.AI

TL;DR: 本研究发现现有医学大语言模型基准测试主要反映高收入国家的疾病谱，严重缺乏非洲地区主要疾病（如疟疾、HIV、结核病等）的代表性，因此开发了基于肯尼亚临床实践指南的Alama Health QA基准来更好地评估模型在非洲医疗场景下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有医学大语言模型基准测试主要基于高收入国家的考试大纲和疾病谱，对于以疟疾、HIV、结核病、镰状细胞病等被忽视热带疾病为主要负担的非洲地区部署存在有效性问题，需要开发更符合非洲医疗实际需求的评估基准。

Method: 系统回顾了31篇定量LLM评估论文（2019年1月-2025年5月），识别出19个英语医学问答基准。使用基于肯尼亚临床实践指南的检索增强生成框架开发Alama Health QA。对6个广泛使用的基准进行了统一的语义分析（NTD比例、时效性、可读性、词汇多样性指标）和专家盲评（临床相关性、指南一致性、清晰度、干扰项合理性、语言文化适配性）。

Result: Alama Health QA在所有语料库中捕获了超过40%的NTD提及，在疟疾（7.7%）、HIV（4.1%）和结核病（5.2%）方面具有最高的集内频率；AfriMedQA排名第二但缺乏正式的指南链接。全球基准显示最小的代表性（如镰状细胞病在三个集合中缺失）。定性评估中，Alama在相关性和指南一致性方面得分最高；PubMedQA在临床实用性方面得分最低。

Conclusion: 文献中广泛使用的定量医学LLM基准测试对非洲疾病负担和监管环境代表性不足，存在误导性能声明的风险。基于指南锚定、区域策划的资源如Alama Health QA及其扩展的疾病特异性衍生物对于非洲卫生系统中安全、公平的模型评估和部署至关重要。

Abstract: Introduction: Existing medical LLM benchmarks largely reflect examination
syllabi and disease profiles from high income settings, raising questions about
their validity for African deployment where malaria, HIV, TB, sickle cell
disease and other neglected tropical diseases (NTDs) dominate burden and
national guidelines drive care. Methodology: We systematically reviewed 31
quantitative LLM evaluation papers (Jan 2019 May 2025) identifying 19 English
medical QA benchmarks. Alama Health QA was developed using a retrieval
augmented generation framework anchored on the Kenyan Clinical Practice
Guidelines. Six widely used sets (AfriMedQA, MMLUMedical, PubMedQA, MedMCQA,
MedQAUSMLE, and guideline grounded Alama Health QA) underwent harmonized
semantic profiling (NTD proportion, recency, readability, lexical diversity
metrics) and blinded expert rating across five dimensions: clinical relevance,
guideline alignment, clarity, distractor plausibility, and language/cultural
fit. Results: Alama Health QA captured >40% of all NTD mentions across corpora
and the highest within set frequencies for malaria (7.7%), HIV (4.1%), and TB
(5.2%); AfriMedQA ranked second but lacked formal guideline linkage. Global
benchmarks showed minimal representation (e.g., sickle cell disease absent in
three sets) despite large scale. Qualitatively, Alama scored highest for
relevance and guideline alignment; PubMedQA lowest for clinical utility.
Discussion: Quantitative medical LLM benchmarks widely used in the literature
underrepresent African disease burdens and regulatory contexts, risking
misleading performance claims. Guideline anchored, regionally curated resources
such as Alama Health QA and expanded disease specific derivatives are essential
for safe, equitable model evaluation and deployment across African health
systems.

</details>


### [27] [Higher Gauge Flow Models](https://arxiv.org/abs/2507.16334)
*Alexander Strunk,Roland Assam*

Main category: cs.AI

TL;DR: 本文提出了高阶规范流模型，这是一类新颖的生成流模型，通过利用L∞代数扩展李代数，将高阶几何和高阶对称性集成到生成流模型框架中，在高斯混合模型数据集上表现出显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的生成流模型在处理复杂几何结构和对称性方面存在局限性，需要一种能够更好地利用高阶几何和高阶对称性的新方法来提升模型性能。

Method: 基于普通规范流模型的基础上，引入L∞代数来有效扩展李代数，从而将与高阶群相关的高阶几何和高阶对称性整合到生成流模型的框架中，构建高阶规范流模型。

Result: 在高斯混合模型数据集上的实验评估显示，与传统流模型相比，高阶规范流模型实现了显著的性能改进。

Conclusion: 高阶规范流模型通过集成高阶几何和高阶对称性，成功扩展了生成流模型的能力，为处理复杂数据分布提供了一种有效的新方法。

Abstract: This paper introduces Higher Gauge Flow Models, a novel class of Generative
Flow Models. Building upon ordinary Gauge Flow Models (arXiv:2507.13414), these
Higher Gauge Flow Models leverage an L$_{\infty}$-algebra, effectively
extending the Lie Algebra. This expansion allows for the integration of the
higher geometry and higher symmetries associated with higher groups into the
framework of Generative Flow Models. Experimental evaluation on a Gaussian
Mixture Model dataset revealed substantial performance improvements compared to
traditional Flow Models.

</details>


### [28] [Learning to Call: A Field Trial of a Collaborative Bandit Algorithm for Improved Message Delivery in Mobile Maternal Health](https://arxiv.org/abs/2507.16356)
*Arpan Dasgupta,Mizhaan Maniyar,Awadhesh Srivastava,Sanat Kumar,Amrita Mahale,Aparna Hedge,Arun Suggala,Karthikeyan Shanmugam,Aparna Taneja,Milind Tambe*

Main category: cs.AI

TL;DR: 该研究通过协同强盗算法优化印度Kilkari母婴健康项目的语音通话时间安排，在6500名参与者的试点中显著提高了通话接听率，展示了个性化调度在移动健康干预中的有效性。


<details>
  <summary>Details</summary>
Motivation: 印度Kilkari项目通过每周语音通话向数百万母亲传递重要的母婴健康信息，但当前随机通话调度经常导致未接听电话和信息传递效果下降，需要优化通话时间安排以提高信息传递效率。

Method: 设计并部署了一种协同强盗算法，通过学习每位母亲的个人通话偏好时间来优化通话调度。在约6500名Kilkari参与者中进行现场试验，将算法性能与基线随机通话方法进行比较。

Result: 协同强盗算法在通话接听率方面实现了统计学显著性改善，证明了该算法相比随机调度方法的优越性，展示了其在提高信息传递效果方面的潜力。

Conclusion: 个性化调度在移动健康干预中具有显著效果，机器学习技术在大规模改善母婴健康推广方面具有巨大潜力，该算法有望影响印度数百万母亲的健康信息获取。

Abstract: Mobile health (mHealth) programs utilize automated voice messages to deliver
health information, particularly targeting underserved communities,
demonstrating the effectiveness of using mobile technology to disseminate
crucial health information to these populations, improving health outcomes
through increased awareness and behavioral change. India's Kilkari program
delivers vital maternal health information via weekly voice calls to millions
of mothers. However, the current random call scheduling often results in missed
calls and reduced message delivery. This study presents a field trial of a
collaborative bandit algorithm designed to optimize call timing by learning
individual mothers' preferred call times. We deployed the algorithm with around
$6500$ Kilkari participants as a pilot study, comparing its performance to the
baseline random calling approach. Our results demonstrate a statistically
significant improvement in call pick-up rates with the bandit algorithm,
indicating its potential to enhance message delivery and impact millions of
mothers across India. This research highlights the efficacy of personalized
scheduling in mobile health interventions and underscores the potential of
machine learning to improve maternal health outreach at scale.

</details>


### [29] [Canonical Representations of Markovian Structural Causal Models: A Framework for Counterfactual Reasoning](https://arxiv.org/abs/2507.16370)
*Lucas de Lara*

Main category: cs.AI

TL;DR: 本文提出了一种新的反事实模型方法，作为结构因果模型的替代方案，用于在Pearl因果框架的马尔可夫设定下表示与给定因果图模型兼容的反事实推理。


<details>
  <summary>Details</summary>
Motivation: 反事实推理对应因果关系的最细粒度层次，虽然许多反事实陈述无法被证伪（即使通过随机实验），但它们支撑着个体公平性等基本概念。因此，提供模型来形式化和实现反事实信念仍然是一个基本的科学问题。

Method: 在Pearl因果框架的马尔可夫设定下，引入反事实模型（也称为结构因果模型的规范表示）。该方法使分析师能够通过具有预分配边际分布的随机过程概率分布来选择反事实概念，并刻画结构因果模型的反事实等价类。然后提出一个标准化程序来描述和实现各种反事实概念。

Result: 与结构因果模型相比，该方法允许在不改变观察和干预约束的情况下指定许多反事实概念。对应反事实层的模型内容不需要被估计，只需要做出选择。通过理论和数值例子说明了反事实在因果关系中的特定作用以及该方法的优势。

Conclusion: 该研究提供了一种新的反事实建模框架，能够更灵活地处理反事实推理问题，为因果推理中的反事实分析提供了有效的工具和方法。

Abstract: Counterfactual reasoning aims at answering contrary-to-fact questions like
''Would have Alice recovered had she taken aspirin?'' and corresponds to the
most fine-grained layer of causation. Critically, while many counterfactual
statements cannot be falsified -- even by randomized experiments -- they
underpin fundamental concepts like individual-wise fairness. Therefore,
providing models to formalize and implement counterfactual beliefs remains a
fundamental scientific problem. In the Markovian setting of Pearl's causal
framework, we propose an alternative approach to structural causal models to
represent counterfactuals compatible with a given causal graphical model. More
precisely, we introduce counterfactual models, also called canonical
representations of structural causal models. They enable analysts to choose a
counterfactual conception via random-process probability distributions with
preassigned marginals and characterize the counterfactual equivalence class of
structural causal models. Then, we present a normalization procedure to
describe and implement various counterfactual conceptions. Compared to
structural causal models, it allows to specify many counterfactual conceptions
without altering the observational and interventional constraints. Moreover,
the content of the model corresponding to the counterfactual layer does not
need to be estimated; only to make a choice. Finally, we illustrate the
specific role of counterfactuals in causality and the benefits of our approach
on theoretical and numerical examples.

</details>


### [30] [LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning](https://arxiv.org/abs/2507.16395)
*Bo Hou,Xin Tan,Kai Zheng,Fang Liu,Yinghao Zhu,Li Zhang*

Main category: cs.AI

TL;DR: 本文提出ColaUntangle，一个基于大语言模型的多智能体协作框架，用于解决代码提交解缠问题。该框架通过显式和隐式依赖分析，在C#和Java数据集上分别实现44%和100%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 开发者经常产生混合不相关变更的纠缠提交，这会对代码审查和维护产生负面影响。现有的基于规则、特征或图的解缠方法往往依赖浅层信号，无法有效区分显式依赖（如控制/数据流）和隐式依赖（如语义或概念关系）。

Method: 提出ColaUntangle协作咨询框架，采用多智能体架构：一个智能体专门处理显式依赖，另一个处理隐式依赖，审查者智能体通过迭代咨询综合两者观点。构建多版本程序依赖图(delta-PDG)来捕获显式和隐式上下文信息，使智能体能够在符号和语义层面推理代码关系。

Result: 在两个广泛使用的数据集（1,612个C#和14k个Java纠缠提交）上评估，ColaUntangle超越最佳基线方法，在C#数据集上实现44%改进，在Java数据集上实现100%改进。

Conclusion: 研究结果突出了基于大语言模型的协作框架在推进自动化提交解缠任务方面的潜力，证明了多智能体协作和显式/隐式依赖建模的有效性。

Abstract: Atomic commits, each of which addresses a single development concern, are a
best practice in software development. However, developers frequently produce
tangled commits that mix unrelated changes due to practical constraints or
unclear boundaries, negatively impacting code review and maintenance. Although
prior commit untangling approaches: rule-based, feature-based, or graph-based,
have made progress, they often rely on shallow signals and fail to distinguish
between explicit dependencies (e.g., control/data flow) and implicit ones
(e.g., semantic or conceptual relationships). In this paper, we propose
ColaUntangle, a new collaborative consultation framework for commit untangling
that models both explicit and implicit dependencies among code changes.
ColaUntangle integrates Large Language Model (LLM)-driven agents in a
multi-agent architecture: one agent specializes in explicit dependencies,
another in implicit ones, and a reviewer agent synthesizes their perspectives
through iterative consultation. To capture explicit and implicit contextual
information, we construct multi-version Program Dependency Graphs (delta-PDG),
enabling agents to reason over code relationships with both symbolic and
semantic depth. We evaluate ColaUntangle on two widely-used datasets (1,612 C#
and 14k Java tangled commits). Experimental results show that ColaUntangle
outperforms the best-performing baseline, achieving an improvement of 44% on
the C# dataset and 100% on the Java dataset. These findings highlight the
potential of LLM-based collaborative frameworks for advancing automated commit
untangling tasks.

</details>


### [31] [Self-Supervised Inductive Logic Programming](https://arxiv.org/abs/2507.16405)
*Stassa Patsantzis*

Main category: cs.AI

TL;DR: 本文提出了一种新的自监督归纳逻辑编程(ILP)方法Poker，能够在缺乏专家知识背景理论和负例的情况下，仅从少量正例和未标记样本中学习递归逻辑程序，并在学习过程中自动生成和标记新的正负例。


<details>
  <summary>Details</summary>
Motivation: 传统的归纳逻辑编程方法如元解释学习(MIL)需要依赖专家精心选择的背景理论和负例才能有效学习，但在实际应用中往往缺乏这些专业知识。因此需要开发一种能够在没有问题特定背景理论或负例的情况下进行学习的新方法。

Method: 提出了自监督ILP的新设置，开发了新的MIL算法Poker系统，该算法能够从正标记样本和零个或多个未标记样本中学习，并在学习过程中自动生成和标记新的正负例。同时引入了二阶确定范式(SONF)的方法来选择二阶背景理论，使其足够通用以学习某一类中的所有程序。

Result: 在上下文无关语法和L系统语言的语法学习实验中，Poker系统与最先进的Louise系统进行比较。实验结果显示，Poker的性能随着自动生成样本数量的增加而提高，而缺乏负例的Louise系统出现了过度泛化的问题。

Conclusion: Poker系统成功解决了传统ILP方法对专家知识依赖的问题，通过自动生成训练样本和采用通用的二阶背景理论，实现了更好的学习性能，为归纳逻辑编程在缺乏专业知识场景下的应用提供了新的解决方案。

Abstract: Inductive Logic Programming (ILP) approaches like Meta \-/ Interpretive
Learning (MIL) can learn, from few examples, recursive logic programs with
invented predicates that generalise well to unseen instances. This ability
relies on a background theory and negative examples, both carefully selected
with expert knowledge of a learning problem and its solutions. But what if such
a problem-specific background theory or negative examples are not available? We
formalise this question as a new setting for Self-Supervised ILP and present a
new MIL algorithm that learns in the new setting from some positive labelled,
and zero or more unlabelled examples, and automatically generates, and labels,
new positive and negative examples during learning. We implement this algorithm
in Prolog in a new MIL system, called Poker. We compare Poker to
state-of-the-art MIL system Louise on experiments learning grammars for
Context-Free and L-System languages from labelled, positive example strings, no
negative examples, and just the terminal vocabulary of a language, seen in
examples, as a first-order background theory. We introduce a new approach for
the principled selection of a second-order background theory as a Second Order
Definite Normal Form (SONF), sufficiently general to learn all programs in a
class, thus removing the need for a backgound theory tailored to a learning
task. We find that Poker's performance improves with increasing numbers of
automatically generated examples while Louise, bereft of negative examples,
over-generalises.

</details>


### [32] [Identifying Pre-training Data in LLMs: A Neuron Activation-Based Detection Framework](https://arxiv.org/abs/2507.16414)
*Hongyi Tang,Zhihao Zhu,Yi Yang*

Main category: cs.AI

TL;DR: 本文提出了NA-PDD算法，通过分析神经元激活模式来检测大语言模型的预训练数据，并构建了CCNewsPDD基准测试集，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的训练数据可能包含版权材料或私人信息，引发法律和伦理问题，同时面临数据集污染和偏见内化的批评。现有的预训练数据检测方法依赖于预测置信度和损失等表面特征，性能有限。

Method: 提出NA-PDD算法，基于训练数据和非训练数据在大语言模型推理过程中激活不同神经元的观察，分析差异化神经元激活模式来识别预训练数据。同时构建了CCNewsPDD基准测试集，采用严格的数据变换确保训练和非训练数据间时间分布的一致性。

Result: 在三个基准测试和多个大语言模型上的实验表明，NA-PDD算法显著优于现有的预训练数据检测方法。

Conclusion: 通过分析神经元激活模式的NA-PDD算法为预训练数据检测提供了更有效的解决方案，能够更准确地识别大语言模型预训练语料中的特定数据，有助于解决版权和隐私相关的法律伦理问题。

Abstract: The performance of large language models (LLMs) is closely tied to their
training data, which can include copyrighted material or private information,
raising legal and ethical concerns. Additionally, LLMs face criticism for
dataset contamination and internalizing biases. To address these issues, the
Pre-Training Data Detection (PDD) task was proposed to identify if specific
data was included in an LLM's pre-training corpus. However, existing PDD
methods often rely on superficial features like prediction confidence and loss,
resulting in mediocre performance. To improve this, we introduce NA-PDD, a
novel algorithm analyzing differential neuron activation patterns between
training and non-training data in LLMs. This is based on the observation that
these data types activate different neurons during LLM inference. We also
introduce CCNewsPDD, a temporally unbiased benchmark employing rigorous data
transformations to ensure consistent time distributions between training and
non-training data. Our experiments demonstrate that NA-PDD significantly
outperforms existing methods across three benchmarks and multiple LLMs.

</details>


### [33] [From model-based learning to model-free behaviour with Meta-Interpretive Learning](https://arxiv.org/abs/2507.16434)
*Stassa Patsantzis*

Main category: cs.AI

TL;DR: 本文提出了一种结合模型化和无模型强化学习的自主智能体方法，使用元解释学习训练模型化求解器来指导无模型控制器的训练，在网格导航任务中验证了两者的等效性。


<details>
  <summary>Details</summary>
Motivation: 自主智能体需要在新环境中独立行动，这要求同时具备模型化智能体的规划能力和无模型智能体的环境适应能力。现有方法往往只专注于其中一种能力，缺乏有效结合两者优势的框架。

Method: 使用元解释学习(Meta-Interpretive Learning)来学习一个模型化求解器(Solver)，然后用这个求解器来训练一个无模型控制器(Controller)，使控制器能够解决与求解器相同的规划问题。

Result: 在两种网格导航环境中验证了方法的有效性：随机生成的迷宫和具有大片开放区域的湖泊地图。实验表明，求解器能解决的所有导航问题，控制器同样能够解决，证明了两者在问题解决能力上的等效性。

Conclusion: 成功创建了一个结合模型化和无模型能力的自主智能体，通过元解释学习实现了求解器和控制器的等效性，为开发能在新环境中独立行动的智能体提供了有效的技术路径。

Abstract: A "model" is a theory that describes the state of an environment and the
effects of an agent's decisions on the environment. A model-based agent can use
its model to predict the effects of its future actions and so plan ahead, but
must know the state of the environment. A model-free agent cannot plan, but can
act without a model and without completely observing the environment. An
autonomous agent capable of acting independently in novel environments must
combine both sets of capabilities. We show how to create such an agent with
Meta-Interpretive Learning used to learn a model-based Solver used to train a
model-free Controller that can solve the same planning problems as the Solver.
We demonstrate the equivalence in problem-solving ability of the two agents on
grid navigation problems in two kinds of environment: randomly generated mazes,
and lake maps with wide open areas. We find that all navigation problems solved
by the Solver are also solved by the Controller, indicating the two are
equivalent.

</details>


### [34] [Improving ASP-based ORS Schedules through Machine Learning Predictions](https://arxiv.org/abs/2507.16454)
*Pierangela Bruno,Carmine Dodaro,Giuseppe Galatà,Marco Maratea,Marco Mochi*

Main category: cs.AI

TL;DR: 本文提出了一种集成归纳和演绎技术的手术室调度优化方法，通过机器学习预测手术时长并结合答案集编程生成更稳健的临时调度方案


<details>
  <summary>Details</summary>
Motivation: 现有基于答案集编程(ASP)的手术室调度解决方案虽然整体令人满意，但应用于真实数据时只能验证编码是否与实际数据一致，最多建议可能的替代调度方案。因此无法生成临时调度，且结果调度方案不够稳健

Method: 集成归纳和演绎技术：首先使用机器学习算法从历史数据预测手术持续时间来计算临时调度；然后将预测的置信度作为问题的额外输入，相应更新编码以计算更稳健的调度方案

Result: 在意大利利古里亚ASL1的历史数据上的实验结果证实了这种集成方法的可行性

Conclusion: 通过将机器学习预测与答案集编程相结合，成功解决了手术室调度中无法生成临时调度和调度方案不够稳健的问题，为实际医疗环境中的手术室调度优化提供了有效解决方案

Abstract: The Operating Room Scheduling (ORS) problem deals with the optimization of
daily operating room surgery schedules. It is a challenging problem subject to
many constraints, like to determine the starting time of different surgeries
and allocating the required resources, including the availability of beds in
different department units. Recently, solutions to this problem based on Answer
Set Programming (ASP) have been delivered. Such solutions are overall
satisfying but, when applied to real data, they can currently only verify
whether the encoding aligns with the actual data and, at most, suggest
alternative schedules that could have been computed. As a consequence, it is
not currently possible to generate provisional schedules. Furthermore, the
resulting schedules are not always robust.
  In this paper, we integrate inductive and deductive techniques for solving
these issues. We first employ machine learning algorithms to predict the
surgery duration, from historical data, to compute provisional schedules. Then,
we consider the confidence of such predictions as an additional input to our
problem and update the encoding correspondingly in order to compute more robust
schedules. Results on historical data from the ASL1 Liguria in Italy confirm
the viability of our integration.
  Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [35] [Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs](https://arxiv.org/abs/2507.16473)
*Chang Li,Yaren Zhang,Haoran Lv,Qiong Cao,Chao Xue,Xiaodong He*

Main category: cs.AI

TL;DR: 本文提出了一种在潜在空间进行隐式推理的框架，通过分层强化学习中的选项(options)来替代大语言模型中计算昂贵的显式思维链推理，并通过变分马尔可夫选项评论家算法和连续MDP同态理论为该方法提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然通过显式思维链提示展现出强大的推理能力，但生成逐步的文本解释在计算上既昂贵又缓慢。为了克服这一问题，研究者希望开发一种高效的隐式推理框架，让模型在潜在空间中"思考"而无需为每一步生成显式文本。

Method: 提出将潜在思维建模为分层强化学习框架中的时间扩展抽象动作(选项)。引入变分马尔可夫选项评论家(VMOC)算法，这是一种使用变分推理的离策略算法。扩展连续MDP同态理论为使用选项作为抽象推理空间提供理论基础。提出冷启动程序，利用监督微调数据将人类推理演示蒸馏到潜在选项空间中。

Result: 在复杂逻辑推理基准测试和具有挑战性的运动控制任务上取得了强劲的性能表现，验证了该框架作为学习语言和控制抽象技能的原则性方法的有效性。

Conclusion: 该研究成功开发了一个在潜在空间进行高效隐式推理的框架，通过理论基础和实验验证证明了该方法能够在保持解决方案最优性的同时显著提高推理效率，为大语言模型的推理能力提供了新的发展方向。

Abstract: Large Language Models (LLMs) have shown remarkable reasoning ability through
explicit Chain-of-Thought (CoT) prompting, but generating these step-by-step
textual explanations is computationally expensive and slow. To overcome this,
we aim to develop a framework for efficient, implicit reasoning, where the
model "thinks" in a latent space without generating explicit text for every
step. We propose that these latent thoughts can be modeled as
temporally-extended abstract actions, or options, within a hierarchical
reinforcement learning framework. To effectively learn a diverse library of
options as latent embeddings, we first introduce the Variational Markovian
Option Critic (VMOC), an off-policy algorithm that uses variational inference
within the HiT-MDP framework. To provide a rigorous foundation for using these
options as an abstract reasoning space, we extend the theory of continuous MDP
homomorphisms. This proves that learning a policy in the simplified, abstract
latent space, for which VMOC is suited, preserves the optimality of the
solution to the original, complex problem. Finally, we propose a cold-start
procedure that leverages supervised fine-tuning (SFT) data to distill human
reasoning demonstrations into this latent option space, providing a rich
initialization for the model's reasoning capabilities. Extensive experiments
demonstrate that our approach achieves strong performance on complex logical
reasoning benchmarks and challenging locomotion tasks, validating our framework
as a principled method for learning abstract skills for both language and
control.

</details>


### [36] [ACT: Bridging the Gap in Code Translation through Synthetic Data Generation & Adaptive Training](https://arxiv.org/abs/2507.16478)
*Shreya Saxena,Siva Prasad,Zishan Ahmad,Vishal Vaddina*

Main category: cs.AI

TL;DR: 提出了ACT框架，通过自动化流水线对开源大语言模型进行微调，以提升代码翻译能力，缩小开源模型与闭源解决方案之间的性能差距


<details>
  <summary>Details</summary>
Motivation: 传统的自动化代码翻译方法依赖手工规则缺乏灵活性和可扩展性，而先进的语言模型虽有前景但多为专有API实现，存在数据安全和依赖性问题，因此需要一个能够提升开源大语言模型代码翻译能力的框架

Method: 开发ACT框架，包含三个核心模块：1）合成数据生成模块，从初始代码样本构建高质量数据集并加入单元测试确保功能准确性；2）执行级检查的评估框架，全面评估翻译质量；3）控制器模块，动态调整超参数，协调迭代数据生成和基于实时评估的微调过程

Result: ACT持续提升开源模型的有效性，为企业和开发者提供安全可靠的替代方案。将数据生成流水线应用于工业级迁移项目显著提高了开发者效率

Conclusion: ACT框架成功缩小了开源模型与闭源解决方案之间的性能差距，通过自动化流水线和智能控制实现了开源大语言模型代码翻译能力的显著提升，为软件开发和迁移项目提供了安全、可靠且高效的解决方案

Abstract: Code translation is a crucial process in software development and migration
projects, enabling interoperability between different programming languages and
enhancing software adaptability and thus longevity. Traditional automated
translation methods rely heavily on handcrafted transformation rules, which
often lack flexibility and scalability. Meanwhile, advanced language models
present promising alternatives but are often limited by proprietary, API-based
implementations that raise concerns over data security and reliance. In this
paper, we present Auto-Train for Code Translation (ACT), an innovative
framework that aims to improve code translation capabilities by enabling
in-house finetuning of open-source Large Language Models (LLMs). ACT's
automated pipeline significantly boosts the performance of these models,
narrowing the gap between open-source accessibility and the high performance of
closed-source solutions. Central to ACT is its synthetic data generation
module, which builds extensive, high-quality datasets from initial code
samples, incorporating unit tests to ensure functional accuracy and diversity.
ACT's evaluation framework incorporates execution-level checks, offering a
comprehensive assessment of translation quality. A key feature in ACT is its
controller module, which manages the entire pipeline by dynamically adjusting
hyperparameters, orchestrating iterative data generation, and finetuning based
on real-time evaluations. This enables ACT to intelligently optimize when to
continue training, generate additional targeted training data, or stop the
process. Our results demonstrate that ACT consistently enhances the
effectiveness of open-source models, offering businesses and developers a
secure and reliable alternative. Additionally, applying our data generation
pipeline to industry-scale migration projects has led to a notable increase in
developer acceleration.

</details>


### [37] [Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications](https://arxiv.org/abs/2507.16507)
*Jean Lelong,Adnane Errazine,Annabelle Blangero*

Main category: cs.AI

TL;DR: 本文介绍了INRAExplorer，一个针对法国农业食品环境研究院(INRAE)科学数据的智能体RAG系统，通过多工具架构和知识图谱克服了传统RAG系统在复杂查询上的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的检索增强生成(RAG)系统在处理复杂查询时存在显著不足：只能提供有限的提取式答案，难以进行多目标检索，无法有效处理复杂的实体关系。这在知识密集型领域中形成了关键缺口，需要更强大的系统来处理专业领域的复杂知识交互需求。

Method: 开发了INRAExplorer智能体RAG系统，采用基于LLM的智能体和多工具架构设计。系统通过从INRAE开放获取出版物构建的综合知识图谱来动态接入丰富的知识库，实现迭代式定向查询、全面数据集检索和多跳推理功能。

Result: INRAExplorer能够成功进行迭代式定向查询，检索详尽的数据集（如某作者的所有出版物），执行多跳推理，并提供结构化的综合性答案，有效提升了专业领域的知识交互能力。

Conclusion: INRAExplorer作为增强专业领域知识交互的具体实例，证明了智能体RAG系统在克服传统RAG局限性方面的有效性，为知识密集型领域提供了更强大的查询和推理解决方案。

Abstract: Conventional Retrieval-Augmented Generation (RAG) systems enhance Large
Language Models (LLMs) but often fall short on complex queries, delivering
limited, extractive answers and struggling with multiple targeted retrievals or
navigating intricate entity relationships. This is a critical gap in
knowledge-intensive domains. We introduce INRAExplorer, an agentic RAG system
for exploring the scientific data of INRAE (France's National Research
Institute for Agriculture, Food and Environment). INRAExplorer employs an
LLM-based agent with a multi-tool architecture to dynamically engage a rich
knowledge base, through a comprehensive knowledge graph derived from open
access INRAE publications. This design empowers INRAExplorer to conduct
iterative, targeted queries, retrieve exhaustive datasets (e.g., all
publications by an author), perform multi-hop reasoning, and deliver
structured, comprehensive answers. INRAExplorer serves as a concrete
illustration of enhancing knowledge interaction in specialized fields.

</details>


### [38] [Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report](https://arxiv.org/abs/2507.16534)
*Shanghai AI Lab,:,Xiaoyang Chen,Yunhao Chen,Zeren Chen,Zhiyun Chen,Hanyun Cui,Yawen Duan,Jiaxuan Guo,Qi Guo,Xuhao Hu,Hong Huang,Lige Huang,Chunxiao Li,Juncheng Li,Qihao Lin,Dongrui Liu,Xinmin Liu,Zicheng Liu,Chaochao Lu,Xiaoya Lu,Jingjing Qu,Qibing Ren,Jing Shao,Jingwei Shi,Jingwei Sun,Peng Wang,Weibing Wang,Jia Xu,Lewen Yan,Xiao Yu,Yi Yu,Boxuan Zhang,Jie Zhang,Weichen Zhang,Zhijie Zheng,Tianyi Zhou,Bowen Zhou*

Main category: cs.AI

TL;DR: 本研究对前沿AI模型的风险进行了全面评估，识别了七个关键风险领域，并使用"红线"和"黄线"建立了风险评估框架。研究发现当前前沿AI模型主要处于绿色和黄色风险区域，尚未跨越红线，但在说服操控等领域存在较高风险。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能技术快速发展，前沿AI模型带来前所未有的风险，需要建立系统性的风险识别和评估框架，以理解和管控这些新兴风险，确保AI技术的安全发展。

Method: 采用E-T-C分析框架（部署环境-威胁源-使能能力），结合"AI-45°定律"，建立包含"红线"（不可容忍阈值）和"黄线"（早期警告指标）的风险评估体系，将风险划分为绿色（可管理）、黄色（需加强缓解措施）和红色（需暂停开发/部署）三个区域。

Result: 实验结果显示所有最新前沿AI模型均处于绿色和黄色区域，未跨越红线。网络攻击和失控AI研发风险未达到黄线；自我复制和战略欺骗风险大多处于绿区，部分推理模型达到黄区；说服操控领域大多数模型处于黄区；生物化学风险无法排除大多数模型处于黄区的可能性。

Conclusion: 当前前沿AI模型的风险总体可控但不容忽视，特别是在人类影响力方面表现出较高风险。研究反映了对AI前沿风险的当前理解水平，呼吁采取集体行动来缓解这些挑战，为AI安全发展提供指导。

Abstract: To understand and identify the unprecedented risks posed by rapidly advancing
artificial intelligence (AI) models, this report presents a comprehensive
assessment of their frontier risks. Drawing on the E-T-C analysis (deployment
environment, threat source, enabling capability) from the Frontier AI Risk
Management Framework (v1.0) (SafeWork-F1-Framework), we identify critical risks
in seven areas: cyber offense, biological and chemical risks, persuasion and
manipulation, uncontrolled autonomous AI R\&D, strategic deception and
scheming, self-replication, and collusion. Guided by the "AI-$45^\circ$ Law,"
we evaluate these risks using "red lines" (intolerable thresholds) and "yellow
lines" (early warning indicators) to define risk zones: green (manageable risk
for routine deployment and continuous monitoring), yellow (requiring
strengthened mitigations and controlled deployment), and red (necessitating
suspension of development and/or deployment). Experimental results show that
all recent frontier AI models reside in green and yellow zones, without
crossing red lines. Specifically, no evaluated models cross the yellow line for
cyber offense or uncontrolled AI R\&D risks. For self-replication, and
strategic deception and scheming, most models remain in the green zone, except
for certain reasoning models in the yellow zone. In persuasion and
manipulation, most models are in the yellow zone due to their effective
influence on humans. For biological and chemical risks, we are unable to rule
out the possibility of most models residing in the yellow zone, although
detailed threat modeling and in-depth assessment are required to make further
claims. This work reflects our current understanding of AI frontier risks and
urges collective action to mitigate these challenges.

</details>


### [39] [Novel Multi-Agent Action Masked Deep Reinforcement Learning for General Industrial Assembly Lines Balancing Problems](https://arxiv.org/abs/2507.16635)
*Ali Mohamed Ali,Luca Tirel,Hashim A. Hashim*

Main category: cs.AI

TL;DR: 本文提出了一种基于深度强化学习的工业装配线优化方法，通过马尔可夫决策过程建模，采用动作掩码和多智能体架构来提高任务和资源调度的效率，相比传统方法实现了更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 传统的整数规划方法在大规模场景下计算复杂度过高，遗传算法等启发式方法在复杂情况下往往产生次优解，现有模型大多对装配线类型有特定假设限制，因此需要一种通用且高效的工业装配线优化方法。

Method: 将通用工业装配线建模为马尔可夫决策过程(MDP)，不对装配线类型施加假设；使用深度强化学习智能体进行任务和资源调度优化；提出动作掩码技术确保智能体只选择可行动作；采用多智能体方法，每个工作站由独立智能体管理；使用集中训练分散执行的框架。

Result: 通过数值仿真验证了所提方案的有效性，与基于模型的对比方法相比，实现了显著更快的最优解收敛速度；动作掩码技术减少了训练时间；多智能体方法降低了状态和动作空间的复杂度；框架具有良好的可扩展性。

Conclusion: 提出的基于深度强化学习的工业装配线优化框架能够有效解决大规模装配线调度问题，通过创新的动作掩码和多智能体架构显著提高了学习效率和解决方案质量，为实际工业应用提供了可行的实时优化方案。

Abstract: Efficient planning of activities is essential for modern industrial assembly
lines to uphold manufacturing standards, prevent project constraint violations,
and achieve cost-effective operations. While exact solutions to such challenges
can be obtained through Integer Programming (IP), the dependence of the search
space on input parameters often makes IP computationally infeasible for
large-scale scenarios. Heuristic methods, such as Genetic Algorithms, can also
be applied, but they frequently produce suboptimal solutions in extensive
cases. This paper introduces a novel mathematical model of a generic industrial
assembly line formulated as a Markov Decision Process (MDP), without imposing
assumptions on the type of assembly line a notable distinction from most
existing models. The proposed model is employed to create a virtual environment
for training Deep Reinforcement Learning (DRL) agents to optimize task and
resource scheduling. To enhance the efficiency of agent training, the paper
proposes two innovative tools. The first is an action-masking technique, which
ensures the agent selects only feasible actions, thereby reducing training
time. The second is a multi-agent approach, where each workstation is managed
by an individual agent, as a result, the state and action spaces were reduced.
A centralized training framework with decentralized execution is adopted,
offering a scalable learning architecture for optimizing industrial assembly
lines. This framework allows the agents to learn offline and subsequently
provide real-time solutions during operations by leveraging a neural network
that maps the current factory state to the optimal action. The effectiveness of
the proposed scheme is validated through numerical simulations, demonstrating
significantly faster convergence to the optimal solution compared to a
comparable model-based approach.

</details>


### [40] [Adaptive Inventory Strategies using Deep Reinforcement Learning for Dynamic Agri-Food Supply Chains](https://arxiv.org/abs/2507.16670)
*Amandeep Kaur,Gyan Prakash*

Main category: cs.AI

TL;DR: 本研究提出了一种新颖的深度强化学习算法，用于解决农产品供应链中需求和交货时间不确定性下的库存管理问题，通过结合价值型和策略型DRL方法来优化库存补充策略并最大化整体利润。


<details>
  <summary>Details</summary>
Motivation: 农产品面临季节性生产和需求波动，传统库存管理方法在应对需求和交货时间不确定性以及产品易腐性时存在挑战，且现有文献缺乏对食品供应链各层级利益相关者协调的考虑，导致库存过剩或缺货问题。

Method: 提出了一种结合价值型和策略型深度强化学习方法的新算法，该算法能够在连续动作空间中选择最优订购量，同时考虑产品易腐性和不确定性，通过共享的利润最大化优化目标来激励利益相关者之间的协作。

Result: 使用新鲜农产品供应链库存的实证数据进行评估，实验结果证实了所提出的库存补充策略在随机需求模式和交货时间场景下的性能改善，能够有效解决库存优化挑战。

Conclusion: 研究成果为政策制定者在不确定性条件下更有效地管理农产品库存提供了管理启示，所提出的DRL算法能够成功解决农产品供应链中的复杂库存管理问题。

Abstract: Agricultural products are often subject to seasonal fluctuations in
production and demand. Predicting and managing inventory levels in response to
these variations can be challenging, leading to either excess inventory or
stockouts. Additionally, the coordination among stakeholders at various level
of food supply chain is not considered in the existing body of literature. To
bridge these research gaps, this study focuses on inventory management of
agri-food products under demand and lead time uncertainties. By implementing
effective inventory replenishment policy results in maximize the overall profit
throughout the supply chain. However, the complexity of the problem increases
due to these uncertainties and shelf-life of the product, that makes
challenging to implement traditional approaches to generate optimal set of
solutions. Thus, the current study propose a novel Deep Reinforcement Learning
(DRL) algorithm that combines the benefits of both value- and policy-based DRL
approaches for inventory optimization under uncertainties. The proposed
algorithm can incentivize collaboration among stakeholders by aligning their
interests and objectives through shared optimization goal of maximizing
profitability along the agri-food supply chain while considering perishability,
and uncertainty simultaneously. By selecting optimal order quantities with
continuous action space, the proposed algorithm effectively addresses the
inventory optimization challenges. To rigorously evaluate this algorithm, the
empirical data from fresh agricultural products supply chain inventory is
considered. Experimental results corroborate the improved performance of the
proposed inventory replenishment policy under stochastic demand patterns and
lead time scenarios. The research findings hold managerial implications for
policymakers to manage the inventory of agricultural products more effectively
under uncertainty.

</details>


### [41] [Deliberative Searcher: Improving LLM Reliability via Reinforcement Learning with constraints](https://arxiv.org/abs/2507.16727)
*Zhenyun Yin,Shujie Wang,Xuhong Wang,Xingjun Ma,Yinchun Wang*

Main category: cs.AI

TL;DR: 本文提出了Deliberative Searcher框架，这是首个将确定性校准与基于检索的搜索相结合的开放域问答系统，通过多步反思和验证提高大语言模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 提高大语言模型在真实场景部署中的可靠性是关键问题，需要解决模型置信度与正确性之间的对齐问题，使模型输出更加可信。

Method: 提出Deliberative Searcher框架，将确定性校准与基于检索的搜索相结合，智能体在维基百科数据上执行多步反思和验证，并使用强化学习算法在软可靠性约束下优化准确性。

Result: 实验结果表明，所提出的方法改善了模型置信度与正确性之间的对齐，生成了更加可信的输出结果。

Conclusion: Deliberative Searcher框架成功提高了大语言模型在开放域问答任务中的可靠性，通过整合确定性校准和检索验证机制，实现了更好的置信度校准和输出可信度。

Abstract: Improving the reliability of large language models (LLMs) is critical for
deploying them in real-world scenarios. In this paper, we propose
\textbf{Deliberative Searcher}, the first framework to integrate certainty
calibration with retrieval-based search for open-domain question answering. The
agent performs multi-step reflection and verification over Wikipedia data and
is trained with a reinforcement learning algorithm that optimizes for accuracy
under a soft reliability constraint. Empirical results show that proposed
method improves alignment between model confidence and correctness, leading to
more trustworthy outputs. This paper will be continuously updated.

</details>


### [42] [WGRAMMAR: Leverage Prior Knowledge to Accelerate Structured Decoding](https://arxiv.org/abs/2507.16768)
*Ran Wang,Xiaoxuan Liu,Hao Ren,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.AI

TL;DR: 该论文提出了wgrammar，一个轻量级的结构化解码引擎，通过将约束分解为静态和动态组件，实现了比现有系统高达250倍的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的结构化解码方法在让大语言模型生成特定格式输出（如HTML或JSON）时存在效率瓶颈，主要体现在语法编译、状态跟踪和掩码创建等方面。许多实际任务中蕴含着关于输出结构的强先验知识，但现有方法没有充分利用这一点。

Method: 提出了一种约束分解方法，将约束分为静态和动态组件：静态结构离线预编译，动态参数在运行时使用语法片段实例化。采用组合操作符集合来建模规则格式，而不是依赖下推自动机，从而降低转换延迟。开发了wgrammar解码引擎，集成了领域感知简化、约束分解和掩码缓存技术。

Result: wgrammar实现了比现有系统高达250倍的性能提升，显著改善了结构化解码的效率。该系统的源代码已在GitHub上公开发布。

Conclusion: 通过智能地分解约束并利用领域先验知识，wgrammar成功解决了结构化解码中的效率瓶颈问题，为大语言模型生成格式化输出提供了一个高效的解决方案。

Abstract: Structured decoding enables large language models (LLMs) to generate outputs
in formats required by downstream systems, such as HTML or JSON. However,
existing methods suffer from efficiency bottlenecks due to grammar compilation,
state tracking, and mask creation. We observe that many real-world tasks embed
strong prior knowledge about output structure. Leveraging this, we propose a
decomposition of constraints into static and dynamic components -- precompiling
static structures offline and instantiating dynamic arguments at runtime using
grammar snippets. Instead of relying on pushdown automata, we employ a
compositional set of operators to model regular formats, achieving lower
transition latency. We introduce wgrammar, a lightweight decoding engine that
integrates domain-aware simplification, constraint decomposition, and mask
caching, achieving up to 250x speedup over existing systems. wgrammar's source
code is publicly available at https://github.com/wrran/wgrammar.

</details>


### [43] [ChatChecker: A Framework for Dialogue System Testing and Evaluation Through Non-cooperative User Simulation](https://arxiv.org/abs/2507.16792)
*Roman Mayr,Michel Schimpf,Thomas Bohné*

Main category: cs.AI

TL;DR: 本文提出了ChatChecker框架，用于自动化评估和测试复杂对话系统，通过LLM模拟用户交互来识别对话故障并评估质量，无需参考对话且与目标系统实现解耦。


<details>
  <summary>Details</summary>
Motivation: 现代对话系统依赖大语言模型但实现复杂，集成多个LLM、外部工具和数据库，仅评估底层LLM不足，需要整体测试评估对话系统，但缺乏有效的对话级质量保证方法。

Method: 设计ChatChecker框架，使用LLM模拟多样化用户交互，通过在提示中包含错误分类法来改进故障检测，并提出基于挑战性角色的非合作用户模拟器来更有效地发现目标对话系统的弱点。

Result: 相比之前基于LLM的方法，通过在提示中包含错误分类法提高了故障检测性能；非合作用户模拟器能更有效地揭示对话系统的弱点；框架减少了设置工作量且具有泛化性。

Conclusion: ChatChecker为复杂对话系统提供了全面且可扩展的测试方案，帮助研究人员和从业者加速开发稳健的对话系统，解决了对话系统整体评估的重要挑战。

Abstract: While modern dialogue systems heavily rely on large language models (LLMs),
their implementation often goes beyond pure LLM interaction. Developers
integrate multiple LLMs, external tools, and databases. Therefore, assessment
of the underlying LLM alone does not suffice, and the dialogue systems must be
tested and evaluated as a whole. However, this remains a major challenge. With
most previous work focusing on turn-level analysis, less attention has been
paid to integrated dialogue-level quality assurance. To address this, we
present ChatChecker, a framework for automated evaluation and testing of
complex dialogue systems. ChatChecker uses LLMs to simulate diverse user
interactions, identify dialogue breakdowns, and evaluate quality. Compared to
previous approaches, our design reduces setup effort and is generalizable, as
it does not require reference dialogues and is decoupled from the
implementation of the target dialogue system. We improve breakdown detection
performance over a prior LLM-based approach by including an error taxonomy in
the prompt. Additionally, we propose a novel non-cooperative user simulator
based on challenging personas that uncovers weaknesses in target dialogue
systems more effectively. Through this, ChatChecker contributes to thorough and
scalable testing. This enables both researchers and practitioners to accelerate
the development of robust dialogue systems.

</details>


### [44] [Uncertainty-Aware Knowledge Transformers for Peer-to-Peer Energy Trading with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2507.16796)
*Mian Ibad Ali Shah,Enda Barrett,Karl Mason*

Main category: cs.AI

TL;DR: 本文提出了一个结合不确定性感知预测和多智能体强化学习的P2P能源交易框架，通过Knowledge Transformer with Uncertainty (KTU)模型量化预测不确定性，显著降低能源采购成本并提高销售收入。


<details>
  <summary>Details</summary>
Motivation: 现有P2P能源交易研究依赖确定性预测，缺乏对预测不确定性的量化，这在随机性环境中影响决策的鲁棒性。需要一个能够明确处理风险和变异性的不确定性感知框架。

Method: 提出Knowledge Transformer with Uncertainty (KTU)异方差概率变换器预测模型，利用领域特定特征和定制损失函数生成可靠的概率预测和置信区间。将不确定性感知预测集成到多智能体强化学习(MARL)框架中，使智能体能够在明确理解风险的情况下优化交易策略。

Result: 不确定性感知深度Q网络在无P2P交易时降低能源采购成本5.7%，有P2P交易时降低3.2%；电力销售收入分别增加6.4%和44.7%；峰时电网需求分别减少38.8%和45.6%。启用P2P交易时改善效果更加显著。

Conclusion: 不确定性感知预测与多智能体强化学习的结合显著提升了P2P能源交易的经济效率和系统韧性。先进预测技术与市场机制的协同作用为构建弹性、经济高效的能源社区提供了有效解决方案。

Abstract: This paper presents a novel framework for Peer-to-Peer (P2P) energy trading
that integrates uncertainty-aware prediction with multi-agent reinforcement
learning (MARL), addressing a critical gap in current literature. In contrast
to previous works relying on deterministic forecasts, the proposed approach
employs a heteroscedastic probabilistic transformer-based prediction model
called Knowledge Transformer with Uncertainty (KTU) to explicitly quantify
prediction uncertainty, which is essential for robust decision-making in the
stochastic environment of P2P energy trading. The KTU model leverages
domain-specific features and is trained with a custom loss function that
ensures reliable probabilistic forecasts and confidence intervals for each
prediction. Integrating these uncertainty-aware forecasts into the MARL
framework enables agents to optimize trading strategies with a clear
understanding of risk and variability. Experimental results show that the
uncertainty-aware Deep Q-Network (DQN) reduces energy purchase costs by up to
5.7% without P2P trading and 3.2% with P2P trading, while increasing
electricity sales revenue by 6.4% and 44.7%, respectively. Additionally, peak
hour grid demand is reduced by 38.8% without P2P and 45.6% with P2P. These
improvements are even more pronounced when P2P trading is enabled, highlighting
the synergy between advanced forecasting and market mechanisms for resilient,
economically efficient energy communities.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [45] [Byzantine-Resilient Distributed Computation via Task Replication and Local Computations](https://arxiv.org/abs/2507.16014)
*Aayush Rajesh,Nikhil Karamchandani,Vinod M. Prabhakaran*

Main category: cs.IT

TL;DR: 研究在存在拜占庭工作节点的分布式计算问题，中心节点通过工作节点复制计算和少量本地计算来解决独立子任务，提出了在无通信约束下使用最优本地计算数量的协议，并改进了通信效率。


<details>
  <summary>Details</summary>
Motivation: 在分布式计算环境中，当存在拜占庭故障工作节点时，需要设计可靠的协议来确保所有独立子任务都能被正确解决，同时最小化昂贵的本地计算开销。

Method: 提出了一种基于平衡作业分配的协议，通过在工作节点间复制分配子任务计算，结合少量本地计算来解决问题。针对循环分配提供了封闭形式的性能结果，并提出协议改进版本以提高通信效率。

Result: 在无通信约束条件下，协议能够使用最优数量的本地计算成功解决所有子任务。对于循环分配给出了封闭形式的性能分析结果。改进版本在不增加本地计算量的前提下提高了通信效率。

Conclusion: 提出的协议在拜占庭工作节点环境下实现了分布式计算的可靠性，达到了本地计算的最优性，并通过改进版本在保持计算效率的同时提升了通信性能。

Abstract: We study a distributed computation problem in the presence of Byzantine
workers where a central node wishes to solve a task that is divided into
independent sub-tasks, each of which needs to be solved correctly. The
distributed computation is achieved by allocating the sub-task computation
across workers with replication, as well as solving a small number of sub-tasks
locally, which we wish to minimize due to it being expensive. For a general
balanced job allocation, we propose a protocol that successfully solves for all
sub-tasks using an optimal number of local computations under no communication
constraints. Closed-form performance results are presented for cyclic
allocations. Furthermore, we propose a modification to this protocol to improve
communication efficiency without compromising on the amount of local
computation.

</details>


### [46] [Constructions and List Decoding of Sum-Rank Metric Codes Based on Orthogonal Spaces over Finite Fields](https://arxiv.org/abs/2507.16377)
*Xuemei Liu,Jiarong Zhang,Gang Wang*

Main category: cs.IT

TL;DR: 本研究基于有限域上的正交空间构造和-秩度量码，并计算不同解码算法的列表大小，提出了两种构造方法并改进了解码成功率。


<details>
  <summary>Details</summary>
Motivation: 和-秩度量码作为汉明码和秩度量码的推广，在多发线性网络编码、空时编码和分布式存储系统等领域具有重要应用，因此需要研究其构造方法和解码算法。

Method: 基于有限域上原始多项式的伴随矩阵构造阶为q^n-1的循环正交群和阶为(q^n-1)^2的阿贝尔非循环正交群；通过选择不同的子空间生成矩阵构造最大秩距离(MRD)码；提出两种构造和-秩度量码的方法；使用[n,k,d]系统将和-秩度量码与子空间设计相关联。

Result: 成功构造了参数为(n×2n, q^2n, n)_q和(n×4n, q^4n, n)_q的MRD码；计算了列表解码算法下的列表大小；基于子空间设计的计算方法相比传统方法提高了解码成功率。

Conclusion: 本研究成功构造了基于正交空间的和-秩度量码，提出的构造方法和解码算法计算方式在提高解码成功率方面表现出优势，为相关应用领域提供了理论基础。

Abstract: Sum-rank metric codes, as a generalization of Hamming codes and rank metric
codes, have important applications in fields such as multi-shot linear network
coding, space-time coding and distributed storage systems. The purpose of this
study is to construct sum-rank metric codes based on orthogonal spaces over
finite fields, and calculate the list sizes outputted by different decoding
algorithms. The following achievements have been obtained.
  In this study, we construct a cyclic orthogonal group of order $q^n-1$ and an
Abelian non-cyclic orthogonal group of order $(q^n-1)^2$ based on the companion
matrices of primitive polynomials over finite fields. By selecting different
subspace generating matrices, maximum rank distance (MRD) codes with parameters
$(n \times {2n}, q^{2n}, n)_q$ and $(n \times {4n}, q^{4n}, n)_q$ are
constructed respectively. Two methods for constructing sum-rank metric codes
are proposed for the constructed MRD codes, and the list sizes outputted under
the list decoding algorithm are calculated. Subsequently, the
$[{\bf{n}},k,d]_{{q^n}/q}$-system is used to relate sum-rank metric codes to
subspace designs. The list size of sum-rank metric codes under the list
decoding algorithm is calculated based on subspace designs. This calculation
method improves the decoding success rate compared with traditional methods.

</details>


### [47] [Typicality with Feedback](https://arxiv.org/abs/2507.16384)
*Thomas Sturma,Michèle Wigger*

Main category: cs.IT

TL;DR: 该论文分析了发射机在离散无记忆信道中基于反馈信号自适应调整输入的闭环系统，证明了无论发射机采用何种策略，输出的条件类型都接近信道转移律，并将此结果应用于集成感知与通信系统，证明在特定条件下闭环系统的基本限制与开环系统相同。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对闭环反馈系统中发射机自适应策略影响的深入理论分析，特别是在集成感知与通信（ISAC）系统中，需要理解自适应输入对系统基本性能限制的影响。

Method: 通过数学分析证明在离散无记忆信道中，给定输入的输出条件类型始终接近信道转移律P_{Y|X}，然后将此一般性结果应用于ISAC模型的逆定理证明中。

Result: 证明了在闭环反馈系统中，输出的条件类型保持接近DMC转移律；在ISAC系统应用中，当允许平均解码错误概率ε和允许超额失真概率δ满足δ+ε<1时，闭环系统的基本限制与开环系统相同。

Conclusion: 反馈自适应输入并不能改善某些通信系统的基本性能限制，特别是在ISAC系统中，只要错误概率和失真概率之和小于1，闭环和开环系统具有相同的基本限制。

Abstract: The main objective of this paper is to analyze a closed-loop feedback system
where a transmitter probes a discrete memoryless channel (DMC) and can adapt
its inputs based on the previous channel outputs. We prove that, regardless of
the transmitter's strategy, the conditional type of the outputs given the
inputs remains close to the DMC transition law $P_{Y|X}$. This general result
enables the study of fundamental limits in certain adaptive systems.
  As an application, we establish a converse result for an integrated sensing
and communication (ISAC) model. In this setting, the transmitter also functions
as a radar receiver, aiming to simultaneously transmit a message over the
channel and estimate the channel state from the backscattered feedback signals.
We show that the fundamental limits of the closed loop system are the same as
of the open-loop system where the transmitter can use the feedback signal to
estimate the state but not to produce adaptive channel inputs. This result
holds as long as the sum of the admissible-average-decoding-error-probability,
denoted $\epsilon$, and the admissible-excess-distortion-probability, denoted
$\delta$, is below $1$, i.e., $\delta +\epsilon < 1$.

</details>


### [48] [Active RISs: Modeling and Optimization](https://arxiv.org/abs/2507.16499)
*Recep Akif Tasci,Panagiotis Gavriilidis,Ertugrul Basar,George C. Alexandropoulos*

Main category: cs.IT

TL;DR: 该论文研究了主动可重构智能表面(Active RIS)技术，提出了两种硬件设计方案来克服传统被动RIS的双路径损耗问题，通过理论建模、性能分析和优化框架，证明主动RIS能够有效提升无线通信系统性能。


<details>
  <summary>Details</summary>
Motivation: 传统可重构智能表面(RIS)受到双路径损耗效应的根本限制，严重衰减反射信号，需要开发能够放大入射信号的主动RIS架构来克服这一限制。

Method: 提出两种主动RIS硬件设计：1）基于单功率放大器的双RIS结构；2）在单元级使用隧道二极管的反射放大结构。建立综合数学模型，推导闭式表达式，提出相移和放大器增益的优化框架，并分析隧道二极管的I-V特性和反射系数的相位-幅度耦合特性。

Result: 推导出接收信噪比、误码率概率和能效的闭式表达式；建立了功率约束下系统容量最大化的优化框架；分析了隧道二极管的负阻范围和功耗模型；通过紧凑线性代数公式表征了反射系数的相位-幅度耦合；数值仿真验证了理论分析的正确性。

Conclusion: 主动RIS能够有效克服双路径损耗限制，与被动RIS相比实现更好的能效权衡。研究发现更多的主动元件数量并不总是带来最优性能，需要在可用功率预算和主动元件数量之间进行权衡。

Abstract: Reconfigurable Intelligent Surfaces (RIS)-empowered communication has emerged
as a transformative technology for next generation wireless networks, enabling
the programmable shaping of the propagation environment. However, conventional
RISs are fundamentally limited by the double path loss effect, which severely
attenuates the reflected signals. To overcome this, active RIS architectures,
capable of amplifying impinging signals, have been proposed. This chapter
investigates the modeling, performance analysis, and optimization of active
RISs, focusing on two hardware designs: a dual-RIS structure with a single
Power Amplifier (PA), and a reflection amplification structure at the unit cell
level using tunnel diodes. For the PA-based design, a comprehensive
mathematical model is developed, and closed-form expressions for the received
signal-to-noise ratio, bit error probability, and Energy Efficiency (EE) are
derived. An optimization framework for configuring the phase shifts and
amplifier gain is proposed to maximize system capacity under power constraints.
Regarding the second design, the integration of a tunnel diode into the unit
cell is carefully studied by analyzing its I-V characteristic, enabling the
derivation of the negative resistance range and the power consumption model.
Furthermore, the intrinsic phase-amplitude coupling of the reflection
coefficient is characterized through compact linear algebra formulations,
enabling practical optimization of active RISs. Extensive numerical simulations
validate the theoretical analyses, demonstrating that active RISs can
effectively overcome the double path loss limitation and achieve favorable EE
trade-offs compared to passive RISs. Finally, the trade-off between the
available power budget and the number of active elements is examined, revealing
that a higher number of active elements does not always lead to optimal
performance.

</details>


### [49] [A Robust 5G Terrestrial Positioning System with Sensor Fusion in GNSS-denied Scenarios](https://arxiv.org/abs/2507.16600)
*Hamed Talebian,Nazrul Mohamed Nazeer,Darius Chmieliauskas,Jakub Nikonowicz,Mehdi Haghshenas,Łukasz Matuszewski,Mairo Leier,Aamir Mahmood*

Main category: cs.IT

TL;DR: 本文提出了一种基于5G基础设施的地面定位系统，作为GNSS的可行替代方案，通过载波相位测距结合三边测量实现定位，在KITTI数据集上达到了小于5米的定位精度


<details>
  <summary>Details</summary>
Motivation: 在GNSS信号被遮挡或不可用的场景下，需要一种可靠的替代定位解决方案。传统地面网络主要专注于通信服务而非定位服务，因此需要设计专门优化定位性能的网络规划和定位系统

Method: 提出基于5G基础设施的地面定位系统，采用多载波载波相位(CP)测距方法消除整数模糊度估计需求；开发深度学习模型识别和排除非视距(NLOS)链路；在视距受阻情况下，使用误差状态扩展卡尔曼滤波器融合IMU和相机等传感器数据实现鲁棒跟踪

Result: 在真实世界KITTI数据集上进行评估，该系统在城市环境中移动车辆场景下实现了小于5米的定位误差，性能可与商用GNSS服务相媲美

Conclusion: 所提出的基于5G的地面定位系统在GNSS受限环境中展现出作为弹性且准确定位解决方案的巨大潜力，能够有效解决载波相位定位中的关键技术挑战，为GNSS拒止环境提供了可靠的定位替代方案

Abstract: This paper presents a terrestrial localization system based on 5G
infrastructure as a viable alternative to GNSS, particularly in scenarios where
GNSS signals are obstructed or unavailable. It discusses network planning aimed
at enabling positioning as a primary service, in contrast to the traditional
focus on communication services in terrestrial networks. Building on a network
infrastructure optimized for positioning, the paper proposes a system that
leverages carrier phase (CP) ranging in combination with trilateration to
localize the user within the network when at least three base stations (BSs)
provide line-of-sight (LOS) conditions. Achieving accurate CP-based positioning
requires addressing three key challenges: integer ambiguity resolution,
LOS/NLOS link identification, and localization under obstructed LOS conditions.
To this end, the system employs a multi-carrier CP approach, which eliminates
the need for explicit integer ambiguity estimation. Additionally, a deep
learning model is developed to identify NLOS links and exclude them from the
trilateration process. In cases where LOS is obstructed and CP ranging becomes
unreliable, the system incorporates an error-state extended Kalman filter to
fuse complementary data from other sensors, such as inertial measurement units
(IMUs) and cameras. This hybrid approach enables robust tracking of moving
users across diverse channel conditions. The performance of the proposed
terrestrial positioning system is evaluated using the real-world KITTI dataset,
featuring a moving vehicle in an urban environment. Simulation results show
that the system can achieve a positioning error of less than 5 meters in the
KITTI urban scenario--comparable to that of public commercial GNSS
services--highlighting its potential as a resilient and accurate solution for
GNSS-denied environments.

</details>


### [50] [Reconfigurable Intelligent Surface-Enabled Green and Secure Offloading for Mobile Edge Computing Networks](https://arxiv.org/abs/2507.16666)
*Tong-Xing Zheng,Xinji Wang,Xin Chen,Di Mao,Jia Shi,Cunhua Pan,Chongwen Huang,Haiyang Ding,Zan Li*

Main category: cs.IT

TL;DR: 该论文研究了在智能反射面(RIS)辅助下的多用户上行移动边缘计算网络中的安全任务卸载问题，提出了一种基于块坐标下降的优化框架来最小化总能耗，实验表明RIS可以节省高达60%的能耗。


<details>
  <summary>Details</summary>
Motivation: 在多用户移动边缘计算网络中，用户需要在多天线窃听者存在的情况下安全地卸载部分任务到接入点，现有方案缺乏有效的安全保障和能耗优化机制，因此需要研究如何利用智能反射面技术实现安全高效的任务卸载。

Method: 提出了基于块坐标下降的优化框架，迭代优化用户的本地计算比特数和传输功率、RIS相移以及接入点的多用户检测矩阵。针对完美信道状态信息情况采用连续凸近似、半定规划和半定松弛技术；针对不完美信道状态信息情况采用S-procedure和惩罚凸凹方法实现鲁棒设计。

Result: 数值结果验证了所提算法的收敛性和有效性。与没有RIS的情况相比，部署精心设计的RIS可以节省高达60%的能耗。研究还揭示了RIS元素数量和部署位置、用户数量、任务规模和持续时间以及信道状态信息不完美性等关键因素对安全能效的影响。

Conclusion: 智能反射面在实现安全高效的移动边缘计算网络中发挥重要作用，所提出的优化算法能够有效最小化系统总能耗同时保证安全卸载要求，为RIS辅助的MEC网络设计提供了理论基础和实用方案。

Abstract: This paper investigates a multi-user uplink mobile edge computing (MEC)
network, where the users offload partial tasks securely to an access point
under the non-orthogonal multiple access policy with the aid of a
reconfigurable intelligent surface (RIS) against a multi-antenna eavesdropper.
We formulate a non-convex optimization problem of minimizing the total energy
consumption subject to secure offloading requirement, and we build an efficient
block coordinate descent framework to iteratively optimize the number of local
computation bits and transmit power at the users, the RIS phase shifts, and the
multi-user detection matrix at the access point. Specifically, we successively
adopt successive convex approximation, semi-definite programming, and
semidefinite relaxation to solve the problem with perfect eavesdropper's
channel state information (CSI), and we then employ S-procedure and penalty
convex-concave to achieve robust design for the imperfect CSI case. We provide
extensive numerical results to validate the convergence and effectiveness of
the proposed algorithms. We demonstrate that RIS plays a significant role in
realizing a secure and energy-efficient MEC network, and deploying a
well-designed RIS can save energy consumption by up to 60\% compared to that
without RIS. We further reveal impacts of various key factors on the secrecy
energy efficiency, including RIS element number and deployment position, user
number, task scale and duration, and CSI imperfection.

</details>


### [51] [Error Detection Based on Generalized Successive Cancellation List Decoding for Polar Codes](https://arxiv.org/abs/2507.16699)
*Alexander Sauter,Mustafa Cemil Coşkun,Gianluigi Liva*

Main category: cs.IT

TL;DR: 本文提出了一种改进的极化码连续消除列表(SCL)解码方法，当列表大小为2^γ时（γ为混合因子），可以实现Forney的广义解码规则，从而有效丢弃不可靠的解码决策，并通过蒙特卡罗仿真验证了短极化码的性能提升。


<details>
  <summary>Details</summary>
Motivation: 虽然SCL解码在足够大的列表大小下能够实现接近最大似然的性能，但仍需要一种更有效的方法来处理不可靠的解码决策，以进一步提升极化码的解码性能。

Method: 提出了一种修改的SCL解码方法，当列表大小设置为2^γ（其中γ是混合因子这一基本量）时，该方法能够实现Forney的广义解码规则，从而提供一种有效的手段来丢弃不可靠的解码决策。

Result: 通过蒙特卡罗仿真分析了短极化码在所提出的广义SCL解码下的性能表现，验证了该方法的有效性。

Conclusion: 所提出的广义SCL解码方法能够在特定列表大小条件下实现Forney的广义解码规则，为极化码解码提供了一种新的性能提升途径，特别是在处理短极化码时表现出良好的效果。

Abstract: Successive cancellation list (SCL) decoding has been widely adopted for polar
codes, which allows near maximum likelihood performance with sufficiently large
list size. In this work, we show that, if the list size is $2^\gamma$, where
$\gamma$ is the fundamental quantity called mixing factor, then a modification
to SCL decoding can implement Forney's generalized decoding rule. Hence, it
provides an efficient means to discard unreliable decisions. The performance
achieved by short polar codes under the proposed generalized SCL decoding is
analyzed via Monte Carlo simulations.

</details>


### [52] [Multi-RIS-Empowered Communication Systems: Capacity Analysis and Optimization](https://arxiv.org/abs/2507.16767)
*Aris L. Moustakas,George C. Alexandropoulos*

Main category: cs.IT

TL;DR: 本文使用统计物理方法，为多天线收发器在多个可重构智能表面（RIS）环境中的互信息推导出渐近闭式表达式，并提出了无需暴力数值优化的RIS优化方法


<details>
  <summary>Details</summary>
Motivation: 在快衰落条件下，信道估计变得困难，需要开发有效的方法来分析和优化多RIS辅助的多天线通信系统的性能，特别是在大系统极限下的互信息特性

Method: 采用统计物理方法推导多天线收发器在多RIS环境中互信息的均值和方差的渐近闭式表达式；利用RIS处入射和出射信号相关矩阵的渐近特性进行统计优化，避免暴力数值优化

Result: 推导出的高斯近似在适度规模的天线阵列和超表面下仍然准确；当RIS附近信道相关时（如小角度扩展），统计RIS优化带来的增益显著高于近似不相关情况；即使RIS的期望反射显著偏离几何光学，超表面仍可优化以提供鲁棒通信链路

Conclusion: 该研究表明，通过统计物理方法可以有效分析和优化多RIS辅助的多天线系统，在相关信道条件下能够获得显著的性能增益，且无需复杂的数值优化或精确的RIS位置放置

Abstract: In this chapter, using statistical physics methods, asymptotic closed-form
expressions for the mean and variance of the mutual information for a
multi-antenna transmitter-receiver pair in the presence of multiple
Reconfigurable Intelligent Surfaces (RISs) are presented. While nominally valid
in the large-system limit, it is shown that the derived Gaussian approximation
for the mutual information can be quite accurate, even for modest-sized antenna
arrays and metasurfaces. The above results are particularly useful when
fast-fading conditions are present, which renders channel estimation
challenging. The derived analysis indicates that, when the channel close to an
RIS is correlated, for instance due to small angle spread which is reasonable
for wireless systems with increasing carrier frequencies, the communication
link benefits significantly from statistical RIS optimization, resulting in
gains that are surprisingly higher than the nearly uncorrelated case. More
importantly, the presented novel asymptotic properties of the correlation
matrices of the impinging and outgoing signals at the RISs can be deployed to
optimize the metasurfaces without brute-force numerical optimization. The
numerical investigation demonstrates that, when the desired reflection from any
of the RISs departs significantly from geometrical optics, the metasurfaces can
be optimized to provide robust communication links, without significant need
for their optimal placement.

</details>
