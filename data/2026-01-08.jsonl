{"id": "2601.03593", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.03593", "abs": "https://arxiv.org/abs/2601.03593", "authors": ["Kevin Zhao", "Chenning Li", "Anton A. Zabreyko", "Arash Nasr-Esfahany", "Anna Goncharenko", "David Dai", "Sidharth Lakshmanan", "Claire Li", "Mohammad Alizadeh", "Thomas E. Anderson"], "title": "Prediction-Guided Control in Data Center Networks", "comment": null, "summary": "In this paper, we design, implement, and evaluate Polyphony, a system to give network operators a new way to control and reduce the frequency of poor tail latency events in multi-class data center networks, on the time scale of minutes. Polyphony is designed to be complementary to other adaptive mechanisms like congestion control and traffic engineering, but targets different aspects of network operation that have previously been considered static. By contrast to Polyphony, prior model-free optimization methods work best when there are only a few relevant degrees of freedom and where workloads and measurements are stable, assumptions not present in modern data center networks.\n  Polyphony develops novel methods for measuring, predicting, and controlling network quality of service metrics for a dynamically changing workload. First, we monitor and aggregate workloads on a network-wide basis; we use the result as input to an approximate counterfactual prediction engine that estimates the effect of potential network configuration changes on network quality of service; we apply the best candidate and repeat in a closed-loop manner aimed at rapidly and stably converging to a configuration that meets operator goals. Using CloudLab on a simple topology, we observe that Polyphony converges to tight SLOs within ten minutes, and re-stabilizes after large workload shifts within fifteen minutes, while the prior state of the art fails to adapt."}
{"id": "2601.03757", "categories": ["cs.NI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2601.03757", "abs": "https://arxiv.org/abs/2601.03757", "authors": ["Nguyen Cong Luong", "Zeping Sui", "Duc Van Le", "Jie Cao", "Bo Ma", "Nguyen Duc Hai", "Ruichen Zhang", "Vu Van Quang", "Dusit Niyato", "Shaohan Feng"], "title": "Incentive Mechanism Design for Resource Management in Satellite Networks: A Comprehensive Survey", "comment": "28 pages, 8 figures, accepted by IEEE IoTJ", "summary": "Resource management is one of the challenges in satellite networks due to their high mobility, wide coverage, long propagation distances, and stringent constraints on energy, communication, and computation resources. Traditional resource allocation approaches rely only on hard and rigid system performance metrics. Meanwhile, incentive mechanisms, which are based on game theory and auction theory, investigate systems from the \"economic\" perspective in addition to the \"system\" perspective. Particularly, incentive mechanisms are able to take into account rationality and other behavior of human users into account, which guarantees benefits/utility of all system entities, thereby improving the scalability, adaptability, and fairness in resource allocation. This paper presents a comprehensive survey of incentive mechanism design for resource management in satellite networks. The paper covers key issues in the satellite networks, such as communication resource allocation, computation offloading, privacy and security, and coordination. We conclude with future research directions including learning-based mechanism design for satellite networks."}
{"id": "2601.03917", "categories": ["cs.NI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.03917", "abs": "https://arxiv.org/abs/2601.03917", "authors": ["Jinting Liu", "Jingwei Li", "Tengfei Chang"], "title": "Monaas: Mobile Node as a Service for TSCH-based Industrial IoT Networks", "comment": null, "summary": "The Time-Slotted Channel Hopping (TSCH) mode of IEEE802.15.4 standard provides ultra high end-to-end reliability and low-power consumption for application in field of Industrial Internet of Things (IIoT). With the evolving of Industrial 4.0, dynamic and bursty tasks with varied Quality of Service (QoS); effective management and utilization of growing number of mobile equipments become two major challenges for network solutions. The existing TSCH-based networks lack of a system framework design to handle these challenges. In this paper, we propose a novel, service-oriented, and hierarchical IoT network architecture named Mobile Node as a Service (Monaas). Monaas aims to systematically manage and schedule mobile nodes as on-demand, elastic resources through a new architectural design and protocol mechanisms. Its core features include a hierarchical architecture to balance global coordination with local autonomy, task-driven scheduling for proactive resource allocation, and an on-demand mobile resource integration mechanism. The feasibility and potential of the Monaas link layer mechanisms are validated through implementation and performance evaluation on an nRF52840 hardware testbed, demonstrating its potential advantages in specific scenarios. On a physical nRF52840 testbed, Monaas consistently achieved a Task Completion Rate (TCR) above 98% for high-priority tasks under bursty traffic and link degradation, whereas all representative baselines (Static TSCH, 6TiSCH Minimal, OST, FTS-SDN) remained below 40%.Moreover, its on-demand mobile resource integration activated services in 1.2 s, at least 65% faster than SDN (3.5 s) and OST/6TiSCH (> 5.8 s)."}
{"id": "2601.03958", "categories": ["cs.NI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.03958", "abs": "https://arxiv.org/abs/2601.03958", "authors": ["Mattia Figaro", "Francesco Rossato", "Alexander Bonora", "Marco Giordani", "Giovanni Schembra", "Michele Zorzi"], "title": "Experimental Evaluation of a UAV-Mounted LEO Satellite Backhaul for Emergency Connectivity", "comment": "6 pages, 7 figures. This paper has been accepted for presentation at the 2026 International Conference on Computing, Networking and Communications (ICNC)", "summary": "Reliable connectivity is critical for Public Protection and Disaster Relief operations, especially in rural or compromised environments where terrestrial infrastructure is unavailable. In such scenarios, NTNs, and specifically UAVs, are promising candidates to provide on-demand and rapid connectivity on the ground, serving as aerial base stations. In this paper, we implement a setup in which a rotary-wing UAV, equipped with a Starlink Mini terminal, provides Internet connectivity to an emergency ground user in the absence of cellular coverage via LEO satellites. The UAV functions as a Wi-Fi access point, while backhauling the ground traffic through the Starlink constellation. We evaluate the system via both network simulations in ns-3 and real-world flight experiments in a rural environment, in terms of throughput, latency, coverage, and energy consumption under static and dynamic flight conditions. Our results demonstrate that the system can maintain a stable uplink throughput of approximately 30 Mbps up to approximately 200 meters, and with minimal impact on the UAV battery lifetime. These findings demonstrate the feasibility of deploying commercial LEO satellite terminals on UAVs as a practical solution for emergency connectivity."}
{"id": "2601.03306", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03306", "abs": "https://arxiv.org/abs/2601.03306", "authors": ["Jingbin Liu", "Xuechun Wang"], "title": "Mastering the Game of Go with Self-play Experience Replay", "comment": "13 pages, 5 figures", "summary": "The game of Go has long served as a benchmark for artificial intelligence, demanding sophisticated strategic reasoning and long-term planning. Previous approaches such as AlphaGo and its successors, have predominantly relied on model-based Monte-Carlo Tree Search (MCTS). In this work, we present QZero, a novel model-free reinforcement learning algorithm that forgoes search during training and learns a Nash equilibrium policy through self-play and off-policy experience replay. Built upon entropy-regularized Q-learning, QZero utilizes a single Q-value network to unify policy evaluation and improvement. Starting tabula rasa without human data and trained for 5 months with modest compute resources (7 GPUs), QZero achieved a performance level comparable to that of AlphaGo. This demonstrates, for the first time, the efficiency of using model-free reinforcement learning to master the game of Go, as well as the feasibility of off-policy reinforcement learning in solving large-scale and complex environments."}
{"id": "2601.03489", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.03489", "abs": "https://arxiv.org/abs/2601.03489", "authors": ["Sanjit Bhowmick"], "title": "LCPs of Subspace Codes", "comment": null, "summary": "A subspace code is a nonempty collection of subspaces of the vector space $\\mathbb{F}_q^{n}$. A pair of linear codes is called a linear complementary pair (in short LCP) of codes if their intersection is trivial and the sum of their dimensions equals the dimension of the ambient space. Equivalently, the two codes form an LCP if the direct sum of these two codes is equal to the entire space. In this paper, we introduce the concept of LCPs of subspace codes. We first provide a characterization of subspace codes that form an LCP. Furthermore, we present a sufficient condition for the existence of an LCP of subspace codes based on a complement function on a subspace code. In addition, we give several constructions of LCPs for subspace codes using various techniques and provide an application to insertion error correction."}
{"id": "2601.04042", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.04042", "abs": "https://arxiv.org/abs/2601.04042", "authors": ["Marcin Hoffmann"], "title": "Badanie Sieci Massive MIMO o Architekturze Zorientowanej na Uzytkownika", "comment": "in Polish language", "summary": "The future 6G networks are expected to utilize large antenna arrays and follow the user-centric architecture, where the user is being served by all base stations. This work evaluates such a system within an advanced system-level simulator, which utilizes an accurate 3D Ray-Tracing radio channel model. Results show that the novel user-centric network architecture can increase the cell-edge users throughput by a fold of 3."}
{"id": "2601.03335", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.03335", "abs": "https://arxiv.org/abs/2601.03335", "authors": ["Akarsh Kumar", "Ryan Bahlous-Boldi", "Prafull Sharma", "Phillip Isola", "Sebastian Risi", "Yujin Tang", "David Ha"], "title": "Digital Red Queen: Adversarial Program Evolution in Core War with LLMs", "comment": "14 pages, 13 figures", "summary": "Large language models (LLMs) are increasingly being used to evolve solutions to problems in many domains, in a process inspired by biological evolution. However, unlike biological evolution, most LLM-evolution frameworks are formulated as static optimization problems, overlooking the open-ended adversarial dynamics that characterize real-world evolutionary processes. Here, we study Digital Red Queen (DRQ), a simple self-play algorithm that embraces these so-called \"Red Queen\" dynamics via continual adaptation to a changing objective. DRQ uses an LLM to evolve assembly-like programs, called warriors, which compete against each other for control of a virtual machine in the game of Core War, a Turing-complete environment studied in artificial life and connected to cybersecurity. In each round of DRQ, the model evolves a new warrior to defeat all previous ones, producing a sequence of adapted warriors. Over many rounds, we observe that warriors become increasingly general (relative to a set of held-out human warriors). Interestingly, warriors also become less behaviorally diverse across independent runs, indicating a convergence pressure toward a general-purpose behavioral strategy, much like convergent evolution in nature. This result highlights a potential value of shifting from static objectives to dynamic Red Queen objectives. Our work positions Core War as a rich, controllable sandbox for studying adversarial adaptation in artificial systems and for evaluating LLM-based evolution methods. More broadly, the simplicity and effectiveness of DRQ suggest that similarly minimal self-play approaches could prove useful in other more practical multi-agent adversarial domains, like real-world cybersecurity or combating drug resistance."}
{"id": "2601.03492", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.03492", "abs": "https://arxiv.org/abs/2601.03492", "authors": ["Sanjit Bhowmick", "Kuntal Deka"], "title": "Hermitian LCD $2$-Quasi Abelian Codes over Finite Chain Rings", "comment": null, "summary": "This paper introduces a class of Hermitian LCD $2$-quasi-abelian codes over finite fields and presents a comprehensive enumeration of these codes in which relative minimum weights are small. We show that such codes are asymptotically good over finite fields. Furthermore, we extend our analysis to finite chain rings by characterizing $2$-quasi-abelian codes in this setting and proving the existence of asymptotically good Hermitian LCD $2$-quasi-abelian codes over finite chain rings as well."}
{"id": "2601.04083", "categories": ["cs.NI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04083", "abs": "https://arxiv.org/abs/2601.04083", "authors": ["Marvin Illian", "Ramin Khalili", "Antonio A. de A. Rocha", "Lin Wang"], "title": "Cells on Autopilot: Adaptive Cell (Re)Selection via Reinforcement Learning", "comment": "11 pages, 12 figures", "summary": "The widespread deployment of 5G networks, together with the coexistence of 4G/LTE networks, provides mobile devices a diverse set of candidate cells to connect to. However, associating mobile devices to cells to maximize overall network performance, a.k.a. cell (re)selection, remains a key challenge for mobile operators. Today, cell (re)selection parameters are typically configured manually based on operator experience and rarely adapted to dynamic network conditions. In this work, we ask: Can an agent automatically learn and adapt cell (re)selection parameters to consistently improve network performance? We present a reinforcement learning (RL)-based framework called CellPilot that adaptively tunes cell (re)selection parameters by learning spatiotemporal patterns of mobile network dynamics. Our study with real-world data demonstrates that even a lightweight RL agent can outperform conventional heuristic reconfigurations by up to 167%, while generalizing effectively across different network scenarios. These results indicate that data-driven approaches can significantly improve cell (re)selection configurations and enhance mobile network performance."}
{"id": "2601.03359", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03359", "abs": "https://arxiv.org/abs/2601.03359", "authors": ["Alberto Purpura", "Li Wang", "Sahil Badyal", "Eugenio Beaufrand", "Adam Faulkner"], "title": "Enhancing LLM Instruction Following: An Evaluation-Driven Multi-Agentic Workflow for Prompt Instructions Optimization", "comment": null, "summary": "Large Language Models (LLMs) often generate substantively relevant content but fail to adhere to formal constraints, leading to outputs that are conceptually correct but procedurally flawed. Traditional prompt refinement approaches focus on rephrasing the description of the primary task an LLM has to perform, neglecting the granular constraints that function as acceptance criteria for its response. We propose a novel multi-agentic workflow that decouples optimization of the primary task description from its constraints, using quantitative scores as feedback to iteratively rewrite and improve them. Our evaluation demonstrates this method produces revised prompts that yield significantly higher compliance scores from models like Llama 3.1 8B and Mixtral-8x 7B."}
{"id": "2601.03831", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.03831", "abs": "https://arxiv.org/abs/2601.03831", "authors": ["Matteo Nerini", "Zheyu Wu", "Shanpu Shen", "Bruno Clerckx"], "title": "Low-Complexity Planar Beyond-Diagonal RIS Architecture Design Using Graph Theory", "comment": "Submitted to IEEE for publication", "summary": "Reconfigurable intelligent surfaces (RISs) enable programmable control of the wireless propagation environment and are key enablers for future networks. Beyond-diagonal RIS (BD-RIS) architectures enhance conventional RIS by interconnecting elements through tunable impedance components, offering greater flexibility with higher circuit complexity. However, excessive interconnections between BD-RIS elements require multi-layer printed circuit board (PCB) designs, increasing fabrication difficulty. In this letter, we use graph theory to characterize the BD-RIS architectures that can be realized on double-layer PCBs, denoted as planar-connected RISs. Among the possible planar-connected RISs, we identify the ones with the most degrees of freedom, expected to achieve the best performance under practical constraints."}
{"id": "2601.04089", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.04089", "abs": "https://arxiv.org/abs/2601.04089", "authors": ["Adrian Pekar", "Richard Plny", "Karel Hynek"], "title": "Tutorial on Flow-Based Network Traffic Classification Using Machine Learning", "comment": "under review", "summary": "Modern networks carry increasingly diverse and encrypted traffic types that demand classification techniques beyond traditional port-based and payload-based methods. This tutorial provides a practical, end-to-end guide to building machine-learning-based network traffic flow classification systems. We cover the workflow from flow metering and dataset creation, through ground-truth labeling and feature engineering, to leakage-resistant experimental design, model training and evaluation, explainability, and deployment considerations. The tutorial focuses on supervised flow-based classification that remains effective under encryption and provides actionable guidance on algorithm selection, performance metrics, and realistic partitioning strategies, with emphasis on common real-world measurement artifacts and methodological pitfalls. A companion set of five Jupyter notebooks on GitHub implements the data-to-model workflow on real traffic captures, enabling readers to reproduce key steps. The intended audience includes researchers and practitioners with foundational networking knowledge who aim to design and deploy robust traffic classification systems in operational environments."}
{"id": "2601.03389", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03389", "abs": "https://arxiv.org/abs/2601.03389", "authors": ["Michael Petrowski", "Milica Gašić"], "title": "Exploration Through Introspection: A Self-Aware Reward Model", "comment": "Accepted at AAAI-26 ToM4AI Workshop", "summary": "Understanding how artificial agents model internal mental states is central to advancing Theory of Mind in AI. Evidence points to a unified system for self- and other-awareness. We explore this self-awareness by having reinforcement learning agents infer their own internal states in gridworld environments. Specifically, we introduce an introspective exploration component that is inspired by biological pain as a learning signal by utilizing a hidden Markov model to infer \"pain-belief\" from online observations. This signal is integrated into a subjective reward function to study how self-awareness affects the agent's learning abilities. Further, we use this computational framework to investigate the difference in performance between normal and chronic pain perception models. Results show that introspective agents in general significantly outperform standard baseline agents and can replicate complex human-like behaviors."}
{"id": "2601.03982", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.03982", "abs": "https://arxiv.org/abs/2601.03982", "authors": ["Haojie Gu", "Jun Zhang"], "title": "Unique Decoding of Hyperderivative Reed-Solomon Codes", "comment": null, "summary": "Error-correcting codes are combinatorial objects designed to cope with the problem of reliable transmission of information on a noisy channel. A fundamental problem in coding theory and practice is to efficiently decode the received word with errors to obtain the transmitted codeword. In this paper, we consider the decoding problem of Hyperderivative Reed-Solomon (HRS) codes with respect to the NRT metric. Specifically, we propose a Welch-Berlekamp algorithm for the unique decoding of NRT HRS codes."}
{"id": "2601.03470", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03470", "abs": "https://arxiv.org/abs/2601.03470", "authors": ["Michael C. Darling", "Alan H. Hesu", "Michael A. Mardikes", "Brian C. McGuigan", "Reed M. Milewicz"], "title": "Toward Maturity-Based Certification of Embodied AI: Quantifying Trustworthiness Through Measurement Mechanisms", "comment": "5 pages, Accepted to AAAI-26 Bridge Program B10: Making Embodied AI Reliable with Testing and Formal Verification", "summary": "We propose a maturity-based framework for certifying embodied AI systems through explicit measurement mechanisms. We argue that certifiable embodied AI requires structured assessment frameworks, quantitative scoring mechanisms, and methods for navigating multi-objective trade-offs inherent in trustworthiness evaluation. We demonstrate this approach using uncertainty quantification as an exemplar measurement mechanism and illustrate feasibility through an Uncrewed Aircraft System (UAS) detection case study."}
{"id": "2601.04011", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.04011", "abs": "https://arxiv.org/abs/2601.04011", "authors": ["Wei Shi", "Wei Xu", "Yongming Huang", "Jiacheng Yao", "Wenhao Hu", "Dongming Wang"], "title": "Flexible-Duplex Cell-Free Architecture for Secure Uplink Communications in Low-Altitude Wireless Networks", "comment": "Submitted to an IEEE Journal", "summary": "Low-altitude wireless networks (LAWNs) are expected to play a central role in future 6G infrastructures, yet uplink transmissions of uncrewed aerial vehicles (UAVs) remain vulnerable to eavesdropping due to their limited transmit power, constrained antenna resources, and highly exposed air-ground propagation conditions. To address this fundamental bottleneck, we propose a flexible-duplex cell-free (CF) architecture in which each distributed access point (AP) can dynamically operate either as a receive AP for UAV uplink collection or as a transmit AP that generates cooperative artificial noise (AN) for secrecy enhancement. Such AP-level duplex flexibility introduces an additional spatial degree of freedom that enables distributed and adaptive protection against wiretapping in LAWNs. Building upon this architecture, we formulate a max-min secrecy-rate problem that jointly optimizes AP mode selection, receive combining, and AN covariance design. This tightly coupled and nonconvex optimization is tackled by first deriving the optimal receive combiners in closed form, followed by developing a penalty dual decomposition (PDD) algorithm with guaranteed convergence to a stationary solution. To further reduce computational burden, we propose a low-complexity sequential scheme that determines AP modes via a heuristic metric and then updates the AN covariance matrices through closed-form iterations embedded in the PDD framework. Simulation results show that the proposed flexible-duplex architecture yields substantial secrecy-rate gains over CF systems with fixed AP roles. The joint optimization method attains the highest secrecy performance, while the low-complexity approach achieves over 90% of the optimal performance with an order-of-magnitude lower computational complexity, offering a practical solution for secure uplink communications in LAWNs."}
{"id": "2601.03475", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03475", "abs": "https://arxiv.org/abs/2601.03475", "authors": ["Ruiqi Deng", "Geoffrey Martin", "Tony Wang", "Gongbo Zhang", "Yi Liu", "Chunhua Weng", "Yanshan Wang", "Justin F Rousseau", "Yifan Peng"], "title": "CPGPrompt: Translating Clinical Guidelines into LLM-Executable Decision Support", "comment": null, "summary": "Clinical practice guidelines (CPGs) provide evidence-based recommendations for patient care; however, integrating them into Artificial Intelligence (AI) remains challenging. Previous approaches, such as rule-based systems, face significant limitations, including poor interpretability, inconsistent adherence to guidelines, and narrow domain applicability. To address this, we develop and validate CPGPrompt, an auto-prompting system that converts narrative clinical guidelines into large language models (LLMs).\n  Our framework translates CPGs into structured decision trees and utilizes an LLM to dynamically navigate them for patient case evaluation. Synthetic vignettes were generated across three domains (headache, lower back pain, and prostate cancer) and distributed into four categories to test different decision scenarios. System performance was assessed on both binary specialty-referral decisions and fine-grained pathway-classification tasks.\n  The binary specialty referral classification achieved consistently strong performance across all domains (F1: 0.85-1.00), with high recall (1.00 $\\pm$ 0.00). In contrast, multi-class pathway assignment showed reduced performance, with domain-specific variations: headache (F1: 0.47), lower back pain (F1: 0.72), and prostate cancer (F1: 0.77). Domain-specific performance differences reflected the structure of each guideline. The headache guideline highlighted challenges with negation handling. The lower back pain guideline required temporal reasoning. In contrast, prostate cancer pathways benefited from quantifiable laboratory tests, resulting in more reliable decision-making."}
{"id": "2601.04041", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.04041", "abs": "https://arxiv.org/abs/2601.04041", "authors": ["Avital Boruchovsky", "Anina Gruica", "Jonathan Niemann", "Eitan Yaakobi"], "title": "Serving Every Symbol: All-Symbol PIR and Batch Codes", "comment": null, "summary": "A $t$-all-symbol PIR code and a $t$-all-symbol batch code of dimension $k$ consist of $n$ servers storing linear combinations of $k$ linearly independent information symbols with the following recovery property: any symbol stored by a server can be recovered from $t$ pairwise disjoint subsets of servers. In the batch setting, we further require that any multiset of size $t$ of stored symbols can be recovered from $t$ disjoint subsets of servers. This framework unifies and extends several well-known code families, including one-step majority-logic decodable codes, (functional) PIR codes, and (functional) batch codes.\n  In this paper, we determine the minimum code length for some small values of $k$ and $t$, characterize structural properties of codes attaining this optimum, and derive bounds that show the trade-offs between length, dimension, minimum distance, and $t$. In addition, we study MDS codes and the simplex code, demonstrating how these classical families fit within our framework, and establish new cases of an open conjecture from \\cite{YAAKOBI2020} concerning the minimal $t$ for which the simplex code is a $t$-functional batch code."}
{"id": "2601.03482", "categories": ["cs.AI", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.03482", "abs": "https://arxiv.org/abs/2601.03482", "authors": ["Stefan Konigorski", "Johannes E. Vedder", "Babajide Alamu Owoyele", "İbrahim Özkan"], "title": "Personalization of Large Foundation Models for Health Interventions", "comment": "Accepted to the AAAI 2026 Workshop on Personalization in the Era of Large Foundation Models (PerFM)", "summary": "Large foundation models (LFMs) transform healthcare AI in prevention, diagnostics, and treatment. However, whether LFMs can provide truly personalized treatment recommendations remains an open question. Recent research has revealed multiple challenges for personalization, including the fundamental generalizability paradox: models achieving high accuracy in one clinical study perform at chance level in others, demonstrating that personalization and external validity exist in tension. This exemplifies broader contradictions in AI-driven healthcare: the privacy-performance paradox, scale-specificity paradox, and the automation-empathy paradox. As another challenge, the degree of causal understanding required for personalized recommendations, as opposed to mere predictive capacities of LFMs, remains an open question. N-of-1 trials -- crossover self-experiments and the gold standard for individual causal inference in personalized medicine -- resolve these tensions by providing within-person causal evidence while preserving privacy through local experimentation. Despite their impressive capabilities, this paper argues that LFMs cannot replace N-of-1 trials. We argue that LFMs and N-of-1 trials are complementary: LFMs excel at rapid hypothesis generation from population patterns using multimodal data, while N-of-1 trials excel at causal validation for a given individual. We propose a hybrid framework that combines the strengths of both to enable personalization and navigate the identified paradoxes: LFMs generate ranked intervention candidates with uncertainty estimates, which trigger subsequent N-of-1 trials. Clarifying the boundary between prediction and causation and explicitly addressing the paradoxical tensions are essential for responsible AI integration in personalized medicine."}
{"id": "2601.04166", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.04166", "abs": "https://arxiv.org/abs/2601.04166", "authors": ["Christian Forsch", "Laura Cottatellucci"], "title": "Expectation Propagation for Distributed Inference in Grant-Free Cell-Free Massive MIMO", "comment": "13 pages, 5 figures, submitted for possible journal publication", "summary": "Grant-free cell-free massive multiple-input multiple-output (GF-CF-MaMIMO) systems are anticipated to be a key enabling technology for next-generation Internet-of-Things (IoT) networks, as they support massive connectivity without explicit scheduling. However, the large amount of connected devices prevents the use of orthogonal pilot sequences, resulting in severe pilot contamination (PC) that degrades channel estimation and data detection performance. Furthermore, scalable GF-CF-MaMIMO networks inherently rely on distributed signal processing. In this work, we consider the uplink of a GF-CF-MaMIMO system and propose two novel distributed algorithms for joint activity detection, channel estimation, and data detection (JACD) based on expectation propagation (EP). The first algorithm, denoted as JACD-EP, uses Gaussian approximations for the channel variables, whereas the second, referred to as JACD-EP-BG, models them as Bernoulli-Gaussian (BG) random variables. To integrate the BG distribution into the EP framework, we derive its exponential family representation and develop the two algorithms as efficient message passing over a factor graph constructed from the a posteriori probability (APP) distribution. The proposed framework is inherently scalable with respect to both the number of access points (APs) and user equipments (UEs). Simulation results show the efficient mitigation of PC by the proposed distributed algorithms and their superior detection accuracy compared to (genie-aided) centralized linear detectors."}
{"id": "2601.03509", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.03509", "abs": "https://arxiv.org/abs/2601.03509", "authors": ["Haochen Shi", "Xingdi Yuan", "Bang Liu"], "title": "Evolving Programmatic Skill Networks", "comment": null, "summary": "We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault localization over skill compositions, (2) progressive optimization with maturity-aware update gating that stabilizes reliable skills while maintaining plasticity for uncertain ones, and (3) canonical structural refactoring under rollback validation that maintains network compactness. We further show that PSN's learning dynamics exhibit structural parallels to neural network training. Experiments on MineDojo and Crafter demonstrate robust skill reuse, rapid adaptation, and strong generalization across open-ended task distributions.\\footnote{We plan to open-source the code."}
{"id": "2601.04193", "categories": ["cs.IT", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.04193", "abs": "https://arxiv.org/abs/2601.04193", "authors": ["Kieran Morris", "Oliver Johnson"], "title": "A discrete Benamou-Brenier formulation of Optimal Transport on graphs", "comment": null, "summary": "We propose a discrete transport equation on graphs which connects distributions on both vertices and edges. We then derive a discrete analogue of the Benamou-Brenier formulation for Wasserstein-$1$ distance on a graph and as a result classify all $W_1$ geodesics on graphs."}
{"id": "2601.03523", "categories": ["cs.AI", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.03523", "abs": "https://arxiv.org/abs/2601.03523", "authors": ["Kengo Nakamura", "Masaaki Nishino", "Norihito Yasuda"], "title": "Variance Computation for Weighted Model Counting with Knowledge Compilation Approach", "comment": "25 pages; accepted for AAAI 2026 main track", "summary": "One of the most important queries in knowledge compilation is weighted model counting (WMC), which has been applied to probabilistic inference on various models, such as Bayesian networks. In practical situations on inference tasks, the model's parameters have uncertainty because they are often learned from data, and thus we want to compute the degree of uncertainty in the inference outcome. One possible approach is to regard the inference outcome as a random variable by introducing distributions for the parameters and evaluate the variance of the outcome. Unfortunately, the tractability of computing such a variance is hardly known. Motivated by this, we consider the problem of computing the variance of WMC and investigate this problem's tractability. First, we derive a polynomial time algorithm to evaluate the WMC variance when the input is given as a structured d-DNNF. Second, we prove the hardness of this problem for structured DNNFs, d-DNNFs, and FBDDs, which is intriguing because the latter two allow polynomial time WMC algorithms. Finally, we show an application that measures the uncertainty in the inference of Bayesian networks. We empirically show that our algorithm can evaluate the variance of the marginal probability on real-world Bayesian networks and analyze the impact of the variances of parameters on the variance of the marginal."}
{"id": "2601.03537", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03537", "abs": "https://arxiv.org/abs/2601.03537", "authors": ["Di Wu", "Yanyan Zhao", "Xin Lu", "Mingzhe Li", "Bing Qin"], "title": "STAR-S: Improving Safety Alignment through Self-Taught Reasoning on Safety Rules", "comment": "19 pages,4 figures", "summary": "Defending against jailbreak attacks is crucial for the safe deployment of Large Language Models (LLMs). Recent research has attempted to improve safety by training models to reason over safety rules before responding. However, a key issue lies in determining what form of safety reasoning effectively defends against jailbreak attacks, which is difficult to explicitly design or directly obtain. To address this, we propose \\textbf{STAR-S} (\\textbf{S}elf-\\textbf{TA}ught \\textbf{R}easoning based on \\textbf{S}afety rules), a framework that integrates the learning of safety rule reasoning into a self-taught loop. The core of STAR-S involves eliciting reasoning and reflection guided by safety rules, then leveraging fine-tuning to enhance safety reasoning. Repeating this process creates a synergistic cycle. Improvements in the model's reasoning and interpretation of safety rules allow it to produce better reasoning data under safety rule prompts, which is then utilized for further training. Experiments show that STAR-S effectively defends against jailbreak attacks, outperforming baselines. Code is available at: https://github.com/pikepokenew/STAR_S.git."}
{"id": "2601.03550", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03550", "abs": "https://arxiv.org/abs/2601.03550", "authors": ["Zhizhang Fu", "Yuancheng Gu", "Chenkai Hu", "Hanmeng Liu", "Yue Zhang"], "title": "ReEfBench: Quantifying the Reasoning Efficiency of LLMs", "comment": null, "summary": "Test-time scaling has enabled Large Language Models (LLMs) to tackle complex reasoning, yet the limitations of current Chain-of-Thought (CoT) evaluation obscures whether performance gains stem from genuine reasoning or mere verbosity. To address this, (1) we propose a novel neuro-symbolic framework for the non-intrusive, comprehensive process-centric evaluation of reasoning. (2) Through this lens, we identify four distinct behavioral prototypes and diagnose the failure modes. (3) We examine the impact of inference mode, training strategy, and model scale. Our analysis reveals that extended token generation is not a prerequisite for deep reasoning. Furthermore, we reveal critical constraints: mixing long and short CoT data in training risks in premature saturation and collapse, while distillation into smaller models captures behavioral length but fails to replicate logical efficacy due to intrinsic capacity limits."}
{"id": "2601.03555", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03555", "abs": "https://arxiv.org/abs/2601.03555", "authors": ["Yuxuan Jiang", "Francis Ferraro"], "title": "SCRIBE: Structured Mid-Level Supervision for Tool-Using Language Models", "comment": null, "summary": "Training reliable tool-augmented agents remains a significant challenge, largely due to the difficulty of credit assignment in multi-step reasoning. While process-level reward models offer a promising direction, existing LLM-based judges often produce noisy and inconsistent signals because they lack fine-grained, task-specific rubrics to distinguish high-level planning from low-level execution. In this work, we introduce SCRIBE (Skill-Conditioned Reward with Intermediate Behavioral Evaluation), a reinforcement learning framework that intervenes at a novel mid-level abstraction. SCRIBE grounds reward modeling in a curated library of skill prototypes, transforming open-ended LLM evaluation into a constrained verification problem. By routing each subgoal to a corresponding prototype, the reward model is equipped with precise, structured rubrics that substantially reduce reward variance.\n  Experimental results show that SCRIBE achieves state-of-the-art performance across a range of reasoning and tool-use benchmarks. In particular, it improves the AIME25 accuracy of a Qwen3-4B model from 43.3% to 63.3%, and significantly increases success rates in complex multi-turn tool interactions.\n  Further analysis of training dynamics reveals a co-evolution across abstraction levels, where mastery of mid-level skills consistently precedes the emergence of effective high-level planning behaviors. Finally, we demonstrate that SCRIBE is additive to low-level tool optimizations, providing a scalable and complementary pathway toward more autonomous and reliable tool-using agents."}
{"id": "2601.03595", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03595", "abs": "https://arxiv.org/abs/2601.03595", "authors": ["Yi Fang", "Wenjie Wang", "Mingfeng Xue", "Boyi Deng", "Fengli Xu", "Dayiheng Liu", "Fuli Feng"], "title": "Controllable LLM Reasoning via Sparse Autoencoder-Based Steering", "comment": "Under Review", "summary": "Large Reasoning Models (LRMs) exhibit human-like cognitive reasoning strategies (e.g. backtracking, cross-verification) during reasoning process, which improves their performance on complex tasks. Currently, reasoning strategies are autonomously selected by LRMs themselves. However, such autonomous selection often produces inefficient or even erroneous reasoning paths. To make reasoning more reliable and flexible, it is important to develop methods for controlling reasoning strategies. Existing methods struggle to control fine-grained reasoning strategies due to conceptual entanglement in LRMs' hidden states. To address this, we leverage Sparse Autoencoders (SAEs) to decompose strategy-entangled hidden states into a disentangled feature space. To identify the few strategy-specific features from the vast pool of SAE features, we propose SAE-Steering, an efficient two-stage feature identification pipeline. SAE-Steering first recalls features that amplify the logits of strategy-specific keywords, filtering out over 99\\% of features, and then ranks the remaining features by their control effectiveness. Using the identified strategy-specific features as control vectors, SAE-Steering outperforms existing methods by over 15\\% in control effectiveness. Furthermore, controlling reasoning strategies can redirect LRMs from erroneous paths to correct ones, achieving a 7\\% absolute accuracy improvement."}
{"id": "2601.03604", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03604", "abs": "https://arxiv.org/abs/2601.03604", "authors": ["Chuanliu Fan", "Zicheng Ma", "Huanran Meng", "Aijia Zhang", "Wenjie Du", "Jun Zhang", "Yi Qin Gao", "Ziqiang Cao", "Guohong Fu"], "title": "Interleaved Tool-Call Reasoning for Protein Function Understanding", "comment": null, "summary": "Recent advances in large language models (LLMs) have highlighted the effectiveness of chain-of-thought reasoning in symbolic domains such as mathematics and programming. However, our study shows that directly transferring such text-based reasoning paradigms to protein function understanding is ineffective: reinforcement learning mainly amplifies superficial keyword patterns while failing to introduce new biological knowledge, resulting in limited generalization. We argue that protein function prediction is a knowledge-intensive scientific task that fundamentally relies on external biological priors and computational tools rather than purely internal reasoning. To address this gap, we propose PFUA, a tool-augmented protein reasoning agent that unifies problem decomposition, tool invocation, and grounded answer generation. Instead of relying on long unconstrained reasoning traces, PFUA integrates domain-specific tools to produce verifiable intermediate evidence. Experiments on four benchmarks demonstrate that PFUA consistently outperforms text-only reasoning models with an average performance improvement of 103%."}
{"id": "2601.03624", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03624", "abs": "https://arxiv.org/abs/2601.03624", "authors": ["Zoran Milosevic", "Fethi Rabhi"], "title": "Architecting Agentic Communities using Design Patterns", "comment": "supplementary material accompanying this paper is also attached .. its title is \"Complete Agentic AI Design Patterns Catalogue\"", "summary": "The rapid evolution of Large Language Models (LLM) and subsequent Agentic AI technologies requires systematic architectural guidance for building sophisticated, production-grade systems. This paper presents an approach for architecting such systems using design patterns derived from enterprise distributed systems standards, formal methods, and industry practice. We classify these patterns into three tiers: LLM Agents (task-specific automation), Agentic AI (adaptive goal-seekers), and Agentic Communities (organizational frameworks where AI agents and human participants coordinate through formal roles, protocols, and governance structures). We focus on Agentic Communities - coordination frameworks encompassing LLM Agents, Agentic AI entities, and humans - most relevant for enterprise and industrial applications. Drawing on established coordination principles from distributed systems, we ground these patterns in a formal framework that specifies collaboration agreements where AI agents and humans fill roles within governed ecosystems. This approach provides both practical guidance and formal verification capabilities, enabling expression of organizational, legal, and ethical rules through accountability mechanisms that ensure operational and verifiable governance of inter-agent communication, negotiation, and intent modeling. We validate this framework through a clinical trial matching case study. Our goal is to provide actionable guidance to practitioners while maintaining the formal rigor essential for enterprise deployment in dynamic, multi-agent ecosystems."}
{"id": "2601.03662", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03662", "abs": "https://arxiv.org/abs/2601.03662", "authors": ["Su-Hyeon Kim", "Hyundong Jin", "Yejin Lee", "Yo-Sub Han"], "title": "How Does the Thinking Step Influence Model Safety? An Entropy-based Safety Reminder for LRMs", "comment": null, "summary": "Large Reasoning Models (LRMs) achieve remarkable success through explicit thinking steps, yet the thinking steps introduce a novel risk by potentially amplifying unsafe behaviors. Despite this vulnerability, conventional defense mechanisms remain ineffective as they overlook the unique reasoning dynamics of LRMs. In this work, we find that the emergence of safe-reminding phrases within thinking steps plays a pivotal role in ensuring LRM safety. Motivated by this finding, we propose SafeRemind, a decoding-time defense method that dynamically injects safe-reminding phrases into thinking steps. By leveraging entropy triggers to intervene at decision-locking points, SafeRemind redirects potentially harmful trajectories toward safer outcomes without requiring any parameter updates. Extensive evaluations across five LRMs and six benchmarks demonstrate that SafeRemind substantially enhances safety, achieving improvements of up to 45.5%p while preserving core reasoning utility."}
{"id": "2601.03672", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03672", "abs": "https://arxiv.org/abs/2601.03672", "authors": ["Chen Zhang", "Kepu Zhang", "Jiatong Zhang", "Xiao Zhang", "Jun Xu"], "title": "Sandwich Reasoning: An Answer-Reasoning-Answer Approach for Low-Latency Query Correction", "comment": null, "summary": "Query correction is a critical entry point in modern search pipelines, demanding high accuracy strictly within real-time latency constraints. Chain-of-Thought (CoT) reasoning improves accuracy but incurs prohibitive latency for real-time query correction. A potential solution is to output an answer before reasoning to reduce latency; however, under autoregressive decoding, the early answer is independent of subsequent reasoning, preventing the model from leveraging its reasoning capability to improve accuracy. To address this issue, we propose Sandwich Reasoning (SandwichR), a novel approach that explicitly aligns a fast initial answer with post-hoc reasoning, enabling low-latency query correction without sacrificing reasoning-aware accuracy. SandwichR follows an Answer-Reasoning-Answer paradigm, producing an initial correction, an explicit reasoning process, and a final refined correction. To align the initial answer with post-reasoning insights, we design a consistency-aware reinforcement learning (RL) strategy: a dedicated consistency reward enforces alignment between the initial and final corrections, while margin-based rejection sampling prioritizes borderline samples where reasoning drives the most impactful corrective gains. Additionally, we construct a high-quality query correction dataset, addressing the lack of specialized benchmarks for complex query correction. Experimental results demonstrate that SandwichR achieves SOTA accuracy comparable to standard CoT while delivering a 40-70% latency reduction, resolving the latency-accuracy trade-off in online search."}
{"id": "2601.03687", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03687", "abs": "https://arxiv.org/abs/2601.03687", "authors": ["Yonatan Vernik", "Alexander Tuisov", "David Izhaki", "Hana Weitman", "Gal A. Kaminka", "Alexander Shleyfman"], "title": "Personalized Medication Planning via Direct Domain Modeling and LLM-Generated Heuristics", "comment": null, "summary": "Personalized medication planning involves selecting medications and determining a dosing schedule to achieve medical goals specific to each individual patient. Previous work successfully demonstrated that automated planners, using general domain-independent heuristics, are able to generate personalized treatments, when the domain and problems are modeled using a general domain description language (\\pddlp). Unfortunately, this process was limited in practice to consider no more than seven medications. In clinical terms, this is a non-starter. In this paper, we explore the use of automatically-generated domain- and problem-specific heuristics to be used with general search, as a method of scaling up medication planning to levels allowing closer work with clinicians. Specifically, we specify the domain programmatically (specifying an initial state and a successor generation procedure), and use an LLM to generate a problem specific heuristic that can be used by a fixed search algorithm (GBFS). The results indicate dramatic improvements in coverage and planning time, scaling up the number of medications to at least 28, and bringing medication planning one step closer to practical applications."}
{"id": "2601.03769", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03769", "abs": "https://arxiv.org/abs/2601.03769", "authors": ["Zihang Li", "Yuhang Wang", "Yikun Zong", "Wenhan Yu", "Xiaokun Yuan", "Runhan Jiang", "Zirui Liu", "Tong Yang", "Arthur Jiang"], "title": "EntroCoT: Enhancing Chain-of-Thought via Adaptive Entropy-Guided Segmentation", "comment": null, "summary": "Chain-of-Thought (CoT) prompting has significantly enhanced the mathematical reasoning capabilities of Large Language Models. We find existing fine-tuning datasets frequently suffer from the \"answer right but reasoning wrong\" probelm, where correct final answers are derived from hallucinated, redundant, or logically invalid intermediate steps. This paper proposes EntroCoT, a unified framework for automatically identifying and refining low-quality CoT supervision traces. EntroCoT first proposes an entropy-based mechanism to segment the reasoning trace into multiple steps at uncertain junctures, and then introduces a Monte Carlo rollout-based mechanism to evaluate the marginal contribution of each step. By accurately filtering deceptive reasoning samples, EntroCoT constructs a high-quality dataset where every intermediate step in each reasoning trace facilitates the final answer. Extensive experiments on mathematical benchmarks demonstrate that fine-tuning on the subset constructed by EntroCoT consistently outperforms the baseslines of full-dataset supervision."}
{"id": "2601.03822", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03822", "abs": "https://arxiv.org/abs/2601.03822", "authors": ["Muyang Zhao", "Qi Qi", "Hao Sun"], "title": "ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition", "comment": null, "summary": "Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered Stochastic Multiple-Choice Knapsack Problem(OS-MCKP). This perspective highlights a meta-cognitive requirement -- anticipating task difficulty, estimating return over investment (ROI), and allocating computation strategically. We propose ROI-Reasoning, a two-stage framework that endows LLMs with intrinsic, budget-aware rationality. In the first stage, Meta-Cognitive Fine-Tuning teaches models to predict reasoning cost and expected utility before generation, enabling explicit solve-or-skip decisions. Next, Rationality-Aware Reinforcement Learning optimizes sequential decision making under a hard token budget, allowing models to learn long-horizon allocation strategies. Across budgeted mathematical reasoning benchmarks, ROI-Reasoning consistently improves overall score while substantially reducing regret under tight computation budgets."}
{"id": "2601.03840", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.03840", "abs": "https://arxiv.org/abs/2601.03840", "authors": ["Racquel Dennison", "Jesse Heyninck", "Thomas Meyer"], "title": "Defeasible Conditionals using Answer Set Programming", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "Defeasible entailment is concerned with drawing plausible conclusions from incomplete information. A foundational framework for modelling defeasible entailment is the KLM framework. Introduced by Kraus, Lehmann, and Magidor, the KLM framework outlines several key properties for defeasible entailment. One of the most prominent algorithms within this framework is Rational Closure (RC). This paper presents a declarative definition for computing RC using Answer Set Programming (ASP). Our approach enables the automatic construction of the minimal ranked model from a given knowledge base and supports entailment checking for specified queries. We formally prove the correctness of our ASP encoding and conduct empirical evaluations to compare the performance of our implementation with that of existing imperative implementations, specifically the InfOCF solver. The results demonstrate that our ASP-based approach adheres to RC's theoretical foundations and offers improved computational efficiency."}
{"id": "2601.03844", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03844", "abs": "https://arxiv.org/abs/2601.03844", "authors": ["Agostino Dovier", "Talissa Dreossi", "Andrea Formisano", "Benedetta Strizzolo"], "title": "XAI-LAW: A Logic Programming Tool for Modeling, Explaining, and Learning Legal Decisions", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "We propose an approach to model articles of the Italian Criminal Code (ICC), using Answer Set Programming (ASP), and to semi-automatically learn legal rules from examples based on prior judicial decisions. The developed tool is intended to support legal experts during the criminal trial phase by providing reasoning and possible legal outcomes. The methodology involves analyzing and encoding articles of the ICC in ASP, including \"crimes against the person\" and property offenses. The resulting model is validated on a set of previous verdicts and refined as necessary. During the encoding process, contradictions may arise; these are properly handled by the system, which also generates possible decisions for new cases and provides explanations through a tool that leverages the \"supportedness\" of stable models. The automatic explainability offered by the tool can also be used to clarify the logic behind judicial decisions, making the decision-making process more interpretable. Furthermore, the tool integrates an inductive logic programming system for ASP, which is employed to generalize legal rules from case examples."}
{"id": "2601.03845", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.03845", "abs": "https://arxiv.org/abs/2601.03845", "authors": ["Akihiro Takemura", "Masayuki Otani", "Katsumi Inoue"], "title": "Formally Explaining Decision Tree Models with Answer Set Programming", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "Decision tree models, including random forests and gradient-boosted decision trees, are widely used in machine learning due to their high predictive performance.  However, their complex structures often make them difficult to interpret, especially in safety-critical applications where model decisions require formal justification.  Recent work has demonstrated that logical and abductive explanations can be derived through automated reasoning techniques.  In this paper, we propose a method for generating various types of explanations, namely, sufficient, contrastive, majority, and tree-specific explanations, using Answer Set Programming (ASP).  Compared to SAT-based approaches, our ASP-based method offers greater flexibility in encoding user preferences and supports enumeration of all possible explanations.  We empirically evaluate the approach on a diverse set of datasets and demonstrate its effectiveness and limitations compared to existing methods."}
{"id": "2601.03847", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03847", "abs": "https://arxiv.org/abs/2601.03847", "authors": ["Ly Ly Trieu", "Tran Cao Son"], "title": "xDNN(ASP): Explanation Generation System for Deep Neural Networks powered by Answer Set Programming", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "Explainable artificial intelligence (xAI) has gained significant attention in recent years. Among other things, explainablility for deep neural networks has been a topic of intensive research due to the meteoric rise in prominence of deep neural networks and their \"black-box\" nature. xAI approaches can be characterized along different dimensions such as their scope (global versus local explanations) or underlying methodologies (statistic-based versus rule-based strategies). Methods generating global explanations aim to provide reasoning process applicable to all possible output classes while local explanation methods focus only on a single, specific class. SHAP (SHapley Additive exPlanations), a well-known statistical technique, identifies important features of a network. Deep neural network rule extraction method constructs IF-THEN rules that link input conditions to a class. Another approach focuses on generating counterfactuals which help explain how small changes to an input can affect the model's predictions. However, these techniques primarily focus on the input-output relationship and thus neglect the structure of the network in explanation generation.   In this work, we propose xDNN(ASP), an explanation generation system for deep neural networks that provides global explanations. Given a neural network model and its training data, xDNN(ASP) extracts a logic program under answer set semantics that-in the ideal case-represents the trained model, i.e., answer sets of the extracted program correspond one-to-one to input-output pairs of the network. We demonstrate experimentally, using two synthetic datasets, that not only the extracted logic program maintains a high-level of accuracy in the prediction task, but it also provides valuable information for the understanding of the model such as the importance of features as well as the impact of hidden nodes on the prediction. The latter can be used as a guide for reducing the number of nodes used in hidden layers, i.e., providing a means for optimizing the network."}
{"id": "2601.03850", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03850", "abs": "https://arxiv.org/abs/2601.03850", "authors": ["Veronika Semmelrock", "Gerhard Friedrich"], "title": "Investigating the Grounding Bottleneck for a Large-Scale Configuration Problem: Existing Tools and Constraint-Aware Guessing", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "Answer set programming (ASP) aims to realize the AI vision: The user specifies the problem, and the computer solves it. Indeed, ASP has made this vision true in many application domains. However, will current ASP solving techniques scale up for large configuration problems? As a benchmark for such problems, we investigated the configuration of electronic systems, which may comprise more than 30,000 components. We show the potential and limits of current ASP technology, focusing on methods that address the so-called grounding bottleneck, i.e., the sharp increase of memory demands in the size of the problem instances. To push the limits, we investigated the incremental solving approach, which proved effective in practice. However, even in the incremental approach, memory demands impose significant limits. Based on an analysis of grounding, we developed the method constraint-aware guessing, which significantly reduced the memory need."}
{"id": "2601.03905", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03905", "abs": "https://arxiv.org/abs/2601.03905", "authors": ["Cheng Qian", "Emre Can Acikgoz", "Bingxuan Li", "Xiusi Chen", "Yuji Zhang", "Bingxiang He", "Qinyu Luo", "Dilek Hakkani-Tür", "Gokhan Tur", "Yunzhu Li", "Heng Ji", "Heng Ji"], "title": "Current Agents Fail to Leverage World Model as Tool for Foresight", "comment": "36 Pages, 13 Figures, 17 Tables", "summary": "Agents built on vision-language models increasingly face tasks that demand anticipating future states rather than relying on short-horizon reasoning. Generative world models offer a promising remedy: agents could use them as external simulators to foresee outcomes before acting. This paper empirically examines whether current agents can leverage such world models as tools to enhance their cognition. Across diverse agentic and visual question answering tasks, we observe that some agents rarely invoke simulation (fewer than 1%), frequently misuse predicted rollouts (approximately 15%), and often exhibit inconsistent or even degraded performance (up to 5%) when simulation is available or enforced. Attribution analysis further indicates that the primary bottleneck lies in the agents' capacity to decide when to simulate, how to interpret predicted outcomes, and how to integrate foresight into downstream reasoning. These findings underscore the need for mechanisms that foster calibrated, strategic interaction with world models, paving the way toward more reliable anticipatory cognition in future agent systems."}
{"id": "2601.03948", "categories": ["cs.AI", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2601.03948", "abs": "https://arxiv.org/abs/2601.03948", "authors": ["Rui Sun", "Yifan Sun", "Sheng Xu", "Li Zhao", "Jing Li", "Daxin Jiang", "Chen Hua", "Zuo Bai"], "title": "Trade-R1: Bridging Verifiable Rewards to Stochastic Environments via Process-Level Reasoning Verification", "comment": null, "summary": "Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to achieve remarkable reasoning in domains like mathematics and coding, where verifiable rewards provide clear signals. However, extending this paradigm to financial decision is challenged by the market's stochastic nature: rewards are verifiable but inherently noisy, causing standard RL to degenerate into reward hacking. To address this, we propose Trade-R1, a model training framework that bridges verifiable rewards to stochastic environments via process-level reasoning verification. Our key innovation is a verification method that transforms the problem of evaluating reasoning over lengthy financial documents into a structured Retrieval-Augmented Generation (RAG) task. We construct a triangular consistency metric, assessing pairwise alignment between retrieved evidence, reasoning chains, and decisions to serve as a validity filter for noisy market returns. We explore two reward integration strategies: Fixed-effect Semantic Reward (FSR) for stable alignment signals, and Dynamic-effect Semantic Reward (DSR) for coupled magnitude optimization. Experiments on different country asset selection demonstrate that our paradigm reduces reward hacking, with DSR achieving superior cross-market generalization while maintaining the highest reasoning consistency."}
{"id": "2601.03969", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03969", "abs": "https://arxiv.org/abs/2601.03969", "authors": ["Wei Wu", "Liyi Chen", "Congxi Xiao", "Tianfu Wang", "Qimeng Wang", "Chengqiang Lu", "Yan Gao", "Yi Wu", "Yao Hu", "Hui Xiong"], "title": "Anti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models", "comment": null, "summary": "Large reasoning models enhanced by reinforcement learning with verifiable rewards have achieved significant performance gains by extending their chain-of-thought. However, this paradigm incurs substantial deployment costs as models often exhibit excessive verbosity on simple queries. Existing efficient reasoning methods relying on explicit length penalties often introduce optimization conflicts and leave the generative mechanisms driving overthinking largely unexamined. In this paper, we identify a phenomenon termed length shift where models increasingly generate unnecessary reasoning on trivial inputs during training. To address this, we introduce Dynamic Outlier Truncation (DOT), a training-time intervention that selectively suppresses redundant tokens. This method targets only the extreme tail of response lengths within fully correct rollout groups while preserving long-horizon reasoning capabilities for complex problems. To complement this intervention and ensure stable convergence, we further incorporate auxiliary KL regularization and predictive dynamic sampling. Experimental results across multiple model scales demonstrate that our approach significantly pushes the efficiency-performance Pareto frontier outward. Notably, on the AIME-24, our method reduces inference token usage by 78% while simultaneously increasing accuracy compared to the initial policy and surpassing state-of-the-art efficient reasoning methods."}
{"id": "2601.04035", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04035", "abs": "https://arxiv.org/abs/2601.04035", "authors": ["Yilin Cao", "Yufeng Zhong", "Zhixiong Zeng", "Liming Zheng", "Jing Huang", "Haibo Qiu", "Peng Shi", "Wenji Mao", "Wan Guanglu"], "title": "MobileDreamer: Generative Sketch World Model for GUI Agent", "comment": null, "summary": "Mobile GUI agents have shown strong potential in real-world automation and practical applications. However, most existing agents remain reactive, making decisions mainly from current screen, which limits their performance on long-horizon tasks. Building a world model from repeated interactions enables forecasting action outcomes and supports better decision making for mobile GUI agents. This is challenging because the model must predict post-action states with spatial awareness while remaining efficient enough for practical deployment. In this paper, we propose MobileDreamer, an efficient world-model-based lookahead framework to equip the GUI agents based on the future imagination provided by the world model. It consists of textual sketch world model and rollout imagination for GUI agent. Textual sketch world model forecasts post-action states through a learning process to transform digital images into key task-related sketches, and designs a novel order-invariant learning strategy to preserve the spatial information of GUI elements. The rollout imagination strategy for GUI agent optimizes the action-selection process by leveraging the prediction capability of world model. Experiments on Android World show that MobileDreamer achieves state-of-the-art performance and improves task success by 5.25%. World model evaluations further verify that our textual sketch modeling accurately forecasts key GUI elements."}
{"id": "2601.04060", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04060", "abs": "https://arxiv.org/abs/2601.04060", "authors": ["Jinwei Su", "Qizhen Lan", "Zeyu Wang", "Yinghui Xia", "Hairu Wen", "Yiqun Duan", "Xi Xiao", "Tianyu Shi", "Yang Jingsong", "Lewei He"], "title": "ComfySearch: Autonomous Exploration and Reasoning for ComfyUI Workflows", "comment": null, "summary": "AI-generated content has progressed from monolithic models to modular workflows, especially on platforms like ComfyUI, allowing users to customize complex creative pipelines. However, the large number of components in ComfyUI and the difficulty of maintaining long-horizon structural consistency under strict graph constraints frequently lead to low pass rates and workflows of limited quality. To tackle these limitations, we present ComfySearch, an agentic framework that can effectively explore the component space and generate functional ComfyUI pipelines via validation-guided workflow construction. Experiments demonstrate that ComfySearch substantially outperforms existing methods on complex and creative tasks, achieving higher executability (pass) rates, higher solution rates, and stronger generalization."}
{"id": "2601.04170", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04170", "abs": "https://arxiv.org/abs/2601.04170", "authors": ["Abhishek Rath"], "title": "Agent Drift: Quantifying Behavioral Degradation in Multi-Agent LLM Systems Over Extended Interactions", "comment": null, "summary": "Multi-agent Large Language Model (LLM) systems have emerged as powerful architectures for complex task decomposition and collaborative problem-solving. However, their long-term behavioral stability remains largely unexamined. This study introduces the concept of agent drift, defined as the progressive degradation of agent behavior, decision quality, and inter-agent coherence over extended interaction sequences. We present a comprehensive theoretical framework for understanding drift phenomena, proposing three distinct manifestations: semantic drift (progressive deviation from original intent), coordination drift (breakdown in multi-agent consensus mechanisms), and behavioral drift (emergence of unintended strategies).\n  We introduce the Agent Stability Index (ASI), a novel composite metric framework for quantifying drift across twelve dimensions, including response consistency, tool usage patterns, reasoning pathway stability, and inter-agent agreement rates. Through simulation-based analysis and theoretical modeling, we demonstrate how unchecked agent drift can lead to substantial reductions in task completion accuracy and increased human intervention requirements.\n  We propose three mitigation strategies: episodic memory consolidation, drift-aware routing protocols, and adaptive behavioral anchoring. Theoretical analysis suggests these approaches can significantly reduce drift-related errors while maintaining system throughput. This work establishes a foundational methodology for monitoring, measuring, and mitigating agent drift in production agentic AI systems, with direct implications for enterprise deployment reliability and AI safety research."}
